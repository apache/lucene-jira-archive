Index: src/test/org/apache/lucene/analysis/TestAnalyzers.java
===================================================================
--- src/test/org/apache/lucene/analysis/TestAnalyzers.java	(revision 826223)
+++ src/test/org/apache/lucene/analysis/TestAnalyzers.java	(working copy)
@@ -74,7 +74,7 @@
   }
 
   public void testStop() throws Exception {
-    Analyzer a = new StopAnalyzer();
+    Analyzer a = new StopAnalyzer(true);
     assertAnalyzesTo(a, "foo bar FOO BAR", 
                      new String[] { "foo", "bar", "foo", "bar" });
     assertAnalyzesTo(a, "foo a bar such FOO THESE BAR", 
@@ -120,6 +120,10 @@
   }
 
   private static class MyStandardAnalyzer extends StandardAnalyzer {
+    public MyStandardAnalyzer() {
+      super(org.apache.lucene.util.Version.LUCENE_CURRENT);
+    }
+  
     public TokenStream tokenStream(String field, Reader reader) {
       return new WhitespaceAnalyzer().tokenStream(field, reader);
     }
Index: src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java
===================================================================
--- src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java	(revision 826223)
+++ src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java	(working copy)
@@ -26,16 +26,16 @@
 
 public class TestStandardAnalyzer extends BaseTokenStreamTestCase {
 
-  private Analyzer a = new StandardAnalyzer();
+  private Analyzer a = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
 
   public void testMaxTermLength() throws Exception {
-    StandardAnalyzer sa = new StandardAnalyzer();
+    StandardAnalyzer sa = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     sa.setMaxTokenLength(5);
     assertAnalyzesTo(sa, "ab cd toolong xy z", new String[]{"ab", "cd", "xy", "z"});
   }
 
   public void testMaxTermLength2() throws Exception {
-    StandardAnalyzer sa = new StandardAnalyzer();
+    StandardAnalyzer sa = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     assertAnalyzesTo(sa, "ab cd toolong xy z", new String[]{"ab", "cd", "toolong", "xy", "z"});
     sa.setMaxTokenLength(5);
     
@@ -99,24 +99,26 @@
 
   public void testLucene1140() throws Exception {
     try {
-      StandardAnalyzer analyzer = new StandardAnalyzer(true);
+      StandardAnalyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
       assertAnalyzesTo(analyzer, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
     } catch (NullPointerException e) {
-      assertTrue("Should not throw an NPE and it did", false);
+      fail("Should not throw an NPE and it did");
     }
 
   }
 
   public void testDomainNames() throws Exception {
     // Don't reuse a because we alter its state (setReplaceInvalidAcronym)
-    StandardAnalyzer a2 = new StandardAnalyzer();
+    StandardAnalyzer a2 = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     // domain names
     assertAnalyzesTo(a2, "www.nutch.org", new String[]{"www.nutch.org"});
     //Notice the trailing .  See https://issues.apache.org/jira/browse/LUCENE-1068.
     // the following should be recognized as HOST:
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
-    a2.setReplaceInvalidAcronym(false);
+    /* no support for 2.3 here:
+    a2 = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_23);
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "wwwnutchorg" }, new String[] { "<ACRONYM>" });
+    */
   }
 
   public void testEMailAddresses() throws Exception {
@@ -220,11 +222,4 @@
                     "<ALPHANUM>", "<NUM>", "<HOST>", "<NUM>", "<ALPHANUM>",
                     "<ALPHANUM>", "<HOST>"});
   }
-
-  /** @deprecated this should be removed in the 3.0. */
-   public void testDeprecatedAcronyms() throws Exception {
- 	// test backward compatibility for applications that require the old behavior.
- 	// this should be removed once replaceDepAcronym is removed.
- 	  assertAnalyzesTo(a, "lucene.apache.org.", new String[]{ "lucene.apache.org" }, new String[] { "<HOST>" });
-   }
 }
Index: src/test/org/apache/lucene/analysis/TestStopAnalyzer.java
===================================================================
--- src/test/org/apache/lucene/analysis/TestStopAnalyzer.java	(revision 826223)
+++ src/test/org/apache/lucene/analysis/TestStopAnalyzer.java	(working copy)
@@ -61,7 +61,7 @@
     stopWordsSet.add("good");
     stopWordsSet.add("test");
     stopWordsSet.add("analyzer");
-    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));
+    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, false);
     StringReader reader = new StringReader("This is a good test of the english stop analyzer");
     TokenStream stream = newStop.tokenStream("test", reader);
     assertNotNull(stream);
@@ -76,29 +76,23 @@
   }
 
   public void testStopListPositions() throws IOException {
-    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();
-    StopFilter.setEnablePositionIncrementsDefault(true);
-    try {
-      Set stopWordsSet = new HashSet();
-      stopWordsSet.add("good");
-      stopWordsSet.add("test");
-      stopWordsSet.add("analyzer");
-      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));
-      StringReader reader = new StringReader("This is a good test of the english stop analyzer with positions");
-      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};
-      TokenStream stream = newStop.tokenStream("test", reader);
-      assertNotNull(stream);
-      int i = 0;
-      TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-      PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
+    Set stopWordsSet = new HashSet();
+    stopWordsSet.add("good");
+    stopWordsSet.add("test");
+    stopWordsSet.add("analyzer");
+    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, true);
+    StringReader reader = new StringReader("This is a good test of the english stop analyzer with positions");
+    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};
+    TokenStream stream = newStop.tokenStream("test", reader);
+    assertNotNull(stream);
+    int i = 0;
+    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
 
-      while (stream.incrementToken()) {
-        String text = termAtt.term();
-        assertFalse(stopWordsSet.contains(text));
-        assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());
-      }
-    } finally {
-      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);
+    while (stream.incrementToken()) {
+      String text = termAtt.term();
+      assertFalse(stopWordsSet.contains(text));
+      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());
     }
   }
 
Index: src/test/org/apache/lucene/analysis/TestStopFilter.java
===================================================================
--- src/test/org/apache/lucene/analysis/TestStopFilter.java	(revision 826223)
+++ src/test/org/apache/lucene/analysis/TestStopFilter.java	(working copy)
@@ -23,7 +23,9 @@
 import java.io.IOException;
 import java.io.StringReader;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Set;
+import java.util.HashSet;
 
 
 public class TestStopFilter extends BaseTokenStreamTestCase {
@@ -34,8 +36,8 @@
 
   public void testExactCase() throws IOException {
     StringReader reader = new StringReader("Now is The Time");
-    String[] stopWords = new String[] { "is", "the", "Time" };
-    TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopWords);
+    Set stopWords = new HashSet(Arrays.asList(new String[]{"is", "the", "Time"}));
+    TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopWords, false);
     final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals("Now", termAtt.term());
@@ -46,7 +48,7 @@
 
   public void testIgnoreCase() throws IOException {
     StringReader reader = new StringReader("Now is The Time");
-    String[] stopWords = new String[] { "is", "the", "Time" };
+    Set stopWords = new HashSet(Arrays.asList(new String[]{"is", "the", "Time"}));
     TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopWords, true);
     final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
Index: src/test/org/apache/lucene/document/TestBinaryDocument.java
===================================================================
--- src/test/org/apache/lucene/document/TestBinaryDocument.java	(revision 826223)
+++ src/test/org/apache/lucene/document/TestBinaryDocument.java	(working copy)
@@ -62,7 +62,7 @@
     
     /** add the doc to a ram index */
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.addDocument(doc);
     writer.close();
     
@@ -100,7 +100,7 @@
     
     /** add the doc to a ram index */
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.addDocument(doc);
     writer.close();
     
Index: src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- src/test/org/apache/lucene/document/TestDocument.java	(revision 826223)
+++ src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -157,7 +157,7 @@
     public void testGetValuesForIndexedDocument() throws Exception
     {
         RAMDirectory dir = new RAMDirectory();
-        IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+        IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
         writer.addDocument(makeDocumentWithFields());
         writer.close();
 
@@ -228,7 +228,7 @@
       doc.add(new Field("keyword", "test", Field.Store.YES, Field.Index.NOT_ANALYZED));
 
       RAMDirectory dir = new RAMDirectory();
-      IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       writer.addDocument(doc);
       field.setValue("id2");
       writer.addDocument(doc);
Index: src/test/org/apache/lucene/index/TestDirectoryReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestDirectoryReader.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestDirectoryReader.java	(working copy)
@@ -193,7 +193,7 @@
   }
 
   private void addDoc(RAMDirectory ramDir1, String s, boolean create) throws IOException {
-    IndexWriter iw = new IndexWriter(ramDir1, new StandardAnalyzer(), create, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter iw = new IndexWriter(ramDir1, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), create, IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     doc.add(new Field("body", s, Field.Store.YES, Field.Index.ANALYZED));
     iw.addDocument(doc);
Index: src/test/org/apache/lucene/index/TestDocumentWriter.java
===================================================================
--- src/test/org/apache/lucene/index/TestDocumentWriter.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestDocumentWriter.java	(working copy)
@@ -259,7 +259,7 @@
     doc.add(new Field("f2", "v1", Store.YES, Index.NOT_ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
     doc.add(new Field("f2", "v2", Store.YES, Index.NOT_ANALYZED, TermVector.NO));
 
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.addDocument(doc);
     writer.close();
 
@@ -292,7 +292,7 @@
     doc.add(f);
     doc.add(new Field("f2", "v2", Store.YES, Index.NO));
 
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.addDocument(doc);
     writer.optimize(); // be sure to have a single segment
     writer.close();
Index: src/test/org/apache/lucene/index/TestIndexReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReader.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexReader.java	(working copy)
@@ -76,7 +76,7 @@
       commitUserData.put("foo", "fighters");
       
       // set up writer
-      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       writer.setMaxBufferedDocs(2);
       for(int i=0;i<27;i++)
         addDocumentWithFields(writer);
@@ -98,7 +98,7 @@
       assertTrue(c.equals(r.getIndexCommit()));
 
       // Change the index
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.setMaxBufferedDocs(2);
       for(int i=0;i<7;i++)
         addDocumentWithFields(writer);
@@ -109,7 +109,7 @@
       assertFalse(r2.getIndexCommit().isOptimized());
       r3.close();
 
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.optimize();
       writer.close();
 
@@ -123,19 +123,19 @@
     public void testIsCurrent() throws Exception
     {
       RAMDirectory d = new MockRAMDirectory();
-      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       addDocumentWithFields(writer);
       writer.close();
       // set up reader:
       IndexReader reader = IndexReader.open(d, false);
       assertTrue(reader.isCurrent());
       // modify index by adding another document:
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       addDocumentWithFields(writer);
       writer.close();
       assertFalse(reader.isCurrent());
       // re-create index:
-      writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       addDocumentWithFields(writer);
       writer.close();
       assertFalse(reader.isCurrent());
@@ -151,7 +151,7 @@
     {
         RAMDirectory d = new MockRAMDirectory();
         // set up writer
-        IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+        IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
         addDocumentWithFields(writer);
         writer.close();
         // set up reader
@@ -163,7 +163,7 @@
         assertTrue(fieldNames.contains("unstored"));
         reader.close();
         // add more documents
-        writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+        writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
         // want to get some more segments here
         for (int i = 0; i < 5*writer.getMergeFactor(); i++)
         {
@@ -243,7 +243,7 @@
   public void testTermVectors() throws Exception {
     RAMDirectory d = new MockRAMDirectory();
     // set up writer
-    IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     // want to get some more segments here
     // new termvector fields
     for (int i = 0; i < 5 * writer.getMergeFactor(); i++) {
@@ -1418,7 +1418,7 @@
       RAMDirectory d = new MockRAMDirectory();
 
       // set up writer
-      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       writer.setMaxBufferedDocs(2);
       for(int i=0;i<27;i++)
         addDocumentWithFields(writer);
@@ -1434,7 +1434,7 @@
       assertTrue(c.equals(r.getIndexCommit()));
 
       // Change the index
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.setMaxBufferedDocs(2);
       for(int i=0;i<7;i++)
         addDocumentWithFields(writer);
@@ -1445,7 +1445,7 @@
       assertFalse(r2.getIndexCommit().isOptimized());
       r2.close();
 
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.optimize();
       writer.close();
 
@@ -1459,7 +1459,7 @@
 
     public void testReadOnly() throws Throwable {
       RAMDirectory d = new MockRAMDirectory();
-      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       addDocumentWithFields(writer);
       writer.commit();
       addDocumentWithFields(writer);
@@ -1473,7 +1473,7 @@
         // expected
       }
       
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       addDocumentWithFields(writer);
       writer.close();
 
@@ -1490,7 +1490,7 @@
         // expected
       }
 
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.optimize();
       writer.close();
 
@@ -1508,7 +1508,7 @@
       }
 
       // Make sure write lock isn't held
-      writer = new IndexWriter(d, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+      writer = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
       writer.close();
 
       r3.close();
@@ -1518,7 +1518,7 @@
   // LUCENE-1474
   public void testIndexReader() throws Exception {
     Directory dir = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(),
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.UNLIMITED);
     writer.addDocument(createDocument("a"));
     writer.addDocument(createDocument("b"));
@@ -1536,7 +1536,7 @@
   public void testIndexReaderUnDeleteAll() throws Exception {
     MockRAMDirectory dir = new MockRAMDirectory();
     dir.setPreventDoubleWrite(false);
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(),
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.UNLIMITED);
     writer.addDocument(createDocument("a"));
     writer.addDocument(createDocument("b"));
@@ -1578,7 +1578,7 @@
 
     Directory dir = new MockRAMDirectory();
     
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(),
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.LIMITED);
 
     writer.setMaxBufferedDocs(2);
Index: src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(working copy)
@@ -69,7 +69,7 @@
   protected void setUp() throws Exception {
     super.setUp();
     similarityOne = new SimilarityOne();
-    anlzr = new StandardAnalyzer();
+    anlzr = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
   }
   
   /**
Index: src/test/org/apache/lucene/index/TestIndexReaderReopen.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(working copy)
@@ -687,7 +687,7 @@
     final Directory dir = new MockRAMDirectory();
     final int n = 150;
 
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     for (int i = 0; i < n; i++) {
       writer.addDocument(createDocument(i, 3));
     }
@@ -705,7 +705,7 @@
           modifier.deleteDocument(i % modifier.maxDoc());
           modifier.close();
         } else {
-          IndexWriter modifier = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+          IndexWriter modifier = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
           modifier.addDocument(createDocument(n + i, 6));
           modifier.close();
         }
Index: src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -547,7 +547,7 @@
     */
     public void testWickedLongTerm() throws IOException {
       RAMDirectory dir = new RAMDirectory();
-      IndexWriter writer  = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter writer  = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
 
       char[] chars = new char[DocumentsWriter.CHAR_BLOCK_SIZE-1];
       Arrays.fill(chars, 'x');
@@ -591,7 +591,7 @@
       // maximum length term, and search on that term:
       doc = new Document();
       doc.add(new Field("content", bigTerm, Field.Store.NO, Field.Index.ANALYZED));
-      StandardAnalyzer sa = new StandardAnalyzer();
+      StandardAnalyzer sa = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
       sa.setMaxTokenLength(100000);
       writer  = new IndexWriter(dir, sa, IndexWriter.MaxFieldLength.LIMITED);
       writer.addDocument(doc);
@@ -1579,7 +1579,7 @@
    */
   public void testBadSegment() throws IOException {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter ir = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter ir = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     
     Document document = new Document();
     document.add(new Field("tvtest", "", Field.Store.NO, Field.Index.ANALYZED,
@@ -1592,7 +1592,7 @@
   // LUCENE-1008
   public void testNoTermVectorAfterTermVector() throws IOException {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document document = new Document();
     document.add(new Field("tvtest", "a b c", Field.Store.NO, Field.Index.ANALYZED,
         Field.TermVector.YES));
@@ -1618,7 +1618,7 @@
   // LUCENE-1010
   public void testNoTermVectorAfterTermVectorMerge() throws IOException {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document document = new Document();
     document.add(new Field("tvtest", "a b c", Field.Store.NO, Field.Index.ANALYZED,
         Field.TermVector.YES));
@@ -1650,7 +1650,7 @@
     int pri = Thread.currentThread().getPriority();
     try {
       MockRAMDirectory dir = new MockRAMDirectory();
-      IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+      IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
       Document document = new Document();
       document.add(new Field("tvtest", "a b c", Field.Store.NO, Field.Index.ANALYZED,
                              Field.TermVector.YES));
@@ -1688,7 +1688,7 @@
   // LUCENE-1013
   public void testSetMaxMergeDocs() throws IOException {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     iw.setMergeScheduler(new MyMergeScheduler());
     iw.setMaxMergeDocs(20);
     iw.setMaxBufferedDocs(2);
@@ -2737,7 +2737,7 @@
     Directory dir = new MockRAMDirectory();
     for(int iter=0;iter<2;iter++) {
       IndexWriter writer = new IndexWriter(dir,
-                                           new StandardAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
+                                           new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);
       writer.setMaxBufferedDocs(2);
       writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
       writer.setMergeScheduler(new SerialMergeScheduler());
@@ -2770,7 +2770,7 @@
       reader.close();
 
       writer = new IndexWriter(dir,
-                               new StandardAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
+                               new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);
       writer.setMaxBufferedDocs(2);
       writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
       writer.setMergeScheduler(new SerialMergeScheduler());
@@ -2789,7 +2789,7 @@
     Directory dir = new MockRAMDirectory();
     for(int iter=0;iter<2;iter++) {
       IndexWriter writer = new IndexWriter(dir,
-                                           new StandardAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
+                                           new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);
       writer.setMaxBufferedDocs(2);
       writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
       writer.setMergeScheduler(new SerialMergeScheduler());
@@ -2826,7 +2826,7 @@
   public void testTermVectorCorruption3() throws IOException {
     Directory dir = new MockRAMDirectory();
     IndexWriter writer = new IndexWriter(dir,
-                                         new StandardAnalyzer(),
+                                         new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(2);
     writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
@@ -2848,7 +2848,7 @@
     writer.close();
 
     writer = new IndexWriter(dir,
-                             new StandardAnalyzer(),
+                             new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                              IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(2);
     writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
@@ -2896,7 +2896,7 @@
   public void testExpungeDeletes() throws IOException {
     Directory dir = new MockRAMDirectory();
     IndexWriter writer = new IndexWriter(dir,
-                                         new StandardAnalyzer(),
+                                         new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(2);
     writer.setRAMBufferSizeMB(IndexWriter.DISABLE_AUTO_FLUSH);
@@ -2924,7 +2924,7 @@
     ir.close();
 
     writer = new IndexWriter(dir,
-                             new StandardAnalyzer(),
+                             new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                              IndexWriter.MaxFieldLength.LIMITED);
     assertEquals(8, writer.numDocs());
     assertEquals(10, writer.maxDoc());
@@ -2942,7 +2942,7 @@
   public void testExpungeDeletes2() throws IOException {
     Directory dir = new MockRAMDirectory();
     IndexWriter writer = new IndexWriter(dir,
-                                         new StandardAnalyzer(),
+                                         new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(2);
     writer.setMergeFactor(50);
@@ -2971,7 +2971,7 @@
     ir.close();
 
     writer = new IndexWriter(dir,
-                             new StandardAnalyzer(),
+                             new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                              IndexWriter.MaxFieldLength.LIMITED);
     writer.setMergeFactor(3);
     assertEquals(49, writer.numDocs());
@@ -2989,7 +2989,7 @@
   public void testExpungeDeletes3() throws IOException {
     Directory dir = new MockRAMDirectory();
     IndexWriter writer = new IndexWriter(dir,
-                                         new StandardAnalyzer(),
+                                         new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                                          IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(2);
     writer.setMergeFactor(50);
@@ -3018,7 +3018,7 @@
     ir.close();
 
     writer = new IndexWriter(dir,
-                             new StandardAnalyzer(),
+                             new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),
                              IndexWriter.MaxFieldLength.LIMITED);
     // Force many merges to happen
     writer.setMergeFactor(3);
@@ -4021,7 +4021,7 @@
 
     final List thrown = new ArrayList();
 
-    final IndexWriter writer = new IndexWriter(new MockRAMDirectory(), new StandardAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED) {
+    final IndexWriter writer = new IndexWriter(new MockRAMDirectory(), new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED) {
         public void message(final String message) {
           if (message.startsWith("now flush at close") && 0 == thrown.size()) {
             thrown.add(null);
@@ -4174,7 +4174,7 @@
   // LUCENE-1448
   public void testEndOffsetPositionStopFilter() throws Exception {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter w = new IndexWriter(dir, new StopAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w = new IndexWriter(dir, new StopAnalyzer(true), IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     Field f = new Field("field", "abcd the", Field.Store.NO, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
     doc.add(f);
@@ -4196,7 +4196,7 @@
   // LUCENE-1448
   public void testEndOffsetPositionStandard() throws Exception {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     Field f = new Field("field", "abcd the  ", Field.Store.NO,
         Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
@@ -4226,7 +4226,7 @@
   // LUCENE-1448
   public void testEndOffsetPositionStandardEmptyField() throws Exception {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     Field f = new Field("field", "", Field.Store.NO,
                         Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
@@ -4253,7 +4253,7 @@
   // LUCENE-1448
   public void testEndOffsetPositionStandardEmptyField2() throws Exception {
     MockRAMDirectory dir = new MockRAMDirectory();
-    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
 
     Field f = new Field("field", "abcd", Field.Store.NO,
Index: src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexWriterLockRelease.java	(working copy)
@@ -75,10 +75,10 @@
         IndexWriter im;
         FSDirectory dir = FSDirectory.open(this.__test_dir);
         try {
-            im = new IndexWriter(dir, new org.apache.lucene.analysis.standard.StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+            im = new IndexWriter(dir, new org.apache.lucene.analysis.standard.StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
         } catch (FileNotFoundException e) {
             try {
-                im = new IndexWriter(dir, new org.apache.lucene.analysis.standard.StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+                im = new IndexWriter(dir, new org.apache.lucene.analysis.standard.StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
             } catch (FileNotFoundException e1) {
             }
         } finally {
Index: src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -56,7 +56,7 @@
 
     Directory merged = new MockRAMDirectory();
 
-    IndexWriter writer = new IndexWriter(merged, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(merged, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMergeFactor(2);
 
     writer.addIndexesNoOptimize(new Directory[]{indexA, indexB});
@@ -93,7 +93,7 @@
   private void fillIndex(Directory dir, int start, int numDocs) throws IOException
   {
 
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMergeFactor(2);
     writer.setMaxBufferedDocs(2);
 
Index: src/test/org/apache/lucene/index/TestNorms.java
===================================================================
--- src/test/org/apache/lucene/index/TestNorms.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestNorms.java	(working copy)
@@ -63,7 +63,7 @@
   protected void setUp() throws Exception {
     super.setUp();
     similarityOne = new SimilarityOne();
-    anlzr = new StandardAnalyzer();
+    anlzr = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
   }
 
   /**
Index: src/test/org/apache/lucene/index/TestOmitTf.java
===================================================================
--- src/test/org/apache/lucene/index/TestOmitTf.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestOmitTf.java	(working copy)
@@ -57,7 +57,7 @@
   // omitTermFreqAndPositions bit in the FieldInfo
   public void testOmitTermFreqAndPositions() throws Exception {
     Directory ram = new MockRAMDirectory();
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter writer = new IndexWriter(ram, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     Document d = new Document();
         
@@ -103,7 +103,7 @@
   // omitTermFreqAndPositions for the same field works
   public void testMixedMerge() throws Exception {
     Directory ram = new MockRAMDirectory();
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter writer = new IndexWriter(ram, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(3);
     writer.setMergeFactor(2);
@@ -156,7 +156,7 @@
   // field, 
   public void testMixedRAM() throws Exception {
     Directory ram = new MockRAMDirectory();
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter writer = new IndexWriter(ram, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(10);
     writer.setMergeFactor(2);
@@ -204,7 +204,7 @@
   // Verifies no *.prx exists when all fields omit term freq:
   public void testNoPrxFile() throws Throwable {
     Directory ram = new MockRAMDirectory();
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter writer = new IndexWriter(ram, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(3);
     writer.setMergeFactor(2);
@@ -235,7 +235,7 @@
   // Test scores with one field with Term Freqs and one without, otherwise with equal content 
   public void testBasic() throws Exception {
     Directory dir = new MockRAMDirectory();  
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter writer = new IndexWriter(dir, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMergeFactor(2);
     writer.setMaxBufferedDocs(2);
Index: src/test/org/apache/lucene/index/TestParallelReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestParallelReader.java	(revision 826223)
+++ src/test/org/apache/lucene/index/TestParallelReader.java	(working copy)
@@ -105,7 +105,7 @@
 
     // one document only:
     Directory dir2 = new MockRAMDirectory();
-    IndexWriter w2 = new IndexWriter(dir2, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w2 = new IndexWriter(dir2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document d3 = new Document();
     d3.add(new Field("f3", "v1", Field.Store.YES, Field.Index.ANALYZED));
     w2.addDocument(d3);
@@ -150,13 +150,13 @@
     Directory dir2 = getDir2();
     
     // add another document to ensure that the indexes are not optimized
-    IndexWriter modifier = new IndexWriter(dir1, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter modifier = new IndexWriter(dir1, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     Document d = new Document();
     d.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     modifier.addDocument(d);
     modifier.close();
     
-    modifier = new IndexWriter(dir2, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    modifier = new IndexWriter(dir2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     d = new Document();
     d.add(new Field("f2", "v2", Field.Store.YES, Field.Index.ANALYZED));
     modifier.addDocument(d);
@@ -169,7 +169,7 @@
     assertFalse(pr.isOptimized());
     pr.close();
     
-    modifier = new IndexWriter(dir1, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    modifier = new IndexWriter(dir1, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     modifier.optimize();
     modifier.close();
     
@@ -181,7 +181,7 @@
     pr.close();
 
     
-    modifier = new IndexWriter(dir2, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    modifier = new IndexWriter(dir2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     modifier.optimize();
     modifier.close();
     
@@ -232,7 +232,7 @@
   // Fields 1-4 indexed together:
   private Searcher single() throws IOException {
     Directory dir = new MockRAMDirectory();
-    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document d1 = new Document();
     d1.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d1.add(new Field("f2", "v1", Field.Store.YES, Field.Index.ANALYZED));
@@ -262,7 +262,7 @@
 
   private Directory getDir1() throws IOException {
     Directory dir1 = new MockRAMDirectory();
-    IndexWriter w1 = new IndexWriter(dir1, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w1 = new IndexWriter(dir1, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document d1 = new Document();
     d1.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d1.add(new Field("f2", "v1", Field.Store.YES, Field.Index.ANALYZED));
@@ -277,7 +277,7 @@
 
   private Directory getDir2() throws IOException {
     Directory dir2 = new RAMDirectory();
-    IndexWriter w2 = new IndexWriter(dir2, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter w2 = new IndexWriter(dir2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     Document d3 = new Document();
     d3.add(new Field("f3", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d3.add(new Field("f4", "v1", Field.Store.YES, Field.Index.ANALYZED));
Index: src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(revision 826223)
+++ src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(working copy)
@@ -70,7 +70,7 @@
   
   public void testSimple() throws Exception {
     String[] fields = {"b", "t"};
-    MultiFieldQueryParser mfqp = new MultiFieldQueryParser(fields, new StandardAnalyzer());
+    MultiFieldQueryParser mfqp = new MultiFieldQueryParser(fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     
     Query q = mfqp.parse("one");
     assertEquals("b:one t:one", q.toString());
@@ -133,7 +133,7 @@
       boosts.put("b", new Float(5));
       boosts.put("t", new Float(10));
       String[] fields = {"b", "t"};
-      MultiFieldQueryParser mfqp = new MultiFieldQueryParser(fields, new StandardAnalyzer(), boosts);
+      MultiFieldQueryParser mfqp = new MultiFieldQueryParser(fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), boosts);
       
       
       //Check for simple
@@ -159,24 +159,24 @@
   public void testStaticMethod1() throws ParseException {
     String[] fields = {"b", "t"};
     String[] queries = {"one", "two"};
-    Query q = MultiFieldQueryParser.parse(queries, fields, new StandardAnalyzer());
+    Query q = MultiFieldQueryParser.parse(queries, fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("b:one t:two", q.toString());
 
     String[] queries2 = {"+one", "+two"};
-    q = MultiFieldQueryParser.parse(queries2, fields, new StandardAnalyzer());
+    q = MultiFieldQueryParser.parse(queries2, fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("(+b:one) (+t:two)", q.toString());
 
     String[] queries3 = {"one", "+two"};
-    q = MultiFieldQueryParser.parse(queries3, fields, new StandardAnalyzer());
+    q = MultiFieldQueryParser.parse(queries3, fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("b:one (+t:two)", q.toString());
 
     String[] queries4 = {"one +more", "+two"};
-    q = MultiFieldQueryParser.parse(queries4, fields, new StandardAnalyzer());
+    q = MultiFieldQueryParser.parse(queries4, fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("(b:one +b:more) (+t:two)", q.toString());
 
     String[] queries5 = {"blah"};
     try {
-      q = MultiFieldQueryParser.parse(queries5, fields, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse(queries5, fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -198,15 +198,15 @@
   public void testStaticMethod2() throws ParseException {
     String[] fields = {"b", "t"};
     BooleanClause.Occur[] flags = {BooleanClause.Occur.MUST, BooleanClause.Occur.MUST_NOT};
-    Query q = MultiFieldQueryParser.parse("one", fields, flags, new StandardAnalyzer());
+    Query q = MultiFieldQueryParser.parse("one", fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("+b:one -t:one", q.toString());
 
-    q = MultiFieldQueryParser.parse("one two", fields, flags, new StandardAnalyzer());
+    q = MultiFieldQueryParser.parse("one two", fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("+(b:one b:two) -(t:one t:two)", q.toString());
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -217,17 +217,17 @@
     String[] fields = {"b", "t"};
     //int[] flags = {MultiFieldQueryParser.REQUIRED_FIELD, MultiFieldQueryParser.PROHIBITED_FIELD};
       BooleanClause.Occur[] flags = {BooleanClause.Occur.MUST, BooleanClause.Occur.MUST_NOT};
-      MultiFieldQueryParser parser = new MultiFieldQueryParser(fields, new StandardAnalyzer());
+      MultiFieldQueryParser parser = new MultiFieldQueryParser(fields, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
 
-    Query q = MultiFieldQueryParser.parse("one", fields, flags, new StandardAnalyzer());//, fields, flags, new StandardAnalyzer());
+    Query q = MultiFieldQueryParser.parse("one", fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));//, fields, flags, new StandardAnalyzer());
     assertEquals("+b:one -t:one", q.toString());
 
-    q = MultiFieldQueryParser.parse("one two", fields, flags, new StandardAnalyzer());
+    q = MultiFieldQueryParser.parse("one two", fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("+(b:one b:two) -(t:one t:two)", q.toString());
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -239,12 +239,12 @@
     String[] fields = {"f1", "f2", "f3"};
     BooleanClause.Occur[] flags = {BooleanClause.Occur.MUST,
         BooleanClause.Occur.MUST_NOT, BooleanClause.Occur.SHOULD};
-    Query q = MultiFieldQueryParser.parse(queries, fields, flags, new StandardAnalyzer());
+    Query q = MultiFieldQueryParser.parse(queries, fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("+f1:one -f2:two f3:three", q.toString());
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse(queries, fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse(queries, fields, flags2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -255,12 +255,12 @@
     String[] queries = {"one", "two"};
     String[] fields = {"b", "t"};
       BooleanClause.Occur[] flags = {BooleanClause.Occur.MUST, BooleanClause.Occur.MUST_NOT};
-    Query q = MultiFieldQueryParser.parse(queries, fields, flags, new StandardAnalyzer());
+    Query q = MultiFieldQueryParser.parse(queries, fields, flags, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     assertEquals("+b:one -t:two", q.toString());
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse(queries, fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse(queries, fields, flags2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -282,7 +282,7 @@
   }
 
   public void testStopWordSearching() throws Exception {
-    Analyzer analyzer = new StandardAnalyzer();
+    Analyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     Directory ramDir = new RAMDirectory();
     IndexWriter iw =  new IndexWriter(ramDir, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
@@ -304,7 +304,7 @@
    * Return empty tokens for field "f1".
    */
   private static class AnalyzerReturningNull extends Analyzer {
-    StandardAnalyzer stdAnalyzer = new StandardAnalyzer();
+    StandardAnalyzer stdAnalyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
 
     public AnalyzerReturningNull() {
     }
Index: src/test/org/apache/lucene/queryParser/TestQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestQueryParser.java	(revision 826223)
+++ src/test/org/apache/lucene/queryParser/TestQueryParser.java	(working copy)
@@ -291,7 +291,7 @@
     assertQueryEquals("+title:(dog OR cat) -author:\"bob dole\"", null,
                       "+(title:dog title:cat) -author:\"bob dole\"");
     
-    QueryParser qp = new QueryParser("field", new StandardAnalyzer());
+    QueryParser qp = new QueryParser("field", new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     // make sure OR is the default:
     assertEquals(QueryParser.OR_OPERATOR, qp.getDefaultOperator());
     qp.setDefaultOperator(QueryParser.AND_OPERATOR);
@@ -321,7 +321,7 @@
     assertQueryEquals("term 1.0 1 2", null, "term");
     assertQueryEquals("term term1 term2", null, "term term term");
 
-    Analyzer a = new StandardAnalyzer();
+    Analyzer a = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     assertQueryEquals("3", a, "3");
     assertQueryEquals("term 1.0 1 2", a, "term 1.0 1 2");
     assertQueryEquals("term term1 term2", a, "term term1 term2");
@@ -791,7 +791,7 @@
     throws Exception {
     Set stopWords = new HashSet(1);
     stopWords.add("on");
-    StandardAnalyzer oneStopAnalyzer = new StandardAnalyzer(stopWords);
+    StandardAnalyzer oneStopAnalyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT, stopWords);
     QueryParser qp = new QueryParser("field", oneStopAnalyzer);
     Query q = qp.parse("on^1.0");
     assertNotNull(q);
@@ -804,7 +804,7 @@
     q = qp.parse("\"on\"^1.0");
     assertNotNull(q);
 
-    QueryParser qp2 = new QueryParser("field", new StandardAnalyzer());
+    QueryParser qp2 = new QueryParser("field", new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     q = qp2.parse("the^3");
     // "the" is a stop word so the result is an empty query:
     assertNotNull(q);
@@ -944,7 +944,7 @@
   }
 
   public void testStopwords() throws Exception {
-    QueryParser qp = new QueryParser("a", new StopAnalyzer(new String[]{"the", "foo"}));
+    QueryParser qp = new QueryParser("a", new StopAnalyzer(StopFilter.makeStopSet(new String[]{"the", "foo"}), true));
     Query result = qp.parse("a:the OR a:foo");
     assertNotNull("result is null and it shouldn't be", result);
     assertTrue("result is not a BooleanQuery", result instanceof BooleanQuery);
@@ -960,25 +960,19 @@
   }
 
   public void testPositionIncrement() throws Exception {
-    boolean dflt = StopFilter.getEnablePositionIncrementsDefault();
-    StopFilter.setEnablePositionIncrementsDefault(true);
-    try {
-      QueryParser qp = new QueryParser("a", new StopAnalyzer(new String[]{"the", "in", "are", "this"}));
-      qp.setEnablePositionIncrements(true);
-      String qtxt = "\"the words in poisitions pos02578 are stopped in this phrasequery\"";
-      //               0         2                      5           7  8
-      int expectedPositions[] = {1,3,4,6,9};
-      PhraseQuery pq = (PhraseQuery) qp.parse(qtxt);
-      //System.out.println("Query text: "+qtxt);
-      //System.out.println("Result: "+pq);
-      Term t[] = pq.getTerms();
-      int pos[] = pq.getPositions();
-      for (int i = 0; i < t.length; i++) {
-        //System.out.println(i+". "+t[i]+"  pos: "+pos[i]);
-        assertEquals("term "+i+" = "+t[i]+" has wrong term-position!",expectedPositions[i],pos[i]);
-      }
-    } finally {
-      StopFilter.setEnablePositionIncrementsDefault(dflt);
+    QueryParser qp = new QueryParser("a", new StopAnalyzer(StopFilter.makeStopSet(new String[]{"the", "in", "are", "this"}), true));
+    qp.setEnablePositionIncrements(true);
+    String qtxt = "\"the words in poisitions pos02578 are stopped in this phrasequery\"";
+    //               0         2                      5           7  8
+    int expectedPositions[] = {1,3,4,6,9};
+    PhraseQuery pq = (PhraseQuery) qp.parse(qtxt);
+    //System.out.println("Query text: "+qtxt);
+    //System.out.println("Result: "+pq);
+    Term t[] = pq.getTerms();
+    int pos[] = pq.getPositions();
+    for (int i = 0; i < t.length; i++) {
+      //System.out.println(i+". "+t[i]+"  pos: "+pos[i]);
+      assertEquals("term "+i+" = "+t[i]+" has wrong term-position!",expectedPositions[i],pos[i]);
     }
   }
 
Index: src/test/org/apache/lucene/search/function/FunctionTestSetup.java
===================================================================
--- src/test/org/apache/lucene/search/function/FunctionTestSetup.java	(revision 826223)
+++ src/test/org/apache/lucene/search/function/FunctionTestSetup.java	(working copy)
@@ -86,7 +86,7 @@
     // prepare a small index with just a few documents.  
     super.setUp();
     dir = new RAMDirectory();
-    anlzr = new StandardAnalyzer();
+    anlzr = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT);
     IndexWriter iw = new IndexWriter(dir, anlzr,
                                      IndexWriter.MaxFieldLength.LIMITED);
     // add docs not exactly in natural ID order, to verify we do check the order of docs by scores
Index: src/test/org/apache/lucene/search/spans/TestSpans.java
===================================================================
--- src/test/org/apache/lucene/search/spans/TestSpans.java	(revision 826223)
+++ src/test/org/apache/lucene/search/spans/TestSpans.java	(working copy)
@@ -39,7 +39,7 @@
 import org.apache.lucene.util.LuceneTestCase;
 
 import java.io.IOException;
-import java.util.HashSet;
+import java.util.Collections;
 
 public class TestSpans extends LuceneTestCase {
   private IndexSearcher searcher;
@@ -449,7 +449,7 @@
   // LUCENE-1404
   public void testNPESpanQuery() throws Throwable {
     final Directory dir = new MockRAMDirectory();
-    final IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(new HashSet(0)), IndexWriter.MaxFieldLength.LIMITED);
+    final IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT, Collections.emptySet()), IndexWriter.MaxFieldLength.LIMITED);
 
     // Add documents
     addDoc(writer, "1", "the big dogs went running to the market");
Index: src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
===================================================================
--- src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(revision 826223)
+++ src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(working copy)
@@ -55,7 +55,7 @@
 
         // create test index
         mDirectory = new RAMDirectory();
-        final IndexWriter writer = new IndexWriter(mDirectory, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+        final IndexWriter writer = new IndexWriter(mDirectory, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
         addDocument(writer, "1", "I think it should work.");
         addDocument(writer, "2", "I think it should work.");
         addDocument(writer, "3", "I think it should work.");
Index: src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java
===================================================================
--- src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java	(revision 826223)
+++ src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java	(working copy)
@@ -39,7 +39,7 @@
         super.setUp();
 
         // create test index
-        final IndexWriter writer = new IndexWriter(mDirectory, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+        final IndexWriter writer = new IndexWriter(mDirectory, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
         addDocument(writer, "A", "Should we, could we, would we?");
         addDocument(writer, "B", "It should.  Should it?");
         addDocument(writer, "C", "It shouldn't.");
Index: src/test/org/apache/lucene/search/TestBooleanOr.java
===================================================================
--- src/test/org/apache/lucene/search/TestBooleanOr.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestBooleanOr.java	(working copy)
@@ -135,7 +135,7 @@
 		RAMDirectory rd = new RAMDirectory();
 
 		//
-		IndexWriter writer = new IndexWriter(rd, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+		IndexWriter writer = new IndexWriter(rd, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
 
 		//
 		Document d = new Document();
Index: src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
===================================================================
--- src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(working copy)
@@ -32,7 +32,7 @@
 public class TestCachingWrapperFilter extends LuceneTestCase {
   public void testCachingWorks() throws Exception {
     Directory dir = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -71,7 +71,7 @@
   
   public void testIsCacheAble() throws Exception {
     Directory dir = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
Index: src/test/org/apache/lucene/search/TestCustomSearcherSort.java
===================================================================
--- src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(working copy)
@@ -70,7 +70,7 @@
 	private Directory getIndex()
 	throws IOException {
 	        RAMDirectory indexStore = new RAMDirectory ();
-	        IndexWriter writer = new IndexWriter (indexStore, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+	        IndexWriter writer = new IndexWriter (indexStore, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
 	        RandomGen random = new RandomGen(newRandom());
 	        for (int i=0; i<INDEX_SIZE; ++i) { // don't decrease; if to low the problem doesn't show up
 	        Document doc = new Document();
Index: src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(working copy)
@@ -33,6 +33,7 @@
 import java.io.IOException;
 import java.util.HashSet;
 import java.util.LinkedList;
+import java.util.Collections;
 
 /**
  * This class tests the MultiPhraseQuery class.
@@ -170,7 +171,7 @@
     
   public void testPhrasePrefixWithBooleanQuery() throws IOException {
     RAMDirectory indexStore = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(indexStore, new StandardAnalyzer(new HashSet(0)), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(indexStore, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT, Collections.emptySet()), true, IndexWriter.MaxFieldLength.LIMITED);
     add("This is a test", "object", writer);
     add("a note", "note", writer);
     writer.close();
Index: src/test/org/apache/lucene/search/TestMultiSearcher.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiSearcher.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestMultiSearcher.java	(working copy)
@@ -84,9 +84,9 @@
         lDoc3.add(new Field("handle", "1", Field.Store.YES, Field.Index.NOT_ANALYZED));
 
         // creating an index writer for the first index
-        IndexWriter writerA = new IndexWriter(indexStoreA, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+        IndexWriter writerA = new IndexWriter(indexStoreA, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
         // creating an index writer for the second index, but writing nothing
-        IndexWriter writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+        IndexWriter writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
 
         //--------------------------------------------------------------------
         // scenario 1
@@ -103,7 +103,7 @@
         writerB.close();
 
         // creating the query
-        QueryParser parser = new QueryParser("fulltext", new StandardAnalyzer());
+        QueryParser parser = new QueryParser("fulltext", new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
         Query query = parser.parse("handle:1");
 
         // building the searchables
@@ -130,7 +130,7 @@
         //--------------------------------------------------------------------
 
         // adding one document to the empty index
-        writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+        writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
         writerB.addDocument(lDoc);
         writerB.optimize();
         writerB.close();
@@ -176,7 +176,7 @@
         readerB.close();
 
         // optimizing the index with the writer
-        writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);
+        writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), false, IndexWriter.MaxFieldLength.LIMITED);
         writerB.optimize();
         writerB.close();
 
Index: src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(working copy)
@@ -88,7 +88,7 @@
   private void checkQuery(String queryStr) throws IOException, ParseException {
     // check result hit ranking
     if(verbose) System.out.println("Query: " + queryStr);
-      QueryParser queryParser = new QueryParser(FIELD_NAME, new StandardAnalyzer());
+      QueryParser queryParser = new QueryParser(FIELD_NAME, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     Query query = queryParser.parse(queryStr);
     ScoreDoc[] multiSearcherHits = multiSearcher.search(query, null, 1000).scoreDocs;
     ScoreDoc[] singleSearcherHits = singleSearcher.search(query, null, 1000).scoreDocs;
@@ -114,12 +114,12 @@
     super.setUp();
     // create MultiSearcher from two seperate searchers
     Directory d1 = new RAMDirectory();
-    IndexWriter iw1 = new IndexWriter(d1, new StandardAnalyzer(), true,
+    IndexWriter iw1 = new IndexWriter(d1, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true,
                                       IndexWriter.MaxFieldLength.LIMITED);
     addCollection1(iw1);
     iw1.close();
     Directory d2 = new RAMDirectory();
-    IndexWriter iw2 = new IndexWriter(d2, new StandardAnalyzer(), true,
+    IndexWriter iw2 = new IndexWriter(d2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true,
                                       IndexWriter.MaxFieldLength.LIMITED);
     addCollection2(iw2);
     iw2.close();
@@ -131,7 +131,7 @@
 
     // create IndexSearcher which contains all documents
     Directory d = new RAMDirectory();
-    IndexWriter iw = new IndexWriter(d, new StandardAnalyzer(), true,
+    IndexWriter iw = new IndexWriter(d, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true,
                                      IndexWriter.MaxFieldLength.LIMITED);
     addCollection1(iw);
     addCollection2(iw);
Index: src/test/org/apache/lucene/search/TestPhraseQuery.java
===================================================================
--- src/test/org/apache/lucene/search/TestPhraseQuery.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestPhraseQuery.java	(working copy)
@@ -201,7 +201,7 @@
   
   public void testPhraseQueryWithStopAnalyzer() throws Exception {
     RAMDirectory directory = new RAMDirectory();
-    StopAnalyzer stopAnalyzer = new StopAnalyzer();
+    StopAnalyzer stopAnalyzer = new StopAnalyzer(false);
     IndexWriter writer = new IndexWriter(directory, stopAnalyzer, true, 
                                          IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
@@ -357,8 +357,7 @@
   }
   
   public void testToString() throws Exception {
-    StopAnalyzer analyzer = new StopAnalyzer();
-    StopFilter.setEnablePositionIncrementsDefault(true);
+    StopAnalyzer analyzer = new StopAnalyzer(true);
     QueryParser qp = new QueryParser("field", analyzer);
     qp.setEnablePositionIncrements(true);
     PhraseQuery q = (PhraseQuery)qp.parse("\"this hi this is a test is\"");
Index: src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -21,6 +21,7 @@
 import java.io.IOException;
 import java.io.StringReader;
 import java.util.Collection;
+import java.util.Collections;
 import java.util.Iterator;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -31,6 +32,7 @@
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
@@ -226,7 +228,7 @@
     }
     public TokenStream tokenStream(String fieldName, Reader reader) {
       TokenStream ts = a.tokenStream(fieldName,reader);
-      return new StopFilter(enablePositionIncrements, ts, new String[]{"stop"});
+      return new StopFilter(enablePositionIncrements, ts, new CharArraySet(Collections.singleton("stop"), true));
     }
   }
   
Index: src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
===================================================================
--- src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(working copy)
@@ -33,7 +33,7 @@
 
   public void testBasic() throws Exception {
     Directory dir = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true,
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true,
         IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     doc.add(new Field("field", "value", Store.NO, Index.ANALYZED));
Index: src/test/org/apache/lucene/search/TestSimpleExplanations.java
===================================================================
--- src/test/org/apache/lucene/search/TestSimpleExplanations.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestSimpleExplanations.java	(working copy)
@@ -316,8 +316,8 @@
     Document lDoc3 = new Document();
     lDoc3.add(new Field("handle", "1 2", Field.Store.YES, Field.Index.ANALYZED));
 
-    IndexWriter writerA = new IndexWriter(indexStoreA, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
-    IndexWriter writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writerA = new IndexWriter(indexStoreA, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writerB = new IndexWriter(indexStoreB, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);
 
     writerA.addDocument(lDoc);
     writerA.addDocument(lDoc2);
@@ -327,7 +327,7 @@
     writerB.addDocument(lDoc3);
     writerB.close();
 
-    QueryParser parser = new QueryParser("fulltext", new StandardAnalyzer());
+    QueryParser parser = new QueryParser("fulltext", new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT));
     Query query = parser.parse("handle:1");
 
     Searcher[] searchers = new Searcher[2];
Index: src/test/org/apache/lucene/search/TestStressSort.java
===================================================================
--- src/test/org/apache/lucene/search/TestStressSort.java	(revision 826223)
+++ src/test/org/apache/lucene/search/TestStressSort.java	(working copy)
@@ -72,7 +72,7 @@
     // deterministic, but do not commit with a seed (to
     // better test):
     dir = new MockRAMDirectory();
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     writer.setMaxBufferedDocs(17);
 
     final Document doc = new Document();
@@ -169,13 +169,13 @@
     searcherMultiSegment.setDefaultFieldSortScoring(true, true);
 
     dir2 = new MockRAMDirectory(dir);
-    writer = new IndexWriter(dir2, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    writer = new IndexWriter(dir2, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     writer.optimize();
     writer.close();
     searcherSingleSegment = new IndexSearcher(dir2, true);
     searcherSingleSegment.setDefaultFieldSortScoring(true, true);
     dir3 = new MockRAMDirectory(dir);
-    writer = new IndexWriter(dir3, new StandardAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    writer = new IndexWriter(dir3, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.LIMITED);
     writer.optimize(3);
     writer.close();
     searcherFewSegment = new IndexSearcher(dir3, true);
Index: src/test/org/apache/lucene/store/TestWindowsMMap.java
===================================================================
--- src/test/org/apache/lucene/store/TestWindowsMMap.java	(revision 826223)
+++ src/test/org/apache/lucene/store/TestWindowsMMap.java	(working copy)
@@ -17,7 +17,7 @@
  * limitations under the License.
  */
 
-import java.util.HashSet;
+import java.util.Collections;
 import java.util.Random;
 import java.io.File;
 
@@ -68,7 +68,7 @@
 
 		// plan to add a set of useful stopwords, consider changing some of the
 		// interior filters.
-		StandardAnalyzer analyzer = new StandardAnalyzer(new HashSet());
+		StandardAnalyzer analyzer = new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT, Collections.emptySet());
 		// TODO: something about lock timeouts and leftover locks.
 		IndexWriter writer = new IndexWriter(storeDirectory, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
 		IndexSearcher searcher = new IndexSearcher(storeDirectory, true);
Index: src/test/org/apache/lucene/TestSnapshotDeletionPolicy.java
===================================================================
--- src/test/org/apache/lucene/TestSnapshotDeletionPolicy.java	(revision 826223)
+++ src/test/org/apache/lucene/TestSnapshotDeletionPolicy.java	(working copy)
@@ -68,7 +68,7 @@
     Directory dir = new MockRAMDirectory();
 
     SnapshotDeletionPolicy dp = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
-    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), dp, IndexWriter.MaxFieldLength.UNLIMITED);
+    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), dp, IndexWriter.MaxFieldLength.UNLIMITED);
     // Force frequent commits
     writer.setMaxBufferedDocs(2);
     Document doc = new Document();
@@ -84,7 +84,7 @@
     writer.close();
     copyFiles(dir, cp);
     
-    writer = new IndexWriter(dir, new StandardAnalyzer(), dp, IndexWriter.MaxFieldLength.UNLIMITED);
+    writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), dp, IndexWriter.MaxFieldLength.UNLIMITED);
     copyFiles(dir, cp);
     for(int i=0;i<7;i++) {
       writer.addDocument(doc);
@@ -97,7 +97,7 @@
     writer.close();
     copyFiles(dir, cp);
     dp.release();
-    writer = new IndexWriter(dir, new StandardAnalyzer(), dp, IndexWriter.MaxFieldLength.UNLIMITED);
+    writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), dp, IndexWriter.MaxFieldLength.UNLIMITED);
     writer.close();
     try {
       copyFiles(dir, cp);
@@ -113,7 +113,7 @@
     final long stopTime = System.currentTimeMillis() + 7000;
 
     SnapshotDeletionPolicy dp = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
-    final IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), dp, IndexWriter.MaxFieldLength.UNLIMITED);
+    final IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT), dp, IndexWriter.MaxFieldLength.UNLIMITED);
 
     // Force frequent commits
     writer.setMaxBufferedDocs(2);
