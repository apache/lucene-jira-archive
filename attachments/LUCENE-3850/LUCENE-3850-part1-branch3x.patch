Index: .
===================================================================
--- .	(revision 1297051)
+++ .	(working copy)

Property changes on: .
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk:r1297048
Index: lucene
===================================================================
--- lucene	(revision 1297051)
+++ lucene	(working copy)

Property changes on: lucene
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene:r1297048
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java	(revision 1297051)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java	(working copy)
@@ -60,7 +60,7 @@
         termAtt.copyBuffer(t.buffer(), 0, t.length());
         offsetAtt.setOffset(t.startOffset(), t.endOffset());
         posIncrAtt.setPositionIncrement(t.getPositionIncrement());
-        typeAtt.setType(TypeAttributeImpl.DEFAULT_TYPE);
+        typeAtt.setType(TypeAttribute.DEFAULT_TYPE);
         return true;
       } else {
         return false;
@@ -1019,14 +1019,14 @@
     assertTokenStreamContents(filter,
       new String[]{"please","please divide","divide","divide this","this","this sentence","sentence"},
       new int[]{0,0,7,7,14,14,19}, new int[]{6,13,13,18,18,27,27},
-      new String[]{TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE},
+      new String[]{TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE},
       new int[]{1,0,1,0,1,0,1}
     );
     wsTokenizer.reset(new StringReader("please divide this sentence"));
     assertTokenStreamContents(filter,
       new String[]{"please","please divide","divide","divide this","this","this sentence","sentence"},
       new int[]{0,0,7,7,14,14,19}, new int[]{6,13,13,18,18,27,27},
-      new String[]{TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE,"shingle",TypeAttributeImpl.DEFAULT_TYPE},
+      new String[]{TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE,"shingle",TypeAttribute.DEFAULT_TYPE},
       new int[]{1,0,1,0,1,0,1}
     );
   }
Index: lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java
===================================================================
--- lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java	(revision 1297051)
+++ lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/AbstractDictionary.java	(working copy)
@@ -85,7 +85,7 @@
    * @return unicode String
    */
   public String getCCByGB2312Id(int ccid) {
-    if (ccid < 0 || ccid > WordDictionary.GB2312_CHAR_NUM)
+    if (ccid < 0 || ccid > AbstractDictionary.GB2312_CHAR_NUM)
       return "";
     int cc1 = ccid / 94 + 161;
     int cc2 = ccid % 94 + 161;
Index: lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java
===================================================================
--- lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java	(revision 1297051)
+++ lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java	(working copy)
@@ -36,7 +36,7 @@
 abstract public class AbstractFirstPassGroupingCollector<GROUP_VALUE_TYPE> extends Collector {
 
   private final Sort groupSort;
-  private final FieldComparator[] comparators;
+  private final FieldComparator<?>[] comparators;
   private final int[] reversed;
   private final int topNGroups;
   private final HashMap<GROUP_VALUE_TYPE, CollectedSearchGroup<GROUP_VALUE_TYPE>> groupMap;
@@ -135,7 +135,7 @@
 
   @Override
   public void setScorer(Scorer scorer) throws IOException {
-    for (FieldComparator comparator : comparators) {
+    for (FieldComparator<?> comparator : comparators) {
       comparator.setScorer(scorer);
     }
   }
@@ -195,7 +195,7 @@
         sg.groupValue = copyDocGroupValue(groupValue, null);
         sg.comparatorSlot = groupMap.size();
         sg.topDoc = docBase + doc;
-        for (FieldComparator fc : comparators) {
+        for (FieldComparator<?> fc : comparators) {
           fc.copy(sg.comparatorSlot, doc);
         }
         groupMap.put(sg.groupValue, sg);
@@ -224,7 +224,7 @@
       bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);
       bottomGroup.topDoc = docBase + doc;
 
-      for (FieldComparator fc : comparators) {
+      for (FieldComparator<?> fc : comparators) {
         fc.copy(bottomGroup.comparatorSlot, doc);
       }
 
@@ -233,7 +233,7 @@
       assert orderedGroups.size() == topNGroups;
 
       final int lastComparatorSlot = orderedGroups.last().comparatorSlot;
-      for (FieldComparator fc : comparators) {
+      for (FieldComparator<?> fc : comparators) {
         fc.setBottom(lastComparatorSlot);
       }
 
@@ -242,7 +242,7 @@
 
     // Update existing group:
     for (int compIDX = 0;; compIDX++) {
-      final FieldComparator fc = comparators[compIDX];
+      final FieldComparator<?> fc = comparators[compIDX];
       fc.copy(spareSlot, doc);
 
       final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);
@@ -289,7 +289,7 @@
       final CollectedSearchGroup newLast = orderedGroups.last();
       // If we changed the value of the last group, or changed which group was last, then update bottom:
       if (group == newLast || prevLast != newLast) {
-        for (FieldComparator fc : comparators) {
+        for (FieldComparator<?> fc : comparators) {
           fc.setBottom(newLast.comparatorSlot);
         }
       }
@@ -300,7 +300,7 @@
     final Comparator<CollectedSearchGroup> comparator = new Comparator<CollectedSearchGroup>() {
       public int compare(CollectedSearchGroup o1, CollectedSearchGroup o2) {
         for (int compIDX = 0;; compIDX++) {
-          FieldComparator fc = comparators[compIDX];
+          FieldComparator<?> fc = comparators[compIDX];
           final int c = reversed[compIDX] * fc.compare(o1.comparatorSlot, o2.comparatorSlot);
           if (c != 0) {
             return c;
@@ -315,7 +315,7 @@
     orderedGroups.addAll(groupMap.values());
     assert orderedGroups.size() > 0;
 
-    for (FieldComparator fc : comparators) {
+    for (FieldComparator<?> fc : comparators) {
       fc.setBottom(orderedGroups.last().comparatorSlot);
     }
   }
Index: lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractSecondPassGroupingCollector.java
===================================================================
--- lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractSecondPassGroupingCollector.java	(revision 1297051)
+++ lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/AbstractSecondPassGroupingCollector.java	(working copy)
@@ -66,7 +66,7 @@
 
     for (SearchGroup<GROUP_VALUE_TYPE> group : groups) {
       //System.out.println("  prep group=" + (group.groupValue == null ? "null" : group.groupValue.utf8ToString()));
-      final TopDocsCollector collector;
+      final TopDocsCollector<?> collector;
       if (withinGroupSort == null) {
         // Sort by score
         collector = TopScoreDocCollector.create(maxDocsPerGroup, true);
@@ -146,9 +146,9 @@
   public class SearchGroupDocs<GROUP_VALUE_TYPE> {
 
     public final GROUP_VALUE_TYPE groupValue;
-    public final TopDocsCollector collector;
+    public final TopDocsCollector<?> collector;
 
-    public SearchGroupDocs(GROUP_VALUE_TYPE groupValue, TopDocsCollector collector) {
+    public SearchGroupDocs(GROUP_VALUE_TYPE groupValue, TopDocsCollector<?> collector) {
       this.groupValue = groupValue;
       this.collector = collector;
     }
Index: lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
===================================================================
--- lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java	(revision 1297051)
+++ lucene/contrib/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java	(working copy)
@@ -26,6 +26,7 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.FieldComparator;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
@@ -76,7 +77,7 @@
   // TODO: specialize into 2 classes, static "create" method:
   private final boolean needsScores;
 
-  private final FieldComparator[] comparators;
+  private final FieldComparator<?>[] comparators;
   private final int[] reversed;
   private final int compIDXEnd;
   private int bottomSlot;
@@ -319,14 +320,14 @@
 
     final FakeScorer fakeScorer = new FakeScorer();
 
-    @SuppressWarnings("unchecked")
-    final GroupDocs<Object>[] groups = new GroupDocs[groupQueue.size() - groupOffset];
+    @SuppressWarnings({"unchecked","rawtypes"})
+    final GroupDocs<Object>[] groups = (GroupDocs<Object>[]) new GroupDocs[groupQueue.size() - groupOffset];
     for(int downTo=groupQueue.size()-groupOffset-1;downTo>=0;downTo--) {
       final OneGroup og = groupQueue.pop();
 
       // At this point we hold all docs w/ in each group,
       // unsorted; we now sort them:
-      final TopDocsCollector collector;
+      final TopDocsCollector<?> collector;
       if (withinGroupSort == null) {
         // Sort by score
         if (!needsScores) {
@@ -387,7 +388,7 @@
   @Override
   public void setScorer(Scorer scorer) throws IOException {
     this.scorer = scorer;
-    for (FieldComparator comparator : comparators) {
+    for (FieldComparator<?> comparator : comparators) {
       comparator.setScorer(scorer);
     }
   }
@@ -428,7 +429,7 @@
         assert !queueFull;
 
         //System.out.println("    init copy to bottomSlot=" + bottomSlot);
-        for (FieldComparator fc : comparators) {
+        for (FieldComparator<?> fc : comparators) {
           fc.copy(bottomSlot, doc);
           fc.setBottom(bottomSlot);
         }        
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 1297051)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -1954,16 +1954,16 @@
 
         String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,
             fragmentSeparator);
-        if (HighlighterTest.VERBOSE) System.out.println("\t" + result);
+        if (LuceneTestCase.VERBOSE) System.out.println("\t" + result);
       }
     }
 
     abstract void run() throws Exception;
 
     void start() throws Exception {
-      if (HighlighterTest.VERBOSE) System.out.println("Run QueryScorer");
+      if (LuceneTestCase.VERBOSE) System.out.println("Run QueryScorer");
       run();
-      if (HighlighterTest.VERBOSE) System.out.println("Run QueryTermScorer");
+      if (LuceneTestCase.VERBOSE) System.out.println("Run QueryTermScorer");
       mode = QUERY_TERM;
       run();
     }
Index: lucene/contrib/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ScriptIterator.java
===================================================================
--- lucene/contrib/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ScriptIterator.java	(revision 1297051)
+++ lucene/contrib/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ScriptIterator.java	(working copy)
@@ -29,6 +29,7 @@
  */
 
 import com.ibm.icu.lang.UCharacter;
+import com.ibm.icu.lang.UCharacterEnums.ECharacterCategory;
 import com.ibm.icu.lang.UScript;
 import com.ibm.icu.text.UTF16;
 
@@ -110,7 +111,7 @@
        * value — should inherit the script value of its base character.
        */
       if (isSameScript(scriptCode, sc)
-          || UCharacter.getType(ch) == UCharacter.NON_SPACING_MARK) {
+          || UCharacter.getType(ch) == ECharacterCategory.NON_SPACING_MARK) {
         index += UTF16.getCharCount(ch);
 
         /*
Index: lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java
===================================================================
--- lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java	(revision 1297051)
+++ lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java	(working copy)
@@ -412,7 +412,7 @@
     assertEquals(4, searchers.size());
     int num_field2 = this.numdoc();
     assertEquals(num_field2, num_field1 + 1);
-    int numThreads = 5 + this.random.nextInt(5);
+    int numThreads = 5 + LuceneTestCase.random.nextInt(5);
     ExecutorService executor = Executors.newFixedThreadPool(numThreads);
     SpellCheckWorker[] workers = new SpellCheckWorker[numThreads];
     for (int i = 0; i < numThreads; i++) {
Index: lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java
===================================================================
--- lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java	(revision 1297051)
+++ lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java	(working copy)
@@ -181,7 +181,7 @@
 		Element root = doc.createElement ("Document");
 		doc.appendChild (root);
 		
-		Enumeration keysEnum = formProperties.keys();
+		Enumeration<Object> keysEnum = formProperties.keys();
 		while(keysEnum.hasMoreElements())
 		{
 		    String propName=(String) keysEnum.nextElement();
Index: lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java
===================================================================
--- lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java	(revision 1297051)
+++ lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java	(working copy)
@@ -103,7 +103,7 @@
 		Filter filter2 = filterBuilder.getFilter(doc2.getDocumentElement());
 		assertTrue(filter2 instanceof NumericRangeFilter<?>);
 		@SuppressWarnings("unchecked")
-		NumericRangeFilter<Integer> numRangeFilter2 = (NumericRangeFilter) filter2;
+		NumericRangeFilter<Integer> numRangeFilter2 = (NumericRangeFilter<Integer>) filter2;
 		assertEquals(Integer.valueOf(-1), numRangeFilter2.getMin());
 		assertEquals(Integer.valueOf(10), numRangeFilter2.getMax());
 		assertEquals("AGE", numRangeFilter2.getField());
Index: lucene/core/src/java/org/apache/lucene/analysis/CharArrayMap.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/CharArrayMap.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/analysis/CharArrayMap.java	(working copy)
@@ -375,11 +375,11 @@
 
   /** Returns an {@link CharArraySet} view on the map's keys.
    * The set will use the same {@code matchVersion} as this map. */
-  @Override @SuppressWarnings("unchecked")
+  @Override @SuppressWarnings({"unchecked","rawtypes"})
   public final CharArraySet keySet() {
     if (keySet == null) {
       // prevent adding of entries
-      keySet = new CharArraySet((CharArrayMap) this) {
+      keySet = new CharArraySet((CharArrayMap<Object>) this) {
         @Override
         public boolean add(Object o) {
           throw new UnsupportedOperationException();
@@ -507,10 +507,11 @@
     }
     
     @Override
+    @SuppressWarnings({"unchecked","rawtypes"})
     public boolean contains(Object o) {
       if (!(o instanceof Map.Entry))
         return false;
-      final Map.Entry e = (Map.Entry)o;
+      final Map.Entry<Object,V> e = (Map.Entry<Object,V>)o;
       final Object key = e.getKey();
       final Object val = e.getValue();
       final Object v = get(key);
Index: lucene/core/src/java/org/apache/lucene/analysis/CharArraySet.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/CharArraySet.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/analysis/CharArraySet.java	(working copy)
@@ -304,7 +304,7 @@
    * return {@code char[]} on {@code next()}</li>
    * </ul>
    */
-  @Override @SuppressWarnings("unchecked")
+  @Override @SuppressWarnings({"unchecked","rawtypes"})
   public Iterator<Object> iterator() {
     // use the AbstractSet#keySet()'s iterator (to not produce endless recursion)
     return map.matchVersion.onOrAfter(Version.LUCENE_31) ?
Index: lucene/core/src/java/org/apache/lucene/search/FieldCacheRangeFilter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldCacheRangeFilter.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/FieldCacheRangeFilter.java	(working copy)
@@ -448,6 +448,7 @@
   }
 
   @Override
+  @SuppressWarnings({"unchecked","rawtypes"})
   public final boolean equals(Object o) {
     if (this == o) return true;
     if (!(o instanceof FieldCacheRangeFilter)) return false;
Index: lucene/core/src/java/org/apache/lucene/search/FieldComparatorSource.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldComparatorSource.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/FieldComparatorSource.java	(working copy)
@@ -37,6 +37,6 @@
    * @throws IOException
    *           If an error occurs reading the index.
    */
-  public abstract FieldComparator newComparator(String fieldname, int numHits, int sortPos, boolean reversed)
+  public abstract FieldComparator<?> newComparator(String fieldname, int numHits, int sortPos, boolean reversed)
       throws IOException;
 }
Index: lucene/core/src/java/org/apache/lucene/search/FieldDocSortedHitQueue.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldDocSortedHitQueue.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/FieldDocSortedHitQueue.java	(working copy)
@@ -38,7 +38,7 @@
   // based strings
   volatile Collator[] collators = null;
 
-  volatile FieldComparator[] comparators = null;
+  volatile FieldComparator<?>[] comparators = null;
 
 
   /**
@@ -59,6 +59,7 @@
    * This method should be synchronized external like all other PQ methods.
    * @param fields
    */
+  @SuppressWarnings({"unchecked","rawtypes"})
   void setFields (SortField[] fields) throws IOException {
     this.fields = fields;
     this.collators = hasCollators (fields);
@@ -98,7 +99,8 @@
    * @param b ScoreDoc
    * @return <code>true</code> if document <code>a</code> should be sorted after document <code>b</code>.
    */
-  @SuppressWarnings("unchecked") @Override
+  @Override
+  @SuppressWarnings({"unchecked","rawtypes"})
   protected final boolean lessThan(final FieldDoc docA, final FieldDoc docB) {
     final int n = fields.length;
     int c = 0;
@@ -120,7 +122,8 @@
           c = collators[i].compare(s1, s2);
         }
       } else {
-        c = comparators[i].compareValues(docA.fields[i], docB.fields[i]);
+        final FieldComparator<Object> comp = (FieldComparator<Object>) comparators[i];
+        c = comp.compareValues(docA.fields[i], docB.fields[i]);
       }
       // reverse sort
       if (fields[i].getReverse()) {
Index: lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java	(working copy)
@@ -53,7 +53,7 @@
    */
   private static final class OneComparatorFieldValueHitQueue<T extends FieldValueHitQueue.Entry> extends FieldValueHitQueue<T> {
 
-    private final FieldComparator comparator;
+    private final FieldComparator<?> comparator;
     private final int oneReverseMul;
     
     public OneComparatorFieldValueHitQueue(SortField[] fields, int size)
@@ -136,6 +136,7 @@
   }
   
   // prevent instantiation and extension.
+  @SuppressWarnings({"unchecked","rawtypes"})
   private FieldValueHitQueue(SortField[] fields) {
     // When we get here, fields.length is guaranteed to be > 0, therefore no
     // need to check it again.
@@ -175,7 +176,7 @@
     }
   }
   
-  public FieldComparator[] getComparators() {
+  public FieldComparator<?>[] getComparators() {
     return comparators;
   }
 
@@ -185,7 +186,7 @@
 
   /** Stores the sort criteria being used. */
   protected final SortField[] fields;
-  protected final FieldComparator[] comparators;
+  protected final FieldComparator<?>[] comparators;
   protected final int[] reverseMul;
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java	(working copy)
@@ -57,6 +57,7 @@
   }
 
   @Override
+  @SuppressWarnings({"unchecked","rawtypes"})
   public final boolean equals(final Object o) {
     if (o==this) return true;
     if (o==null) return false;
Index: lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/NumericRangeQuery.java	(working copy)
@@ -345,6 +345,7 @@
   }
 
   @Override
+  @SuppressWarnings({"unchecked","rawtypes"})
   public final boolean equals(final Object o) {
     if (o==this) return true;
     if (!super.equals(o))
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(working copy)
@@ -127,7 +127,8 @@
           }
         }
 
-        @SuppressWarnings("unchecked") final List<Query>[] disjunctLists = new List[maxPosition + 1];
+        @SuppressWarnings({"rawtypes","unchecked"}) final List<Query>[] disjunctLists =
+            new List[maxPosition + 1];
         int distinctPositions = 0;
 
         for (int i = 0; i < termArrays.size(); ++i) {
Index: lucene/core/src/java/org/apache/lucene/search/SortField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/SortField.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/SortField.java	(working copy)
@@ -386,7 +386,7 @@
    *   optimize themselves when they are the primary sort.
    * @return {@link FieldComparator} to use when sorting
    */
-  public FieldComparator getComparator(final int numHits, final int sortPos) throws IOException {
+  public FieldComparator<?> getComparator(final int numHits, final int sortPos) throws IOException {
 
     if (locale != null) {
       // TODO: it'd be nice to allow FieldCache.getStringIndex
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(working copy)
@@ -61,6 +61,7 @@
    * needs a fixed field. The wrapped query must therefore support getField() or getTerm().
    * @throws IllegalArgumentException if the wrapped query does not provide getField() or getTerm().
    */
+  @SuppressWarnings({"rawtypes","unchecked"})
   public SpanMultiTermQueryWrapper(Q query) {
     this.query = query;
     
@@ -150,6 +151,7 @@
   }
 
   @Override
+  @SuppressWarnings({"rawtypes","unchecked"})
   public boolean equals(Object obj) {
     if (this == obj) return true;
     if (obj == null) return false;
Index: lucene/core/src/java/org/apache/lucene/search/TopDocs.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopDocs.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/TopDocs.java	(working copy)
@@ -116,10 +116,11 @@
     }
   }
 
+  @SuppressWarnings({"rawtypes","unchecked"})
   private static class MergeSortQueue extends PriorityQueue<ShardRef> {
     // These are really FieldDoc instances:
     final ScoreDoc[][] shardHits;
-    final FieldComparator[] comparators;
+    final FieldComparator<?>[] comparators;
     final int[] reverseMul;
 
     public MergeSortQueue(Sort sort, TopDocs[] shardHits) throws IOException {
@@ -145,7 +146,7 @@
       }
 
       final SortField[] sortFields = sort.getSort();
-      comparators = new FieldComparator[sortFields.length];
+      comparators = new FieldComparator<?>[sortFields.length];
       reverseMul = new int[sortFields.length];
       for(int compIDX=0;compIDX<sortFields.length;compIDX++) {
         final SortField sortField = sortFields[compIDX];
@@ -155,7 +156,7 @@
     }
 
     // Returns true if first is < second
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     public boolean lessThan(ShardRef first, ShardRef second) {
       assert first != second;
       final FieldDoc firstFD = (FieldDoc) shardHits[first.shardIndex][first.hitIndex];
Index: lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java	(working copy)
@@ -46,7 +46,7 @@
   private static class OneComparatorNonScoringCollector extends 
       TopFieldCollector {
 
-    final FieldComparator comparator;
+    final FieldComparator<?> comparator;
     final int reverseMul;
     
     public OneComparatorNonScoringCollector(FieldValueHitQueue<Entry> queue,
@@ -379,7 +379,7 @@
    */
   private static class MultiComparatorNonScoringCollector extends TopFieldCollector {
     
-    final FieldComparator[] comparators;
+    final FieldComparator<?>[] comparators;
     final int[] reverseMul;
 
     public MultiComparatorNonScoringCollector(FieldValueHitQueue<Entry> queue,
Index: lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite.java	(working copy)
@@ -87,7 +87,7 @@
     return 31 * size;
   }
 
-  @Override
+  @Override @SuppressWarnings({"unchecked","rawtypes"})
   public boolean equals(Object obj) {
     if (this == obj) return true;
     if (obj == null) return false;
Index: lucene/core/src/java/org/apache/lucene/util/fst/Builder.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/fst/Builder.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/util/fst/Builder.java	(working copy)
@@ -144,7 +144,8 @@
     }
     NO_OUTPUT = outputs.getNoOutput();
 
-    @SuppressWarnings("unchecked") final UnCompiledNode<T>[] f = (UnCompiledNode<T>[]) new UnCompiledNode[10];
+    @SuppressWarnings({"rawtypes","unchecked"}) final UnCompiledNode<T>[] f =
+        (UnCompiledNode<T>[]) new UnCompiledNode[10];
     frontier = f;
     for(int idx=0;idx<frontier.length;idx++) {
       frontier[idx] = new UnCompiledNode<T>(this, idx);
@@ -239,7 +240,8 @@
         if (node.inputCount < minSuffixCount2 || (minSuffixCount2 == 1 && node.inputCount == 1 && idx > 1)) {
           // drop all arcs
           for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
-            @SuppressWarnings("unchecked") final UnCompiledNode<T> target = (UnCompiledNode<T>) node.arcs[arcIdx].target;
+            @SuppressWarnings({"rawtypes","unchecked"}) final UnCompiledNode<T> target =
+                (UnCompiledNode<T>) node.arcs[arcIdx].target;
             target.clear();
           }
           node.numArcs = 0;
@@ -356,7 +358,7 @@
     final int prefixLenPlus1 = pos1+1;
       
     if (frontier.length < input.length+1) {
-      @SuppressWarnings("unchecked") final UnCompiledNode<T>[] next =
+      @SuppressWarnings({"rawtypes","unchecked"}) final UnCompiledNode<T>[] next =
         new UnCompiledNode[ArrayUtil.oversize(input.length+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
       System.arraycopy(frontier, 0, next, 0, frontier.length);
       for(int idx=frontier.length;idx<next.length;idx++) {
@@ -458,7 +460,7 @@
       final Arc<T> arc = node.arcs[arcIdx];
       if (!arc.target.isCompiled()) {
         // not yet compiled
-        @SuppressWarnings("unchecked") final UnCompiledNode<T> n = (UnCompiledNode<T>) arc.target;
+        @SuppressWarnings({"rawtypes","unchecked"}) final UnCompiledNode<T> n = (UnCompiledNode<T>) arc.target;
         if (n.numArcs == 0) {
           //System.out.println("seg=" + segment + "        FORCE final arc=" + (char) arc.label);
           arc.isFinal = n.isFinal = true;
@@ -512,7 +514,7 @@
      *          LUCENE-2934 (node expansion based on conditions other than the
      *          fanout size).
      */
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"rawtypes","unchecked"})
     public UnCompiledNode(Builder<T> owner, int depth) {
       this.owner = owner;
       arcs = (Arc<T>[]) new Arc[1];
@@ -545,7 +547,7 @@
       assert label >= 0;
       assert numArcs == 0 || label > arcs[numArcs-1].label: "arc[-1].label=" + arcs[numArcs-1].label + " new label=" + label + " numArcs=" + numArcs;
       if (numArcs == arcs.length) {
-        @SuppressWarnings("unchecked") final Arc<T>[] newArcs =
+        @SuppressWarnings({"rawtypes","unchecked"}) final Arc<T>[] newArcs =
           new Arc[ArrayUtil.oversize(numArcs+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
         System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
         for(int arcIdx=numArcs;arcIdx<newArcs.length;arcIdx++) {
Index: lucene/core/src/java/org/apache/lucene/util/fst/FST.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/fst/FST.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/util/fst/FST.java	(working copy)
@@ -376,7 +376,7 @@
   }
 
   // Caches first 128 labels
-  @SuppressWarnings("unchecked")
+  @SuppressWarnings({"rawtypes","unchecked"})
   private void cacheRootArcs() throws IOException {
     cachedRootArcs = (Arc<T>[]) new Arc[0x80];
     final Arc<T> arc = new Arc<T>();
Index: lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java	(revision 1297051)
+++ lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java	(working copy)
@@ -30,9 +30,9 @@
 abstract class FSTEnum<T> {
   protected final FST<T> fst;
 
-  @SuppressWarnings("unchecked") protected FST.Arc<T>[] arcs = new FST.Arc[10];
+  @SuppressWarnings({"rawtypes","unchecked"}) protected FST.Arc<T>[] arcs = new FST.Arc[10];
   // outputs are cumulative
-  @SuppressWarnings("unchecked") protected T[] output = (T[]) new Object[10];
+  @SuppressWarnings({"rawtypes","unchecked"}) protected T[] output = (T[]) new Object[10];
 
   protected final T NO_OUTPUT;
   protected final FST.Arc<T> scratchArc = new FST.Arc<T>();
@@ -462,13 +462,13 @@
     upto++;
     grow();
     if (arcs.length <= upto) {
-      @SuppressWarnings("unchecked") final FST.Arc<T>[] newArcs =
+      @SuppressWarnings({"rawtypes","unchecked"}) final FST.Arc<T>[] newArcs =
         new FST.Arc[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
       System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
       arcs = newArcs;
     }
     if (output.length <= upto) {
-      @SuppressWarnings("unchecked") final T[] newOutput =
+      @SuppressWarnings({"rawtypes","unchecked"}) final T[] newOutput =
         (T[]) new Object[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
       System.arraycopy(output, 0, newOutput, 0, output.length);
       output = newOutput;
Index: lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(working copy)
@@ -29,6 +29,7 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermPositions;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 
 public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
Index: lucene/core/src/test/org/apache/lucene/analysis/TestCharArraySet.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/analysis/TestCharArraySet.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/analysis/TestCharArraySet.java	(working copy)
@@ -501,7 +501,7 @@
     } catch (NullPointerException e) {}
   }
   
-  @Deprecated @SuppressWarnings("unchecked")
+  @Deprecated @SuppressWarnings({"unchecked","rawtypes"})
   public void testIterator() {
     HashSet<String> hset = new HashSet<String>();
     hset.addAll(Arrays.asList(TEST_STOP_WORDS));
Index: lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(working copy)
@@ -35,6 +35,7 @@
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field.TermVector;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.LuceneTestCase;
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -32,6 +32,7 @@
 import org.apache.lucene.document.Field.Index;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(working copy)
@@ -23,6 +23,7 @@
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
Index: lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java	(working copy)
@@ -27,6 +27,7 @@
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.FixedBitSet;
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(working copy)
@@ -24,6 +24,7 @@
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field.Index;
 import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 
 public class TestParallelTermEnum extends LuceneTestCase {
Index: lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java	(working copy)
@@ -24,6 +24,7 @@
 import java.util.Map;
 
 import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
Index: lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java	(working copy)
@@ -22,6 +22,7 @@
 import java.util.Set;
 
 import org.apache.lucene.util.*;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.*;
 import org.apache.lucene.document.*;
 
Index: lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -32,6 +32,7 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Fieldable;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
Index: lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java	(working copy)
@@ -28,6 +28,7 @@
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
Index: lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(working copy)
@@ -29,6 +29,7 @@
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
Index: lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java	(working copy)
@@ -254,7 +254,7 @@
   static final class JustCompileFieldComparatorSource extends FieldComparatorSource {
 
     @Override
-    public FieldComparator newComparator(String fieldname, int numHits,
+    public FieldComparator<?> newComparator(String fieldname, int numHits,
         int sortPos, boolean reversed) throws IOException {
       throw new UnsupportedOperationException(UNSUPPORTED_MSG);
     }
Index: lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(working copy)
@@ -51,7 +51,7 @@
     INDEX_SIZE = atLeast(2000);
     index = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, index);
-    RandomGen random = new RandomGen(this.random);
+    RandomGen random = new RandomGen(LuceneTestCase.random);
     for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                            // problem doesn't show up
       Document doc = new Document();
Index: lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java	(working copy)
@@ -136,7 +136,7 @@
   }
 
   @Override
-  public FieldComparator newComparator(final String fieldname, final int numHits, int sortPos, boolean reversed) throws IOException {
+  public FieldComparator<Integer> newComparator(final String fieldname, final int numHits, int sortPos, boolean reversed) throws IOException {
    return new FieldComparator<Integer>() {
 
      FieldCache.StringIndex idIndex;
Index: lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -362,7 +362,7 @@
       }
       posIncrAttr.setPositionIncrement(posIncr);
       pos += posIncr;
-      if (TestPositionIncrement.VERBOSE) {
+      if (LuceneTestCase.VERBOSE) {
         System.out.println("term=" + termAttr + " pos=" + pos);
       }
       i++;
Index: lucene/core/src/test/org/apache/lucene/search/TestSort.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSort.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/TestSort.java	(working copy)
@@ -553,7 +553,7 @@
 
   static class MyFieldComparatorSource extends FieldComparatorSource {
     @Override
-    public FieldComparator newComparator(String fieldname, int numHits, int sortPos, boolean reversed) {
+    public FieldComparator<Integer> newComparator(String fieldname, int numHits, int sortPos, boolean reversed) {
       return new MyFieldComparator(numHits);
     }
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java	(working copy)
@@ -159,7 +159,7 @@
     }
   }
 
-  @SuppressWarnings("unchecked")
+  @SuppressWarnings({"unchecked","rawtypes"})
   @Test
   public void testBooleanQuery() throws Exception {
     TermQuery aQuery = new TermQuery(new Term("f", "a"));
Index: lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java	(working copy)
@@ -50,6 +50,7 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.UnicodeUtil;
 import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.fst.BytesRefFSTEnum.InputOutput;
 import org.apache.lucene.util.fst.FST.Arc;
 import org.apache.lucene.util.fst.FST.BytesReader;
 import org.apache.lucene.util.fst.PairOutputs.Pair;
@@ -964,7 +965,7 @@
         if (VERBOSE) {
           System.out.println("  fstEnum.next prefix=" + inputToString(inputMode, current.input, false) + " output=" + outputs.outputToString(current.output));
         }
-        final CountMinOutput cmo = prefixes.get(current.input);
+        final CountMinOutput<T> cmo = prefixes.get(current.input);
         assertNotNull(cmo);
         assertTrue(cmo.isLeaf || cmo.isFinal);
         //if (cmo.isFinal && !cmo.isLeaf) {
@@ -1190,7 +1191,7 @@
           }
 
           termEnum = r.terms(new Term("body", randomTerm));
-          final IntsRefFSTEnum.InputOutput fstSeekResult = fstEnum.seekCeil(toIntsRef(randomTerm));
+          final IntsRefFSTEnum.InputOutput<Long> fstSeekResult = fstEnum.seekCeil(toIntsRef(randomTerm));
 
           if (termEnum.term() == null || !"body".equals(termEnum.term().field())) {
             assertNull("got " + (fstSeekResult == null ? "null" : toString(fstSeekResult.input) + " but expected null"), fstSeekResult);
@@ -1231,7 +1232,7 @@
     dir.close();
   }
 
-  private void assertSame(TermEnum termEnum, IntsRefFSTEnum fstEnum, boolean storeOrd) throws Exception {
+  private void assertSame(TermEnum termEnum, IntsRefFSTEnum<?> fstEnum, boolean storeOrd) throws Exception {
     if (termEnum.term() == null || !"body".equals(termEnum.term().field())) {
       if (fstEnum.current() != null) {
         fail("fstEnum.current().input=" + toString(fstEnum.current().input));
@@ -1831,7 +1832,7 @@
 
       public int verifyStateAndBelow(FST<Object> fst, Arc<Object> arc, int depth) 
         throws IOException {
-        if (fst.targetHasArcs(arc)) {
+        if (FST.targetHasArcs(arc)) {
           int childCount = 0;
           for (arc = fst.readFirstTargetArc(arc, arc);; 
                arc = fst.readNextArc(arc), childCount++)
Index: lucene/core/src/test/org/apache/lucene/util/TestAttributeSource.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/TestAttributeSource.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/util/TestAttributeSource.java	(working copy)
@@ -156,7 +156,7 @@
       src.addAttribute(TypeAttribute.class) instanceof TypeAttributeImpl);
   }
   
-  @SuppressWarnings("unchecked")
+  @SuppressWarnings({"rawtypes","unchecked"})
   public void testInvalidArguments() throws Exception {
     try {
       AttributeSource src = new AttributeSource();
Index: lucene/core/src/test/org/apache/lucene/util/TestVirtualMethod.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/TestVirtualMethod.java	(revision 1297051)
+++ lucene/core/src/test/org/apache/lucene/util/TestVirtualMethod.java	(working copy)
@@ -69,7 +69,7 @@
     assertEquals(0, VirtualMethod.compareImplementationDistance(TestClass5.class, publicTestMethod, protectedTestMethod));
   }
 
-  @SuppressWarnings("unchecked")
+  @SuppressWarnings({"rawtypes","unchecked"})
   public void testExceptions() {
     try {
       // cast to Class to remove generics:
Index: solr
===================================================================
--- solr	(revision 1297051)
+++ solr	(working copy)

Property changes on: solr
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/solr:r1297048
Index: solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java	(revision 1297051)
+++ solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/MailEntityProcessor.java	(working copy)
@@ -19,7 +19,9 @@
 import com.sun.mail.imap.IMAPMessage;
 
 import org.apache.tika.Tika;
+import org.apache.tika.metadata.HttpHeaders;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaMetadataKeys;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -168,8 +170,8 @@
       InputStream is = part.getInputStream();
       String fileName = part.getFileName();
       Metadata md = new Metadata();
-      md.set(Metadata.CONTENT_TYPE, ctype.getBaseType().toLowerCase(Locale.ENGLISH));
-      md.set(Metadata.RESOURCE_NAME_KEY, fileName);
+      md.set(HttpHeaders.CONTENT_TYPE, ctype.getBaseType().toLowerCase(Locale.ENGLISH));
+      md.set(TikaMetadataKeys.RESOURCE_NAME_KEY, fileName);
       String content = tika.parseToString(is, md);
       if (disp != null && disp.equalsIgnoreCase(Part.ATTACHMENT)) {
         if (row.get(ATTACHMENT) == null)
Index: solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java	(revision 1297051)
+++ solr/contrib/dataimporthandler-extras/src/java/org/apache/solr/handler/dataimport/TikaEntityProcessor.java	(working copy)
@@ -34,6 +34,7 @@
 
 import javax.xml.transform.OutputKeys;
 import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.TransformerFactory;
 import javax.xml.transform.sax.SAXTransformerFactory;
 import javax.xml.transform.sax.TransformerHandler;
 import javax.xml.transform.stream.StreamResult;
@@ -142,7 +143,7 @@
   private static ContentHandler getHtmlHandler(Writer writer)
           throws TransformerConfigurationException {
     SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
+            TransformerFactory.newInstance();
     TransformerHandler handler = factory.newTransformerHandler();
     handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "html");
     handler.setResult(new StreamResult(writer));
@@ -185,7 +186,7 @@
   private static ContentHandler getXmlContentHandler(Writer writer)
           throws TransformerConfigurationException {
     SAXTransformerFactory factory = (SAXTransformerFactory)
-            SAXTransformerFactory.newInstance();
+            TransformerFactory.newInstance();
     TransformerHandler handler = factory.newTransformerHandler();
     handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
     handler.setResult(new StreamResult(writer));
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java	(revision 1297051)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java	(working copy)
@@ -211,7 +211,7 @@
     tmpdir.delete();
     tmpdir.mkdir();
     tmpdir.deleteOnExit();
-    TestFileListEntityProcessor.createFile(tmpdir, "x.xsl", xsl.getBytes("UTF-8"),
+    AbstractDataImportHandlerTestCase.createFile(tmpdir, "x.xsl", xsl.getBytes("UTF-8"),
             false);
     Map entityAttrs = createMap("name", "e",
             XPathEntityProcessor.USE_SOLR_ADD_SCHEMA, "true", "xsl", ""
Index: solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java
===================================================================
--- solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java	(revision 1297051)
+++ solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java	(working copy)
@@ -36,7 +36,9 @@
 import org.apache.solr.update.processor.UpdateRequestProcessor;
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.HttpHeaders;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaMetadataKeys;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.DefaultParser;
@@ -168,11 +170,11 @@
       // then Tika can make use of it in guessing the appropriate MIME type:
       String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);
       if (resourceName != null) {
-        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);
+        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);
       }
       // Provide stream's content type as hint for auto detection
       if(stream.getContentType() != null) {
-        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());
+        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());
       }
 
       InputStream inputStream = null;
@@ -185,7 +187,7 @@
         // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata
         String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());
         if(charset != null){
-          metadata.add(Metadata.CONTENT_ENCODING, charset);
+          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);
         }
 
         String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);
Index: solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/SolrContentHandler.java
===================================================================
--- solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/SolrContentHandler.java	(revision 1297051)
+++ solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/SolrContentHandler.java	(working copy)
@@ -24,6 +24,7 @@
 import org.apache.solr.schema.IndexSchema;
 import org.apache.solr.schema.SchemaField;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaMetadataKeys;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.xml.sax.Attributes;
@@ -191,7 +192,7 @@
     if (sf==null && unknownFieldPrefix.length() > 0) {
       name = unknownFieldPrefix + name;
       sf = schema.getFieldOrNull(name);
-    } else if (sf == null && defaultField.length() > 0 && name.equals(Metadata.RESOURCE_NAME_KEY) == false /*let the fall through below handle this*/){
+    } else if (sf == null && defaultField.length() > 0 && name.equals(TikaMetadataKeys.RESOURCE_NAME_KEY) == false /*let the fall through below handle this*/){
       name = defaultField;
       sf = schema.getFieldOrNull(name);
     }
@@ -201,7 +202,7 @@
     // ExtractingDocumentLoader.load(). You shouldn't have to define a mapping for this
     // field just because you specified a resource.name parameter to the handler, should
     // you?
-    if (sf == null && unknownFieldPrefix.length()==0 && name == Metadata.RESOURCE_NAME_KEY) {
+    if (sf == null && unknownFieldPrefix.length()==0 && name == TikaMetadataKeys.RESOURCE_NAME_KEY) {
       return;
     }
 
Index: solr/contrib/velocity/src/java/org/apache/solr/response/VelocityResponseWriter.java
===================================================================
--- solr/contrib/velocity/src/java/org/apache/solr/response/VelocityResponseWriter.java	(revision 1297051)
+++ solr/contrib/velocity/src/java/org/apache/solr/response/VelocityResponseWriter.java	(working copy)
@@ -25,6 +25,7 @@
 import org.apache.velocity.Template;
 import org.apache.velocity.VelocityContext;
 import org.apache.velocity.app.VelocityEngine;
+import org.apache.velocity.runtime.RuntimeConstants;
 import org.apache.velocity.tools.generic.*;
 
 import java.io.*;
@@ -117,14 +118,14 @@
     if (template_root != null) {
       baseDir = new File(template_root);
     }
-    engine.setProperty(VelocityEngine.FILE_RESOURCE_LOADER_PATH, baseDir.getAbsolutePath());
+    engine.setProperty(RuntimeConstants.FILE_RESOURCE_LOADER_PATH, baseDir.getAbsolutePath());
     engine.setProperty("params.resource.loader.instance", new SolrParamResourceLoader(request));
     SolrVelocityResourceLoader resourceLoader =
         new SolrVelocityResourceLoader(request.getCore().getSolrConfig().getResourceLoader());
     engine.setProperty("solr.resource.loader.instance", resourceLoader);
 
     // TODO: Externalize Velocity properties
-    engine.setProperty(VelocityEngine.RESOURCE_LOADER, "params,file,solr");
+    engine.setProperty(RuntimeConstants.RESOURCE_LOADER, "params,file,solr");
     String propFile = request.getParams().get("v.properties");
     try {
       if (propFile == null)
Index: solr/core
===================================================================
--- solr/core	(revision 1297051)
+++ solr/core	(working copy)

Property changes on: solr/core
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/solr/core:r1297048
Index: solr/core/src/java/org/apache/solr/request/SimpleFacets.java
===================================================================
--- solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(working copy)
@@ -645,7 +645,7 @@
     }
 
     final String gap = required.getFieldParam(f,FacetParams.FACET_DATE_GAP);
-    final DateMathParser dmp = new DateMathParser(ft.UTC, Locale.US);
+    final DateMathParser dmp = new DateMathParser(DateField.UTC, Locale.US);
 
     final int minCount = params.getFieldInt(f,FacetParams.FACET_MINCOUNT, 0);
 
Index: solr/core/src/java/org/apache/solr/request/UnInvertedField.java
===================================================================
--- solr/core/src/java/org/apache/solr/request/UnInvertedField.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/request/UnInvertedField.java	(working copy)
@@ -974,7 +974,7 @@
       // we hit the term exactly... lucky us!
       if (tenum != null) tenum.close();
       tenum = reader.terms(target);
-      pos = startIdx << tindex.intervalBits;
+      pos = startIdx << TermIndex.intervalBits;
       return setTerm();
     }
 
@@ -992,14 +992,14 @@
     // back up to the start of the block
     startIdx--;
 
-    if ((pos >> tindex.intervalBits) == startIdx && t != null && t.text().compareTo(target.text())<=0) {
+    if ((pos >> TermIndex.intervalBits) == startIdx && t != null && t.text().compareTo(target.text())<=0) {
       // we are already in the right block and the current term is before the term we want,
       // so we don't need to seek.
     } else {
       // seek to the right block
       if (tenum != null) tenum.close();            
       tenum = reader.terms(target.createTerm(tindex.index[startIdx]));
-      pos = startIdx << tindex.intervalBits;
+      pos = startIdx << TermIndex.intervalBits;
       setTerm();  // should be true since it's in the index
     }
 
@@ -1014,10 +1014,10 @@
 
   public boolean skipTo(int termNumber) throws IOException {
     int delta = termNumber - pos;
-    if (delta < 0 || delta > tindex.interval || tenum==null) {
-      int idx = termNumber >>> tindex.intervalBits;
+    if (delta < 0 || delta > TermIndex.interval || tenum==null) {
+      int idx = termNumber >>> TermIndex.intervalBits;
       String base = tindex.index[idx];
-      pos = idx << tindex.intervalBits;
+      pos = idx << TermIndex.intervalBits;
       delta = termNumber - pos;
       if (tenum != null) tenum.close();
       tenum = reader.terms(tindex.createTerm(base));
Index: solr/core/src/java/org/apache/solr/schema/LatLonType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/LatLonType.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/schema/LatLonType.java	(working copy)
@@ -349,8 +349,8 @@
 
     public SpatialWeight(Searcher searcher) throws IOException {
       this.searcher = searcher;
-      this.latContext = latSource.newContext();
-      this.lonContext = lonSource.newContext();
+      this.latContext = ValueSource.newContext();
+      this.lonContext = ValueSource.newContext();
       latSource.createWeight(latContext, searcher);
       lonSource.createWeight(lonContext, searcher);
     }
Index: solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParserPlugin.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParserPlugin.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParserPlugin.java	(working copy)
@@ -105,25 +105,25 @@
     
     SolrParams solrParams = SolrParams.wrapDefaults(localParams, params);
 
-    queryFields = U.parseFieldBoosts(solrParams.getParams(DMP.QF));
+    queryFields = SolrPluginUtils.parseFieldBoosts(solrParams.getParams(DisMaxParams.QF));
     if (0 == queryFields.size()) {
       queryFields.put(req.getSchema().getDefaultSearchFieldName(), 1.0f);
     }
     
     // Boosted phrase of the full query string
     Map<String,Float> phraseFields = 
-      U.parseFieldBoosts(solrParams.getParams(DMP.PF));
+      SolrPluginUtils.parseFieldBoosts(solrParams.getParams(DisMaxParams.PF));
     // Boosted Bi-Term Shingles from the query string
     Map<String,Float> phraseFields2 = 
-      U.parseFieldBoosts(solrParams.getParams("pf2"));
+      SolrPluginUtils.parseFieldBoosts(solrParams.getParams("pf2"));
     // Boosted Tri-Term Shingles from the query string
     Map<String,Float> phraseFields3 = 
-      U.parseFieldBoosts(solrParams.getParams("pf3"));
+      SolrPluginUtils.parseFieldBoosts(solrParams.getParams("pf3"));
 
-    float tiebreaker = solrParams.getFloat(DMP.TIE, 0.0f);
+    float tiebreaker = solrParams.getFloat(DisMaxParams.TIE, 0.0f);
 
-    int pslop = solrParams.getInt(DMP.PS, 0);
-    int qslop = solrParams.getInt(DMP.QS, 0);
+    int pslop = solrParams.getInt(DisMaxParams.PS, 0);
+    int qslop = solrParams.getInt(DisMaxParams.QS, 0);
 
     // remove stopwords from mandatory "matching" component?
     boolean stopwords = solrParams.getBool("stopwords", true);
@@ -139,7 +139,7 @@
     altUserQuery = null;
     if( userQuery == null || userQuery.length() < 1 ) {
       // If no query is specified, we may have an alternate
-      String altQ = solrParams.get( DMP.ALTQ );
+      String altQ = solrParams.get( DisMaxParams.ALTQ );
       if (altQ != null) {
         altQParser = subQuery(altQ, null);
         altUserQuery = altQParser.getQuery();
@@ -248,9 +248,9 @@
       }
 
       if (parsedUserQuery != null && doMinMatched) {
-        String minShouldMatch = solrParams.get(DMP.MM, "100%");
+        String minShouldMatch = solrParams.get(DisMaxParams.MM, "100%");
         if (parsedUserQuery instanceof BooleanQuery) {
-          U.setMinShouldMatch((BooleanQuery)parsedUserQuery, minShouldMatch);
+          SolrPluginUtils.setMinShouldMatch((BooleanQuery)parsedUserQuery, minShouldMatch);
         }
       }
 
@@ -286,12 +286,12 @@
         parsedUserQuery = up.parse(escapedUserQuery);
 
         // Only do minimum-match logic
-        String minShouldMatch = solrParams.get(DMP.MM, "100%");
+        String minShouldMatch = solrParams.get(DisMaxParams.MM, "100%");
 
         if (parsedUserQuery instanceof BooleanQuery) {
           BooleanQuery t = new BooleanQuery();
-          U.flattenBooleanQuery(t, (BooleanQuery)parsedUserQuery);
-          U.setMinShouldMatch(t, minShouldMatch);
+          SolrPluginUtils.flattenBooleanQuery(t, (BooleanQuery)parsedUserQuery);
+          SolrPluginUtils.setMinShouldMatch(t, minShouldMatch);
           parsedUserQuery = t;
         }
       }
@@ -331,7 +331,7 @@
 
 
     /* * * Boosting Query * * */
-    boostParams = solrParams.getParams(DMP.BQ);
+    boostParams = solrParams.getParams(DisMaxParams.BQ);
     //List<Query> boostQueries = U.parseQueryStrings(req, boostParams);
     boostQueries=null;
     if (boostParams!=null && boostParams.length>0) {
@@ -350,7 +350,7 @@
 
     /* * * Boosting Functions * * */
 
-    String[] boostFuncs = solrParams.getParams(DMP.BF);
+    String[] boostFuncs = solrParams.getParams(DisMaxParams.BF);
     if (null != boostFuncs && 0 != boostFuncs.length) {
       for (String boostFunc : boostFuncs) {
         if(null == boostFunc || "".equals(boostFunc)) continue;
Index: solr/core/src/java/org/apache/solr/search/function/BoostedQuery.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/function/BoostedQuery.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/search/function/BoostedQuery.java	(working copy)
@@ -68,7 +68,7 @@
     public BoostedWeight(Searcher searcher) throws IOException {
       this.searcher = searcher;
       this.qWeight = q.createWeight(searcher);
-      this.context = boostVal.newContext();
+      this.context = ValueSource.newContext();
       boostVal.createWeight(context,searcher);
     }
 
Index: solr/core/src/java/org/apache/solr/search/function/FunctionQuery.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/function/FunctionQuery.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/search/function/FunctionQuery.java	(working copy)
@@ -65,7 +65,7 @@
 
     public FunctionWeight(Searcher searcher) throws IOException {
       this.searcher = searcher;
-      this.context = func.newContext();
+      this.context = ValueSource.newContext();
       func.createWeight(context, searcher);
     }
 
Index: solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java	(working copy)
@@ -23,6 +23,7 @@
 import org.apache.lucene.util.OpenBitSet;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.search.*;
+import org.apache.solr.search.QueryUtils;
 import org.apache.solr.search.grouping.distributed.shardresultserializer.ShardResultTransformer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
Index: solr/core/src/java/org/apache/solr/update/DirectUpdateHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/DirectUpdateHandler.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/update/DirectUpdateHandler.java	(working copy)
@@ -135,8 +135,8 @@
     try {
       Term term = new Term(idField.getName(), indexedId);
       num = ir.deleteDocuments(term);
-      if (core.log.isTraceEnabled()) {
-        core.log.trace( core.getLogId()+"deleted " + num + " docs matching id " + idFieldType.indexedToReadable(indexedId));
+      if (SolrCore.log.isTraceEnabled()) {
+        SolrCore.log.trace( core.getLogId()+"deleted " + num + " docs matching id " + idFieldType.indexedToReadable(indexedId));
       }
     } finally {
       try { if (tdocs != null) tdocs.close(); } catch (Exception e) {}
@@ -205,8 +205,8 @@
       totDeleted = deleter.deleted;
     }
 
-    if (core.log.isDebugEnabled()) {
-      core.log.debug(core.getLogId()+"docs deleted:" + totDeleted);
+    if (SolrCore.log.isDebugEnabled()) {
+      SolrCore.log.debug(core.getLogId()+"docs deleted:" + totDeleted);
     }
 
   }
Index: solr/core/src/java/org/apache/solr/update/DirectUpdateHandler2.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/DirectUpdateHandler2.java	(revision 1297051)
+++ solr/core/src/java/org/apache/solr/update/DirectUpdateHandler2.java	(working copy)
@@ -160,7 +160,7 @@
 
   // must only be called when iwCommit lock held
   private void deleteAll() throws IOException {
-    core.log.info(core.getLogId()+"REMOVING ALL DOCUMENTS FROM INDEX");
+    SolrCore.log.info(core.getLogId()+"REMOVING ALL DOCUMENTS FROM INDEX");
     closeWriter();
     writer = createMainIndexWriter("DirectUpdateHandler2", true);
   }
Index: solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java
===================================================================
--- solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java	(working copy)
@@ -18,6 +18,7 @@
 package org.apache.solr.analysis;
 
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.StopFilter;
@@ -298,12 +299,12 @@
     
     TokenStream ts = factoryDefault.create(
         new WhitespaceTokenizer(BaseTokenTestCase.DEFAULT_VERSION, new StringReader(testText)));
-    BaseTokenTestCase.assertTokenStreamContents(ts, 
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
         new String[] { "I", "borrowed", "5", "400", "00", "540000", "at", "25", "interest", "rate", "interestrate" });
 
     ts = factoryDefault.create(
         new WhitespaceTokenizer(BaseTokenTestCase.DEFAULT_VERSION, new StringReader("foo\u200Dbar")));
-    BaseTokenTestCase.assertTokenStreamContents(ts, 
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
         new String[] { "foo", "bar", "foobar" });
 
     
@@ -316,13 +317,13 @@
     
     ts = factoryCustom.create(
         new WhitespaceTokenizer(BaseTokenTestCase.DEFAULT_VERSION, new StringReader(testText)));
-    BaseTokenTestCase.assertTokenStreamContents(ts, 
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
         new String[] { "I", "borrowed", "$5,400.00", "at", "25%", "interest", "rate", "interestrate" });
     
     /* test custom behavior with a char > 0x7F, because we had to make a larger byte[] */
     ts = factoryCustom.create(
         new WhitespaceTokenizer(BaseTokenTestCase.DEFAULT_VERSION, new StringReader("foo\u200Dbar")));
-    BaseTokenTestCase.assertTokenStreamContents(ts, 
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
         new String[] { "foo\u200Dbar" });
   }
 
Index: solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
===================================================================
--- solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(working copy)
@@ -50,7 +50,7 @@
         + System.getProperty("file.separator") + "data");
     dataDir.mkdirs();
 
-    solrConfig = h.createConfig("solrconfig.xml");
+    solrConfig = TestHarness.createConfig("solrconfig.xml");
     h = new TestHarness( dataDir.getAbsolutePath(),
         solrConfig,
         "schema12.xml");
Index: solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java	(working copy)
@@ -17,12 +17,14 @@
  * limitations under the License.
  */
 
+import junit.framework.Assert;
 import junit.framework.TestCase;
 
 import org.apache.solr.BaseDistributedSearchTestCase;
 import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SpellingParams;
 import org.apache.solr.common.util.NamedList;
 
 /**
@@ -81,7 +83,7 @@
     NamedList sc = (NamedList) nl.get("spellcheck");
     NamedList sug = (NamedList) sc.get("suggestions");
     if(sug.size()==0) {
-      TestCase.fail("Control data did not return any suggestions.");
+      Assert.fail("Control data did not return any suggestions.");
     }
   }
   
@@ -119,15 +121,15 @@
     handle.put("maxScore", SKIPVAL);
     // we care only about the spellcheck results
     handle.put("response", SKIP);
-    q("q", "*:*", "spellcheck", "true", SpellCheckComponent.SPELLCHECK_BUILD, "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH");
+    q("q", "*:*", "spellcheck", "true", SpellingParams.SPELLCHECK_BUILD, "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH");
     
     query("q", "*:*", "fl", "id,lowerfilt", "spellcheck.q","toyata", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH");
-    query("q", "*:*", "fl", "id,lowerfilt", "spellcheck.q","toyata", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true");
-    query("q", "*:*", "fl", "id,lowerfilt", "spellcheck.q","bluo", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true", SpellCheckComponent.SPELLCHECK_COUNT, "4");
-    query("q", "The quick reb fox jumped over the lazy brown dogs", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true", SpellCheckComponent.SPELLCHECK_COUNT, "4", SpellCheckComponent.SPELLCHECK_COLLATE, "true");
+    query("q", "*:*", "fl", "id,lowerfilt", "spellcheck.q","toyata", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true");
+    query("q", "*:*", "fl", "id,lowerfilt", "spellcheck.q","bluo", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true", SpellingParams.SPELLCHECK_COUNT, "4");
+    query("q", "The quick reb fox jumped over the lazy brown dogs", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true", SpellingParams.SPELLCHECK_COUNT, "4", SpellingParams.SPELLCHECK_COLLATE, "true");
 
-    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true", SpellCheckComponent.SPELLCHECK_COUNT, "10", SpellCheckComponent.SPELLCHECK_COLLATE, "true", SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "10", SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "10", SpellCheckComponent.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "true");
-    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true", SpellCheckComponent.SPELLCHECK_COUNT, "10", SpellCheckComponent.SPELLCHECK_COLLATE, "true", SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "10", SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "10", SpellCheckComponent.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "false");
-    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true", SpellCheckComponent.SPELLCHECK_COUNT, "10", SpellCheckComponent.SPELLCHECK_COLLATE, "true", SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "0", SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "1", SpellCheckComponent.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "false");
+    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true", SpellingParams.SPELLCHECK_COUNT, "10", SpellingParams.SPELLCHECK_COLLATE, "true", SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "10", SpellingParams.SPELLCHECK_MAX_COLLATIONS, "10", SpellingParams.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "true");
+    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true", SpellingParams.SPELLCHECK_COUNT, "10", SpellingParams.SPELLCHECK_COLLATE, "true", SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "10", SpellingParams.SPELLCHECK_MAX_COLLATIONS, "10", SpellingParams.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "false");
+    query("q", "lowerfilt:(+quock +reb)", "fl", "id,lowerfilt", "spellcheck", "true", "qt", "spellCheckCompRH", "shards.qt", "spellCheckCompRH", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true", SpellingParams.SPELLCHECK_COUNT, "10", SpellingParams.SPELLCHECK_COLLATE, "true", SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "0", SpellingParams.SPELLCHECK_MAX_COLLATIONS, "1", SpellingParams.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "false");
   }
 }
Index: solr/core/src/test/org/apache/solr/handler/component/SpellCheckComponentTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/handler/component/SpellCheckComponentTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/handler/component/SpellCheckComponentTest.java	(working copy)
@@ -32,6 +32,7 @@
 import org.apache.solr.request.SolrRequestHandler;
 import org.apache.solr.response.SolrQueryResponse;
 import org.apache.solr.spelling.AbstractLuceneSpellChecker;
+import org.apache.solr.spelling.SolrSpellChecker;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -76,12 +77,12 @@
   
   @Test
   public void testExtendedResultsCount() throws Exception {
-    assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellCheckComponent.SPELLCHECK_BUILD, "true", "q","bluo", SpellCheckComponent.SPELLCHECK_COUNT,"5", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS,"false")
+    assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellingParams.SPELLCHECK_BUILD, "true", "q","bluo", SpellingParams.SPELLCHECK_COUNT,"5", SpellingParams.SPELLCHECK_EXTENDED_RESULTS,"false")
        ,"/spellcheck/suggestions/[0]=='bluo'"
        ,"/spellcheck/suggestions/[1]/numFound==5"
     );
 
-    assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","bluo", SpellCheckComponent.SPELLCHECK_COUNT,"3", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS,"true")
+    assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","bluo", SpellingParams.SPELLCHECK_COUNT,"3", SpellingParams.SPELLCHECK_EXTENDED_RESULTS,"true")
        ,"/spellcheck/suggestions/[1]/suggestion==[{'word':'blud','freq':1}, {'word':'blue','freq':1}, {'word':'blee','freq':1}]"
     );
   }
@@ -96,7 +97,7 @@
 
   @Test
   public void testPerDictionary() throws Exception {
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellCheckComponent.SPELLCHECK_BUILD, "true", "q","documemt"
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellingParams.SPELLCHECK_BUILD, "true", "q","documemt"
         , SpellingParams.SPELLCHECK_DICT, "perDict", SpellingParams.SPELLCHECK_PREFIX + ".perDict.foo", "bar", SpellingParams.SPELLCHECK_PREFIX + ".perDict.bar", "foo")
        ,"/spellcheck/suggestions/bar=={'numFound':1, 'startOffset':0, 'endOffset':1, 'suggestion':['foo']}"
        ,"/spellcheck/suggestions/foo=={'numFound':1, 'startOffset':2, 'endOffset':3, 'suggestion':['bar']}"        
@@ -105,16 +106,16 @@
 
   @Test
   public void testCollate() throws Exception {
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellCheckComponent.SPELLCHECK_BUILD, "true", "q","documemt", SpellCheckComponent.SPELLCHECK_COLLATE, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", SpellingParams.SPELLCHECK_BUILD, "true", "q","documemt", SpellingParams.SPELLCHECK_COLLATE, "true")
        ,"/spellcheck/suggestions/collation=='document'"
     );
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documemt lowerfilt:broen^4", SpellCheckComponent.SPELLCHECK_COLLATE, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documemt lowerfilt:broen^4", SpellingParams.SPELLCHECK_COLLATE, "true")
        ,"/spellcheck/suggestions/collation=='document lowerfilt:brown^4'"
     );
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documemtsss broens", SpellCheckComponent.SPELLCHECK_COLLATE, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documemtsss broens", SpellingParams.SPELLCHECK_COLLATE, "true")
        ,"/spellcheck/suggestions/collation=='document brown'"
     );
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","pixma", SpellCheckComponent.SPELLCHECK_COLLATE, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","pixma", SpellingParams.SPELLCHECK_COLLATE, "true")
        ,"/spellcheck/suggestions/collation=='pixmaa'"
     );
   }
@@ -123,10 +124,10 @@
   @Test
   public void testCorrectSpelling() throws Exception {
     // Make sure correct spellings are signaled in the response
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","lowerfilt:lazy lowerfilt:brown", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","lowerfilt:lazy lowerfilt:brown", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true")
        ,"/spellcheck/suggestions=={'correctlySpelled':true}"
     );
-    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","lakkle", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true")
+    assertJQ(req("json.nl","map", "qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","lakkle", SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true")
        ,"/spellcheck/suggestions/correctlySpelled==false"
     );
   }
@@ -156,7 +157,7 @@
 
     NamedList args = new NamedList();
     NamedList spellchecker = new NamedList();
-    spellchecker.add(AbstractLuceneSpellChecker.DICTIONARY_NAME, "default");
+    spellchecker.add(SolrSpellChecker.DICTIONARY_NAME, "default");
     spellchecker.add(AbstractLuceneSpellChecker.FIELD, "lowerfilt");
     spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, "spellchecker1");
     args.add("spellchecker", spellchecker);
@@ -201,7 +202,7 @@
   	  	//So with a threshold of 29%, "another" is absent from the dictionary 
   	  	//while "document" is present.
     	
-  	  	assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documenq", SpellCheckComponent.SPELLCHECK_DICT, "threshold", SpellCheckComponent.SPELLCHECK_COUNT,"5", SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS,"true")
+  	  	assertJQ(req("qt",rh, SpellCheckComponent.COMPONENT_NAME, "true", "q","documenq", SpellingParams.SPELLCHECK_DICT, "threshold", SpellingParams.SPELLCHECK_COUNT,"5", SpellingParams.SPELLCHECK_EXTENDED_RESULTS,"true")
   	        ,"/spellcheck/suggestions/[1]/suggestion==[{'word':'document','freq':2}]"
   	    );
   	  	
@@ -212,9 +213,9 @@
   	  	
   	  	ModifiableSolrParams params = new ModifiableSolrParams();		
   			params.add(SpellCheckComponent.COMPONENT_NAME, "true");
-  			params.add(SpellCheckComponent.SPELLCHECK_COUNT, "10");	
-  			params.add(SpellCheckComponent.SPELLCHECK_DICT, "threshold");
-  			params.add(SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS,"true");
+  			params.add(SpellingParams.SPELLCHECK_COUNT, "10");	
+  			params.add(SpellingParams.SPELLCHECK_DICT, "threshold");
+  			params.add(SpellingParams.SPELLCHECK_EXTENDED_RESULTS,"true");
   			params.add(CommonParams.Q, "anotheq");
   			
   			SolrRequestHandler handler = core.getRequestHandler("spellCheckCompRH");
Index: solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java
===================================================================
--- solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java	(working copy)
@@ -37,6 +37,7 @@
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.solr.BaseDistributedSearchTestCase;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.TestDistributedSearch;
 import org.apache.solr.client.solrj.SolrServer;
@@ -337,7 +338,7 @@
     assertEquals(nDocs, slaveQueryResult.getNumFound());
 
     //compare results
-    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
+    String cmp = BaseDistributedSearchTestCase.compare(masterQueryResult, slaveQueryResult, 0, null);
     assertEquals(null, cmp);
 
     //start config files replication test
@@ -395,7 +396,7 @@
     assertEquals(nDocs, slaveQueryResult.getNumFound());
 
     //compare results
-    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
+    String cmp = BaseDistributedSearchTestCase.compare(masterQueryResult, slaveQueryResult, 0, null);
     assertEquals(null, cmp);
 
     // start stop polling test
@@ -475,7 +476,7 @@
     SolrDocumentList slaveQueryResult = (SolrDocumentList) slaveQueryRsp.get("response");
     assertEquals(nDocs, slaveQueryResult.getNumFound());
     //compare results
-    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
+    String cmp = BaseDistributedSearchTestCase.compare(masterQueryResult, slaveQueryResult, 0, null);
     assertEquals(null, cmp);
 
     // NOTE: at this point, the slave is not polling any more
@@ -524,7 +525,7 @@
     assertEquals(nDocs, slaveQueryResult.getNumFound());
 
     //compare results
-    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
+    String cmp = BaseDistributedSearchTestCase.compare(masterQueryResult, slaveQueryResult, 0, null);
     assertEquals(null, cmp);
 
     // NOTE: the master only replicates after startup now!
@@ -564,7 +565,7 @@
     assertEquals(nDocs, slaveQueryResult.getNumFound());
 
     //compare results
-    String cmp = TestDistributedSearch.compare(masterQueryResult, slaveQueryResult, 0, null);
+    String cmp = BaseDistributedSearchTestCase.compare(masterQueryResult, slaveQueryResult, 0, null);
     assertEquals(null, cmp);
 
     //start config files replication test
Index: solr/core/src/test/org/apache/solr/spelling/FileBasedSpellCheckerTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/spelling/FileBasedSpellCheckerTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/spelling/FileBasedSpellCheckerTest.java	(working copy)
@@ -66,11 +66,11 @@
 
     spellchecker.add(SolrSpellChecker.DICTIONARY_NAME, "external");
     spellchecker.add(AbstractLuceneSpellChecker.LOCATION, "spellings.txt");
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "teststop");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "teststop");
     spellchecker.add(FileBasedSpellChecker.SOURCE_FILE_CHAR_ENCODING, "UTF-8");
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     indexDir.mkdirs();
-    spellchecker.add(FileBasedSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
+    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
     SolrCore core = h.getCore();
     String dictName = checker.init(spellchecker, core);
     assertTrue(dictName + " is not equal to " + "external", dictName.equals("external") == true);
@@ -102,12 +102,12 @@
     spellchecker.add("classname", FileBasedSpellChecker.class.getName());
     spellchecker.add(SolrSpellChecker.DICTIONARY_NAME, "external");
     spellchecker.add(AbstractLuceneSpellChecker.LOCATION, "spellings.txt");
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "teststop");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "teststop");
     spellchecker.add(FileBasedSpellChecker.SOURCE_FILE_CHAR_ENCODING, "UTF-8");
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     indexDir.mkdirs();
-    spellchecker.add(FileBasedSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
-    spellchecker.add(FileBasedSpellChecker.FIELD_TYPE, "teststop");
+    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
+    spellchecker.add(SolrSpellChecker.FIELD_TYPE, "teststop");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
     SolrCore core = h.getCore();
     String dictName = checker.init(spellchecker, core);
@@ -149,8 +149,8 @@
     spellchecker.add(SolrSpellChecker.DICTIONARY_NAME, "external");
     spellchecker.add(AbstractLuceneSpellChecker.LOCATION, "spellings.txt");
     spellchecker.add(FileBasedSpellChecker.SOURCE_FILE_CHAR_ENCODING, "UTF-8");
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "teststop");
-    spellchecker.add(FileBasedSpellChecker.FIELD_TYPE, "teststop");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "teststop");
+    spellchecker.add(SolrSpellChecker.FIELD_TYPE, "teststop");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
 
     SolrCore core = h.getCore();
Index: solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java	(working copy)
@@ -109,7 +109,7 @@
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     indexDir.mkdirs();
     spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "title");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
     SolrCore core = h.getCore();
 
@@ -185,7 +185,7 @@
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     indexDir.mkdirs();
     spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "title");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
     SolrCore core = h.getCore();
     String dictName = checker.init(spellchecker, core);
@@ -242,7 +242,7 @@
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     indexDir.mkdirs();
     spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "title");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
     spellchecker.add(AbstractLuceneSpellChecker.STRING_DISTANCE, JaroWinklerDistance.class.getName());
     SolrCore core = h.getCore();
@@ -297,7 +297,7 @@
     indexDir.mkdirs();
     spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());
     spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());
-    spellchecker.add(IndexBasedSpellChecker.FIELD, "title");
+    spellchecker.add(AbstractLuceneSpellChecker.FIELD, "title");
     spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);
     SolrCore core = h.getCore();
     String dictName = checker.init(spellchecker, core);
Index: solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java	(working copy)
@@ -23,6 +23,7 @@
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SpellingParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.SimpleOrderedMap;
 import org.apache.solr.core.SolrCore;
@@ -58,9 +59,9 @@
     
     ModifiableSolrParams params = new ModifiableSolrParams();   
     params.add(SpellCheckComponent.COMPONENT_NAME, "true");
-    params.add(SpellCheckComponent.SPELLCHECK_BUILD, "true");
-    params.add(SpellCheckComponent.SPELLCHECK_COUNT, "10");   
-    params.add(SpellCheckComponent.SPELLCHECK_COLLATE, "true");
+    params.add(SpellingParams.SPELLCHECK_BUILD, "true");
+    params.add(SpellingParams.SPELLCHECK_COUNT, "10");   
+    params.add(SpellingParams.SPELLCHECK_COLLATE, "true");
     
     params.add(CommonParams.Q, "lowerfilt:(hypenated-wotd)");
     {
@@ -110,11 +111,11 @@
 		
 		ModifiableSolrParams params = new ModifiableSolrParams();		
 		params.add(SpellCheckComponent.COMPONENT_NAME, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_BUILD, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_COUNT, "10");		
-		params.add(SpellCheckComponent.SPELLCHECK_COLLATE, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "10");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "10");
+		params.add(SpellingParams.SPELLCHECK_BUILD, "true");
+		params.add(SpellingParams.SPELLCHECK_COUNT, "10");		
+		params.add(SpellingParams.SPELLCHECK_COLLATE, "true");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "10");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATIONS, "10");
 		params.add(CommonParams.Q, "lowerfilt:(+fauth +home +loane)");
 		params.add(CommonParams.FQ, "NOT(id:1)");
 		
@@ -145,12 +146,12 @@
 		
 		ModifiableSolrParams params = new ModifiableSolrParams();		
 		params.add(SpellCheckComponent.COMPONENT_NAME, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_DICT, "multipleFields");
-		params.add(SpellCheckComponent.SPELLCHECK_BUILD, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_COUNT, "10");		
-		params.add(SpellCheckComponent.SPELLCHECK_COLLATE, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "1");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "1");
+		params.add(SpellingParams.SPELLCHECK_DICT, "multipleFields");
+		params.add(SpellingParams.SPELLCHECK_BUILD, "true");
+		params.add(SpellingParams.SPELLCHECK_COUNT, "10");		
+		params.add(SpellingParams.SPELLCHECK_COLLATE, "true");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "1");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATIONS, "1");
 		params.add(CommonParams.Q, "peac");	
 		
 		//SpellCheckCompRH has no "qf" defined.  It will not find "peace" from "peac" despite it being in the dictionary
@@ -169,7 +170,7 @@
 		
 		//SpellCheckCompRH1 has "lowerfilt1" defined in the "qf" param.  It will find "peace" from "peac" because
 		//requrying field "lowerfilt1" returns the hit.
-		params.remove(SpellCheckComponent.SPELLCHECK_BUILD);
+		params.remove(SpellingParams.SPELLCHECK_BUILD);
 		handler = core.getRequestHandler("spellCheckCompRH1");
 		rsp = new SolrQueryResponse();
 		rsp.add("responseHeader", new SimpleOrderedMap());
@@ -192,11 +193,11 @@
 		ModifiableSolrParams params = new ModifiableSolrParams();
 		params.add(CommonParams.QT, "spellCheckCompRH");
 		params.add(CommonParams.Q, "lowerfilt:(+fauth +home +loane)");
-		params.add(SpellCheckComponent.SPELLCHECK_EXTENDED_RESULTS, "true");
+		params.add(SpellingParams.SPELLCHECK_EXTENDED_RESULTS, "true");
 		params.add(SpellCheckComponent.COMPONENT_NAME, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_BUILD, "true");
-		params.add(SpellCheckComponent.SPELLCHECK_COUNT, "10");
-		params.add(SpellCheckComponent.SPELLCHECK_COLLATE, "true");
+		params.add(SpellingParams.SPELLCHECK_BUILD, "true");
+		params.add(SpellingParams.SPELLCHECK_COUNT, "10");
+		params.add(SpellingParams.SPELLCHECK_COLLATE, "true");
 
 		// Testing backwards-compatible behavior.
 		// Returns 1 collation as a single string.
@@ -216,9 +217,9 @@
 
 		// Testing backwards-compatible response format but will only return a
 		// collation that would return results.
-		params.remove(SpellCheckComponent.SPELLCHECK_BUILD);
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "5");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "1");
+		params.remove(SpellingParams.SPELLCHECK_BUILD);
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "5");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATIONS, "1");
 		handler = core.getRequestHandler("spellCheckCompRH");
 		rsp = new SolrQueryResponse();
 		rsp.add("responseHeader", new SimpleOrderedMap());
@@ -233,10 +234,10 @@
 
 		// Testing returning multiple collations if more than one valid
 		// combination exists.
-		params.remove(SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES);
-		params.remove(SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS);
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATION_TRIES, "10");
-		params.add(SpellCheckComponent.SPELLCHECK_MAX_COLLATIONS, "2");
+		params.remove(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES);
+		params.remove(SpellingParams.SPELLCHECK_MAX_COLLATIONS);
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, "10");
+		params.add(SpellingParams.SPELLCHECK_MAX_COLLATIONS, "2");
 		handler = core.getRequestHandler("spellCheckCompRH");
 		rsp = new SolrQueryResponse();
 		rsp.add("responseHeader", new SimpleOrderedMap());
@@ -255,7 +256,7 @@
 
 		// Testing return multiple collations with expanded collation response
 		// format.
-		params.add(SpellCheckComponent.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "true");
+		params.add(SpellingParams.SPELLCHECK_COLLATE_EXTENDED_RESULTS, "true");
 		handler = core.getRequestHandler("spellCheckCompRH");
 		rsp = new SolrQueryResponse();
 		rsp.add("responseHeader", new SimpleOrderedMap());
Index: solr/core/src/test/org/apache/solr/util/DateMathParserTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/util/DateMathParserTest.java	(revision 1297051)
+++ solr/core/src/test/org/apache/solr/util/DateMathParserTest.java	(working copy)
@@ -167,7 +167,8 @@
     Date trash = p.parseMath("+7YEARS");
     trash = p.parseMath("/MONTH");
     trash = p.parseMath("-5DAYS+20MINUTES");
-    Thread.currentThread().sleep(5);
+    Thread.currentThread();
+    Thread.sleep(5);
     
     String a = fmt.format(p.parseMath(""));
     assertEquals("State of DateMathParser changed", e, a);
Index: solr/solrj/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java
===================================================================
--- solr/solrj/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java	(revision 1297051)
+++ solr/solrj/src/test/org/apache/solr/client/solrj/embedded/JettyWebappTest.java	(working copy)
@@ -56,7 +56,7 @@
     super.setUp();
     System.setProperty("solr.solr.home", ExternalPaths.EXAMPLE_HOME);
     
-    File dataDir = new File(SolrTestCaseJ4.TEMP_DIR,
+    File dataDir = new File(LuceneTestCase.TEMP_DIR,
         getClass().getName() + "-" + System.currentTimeMillis());
     dataDir.mkdirs();
     System.setProperty("solr.data.dir", dataDir.getCanonicalPath());
Index: solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
===================================================================
--- solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java	(revision 1297051)
+++ solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java	(working copy)
@@ -240,7 +240,7 @@
     }
 
     public void setUp() throws Exception {
-      File home = new File(SolrTestCaseJ4.TEMP_DIR,
+      File home = new File(LuceneTestCase.TEMP_DIR,
               getClass().getName() + "-" + System.currentTimeMillis());
 
 
Index: solr/solrj/src/test/org/apache/solr/common/util/TestFastInputStream.java
===================================================================
--- solr/solrj/src/test/org/apache/solr/common/util/TestFastInputStream.java	(revision 1297051)
+++ solr/solrj/src/test/org/apache/solr/common/util/TestFastInputStream.java	(working copy)
@@ -38,7 +38,7 @@
     String ss = "Helloooooooooooooooooooo";
     writeChars(gzos, ss, 0, ss.length());
     gzos.close();
-    NamedListCodec.writeVInt(10, fos);
+    JavaBinCodec.writeVInt(10, fos);
     fos.flushBuffer();
     GZIPInputStream gzis = new GZIPInputStream(new ByteArrayInputStream(b.toByteArray(), 0, b.size()));
     char[] cbuf = new char[ss.length()];
Index: solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
===================================================================
--- solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java	(revision 1297051)
+++ solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java	(working copy)
@@ -17,6 +17,7 @@
  * limitations under the License.
  */
 
+import junit.framework.Assert;
 import junit.framework.TestCase;
 import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
@@ -539,7 +540,7 @@
     cmp = compare(a.getResponse(), b.getResponse(), flags, handle);
     if (cmp != null) {
       log.info("Mismatched responses:\n" + a + "\n" + b);
-      TestCase.fail(cmp);
+      Assert.fail(cmp);
     }
   }
 
Index: solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
===================================================================
--- solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java	(revision 1297051)
+++ solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java	(working copy)
@@ -280,7 +280,7 @@
     String configFile = getSolrConfigFile();
     if (configFile != null) {
 
-      solrConfig = h.createConfig(getSolrConfigFile());
+      solrConfig = TestHarness.createConfig(getSolrConfigFile());
       h = new TestHarness( dataDir.getAbsolutePath(),
               solrConfig,
               getSchemaFile());
@@ -524,13 +524,13 @@
    * @see TestHarness#optimize
    */
   public static String optimize(String... args) {
-    return h.optimize(args);
+    return TestHarness.optimize(args);
   }
   /**
    * @see TestHarness#commit
    */
   public static String commit(String... args) {
-    return h.commit(args);
+    return TestHarness.commit(args);
   }
 
   /**
@@ -595,7 +595,7 @@
    * @see TestHarness#deleteById
    */
   public static String delI(String id) {
-    return h.deleteById(id);
+    return TestHarness.deleteById(id);
   }
   /**
    * Generates a &lt;delete&gt;... XML string for an query
@@ -603,7 +603,7 @@
    * @see TestHarness#deleteByQuery
    */
   public static String delQ(String q) {
-    return h.deleteByQuery(q);
+    return TestHarness.deleteByQuery(q);
   }
 
   /**
@@ -614,7 +614,7 @@
    */
   public static XmlDoc doc(String... fieldsAndValues) {
     XmlDoc d = new XmlDoc();
-    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
+    d.xml = TestHarness.makeSimpleDoc(fieldsAndValues).toString();
     return d;
   }
 
Index: solr/test-framework/src/java/org/apache/solr/util/AbstractSolrTestCase.java
===================================================================
--- solr/test-framework/src/java/org/apache/solr/util/AbstractSolrTestCase.java	(revision 1297051)
+++ solr/test-framework/src/java/org/apache/solr/util/AbstractSolrTestCase.java	(working copy)
@@ -154,7 +154,7 @@
     System.setProperty("solr.solr.home", getSolrHome());
     if (configFile != null) {
 
-      solrConfig = h.createConfig(getSolrConfigFile());
+      solrConfig = TestHarness.createConfig(getSolrConfigFile());
       h = new TestHarness( dataDir.getAbsolutePath(),
               solrConfig,
               getSchemaFile());
@@ -312,13 +312,13 @@
    * @see TestHarness#optimize
    */
   public String optimize(String... args) {
-    return h.optimize(args);
+    return TestHarness.optimize(args);
   }
   /**
    * @see TestHarness#commit
    */
   public String commit(String... args) {
-    return h.commit(args);
+    return TestHarness.commit(args);
   }
 
   /**
@@ -397,7 +397,7 @@
    * @see TestHarness#deleteById
    */
   public String delI(String id, String... args) {
-    return h.deleteById(id, args);
+    return TestHarness.deleteById(id, args);
   }
   
   /**
@@ -406,7 +406,7 @@
    * @see TestHarness#deleteByQuery
    */
   public String delQ(String q, String... args) {
-    return h.deleteByQuery(q, args);
+    return TestHarness.deleteByQuery(q, args);
   }
   
   /**
@@ -417,7 +417,7 @@
    */
   public Doc doc(String... fieldsAndValues) {
     Doc d = new Doc();
-    d.xml = h.makeSimpleDoc(fieldsAndValues).toString();
+    d.xml = TestHarness.makeSimpleDoc(fieldsAndValues).toString();
     return d;
   }
 
