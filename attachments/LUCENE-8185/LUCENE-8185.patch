Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/Hyphenation.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/Hyphenation.java	(date 1519489313000)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/Hyphenation.java	(date 1519591166000)
@@ -23,12 +23,12 @@
  */
 public class Hyphenation {
 
-  private int[] hyphenPoints;
+  private final int[] hyphenPoints;
 
   /**
    * rawWord as made of alternating strings and {@link Hyphen Hyphen} instances
    */
-  Hyphenation(int[] points) {
+  public Hyphenation(int[] points) {
     hyphenPoints = points;
   }
 
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java	(date 1519489313000)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java	(date 1519591352000)
@@ -158,7 +158,7 @@
         // we only put subwords to the token stream
         // that are longer than minPartSize
         if (partLength < this.minSubwordSize) {
-          // BOGUS/BROKEN/FUNKY/WACKO: somehow we have negative 'parts' according to the 
+          // BOGUS/BROKEN/FUNKY/WACKO: somehow we have negative 'parts' according to the
           // calculation above, and we rely upon minSubwordSize being >=0 to filter them out...
           continue;
         }
@@ -176,11 +176,10 @@
           } else {
             tokens.add(new CompoundToken(start, partLength));
           }
-        } else if (dictionary.contains(termAtt.buffer(), start, partLength - 1)) {
-          // check the dictionary again with a word that is one character
-          // shorter
-          // to avoid problems with genitive 's characters and other binding
-          // characters
+        } else if (partLength - 1 >= this.minSubwordSize &&
+            dictionary.contains(termAtt.buffer(), start, partLength - 1)) {
+          // check the dictionary again with last character removed to also catch terms appended with fogemorphemes
+          // (characters inserted in some languages when joining two words)
           if (this.onlyLongestMatch) {
             if (longestMatchToken != null) {
               if (longestMatchToken.txt.length() < partLength - 1) {
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java	(date 1519489313000)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java	(date 1519591352000)
@@ -21,6 +21,8 @@
 import java.io.Reader;
 import java.io.StringReader;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.Map;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
@@ -31,6 +33,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.charfilter.MappingCharFilter;
 import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
+import org.apache.lucene.analysis.compound.hyphenation.Hyphenation;
 import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
@@ -92,7 +95,7 @@
     InputSource is = new InputSource(getClass().getResource("da_UTF8.xml").toExternalForm());
     HyphenationTree hyphenator = HyphenationCompoundWordTokenFilter
         .getHyphenationTree(is);
-    
+
     HyphenationCompoundWordTokenFilter tf = new HyphenationCompoundWordTokenFilter(
 
         whitespaceMockTokenizer("basketballkurv"),
@@ -132,6 +135,23 @@
     
   }
 
+  public void testHyphenationAndDictionaryHonoursMinWordLength() throws Exception {
+    String input = "Wirtschaftswissenschaft";
+    Hyphenation hyphenation = new Hyphenation(new int[]{ 0, 4, 11, 14, 17, 23});
+    HyphenationTree hyphenator = new MockHyphenator(Collections.singletonMap(input, hyphenation));
+    CharArraySet dictionary = makeDictionary("Schaf", "Schaft", "Wir", "Wirt", "Wirtschaft", "Wissen", "Wissenschaft");
+
+    HyphenationCompoundWordTokenFilter tf6 = new HyphenationCompoundWordTokenFilter(whitespaceMockTokenizer(input),
+        hyphenator, dictionary, CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,
+        6, 12,false);
+    assertTokenStreamContents(tf6, new String[] { "Wirtschaftswissenschaft", "Wirtschaft", "schaft", "wissen", "wissenschaft", "schaft"});
+
+    HyphenationCompoundWordTokenFilter tf7 = new HyphenationCompoundWordTokenFilter(whitespaceMockTokenizer(input),
+        hyphenator, dictionary, CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE,
+        7, 12,false);
+    assertTokenStreamContents(tf7, new String[] { "Wirtschaftswissenschaft", "Wirtschaft", "wissenschaft"});
+  }
+
   public void testDumbCompoundWordsSE() throws Exception {
     CharArraySet dict = makeDictionary("Bil", "Dörr", "Motor", "Tak", "Borr", "Slag", "Hammar",
         "Pelar", "Glas", "Ögon", "Fodral", "Bas", "Fiol", "Makare", "Gesäll",
@@ -331,7 +351,22 @@
       }
     }
   }
-  
+
+  // Hyphenator that has prior knowledge of hyphenation points for terms
+  private static class MockHyphenator extends HyphenationTree {
+
+    private final Map<String, Hyphenation> hyphenations;
+
+    MockHyphenator(Map<String, Hyphenation> hyphenations) {
+      this.hyphenations = hyphenations;
+    }
+
+    @Override
+    public Hyphenation hyphenate(char[] w, int offset, int len, int remainCharCount, int pushCharCount) {
+      return hyphenations.get(new String(w, offset, len));
+    }
+  }
+
   // SOLR-2891
   // *CompoundWordTokenFilter blindly adds term length to offset, but this can take things out of bounds
   // wrt original text if a previous filter increases the length of the word (in this case ü -> ue)
