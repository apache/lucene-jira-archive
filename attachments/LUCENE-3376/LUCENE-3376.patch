Index: solr/core/src/java/org/apache/solr/analysis/FSTSynonymFilterFactory.java
===================================================================
--- solr/core/src/java/org/apache/solr/analysis/FSTSynonymFilterFactory.java	(revision 1159839)
+++ solr/core/src/java/org/apache/solr/analysis/FSTSynonymFilterFactory.java	(working copy)
@@ -37,7 +37,7 @@
 import org.apache.lucene.analysis.synonym.SynonymMap;
 import org.apache.lucene.analysis.synonym.SolrSynonymParser;
 import org.apache.lucene.analysis.synonym.WordnetSynonymParser;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 import org.apache.solr.common.ResourceLoader;
 import org.apache.solr.common.SolrException;
Index: modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUTransformFilter.java
===================================================================
--- modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUTransformFilter.java	(revision 1159839)
+++ modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUTransformFilter.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
 
 import com.ibm.icu.text.Transliterator;
Index: modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java
===================================================================
--- modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java	(revision 1159839)
+++ modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java	(working copy)
@@ -22,7 +22,7 @@
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.icu.ICUNormalizer2Filter;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import java.io.IOException;
 import java.io.Reader;
Index: modules/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyAnalyzer.java
===================================================================
--- modules/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyAnalyzer.java	(revision 1159839)
+++ modules/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyAnalyzer.java	(working copy)
@@ -20,7 +20,7 @@
 
 import com.ibm.icu.text.Collator;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.collation.CollationKeyAnalyzer; // javadocs
 import org.apache.lucene.util.IndexableBinaryStringTools; // javadocs
 import org.apache.lucene.util.Version;
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java	(working copy)
@@ -5,7 +5,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 import java.io.IOException;
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java	(working copy)
@@ -8,7 +8,7 @@
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 import java.io.BufferedReader;
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilter.java	(working copy)
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Basic tests for {@link LatvianStemmer}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballVocab.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballVocab.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballVocab.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.LuceneTestCase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilter.java	(working copy)
@@ -28,7 +28,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Simple tests for {@link PortugueseStemFilter}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilter.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilter.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemmer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemmer.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemmer.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Tests {@link IndonesianStemmer}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilter.java	(working copy)
@@ -28,7 +28,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Simple tests for {@link GalicianStemFilter}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Simple tests for {@link EnglishMinimalStemFilter}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemmer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemmer.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemmer.java	(working copy)
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * Tests for {@link KStemmer}
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilter.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 import static org.apache.lucene.analysis.VocabularyAssert.*;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter.java	(working copy)
@@ -33,7 +33,7 @@
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.*;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util._TestUtil;
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java	(working copy)
@@ -27,7 +27,7 @@
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.en.EnglishAnalyzer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.junit.Test;
 
 /**
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestWordnetSynonymParser.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestWordnetSynonymParser.java	(revision 1159839)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestWordnetSynonymParser.java	(working copy)
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 public class TestWordnetSynonymParser extends BaseTokenStreamTestCase {
   Analyzer analyzer;
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java	(working copy)
@@ -107,10 +107,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link ArabicNormalizationFilter},
    *         {@link PersianNormalizationFilter} and Persian Stop words
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java	(working copy)
@@ -107,11 +107,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java	(working copy)
@@ -21,7 +21,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.util.CharTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 /** An {@link Analyzer} that filters {@link LetterTokenizer} 
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.Reader;
 
 import org.apache.lucene.analysis.util.CharTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 /**
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordAnalyzer.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.io.Reader;
 
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 
 /**
  * "Tokenizes" the entire stream as a single token. This is useful
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopAnalyzer.java	(working copy)
@@ -95,10 +95,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link LowerCaseTokenizer} filtered with
    *         {@link StopFilter}
    */
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java	(working copy)
@@ -158,10 +158,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java	(working copy)
@@ -106,10 +106,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link IndicTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link IndicNormalizationFilter},
    *         {@link HindiNormalizationFilter}, {@link KeywordMarkerFilter}
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java	(working copy)
@@ -117,10 +117,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link StandardFilter}, {@link StopFilter}
    *         , and {@link BrazilianStemFilter}.
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(working copy)
@@ -168,10 +168,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link ElisionFilter},
    *         {@link LowerCaseFilter}, {@link StopFilter},
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(working copy)
@@ -29,7 +29,7 @@
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
 
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java	(working copy)
@@ -27,7 +27,7 @@
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 /**
@@ -45,10 +45,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link ThaiWordFilter}, and
    *         {@link StopFilter}
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java	(working copy)
@@ -105,11 +105,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java	(working copy)
@@ -110,11 +110,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java	(working copy)
@@ -104,11 +104,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.analysis.standard.*;
 import org.apache.lucene.analysis.tr.TurkishLowerCaseFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 import java.io.Reader;
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java	(working copy)
@@ -105,11 +105,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java	(working copy)
@@ -109,11 +109,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link TurkishLowerCaseFilter},
    *         {@link StopFilter}, {@link KeywordMarkerFilter} if a stem
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java	(working copy)
@@ -139,10 +139,10 @@
    
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java	(working copy)
@@ -106,10 +106,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter},
    *         {@link StopFilter}, {@link KeywordMarkerFilter}
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.Reader;
 
 import org.apache.lucene.analysis.standard.StandardAnalyzer; // javadoc @link
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.Tokenizer;
 
@@ -35,10 +35,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link ChineseTokenizer} filtered with
    *         {@link ChineseFilter}
    */
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java	(working copy)
@@ -101,10 +101,10 @@
   
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link GreekLowerCaseFilter}, {@link StandardFilter},
    *         {@link StopFilter}, and {@link GreekStemFilter}
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java	(working copy)
@@ -104,11 +104,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java	(working copy)
@@ -126,10 +126,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link StopFilter},
    *         {@link ArabicNormalizationFilter}, {@link KeywordMarkerFilter}
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java	(working copy)
@@ -89,11 +89,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java	(working copy)
@@ -106,11 +106,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java	(working copy)
@@ -105,11 +105,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(working copy)
@@ -123,11 +123,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link ElisionFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
@@ -122,10 +122,10 @@
 
   /**
    * Creates
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
    * 
-   * @return {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , and {@link CzechStemFilter} (only if version is >= LUCENE_31). If
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/util/StopwordAnalyzerBase.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/util/StopwordAnalyzerBase.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/util/StopwordAnalyzerBase.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.IOException;
 import java.util.Set;
 
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
 
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/util/ReusableAnalyzerBase.java (deleted)
===================================================================
Index: modules/analysis/common/src/java/org/apache/lucene/collation/CollationKeyAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/collation/CollationKeyAnalyzer.java	(revision 1159839)
+++ modules/analysis/common/src/java/org/apache/lucene/collation/CollationKeyAnalyzer.java	(working copy)
@@ -19,7 +19,7 @@
 
 
 import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.IndexableBinaryStringTools; // javadoc @link
 import org.apache.lucene.util.Version;
 
Index: modules/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java
===================================================================
--- modules/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java	(revision 1159839)
+++ modules/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 import morfologik.stemming.PolishStemmer.DICTIONARY;
@@ -62,14 +62,14 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @param field ignored field name
    * @param reader source of tokens
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter} and {@link MorfologikFilter}.
    */
Index: modules/analysis/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java
===================================================================
--- modules/analysis/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java	(revision 1159839)
+++ modules/analysis/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java	(working copy)
@@ -121,11 +121,11 @@
 
   /**
    * Creates a
-   * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   * {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    * which tokenizes all the text in the provided {@link Reader}.
    * 
    * @return A
-   *         {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
+   *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1159839)
+++ lucene/CHANGES.txt	(working copy)
@@ -479,6 +479,9 @@
 
 * LUCENE-3354: FieldCache can cache DocTermOrds. (Martijn van Groningen)
 
+* LUCENE-3376: ReusableAnalyzerBase has been moved from modules/analysis/common
+  into lucene/src/java/org/apache/lucene/analysis (Chris Male)
+
 Optimizations
 
 * LUCENE-2588: Don't store unnecessary suffixes when writing the terms
Index: lucene/src/java/org/apache/lucene/analysis/ReusableAnalyzerBase.java
===================================================================
--- lucene/src/java/org/apache/lucene/analysis/ReusableAnalyzerBase.java	(revision 1159839)
+++ lucene/src/java/org/apache/lucene/analysis/ReusableAnalyzerBase.java	(working copy)
@@ -1,4 +1,6 @@
-/**
+package org.apache.lucene.analysis;
+
+/*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
@@ -15,25 +17,16 @@
  * limitations under the License.
  */
 
-package org.apache.lucene.analysis.util;
-
 import java.io.IOException;
 import java.io.Reader;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper; // javadocs
-
 /**
  * An convenience subclass of Analyzer that makes it easy to implement
  * {@link TokenStream} reuse.
  * <p>
  * ReusableAnalyzerBase is a simplification of Analyzer that supports easy reuse
  * for the most common use-cases. Analyzers such as
- * {@link PerFieldAnalyzerWrapper} that behave differently depending upon the
+ * PerFieldAnalyzerWrapper that behave differently depending upon the
  * field name need to subclass Analyzer directly instead.
  * </p>
  * <p>
