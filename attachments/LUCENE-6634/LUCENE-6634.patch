Index: lucene/misc/src/java/org/apache/lucene/index/PKIndexSplitter.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/index/PKIndexSplitter.java	(revision 1688225)
+++ lucene/misc/src/java/org/apache/lucene/index/PKIndexSplitter.java	(working copy)
@@ -21,11 +21,12 @@
 import java.util.List;
 
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.TermRangeQuery;
+import org.apache.lucene.search.Weight;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.Bits;
@@ -33,11 +34,11 @@
 import org.apache.lucene.util.IOUtils;
 
 /**
- * Split an index based on a {@link Filter}.
+ * Split an index based on a {@link Query}.
  */
 
 public class PKIndexSplitter {
-  private final Filter docsInFirstIndex;
+  private final Query docsInFirstIndex;
   private final Directory input;
   private final Directory dir1;
   private final Directory dir2;
@@ -45,10 +46,10 @@
   private final IndexWriterConfig config2;
   
   /**
-   * Split an index based on a {@link Filter}. All documents that match the filter
+   * Split an index based on a {@link Query}. All documents that match the query
    * are sent to dir1, remaining ones to dir2.
    */
-  public PKIndexSplitter(Directory input, Directory dir1, Directory dir2, Filter docsInFirstIndex) {
+  public PKIndexSplitter(Directory input, Directory dir1, Directory dir2, Query docsInFirstIndex) {
     this(input, dir1, dir2, docsInFirstIndex, newDefaultConfig(), newDefaultConfig());
   }
   
@@ -57,7 +58,7 @@
   }
   
   public PKIndexSplitter(Directory input, Directory dir1, 
-      Directory dir2, Filter docsInFirstIndex, IndexWriterConfig config1, IndexWriterConfig config2) {
+      Directory dir2, Query docsInFirstIndex, IndexWriterConfig config1, IndexWriterConfig config2) {
     this.input = input;
     this.dir1 = dir1;
     this.dir2 = dir2;
@@ -79,7 +80,7 @@
   public PKIndexSplitter(Directory input, Directory dir1, 
       Directory dir2, Term midTerm, IndexWriterConfig config1, IndexWriterConfig config2) {
     this(input, dir1, dir2,
-        new QueryWrapperFilter(new TermRangeQuery(midTerm.field(), null, midTerm.bytes(), true, false)), config1, config2);
+        new TermRangeQuery(midTerm.field(), null, midTerm.bytes(), true, false), config1, config2);
   }
   
   public void split() throws IOException {
@@ -99,15 +100,19 @@
     }
   }
   
-  private void createIndex(IndexWriterConfig config, Directory target, DirectoryReader reader, Filter preserveFilter, boolean negateFilter) throws IOException {
+  private void createIndex(IndexWriterConfig config, Directory target, DirectoryReader reader, Query preserveFilter, boolean negateFilter) throws IOException {
     boolean success = false;
     final IndexWriter w = new IndexWriter(target, config);
     try {
+      final IndexSearcher searcher = new IndexSearcher(reader);
+      searcher.setQueryCache(null);
+      final boolean needsScores = false; // scores are not needed, only matching docs
+      final Weight preserveWeight = searcher.createNormalizedWeight(preserveFilter, needsScores);
       final List<LeafReaderContext> leaves = reader.leaves();
       final CodecReader[] subReaders = new CodecReader[leaves.size()];
       int i = 0;
       for (final LeafReaderContext ctx : leaves) {
-        subReaders[i++] = new DocumentFilteredLeafIndexReader(ctx, preserveFilter, negateFilter);
+        subReaders[i++] = new DocumentFilteredLeafIndexReader(ctx, preserveWeight, negateFilter);
       }
       w.addIndexes(subReaders);
       success = true;
@@ -124,18 +129,15 @@
     final Bits liveDocs;
     final int numDocs;
     
-    public DocumentFilteredLeafIndexReader(LeafReaderContext context, Filter preserveFilter, boolean negateFilter) throws IOException {
+    public DocumentFilteredLeafIndexReader(LeafReaderContext context, Weight preserveWeight, boolean negateFilter) throws IOException {
       // our cast is ok, since we open the Directory.
       super((CodecReader) context.reader());
       final int maxDoc = in.maxDoc();
       final FixedBitSet bits = new FixedBitSet(maxDoc);
       // ignore livedocs here, as we filter them later:
-      final DocIdSet docs = preserveFilter.getDocIdSet(context, null);
-      if (docs != null) {
-        final DocIdSetIterator it = docs.iterator();
-        if (it != null) {
-          bits.or(it);
-        }
+      final DocIdSetIterator preserveIt = preserveWeight.scorer(context);
+      if (preserveIt != null) {
+        bits.or(preserveIt);
       }
       if (negateFilter) {
         bits.flip(0, maxDoc);
@@ -145,7 +147,7 @@
         final Bits oldLiveDocs = in.getLiveDocs();
         assert oldLiveDocs != null;
         final DocIdSetIterator it = new BitSetIterator(bits, 0L); // the cost is not useful here
-        for (int i = it.nextDoc(); i < maxDoc; i = it.nextDoc()) {
+        for (int i = it.nextDoc(); i != DocIdSetIterator.NO_MORE_DOCS; i = it.nextDoc()) {
           if (!oldLiveDocs.get(i)) {
             // we can safely modify the current bit, as the iterator already stepped over it:
             bits.clear(i);
@@ -152,7 +154,7 @@
           }
         }
       }
-      
+
       this.liveDocs = bits;
       this.numDocs = bits.cardinality();
     }
