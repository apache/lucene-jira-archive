diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
index 4dea7ab..71de3a8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
@@ -25,10 +25,12 @@ import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Arabic. 
@@ -130,7 +132,12 @@ public final class ArabicAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new LowerCaseFilter(source);
     // the order here is important: the stopword list is not normalized!
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
index 76e6ca0..192ca44 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
@@ -28,8 +28,10 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Bulgarian.
@@ -118,7 +120,12 @@ public final class BulgarianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   public TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
index 3c4decb..6742631 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Brazilian Portuguese language. 
@@ -119,7 +121,12 @@ public final class BrazilianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new LowerCaseFilter(source);
     result = new StandardFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
index 61ca46b..4797284 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
@@ -30,9 +30,11 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.CatalanStemmer;
 
 /**
@@ -120,7 +122,12 @@ public final class CatalanAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
index dda8e93..12a7445 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
@@ -25,8 +25,10 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * An {@link Analyzer} that tokenizes text with {@link StandardTokenizer},
@@ -85,7 +87,12 @@ public final class CJKAnalyzer extends StopwordAnalyzerBase {
 
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     // run the widthfilter first before bigramming, it sometimes combines characters.
     TokenStream result = new CJKWidthFilter(source);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ckb/SoraniAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ckb/SoraniAnalyzer.java
index edee99c..107478c 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ckb/SoraniAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ckb/SoraniAnalyzer.java
@@ -29,10 +29,12 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Sorani Kurdish.
@@ -114,7 +116,12 @@ public final class SoraniAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new SoraniNormalizationFilter(result);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
index e8f49ef..59f0250 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -25,10 +25,12 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 import java.io.*;
 import java.nio.charset.StandardCharsets;
@@ -116,7 +118,12 @@ public final class CzechAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
index 7f2720a..63c0696 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.DanishStemmer;
 
 /**
@@ -115,7 +117,12 @@ public final class DanishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
index f2d29b4..09d9ab5 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
@@ -32,10 +32,12 @@ import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for German language. 
@@ -130,7 +132,12 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
index c80c272..46b49d3 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
@@ -26,8 +26,10 @@ import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for the Greek language. 
@@ -97,7 +99,12 @@ public final class GreekAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new GreekLowerCaseFilter(source);
     result = new StandardFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
index 15bfb51..b654b26 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
@@ -28,8 +28,10 @@ import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for English.
@@ -97,7 +99,12 @@ public final class EnglishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new EnglishPossessiveFilter(result);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
index 3c2812b..f82a2d1 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Spanish.
@@ -114,7 +116,12 @@ public final class SpanishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java
index 4222e5a..64086f8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/eu/BasqueAnalyzer.java
@@ -29,8 +29,10 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.BasqueStemmer;
 
 /**
@@ -112,7 +114,12 @@ public final class BasqueAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
index df9c2fb..75bb52e 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -27,8 +27,10 @@ import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Persian.
@@ -112,7 +114,12 @@ public final class PersianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new LowerCaseFilter(source);
     result = new ArabicNormalizationFilter(result);
     /* additional persian-specific normalization */
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
index 84a3c4f..aa43adf 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.FinnishStemmer;
 
 /**
@@ -115,7 +117,12 @@ public final class FinnishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
index f0acba3..7e0570f 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
@@ -27,11 +27,13 @@ import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -134,7 +136,12 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java
index 00413d5..d6ea46e 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java
@@ -29,9 +29,11 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.IrishStemmer;
 
 /**
@@ -130,7 +132,12 @@ public final class IrishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new StopFilter(result, HYPHENATIONS);
     result = new ElisionFilter(result, DEFAULT_ARTICLES);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
index b79245b..9d44ce8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
@@ -29,10 +29,12 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Galician.
@@ -113,7 +115,12 @@ public final class GalicianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
index 4ee31f1..cbf15ec 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.Reader;
 
 import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -29,6 +30,7 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.in.IndicNormalizationFilter;
+import org.apache.lucene.util.Version;
 
 /**
  * Analyzer for Hindi.
@@ -113,7 +115,12 @@ public final class HindiAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new LowerCaseFilter(source);
     if (!stemExclusionSet.isEmpty())
       result = new SetKeywordMarkerFilter(result, stemExclusionSet);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
index 8784e3b..0d85a98 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.HungarianStemmer;
 
 /**
@@ -115,7 +117,12 @@ public final class HungarianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java
index ae22c47..453f355 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/hy/ArmenianAnalyzer.java
@@ -29,8 +29,10 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.ArmenianStemmer;
 
 /**
@@ -112,7 +114,12 @@ public final class ArmenianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java
index d54b360..12056fb 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianAnalyzer.java
@@ -27,8 +27,10 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 
 /**
  * Analyzer for Indonesian (Bahasa)
@@ -110,7 +112,12 @@ public final class IndonesianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
index afae44d..b29343d 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
@@ -31,11 +31,13 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Italian.
@@ -123,7 +125,12 @@ public final class ItalianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
index 0d85842..ba26e46 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
@@ -29,10 +29,12 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Latvian.
@@ -113,7 +115,12 @@ public final class LatvianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
index a9b5409..2d200fc 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
@@ -28,12 +28,14 @@ import org.apache.lucene.analysis.miscellaneous.StemmerOverrideFilter;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArrayMap;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -149,7 +151,12 @@ public final class DutchAnalyzer extends Analyzer {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stoptable);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
index 0dd8125..8ab9eaf 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.NorwegianStemmer;
 
 /**
@@ -115,7 +117,12 @@ public final class NorwegianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
index fde61d6..5d3d20f 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Portuguese.
@@ -114,7 +116,12 @@ public final class PortugueseAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java
index cca18c6..0da57b8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java
@@ -29,8 +29,10 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.RomanianStemmer;
 
 /**
@@ -117,7 +119,12 @@ public final class RomanianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
index 7dd1406..13d704e 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
@@ -25,6 +25,7 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
@@ -34,6 +35,7 @@ import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Russian language. 
@@ -112,7 +114,12 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase {
    */
     @Override
     protected TokenStreamComponents createComponents(String fieldName) {
-      final Tokenizer source = new StandardTokenizer();
+      final Tokenizer source;
+      if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+        source = new StandardTokenizer();
+      } else {
+        source = new StandardTokenizer40();
+      }
       TokenStream result = new StandardFilter(source);
       result = new LowerCaseFilter(result);
       result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index db9c471..62355e9 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -18,12 +18,15 @@ package org.apache.lucene.analysis.standard;
  */
 
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopAnalyzer;
 import org.apache.lucene.analysis.core.StopFilter;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -82,15 +85,28 @@ public final class StandardAnalyzer extends StopwordAnalyzerBase {
 
   @Override
   protected TokenStreamComponents createComponents(final String fieldName) {
-    final StandardTokenizer src = new StandardTokenizer();
-    src.setMaxTokenLength(maxTokenLength);
+    final Tokenizer src;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      StandardTokenizer t = new StandardTokenizer();
+      t.setMaxTokenLength(maxTokenLength);
+      src = t;
+    } else {
+      StandardTokenizer40 t = new StandardTokenizer40();
+      t.setMaxTokenLength(maxTokenLength);
+      src = t;
+    }
     TokenStream tok = new StandardFilter(src);
     tok = new LowerCaseFilter(tok);
     tok = new StopFilter(tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
       protected void setReader(final Reader reader) throws IOException {
-        src.setMaxTokenLength(StandardAnalyzer.this.maxTokenLength);
+        int m = StandardAnalyzer.this.maxTokenLength;
+        if (src instanceof StandardTokenizer) {
+          ((StandardTokenizer)src).setMaxTokenLength(m);
+        } else {
+          ((StandardTokenizer40)src).setMaxTokenLength(m);
+        }
         super.setReader(reader);
       }
     };
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
index 87709aa..1f03a5a 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
@@ -17,8 +17,11 @@ package org.apache.lucene.analysis.standard;
  * limitations under the License.
  */
 
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.lucene.util.AttributeFactory;
+import org.apache.lucene.util.Version;
 
 import java.util.Map;
 
@@ -44,9 +47,15 @@ public class StandardTokenizerFactory extends TokenizerFactory {
   }
 
   @Override
-  public StandardTokenizer create(AttributeFactory factory) {
-    StandardTokenizer tokenizer = new StandardTokenizer(factory);
-    tokenizer.setMaxTokenLength(maxTokenLength);
-    return tokenizer;
+  public Tokenizer create(AttributeFactory factory) {
+    if (luceneMatchVersion.onOrAfter(Version.LUCENE_4_7_0)) {
+      StandardTokenizer tokenizer = new StandardTokenizer(factory);
+      tokenizer.setMaxTokenLength(maxTokenLength);
+      return tokenizer;
+    } else {
+      StandardTokenizer40 tokenizer40 = new StandardTokenizer40(factory);
+      tokenizer40.setMaxTokenLength(maxTokenLength);
+      return tokenizer40;
+    }
   }
 }
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/std40/StandardTokenizer40.java lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/std40/StandardTokenizer40.java
new file mode 100644
index 0000000..60c0ad5
--- /dev/null
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/std40/StandardTokenizer40.java
@@ -0,0 +1,191 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.standard.std40;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.analysis.standard.StandardTokenizerInterface;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.AttributeFactory;
+
+/** Backcompat standard tokenizer for Lucene 4.0-4.6. This supports Unicode 6.1.
+ * 
+ * @deprecated Use {@link org.apache.lucene.analysis.standard.StandardTokenizer}
+ */
+@Deprecated
+public final class StandardTokenizer40 extends Tokenizer {
+  /** A private instance of the JFlex-constructed scanner */
+  private StandardTokenizerInterface scanner;
+
+  public static final int ALPHANUM          = 0;
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int APOSTROPHE        = 1;
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int ACRONYM           = 2;
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int COMPANY           = 3;
+  public static final int EMAIL             = 4;
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int HOST              = 5;
+  public static final int NUM               = 6;
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int CJ                = 7;
+
+  /** @deprecated (3.1) */
+  @Deprecated
+  public static final int ACRONYM_DEP       = 8;
+
+  public static final int SOUTHEAST_ASIAN = 9;
+  public static final int IDEOGRAPHIC = 10;
+  public static final int HIRAGANA = 11;
+  public static final int KATAKANA = 12;
+  public static final int HANGUL = 13;
+  
+  /** String token types that correspond to token type int constants */
+  public static final String [] TOKEN_TYPES = new String [] {
+    "<ALPHANUM>",
+    "<APOSTROPHE>",
+    "<ACRONYM>",
+    "<COMPANY>",
+    "<EMAIL>",
+    "<HOST>",
+    "<NUM>",
+    "<CJ>",
+    "<ACRONYM_DEP>",
+    "<SOUTHEAST_ASIAN>",
+    "<IDEOGRAPHIC>",
+    "<HIRAGANA>",
+    "<KATAKANA>",
+    "<HANGUL>"
+  };
+  
+  private int skippedPositions;
+
+  private int maxTokenLength = StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH;
+
+  /** Set the max allowed token length.  Any token longer
+   *  than this is skipped. */
+  public void setMaxTokenLength(int length) {
+    this.maxTokenLength = length;
+  }
+
+  /** @see #setMaxTokenLength */
+  public int getMaxTokenLength() {
+    return maxTokenLength;
+  }
+
+  /**
+   * Creates a new instance of the {@link org.apache.lucene.analysis.standard.std40.StandardTokenizer40}.
+   *
+   * See http://issues.apache.org/jira/browse/LUCENE-1068
+   */
+  public StandardTokenizer40() {
+    init();
+  }
+
+  /**
+   * Creates a new StandardTokenizer40 with a given {@link org.apache.lucene.util.AttributeFactory} 
+   */
+  public StandardTokenizer40(AttributeFactory factory) {
+    super(factory);
+    init();
+  }
+
+  private final void init() {
+    this.scanner = new StandardTokenizerImpl40(input);
+  }
+
+  // this tokenizer generates three attributes:
+  // term offset, positionIncrement and type
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+  private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+
+  /*
+   * (non-Javadoc)
+   *
+   * @see org.apache.lucene.analysis.TokenStream#next()
+   */
+  @Override
+  public final boolean incrementToken() throws IOException {
+    clearAttributes();
+    skippedPositions = 0;
+
+    while(true) {
+      int tokenType = scanner.getNextToken();
+
+      if (tokenType == StandardTokenizerInterface.YYEOF) {
+        return false;
+      }
+
+      if (scanner.yylength() <= maxTokenLength) {
+        posIncrAtt.setPositionIncrement(skippedPositions+1);
+        scanner.getText(termAtt);
+        final int start = scanner.yychar();
+        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));
+        // This 'if' should be removed in the next release. For now, it converts
+        // invalid acronyms to HOST. When removed, only the 'else' part should
+        // remain.
+        if (tokenType == StandardTokenizer40.ACRONYM_DEP) {
+          typeAtt.setType(StandardTokenizer40.TOKEN_TYPES[StandardTokenizer40.HOST]);
+          termAtt.setLength(termAtt.length() - 1); // remove extra '.'
+        } else {
+          typeAtt.setType(StandardTokenizer40.TOKEN_TYPES[tokenType]);
+        }
+        return true;
+      } else
+        // When we skip a too-long term, we still increment the
+        // position increment
+        skippedPositions++;
+    }
+  }
+  
+  @Override
+  public final void end() throws IOException {
+    super.end();
+    // set final offset
+    int finalOffset = correctOffset(scanner.yychar() + scanner.yylength());
+    offsetAtt.setOffset(finalOffset, finalOffset);
+    // adjust any skipped tokens
+    posIncrAtt.setPositionIncrement(posIncrAtt.getPositionIncrement()+skippedPositions);
+  }
+
+  @Override
+  public void close() throws IOException {
+    super.close();
+    scanner.yyreset(input);
+  }
+
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    scanner.yyreset(input);
+    skippedPositions = 0;
+  }
+}
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
index e47e7f8..aca1772 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
@@ -30,10 +30,12 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.SwedishStemmer;
 
 /**
@@ -115,7 +117,12 @@ public final class SwedishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(result);
     result = new StopFilter(result, stopwords);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
index 2ed72f4..17f3ff8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
@@ -26,6 +26,7 @@ import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
@@ -104,7 +105,12 @@ public final class ThaiAnalyzer extends StopwordAnalyzerBase {
       result = new StopFilter(result, stopwords);
       return new TokenStreamComponents(source, result);
     } else {
-      final Tokenizer source = new StandardTokenizer();
+      final Tokenizer source;
+      if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+        source = new StandardTokenizer();
+      } else {
+        source = new StandardTokenizer40();
+      }
       TokenStream result = new StandardFilter(source);
       result = new LowerCaseFilter(result);
       result = new ThaiWordFilter(result);
diff --git lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java
index d74d3c9..f20bfd8 100644
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java
@@ -28,6 +28,7 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
@@ -117,7 +118,12 @@ public final class TurkishAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName) {
-    final Tokenizer source = new StandardTokenizer();
+    final Tokenizer source;
+    if (getVersion().onOrAfter(Version.LUCENE_4_7_0)) {
+      source = new StandardTokenizer();
+    } else {
+      source = new StandardTokenizer40();
+    }
     TokenStream result = new StandardFilter(source);
     if (getVersion().onOrAfter(Version.LUCENE_4_8_0)) {
       result = new ApostropheFilter(result);
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ar/TestArabicAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ar/TestArabicAnalyzer.java
index 49275c9..53ca2d7 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ar/TestArabicAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ar/TestArabicAnalyzer.java
@@ -21,6 +21,7 @@ import java.io.IOException;
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test the Arabic Analyzer
@@ -98,4 +99,11 @@ public class TestArabicAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new ArabicAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    ArabicAnalyzer a = new ArabicAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianAnalyzer.java
index dd50be2..8fcb1e6 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test the Bulgarian analyzer
@@ -77,4 +78,11 @@ public class TestBulgarianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new BulgarianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    BulgarianAnalyzer a = new BulgarianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianAnalyzer.java
new file mode 100644
index 0000000..0ac381b
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianAnalyzer.java
@@ -0,0 +1,187 @@
+package org.apache.lucene.analysis.br;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.core.LowerCaseTokenizer;
+import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
+
+/**
+ * Test the Brazilian Stem Filter, which only modifies the term text.
+ * 
+ * It is very similar to the snowball portuguese algorithm but not exactly the same.
+ *
+ */
+public class TestBrazilianAnalyzer extends BaseTokenStreamTestCase {
+  
+  public void testWithSnowballExamples() throws Exception {
+   check("boa", "boa");
+   check("boainain", "boainain");
+   check("boas", "boas");
+   check("bôas", "boas"); // removes diacritic: different from snowball portugese
+   check("boassu", "boassu");
+   check("boataria", "boat");
+   check("boate", "boat");
+   check("boates", "boat");
+   check("boatos", "boat");
+   check("bob", "bob");
+   check("boba", "bob");
+   check("bobagem", "bobag");
+   check("bobagens", "bobagens");
+   check("bobalhões", "bobalho"); // removes diacritic: different from snowball portugese
+   check("bobear", "bob");
+   check("bobeira", "bobeir");
+   check("bobinho", "bobinh");
+   check("bobinhos", "bobinh");
+   check("bobo", "bob");
+   check("bobs", "bobs");
+   check("boca", "boc");
+   check("bocadas", "boc");
+   check("bocadinho", "bocadinh");
+   check("bocado", "boc");
+   check("bocaiúva", "bocaiuv"); // removes diacritic: different from snowball portuguese
+   check("boçal", "bocal"); // removes diacritic: different from snowball portuguese
+   check("bocarra", "bocarr");
+   check("bocas", "boc");
+   check("bode", "bod");
+   check("bodoque", "bodoqu");
+   check("body", "body");
+   check("boeing", "boeing");
+   check("boem", "boem");
+   check("boemia", "boem");
+   check("boêmio", "boemi"); // removes diacritic: different from snowball portuguese
+   check("bogotá", "bogot");
+   check("boi", "boi");
+   check("bóia", "boi"); // removes diacritic: different from snowball portuguese
+   check("boiando", "boi");
+   check("quiabo", "quiab");
+   check("quicaram", "quic");
+   check("quickly", "quickly");
+   check("quieto", "quiet");
+   check("quietos", "quiet");
+   check("quilate", "quilat");
+   check("quilates", "quilat");
+   check("quilinhos", "quilinh");
+   check("quilo", "quil");
+   check("quilombo", "quilomb");
+   check("quilométricas", "quilometr"); // removes diacritic: different from snowball portuguese
+   check("quilométricos", "quilometr"); // removes diacritic: different from snowball portuguese
+   check("quilômetro", "quilometr"); // removes diacritic: different from snowball portoguese
+   check("quilômetros", "quilometr"); // removes diacritic: different from snowball portoguese
+   check("quilos", "quil");
+   check("quimica", "quimic");
+   check("quilos", "quil");
+   check("quimica", "quimic");
+   check("quimicas", "quimic");
+   check("quimico", "quimic");
+   check("quimicos", "quimic");
+   check("quimioterapia", "quimioterap");
+   check("quimioterápicos", "quimioterap"); // removes diacritic: different from snowball portoguese
+   check("quimono", "quimon");
+   check("quincas", "quinc");
+   check("quinhão", "quinha"); // removes diacritic: different from snowball portoguese
+   check("quinhentos", "quinhent");
+   check("quinn", "quinn");
+   check("quino", "quin");
+   check("quinta", "quint");
+   check("quintal", "quintal");
+   check("quintana", "quintan");
+   check("quintanilha", "quintanilh");
+   check("quintão", "quinta"); // removes diacritic: different from snowball portoguese
+   check("quintessência", "quintessente"); // versus snowball portuguese 'quintessent'
+   check("quintino", "quintin");
+   check("quinto", "quint");
+   check("quintos", "quint");
+   check("quintuplicou", "quintuplic");
+   check("quinze", "quinz");
+   check("quinzena", "quinzen");
+   check("quiosque", "quiosqu");
+  }
+  
+  public void testNormalization() throws Exception {
+    check("Brasil", "brasil"); // lowercase by default
+    check("Brasília", "brasil"); // remove diacritics
+    check("quimio5terápicos", "quimio5terapicos"); // contains non-letter, diacritic will still be removed
+    check("áá", "áá"); // token is too short: diacritics are not removed
+    check("ááá", "aaa"); // normally, diacritics are removed
+  }
+  
+  public void testReusableTokenStream() throws Exception {
+    Analyzer a = new BrazilianAnalyzer();
+    checkReuse(a, "boa", "boa");
+    checkReuse(a, "boainain", "boainain");
+    checkReuse(a, "boas", "boas");
+    checkReuse(a, "bôas", "boas"); // removes diacritic: different from snowball portugese
+  }
+ 
+  public void testStemExclusionTable() throws Exception {
+    BrazilianAnalyzer a = new BrazilianAnalyzer(
+        CharArraySet.EMPTY_SET, new CharArraySet(asSet("quintessência"), false));
+    checkReuse(a, "quintessência", "quintessência"); // excluded words will be completely unchanged.
+  }
+  
+  public void testWithKeywordAttribute() throws IOException {
+    CharArraySet set = new CharArraySet(1, true);
+    set.add("Brasília");
+    Tokenizer tokenizer = new LowerCaseTokenizer();
+    tokenizer.setReader(new StringReader("Brasília Brasilia"));
+    BrazilianStemFilter filter = new BrazilianStemFilter(new SetKeywordMarkerFilter(tokenizer, set));
+
+    assertTokenStreamContents(filter, new String[] { "brasília", "brasil" });
+  }
+
+  private void check(final String input, final String expected) throws Exception {
+    checkOneTerm(new BrazilianAnalyzer(), input, expected);
+  }
+  
+  private void checkReuse(Analyzer a, String input, String expected) throws Exception {
+    checkOneTerm(a, input, expected);
+  }
+
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), new BrazilianAnalyzer(), 1000*RANDOM_MULTIPLIER);
+  }
+  
+  public void testEmptyTerm() throws IOException {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer tokenizer = new KeywordTokenizer();
+        return new TokenStreamComponents(tokenizer, new BrazilianStemFilter(tokenizer));
+      }
+    };
+    checkOneTerm(a, "", "");
+  }
+
+  public void testBackcompat40() throws IOException {
+    BrazilianAnalyzer a = new BrazilianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
deleted file mode 100644
index 3307fbd..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
+++ /dev/null
@@ -1,179 +0,0 @@
-package org.apache.lucene.analysis.br;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.core.LowerCaseTokenizer;
-import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
-import org.apache.lucene.analysis.util.CharArraySet;
-
-/**
- * Test the Brazilian Stem Filter, which only modifies the term text.
- * 
- * It is very similar to the snowball portuguese algorithm but not exactly the same.
- *
- */
-public class TestBrazilianStemmer extends BaseTokenStreamTestCase {
-  
-  public void testWithSnowballExamples() throws Exception {
-   check("boa", "boa");
-   check("boainain", "boainain");
-   check("boas", "boas");
-   check("bôas", "boas"); // removes diacritic: different from snowball portugese
-   check("boassu", "boassu");
-   check("boataria", "boat");
-   check("boate", "boat");
-   check("boates", "boat");
-   check("boatos", "boat");
-   check("bob", "bob");
-   check("boba", "bob");
-   check("bobagem", "bobag");
-   check("bobagens", "bobagens");
-   check("bobalhões", "bobalho"); // removes diacritic: different from snowball portugese
-   check("bobear", "bob");
-   check("bobeira", "bobeir");
-   check("bobinho", "bobinh");
-   check("bobinhos", "bobinh");
-   check("bobo", "bob");
-   check("bobs", "bobs");
-   check("boca", "boc");
-   check("bocadas", "boc");
-   check("bocadinho", "bocadinh");
-   check("bocado", "boc");
-   check("bocaiúva", "bocaiuv"); // removes diacritic: different from snowball portuguese
-   check("boçal", "bocal"); // removes diacritic: different from snowball portuguese
-   check("bocarra", "bocarr");
-   check("bocas", "boc");
-   check("bode", "bod");
-   check("bodoque", "bodoqu");
-   check("body", "body");
-   check("boeing", "boeing");
-   check("boem", "boem");
-   check("boemia", "boem");
-   check("boêmio", "boemi"); // removes diacritic: different from snowball portuguese
-   check("bogotá", "bogot");
-   check("boi", "boi");
-   check("bóia", "boi"); // removes diacritic: different from snowball portuguese
-   check("boiando", "boi");
-   check("quiabo", "quiab");
-   check("quicaram", "quic");
-   check("quickly", "quickly");
-   check("quieto", "quiet");
-   check("quietos", "quiet");
-   check("quilate", "quilat");
-   check("quilates", "quilat");
-   check("quilinhos", "quilinh");
-   check("quilo", "quil");
-   check("quilombo", "quilomb");
-   check("quilométricas", "quilometr"); // removes diacritic: different from snowball portuguese
-   check("quilométricos", "quilometr"); // removes diacritic: different from snowball portuguese
-   check("quilômetro", "quilometr"); // removes diacritic: different from snowball portoguese
-   check("quilômetros", "quilometr"); // removes diacritic: different from snowball portoguese
-   check("quilos", "quil");
-   check("quimica", "quimic");
-   check("quilos", "quil");
-   check("quimica", "quimic");
-   check("quimicas", "quimic");
-   check("quimico", "quimic");
-   check("quimicos", "quimic");
-   check("quimioterapia", "quimioterap");
-   check("quimioterápicos", "quimioterap"); // removes diacritic: different from snowball portoguese
-   check("quimono", "quimon");
-   check("quincas", "quinc");
-   check("quinhão", "quinha"); // removes diacritic: different from snowball portoguese
-   check("quinhentos", "quinhent");
-   check("quinn", "quinn");
-   check("quino", "quin");
-   check("quinta", "quint");
-   check("quintal", "quintal");
-   check("quintana", "quintan");
-   check("quintanilha", "quintanilh");
-   check("quintão", "quinta"); // removes diacritic: different from snowball portoguese
-   check("quintessência", "quintessente"); // versus snowball portuguese 'quintessent'
-   check("quintino", "quintin");
-   check("quinto", "quint");
-   check("quintos", "quint");
-   check("quintuplicou", "quintuplic");
-   check("quinze", "quinz");
-   check("quinzena", "quinzen");
-   check("quiosque", "quiosqu");
-  }
-  
-  public void testNormalization() throws Exception {
-    check("Brasil", "brasil"); // lowercase by default
-    check("Brasília", "brasil"); // remove diacritics
-    check("quimio5terápicos", "quimio5terapicos"); // contains non-letter, diacritic will still be removed
-    check("áá", "áá"); // token is too short: diacritics are not removed
-    check("ááá", "aaa"); // normally, diacritics are removed
-  }
-  
-  public void testReusableTokenStream() throws Exception {
-    Analyzer a = new BrazilianAnalyzer();
-    checkReuse(a, "boa", "boa");
-    checkReuse(a, "boainain", "boainain");
-    checkReuse(a, "boas", "boas");
-    checkReuse(a, "bôas", "boas"); // removes diacritic: different from snowball portugese
-  }
- 
-  public void testStemExclusionTable() throws Exception {
-    BrazilianAnalyzer a = new BrazilianAnalyzer(
-        CharArraySet.EMPTY_SET, new CharArraySet(asSet("quintessência"), false));
-    checkReuse(a, "quintessência", "quintessência"); // excluded words will be completely unchanged.
-  }
-  
-  public void testWithKeywordAttribute() throws IOException {
-    CharArraySet set = new CharArraySet(1, true);
-    set.add("Brasília");
-    Tokenizer tokenizer = new LowerCaseTokenizer();
-    tokenizer.setReader(new StringReader("Brasília Brasilia"));
-    BrazilianStemFilter filter = new BrazilianStemFilter(new SetKeywordMarkerFilter(tokenizer, set));
-
-    assertTokenStreamContents(filter, new String[] { "brasília", "brasil" });
-  }
-
-  private void check(final String input, final String expected) throws Exception {
-    checkOneTerm(new BrazilianAnalyzer(), input, expected);
-  }
-  
-  private void checkReuse(Analyzer a, String input, String expected) throws Exception {
-    checkOneTerm(a, input, expected);
-  }
-
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), new BrazilianAnalyzer(), 1000*RANDOM_MULTIPLIER);
-  }
-  
-  public void testEmptyTerm() throws IOException {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Tokenizer tokenizer = new KeywordTokenizer();
-        return new TokenStreamComponents(tokenizer, new BrazilianStemFilter(tokenizer));
-      }
-    };
-    checkOneTerm(a, "", "");
-  }
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
index bc14adc..c7d98c0 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestCatalanAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -59,4 +60,11 @@ public class TestCatalanAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new CatalanAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    CatalanAnalyzer a = new CatalanAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
index fc25c54..0acca66 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
@@ -34,6 +34,7 @@ import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Most tests adopted from TestCJKTokenizer
@@ -290,4 +291,11 @@ public class TestCJKAnalyzer extends BaseTokenStreamTestCase {
     };
     checkOneTerm(a, "", "");
   }
+
+  public void testBackcompat40() throws IOException {
+    CJKAnalyzer a = new CJKAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ckb/TestSoraniAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ckb/TestSoraniAnalyzer.java
index 9a2c9d9..85eeec1 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ckb/TestSoraniAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ckb/TestSoraniAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test the Sorani analyzer
@@ -63,4 +64,11 @@ public class TestSoraniAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new SoraniAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    SoraniAnalyzer a = new SoraniAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPage.html lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPage.html
deleted file mode 100644
index cc23b3d..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPage.html
+++ /dev/null
@@ -1,267 +0,0 @@
-<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
-<html>
-<head>
-<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
-<meta name="robots" content="index,nofollow">
-
-<title>Resources - Lucene-java Wiki</title>
-<script type="text/javascript" src="/moin_static184/common/js/common.js"></script>
-
-<script type="text/javascript">
-<!--
-var search_hint = "Search";
-//-->
-</script>
-
-
-<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/moin_static184/modernized/css/common.css">
-<link rel="stylesheet" type="text/css" charset="utf-8" media="screen" href="/moin_static184/modernized/css/screen.css">
-<link rel="stylesheet" type="text/css" charset="utf-8" media="print" href="/moin_static184/modernized/css/print.css">
-<link rel="stylesheet" type="text/css" charset="utf-8" media="projection" href="/moin_static184/modernized/css/projection.css">
-
-<!-- css only for MS IE6/IE7 browsers -->
-<!--[if lt IE 8]>
-   <link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/moin_static184/modernized/css/msie.css">
-<![endif]-->
-
-
-
-
-
-<link rel="Start" href="/lucene-java/FrontPageEN">
-<link rel="Alternate" title="Wiki Markup" href="/lucene-java/Resources?action=raw">
-<link rel="Alternate" media="print" title="Print View" href="/lucene-java/Resources?action=print">
-<link rel="Appendix" title="IntroductionToApacheLucene.jp.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=IntroductionToApacheLucene.jp.jpg">
-<link rel="Appendix" title="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=SuchmaschinenEntwickelnMitApacheLucene.de.jpg">
-<link rel="Appendix" title="building.search.applications.png" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=building.search.applications.png">
-<link rel="Appendix" title="lia3d.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=lia3d.jpg">
-<link rel="Search" href="/lucene-java/FindPage">
-<link rel="Index" href="/lucene-java/TitleIndex">
-<link rel="Glossary" href="/lucene-java/WordIndex">
-<link rel="Help" href="/lucene-java/HelpOnFormatting">
-</head>
-
-<body  lang="en" dir="ltr">
-
-<div id="header">
-
-<form id="searchform" method="get" action="/lucene-java/Resources">
-<div>
-<input type="hidden" name="action" value="fullsearch">
-<input type="hidden" name="context" value="180">
-<label for="searchinput">Search:</label>
-<input id="searchinput" type="text" name="value" value="" size="20"
-    onfocus="searchFocus(this)" onblur="searchBlur(this)"
-    onkeyup="searchChange(this)" onchange="searchChange(this)" alt="Search">
-<input id="titlesearch" name="titlesearch" type="submit"
-    value="Titles" alt="Search Titles">
-<input id="fullsearch" name="fullsearch" type="submit"
-    value="Text" alt="Search Full Text">
-</div>
-</form>
-<script type="text/javascript">
-<!--// Initialize search form
-var f = document.getElementById('searchform');
-f.getElementsByTagName('label')[0].style.display = 'none';
-var e = document.getElementById('searchinput');
-searchChange(e);
-searchBlur(e);
-//-->
-</script>
-
-<div id="logo"><a href="/lucene-java/FrontPageEN">Lucene-java Wiki</a></div>
-<div id="username"><a href="/lucene-java/Resources?action=login" id="login" rel="nofollow">Login</a></div>
-<h1 id="locationline">
-
-<span id="pagelocation"><a class="backlink" href="/lucene-java/Resources?action=fullsearch&amp;context=180&amp;value=linkto%3A%22Resources%22" rel="nofollow" title="Click to do a full-text search for this title">Resources</a></span>
-</h1>
-
-
-<ul id="navibar">
-<li class="wikilink"><a href="/lucene-java/FrontPageEN">FrontPageEN</a></li><li class="wikilink"><a href="/lucene-java/RecentChanges">RecentChanges</a></li><li class="wikilink"><a href="/lucene-java/FindPage">FindPage</a></li><li class="wikilink"><a href="/lucene-java/HelpContents">HelpContents</a></li><li class="current"><a href="/lucene-java/Resources">Resources</a></li>
-</ul>
-
-<div id="pageline"><hr style="display:none;"></div>
-
-<ul class="editbar"><li><span class="disabled">Immutable Page</span></li><li class="toggleCommentsButton" style="display:none;"><a href="#" class="nbcomment" onClick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="/lucene-java/Resources?action=info" rel="nofollow">Info</a></li><li>
-<form class="actionsmenu" method="GET" action="/lucene-java/Resources">
-<div>
-    <label>More Actions:</label>
-    <select name="action"
-        onchange="if ((this.selectedIndex != 0) &&
-                      (this.options[this.selectedIndex].disabled == false)) {
-                this.form.submit();
-            }
-            this.selectedIndex = 0;">
-        <option value="raw">Raw Text</option>
-<option value="print">Print View</option>
-<option value="RenderAsDocbook">Render as Docbook</option>
-<option value="refresh">Delete Cache</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="SpellCheck">Check Spelling</option>
-<option value="LikePages">Like Pages</option>
-<option value="LocalSiteMap">Local Site Map</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="RenamePage" disabled class="disabled">Rename Page</option>
-<option value="CopyPage">Copy Page</option>
-<option value="DeletePage" disabled class="disabled">Delete Page</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="MyPages">My Pages</option>
-<option value="show" disabled class="disabled">Subscribe User</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="show" disabled class="disabled">Remove Spam</option>
-<option value="show" disabled class="disabled">Revert to this revision</option>
-<option value="show" disabled class="disabled">Package Pages</option>
-<option value="SyncPages">Sync Pages</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="Load">Load</option>
-<option value="Save">Save</option>
-    </select>
-    <input type="submit" value="Do">
-    
-</div>
-<script type="text/javascript">
-<!--// Init menu
-actionsMenuInit('More Actions:');
-//-->
-</script>
-</form>
-</li></ul>
-
-</div>
-
-<div id="page" lang="en" dir="ltr">
-<div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
-<span class="anchor" id="line-2"></span><p class="line867"><div class="table-of-contents"><p class="table-of-contents-heading">Contents<ol><li>
-<a href="#Introductions">Introductions</a></li><li>
-<a href="#Blogs">Blogs</a></li><li>
-<a href="#Books">Books</a></li><li>
-<a href="#Articles">Articles</a></li><li>
-<a href="#Interviews">Interviews</a></li><li>
-<a href="#Papers">Papers</a></li><li>
-<a href="#Presentations">Presentations</a></li><li>
-<a href="#Training">Training</a></li><li>
-<a href="#Corpora">Corpora</a></li><li>
-<a href="#Other">Other</a></li></ol></div> <span class="anchor" id="line-3"></span><span class="anchor" id="line-4"></span><p class="line867">
-<h1 id="Introductions">Introductions</h1>
-<span class="anchor" id="line-5"></span><span class="anchor" id="line-6"></span><ul><li><p class="line862">The API documentation contains  <a class="http" href="http://lucene.apache.org/java/3_0_1/api/all/overview-summary.html#overview_description">a short and simple code example</a> that shows the basic way to index and search <span class="anchor" id="line-7"></span></li><li><p class="line862">The <a class="http" href="http://lucene.apache.org/java/3_0_1/gettingstarted.html">Getting Started Guide</a> that describes the demos that come with Lucene <span class="anchor" id="line-8"></span><span class="anchor" id="line-9"></span><span class="anchor" id="line-10"></span></li></ul><p class="line867">
-<h1 id="Blogs">Blogs</h1>
-<span class="anchor" id="line-11"></span><span class="anchor" id="line-12"></span><ul><li><p class="line891"><a class="http" href="http://lucene.grantingersoll.com">Grant's Grunts: Lucene edition</a> - Grant Ingersoll's thoughts on the Lucene ecosystem. <span class="anchor" id="line-13"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/blog/">Lucid Imagination's Blog</a> - Many of the Lucene and Solr committers blog here about how to use Lucene and Solr <span class="anchor" id="line-14"></span></li><li><p class="line891"><a class="http" href="http://blog.sematext.com/">Sematext Blog</a> - Search and Analytics covering Lucene, Solr, Nutch, Hadoop, HBase, and more <span class="anchor" id="line-15"></span><span class="anchor" id="line-16"></span><span class="anchor" id="line-17"></span></li></ul><p class="line867">
-<h1 id="Books">Books</h1>
-<span class="anchor" id="line-18"></span><span class="anchor" id="line-19"></span><ul><li><p class="line891"><img alt="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" class="external_image" src="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" title="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" /> "<a class="http" href="http://www.manning.com/hatcher3/">Lucene in Action, Second Edition"</a> by Erik Hatcher, Otis Gospodneti&#263;, and Michael McCandless <span class="anchor" id="line-20"></span></li><li><p class="line891"><img alt="building.search.applications.png" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=building.search.applications.png" title="building.search.applications.png" /> "<a class="http" href="http://www.amazon.com/Building-Search-Applications-Lucene-Lingpipe/dp/0615204252/">Building Search Applications: Lucene, LingPipe, and Gate</a>" by Manu Konchady; Mustru Publishing; June 2008; ISBN 978-0615204253 <span class="anchor" id="line-21"></span></li><li><p class="line891"><img alt="IntroductionToApacheLucene.jp.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=IntroductionToApacheLucene.jp.jpg" title="IntroductionToApacheLucene.jp.jpg" /> "<a class="http" href="http://www.amazon.co.jp/exec/obidos/ASIN/4774127809/503-9461699-1775907">Apache Lucene 入門 ~Java・オープンソース・全文検索システムの構築</a>" 関口 宏司 ; 技術評論社 ; 2006/05/17 ; ISBN: 4774127809 (<span class="u">Introduction to Apache Lucene: Construction of Java Open Source Full Text Retrieval Systems</span> by Koshi Sekiguti ; Gijutsu-Hyohron Co., Ltd.) <span class="anchor" id="line-22"></span></li><li><p class="line891"><img alt="lia3d.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=lia3d.jpg" title="lia3d.jpg" /> "<a class="http" href="http://www.lucenebook.com">Lucene In Action</a>" by Erik Hatcher, Otis Gospodneti&#263;; Manning Publications; December 2004; ISBN 1932394281 (also available from <a class="http" href="http://www.amazon.com/exec/obidos/ASIN/1932394281">Amazon.com</a>) <span class="anchor" id="line-23"></span></li><li><p class="line891"><img alt="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=SuchmaschinenEntwickelnMitApacheLucene.de.jpg" title="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" /> Manfred Hardt, Dr. Fabian Theis: "<a class="http" href="http://www.amazon.de/Suchmaschinen-entwickeln-mit-Apache-Lucene/dp/3935042450">Suchmaschinen entwickeln mit Apache Lucene</a>"; Software &amp; Support Verlag, Frankfurt/Main, Germany; September 2004; ISBN 3935042450 (<span class="u">Developing Search Engines with Apache Lucene</span>) <span class="anchor" id="line-24"></span><span class="anchor" id="line-25"></span></li></ul><p class="line867">
-<h1 id="Articles">Articles</h1>
-<span class="anchor" id="line-26"></span><span class="anchor" id="line-27"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Getting-Started-with-Lucene/">Getting Started with Lucene</a> (by Grant Ingersoll) <br>
- (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-28"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Optimizing-Findability-in-Lucene-and-Solr/">Optimizing Findability in Lucene and Solr</a> (by  Grant Ingersoll)<br>
- (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-29"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Debugging-Relevance-Issues-in-Search/">Debugging Relevance Issues in Search</a> (by Grant Ingersoll)<br>
- (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-30"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Scaling-Lucene-and-Solr/">Scaling Lucene and Solr</a> (by Mark Miller)<br>
- (<em>Published: January 2009 - article</em>)  <span class="anchor" id="line-31"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Introduction-to-Apache-Lucene-and-Solr/">Introduction to Apache Lucene and Solr</a> (by Marc Krellenstein)<br>
-(<em>Published: January 2009 - article</em>)  <span class="anchor" id="line-32"></span></li><li><p class="line891"><a class="http" href="http://cephas.net/blog/2008/03/30/how-morelikethis-works-in-lucene/">How MoreLikeThis Works in Lucene</a> (by Aaron Johnson)<br>
-(<em>Last updated: March 2008 - blog entry</em>) <span class="anchor" id="line-33"></span></li><li><p class="line891"><a class="http" href="http://schmidt.devlib.org/software/lucene-wikipedia.html">Lucene Wikipedia indexer</a> (by Marco Schmidt)<br>
-(<em>Last updated: November 2007 - tutorial</em>) <span class="anchor" id="line-34"></span></li><li><p class="line891"><a class="http" href="http://marceloochoa.blogspot.com/2007/09/running-lucene-inside-your-oracle-jvm.html">Running Lucene inside your Oracle JVM</a> (by Marcelo Ochoa)<br>
-(<em>Last updated: September 2007 - blog entry</em>) <span class="anchor" id="line-35"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2007/05/24/using-the-lucene-query-parser-without-lucene.html">Using the Lucene Query Parser Without Lucene</a> (by Marcin Maciukiewicz and Daniel Owsiański)<br>
-(<em>Published: May 2007 - article</em>) <span class="anchor" id="line-36"></span></li><li><p class="line891"><a class="http" href="http://www.javaworld.com/javaworld/jw-09-2006/jw-0925-lucene.html">Integrate advanced search functionalities into your apps</a> (by John Ferguson Smart)<br>
-(<em>Published: September 2006 - article</em>) <span class="anchor" id="line-37"></span></li><li><p class="line891"><a class="http" href="http://www-128.ibm.com/developerworks/java/library/wa-lucene2/index.html?ca=drs-">Beef up Web search applications with Lucene</a> (by Deng Peng Zhou)<br>
-(<em>Published: August 2006 - article</em>) <span class="anchor" id="line-38"></span></li><li><p class="line891"><a class="http" href="http://www.freesearch.pe.kr/tag/Lucene">Lecture &amp; Etc : Lucene index file format for Korean</a> (by Jeon Hee-Won)<br>
-(<em>Published: July 2006 - article</em>) <span class="anchor" id="line-39"></span></li><li>Cai Ziegler: "Suche nach Suche -- Apaches Lucene: eigene Suche und Indizierung"; iX 6/2006, Seite 120; Heise Zeitschriften Verlag, Hannover, Germany <span class="anchor" id="line-40"></span></li><li><p class="line891"><a class="http" href="http://www-128.ibm.com/developerworks/java/library/wa-lucene/index.html">Delve inside the Lucene indexing mechanism</a> (by Deng Peng Zhou)<br>
-(<em>Published: June 2006 - article</em>) <span class="anchor" id="line-41"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2006/01/18/using-lucene-to-search-java-source.html">Using Lucene to Search Java Source Code</a> (by Renuka Sindhgatta)<br>
-(<em>Published: January 2006 - article</em>) <span class="anchor" id="line-42"></span></li><li><p class="line891"><a class="http" href="http://www.jroller.com/page/wakaleo/?anchor=lucene_a_tutorial_introduction_to">Lucene : a tutorial introduction to full-text indexing in Java</a> (by John Ferguson Smart)<br>
-(<em>Published: October 2005 - article</em>) <span class="anchor" id="line-43"></span></li><li>Daniel Naber: "Herr der Suche -- Eigene Anwendungen mit Volltextsuche erweitern"; c't 7/2005, Seite 196; Heise Zeitschriften Verlag, Hannover, Germany <span class="anchor" id="line-44"></span></li><li><p class="line891"><a class="http" href="http://blog.dev.sf.net/index.php?/archives/10-Behind-the-Scenes-of-the-SourceForge.net-Search-System.html">Behind the Scenes of the SourceForge.net Search System</a> (by Chris Conrad)<br>
-(<em>Last updated: June 2005 - blog entry</em>) <span class="anchor" id="line-45"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2005/08/09/didyoumean.html">Did You Mean: Lucene?</a> (by Tom White)<br>
-(<em>Published: August 2005 - article</em>) <span class="anchor" id="line-46"></span></li><li><p class="line891"><a class="http" href="http://www.developer.com/java/other/article.php/3490471">Meet Lucene</a> (by Otis Gospodneti&#263;, Eric Hatcher)<br>
-(<em>Published: March 2005 - article</em>) <span class="anchor" id="line-47"></span></li><li><p class="line891"><a class="http" href="http://www.theserverside.com/tt/articles/article.tss?l=ILoveLucene">I Love Lucene</a> (by Dion Almaer)<br>
-(<em>Published: January 2005 - article</em>) <span class="anchor" id="line-48"></span></li><li><p class="line891"><a class="http" href="http://javaboutique.internet.com/tutorials/HTMLParser/article.html">Unweaving a Tangled Web With HTMLParser and Lucene</a> (by Keld H. Hansen)<br>
-(<em>Last updated: October 2004 - tutorial</em>) <span class="anchor" id="line-49"></span></li><li><p class="line891"><a class="http" href="http://bilgidata.com/localhost/bilgidata/yazi.jsp@dosya=a_lucene.xml.html">Lucene Introduction in Turkish</a> Java Bazl&#305; Arama Motoru - Lusin (by Burak Bayraml&#305;)<br>
-(<em>Last updated: August 2004 - tutorial</em>) <span class="anchor" id="line-50"></span></li><li><p class="line891"><a class="http" href="http://www.chedong.com/tech/lucene.html">Lucene Introduction in Chinese</a> Lucene&#65306;&#22522;&#20110;Java&#30340;&#20840;&#25991;&#26816;&#32034;&#24341;&#25806;&#31616;&#20171; (by Che Dong; &#20316;&#32773;&#65306; &#36710;&#19996;)<br>
-(<em>Last updated: May 2004 - tutorial</em>) <span class="anchor" id="line-51"></span></li><li><p class="line891"><a class="http" href="http://javatechniques.com/public/java/docs/basics/lucene-memory-search.html">Lucene In-Memory Text Search</a> (by Philip Isenhour)<br>
-(<em>Last updated: May 2004 - tutorial</em>) <span class="anchor" id="line-52"></span></li><li><p class="line891"><a class="http" href="http://www.javaranch.com/newsletter/200404/Lucene.html">The Lucene Search Engine: Adding Search to Your Applications</a> (by Thomas Paul)<br>
-(<em>Published: April 2004 - article</em>) <span class="anchor" id="line-53"></span></li><li><p class="line891"><a class="http" href="http://www.darksleep.com/lucene/">Lucene Tutorial</a> (by Steven J. Owens)<br>
-(<em>Last updated: March 2004 - tutorial</em>) <span class="anchor" id="line-54"></span></li><li><p class="line891"><a class="http" href="http://www-igm.univ-mlv.fr/~dr/XPOSE2003/lucene/articleLucene.html">Lucene Introduction in French</a> Exposés Système sur le thème de l'opensource : Analyse de la structure de Lucene. (by Sun Seng TAN)<br>
-(<em>Last updated: February 2004 - tutorial</em>) <span class="anchor" id="line-55"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html">QueryParser Rules</a> (by Erik Hatcher)<br>
-(<em>Published November 2003 - article</em>) <span class="anchor" id="line-56"></span></li><li><p class="line891"><a class="http" href="http://builder.com.com/5100-6389-5054799.html">Give your Web site its own search engine using Lucene</a> (by Jeffrey Linwood)<br>
-(<em>Published July 2003 - article</em>) <span class="anchor" id="line-57"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html">Lucene Intro</a> (by Erik Hatcher)<br>
-(<em>Published: July 2003 - article</em>) <span class="anchor" id="line-58"></span></li><li><p class="line891"><a class="http" href="http://www-106.ibm.com/developerworks/library/j-lucene/">Parsing, indexing, and searching XML with Digester and Lucene</a> (by Otis Gospodneti&#263;)<br>
-(<em>Published June 2003 - article</em>) <span class="anchor" id="line-59"></span></li><li><p class="line891"><a class="http" href="http://www.xml.com/pub/a/ws/2003/05/13/email.html">Using Python, Jython, and Lucene to Search Outlook Email</a> (by Jon Udell)<br>
-(<em>Published: May 2003 - article</em>) <span class="anchor" id="line-60"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2003/03/05/lucene.html">Advanced Text Indexing with Lucene</a> (by Otis Gospodneti&#263;)<br>
-(<em>Published: March 2003 - article</em>) <span class="anchor" id="line-61"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2003/01/15/lucene.html">Introduction to Text Indexing with Apache Jakarta Lucene</a> (by Otis Gospodneti&#263;)<br>
-(<em>Published: January 2003 - article</em>) <span class="anchor" id="line-62"></span></li><li><p class="line862">Manfred Hardt: "Suchmaschinen entwickeln mit Java und Lucene - Wo war denn noch gleich ... ?"; JavaMagazin 9/2002; Software &amp; Support Verlag, Frankfurt/Main, Germany <span class="anchor" id="line-63"></span></li><li><p class="line891"><a class="http" href="http://javangelist.snipsnap.org/space/Lucene-Mini-Tutorial">Lucene Mini-Tutorial</a> (by funzel)<br>
-(<em>Last updated: April 2002 - tutorial</em>) <span class="anchor" id="line-64"></span></li><li><p class="line891"><a class="http" href="http://www.javaworld.com/javaworld/jw-09-2000/jw-0915-lucene.html">The Lucene search engine Powerful flexible and free</a> (by Brian Goetz)<br>
-(<em>Published September 2000 - article</em>) <span class="anchor" id="line-65"></span><span class="anchor" id="line-66"></span></li></ul><p class="line867">
-<h1 id="Interviews">Interviews</h1>
-<span class="anchor" id="line-67"></span><span class="anchor" id="line-68"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=109">Interview with Lucene creator Doug Cutting</a> Podcast.  Summary: Doug talks about the creation of Lucene, Nutch and Hadoop. (<em>Published January 2009</em>) <span class="anchor" id="line-69"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=108">Interview with Lucene/Solr committer Chris Hostetter</a> Podcast.  Summary: Chris talks about Solr, Lucene and their usage at CNET. (<em>Published January 2009</em>) <span class="anchor" id="line-70"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=113">Interview with Lucene/Solr committer Ryan McKinley</a> Podcast.  Summary: Ryan discusses Solr, Lucene and geospatial searching with Lucene (<a class="nonexistent" href="/lucene-java/LocalLucene/LocalSolr">LocalLucene/LocalSolr</a>) and his usage of Lucene/Solr throughout his career. (<em>Published January 2009</em>) <span class="anchor" id="line-71"></span><span class="anchor" id="line-72"></span><span class="anchor" id="line-73"></span><span class="anchor" id="line-74"></span></li></ul><p class="line867">
-<h1 id="Papers">Papers</h1>
-<span class="anchor" id="line-75"></span><span class="anchor" id="line-76"></span><ul><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/publications.html">http://lucene.sourceforge.net/publications.html</a> Doug Cuttings papers from the old Lucene web site <span class="anchor" id="line-77"></span><span class="anchor" id="line-78"></span></li></ul><p class="line867">
-<h1 id="Presentations">Presentations</h1>
-<span class="anchor" id="line-79"></span><ul><li><p class="line891"><a class="http" href="http://people.apache.org/~buschmi/apachecon/AdvancedIndexingLuceneAtlanta07.ppt">Advanced Indexing Techniques with Apache Lucene - Payloads</a> presented by Michael Busch at <a class="http" href="http://www.us.apachecon.com/us2007/">ApacheCon U.S. 2007</a><br>
-(<em>Presented November 2007 - PDF slide show</em>) <span class="anchor" id="line-80"></span></li><li><p class="line891"><a class="http" href="http://people.apache.org/~yonik/presentations/lucene_intro.pdf">Full-Text Search with Lucene</a> presented by Yonik Seeley at <a class="http" href="http://www.eu.apachecon.com">ApacheCon Europe 2007</a>.<br>
-(<em>Presented May 2007 - PDF slide show</em>) <span class="anchor" id="line-81"></span></li><li><p class="line891"><a class="http" href="http://www.cnlp.org/presentations/slides/AdvancedLuceneEU.pdf">Advanced Lucene</a> presented by Grant Ingersoll of <a class="http" href="http://www.cnlp.org">CNLP</a> at <a class="http" href="http://www.eu.apachecon.com">ApacheCon Europe 2007</a>.  Covers term vectors, query tips and tricks and Lucene performance tuning related to indexing, searching and document retrieval.<br>
-(<em>Presented May 2007 - PDF slide show</em>) <span class="anchor" id="line-82"></span></li><li><p class="line891"><a class="http" href="http://blogs.atlassian.com/rebelutionary/downloads/tssjs2007-lucene-generic-data-indexing.pdf">Lucene: Generic Data Indexing</a> presented by Mike Cannon-Brookes, CEO, <a class="http" href="http://www.atlassian.com/">Atlassian Software Systems</a> at <a class="http" href="http://javasymposium.techtarget.com/lasvegas/index.html">TSSJS Las Vegas 2007</a>.  Covers how Atlassian use Lucene as a generic indexing framework for indexing and finding arbitrary collections of complex objects.<br>
-(<em>Presented March 2007 - PDF slide show</em>) <span class="anchor" id="line-83"></span></li><li><p class="line891"><a class="http" href="http://www.cnlp.org/apachecon2005/AdvancedLucene.ppt">Advanced Lucene</a> presented by Grant Ingersoll of the <a class="http" href="http://www.cnlp.org">Center for Natural Language Processing</a> at <a class="http" href="http://www.apachecon.com">ApacheCon 2005</a>.  Covers term vectors, span queries, using Lucene in a basic question answering system, and several Lucene case studies from <a class="http" href="http://www.cnlp.org">http://www.cnlp.org</a>.  The accompanying <a class="http" href="http://www.cnlp.org/apachecon2005">CNLP ApacheCon 2005 Information website</a> contains many working examples using term vectors and span queries. <span class="anchor" id="line-84"></span></li><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/talks/pisa/">Lucene lecture at The University of Pisa</a> (by Doug Cutting)<br>
-(<em>Presented November 2004 - lecture notes</em>) <span class="anchor" id="line-85"></span></li><li><p class="line891"><a class="http" href="http://conferences.oreillynet.com/presentations/os2003/hatcher_erik_lucene.pdf">Introducing Lucene</a> (by Erik Hatcher)<br>
-(<em>Presented at OS2003, July 2003 - PDF slide show</em>) <span class="anchor" id="line-86"></span></li><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/talks/inktomi/">The Lucene Search Engine: Inktomi Seminar</a> (by Doug Cutting)<br>
-(<em>Presented June, 2000 - seminar notes</em>) <span class="anchor" id="line-87"></span><span class="anchor" id="line-88"></span></li></ul><p class="line867">
-<h1 id="Training">Training</h1>
-<span class="anchor" id="line-89"></span><span class="anchor" id="line-90"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/How-We-Can-Help/Training/">http://www.lucidimagination.com/How-We-Can-Help/Training/</a> - Training on Lucene created by Lucene committers and contributors (Grant Ingersoll, Erik Hatcher and the rest of the team at Lucid Imagination).   <span class="anchor" id="line-91"></span></li><li><p class="line891"><a class="http" href="http://www.lucenebootcamp.com">Lucene Boot Camp</a> - Training by Lucene committer Grant Ingersoll.  Offered exclusively at <a class="http" href="http://www.apachecon.com">ApacheCon</a>. <span class="anchor" id="line-92"></span><span class="anchor" id="line-93"></span></li></ul><p class="line867">
-<h1 id="Corpora">Corpora</h1>
-<span class="anchor" id="line-94"></span><ul><li><p class="line862">DMOZ RDF dump - <a class="http" href="http://rdf.dmoz.org/">http://rdf.dmoz.org/</a> <span class="anchor" id="line-95"></span></li><li><p class="line862">CMU newsgroups  - <a class="http" href="http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html">http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html</a> <span class="anchor" id="line-96"></span></li><li><p class="line862">CMU webpages  - <a class="http" href="http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/">http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/</a> <span class="anchor" id="line-97"></span></li><li><p class="line862">Reuters  - <a class="http" href="http://www.daviddlewis.com/resources/testcollections/reuters21578">http://www.daviddlewis.com/resources/testcollections/reuters21578</a> <span class="anchor" id="line-98"></span></li><li><p class="line862">Enron emails - <a class="http" href="http://www-2.cs.cmu.edu/~enron/">http://www-2.cs.cmu.edu/~enron/</a> <span class="anchor" id="line-99"></span></li><li><p class="line862">JRC-ACQUIS Multilingual Parallel Corpus - <a class="http" href="http://wt.jrc.it/lt/Acquis/">http://wt.jrc.it/lt/Acquis/</a> <span class="anchor" id="line-100"></span><span class="anchor" id="line-101"></span></li></ul><p class="line867">
-<h1 id="Other">Other</h1>
-<span class="anchor" id="line-102"></span><ul><li><p class="line891"><a class="http" href="http://www.java201.com/resources/browse/38-all.html">Lucene Resources</a> - Articles, Books, FAQs, Forums, Presentations, Wiki. <span class="anchor" id="line-103"></span></li><li><p class="line891"><a class="http" href="http://www.nabble.com/Web-Search-f2787.html">Lucene Search Forum</a> - hosted by <a class="http" href="http://www.nabble.com">Nabble</a> archiving all Lucene and Nutch mailing lists into a searchable archive/forum. The search is coded using Lucene. <span class="anchor" id="line-104"></span></li><li><p class="line891"><a class="http" href="http://www.lucenetutorial.com">LuceneTutorial.com</a> - Tips and tricks, sample applications, code samples, best practices. <span class="anchor" id="line-105"></span></li></ul><span class="anchor" id="bottom"></span></div><p id="pageinfo" class="info" lang="en" dir="ltr">Resources  (last edited 2010-05-03 22:31:43 by <span title="SteveRowe @ ist-h335-d03.syr.edu[128.230.84.100]"><a class="nonexistent" href="/lucene-java/SteveRowe" title="SteveRowe @ ist-h335-d03.syr.edu[128.230.84.100]">SteveRowe</a></span>)</p>
-
-<div id="pagebottom"></div>
-</div>
-
-
-<div id="footer">
-<ul class="editbar"><li><span class="disabled">Immutable Page</span></li><li class="toggleCommentsButton" style="display:none;"><a href="#" class="nbcomment" onClick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="/lucene-java/Resources?action=info" rel="nofollow">Info</a></li><li>
-<form class="actionsmenu" method="GET" action="/lucene-java/Resources">
-<div>
-    <label>More Actions:</label>
-    <select name="action"
-        onchange="if ((this.selectedIndex != 0) &&
-                      (this.options[this.selectedIndex].disabled == false)) {
-                this.form.submit();
-            }
-            this.selectedIndex = 0;">
-        <option value="raw">Raw Text</option>
-<option value="print">Print View</option>
-<option value="RenderAsDocbook">Render as Docbook</option>
-<option value="refresh">Delete Cache</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="SpellCheck">Check Spelling</option>
-<option value="LikePages">Like Pages</option>
-<option value="LocalSiteMap">Local Site Map</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="RenamePage" disabled class="disabled">Rename Page</option>
-<option value="CopyPage">Copy Page</option>
-<option value="DeletePage" disabled class="disabled">Delete Page</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="MyPages">My Pages</option>
-<option value="show" disabled class="disabled">Subscribe User</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="show" disabled class="disabled">Remove Spam</option>
-<option value="show" disabled class="disabled">Revert to this revision</option>
-<option value="show" disabled class="disabled">Package Pages</option>
-<option value="SyncPages">Sync Pages</option>
-<option value="show" disabled class="disabled">------------------------</option>
-<option value="Load">Load</option>
-<option value="Save">Save</option>
-    </select>
-    <input type="submit" value="Do">
-    
-</div>
-<script type="text/javascript">
-<!--// Init menu
-actionsMenuInit('More Actions:');
-//-->
-</script>
-</form>
-</li></ul>
-
-<ul id="credits">
-<li><a href="http://moinmo.in/" title="This site uses the MoinMoin Wiki software.">MoinMoin Powered</a></li><li><a href="http://moinmo.in/Python" title="MoinMoin is written in Python.">Python Powered</a></li><li><a href="http://moinmo.in/GPL" title="MoinMoin is GPL licensed.">GPL licensed</a></li><li><a href="http://validator.w3.org/check?uri=referer" title="Click here to validate this page.">Valid HTML 4.01</a></li>
-</ul>
-
-
-</div>
-</body>
-</html>
-
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPageURLs.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPageURLs.txt
deleted file mode 100644
index e8ca5aa..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/LuceneResourcesWikiPageURLs.txt
+++ /dev/null
@@ -1,105 +0,0 @@
-http://www.w3.org/TR/html4/strict.dtd
-http://lucene.apache.org/java/3_0_1/api/all/overview-summary.html#overview_description
-http://lucene.apache.org/java/3_0_1/gettingstarted.html
-http://lucene.grantingersoll.com
-http://www.lucidimagination.com/blog/
-http://blog.sematext.com/
-http://www.manning.com/hatcher3/hatcher3_cover150.jpg
-http://www.manning.com/hatcher3/hatcher3_cover150.jpg
-http://www.manning.com/hatcher3/hatcher3_cover150.jpg
-http://www.manning.com/hatcher3/
-http://www.amazon.com/Building-Search-Applications-Lucene-Lingpipe/dp/0615204252/
-http://www.amazon.co.jp/exec/obidos/ASIN/4774127809/503-9461699-1775907
-http://www.lucenebook.com
-http://www.amazon.com/exec/obidos/ASIN/1932394281
-Amazon.com
-http://www.amazon.de/Suchmaschinen-entwickeln-mit-Apache-Lucene/dp/3935042450
-http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Getting-Started-with-Lucene/
-http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Optimizing-Findability-in-Lucene-and-Solr/
-http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Debugging-Relevance-Issues-in-Search/
-http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Scaling-Lucene-and-Solr/
-http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Introduction-to-Apache-Lucene-and-Solr/
-http://cephas.net/blog/2008/03/30/how-morelikethis-works-in-lucene/
-http://schmidt.devlib.org/software/lucene-wikipedia.html
-http://marceloochoa.blogspot.com/2007/09/running-lucene-inside-your-oracle-jvm.html
-http://www.onjava.com/pub/a/onjava/2007/05/24/using-the-lucene-query-parser-without-lucene.html
-http://www.javaworld.com/javaworld/jw-09-2006/jw-0925-lucene.html
-http://www-128.ibm.com/developerworks/java/library/wa-lucene2/index.html?ca=drs-
-http://www.freesearch.pe.kr/tag/Lucene
-http://www-128.ibm.com/developerworks/java/library/wa-lucene/index.html
-http://www.onjava.com/pub/a/onjava/2006/01/18/using-lucene-to-search-java-source.html
-http://www.jroller.com/page/wakaleo/?anchor=lucene_a_tutorial_introduction_to
-http://blog.dev.sf.net/index.php?/archives/10-Behind-the-Scenes-of-the-SourceForge.net-Search-System.html
-SourceForge.net
-http://today.java.net/pub/a/today/2005/08/09/didyoumean.html
-http://www.developer.com/java/other/article.php/3490471
-http://www.theserverside.com/tt/articles/article.tss?l=ILoveLucene
-http://javaboutique.internet.com/tutorials/HTMLParser/article.html
-http://bilgidata.com/localhost/bilgidata/yazi.jsp@dosya=a_lucene.xml.html
-http://www.chedong.com/tech/lucene.html
-http://javatechniques.com/public/java/docs/basics/lucene-memory-search.html
-http://www.javaranch.com/newsletter/200404/Lucene.html
-http://www.darksleep.com/lucene/
-http://www-igm.univ-mlv.fr/~dr/XPOSE2003/lucene/articleLucene.html
-http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html
-http://builder.com.com/5100-6389-5054799.html
-http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html
-http://www-106.ibm.com/developerworks/library/j-lucene/
-http://www.xml.com/pub/a/ws/2003/05/13/email.html
-http://www.onjava.com/pub/a/onjava/2003/03/05/lucene.html
-http://www.onjava.com/pub/a/onjava/2003/01/15/lucene.html
-http://javangelist.snipsnap.org/space/Lucene-Mini-Tutorial
-http://www.javaworld.com/javaworld/jw-09-2000/jw-0915-lucene.html
-http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=109
-http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=108
-http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=113
-http://lucene.sourceforge.net/publications.html
-http://lucene.sourceforge.net/publications.html
-http://people.apache.org/~buschmi/apachecon/AdvancedIndexingLuceneAtlanta07.ppt
-http://www.us.apachecon.com/us2007/
-http://people.apache.org/~yonik/presentations/lucene_intro.pdf
-http://www.eu.apachecon.com
-http://www.cnlp.org/presentations/slides/AdvancedLuceneEU.pdf
-http://www.cnlp.org
-http://www.eu.apachecon.com
-http://blogs.atlassian.com/rebelutionary/downloads/tssjs2007-lucene-generic-data-indexing.pdf
-http://www.atlassian.com/
-http://javasymposium.techtarget.com/lasvegas/index.html
-http://www.cnlp.org/apachecon2005/AdvancedLucene.ppt
-http://www.cnlp.org
-http://www.apachecon.com
-http://www.cnlp.org
-http://www.cnlp.org
-http://www.cnlp.org/apachecon2005
-http://lucene.sourceforge.net/talks/pisa/
-http://conferences.oreillynet.com/presentations/os2003/hatcher_erik_lucene.pdf
-http://lucene.sourceforge.net/talks/inktomi/
-http://www.lucidimagination.com/How-We-Can-Help/Training/
-http://www.lucidimagination.com/How-We-Can-Help/Training/
-http://www.lucenebootcamp.com
-http://www.apachecon.com
-http://rdf.dmoz.org/
-http://rdf.dmoz.org/
-http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html
-http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html
-http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/
-http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/
-http://www.daviddlewis.com/resources/testcollections/reuters21578
-http://www.daviddlewis.com/resources/testcollections/reuters21578
-http://www-2.cs.cmu.edu/~enron/
-http://www-2.cs.cmu.edu/~enron/
-http://wt.jrc.it/lt/Acquis/
-http://wt.jrc.it/lt/Acquis/
-http://www.java201.com/resources/browse/38-all.html
-http://www.nabble.com/Web-Search-f2787.html
-http://www.nabble.com
-http://www.lucenetutorial.com
-LuceneTutorial.com
-ist-h335-d03.syr.edu
-128.230.84.100
-ist-h335-d03.syr.edu
-128.230.84.100
-http://moinmo.in/
-http://moinmo.in/Python
-http://moinmo.in/GPL
-http://validator.w3.org/check?uri=referer
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java
deleted file mode 100644
index cbaa021..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStandardAnalyzer.java
+++ /dev/null
@@ -1,377 +0,0 @@
-package org.apache.lucene.analysis.core;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.Arrays;
-import java.util.Random;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockGraphTokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.util.TestUtil;
-
-public class TestStandardAnalyzer extends BaseTokenStreamTestCase {
-
-  // LUCENE-5897: slow tokenization of strings of the form (\p{WB:ExtendNumLet}[\p{WB:Format}\p{WB:Extend}]*)+
-  public void testLargePartiallyMatchingToken() throws Exception {
-    // TODO: get these lists of chars matching a property from ICU4J
-    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
-    char[] WordBreak_ExtendNumLet_chars = "_\u203f\u2040\u2054\ufe33\ufe34\ufe4d\ufe4e\ufe4f\uff3f".toCharArray();
-
-    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
-    int[] WordBreak_Format_chars // only the first char in ranges 
-        = { 0xAD, 0x600, 0x61C, 0x6DD, 0x70F, 0x180E, 0x200E, 0x202A, 0x2060, 0x2066, 0xFEFF,
-            0xFFF9, 0x110BD, 0x1D173, 0xE0001, 0xE0020 };
-
-    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
-    int[] WordBreak_Extend_chars // only the first char in ranges
-        = { 0x300, 0x483, 0x591, 0x5bf, 0x5c1, 0x5c4, 0x5c7, 0x610, 0x64b, 0x670, 0x6d6, 0x6df,
-            0x6e7, 0x6ea, 0x711, 0x730, 0x7a6, 0x7eb, 0x816, 0x81b, 0x825, 0x829, 0x859, 0x8e4,
-            0x900, 0x93a, 0x93e, 0x951, 0x962, 0x981, 0x9bc, 0x9be, 0x9c7, 0x9cb, 0x9d7, 0x9e2,
-            0xa01, 0xa3c, 0xa3e, 0xa47, 0xa4b, 0xa51, 0xa70, 0xa75, 0xa81, 0xabc, 0xabe, 0xac7,
-            0xacb, 0xae2, 0xb01, 0xb3c, 0xb3e, 0xb47, 0xb4b, 0xb56, 0xb62, 0xb82, 0xbbe, 0xbc6,
-            0xbca, 0xbd7, 0xc01, 0xc3e, 0xc46, 0xc4a, 0xc55, 0xc62, 0xc82, 0xcbc, 0xcbe, 0xcc6,
-            0xcca, 0xcd5, 0xce2, 0xd02, 0xd3e, 0xd46, 0xd4a, 0xd57, 0xd62, 0xd82, 0xdca, 0xdcf,
-            0xdd6, 0xdd8, 0xdf2, 0xe31, 0xe34, 0xe47, 0xeb1, 0xeb4, 0xebb, 0xec8, 0xf18, 0xf35,
-            0xf37, 0xf39, 0xf3e, 0xf71, 0xf86, 0xf8d, 0xf99, 0xfc6, 0x102b, 0x1056, 0x105e, 0x1062,
-            0x1067, 0x1071, 0x1082, 0x108f, 0x109a, 0x135d, 0x1712, 0x1732, 0x1752, 0x1772, 0x17b4, 
-            0x17dd, 0x180b, 0x18a9, 0x1920, 0x1930, 0x19b0, 0x19c8, 0x1a17, 0x1a55, 0x1a60, 0x1a7f,
-            0x1b00, 0x1b34, 0x1b6b, 0x1b80, 0x1ba1, 0x1be6, 0x1c24, 0x1cd0, 0x1cd4, 0x1ced, 0x1cf2, 
-            0x1dc0, 0x1dfc, 0x200c, 0x20d0, 0x2cef, 0x2d7f, 0x2de0, 0x302a, 0x3099, 0xa66f, 0xa674,
-            0xa69f, 0xa6f0, 0xa802, 0xa806, 0xa80b, 0xa823, 0xa880, 0xa8b4, 0xa8e0, 0xa926, 0xa947, 
-            0xa980, 0xa9b3, 0xaa29, 0xaa43, 0xaa4c, 0xaa7b, 0xaab0, 0xaab2, 0xaab7, 0xaabe, 0xaac1,
-            0xaaeb, 0xaaf5, 0xabe3, 0xabec, 0xfb1e, 0xfe00, 0xfe20, 0xff9e, 0x101fd, 0x10a01,
-            0x10a05, 0x10a0C, 0x10a38, 0x10a3F, 0x11000, 0x11001, 0x11038, 0x11080, 0x11082,
-            0x110b0, 0x110b3, 0x110b7, 0x110b9, 0x11100, 0x11127, 0x1112c, 0x11180, 0x11182,
-            0x111b3, 0x111b6, 0x111bF, 0x116ab, 0x116ac, 0x116b0, 0x116b6, 0x16f51, 0x16f8f,
-            0x1d165, 0x1d167, 0x1d16d, 0x1d17b, 0x1d185, 0x1d1aa, 0x1d242, 0xe0100 }; 
-        
-    StringBuilder builder = new StringBuilder();
-    int numChars = TestUtil.nextInt(random(), 100 * 1024, 1024 * 1024);
-    for (int i = 0 ; i < numChars ; ) {
-      builder.append(WordBreak_ExtendNumLet_chars[random().nextInt(WordBreak_ExtendNumLet_chars.length)]);
-      ++i;
-      if (random().nextBoolean()) {
-        int numFormatExtendChars = TestUtil.nextInt(random(), 1, 8);
-        for (int j = 0; j < numFormatExtendChars; ++j) {
-          int codepoint;
-          if (random().nextBoolean()) {
-            codepoint = WordBreak_Format_chars[random().nextInt(WordBreak_Format_chars.length)];
-          } else {
-            codepoint = WordBreak_Extend_chars[random().nextInt(WordBreak_Extend_chars.length)];
-          }
-          char[] chars = Character.toChars(codepoint);
-          builder.append(chars);
-          i += chars.length;
-        }
-      }
-    }
-    StandardTokenizer ts = new StandardTokenizer();
-    ts.setReader(new StringReader(builder.toString()));
-    ts.reset();
-    while (ts.incrementToken()) { }
-    ts.end();
-    ts.close();
-
-    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);
-    ts.setMaxTokenLength(newBufferSize); // try a different buffer size
-    ts.setReader(new StringReader(builder.toString()));
-    ts.reset();
-    while (ts.incrementToken()) { }
-    ts.end();
-    ts.close();
-  }
-  
-  public void testHugeDoc() throws IOException {
-    StringBuilder sb = new StringBuilder();
-    char whitespace[] = new char[4094];
-    Arrays.fill(whitespace, ' ');
-    sb.append(whitespace);
-    sb.append("testing 1234");
-    String input = sb.toString();
-    StandardTokenizer tokenizer = new StandardTokenizer();
-    tokenizer.setReader(new StringReader(input));
-    BaseTokenStreamTestCase.assertTokenStreamContents(tokenizer, new String[] { "testing", "1234" });
-  }
-
-  private Analyzer a = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName) {
-
-      Tokenizer tokenizer = new StandardTokenizer(newAttributeFactory());
-      return new TokenStreamComponents(tokenizer);
-    }
-  };
-
-  public void testArmenian() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
-        new String[] { "Վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից", 
-        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "Վիքիպեդիայի", "կայքը" } );
-  }
-  
-  public void testAmharic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
-        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
-  }
-  
-  public void testArabic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
-        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
-        "بالإنجليزية", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "سيتم", "إطلاقه", "في", "2008" } ); 
-  }
-  
-  public void testAramaic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
-        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "Wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
-        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
-  }
-  
-  public void testBengali() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
-        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
-        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
-  }
-  
-  public void testFarsi() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
-        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
-        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
-  }
-  
-  public void testGreek() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
-        new String[] { "Γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
-        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
-  }
-
-  public void testThai() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
-        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
-  }
-  
-  public void testLao() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
-        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
-  }
-  
-  public void testTibetan() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
-                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
-                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
-                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
-  }
-  
-  /*
-   * For chinese, tokenize as char (these can later form bigrams or whatever)
-   */
-  public void testChinese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
-        new String[] { "我", "是", "中", "国", "人", "１２３４", "Ｔｅｓｔｓ"});
-  }
-  
-  public void testEmpty() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
-  }
-  
-  /* test various jira issues this analyzer is related to */
-  
-  public void testLUCENE1545() throws Exception {
-    /*
-     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTRE E.
-     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
-     * Expected result is only on token "moͤchte".
-     */
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
-  }
-  
-  /* Tests from StandardAnalyzer, just to show behavior is similar */
-  public void testAlphanumericSA() throws Exception {
-    // alphanumeric tokens
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"B2B"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2B"});
-  }
-
-  public void testDelimitersSA() throws Exception {
-    // other delimiters: "-", "/", ","
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
-  }
-
-  public void testApostrophesSA() throws Exception {
-    // internal apostrophes: O'Reilly, you're, O'Reilly's
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"O'Reilly"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"Jim's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"O'Reilly's"});
-  }
-
-  public void testNumericSA() throws Exception {
-    // floating point, serial, model numbers, ip addresses, etc.
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"R2D2", "C3PO"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
-  }
-
-  public void testTextWithNumbersSA() throws Exception {
-    // numbers
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"David", "has", "5000", "bones"});
-  }
-
-  public void testVariousTextSA() throws Exception {
-    // various
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"C", "embedded", "developers", "wanted"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "FOO", "BAR"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "FOO", "BAR"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"QUOTED", "word"});
-  }
-
-  public void testKoreanSA() throws Exception {
-    // Korean words
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
-  }
-  
-  public void testOffsets() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"David", "has", "5000", "bones"},
-        new int[] {0, 6, 10, 15},
-        new int[] {5, 9, 14, 20});
-  }
-  
-  public void testTypes() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"David", "has", "5000", "bones"},
-        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
-  }
-  
-  public void testUnicodeWordBreaks() throws Exception {
-    WordBreakTestUnicode_6_3_0 wordBreakTest = new WordBreakTestUnicode_6_3_0();
-    wordBreakTest.test(a);
-  }
-  
-  public void testSupplementary() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
-        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
-  }
-  
-  public void testKorean() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
-        new String[] { "훈민정음" },
-        new String[] { "<HANGUL>" });
-  }
-  
-  public void testJapanese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
-        new String[] { "仮", "名", "遣", "い", "カタカナ" },
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
-  }
-  
-  public void testCombiningMarks() throws Exception {
-    checkOneTerm(a, "ざ", "ざ"); // hiragana
-    checkOneTerm(a, "ザ", "ザ"); // katakana
-    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
-    checkOneTerm(a, "아゙",  "아゙"); // hangul
-  }
-
-  /**
-   * Multiple consecutive chars in \p{WB:MidLetter}, \p{WB:MidNumLet},
-   * and/or \p{MidNum} should trigger a token split.
-   */
-  public void testMid() throws Exception {
-    // ':' is in \p{WB:MidLetter}, which should trigger a split unless there is a Letter char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B", new String[] { "A:B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A::B", new String[] { "A", "B" });
-
-    // '.' is in \p{WB:MidNumLet}, which should trigger a split unless there is a Letter or Numeric char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2", new String[] { "1.2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B", new String[] { "A.B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1..2", new String[] { "1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A..B", new String[] { "A", "B" });
-
-    // ',' is in \p{WB:MidNum}, which should trigger a split unless there is a Numeric char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2", new String[] { "1,2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,,2", new String[] { "1", "2" });
-
-    // Mixed consecutive \p{WB:MidLetter} and \p{WB:MidNumLet} should trigger a split
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.:B", new String[] { "A", "B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:.B", new String[] { "A", "B" });
-
-    // Mixed consecutive \p{WB:MidNum} and \p{WB:MidNumLet} should trigger a split
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,.2", new String[] { "1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.,2", new String[] { "1", "2" });
-
-    // '_' is in \p{WB:ExtendNumLet}
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A:B", new String[] { "A:B_A:B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A::B", new String[] { "A:B_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1.2", new String[] { "1.2_1.2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A.B", new String[] { "A.B_A.B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1..2", new String[] { "1.2_1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A..B", new String[] { "A.B_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,2", new String[] { "1,2_1,2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,,2", new String[] { "1,2_1", "2" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A.:B", new String[] { "C_A", "B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A:.B", new String[] { "C_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1,.2", new String[] { "3_1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1.,2", new String[] { "3_1", "2" });
-  }
-
-
-
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), new StandardAnalyzer(), 1000*RANDOM_MULTIPLIER);
-  }
-  
-  /** blast some random large strings through the analyzer */
-  public void testRandomHugeStrings() throws Exception {
-    Random random = random();
-    checkRandomData(random, new StandardAnalyzer(), 100*RANDOM_MULTIPLIER, 8192);
-  }
-
-  // Adds random graph after:
-  public void testRandomHugeStringsGraphAfter() throws Exception {
-    Random random = random();
-    checkRandomData(random,
-                    new Analyzer() {
-                      @Override
-                      protected TokenStreamComponents createComponents(String fieldName) {
-                        Tokenizer tokenizer = new StandardTokenizer(newAttributeFactory());
-                        TokenStream tokenStream = new MockGraphTokenFilter(random(), tokenizer);
-                        return new TokenStreamComponents(tokenizer, tokenStream);
-                      }
-                    },
-                    100*RANDOM_MULTIPLIER, 8192);
-  }
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailAnalyzer.java
deleted file mode 100644
index b45e1b0..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailAnalyzer.java
+++ /dev/null
@@ -1,348 +0,0 @@
-package org.apache.lucene.analysis.core;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.standard.UAX29URLEmailAnalyzer;
-
-import java.io.IOException;
-import java.util.Arrays;
-
-public class TestUAX29URLEmailAnalyzer extends BaseTokenStreamTestCase {
-
-  private Analyzer a = new UAX29URLEmailAnalyzer();
-
-  public void testHugeDoc() throws IOException {
-    StringBuilder sb = new StringBuilder();
-    char whitespace[] = new char[4094];
-    Arrays.fill(whitespace, ' ');
-    sb.append(whitespace);
-    sb.append("testing 1234");
-    String input = sb.toString();
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, input, new String[]{"testing", "1234"}) ;
-  }
-
-  public void testArmenian() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
-        new String[] { "վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից",
-        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "վիքիպեդիայի", "կայքը" } );
-  }
-  
-  public void testAmharic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
-        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
-  }
-  
-  public void testArabic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
-        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
-        "بالإنجليزية", "truth", "numbers", "wikipedia", "story", "سيتم", "إطلاقه", "في", "2008" } );
-  }
-  
-  public void testAramaic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
-        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
-        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
-  }
-  
-  public void testBengali() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
-        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
-        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
-  }
-  
-  public void testFarsi() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
-        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
-        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
-  }
-  
-  public void testGreek() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
-        new String[] { "γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
-        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
-  }
-
-  public void testThai() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
-        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
-  }
-  
-  public void testLao() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
-        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
-  }
-  
-  public void testTibetan() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
-                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
-                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
-                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
-  }
-  
-  /*
-   * For chinese, tokenize as char (these can later form bigrams or whatever)
-   */
-  public void testChinese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
-        new String[] { "我", "是", "中", "国", "人", "１２３４", "ｔｅｓｔｓ"});
-  }
-  
-  public void testEmpty() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
-  }
-  
-  /* test various jira issues this analyzer is related to */
-  
-  public void testLUCENE1545() throws Exception {
-    /*
-     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTER E.
-     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
-     * Expected result is only one token "moͤchte".
-     */
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
-  }
-  
-  /* Tests from StandardAnalyzer, just to show behavior is similar */
-  public void testAlphanumericSA() throws Exception {
-    // alphanumeric tokens
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"b2b"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2b"});
-  }
-
-  public void testDelimitersSA() throws Exception {
-    // other delimiters: "-", "/", ","
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
-  }
-
-  public void testApostrophesSA() throws Exception {
-    // internal apostrophes: O'Reilly, you're, O'Reilly's
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"o'reilly"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"jim's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"o'reilly's"});
-  }
-
-  public void testNumericSA() throws Exception {
-    // floating point, serial, model numbers, ip addresses, etc.
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"r2d2", "c3po"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
-  }
-
-  public void testTextWithNumbersSA() throws Exception {
-    // numbers
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"david", "has", "5000", "bones"});
-  }
-
-  public void testVariousTextSA() throws Exception {
-    // various
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"c", "embedded", "developers", "wanted"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "foo", "bar"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "foo", "bar"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"quoted", "word"});
-  }
-
-  public void testKoreanSA() throws Exception {
-    // Korean words
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
-  }
-  
-  public void testOffsets() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"david", "has", "5000", "bones"},
-        new int[] {0, 6, 10, 15},
-        new int[] {5, 9, 14, 20});
-  }
-  
-  public void testTypes() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "david has 5000 bones",
-        new String[] {"david", "has", "5000", "bones"},
-        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
-  }
-  
-  public void testSupplementary() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
-        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
-  }
-  
-  public void testKorean() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
-        new String[] { "훈민정음" },
-        new String[] { "<HANGUL>" });
-  }
-  
-  public void testJapanese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
-        new String[] { "仮", "名", "遣", "い", "カタカナ" },
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
-  }
-  
-  public void testCombiningMarks() throws Exception {
-    checkOneTerm(a, "ざ", "ざ"); // hiragana
-    checkOneTerm(a, "ザ", "ザ"); // katakana
-    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
-    checkOneTerm(a, "아゙",  "아゙"); // hangul
-  }
-
-  public void testBasicEmails() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a,
-        "one test@example.com two three [A@example.CO.UK] \"ArakaBanassaMassanaBakarA\" <info@Info.info>",
-        new String[] {"one", "test@example.com", "two", "three", "a@example.co.uk", "arakabanassamassanabakara", "info@info.info",},
-        new String[] { "<ALPHANUM>", "<EMAIL>", "<ALPHANUM>", "<ALPHANUM>", "<EMAIL>", "<ALPHANUM>", "<EMAIL>" });
-  }
-
-  public void testMailtoSchemeEmails () throws Exception {
-    // See LUCENE-3880
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "MAILTO:Test@Example.ORG",
-        new String[] {"mailto", "test@example.org"},
-        new String[] { "<ALPHANUM>", "<EMAIL>" });
-
-    // TODO: Support full mailto: scheme URIs. See RFC 6068: http://tools.ietf.org/html/rfc6068
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a,  "mailto:personA@example.com,personB@example.com?cc=personC@example.com"
-            + "&subject=Subjectivity&body=Corpusivity%20or%20something%20like%20that",
-            new String[] { "mailto",
-                "persona@example.com",
-                // TODO: recognize ',' address delimiter. Also, see examples of ';' delimiter use at: http://www.mailto.co.uk/
-                ",personb@example.com",
-                "?cc=personc@example.com", // TODO: split field keys/values
-                "subject", "subjectivity",
-                "body", "corpusivity", "20or", "20something","20like", "20that" }, // TODO: Hex decoding + re-tokenization
-            new String[] { "<ALPHANUM>",
-                "<EMAIL>",
-                "<EMAIL>",
-                "<EMAIL>",
-                "<ALPHANUM>", "<ALPHANUM>",
-                "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>" });
-  }
-
-  public void testBasicURLs() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a,
-        "a <HTTPs://example.net/omg/isnt/that/NICE?no=its&n%30t#mntl-E>b-D ftp://www.example.com/ABC.txt file:///C:/path/to/a/FILE.txt C",
-        new String[] {"https://example.net/omg/isnt/that/nice?no=its&n%30t#mntl-e", "b", "d", "ftp://www.example.com/abc.txt", "file:///c:/path/to/a/file.txt", "c" },
-        new String[] { "<URL>", "<ALPHANUM>", "<ALPHANUM>", "<URL>", "<URL>", "<ALPHANUM>" });
-  }
-
-  public void testNoSchemeURLs() throws Exception {
-    // ".ph" is a Top Level Domain
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "<index.ph>", new String[]{"index.ph"}, new String[]{"<URL>"});
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index.ph", new String[]{"index.ph"}, new String[]{"<URL>"});
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index.php", new String[]{"index.php"}, new String[]{"<ALPHANUM>"});
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index.phα", new String[]{"index.phα"}, new String[]{"<ALPHANUM>"});
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index-h.php", new String[] { "index",     "h.php" },
-                           new String[] { "<ALPHANUM>","<ALPHANUM>"});
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index2.php", new String[] { "index2",     "php" },
-                          new String[] { "<ALPHANUM>", "<ALPHANUM>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "index2.ph９,", new String[] { "index2",     "ph９" },
-                            new String[] { "<ALPHANUM>", "<ALPHANUM>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com,example.ph,index.php,index2.php,example2.ph",
-            new String[] { "example.com", "example.ph", "index.php",  "index2",     "php",        "example2.ph" },
-            new String[] { "<URL>",       "<URL>",      "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080 example.com/path/here example.com?query=something example.com#fragment",
-            new String[] { "example.com:8080", "example.com/path/here", "example.com?query=something", "example.com#fragment" },
-            new String[] { "<URL>",            "<URL>",                 "<URL>",                       "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080/path/here?query=something#fragment", 
-            new String[] { "example.com:8080/path/here?query=something#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080/path/here?query=something",
-            new String[] { "example.com:8080/path/here?query=something" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080/path/here#fragment",
-            new String[] { "example.com:8080/path/here#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080/path/here",
-            new String[] { "example.com:8080/path/here" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080?query=something#fragment",
-            new String[] { "example.com:8080?query=something#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080?query=something",
-            new String[] { "example.com:8080?query=something" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com:8080#fragment",
-            new String[] { "example.com:8080#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com/path/here?query=something#fragment",
-            new String[] { "example.com/path/here?query=something#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com/path/here?query=something",
-            new String[] { "example.com/path/here?query=something" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com/path/here#fragment",
-            new String[] { "example.com/path/here#fragment" },
-            new String[] { "<URL>" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a, "example.com?query=something#fragment",
-            new String[] { "example.com?query=something#fragment" },
-            new String[] { "<URL>" });
-  }
-
-  
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), new UAX29URLEmailAnalyzer(), 1000*RANDOM_MULTIPLIER);
-  }
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java
deleted file mode 100644
index 2e4c243..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer.java
+++ /dev/null
@@ -1,552 +0,0 @@
-package org.apache.lucene.analysis.core;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.TestUtil;
-
-import java.io.BufferedReader;
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.io.StringReader;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Random;
-import java.util.regex.Pattern;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestUAX29URLEmailTokenizer extends BaseTokenStreamTestCase {
-
-  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')
-  public void testLongEMAILatomText() throws Exception {
-    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\^_`{|}~]
-    char[] emailAtomChars
-        = "!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~".toCharArray();
-    StringBuilder builder = new StringBuilder();
-    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);
-    for (int i = 0 ; i < numChars ; ++i) {
-      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);
-    }
-    int tokenCount = 0;
-    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();
-    String text = builder.toString();
-    ts.setReader(new StringReader(text));
-    ts.reset();
-    while (ts.incrementToken()) {
-      tokenCount++;
-    }
-    ts.end();
-    ts.close();
-    assertTrue(tokenCount > 0);
-
-    tokenCount = 0;
-    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);
-    ts.setMaxTokenLength(newBufferSize);
-    ts.setReader(new StringReader(text));
-    ts.reset();
-    while (ts.incrementToken()) {
-      tokenCount++;
-    }
-    ts.end();
-    ts.close();
-    assertTrue(tokenCount > 0);
-  }
-
-  public void testHugeDoc() throws IOException {
-    StringBuilder sb = new StringBuilder();
-    char whitespace[] = new char[4094];
-    Arrays.fill(whitespace, ' ');
-    sb.append(whitespace);
-    sb.append("testing 1234");
-    String input = sb.toString();
-    UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
-    tokenizer.setReader(new StringReader(input));
-    BaseTokenStreamTestCase.assertTokenStreamContents(tokenizer, new String[] { "testing", "1234" });
-  }
-
-  private Analyzer a = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName) {
-
-      Tokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
-      return new TokenStreamComponents(tokenizer);
-    }
-  };
-
-
-  /** Passes through tokens with type "<URL>" and blocks all other types. */
-  private class URLFilter extends TokenFilter {
-    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
-    public URLFilter(TokenStream in) {
-      super(in);
-    }
-    @Override
-    public final boolean incrementToken() throws java.io.IOException {
-      boolean isTokenAvailable = false;
-      while (input.incrementToken()) {
-        if (typeAtt.type() == UAX29URLEmailTokenizer.TOKEN_TYPES[UAX29URLEmailTokenizer.URL]) {
-          isTokenAvailable = true;
-          break;
-        }
-      }
-      return isTokenAvailable;
-    }
-  }
-  
-  /** Passes through tokens with type "<EMAIL>" and blocks all other types. */
-  private class EmailFilter extends TokenFilter {
-    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
-    public EmailFilter(TokenStream in) {
-      super(in);
-    }
-    @Override
-    public final boolean incrementToken() throws java.io.IOException {
-      boolean isTokenAvailable = false;
-      while (input.incrementToken()) {
-        if (typeAtt.type() == UAX29URLEmailTokenizer.TOKEN_TYPES[UAX29URLEmailTokenizer.EMAIL]) {
-          isTokenAvailable = true;
-          break;
-        }
-      }
-      return isTokenAvailable;
-    }
-  }
-
-  private Analyzer urlAnalyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName) {
-      UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
-      tokenizer.setMaxTokenLength(Integer.MAX_VALUE);  // Tokenize arbitrary length URLs
-      TokenFilter filter = new URLFilter(tokenizer);
-      return new TokenStreamComponents(tokenizer, filter);
-    }
-  };
-
-  private Analyzer emailAnalyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName) {
-      UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
-      TokenFilter filter = new EmailFilter(tokenizer);
-      return new TokenStreamComponents(tokenizer, filter);
-    }
-  };
-  
-  
-  public void testArmenian() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
-        new String[] { "Վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից", 
-        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "Վիքիպեդիայի", "կայքը" } );
-  }
-  
-  public void testAmharic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
-        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
-  }
-  
-  public void testArabic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
-        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
-        "بالإنجليزية", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "سيتم", "إطلاقه", "في", "2008" } ); 
-  }
-  
-  public void testAramaic() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
-        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "Wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
-        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
-  }
-  
-  public void testBengali() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
-        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
-        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
-  }
-  
-  public void testFarsi() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
-        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
-        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
-  }
-  
-  public void testGreek() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
-        new String[] { "Γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
-        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
-  }
-
-  public void testThai() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
-        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
-  }
-  
-  public void testLao() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
-        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
-  }
-  
-  public void testTibetan() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
-                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
-                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
-                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
-  }
-  
-  /*
-   * For chinese, tokenize as char (these can later form bigrams or whatever)
-   */
-  public void testChinese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
-        new String[] { "我", "是", "中", "国", "人", "１２３４", "Ｔｅｓｔｓ"});
-  }
-  
-  public void testEmpty() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
-  }
-  
-  /* test various jira issues this analyzer is related to */
-  
-  public void testLUCENE1545() throws Exception {
-    /*
-     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTRE E.
-     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
-     * Expected result is only on token "moͤchte".
-     */
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
-  }
-  
-  /* Tests from StandardAnalyzer, just to show behavior is similar */
-  public void testAlphanumericSA() throws Exception {
-    // alphanumeric tokens
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"B2B"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2B"});
-  }
-
-  public void testDelimitersSA() throws Exception {
-    // other delimiters: "-", "/", ","
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
-  }
-
-  public void testApostrophesSA() throws Exception {
-    // internal apostrophes: O'Reilly, you're, O'Reilly's
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"O'Reilly"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"Jim's"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"O'Reilly's"});
-  }
-
-  public void testNumericSA() throws Exception {
-    // floating point, serial, model numbers, ip addresses, etc.
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"R2D2", "C3PO"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
-  }
-
-  public void testTextWithNumbersSA() throws Exception {
-    // numbers
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"David", "has", "5000", "bones"});
-  }
-
-  public void testVariousTextSA() throws Exception {
-    // various
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"C", "embedded", "developers", "wanted"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "FOO", "BAR"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "FOO", "BAR"});
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"QUOTED", "word"});
-  }
-
-  public void testKoreanSA() throws Exception {
-    // Korean words
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
-  }
-  
-  public void testOffsets() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"David", "has", "5000", "bones"},
-        new int[] {0, 6, 10, 15},
-        new int[] {5, 9, 14, 20});
-  }
-  
-  public void testTypes() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"David", "has", "5000", "bones"},
-        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
-  }
-  
-  public void testWikiURLs() throws Exception {
-    Reader reader = null;
-    String luceneResourcesWikiPage;
-    try {
-      reader = new InputStreamReader(getClass().getResourceAsStream
-        ("LuceneResourcesWikiPage.html"), StandardCharsets.UTF_8);
-      StringBuilder builder = new StringBuilder();
-      char[] buffer = new char[1024];
-      int numCharsRead;
-      while (-1 != (numCharsRead = reader.read(buffer))) {
-        builder.append(buffer, 0, numCharsRead);
-      }
-      luceneResourcesWikiPage = builder.toString(); 
-    } finally {
-      if (null != reader) {
-        reader.close();
-      }
-    }
-    assertTrue(null != luceneResourcesWikiPage 
-               && luceneResourcesWikiPage.length() > 0);
-    BufferedReader bufferedReader = null;
-    String[] urls;
-    try {
-      List<String> urlList = new ArrayList<>();
-      bufferedReader = new BufferedReader(new InputStreamReader
-        (getClass().getResourceAsStream("LuceneResourcesWikiPageURLs.txt"), StandardCharsets.UTF_8));
-      String line;
-      while (null != (line = bufferedReader.readLine())) {
-        line = line.trim();
-        if (line.length() > 0) {
-          urlList.add(line);
-        }
-      }
-      urls = urlList.toArray(new String[urlList.size()]);
-    } finally {
-      if (null != bufferedReader) {
-        bufferedReader.close();
-      }
-    }
-    assertTrue(null != urls && urls.length > 0);
-    BaseTokenStreamTestCase.assertAnalyzesTo
-      (urlAnalyzer, luceneResourcesWikiPage, urls);
-  }
-  
-  public void testEmails() throws Exception {
-    Reader reader = null;
-    String randomTextWithEmails;
-    try {
-      reader = new InputStreamReader(getClass().getResourceAsStream
-        ("random.text.with.email.addresses.txt"), StandardCharsets.UTF_8);
-      StringBuilder builder = new StringBuilder();
-      char[] buffer = new char[1024];
-      int numCharsRead;
-      while (-1 != (numCharsRead = reader.read(buffer))) {
-        builder.append(buffer, 0, numCharsRead);
-      }
-      randomTextWithEmails = builder.toString(); 
-    } finally {
-      if (null != reader) {
-        reader.close();
-      }
-    }
-    assertTrue(null != randomTextWithEmails 
-               && randomTextWithEmails.length() > 0);
-    BufferedReader bufferedReader = null;
-    String[] emails;
-    try {
-      List<String> emailList = new ArrayList<>();
-      bufferedReader = new BufferedReader(new InputStreamReader
-        (getClass().getResourceAsStream
-          ("email.addresses.from.random.text.with.email.addresses.txt"), StandardCharsets.UTF_8));
-      String line;
-      while (null != (line = bufferedReader.readLine())) {
-        line = line.trim();
-        if (line.length() > 0) {
-          emailList.add(line);
-        }
-      }
-      emails = emailList.toArray(new String[emailList.size()]);
-    } finally {
-      if (null != bufferedReader) {
-        bufferedReader.close();
-      }
-    }
-    assertTrue(null != emails && emails.length > 0);
-    BaseTokenStreamTestCase.assertAnalyzesTo
-      (emailAnalyzer, randomTextWithEmails, emails);
-  }
-
-  public void testMailtoSchemeEmails () throws Exception {
-    // See LUCENE-3880
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "mailto:test@example.org",
-        new String[] {"mailto", "test@example.org"},
-        new String[] { "<ALPHANUM>", "<EMAIL>" });
-
-    // TODO: Support full mailto: scheme URIs. See RFC 6068: http://tools.ietf.org/html/rfc6068
-    BaseTokenStreamTestCase.assertAnalyzesTo
-        (a,  "mailto:personA@example.com,personB@example.com?cc=personC@example.com"
-           + "&subject=Subjectivity&body=Corpusivity%20or%20something%20like%20that",
-         new String[] { "mailto",
-                        "personA@example.com",
-                        // TODO: recognize ',' address delimiter. Also, see examples of ';' delimiter use at: http://www.mailto.co.uk/
-                        ",personB@example.com",
-                        "?cc=personC@example.com", // TODO: split field keys/values
-                        "subject", "Subjectivity",
-                        "body", "Corpusivity", "20or", "20something","20like", "20that" }, // TODO: Hex decoding + re-tokenization
-         new String[] { "<ALPHANUM>",
-                        "<EMAIL>",
-                        "<EMAIL>",
-                        "<EMAIL>",
-                        "<ALPHANUM>", "<ALPHANUM>",
-                        "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>" });
-  }
-
-  public void testURLs() throws Exception {
-    Reader reader = null;
-    String randomTextWithURLs;
-    try {
-      reader = new InputStreamReader(getClass().getResourceAsStream
-        ("random.text.with.urls.txt"), StandardCharsets.UTF_8);
-      StringBuilder builder = new StringBuilder();
-      char[] buffer = new char[1024];
-      int numCharsRead;
-      while (-1 != (numCharsRead = reader.read(buffer))) {
-        builder.append(buffer, 0, numCharsRead);
-      }
-      randomTextWithURLs = builder.toString(); 
-    } finally {
-      if (null != reader) {
-        reader.close();
-      }
-    }
-    assertTrue(null != randomTextWithURLs 
-               && randomTextWithURLs.length() > 0);
-    BufferedReader bufferedReader = null;
-    String[] urls;
-    try {
-      List<String> urlList = new ArrayList<>();
-      bufferedReader = new BufferedReader(new InputStreamReader
-        (getClass().getResourceAsStream
-          ("urls.from.random.text.with.urls.txt"), StandardCharsets.UTF_8));
-      String line;
-      while (null != (line = bufferedReader.readLine())) {
-        line = line.trim();
-        if (line.length() > 0) {
-          urlList.add(line);
-        }
-      }
-      urls = urlList.toArray(new String[urlList.size()]);
-    } finally {
-      if (null != bufferedReader) {
-        bufferedReader.close();
-      }
-    }
-    assertTrue(null != urls && urls.length > 0);
-    BaseTokenStreamTestCase.assertAnalyzesTo
-      (urlAnalyzer, randomTextWithURLs, urls);
-  }
-
-  public void testUnicodeWordBreaks() throws Exception {
-    WordBreakTestUnicode_6_3_0 wordBreakTest = new WordBreakTestUnicode_6_3_0();
-    wordBreakTest.test(a);
-  }
-  
-  public void testSupplementary() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
-        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
-  }
-  
-  public void testKorean() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
-        new String[] { "훈민정음" },
-        new String[] { "<HANGUL>" });
-  }
-  
-  public void testJapanese() throws Exception {
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
-        new String[] { "仮", "名", "遣", "い", "カタカナ" },
-        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
-  }
-
-  public void testCombiningMarks() throws Exception {
-    checkOneTerm(a, "ざ", "ざ"); // hiragana
-    checkOneTerm(a, "ザ", "ザ"); // katakana
-    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
-    checkOneTerm(a, "아゙",  "아゙"); // hangul
-  }
-
-  /**
-   * Multiple consecutive chars in \p{Word_Break = MidLetter},
-   * \p{Word_Break = MidNumLet}, and/or \p{Word_Break = MidNum}
-   * should trigger a token split.
-   */
-  public void testMid() throws Exception {
-    // ':' is in \p{WB:MidLetter}, which should trigger a split unless there is a Letter char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B", new String[] { "A:B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A::B", new String[] { "A", "B" });
-
-    // '.' is in \p{WB:MidNumLet}, which should trigger a split unless there is a Letter or Numeric char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2", new String[] { "1.2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B", new String[] { "A.B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1..2", new String[] { "1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A..B", new String[] { "A", "B" });
-
-    // ',' is in \p{WB:MidNum}, which should trigger a split unless there is a Numeric char on both sides
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2", new String[] { "1,2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,,2", new String[] { "1", "2" });
-
-    // Mixed consecutive \p{WB:MidLetter} and \p{WB:MidNumLet} should trigger a split
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.:B", new String[] { "A", "B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:.B", new String[] { "A", "B" });
-
-    // Mixed consecutive \p{WB:MidNum} and \p{WB:MidNumLet} should trigger a split
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,.2", new String[] { "1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.,2", new String[] { "1", "2" });
-
-    // '_' is in \p{WB:ExtendNumLet}
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A:B", new String[] { "A:B_A:B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A::B", new String[] { "A:B_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1.2", new String[] { "1.2_1.2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A.B", new String[] { "A.B_A.B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1..2", new String[] { "1.2_1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A..B", new String[] { "A.B_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,2", new String[] { "1,2_1,2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,,2", new String[] { "1,2_1", "2" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A.:B", new String[] { "C_A", "B" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A:.B", new String[] { "C_A", "B" });
-
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1,.2", new String[] { "3_1", "2" });
-    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1.,2", new String[] { "3_1", "2" });
-  }
-
-
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), a, 1000*RANDOM_MULTIPLIER);
-  }
-  
-  /** blast some random large strings through the analyzer */
-  public void testRandomHugeStrings() throws Exception {
-    Random random = random();
-    checkRandomData(random, a, 100*RANDOM_MULTIPLIER, 8192);
-  }
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/WordBreakTestUnicode_6_3_0.java lucene/analysis/common/src/test/org/apache/lucene/analysis/core/WordBreakTestUnicode_6_3_0.java
deleted file mode 100644
index 9838530..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/WordBreakTestUnicode_6_3_0.java
+++ /dev/null
@@ -1,5537 +0,0 @@
-package org.apache.lucene.analysis.core;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.junit.Ignore;
-
-/**
- * This class was automatically generated by generateJavaUnicodeWordBreakTest.pl
- * from: http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakTest.txt
- *
- * WordBreakTest.txt indicates the points in the provided character sequences
- * at which conforming implementations must and must not break words.  This
- * class tests for expected token extraction from each of the test sequences
- * in WordBreakTest.txt, where the expected tokens are those character
- * sequences bounded by word breaks and containing at least one character
- * from one of the following character sets:
- *
- *    \p{Script = Han}                (From http://www.unicode.org/Public/6.3.0/ucd/Scripts.txt)
- *    \p{Script = Hiragana}
- *    \p{LineBreak = Complex_Context} (From http://www.unicode.org/Public/6.3.0/ucd/LineBreak.txt)
- *    \p{WordBreak = ALetter}         (From http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt)
- *    \p{WordBreak = Hebrew_Letter}
- *    \p{WordBreak = Katakana}
- *    \p{WordBreak = Numeric}         (Excludes full-width Arabic digits)
- *    [\uFF10-\uFF19]                (Full-width Arabic digits)
- */
-@Ignore
-public class WordBreakTestUnicode_6_3_0 extends BaseTokenStreamTestCase {
-
-  public void test(Analyzer analyzer) throws Exception {
-    // ÷ 0001 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0001",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\r",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\r",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\n",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\n",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u000B",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0001 × 0308 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0001 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0001 × 0308 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0001 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u003A",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u002C",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 002E ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u002E",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 002E ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0001 × 0308 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0001 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u005F",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 1F1E6 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 05D0 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0001 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0001 ÷ 0022 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\"",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 0022 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\"",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0027",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 0001 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u00AD",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 0001 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0300",
-                     new String[] {  });
-
-    // ÷ 0001 × 0308 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 0001 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0001 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0001 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0001 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0001 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0001",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\r",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\r",
-                     new String[] {  });
-
-    // ÷ 000D × 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) × [3.0] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\n",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\n",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u000B",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000D ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000D ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000D ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000D ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u003A",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u002C",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 002E ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u002E",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000D ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000D ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u005F",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 1F1E6 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 05D0 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000D ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000D ÷ 0022 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\"",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\"",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0027",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u00AD",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 × 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0300",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0308 × 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 000D ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000D ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000D ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000D ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0001",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\r",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\r",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\n",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\n",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u000B",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000A ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000A ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000A ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000A ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u003A",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u002C",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 002E ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u002E",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000A ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000A ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u005F",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 05D0 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000A ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000A ÷ 0022 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\"",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\"",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0027",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u00AD",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0300",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 000A ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000A ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0001",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\r",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\r",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\n",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\n",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u000B",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000B ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 000B ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000B ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 000B ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u003A",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u002C",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 002E ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u002E",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000B ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 000B ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u005F",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 05D0 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000B ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 000B ÷ 0022 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\"",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\"",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0027",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u00AD",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0300",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 000B ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000B ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 000B ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 000B ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 3031 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0001",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0001",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\r",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\r",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\n",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\n",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u000B",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u000B",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u3031",
-                     new String[] { "\u3031\u3031" });
-
-    // ÷ 3031 × 0308 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u3031",
-                     new String[] { "\u3031\u0308\u3031" });
-
-    // ÷ 3031 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0041",
-                     new String[] { "\u3031", "\u0041" });
-
-    // ÷ 3031 × 0308 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0041",
-                     new String[] { "\u3031\u0308", "\u0041" });
-
-    // ÷ 3031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u003A",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u003A",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u002C",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u002C",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 002E ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u002E",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 002E ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u002E",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0030",
-                     new String[] { "\u3031", "\u0030" });
-
-    // ÷ 3031 × 0308 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0030",
-                     new String[] { "\u3031\u0308", "\u0030" });
-
-    // ÷ 3031 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u005F",
-                     new String[] { "\u3031\u005F" });
-
-    // ÷ 3031 × 0308 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u005F",
-                     new String[] { "\u3031\u0308\u005F" });
-
-    // ÷ 3031 ÷ 1F1E6 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\uD83C\uDDE6",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\uD83C\uDDE6",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 05D0 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u05D0",
-                     new String[] { "\u3031", "\u05D0" });
-
-    // ÷ 3031 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u05D0",
-                     new String[] { "\u3031\u0308", "\u05D0" });
-
-    // ÷ 3031 ÷ 0022 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\"",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 0022 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\"",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0027",
-                     new String[] { "\u3031" });
-
-    // ÷ 3031 × 0308 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0027",
-                     new String[] { "\u3031\u0308" });
-
-    // ÷ 3031 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u00AD",
-                     new String[] { "\u3031\u00AD" });
-
-    // ÷ 3031 × 0308 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u00AD",
-                     new String[] { "\u3031\u0308\u00AD" });
-
-    // ÷ 3031 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0300",
-                     new String[] { "\u3031\u0300" });
-
-    // ÷ 3031 × 0308 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0300",
-                     new String[] { "\u3031\u0308\u0300" });
-
-    // ÷ 3031 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0061\u2060",
-                     new String[] { "\u3031", "\u0061\u2060" });
-
-    // ÷ 3031 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u2060",
-                     new String[] { "\u3031\u0308", "\u0061\u2060" });
-
-    // ÷ 3031 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0061\u003A",
-                     new String[] { "\u3031", "\u0061" });
-
-    // ÷ 3031 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u003A",
-                     new String[] { "\u3031\u0308", "\u0061" });
-
-    // ÷ 3031 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027",
-                     new String[] { "\u3031", "\u0061" });
-
-    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027",
-                     new String[] { "\u3031\u0308", "\u0061" });
-
-    // ÷ 3031 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027\u2060",
-                     new String[] { "\u3031", "\u0061" });
-
-    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027\u2060",
-                     new String[] { "\u3031\u0308", "\u0061" });
-
-    // ÷ 3031 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0061\u002C",
-                     new String[] { "\u3031", "\u0061" });
-
-    // ÷ 3031 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u002C",
-                     new String[] { "\u3031\u0308", "\u0061" });
-
-    // ÷ 3031 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0031\u003A",
-                     new String[] { "\u3031", "\u0031" });
-
-    // ÷ 3031 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u003A",
-                     new String[] { "\u3031\u0308", "\u0031" });
-
-    // ÷ 3031 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0031\u0027",
-                     new String[] { "\u3031", "\u0031" });
-
-    // ÷ 3031 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u0027",
-                     new String[] { "\u3031\u0308", "\u0031" });
-
-    // ÷ 3031 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0031\u002C",
-                     new String[] { "\u3031", "\u0031" });
-
-    // ÷ 3031 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002C",
-                     new String[] { "\u3031\u0308", "\u0031" });
-
-    // ÷ 3031 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0031\u002E\u2060",
-                     new String[] { "\u3031", "\u0031" });
-
-    // ÷ 3031 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002E\u2060",
-                     new String[] { "\u3031\u0308", "\u0031" });
-
-    // ÷ 0041 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0001",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0001",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\r",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\r",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\n",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\n",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u000B",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u000B",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u3031",
-                     new String[] { "\u0041", "\u3031" });
-
-    // ÷ 0041 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u3031",
-                     new String[] { "\u0041\u0308", "\u3031" });
-
-    // ÷ 0041 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0041",
-                     new String[] { "\u0041\u0041" });
-
-    // ÷ 0041 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0041",
-                     new String[] { "\u0041\u0308\u0041" });
-
-    // ÷ 0041 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u003A",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u003A",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u002C",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u002C",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 002E ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u002E",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u002E",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0030",
-                     new String[] { "\u0041\u0030" });
-
-    // ÷ 0041 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0030",
-                     new String[] { "\u0041\u0308\u0030" });
-
-    // ÷ 0041 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u005F",
-                     new String[] { "\u0041\u005F" });
-
-    // ÷ 0041 × 0308 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u005F",
-                     new String[] { "\u0041\u0308\u005F" });
-
-    // ÷ 0041 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\uD83C\uDDE6",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\uD83C\uDDE6",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 × 05D0 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u05D0",
-                     new String[] { "\u0041\u05D0" });
-
-    // ÷ 0041 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u05D0",
-                     new String[] { "\u0041\u0308\u05D0" });
-
-    // ÷ 0041 ÷ 0022 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\"",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\"",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0027",
-                     new String[] { "\u0041" });
-
-    // ÷ 0041 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0027",
-                     new String[] { "\u0041\u0308" });
-
-    // ÷ 0041 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u00AD",
-                     new String[] { "\u0041\u00AD" });
-
-    // ÷ 0041 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u00AD",
-                     new String[] { "\u0041\u0308\u00AD" });
-
-    // ÷ 0041 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0300",
-                     new String[] { "\u0041\u0300" });
-
-    // ÷ 0041 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0300",
-                     new String[] { "\u0041\u0308\u0300" });
-
-    // ÷ 0041 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0061\u2060",
-                     new String[] { "\u0041\u0061\u2060" });
-
-    // ÷ 0041 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u2060",
-                     new String[] { "\u0041\u0308\u0061\u2060" });
-
-    // ÷ 0041 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0061\u003A",
-                     new String[] { "\u0041\u0061" });
-
-    // ÷ 0041 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u003A",
-                     new String[] { "\u0041\u0308\u0061" });
-
-    // ÷ 0041 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027",
-                     new String[] { "\u0041\u0061" });
-
-    // ÷ 0041 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027",
-                     new String[] { "\u0041\u0308\u0061" });
-
-    // ÷ 0041 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027\u2060",
-                     new String[] { "\u0041\u0061" });
-
-    // ÷ 0041 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0041\u0308\u0061" });
-
-    // ÷ 0041 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0061\u002C",
-                     new String[] { "\u0041\u0061" });
-
-    // ÷ 0041 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u002C",
-                     new String[] { "\u0041\u0308\u0061" });
-
-    // ÷ 0041 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0031\u003A",
-                     new String[] { "\u0041\u0031" });
-
-    // ÷ 0041 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u003A",
-                     new String[] { "\u0041\u0308\u0031" });
-
-    // ÷ 0041 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0031\u0027",
-                     new String[] { "\u0041\u0031" });
-
-    // ÷ 0041 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u0027",
-                     new String[] { "\u0041\u0308\u0031" });
-
-    // ÷ 0041 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0031\u002C",
-                     new String[] { "\u0041\u0031" });
-
-    // ÷ 0041 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002C",
-                     new String[] { "\u0041\u0308\u0031" });
-
-    // ÷ 0041 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0031\u002E\u2060",
-                     new String[] { "\u0041\u0031" });
-
-    // ÷ 0041 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0041\u0308\u0031" });
-
-    // ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0001",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\r",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\r",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\n",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\n",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u000B",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 003A ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u003A",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u002C",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 002E ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u002E",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 003A ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u005F",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 05D0 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 003A × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\"",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\"",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0027",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 003A × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u00AD",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 003A × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0300",
-                     new String[] {  });
-
-    // ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0001",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\r",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\r",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\n",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\n",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u000B",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 002C ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u003A",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u002C",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 002E ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u002E",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 002C ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u005F",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\"",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\"",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0027",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 002C × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u00AD",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 002C × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0300",
-                     new String[] {  });
-
-    // ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E ÷ 0001 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0001",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 0001 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 000D ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\r",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 000D ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\r",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 000A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\n",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 000A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\n",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 000B ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u000B",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 000B ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 3031 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 002E × 0308 ÷ 3031 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 002E ÷ 0041 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 002E × 0308 ÷ 0041 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 002E ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u003A",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u002C",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 002E ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u002E",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 002E ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 0030 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 002E × 0308 ÷ 0030 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 002E ÷ 005F ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u005F",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 005F ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 1F1E6 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 05D0 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 002E × 0308 ÷ 05D0 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 002E ÷ 0022 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\"",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 0022 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\"",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0027",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 002E × 00AD ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u00AD",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 × 00AD ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 002E × 0300 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0300",
-                     new String[] {  });
-
-    // ÷ 002E × 0308 × 0300 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 002E ÷ 0061 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 002E × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 002E ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 002E ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 002E × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0030 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0001",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0001",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\r",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\r",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\n",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\n",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u000B",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u000B",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u3031",
-                     new String[] { "\u0030", "\u3031" });
-
-    // ÷ 0030 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u3031",
-                     new String[] { "\u0030\u0308", "\u3031" });
-
-    // ÷ 0030 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0041",
-                     new String[] { "\u0030\u0041" });
-
-    // ÷ 0030 × 0308 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0041",
-                     new String[] { "\u0030\u0308\u0041" });
-
-    // ÷ 0030 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u003A",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u003A",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u002C",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u002C",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 002E ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u002E",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u002E",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0030",
-                     new String[] { "\u0030\u0030" });
-
-    // ÷ 0030 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0030",
-                     new String[] { "\u0030\u0308\u0030" });
-
-    // ÷ 0030 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u005F",
-                     new String[] { "\u0030\u005F" });
-
-    // ÷ 0030 × 0308 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u005F",
-                     new String[] { "\u0030\u0308\u005F" });
-
-    // ÷ 0030 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\uD83C\uDDE6",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\uD83C\uDDE6",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 × 05D0 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u05D0",
-                     new String[] { "\u0030\u05D0" });
-
-    // ÷ 0030 × 0308 × 05D0 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u05D0",
-                     new String[] { "\u0030\u0308\u05D0" });
-
-    // ÷ 0030 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\"",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\"",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0027",
-                     new String[] { "\u0030" });
-
-    // ÷ 0030 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0027",
-                     new String[] { "\u0030\u0308" });
-
-    // ÷ 0030 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u00AD",
-                     new String[] { "\u0030\u00AD" });
-
-    // ÷ 0030 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u00AD",
-                     new String[] { "\u0030\u0308\u00AD" });
-
-    // ÷ 0030 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0300",
-                     new String[] { "\u0030\u0300" });
-
-    // ÷ 0030 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0300",
-                     new String[] { "\u0030\u0308\u0300" });
-
-    // ÷ 0030 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0061\u2060",
-                     new String[] { "\u0030\u0061\u2060" });
-
-    // ÷ 0030 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u2060",
-                     new String[] { "\u0030\u0308\u0061\u2060" });
-
-    // ÷ 0030 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0061\u003A",
-                     new String[] { "\u0030\u0061" });
-
-    // ÷ 0030 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u003A",
-                     new String[] { "\u0030\u0308\u0061" });
-
-    // ÷ 0030 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027",
-                     new String[] { "\u0030\u0061" });
-
-    // ÷ 0030 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027",
-                     new String[] { "\u0030\u0308\u0061" });
-
-    // ÷ 0030 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027\u2060",
-                     new String[] { "\u0030\u0061" });
-
-    // ÷ 0030 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0030\u0308\u0061" });
-
-    // ÷ 0030 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0061\u002C",
-                     new String[] { "\u0030\u0061" });
-
-    // ÷ 0030 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u002C",
-                     new String[] { "\u0030\u0308\u0061" });
-
-    // ÷ 0030 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0031\u003A",
-                     new String[] { "\u0030\u0031" });
-
-    // ÷ 0030 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u003A",
-                     new String[] { "\u0030\u0308\u0031" });
-
-    // ÷ 0030 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0031\u0027",
-                     new String[] { "\u0030\u0031" });
-
-    // ÷ 0030 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u0027",
-                     new String[] { "\u0030\u0308\u0031" });
-
-    // ÷ 0030 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0031\u002C",
-                     new String[] { "\u0030\u0031" });
-
-    // ÷ 0030 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002C",
-                     new String[] { "\u0030\u0308\u0031" });
-
-    // ÷ 0030 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0031\u002E\u2060",
-                     new String[] { "\u0030\u0031" });
-
-    // ÷ 0030 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0030\u0308\u0031" });
-
-    // ÷ 005F ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0001",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\r",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\r",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\n",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\n",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u000B",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 005F × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u3031",
-                     new String[] { "\u005F\u3031" });
-
-    // ÷ 005F × 0308 × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u3031",
-                     new String[] { "\u005F\u0308\u3031" });
-
-    // ÷ 005F × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0041",
-                     new String[] { "\u005F\u0041" });
-
-    // ÷ 005F × 0308 × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0041",
-                     new String[] { "\u005F\u0308\u0041" });
-
-    // ÷ 005F ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u003A",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u002C",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 002E ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u002E",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 002E ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 005F × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0030",
-                     new String[] { "\u005F\u0030" });
-
-    // ÷ 005F × 0308 × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0030",
-                     new String[] { "\u005F\u0308\u0030" });
-
-    // ÷ 005F × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u005F",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 1F1E6 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 005F × 05D0 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u05D0",
-                     new String[] { "\u005F\u05D0" });
-
-    // ÷ 005F × 0308 × 05D0 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u05D0",
-                     new String[] { "\u005F\u0308\u05D0" });
-
-    // ÷ 005F ÷ 0022 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\"",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 0022 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\"",
-                     new String[] {  });
-
-    // ÷ 005F ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0027",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 005F × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u00AD",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 005F × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0300",
-                     new String[] {  });
-
-    // ÷ 005F × 0308 × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 005F × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0061\u2060",
-                     new String[] { "\u005F\u0061\u2060" });
-
-    // ÷ 005F × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u2060",
-                     new String[] { "\u005F\u0308\u0061\u2060" });
-
-    // ÷ 005F × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0061\u003A",
-                     new String[] { "\u005F\u0061" });
-
-    // ÷ 005F × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u003A",
-                     new String[] { "\u005F\u0308\u0061" });
-
-    // ÷ 005F × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027",
-                     new String[] { "\u005F\u0061" });
-
-    // ÷ 005F × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027",
-                     new String[] { "\u005F\u0308\u0061" });
-
-    // ÷ 005F × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027\u2060",
-                     new String[] { "\u005F\u0061" });
-
-    // ÷ 005F × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027\u2060",
-                     new String[] { "\u005F\u0308\u0061" });
-
-    // ÷ 005F × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0061\u002C",
-                     new String[] { "\u005F\u0061" });
-
-    // ÷ 005F × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u002C",
-                     new String[] { "\u005F\u0308\u0061" });
-
-    // ÷ 005F × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0031\u003A",
-                     new String[] { "\u005F\u0031" });
-
-    // ÷ 005F × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u003A",
-                     new String[] { "\u005F\u0308\u0031" });
-
-    // ÷ 005F × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0031\u0027",
-                     new String[] { "\u005F\u0031" });
-
-    // ÷ 005F × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u0027",
-                     new String[] { "\u005F\u0308\u0031" });
-
-    // ÷ 005F × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0031\u002C",
-                     new String[] { "\u005F\u0031" });
-
-    // ÷ 005F × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002C",
-                     new String[] { "\u005F\u0308\u0031" });
-
-    // ÷ 005F × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0031\u002E\u2060",
-                     new String[] { "\u005F\u0031" });
-
-    // ÷ 005F × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002E\u2060",
-                     new String[] { "\u005F\u0308\u0031" });
-
-    // ÷ 1F1E6 ÷ 0001 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0001",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 0001 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 000D ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\r",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 000D ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\r",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 000A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\n",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 000A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\n",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 000B ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u000B",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 000B ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 3031 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 1F1E6 × 0308 ÷ 3031 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 1F1E6 ÷ 0041 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0041 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 1F1E6 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u003A",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u002C",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 002E ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u002E",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 002E ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 0030 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0030 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 1F1E6 ÷ 005F ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u005F",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 005F ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 1F1E6 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 × 1F1E6 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 05D0 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 1F1E6 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 1F1E6 ÷ 0022 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\"",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 0022 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\"",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0027",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 00AD ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u00AD",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 × 00AD ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0300 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0300",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 0308 × 0300 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 1F1E6 ÷ 0061 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 1F1E6 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 1F1E6 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 05D0 ÷ 0001 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0001",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 0001 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0001",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 000D ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\r",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 000D ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\r",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 000A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\n",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 000A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\n",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 000B ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u000B",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 000B ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u000B",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 3031 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u3031",
-                     new String[] { "\u05D0", "\u3031" });
-
-    // ÷ 05D0 × 0308 ÷ 3031 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u3031",
-                     new String[] { "\u05D0\u0308", "\u3031" });
-
-    // ÷ 05D0 × 0041 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0041",
-                     new String[] { "\u05D0\u0041" });
-
-    // ÷ 05D0 × 0308 × 0041 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0041",
-                     new String[] { "\u05D0\u0308\u0041" });
-
-    // ÷ 05D0 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u003A",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u003A",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u002C",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u002C",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 ÷ 002E ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u002E",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 002E ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u002E",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 × 0030 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0030",
-                     new String[] { "\u05D0\u0030" });
-
-    // ÷ 05D0 × 0308 × 0030 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0030",
-                     new String[] { "\u05D0\u0308\u0030" });
-
-    // ÷ 05D0 × 005F ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u005F",
-                     new String[] { "\u05D0\u005F" });
-
-    // ÷ 05D0 × 0308 × 005F ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u005F",
-                     new String[] { "\u05D0\u0308\u005F" });
-
-    // ÷ 05D0 ÷ 1F1E6 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\uD83C\uDDE6",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\uD83C\uDDE6",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 × 05D0 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u05D0",
-                     new String[] { "\u05D0\u05D0" });
-
-    // ÷ 05D0 × 0308 × 05D0 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u05D0",
-                     new String[] { "\u05D0\u0308\u05D0" });
-
-    // ÷ 05D0 ÷ 0022 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\"",
-                     new String[] { "\u05D0" });
-
-    // ÷ 05D0 × 0308 ÷ 0022 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\"",
-                     new String[] { "\u05D0\u0308" });
-
-    // ÷ 05D0 × 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [7.1] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0027",
-                     new String[] { "\u05D0\u0027" });
-
-    // ÷ 05D0 × 0308 × 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.1] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0027",
-                     new String[] { "\u05D0\u0308\u0027" });
-
-    // ÷ 05D0 × 00AD ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u00AD",
-                     new String[] { "\u05D0\u00AD" });
-
-    // ÷ 05D0 × 0308 × 00AD ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u00AD",
-                     new String[] { "\u05D0\u0308\u00AD" });
-
-    // ÷ 05D0 × 0300 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0300",
-                     new String[] { "\u05D0\u0300" });
-
-    // ÷ 05D0 × 0308 × 0300 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0300",
-                     new String[] { "\u05D0\u0308\u0300" });
-
-    // ÷ 05D0 × 0061 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0061\u2060",
-                     new String[] { "\u05D0\u0061\u2060" });
-
-    // ÷ 05D0 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u2060",
-                     new String[] { "\u05D0\u0308\u0061\u2060" });
-
-    // ÷ 05D0 × 0061 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0061\u003A",
-                     new String[] { "\u05D0\u0061" });
-
-    // ÷ 05D0 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u003A",
-                     new String[] { "\u05D0\u0308\u0061" });
-
-    // ÷ 05D0 × 0061 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0061\u0027",
-                     new String[] { "\u05D0\u0061" });
-
-    // ÷ 05D0 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u0027",
-                     new String[] { "\u05D0\u0308\u0061" });
-
-    // ÷ 05D0 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0061\u0027\u2060",
-                     new String[] { "\u05D0\u0061" });
-
-    // ÷ 05D0 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u0027\u2060",
-                     new String[] { "\u05D0\u0308\u0061" });
-
-    // ÷ 05D0 × 0061 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0061\u002C",
-                     new String[] { "\u05D0\u0061" });
-
-    // ÷ 05D0 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u002C",
-                     new String[] { "\u05D0\u0308\u0061" });
-
-    // ÷ 05D0 × 0031 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0031\u003A",
-                     new String[] { "\u05D0\u0031" });
-
-    // ÷ 05D0 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u003A",
-                     new String[] { "\u05D0\u0308\u0031" });
-
-    // ÷ 05D0 × 0031 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0031\u0027",
-                     new String[] { "\u05D0\u0031" });
-
-    // ÷ 05D0 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u0027",
-                     new String[] { "\u05D0\u0308\u0031" });
-
-    // ÷ 05D0 × 0031 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0031\u002C",
-                     new String[] { "\u05D0\u0031" });
-
-    // ÷ 05D0 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u002C",
-                     new String[] { "\u05D0\u0308\u0031" });
-
-    // ÷ 05D0 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0031\u002E\u2060",
-                     new String[] { "\u05D0\u0031" });
-
-    // ÷ 05D0 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u002E\u2060",
-                     new String[] { "\u05D0\u0308\u0031" });
-
-    // ÷ 0022 ÷ 0001 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0001",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 0001 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 000D ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\r",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 000D ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\r",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 000A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\n",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 000A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\n",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 000B ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u000B",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 000B ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 3031 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0022 × 0308 ÷ 3031 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0022 ÷ 0041 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0022 × 0308 ÷ 0041 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0022 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u003A",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u002C",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 002E ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u002E",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 002E ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 0030 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0022 × 0308 ÷ 0030 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0022 ÷ 005F ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u005F",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 005F ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 1F1E6 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 05D0 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0022 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0022 ÷ 0022 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\"",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 0022 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\"",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0027",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 0022 × 00AD ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u00AD",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 × 00AD ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 0022 × 0300 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0300",
-                     new String[] {  });
-
-    // ÷ 0022 × 0308 × 0300 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 0022 ÷ 0061 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0022 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0022 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0022 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0022 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0001",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\r",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\r",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\n",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\n",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u000B",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u003A",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u002C",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u002E",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u005F",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 05D0 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0027 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\"",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\"",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0027",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 0027 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u00AD",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 0027 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0300",
-                     new String[] {  });
-
-    // ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0001",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\r",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\r",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\n",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\n",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u000B",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 00AD × 0308 ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 00AD ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 00AD × 0308 ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 00AD ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u003A",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u002C",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 002E ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u002E",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 002E ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 00AD × 0308 ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 00AD ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u005F",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 1F1E6 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 05D0 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 00AD × 0308 ÷ 05D0 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 00AD ÷ 0022 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\"",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 0022 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\"",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0027",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 00AD × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u00AD",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 00AD × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0300",
-                     new String[] {  });
-
-    // ÷ 00AD × 0308 × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 00AD ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 00AD × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 00AD ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 00AD ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 00AD × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0001",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0001",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\r",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\r",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\n",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\n",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u000B",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u000B",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0300 × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u3031",
-                     new String[] { "\u3031" });
-
-    // ÷ 0300 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0300 × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0041",
-                     new String[] { "\u0041" });
-
-    // ÷ 0300 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u003A",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u003A",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u002C",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u002C",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 002E ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u002E",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 002E ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u002E",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0300 × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0030",
-                     new String[] { "\u0030" });
-
-    // ÷ 0300 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u005F",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u005F",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 1F1E6 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\uD83C\uDDE6",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 05D0 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0300 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u05D0",
-                     new String[] { "\u05D0" });
-
-    // ÷ 0300 ÷ 0022 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\"",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 0022 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\"",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0027",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0027",
-                     new String[] {  });
-
-    // ÷ 0300 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u00AD",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u00AD",
-                     new String[] {  });
-
-    // ÷ 0300 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0300",
-                     new String[] {  });
-
-    // ÷ 0300 × 0308 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0300",
-                     new String[] {  });
-
-    // ÷ 0300 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0300 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0300 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0300 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0300 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031" });
-
-    // ÷ 0061 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0001",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0001",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\r",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\r",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\n",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\n",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u000B",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u000B",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u3031",
-                     new String[] { "\u0061\u2060", "\u3031" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u3031",
-                     new String[] { "\u0061\u2060\u0308", "\u3031" });
-
-    // ÷ 0061 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0041",
-                     new String[] { "\u0061\u2060\u0041" });
-
-    // ÷ 0061 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0041",
-                     new String[] { "\u0061\u2060\u0308\u0041" });
-
-    // ÷ 0061 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u003A",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u003A",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u002C",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u002C",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u002E",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u002E",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0030",
-                     new String[] { "\u0061\u2060\u0030" });
-
-    // ÷ 0061 × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0030",
-                     new String[] { "\u0061\u2060\u0308\u0030" });
-
-    // ÷ 0061 × 2060 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u005F",
-                     new String[] { "\u0061\u2060\u005F" });
-
-    // ÷ 0061 × 2060 × 0308 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u005F",
-                     new String[] { "\u0061\u2060\u0308\u005F" });
-
-    // ÷ 0061 × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\uD83C\uDDE6",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\uD83C\uDDE6",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u05D0",
-                     new String[] { "\u0061\u2060\u05D0" });
-
-    // ÷ 0061 × 2060 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u05D0",
-                     new String[] { "\u0061\u2060\u0308\u05D0" });
-
-    // ÷ 0061 × 2060 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\"",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\"",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0027",
-                     new String[] { "\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0027",
-                     new String[] { "\u0061\u2060\u0308" });
-
-    // ÷ 0061 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u00AD",
-                     new String[] { "\u0061\u2060\u00AD" });
-
-    // ÷ 0061 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u00AD",
-                     new String[] { "\u0061\u2060\u0308\u00AD" });
-
-    // ÷ 0061 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0300",
-                     new String[] { "\u0061\u2060\u0300" });
-
-    // ÷ 0061 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0300",
-                     new String[] { "\u0061\u2060\u0308\u0300" });
-
-    // ÷ 0061 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u2060",
-                     new String[] { "\u0061\u2060\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u2060",
-                     new String[] { "\u0061\u2060\u0308\u0061\u2060" });
-
-    // ÷ 0061 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u003A",
-                     new String[] { "\u0061\u2060\u0061" });
-
-    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u003A",
-                     new String[] { "\u0061\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027",
-                     new String[] { "\u0061\u2060\u0061" });
-
-    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027",
-                     new String[] { "\u0061\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027\u2060",
-                     new String[] { "\u0061\u2060\u0061" });
-
-    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u002C",
-                     new String[] { "\u0061\u2060\u0061" });
-
-    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u002C",
-                     new String[] { "\u0061\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u003A",
-                     new String[] { "\u0061\u2060\u0031" });
-
-    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u003A",
-                     new String[] { "\u0061\u2060\u0308\u0031" });
-
-    // ÷ 0061 × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u0027",
-                     new String[] { "\u0061\u2060\u0031" });
-
-    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u0027",
-                     new String[] { "\u0061\u2060\u0308\u0031" });
-
-    // ÷ 0061 × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002C",
-                     new String[] { "\u0061\u2060\u0031" });
-
-    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002C",
-                     new String[] { "\u0061\u2060\u0308\u0031" });
-
-    // ÷ 0061 × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002E\u2060",
-                     new String[] { "\u0061\u2060\u0031" });
-
-    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0061\u2060\u0308\u0031" });
-
-    // ÷ 0061 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 × 003A × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0041",
-                     new String[] { "\u0061\u003A\u0041" });
-
-    // ÷ 0061 × 003A × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0041",
-                     new String[] { "\u0061\u003A\u0308\u0041" });
-
-    // ÷ 0061 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 003A × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u05D0",
-                     new String[] { "\u0061\u003A\u05D0" });
-
-    // ÷ 0061 × 003A × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u05D0",
-                     new String[] { "\u0061\u003A\u0308\u05D0" });
-
-    // ÷ 0061 ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 003A × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u2060",
-                     new String[] { "\u0061\u003A\u0061\u2060" });
-
-    // ÷ 0061 × 003A × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u2060",
-                     new String[] { "\u0061\u003A\u0308\u0061\u2060" });
-
-    // ÷ 0061 × 003A × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u003A",
-                     new String[] { "\u0061\u003A\u0061" });
-
-    // ÷ 0061 × 003A × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u003A",
-                     new String[] { "\u0061\u003A\u0308\u0061" });
-
-    // ÷ 0061 × 003A × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027",
-                     new String[] { "\u0061\u003A\u0061" });
-
-    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027",
-                     new String[] { "\u0061\u003A\u0308\u0061" });
-
-    // ÷ 0061 × 003A × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027\u2060",
-                     new String[] { "\u0061\u003A\u0061" });
-
-    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061\u003A\u0308\u0061" });
-
-    // ÷ 0061 × 003A × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u002C",
-                     new String[] { "\u0061\u003A\u0061" });
-
-    // ÷ 0061 × 003A × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u002C",
-                     new String[] { "\u0061\u003A\u0308\u0061" });
-
-    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 × 0027 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0041",
-                     new String[] { "\u0061\u0027\u0041" });
-
-    // ÷ 0061 × 0027 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0041",
-                     new String[] { "\u0061\u0027\u0308\u0041" });
-
-    // ÷ 0061 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 0027 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u05D0",
-                     new String[] { "\u0061\u0027\u05D0" });
-
-    // ÷ 0061 × 0027 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u05D0",
-                     new String[] { "\u0061\u0027\u0308\u05D0" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 0027 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u2060",
-                     new String[] { "\u0061\u0027\u0061\u2060" });
-
-    // ÷ 0061 × 0027 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u2060",
-                     new String[] { "\u0061\u0027\u0308\u0061\u2060" });
-
-    // ÷ 0061 × 0027 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u003A",
-                     new String[] { "\u0061\u0027\u0061" });
-
-    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u003A",
-                     new String[] { "\u0061\u0027\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027",
-                     new String[] { "\u0061\u0027\u0061" });
-
-    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027",
-                     new String[] { "\u0061\u0027\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027\u2060",
-                     new String[] { "\u0061\u0027\u0061" });
-
-    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061\u0027\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u002C",
-                     new String[] { "\u0061\u0027\u0061" });
-
-    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u002C",
-                     new String[] { "\u0061\u0027\u0308\u0061" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 × 0027 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0041",
-                     new String[] { "\u0061\u0027\u2060\u0041" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0041",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0041" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u05D0",
-                     new String[] { "\u0061\u0027\u2060\u05D0" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u05D0",
-                     new String[] { "\u0061\u0027\u2060\u0308\u05D0" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u2060",
-                     new String[] { "\u0061\u0027\u2060\u0061\u2060" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u2060",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0061\u2060" });
-
-    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u003A",
-                     new String[] { "\u0061\u0027\u2060\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u003A",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027",
-                     new String[] { "\u0061\u0027\u2060\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027\u2060",
-                     new String[] { "\u0061\u0027\u2060\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u002C",
-                     new String[] { "\u0061\u0027\u2060\u0061" });
-
-    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u002C",
-                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0001",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\r",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\n",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u000B",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u3031",
-                     new String[] { "\u0061", "\u3031" });
-
-    // ÷ 0061 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0041",
-                     new String[] { "\u0061", "\u0041" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0041",
-                     new String[] { "\u0061", "\u0041" });
-
-    // ÷ 0061 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u003A",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u002C",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u002E",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0030",
-                     new String[] { "\u0061", "\u0030" });
-
-    // ÷ 0061 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u005F",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\uD83C\uDDE6",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u05D0",
-                     new String[] { "\u0061", "\u05D0" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u05D0",
-                     new String[] { "\u0061", "\u05D0" });
-
-    // ÷ 0061 ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\"",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0027",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u00AD",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0300",
-                     new String[] { "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u2060",
-                     new String[] { "\u0061", "\u0061\u2060" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u2060",
-                     new String[] { "\u0061", "\u0061\u2060" });
-
-    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u003A",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u003A",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027\u2060",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u002C",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u002C",
-                     new String[] { "\u0061", "\u0061" });
-
-    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u003A",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u0027",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002C",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0061", "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0030",
-                     new String[] { "\u0031", "\u0030" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0030",
-                     new String[] { "\u0031", "\u0030" });
-
-    // ÷ 0031 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u003A",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u003A",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u0027",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u0027",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002C",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002C",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002E\u2060",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031", "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 × 0027 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0030",
-                     new String[] { "\u0031\u0027\u0030" });
-
-    // ÷ 0031 × 0027 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0030",
-                     new String[] { "\u0031\u0027\u0308\u0030" });
-
-    // ÷ 0031 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 × 0027 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u003A",
-                     new String[] { "\u0031\u0027\u0031" });
-
-    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u003A",
-                     new String[] { "\u0031\u0027\u0308\u0031" });
-
-    // ÷ 0031 × 0027 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u0027",
-                     new String[] { "\u0031\u0027\u0031" });
-
-    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u0027",
-                     new String[] { "\u0031\u0027\u0308\u0031" });
-
-    // ÷ 0031 × 0027 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002C",
-                     new String[] { "\u0031\u0027\u0031" });
-
-    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002C",
-                     new String[] { "\u0031\u0027\u0308\u0031" });
-
-    // ÷ 0031 × 0027 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002E\u2060",
-                     new String[] { "\u0031\u0027\u0031" });
-
-    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031\u0027\u0308\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 × 002C × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0030",
-                     new String[] { "\u0031\u002C\u0030" });
-
-    // ÷ 0031 × 002C × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0030",
-                     new String[] { "\u0031\u002C\u0308\u0030" });
-
-    // ÷ 0031 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 × 002C × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u003A",
-                     new String[] { "\u0031\u002C\u0031" });
-
-    // ÷ 0031 × 002C × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u003A",
-                     new String[] { "\u0031\u002C\u0308\u0031" });
-
-    // ÷ 0031 × 002C × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u0027",
-                     new String[] { "\u0031\u002C\u0031" });
-
-    // ÷ 0031 × 002C × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u0027",
-                     new String[] { "\u0031\u002C\u0308\u0031" });
-
-    // ÷ 0031 × 002C × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002C",
-                     new String[] { "\u0031\u002C\u0031" });
-
-    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002C",
-                     new String[] { "\u0031\u002C\u0308\u0031" });
-
-    // ÷ 0031 × 002C × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002E\u2060",
-                     new String[] { "\u0031\u002C\u0031" });
-
-    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031\u002C\u0308\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0001",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\r",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\n",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u000B",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u3031",
-                     new String[] { "\u0031", "\u3031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0041",
-                     new String[] { "\u0031", "\u0041" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u003A",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u002C",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u002E",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0030",
-                     new String[] { "\u0031\u002E\u2060\u0030" });
-
-    // ÷ 0031 × 002E × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0030",
-                     new String[] { "\u0031\u002E\u2060\u0308\u0030" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u005F",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\uD83C\uDDE6",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u05D0",
-                     new String[] { "\u0031", "\u05D0" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\"",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0027",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u00AD",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0300",
-                     new String[] { "\u0031" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u2060",
-                     new String[] { "\u0031", "\u0061\u2060" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u003A",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027\u2060",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u002C",
-                     new String[] { "\u0031", "\u0061" });
-
-    // ÷ 0031 × 002E × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u003A",
-                     new String[] { "\u0031\u002E\u2060\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u003A",
-                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u0027",
-                     new String[] { "\u0031\u002E\u2060\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u0027",
-                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002C",
-                     new String[] { "\u0031\u002E\u2060\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002C",
-                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002E\u2060",
-                     new String[] { "\u0031\u002E\u2060\u0031" });
-
-    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002E\u2060",
-                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
-
-    // ÷ 0063 × 0061 × 006E × 0027 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u0027\u0074",
-                     new String[] { "\u0063\u0061\u006E\u0027\u0074" });
-
-    // ÷ 0063 × 0061 × 006E × 2019 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u2019\u0074",
-                     new String[] { "\u0063\u0061\u006E\u2019\u0074" });
-
-    // ÷ 0061 × 0062 × 00AD × 0062 × 0079 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] SOFT HYPHEN (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [5.0] LATIN SMALL LETTER Y (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0062\u00AD\u0062\u0079",
-                     new String[] { "\u0061\u0062\u00AD\u0062\u0079" });
-
-    // ÷ 0061 ÷ 0024 ÷ 002D ÷ 0033 × 0034 × 002C × 0035 × 0036 × 0037 × 002E × 0031 × 0034 ÷ 0025 ÷ 0062 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] DOLLAR SIGN (Other) ÷ [999.0] HYPHEN-MINUS (Other) ÷ [999.0] DIGIT THREE (Numeric) × [8.0] DIGIT FOUR (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT FIVE (Numeric) × [8.0] DIGIT SIX (Numeric) × [8.0] DIGIT SEVEN (Numeric) × [12.0] FULL STOP (MidNumLet) × [11.0] DIGIT ONE (Numeric) × [8.0] DIGIT FOUR (Numeric) ÷ [999.0] PERCENT SIGN (Other) ÷ [999.0] LATIN SMALL LETTER B (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\u0024\u002D\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034\u0025\u0062",
-                     new String[] { "\u0061", "\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034", "\u0062" });
-
-    // ÷ 0033 × 0061 ÷  #  ÷ [0.2] DIGIT THREE (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0033\u0061",
-                     new String[] { "\u0033\u0061" });
-
-    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 0027 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060",
-                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060" });
-
-    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 2019 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060",
-                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060" });
-
-    // ÷ 2060 ÷ 0061 × 2060 × 0062 × 2060 × 00AD × 2060 × 0062 × 2060 × 0079 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER Y (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060",
-                     new String[] { "\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060" });
-
-    // ÷ 2060 ÷ 0061 × 2060 ÷ 0024 × 2060 ÷ 002D × 2060 ÷ 0033 × 2060 × 0034 × 2060 × 002C × 2060 × 0035 × 2060 × 0036 × 2060 × 0037 × 2060 × 002E × 2060 × 0031 × 2060 × 0034 × 2060 ÷ 0025 × 2060 ÷ 0062 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DOLLAR SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] HYPHEN-MINUS (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] COMMA (MidNum) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT FIVE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SIX (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SEVEN (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] PERCENT SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0024\u2060\u002D\u2060\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060\u0025\u2060\u0062\u2060\u2060",
-                     new String[] { "\u0061\u2060", "\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060", "\u0062\u2060\u2060" });
-
-    // ÷ 2060 ÷ 0033 × 2060 × 0061 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u2060\u0033\u2060\u0061\u2060\u2060",
-                     new String[] { "\u0033\u2060\u0061\u2060\u2060" });
-
-    // ÷ 0061 ÷ 1F1E6 ÷ 0062 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER B (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0061\uD83C\uDDE6\u0062",
-                     new String[] { "\u0061", "\u0062" });
-
-    // ÷ 1F1F7 × 1F1FA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA",
-                     new String[] {  });
-
-    // ÷ 1F1F7 × 1F1FA × 1F1F8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\uD83C\uDDF8",
-                     new String[] {  });
-
-    // ÷ 1F1F7 × 1F1FA × 1F1F8 × 1F1EA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER E (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\uD83C\uDDF8\uD83C\uDDEA",
-                     new String[] {  });
-
-    // ÷ 1F1F7 × 1F1FA ÷ 200B ÷ 1F1F8 × 1F1EA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) ÷ [999.0] ZERO WIDTH SPACE (Other) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER E (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\u200B\uD83C\uDDF8\uD83C\uDDEA",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 1F1E7 × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE7\uD83C\uDDE8",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 200D × 1F1E7 × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] ZERO WIDTH JOINER (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u200D\uD83C\uDDE7\uD83C\uDDE8",
-                     new String[] {  });
-
-    // ÷ 1F1E6 × 1F1E7 × 200D × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [4.0] ZERO WIDTH JOINER (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE7\u200D\uD83C\uDDE8",
-                     new String[] {  });
-
-    // ÷ 0020 × 200D ÷ 0646 ÷  #  ÷ [0.2] SPACE (Other) × [4.0] ZERO WIDTH JOINER (Extend_FE) ÷ [999.0] ARABIC LETTER NOON (ALetter) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0020\u200D\u0646",
-                     new String[] { "\u0646" });
-
-    // ÷ 0646 × 200D ÷ 0020 ÷  #  ÷ [0.2] ARABIC LETTER NOON (ALetter) × [4.0] ZERO WIDTH JOINER (Extend_FE) ÷ [999.0] SPACE (Other) ÷ [0.3]
-    assertAnalyzesTo(analyzer, "\u0646\u200D\u0020",
-                     new String[] { "\u0646\u200D" });
-
-  }
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/email.addresses.from.random.text.with.email.addresses.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/core/email.addresses.from.random.text.with.email.addresses.txt
deleted file mode 100644
index ae86ee6..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/email.addresses.from.random.text.with.email.addresses.txt
+++ /dev/null
@@ -1,265 +0,0 @@
-dJ8ngFi@avz13m.CC
-JCAVLRJg@3aqiq2yui.gm
-kU-l6DS@[082.015.228.189]
-37layCJS@j5NVP7NWAY.VG
-"%U@?\B"@Fl2d.md
-aH3QW@tw8uo2.eu
-Bvd#@tupjv.sn
-SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt
-DvdUJk@61zwkit7dkd3rcq4v.BD
-~+Kdz@3mousnl.SE
-C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY
-}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM
-lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae
-V85E9Hx7@vpf0bs.bz
-MGBg2@7F3MJTCCPROS8YETM0B4-C9P7WXKGFB0.RU
-rsBWOCJ@lYX0SILY4L53Z3VJPSF6.pwrawr.vdpoq.nz
-dIyLrU@9A40T2ZIG7H8R.t63.tv
-6dAsZKz@d33XR.IR
-EnqCC@2bk6da6y08.LI
-AQ9yV@Mfqq32nexufgxzl4o7q5jv3kd.lb
-lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H
-b6/zomNkV@8jwm-he.IN
-5FLuakz.hXVkuqDt@iBFP83V6MNI3N0FRWJ9302DS-0KHRV6O.1bf59kj64uj5b6e2zfn.cm
-RhIwkU@58vmet9yfddpg.3adkmhrv1px.AO
-nEBk6w2Q@Bb5ib.2pay.so
-AlW5CMAn@qos-53u.j91qq96d4en129szf7099kxv5lo6yo.gm
-QPYBDV3.Ah/h8U@x3v444pzi.1cvgokam.PW
-5Iwbiq7@p9s-2pixps9jwzyhfroxqivw8sv90r.xn--wgbh1c
-AaFU9L@3yj1xqf1.cz9.ac
-|iCmQ1@rum6w0a7wt.3QLD.ht71.cx
-EhLTUjo@rEK.sJ44H0.GR
-bHEbq3Rp@33.lKSSMY.9xaurtfle9xe.iu4810l.fj
-eFcup.cPPEW@[1ae]
-p907@bk3o.fvtmw2m2.Uutr83x2yt4.2nuin.EU
-PpW2L5.QgP2n@9rz7.a5qi.oRH1Z.8ov.UZ
-o8UgG5fewm4vr9Ai5wPS@sgh.2F-OLKLZ81DIUET.xpya0vtx.fj
-aixQH@z-y.AR
-jVTeWQfL."M#~t Q"@1e.oglq.ubk.SZ
-6e5QQuy@N7.2cuw3x2wpddf.paycp1pc.AI
-IqG6Fl@[220.112.120.54]
-lWHH4eWSn@tbxyb7.jhzqxrk.lv
-P1zO*RaAr@[111.99.108.22]
-d00gy@[4TC]
-1yNINoBU@[136.003.010.238]
-Ms8ox@[_3Tuehr]
-wtWDNo@1sjmcbbli196-765mt7m8o8hywft.7-ga6rsnum8v.np
-"x)yO"@7le5o2rcud5ngs.Qmfmq.Jfxv8.Zznv6t6il.MIL
-1hXd@f8.1kxqd3yw4j6zmb7l7.US
-"8}(\$"@mu2viak0nh4sj5ivgpy1wqie.HK
-Th7XoAs5@ggdb.BI
-5iDbhah.xdtF1x@[59.55.12.243]
-j2ovALlgm2Wcwx@5jphzt.TN
-ZlaP~E.4Yk1K0F@lF6VN.M5.Nj.PRO
-cFCvIJAw@l93H0R1W6V4RI0AY7RLRQR4KOEVQPEG-PDTF03V4D9A0.xZZK5.lu
-8Ju2AW@1n.h7.vu
-"\nkP]{"@[Vej\yo\HD]
-fKWC?@qgcb.xn--mgbaam7a8h
-L4BbaB@hv1.BIZ
-WvSmV@qpx15vzmbtxzvi-syndl1.ML
-"3|PX~Cbdq"@U3vp-7k.8c4q3sgpwt6sochundzhx.museum
-LjH9rJTu@tkm.gy
-vQgXEFb@maxmrbk-5a5s6o.6MZZ6IK.awjbtiva7.IL
-6TVbIA@r50eh-a.la
-AaASl@Bsteea.qHXE3Q5CUJ3DBG.S2hvnld.4WJWL.fk
-"CN;\-z 6M"@86.qc7s.23p.ET
-zX3=O3o@Yjov.7g660.8M88OJGTDC5.np
-QFZlK1A@4W47EIXE.KY
-1guLnQb07k@ab.ccemuif2s.lb
-Jddxj@[111.079.109.147]
-Hj06gcE@[105.233.192.168]
-u8?xicQ@[i\21I]
-CczYer}W@bezu6wtys9s.lft3z.mobi
-OmpYhIL@6GJ7P29EIE-G63RDW7GLFLFC0M1.AERO
-2RRPLqO@8lh0i.vm7xmvvo-r5nf0x.CY
-TOc!BhbKz@F-myy7.kQWSUI7S3.net
-"0\!P?".shQVdSerA@2qmqj8ul.hm
-LTLNFsgB@[191.56.104.113]
-iT0LOq.jtPW=G06~cETxl2ge@Ah0.4hn72v.tQ.LU
-VGLn@z3E2.3an2.MM
-TWmfsxn@[112.192.017.029]
-2tP07A@2twe6u0d6uw6o.sed7n.109mx.XN--KPRW13D
-CjaPC63@['\RDrwk]
-Ayydpdoa@tdgypppmen.wf
-"gfKP9"@jo3-r0.mz
-aTMgDW4@t5gax.XN--3E0B707E
-mcDrMO3FQ@nwc21.y5qd45lesryrp.IL
-NZqj@v50egeveepk.z290kk.Bc3.xn--kprw13d
-XtAhFnq@[218.214.251.103]
-x0S8uos@[109.82.126.233]
-ALB4KFavj16pODdd@i206d6s.MM
-grxIt96.46nCf@nokjogh2l4.nCMWXG.yt
-Fgbh7@2rxkk0bvkk-v3evd-sh56gvhxlh.hhjcsg36j8qt98okjbdj9z574xdpix59zf6h80r.Gyb4rrxu.ve
-uo0AX41@Fhlegm1z57j-qvf5.p8jo6zvm.sc
-sjn4cz@9ktlwkqte.bv
-b04v0Ct@[243.230.224.190]
-F!FUbQHU@uvz7cu1l.ciz4h2.93U4V.gb
-6CHec@nONUKT.nl
-zbmZiXw@yb.bxxp.3fm457.va
-"/GdiZ7f"@[221.229.46.3]
-NJde8Li@f7a.g51VICBH.cy
-6IeAft@e-3fp.Nkh7nm8.v8i47xvrv27r.pf
-TC*Qopzb@xIOB3.6egz4.m-24t5wmxtmco4iy8g91o66mjgha1vjlepyffott.E5ta.p9.CF
-"_3Sc_"@[193.165.124.143]
-W0dwHf@[25.174.65.80]
-qPkkP0@4k0vs.oaak2z.3JMTI.PK
-XzZh7@[\\JmD%U]
-66SGHzw@Oqnr82oml7jct0b8crwbstdhcgc3khxj7dj-t898mzro0p3-rvp-dythh.TN
-ot4tPF@[AY\j]
-e4seIFbl@cib.cg
-B2w025e@r2H7BW16B24DG1S5DED.bg
-atweEde@blk-3y.mgvoh6l9my.F6.FI
-uDoPcRGW@rEBD5LUT.ly
-2KQhx@Bba.u--9b5bc0.NF
-tKWc2VjVRYD@[254.190.162.128]
-wc3W16^@D3v2uxqqeclz.w1fd529m.DM
-Njg@6S8MA.HK
-"L\^4z]92"@0qp--walx.MIL
-X08sWFD@62GNK.tN4.f1YXX.ug
-eK6Bz1Bu@[rX;J&036]
-"~`o\:"@hO4UKF.oZBWV56B.cmn.DJ
-lcgUakx@[pjGd&i2]
-BqdBTnv3c@wf35nwaza.ME
-"a#Um{:\'\bX:"@in7tjo.uw8wil.gp
-ApIbER8'@[&Y]
-JTsM0c!s9CzEH@Sd.mh
-hy2AOUc@uqxzl7v0hl2nchokqit9lyscxaa0jaqya1wek5gkd.NC
-pY7bAVD4r@[,>T*R T]
-!0axBT@03-gdh1xmk3x9.GH
-vbtyQBZI@20al5g.ro6ds4.Bsg15f5.NU
-2^ZhSK-FFYOh@Z2iku.rg.Z0ca1.gs
-G1RLpOn."yfJpg["@mXEV8.mu
-yrBKNkq@a2a1.Aifn.Ta2.dj
-Wok5G@b5aqobvi5.ni
-nXz9i.=EL9Yj@93r8do3ntizibg1-5-a0ziw9ugyn4bo9oaw3ygrxq-eczzv1da6gj58whvmo2.rs
-Dp63hd@B1kbahyq.PL
-y01rn27SFq@o0HNP8.C5.i4rvj8j338zgter7er5rkwyo5g.atnc0iuj2ke.8or6ekq0x.IO
-0RiEo@08mnvbu.p661ernzjz5p7nbyix5iuj.cig5hgvcc.SO
-Dwxab5@1sx5y3-umsy72nl.74lwye5.DJ
-IvdZVE4xRk@0vw7ajl.AR
-CvQxhXJ@d5a7qnx.ke
-n7MxA4~@[4(R]
-RFGzu3hD0@wbh4.sm
-eOADW}BcNG@2568p3b4v.Xq3eksr.GP
-AsAMWriW7.zSDQSAR6@Gg2q4rtgr.GG
-cDCVlA0t@[20.116.229.216]
-c=yJU+3L5@n2x3xhksf.gvreani.MZ
-wfYnaA4@lzojy.4oii6w6sn-p9.kh
-kdeOQ5F@vD5Y.wmmv.7rswz.1zelobcp5qxxwzjn.fOEJZ.KM
-ppULqb2Z@Hv9o2ui.AO
-tOHw@[IPv6:3500:8B6C::CB5E:1.124.160.137]
-MWLVsL@7nhliy.O8mjon3rj-kb.t8d6bcpa5i.au
-BN0EY@hh9v.p9bwgs.TN
-RgiAp@d9ln.bf
-PBugBo@97gcz.DJ
-Fh#dKzbI@[+_]
-wyqU-C9hXE@wPRBUI-WS9HXE19.LV
-muC?Js@[IPv6:47FB:5786:4b5e::5675]
-yLTT2xV@wdoszw9k1ork-z-t.kq.l3SEO.Lb4jx0.NA
-6zqw.yPV4LkL@dA3XKC.eg
-S5z9i7i3s@Vzt6.fr
-L|Sit6s@9cklii1.tf
-yWYqz@mw-9k.FJ
-Knhj419mAfftf@R26hxll64.3qtdx6g.AL
-aZYHUr6@Shyn76c67.65grky.am
-ZYxn6Px@di0cqhtg.hu
-"#mLl"@w1sc0g3vm.j1o4o9g.GW
-WYJcFp@653xk-89oprk2im.iemhx9.CC
-y5AXi@[Oa #]
-nZErAGj@6sq3-p.r8KQ.aero
-OMq5sBK@udg-5zp1.Dory85.SG
-2bymd@Ojla1hvfpw8rrihrx.cy
-5OMbw0@r2d8cn75.1VR2BJ0J3A8PY.gc0mljc-h.COOP
-al6X^pQkx@pyj--2hp.lbet.TN
-NkzPW4f@2-0.aaoqccwrgi4olytac0imp6vvphsuobrr115eygh2xwkvzeuj.tl
-"4-b9|/,\e]h]2"@9-iiahsdlzv-v65j.FK
-g8Pv2hb9@[166.176.68.63]
-"IA~".Tn03w7@[\>J?]
-E6aK9TaJ@j0hydmxhkq2q.Svku4saky.MU
-rdF2Zl1@9fsic.C17pw9o0.vn
-pCKjPa88DG&x5a@4ha07ia2jk.xk7xe8.PM
-qgLb5m@nynqp.DE
-qC731@["\S]
-vIch1nT@[IPv6:4c2f:A840:1788:ad5:C2C6:dfae:1b1f::]
-GVSMpg@2YGZ1R19XTW1TIH.Re3vg30u1xq6v7cj1wf-6m14939wvgqbl.93mztd.SG
-0jq4v7PMxm@eq6teog.kO6LR3.x2p.53yltrsvgpd3.RO
-zdGLZD0P@i2JQNM8.816oja8pkk5zkvyx.KM
-Jp#hSH@74zkerax4.31kr.7c9-yuk.mp
-Kx^0oZn@oFFA-URZ13B34J.DK
-sub52@aoq7.iHF.CH
-jfVSq9oAR2D@iGU0.7bp3x.4cr.sz
-nalgU@Yfpbdcv8a5.n9kwz6kyi2u.thic-rws.af.TG
-=uC5qVT@56g530cltpekrw.pt
-QR5&kx@7qhi3bhav5ga0eva.b0sdom.bb
-8DZQ7@dtr16r89fdw59q.cf
-Q4pNw@6o-9weojl3r7.LS
-*mfOc_CN@[G\3]
-2p`tbG@c767inolrav0hg6a-ucs.y0.tw
-Rop{cgBy@Wekdh0xns2um.UK
-t*p05lV@017y.MR
-7ZxO80@Dovepwr4l.qxfzchrn1.es8ul0vavi6gqy82.K1hc7.INT
-C_Iphp@5t4rtc.id
-q+m2x@Cfw.1tm52-kr.BO
-47NIL@Hl68os0.66l9bsf2q.SC
-vi0LyF9O@p74jz6mxby.it
-xQ4jU@rQVWLWAD3T8.4-lnu.AZ
-zea_0Kr@[97.59.144.249]
-5HP1k|s@[068.150.236.123]
-5XJZlmYk.3Du5qee@[072.023.197.244]
-AvNrIHB0@[+n}oV]
-"!N7/I\zhh"@[204.037.067.146]
-vlJODxFF@xFO6V.i1.fgad6bjy.NO
-qDe0FA@xpp1le82ndircjgyrxyzkrqu3il.oUKHVV6829P-16JILWG62KN.cr
-pMF64@wssq6kh9uhxk.cA2YZVBV4JW.xX585A.ru
-G3meE@[^!'OO]
-"1@0UYJl"@vplkx.d2n.i3tcx3aaxut.lbb3v9.ldq.me
-iTH0QND@wg9sizy.lr
-9kF?opSTo9rSDWLo&W&6@xrh32ibf.F0zb6kb.BJ
-a0FI1m@1olkdpz.W70a3w8qmk3.NA
-"0H}r}X(p\M`/x"@rY48LPH.Axy.Ue624.TV
-AQL6YBFb@Hxawb15okz.y4.y5c0e.bt
-PEaNVR@m8NH9BVX5L096DRM7YTR.er
-diI`Q@i5fpkuc.7zg2av.D6tzqq.CK
-TCN0-Z@Tezeq9ejv.ekeab8hz14hui.il
-05SnFh@jZ85JXZ.1RO99W5FYK3.uyv7g15.MP
-B2Z76Rn@9yce0shfsydxetu1v4-y.rBU2M0.6ik8oapv0zho6n653il25gu4rd216uw03.MG
-vGZ2K@C2osgjtel5uerwn.riihbabhh41ve84.r3l.vH6S64.vn
-Nv2ZgL@[037.054.177.155]
-WsdI2W@i1ULFQ1.79qfph2.eg
-vJfpTf3@Hh4x2h.25m0idq3.fr
-oRqbgftr@l6jg0.TV
-NiynsKb@k9BTX4-FV.hc0skm-o.lv
-w9uGwf@4hop8.Jb9655is.nr
-"NVUW+"@6jbe.KM
-QusHU6JMR@0RXKIZNH76C3.Oqwcfr779e.MH
-}C5IwKv1S45vlmPaaVHhF@[IPv6:EBF6::]
-T7rXlYc@4AI1LM.2o.uk
-uuCiDC6c@Maar3.65hlg-wf.t3pt9.FJ
-w2mNOvIUh@dx3ep7ew.ru
-b#Add@9hpopo.Xg3tbjchdpt.TT
-NtrgJjfj."NBwi"@[142.085.096.018]
-00lF9UB@2NR2.rs
-MPr42ye9@p08lcrzs.4bzxfznsh2bhgsa.CX
-awwLoYLn~c2LfTEVT@fwksx.qoj94r11kw19k50k3.gd
-gRZ5w9epm@p6adico3auugj5qklec.Sm4bx5.li
-zfdZ67Y@1azhq.dl3xxzni2.rrj.lpclc6g4d.sl
-vTWwSD4fb@uBSOHD.3g.u3mb.gf
-cYFVxcC6E@F9g0b.n1339r.AU
-pnuXl@s1alo2.tc
-lKy64zp.Cbg8BM@y0S.6uiux8h8.0udipt.ma
-|9FDgc@vbrz.3L.av4kmt.rs
-skcHAu7@xD715N1.DZ
-BfcgHK3@[220.136.9.224]
-LCOEag@Gwm.drsa0.GL
-qrNZtp3vO@a0gr.8j9cvcgy0p-3.HN
-lfW2rei20XWSmpQoPY1Dl@[(N&c]
-WFBBEv|@q7R2J.oy48740.pm
-6H6rPx@zVJ40.xgyat.cLUX6SVFJWMLF9EZ2PL8QQEU7U1WT0JW3QR8898ALFGKO18CF1DOX89DR.1tfu30mp.CA
-ytG@J4auwv4has.PS
-"X;+N1A\A "@rc9cln0xyy8wa6axedojj9r0slj0v.Luy9i6ipqrz74lm5-n6f1-2srq5vdo-opef747ubdykv5hc.2lztpe.er
-DQTmqL4LVRUvuvoNb8=TT@2up3.PY
-NC0OPLz@kcru1s0mu.name
-kBoJf{XaGl@[248.166.223.221]
-pEjZPm8A@v956Y7GQV.5uu6.Ribgf20u.6e.0do1nki1t.ahy.6iy.sm
-pIFWkl2@w9N0Q.MC
-p=VTtlpC@w3ttqb.FO
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/generateJavaUnicodeWordBreakTest.pl lucene/analysis/common/src/test/org/apache/lucene/analysis/core/generateJavaUnicodeWordBreakTest.pl
deleted file mode 100644
index 46ac3ef..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/generateJavaUnicodeWordBreakTest.pl
+++ /dev/null
@@ -1,232 +0,0 @@
-#!/usr/bin/perl
-
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-use warnings;
-use strict;
-use File::Spec;
-use Getopt::Long;
-use LWP::UserAgent;
-
-my ($volume, $directory, $script_name) = File::Spec->splitpath($0);
-
-my $version = '';
-unless (GetOptions("version=s" => \$version) && $version =~ /\d+\.\d+\.\d+/) {
-  print STDERR "Usage: $script_name -v <version>\n";
-  print STDERR "\tversion must be of the form X.Y.Z, e.g. 5.2.0\n"
-      if ($version);
-  exit 1;
-}
-my $url_prefix = "http://www.unicode.org/Public/${version}/ucd";
-my $scripts_url = "${url_prefix}/Scripts.txt";
-my $line_break_url = "${url_prefix}/LineBreak.txt";
-my $word_break_url = "${url_prefix}/auxiliary/WordBreakProperty.txt";
-my $word_break_test_url = "${url_prefix}/auxiliary/WordBreakTest.txt";
-my $underscore_version = $version;
-$underscore_version =~ s/\./_/g;
-my $class_name = "WordBreakTestUnicode_${underscore_version}";
-my $output_filename = "${class_name}.java";
-my $header =<<"__HEADER__";
-package org.apache.lucene.analysis.core;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.junit.Ignore;
-
-/**
- * This class was automatically generated by ${script_name}
- * from: ${url_prefix}/auxiliary/WordBreakTest.txt
- *
- * WordBreakTest.txt indicates the points in the provided character sequences
- * at which conforming implementations must and must not break words.  This
- * class tests for expected token extraction from each of the test sequences
- * in WordBreakTest.txt, where the expected tokens are those character
- * sequences bounded by word breaks and containing at least one character
- * from one of the following character sets:
- *
- *    \\p{Script = Han}                (From $scripts_url)
- *    \\p{Script = Hiragana}
- *    \\p{LineBreak = Complex_Context} (From $line_break_url)
- *    \\p{WordBreak = ALetter}         (From $word_break_url)
- *    \\p{WordBreak = Hebrew_Letter}
- *    \\p{WordBreak = Katakana}
- *    \\p{WordBreak = Numeric}         (Excludes full-width Arabic digits)
- *    [\\uFF10-\\uFF19]                (Full-width Arabic digits)
- */
-\@Ignore
-public class ${class_name} extends BaseTokenStreamTestCase {
-
-  public void test(Analyzer analyzer) throws Exception {
-__HEADER__
-
-my $codepoints = [];
-map { $codepoints->[$_] = 1 } (0xFF10..0xFF19);
-# Complex_Context is an alias for 'SA', which is used in LineBreak.txt
-# Using lowercase versions of property value names to allow for case-
-# insensitive comparison with the names in the Unicode data files.
-parse_Unicode_data_file($line_break_url, $codepoints, {'sa' => 1});
-parse_Unicode_data_file($scripts_url, $codepoints, 
-                        {'han' => 1, 'hiragana' => 1});
-parse_Unicode_data_file($word_break_url, $codepoints,
-                        {'aletter' => 1, 'hebrew_letter' => 1, 'katakana' => 1, 'numeric' => 1});
-my @tests = split /\r?\n/, get_URL_content($word_break_test_url);
-
-my $output_path = File::Spec->catpath($volume, $directory, $output_filename);
-open OUT, ">$output_path"
-  || die "Error opening '$output_path' for writing: $!";
-
-print STDERR "Writing '$output_path'...";
-
-print OUT $header;
-
-for my $line (@tests) {
-  next if ($line =~ /^\s*(?:|\#.*)$/); # Skip blank or comment-only lines
-  # Example line: ÷ 0001 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
-  my ($sequence) = $line =~ /^(.*?)\s*\#/;
-  $line =~ s/\t/  /g; # Convert tabs to two spaces (no tabs allowed in Lucene source)
-  print OUT "    // $line\n";
-  $sequence =~ s/\s*÷\s*$//; # Trim trailing break character
-  my $test_string = $sequence;
-  $test_string =~ s/\s*÷\s*/\\u/g;
-  $test_string =~ s/\s*×\s*/\\u/g;
-  $test_string =~ s/\\u([0-9A-F]{5,})/join('', map { "\\u$_" } above_BMP_char_to_surrogates($1))/ge;
-  $test_string =~ s/\\u000A/\\n/g;
-  $test_string =~ s/\\u000D/\\r/g;
-  $test_string =~ s/\\u0022/\\\"/g;
-  $sequence =~ s/^\s*÷\s*//; # Trim leading break character
-  my @tokens = ();
-  for my $candidate (split /\s*÷\s*/, $sequence) {
-    my @chars = ();
-    my $has_wanted_char = 0;
-    while ($candidate =~ /([0-9A-F]+)/gi) {
-      my $hexchar = $1;
-      if (4 == length($hexchar)) {
-        push @chars, $hexchar;
-      } else {
-        push @chars, above_BMP_char_to_surrogates($hexchar);
-      }
-      unless ($has_wanted_char) {
-        $has_wanted_char = 1 if (defined($codepoints->[hex($hexchar)]));
-      }
-    }
-    if ($has_wanted_char) {
-      push @tokens, '"'.join('', map { "\\u$_" } @chars).'"';
-    }
-  }
-  print OUT "    assertAnalyzesTo(analyzer, \"${test_string}\",\n";
-  print OUT "                     new String[] { ";
-  print OUT join(", ", @tokens), " });\n\n";
-}
-
-print OUT "  }\n}\n";
-close OUT;
-print STDERR "done.\n";
-
-
-# sub above_BMP_char_to_surrogates
-#
-# Converts hex references to chars above the BMP (i.e., greater than 0xFFFF)
-# to the corresponding UTF-16 surrogate pair
-#
-# Assumption: input string is a sequence more than four hex digits
-#
-sub above_BMP_char_to_surrogates {
-  my $ch = hex(shift);
-  my $high_surrogate = 0xD800 + (($ch - 0x10000) >> 10);
-  my $low_surrogate  = 0xDC00 + ($ch & 0x3FF);
-  return map { sprintf("%04X", $_) } ($high_surrogate, $low_surrogate);
-}
-
-
-# sub parse_Unicode_data_file
-#
-# Downloads and parses the specified Unicode data file, parses it, and
-# extracts code points assigned any of the given property values, defining
-# the corresponding array position in the passed-in target array.
-#
-# Takes in the following parameters:
-#
-#  - URL of the Unicode data file to download and parse
-#  - Reference to target array
-#  - Reference to hash of property values to get code points for
-#
-sub parse_Unicode_data_file {
-  my $url = shift;
-  my $target = shift;
-  my $wanted_property_values = shift;
-  my $content = get_URL_content($url);
-  print STDERR "Parsing '$url'...";
-  my @lines = split /\r?\n/, $content;
-  for (@lines) {
-    s/\s*#.*//;         # Strip trailing comments
-    s/\s+$//;           # Strip trailing space
-    next unless (/\S/); # Skip empty lines
-    my ($start, $end, $property_value);
-    if (/^([0-9A-F]{4,5})\s*;\s*(.+)/i) {
-      # 00AA       ; LATIN
-      $start = $end = hex $1;
-      $property_value = lc $2; # Property value names are case-insensitive
-    } elsif (/^([0-9A-F]{4,5})..([0-9A-F]{4,5})\s*;\s*(.+)/i) {
-      # 0AE6..0AEF ; Gujarati
-      $start = hex $1;
-      $end = hex $2;
-      $property_value = lc $3; # Property value names are case-insensitive
-    } else {
-      next;
-    }
-    if (defined($wanted_property_values->{$property_value})) {
-      for my $code_point ($start..$end) {
-        $target->[$code_point] = 1;
-      }
-    }
-  }
-  print STDERR "done.\n";
-}
-
-# sub get_URL_content
-#
-# Retrieves and returns the content of the given URL.
-#
-sub get_URL_content {
-  my $url = shift;
-  print STDERR "Retrieving '$url'...";
-  my $user_agent = LWP::UserAgent->new;
-  my $request = HTTP::Request->new(GET => $url);
-  my $response = $user_agent->request($request);
-  unless ($response->is_success) {
-    print STDERR "Failed to download '$url':\n\t",$response->status_line,"\n";
-    exit 1;
-  }
-  print STDERR "done.\n";
-  return $response->content;
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.email.addresses.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.email.addresses.txt
deleted file mode 100644
index 84062cd..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.email.addresses.txt
+++ /dev/null
@@ -1,427 +0,0 @@
-=========
-This file was generated in part (i.e. without the email addresses)
-by the random text generator at:
-<http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-rosalixion-word-2gram&paragraphs=20&length=200&suppress-quotes=on&no-ads=on>
-=========
-waist and Wintja are relearning how dJ8ngFi@avz13m.CC we spread out, but it
-here before, our dimension of story. In Bed and Marys opus in the last thing
-actually having difficulties moving, Spiros rises to our hidden on your
-<JCAVLRJg@3aqiq2yui.gm> orders, my love: Im seven doors and with gentle
-fingers, then disappears? Whats the idea <kU-l6DS@[082.015.228.189]> of
-<37layCJS@j5NVP7NWAY.VG> the "%U@?\B"@Fl2d.md pages blowing to appear on Earth
-in motion (what rules did we can take a radio changes. A VOICE: Hes a
-scoundrel. VOICES: Burn him! Burn him! SPIROS: Want to team of the couple is
-the sweetest love aH3QW@tw8uo2.eu of the teaching teaches members to
-communicate with time interplaying and linked and you marry it. It will leave
-Bvd#@tupjv.sn the logic of it from hereing those people were all
-SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt the
-artist stray? Does a few rose doom the UFO with my dear Sissy says Sissy,
-holding hands up a bit of DvdUJk@61zwkit7dkd3rcq4v.BD fate falls asleep. When
-an internet age is ~+Kdz@3mousnl.SE currently working with his bedside table,
-and brings in a shimmering timeshifty verse vortex, the dream. Victory is
-hallucination, my hand for more. Mmm my head,
-C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY in five. (Spiros waves goodbye to tell
-you, honeybuns: The poisoning is, but no addresses. A message identical reach
-across the script. }0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM I grasp hold their
-flapping wings and when theyre seemingly infallible information? Bookshrine of
-a sip of defined the Great Horned Goddess of no feeling.) Meaw. FFIANA: So,
-darling. Dont be dry white and teases him back
-lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae in society not speaking, giggling
-V85E9Hx7@vpf0bs.bz in MGBg2@7F3MJTCCPROS8YETM0B4-C9P7WXKGFB0.RU the boring
-f***s! (She leaves and Him Lover, Outlanders. Plus Universe where better than
-they just the land any letters in the gods. Expected, this at the threesome get
-even touching myself. rsBWOCJ@lYX0SILY4L53Z3VJPSF6.pwrawr.vdpoq.nz He picks
-dIyLrU@9A40T2ZIG7H8R.t63.tv up at our harem world 6dAsZKz@d33XR.IR so pop up
-you will be gathered, then Wintjas hair; smells of the manuscript: Contains a
-EnqCC@2bk6da6y08.LI common AQ9yV@Mfqq32nexufgxzl4o7q5jv3kd.lb universal within
-this lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H web.
-b6/zomNkV@8jwm-he.IN The
-5FLuakz.hXVkuqDt@iBFP83V6MNI3N0FRWJ9302DS-0KHRV6O.1bf59kj64uj5b6e2zfn.cm cosmos
-is filled with soap bubbles. <RhIwkU@58vmet9yfddpg.3adkmhrv1px.AO> I cant
-concentrate with a nearby and he nEBk6w2Q@Bb5ib.2pay.so pours.
-<AlW5CMAn@qos-53u.j91qq96d4en129szf7099kxv5lo6yo.gm> Its a wine with the joke
-in the only good enough! It hit again the house. He thinks of terrorist, this
-water. They were in verbatim rewritable. World by a quick eye shadow beneath
-the stairway; we not easily counter weight, is filled with your own perceptions
-about it. (Eve, how to talk to you really turns on its physics. The lover on
-the sunflower in worship of the? (She smiles.) Greet
-<QPYBDV3.Ah/h8U@x3v444pzi.1cvgokam.PW> it makes sense$A!-(B Not really,
-5Iwbiq7@p9s-2pixps9jwzyhfroxqivw8sv90r.xn--wgbh1c from up in the candlelight,
-denser <AaFU9L@3yj1xqf1.cz9.ac> medium to say something. Shifting of that
-|iCmQ1@rum6w0a7wt.3QLD.ht71.cx the eyes and there came. And now, approaching.
-When the thing. What did I woke up the printers! We EhLTUjo@rEK.sJ44H0.GR shall
-we are heard like a glimpse of hyperspace. It travels further and kneeled down
-bHEbq3Rp@33.lKSSMY.9xaurtfle9xe.iu4810l.fj to you can walk away? FFIANA: I want
-to eFcup.cPPEW@[1ae] speak. The Fountain of the background when I extract of
-hers, so strange book and a royal destruction of songs of this pearl. Not often
-by an incinerator vessel. Spiros, the delivery of alien exists now. Forward.
-The rosy guidance of wine. Notices that is partly the pipe
-p907@bk3o.fvtmw2m2.Uutr83x2yt4.2nuin.EU of the chance in Old Town. D Strange
-music keeps one of the top of myth and smiles.) SPIROS: Nope, cant even
-PpW2L5.QgP2n@9rz7.a5qi.oRH1Z.8ov.UZ more! says it doesnt exist! The world in
-the cosmos loves us. (Spiros soon
-o8UgG5fewm4vr9Ai5wPS@sgh.2F-OLKLZ81DIUET.xpya0vtx.fj here again aixQH@z-y.AR
-and again he turns and blinks with you want? says Sissy looks over Wintja and
-the fashions of Fit to Spiros continues. Its a situation of the barman says
-Spiros. I read the river. SPIROS: Damn I said. 69
-<jVTeWQfL."M#~t Q"@1e.oglq.ubk.SZ> he kept locked up into a suitcase along
-her body, points a female voice of 6e5QQuy@N7.2cuw3x2wpddf.paycp1pc.AI their
-part of flowers, and Marys opus IqG6Fl@[220.112.120.54] in my PROSECUTOR: Hes
-<lWHH4eWSn@tbxyb7.jhzqxrk.lv> one is <P1zO*RaAr@[111.99.108.22]> unsafe at a
-little <d00gy@[4TC]> secrets, we made to write: And a drink of Eternity,
-Speros, <1yNINoBU@[136.003.010.238]> Mr Boore, back to me! Lovers break
-Ms8ox@[_3Tuehr] the code so
-<8'Hk8a@ksf7qqaa7616xw8dq80h.K6fy89c.3k-8c.g58m48v-18zh8v> recap.29 28 So,
-darling. Dont leave each itself, on and devotion to all about time
-<wtWDNo@1sjmcbbli196-765mt7m8o8hywft.7-ga6rsnum8v.np> has happened? ANON 4593:
-What the tongue Such as she did you back and the whole moment in
-<"x)yO"@7le5o2rcud5ngs.Qmfmq.Jfxv8.Zznv6t6il.MIL> your own lens, thank you
-1hXd@f8.1kxqd3yw4j6zmb7l7.US arent already. It tastes them have ever come come!
-The tomb. Blink to him and flips to it, but the palace. No
-"8}(\$"@mu2viak0nh4sj5ivgpy1wqie.HK way$A!-(B Happily: You smell of it
-all and yet sure this pool Th7XoAs5@ggdb.BI of the first of his
-5iDbhah.xdtF1x@[59.55.12.243] heart j2ovALlgm2Wcwx@5jphzt.TN can take to the
-wind, speak to apply perfectly, you say turn toward sexual nature and lays his
-ZlaP~E.4Yk1K0F@lF6VN.M5.Nj.PRO pipe. No, landing from
-cFCvIJAw@l93H0R1W6V4RI0AY7RLRQR4KOEVQPEG-PDTF03V4D9A0.xZZK5.lu the fruit will
-say. -F�Dont talk like the west 8Ju2AW@1n.h7.vu wing of the letter in every
-second, <"\nkP]{"@[Vej\yo\HD]> but he slipped in. Yours Spiros and there
-when I imagined anything can take returning? <fKWC?@qgcb.xn--mgbaam7a8h> Where?
-With? Who? Going toward his body and kisses the notion that has joined odds. A
-scattered around <L4BbaB@hv1.BIZ> slowly, moving eyes on and
-WvSmV@qpx15vzmbtxzvi-syndl1.ML turns toward her. She sips some way everything
-began was finished my wet Earth. Warning
-"3|PX~Cbdq"@U3vp-7k.8c4q3sgpwt6sochundzhx.museum for me.-A City Different.
-Let your myth LjH9rJTu@tkm.gy settles over it
-<8myMO4@hOV209VZ-SHGBIH5FBYLTCQZSBW-U5-1.dv9> means to Our of a book he has
-only but <vQgXEFb@maxmrbk-5a5s6o.6MZZ6IK.awjbtiva7.IL> the imagination, master
-phreaker, <5ohpA3ww@dcpcotwccy> main railway station. Loses the dreamadoory in
-the surprising success.) A note from round is her splendour in them? Mmm my
-dear, were 6TVbIA@r50eh-a.la from them keywords. Boy,
-AaASl@Bsteea.qHXE3Q5CUJ3DBG.S2hvnld.4WJWL.fk my own imagination, master
-"CN;\-z 6M"@86.qc7s.23p.ET is the usual fashion, says to stream and appointed
-space-time continuum. Dilutes your zX3=O3o@Yjov.7g660.8M88OJGTDC5.np sleep. Ive
-been seen, he says the ringnot we proved? (On the pact. Thanateros is an
-internet caf� where the Queen. Now cmon, lets take to raise the apartment. Like
-a limousine and I kiss timelord slides his hand QFZlK1A@4W47EIXE.KY in words
-now. Get us in the same time conceptualisation is to bed. STEFANDIS: Dont do
-you think Ive put down the green lush. She often by God of a 15 minutes. The
-others knew into the 1guLnQb07k@ab.ccemuif2s.lb you-know-what. Youre the luxury
-hotel. Diamonds and receive the process of action. We wanted in the nominated
-bird. The <Jddxj@[111.079.109.147]> woman undressing. He has him just get at
-Hotel California. Its <Hj06gcE@[105.233.192.168]> about all devices. Playlist?
-Initiating playlist. Timelock? Timelock on. We have a u8?xicQ@[i\21I] lock of
-the apartment. Like a kto, part of Our superhallugram to hook up and
-CczYer}W@bezu6wtys9s.lft3z.mobi outs. polish
-OmpYhIL@6GJ7P29EIE-G63RDW7GLFLFC0M1.AERO fills the crowd, comes from the music
-is impossible. SPIROS: F***. You are your voo goo.
-<2RRPLqO@8lh0i.vm7xmvvo-r5nf0x.CY> Daysends burn deeply and will take
-TOc!BhbKz@F-myy7.kQWSUI7S3.net this he thinks. For UFO from elsewhere. Bzzz!
-Bzzzzzzzz! Bzzzzzzzzzzzzzzz! Tell them "0\!P?".shQVdSerA@2qmqj8ul.hm the leg
-of LTLNFsgB@[191.56.104.113] all, until it has read it is
-iT0LOq.jtPW=G06~cETxl2ge@Ah0.4hn72v.tQ.LU there. <VGLn@z3E2.3an2.MM> Once
-TWmfsxn@[112.192.017.029] Spiros under the place
-2tP07A@2twe6u0d6uw6o.sed7n.109mx.XN--KPRW13D as were not a house of the
-rosebushes and the whateverend, feel her waist. She changes everything. We had
-decided to do you know CjaPC63@['\RDrwk] this, is what did leave, pray; let us
-come to, <Ayydpdoa@tdgypppmen.wf> what history as died. Strange, Spiros with
-delight: That night "gfKP9"@jo3-r0.mz and gold case
-<aTMgDW4@t5gax.XN--3E0B707E> is spring: the aeon arising, wherein he returned,
-retraversing the mcDrMO3FQ@nwc21.y5qd45lesryrp.IL gates, first
-<NZqj@v50egeveepk.z290kk.Bc3.xn--kprw13d> to reach session. Initiating first
-part of the main hall toward his own spurs. Hes an <XtAhFnq@[218.214.251.103]>
-Irifix And older ones who wins? ADAM: x0S8uos@[109.82.126.233] The violin and
-reality. The hidden set up to come. ROSE WAKINS: No answer. The
-ALB4KFavj16pODdd@i206d6s.MM rosy pink cigarette.) Visit the supreme chest and
-express in orgasm, my version of clouds contemplating existence, the horizon.
-Best grxIt96.46nCf@nokjogh2l4.nCMWXG.yt of sheer emotion. Spiros laughs. Why
-did he says Spiros. Ban him, he called for it, sir, says Spiros
-Fgbh7@2rxkk0bvkk-v3evd-sh56gvhxlh.hhjcsg36j8qt98okjbdj9z574xdpix59zf6h80r.Gyb4rrxu.ve
-laughs. uo0AX41@Fhlegm1z57j-qvf5.p8jo6zvm.sc Can we determined that when I am
-Spiros, quoting Jim Morrison. Death. Design patterns, youll hear Spiros says.
-They cant G decide if he was your key that we playing? SPIROS: Why wont xxx
-would be imagined. Technology so beautiful to fill his diary; I like a match.
-Puffs. The Star Eagle. And a person with a play with. sjn4cz@9ktlwkqte.bv
-Faberge can change overcome your work, a large-scale coordination, Goddess say
-is blasting away to end is <b04v0Ct@[243.230.224.190]> very tricky to stab it
-as a turn me to the champagne on your obsession about his nose and
-F!FUbQHU@uvz7cu1l.ciz4h2.93U4V.gb somewhere <6CHec@nONUKT.nl> else, then far
-stretch. The great outdoors), puffing dried cum on the manuscript I$A!-(B O
-one knee, feeling and sex in igniting <zbmZiXw@yb.bxxp.3fm457.va> bomb. (A
-housefly, Musca domestica, lands on into the device. Let me met. Wintja and
-victory. <"/GdiZ7f"@[221.229.46.3]> For years in tipsy bliss. SISSY: (Nods.)
-Yes. Now you witch. And we must remember, will tell you move but her
-NJde8Li@f7a.g51VICBH.cy creation with gentle feet, naked on strange hovering
-futuristic vehicles that when retrieved upon a thought, or reflected. The Crew
-coming on our gratitude for you address then ventured into a dream, has begun,
-she sees a 6IeAft@e-3fp.Nkh7nm8.v8i47xvrv27r.pf golden ball and 4 If you that,
-Izz). Lapis, to the return all laugh. Applesfoods maybe, says
-TC*Qopzb@xIOB3.6egz4.m-24t5wmxtmco4iy8g91o66mjgha1vjlepyffott.E5ta.p9.CF She.
-Cmon I Stefandis.) Count me with a bed sheets, carrying gently away about time
-you rather dramatic, which reaches across this day. It brings forth between
-suns. How about the white sugar, leaves, sugardusty sugar, drinking of time.
-Believe. There "_3Sc_"@[193.165.124.143] is the soul, W0dwHf@[25.174.65.80]
-and only Spiros. Love you. Believe in the multi-leveledness of the 21st century
-and exchanges a book called Sphinx. Alien Star qPkkP0@4k0vs.oaak2z.3JMTI.PK
-initiated. NYKKEL HUMPHRY: Of Make ways over town.) SISSY: $A!-(Band you can
-turn slowly but not yet audible, appears, XzZh7@[\\JmD%U] in the silver
-melt together. This way of vision sees through time). Brewing with a kiss?
-<66SGHzw@Oqnr82oml7jct0b8crwbstdhcgc3khxj7dj-t898mzro0p3-rvp-dythh.TN> Her
-feathers: streaming water of the wind. I started interacting in a boat, on
-ot4tPF@[AY\j] her e4seIFbl@cib.cg thigh as she blinks happily. Here is
-<B2w025e@r2H7BW16B24DG1S5DED.bg> what you around him, Magus says the list. Its
-about what that atweEde@blk-3y.mgvoh6l9my.F6.FI there is functional. We
-vanished into the computer. Up hills and enable entry using his long adventure.
-Do we are all detailed trip against decent behaviour and girls. And you
-alright? You evil laughter: Muah! Muah! Wont wate you all uDoPcRGW@rEBD5LUT.ly
-way that there <2KQhx@Bba.u--9b5bc0.NF> is either both night And our dimension
-of a bad joke, says nothing, just after time. It was indeed. Now that will make
-the streets. He instable? What shall do. tKWc2VjVRYD@[254.190.162.128] Who
-wc3W16^@D3v2uxqqeclz.w1fd529m.DM are heard like our love. Of the stairs too,
-usually through the note nearby and you go now. If I remember Njg@6S8MA.HK how
-it instead. (She chews the rosy petals, frosty and the land at first part of
-waking? That we "L\^4z]92"@0qp--walx.MIL like they meet you.
-<X08sWFD@62GNK.tN4.f1YXX.ug> And out into the bed. From the gods have loads of
-a dark winding stairs and laughs. Why doth Her devastatingly good eyesalve, to
-tell it says the Rosy Dawn. Rising, rosing, the story? (For all the UFO
-shimmers from around him, but we look before eK6Bz1Bu@[rX;J&036] the Eternity
-we shall never go now, look, he thinks, both go for the words said. 69 people
-who live in Thy honor. "~`o\:"@hO4UKF.oZBWV56B.cmn.DJ And
-lcgUakx@[pjGd&i2] here and his life has tasted of becoming more clearly. He
-is dead. Calculating possible meanings of it instead. BqdBTnv3c@wf35nwaza.ME
-(She whispers, smiling.) Theyll be able to help. ELLILIEILIA: You are created
-the visible "a#Um{:\'\bX:"@in7tjo.uw8wil.gp world, without it will see now,
-says Spiros ApIbER8'@[&Y] thinks. Every time and go to write fiction. Indeed,
-love something I pop, from the play? asks JTsM0c!s9CzEH@Sd.mh the taste of the
-outrageous wreck of dream, born and there
-hy2AOUc@uqxzl7v0hl2nchokqit9lyscxaa0jaqya1wek5gkd.NC was still result. Search
-taking <pY7bAVD4r@[,>T*R T]> out into !0axBT@03-gdh1xmk3x9.GH my dear, you
-know, of saint? What did come here from the Crowinshield Garden, amongst the
-warm kiss. Everything is white marble statue he is tunes faberge intricate.
-Spiros, a particular frequency, vbtyQBZI@20al5g.ro6ds4.Bsg15f5.NU spinning,
-trying to a trail of the narrative that it while the Queen, giggling: What are
-a letter with a web we could 2^ZhSK-FFYOh@Z2iku.rg.Z0ca1.gs not a
-G1RLpOn."yfJpg["@mXEV8.mu peculiar yrBKNkq@a2a1.Aifn.Ta2.dj stench of history,
-when appearing in the interface as well as follows the secret I am not
-teleframe the room, disguised <Wok5G@b5aqobvi5.ni> as the brilliance of the
-pressure of the modern world, but
-nXz9i.=EL9Yj@93r8do3ntizibg1-5-a0ziw9ugyn4bo9oaw3ygrxq-eczzv1da6gj58whvmo2.rs
-whatever. The solid concrete, Dp63hd@B1kbahyq.PL and put it stumbling or why
-wont the chalice with communicating with language only she says Spiros,
-whispers.) We left from the second birth? The young man is part of the teapot
-opens. A man in disbelief.
-y01rn27SFq@o0HNP8.C5.i4rvj8j338zgter7er5rkwyo5g.atnc0iuj2ke.8or6ekq0x.IO
-Outwords scratch skills against her in fairy gently
-<0RiEo@08mnvbu.p661ernzjz5p7nbyix5iuj.cig5hgvcc.SO> bite of death and Wintja,
-playing with the name by <Dwxab5@1sx5y3-umsy72nl.74lwye5.DJ> your dreams. He
-arrives <IvdZVE4xRk@0vw7ajl.AR> the information. He swallows all the f*** me
-tell her wineglass and tangles. Synchronising <CvQxhXJ@d5a7qnx.ke> weeks of a
-reason why everything seemed as wet dreamery, remember? Got a purple Ipomoea,
-crawls through the first stage has the riddled beginning to her in a butterfly.
-You landed smoothly. Preparing to n7MxA4~@[4(R] hit a world is man. How much
-in <hEhF@3TV5WQ.fbkx3f> mystery. And RFGzu3hD0@wbh4.sm furthermore, what the
-edge of physics, death and eOADW}BcNG@2568p3b4v.Xq3eksr.GP touched smoothly ah?
-Fashion feasible technical population resulted distinct produces
-AsAMWriW7.zSDQSAR6@Gg2q4rtgr.GG recognize instance the room at the garden.)
-PERNELLE FLAMEL: (To Mrs She is basically very drunk. I see you
-<cDCVlA0t@[20.116.229.216]> cant I walk down naked on it to bed bed into
-c=yJU+3L5@n2x3xhksf.gvreani.MZ the stairway wfYnaA4@lzojy.4oii6w6sn-p9.kh and a
-kiss as though the point we see the numbers, the phone set to be displayed,
-disincarnate entities can feel my wifey. Spiros empties the answering evening.
-That is kdeOQ5F@vD5Y.wmmv.7rswz.1zelobcp5qxxwzjn.fOEJZ.KM simply not but I
-could do to the ground, and the decanter ppULqb2Z@Hv9o2ui.AO is my friends and
-says: I <tOHw@[IPv6:3500:8B6C::CB5E:1.124.160.137]> see The elves of dream
-telepath posts, but makes a gentle people with a redirection is generally said
-Tadeja. Its over, or of ages, you excuse us walk off to Talk A never-ending
-one. I remember how cute she saw the neat fuse weds sexiness. A thick paperback
-book itself continuouslyposition, have heard in the noise We are presently at
-the first of the death MWLVsL@7nhliy.O8mjon3rj-kb.t8d6bcpa5i.au mask there is
-accurate to meet by to this important worse material in separate directions.
-Spiros stands, and arrows and orange from a witch and down the mix? he feels
-Wintjas 13th century. arling peach, cosmos loves playing with silver trays with
-the <BN0EY@hh9v.p9bwgs.TN> language as RgiAp@d9ln.bf I still result. Search
-taking time and time <PBugBo@97gcz.DJ> in time. Spiros, how else or
-Fh#dKzbI@[+_] nonexistence. Eros never guarded the horse stops. Move. Stop.
-Move. After earlier squads mysterious source. It inscribes in case you are
-applause. The world was a. With swiftly cover <wyqU-C9hXE@wPRBUI-WS9HXE19.LV>
-it as in yourself! 5 Yes, now comes from half walls of us, my love. I am your
-vast operation is all worked out? O how long ago. It glimmers, node of the
-voice, the middle of the introducing of utter hell on the car unlocked and mind
-around midsummer and not believing in <muC?Js@[IPv6:47FB:5786:4b5e::5675]> his
-lower lip. From the wind say I was inspired to live in a crime. I know, and
-find people have been reported found a digital electronics. Is the pillow,
-touched falls down their part of the computer and our world
-<yLTT2xV@wdoszw9k1ork-z-t.kq.l3SEO.Lb4jx0.NA> come walking in
-<6zqw.yPV4LkL@dA3XKC.eg> the stuff to help. Websight. Dedicated hosting
-wordpress blogger coined Sister <S5z9i7i3s@Vzt6.fr> short Sissy Cogan. She
-answers. It is finished his way that includes getawayways. Compiling focused is
-this case? Then turn on. ANON 4593: What are pretty kinky a story about the
-L|Sit6s@9cklii1.tf strangest child a Syntax of passage and Wintja and
-reportedly after demolition, decay, and twists up to tales endwhere. This way
-there to born from elsewhere. Bzzz! Bzzzzzzzz! Bzzzzzzzzzzzzzzz! Tell them that
-words from sleep but no poet yWYqz@mw-9k.FJ am I woke
-Knhj419mAfftf@R26hxll64.3qtdx6g.AL up in a kiss made it is heard on Midsummer
-our cards like big fane beneath the secret of the <aZYHUr6@Shyn76c67.65grky.am>
-criticising crowd of the gods and here to... TADEJA: (Suddenly appearing in
-ZYxn6Px@di0cqhtg.hu your "#mLl"@w1sc0g3vm.j1o4o9g.GW voo goo. Daysends burn
-deeply happy, for large bite of his artistic inspiration without feeling as the
-season. One within the dreary WYJcFp@653xk-89oprk2im.iemhx9.CC kingdom. (She
-steps up with Christine says. The Blooming of y5AXi@[Oa #] The time regularly
-we are, she nZErAGj@6sq3-p.r8KQ.aero kisses the gods? I am in his brother I met
-years ago. The word <OMq5sBK@udg-5zp1.Dory85.SG> is because we had. But yes
-just like a while. Were not matter; W it going? Im sad to
-<2bymd@Ojla1hvfpw8rrihrx.cy> where he arrives and information, and smiles
-victoriously. 5OMbw0@r2d8cn75.1VR2BJ0J3A8PY.gc0mljc-h.COOP Mmm, you Rudy. And
-there and day soon is phone and come <al6X^pQkx@pyj--2hp.lbet.TN> back?
-Rephrase that we are good, I leave the gifts of html or center of her right to
-him to where the room.) SPIROS: Okay, sure, Ill be a page is to
-NkzPW4f@2-0.aaoqccwrgi4olytac0imp6vvphsuobrr115eygh2xwkvzeuj.tl put in a novel.
-I want two. "4-b9|/,\e]h]2"@9-iiahsdlzv-v65j.FK Passing
-<1AhBt@od77y.s9ZZP531YKW> now. I go identify what we are always win. Anyway. I
-know. It is here reaching your script and toward the edge of shortcuts. We came
-the Saussiepan and <g8Pv2hb9@[166.176.68.63]> its mysterious ways. I remember
-"IA~".Tn03w7@[\>J?] how am waking to, that the secret about it will say the
-redpurple wine, Our plan all within this moment you can hear me, I heard on the
-clouds. A channel is hidden visible world, without ground turned real, their
-every E6aK9TaJ@j0hydmxhkq2q.Svku4saky.MU way to a radius of
-rdF2Zl1@9fsic.C17pw9o0.vn apple tree and says Spiros. Here I saw her. He walks
-by the landscape of secrets of paper. I love it! But I could call the
-<pCKjPa88DG&x5a@4ha07ia2jk.xk7xe8.PM> world with the manuscript I$A!-(B O
-nothing. Im proofreading the most dead branch in qgLb5m@nynqp.DE the screen,
-then I did you can remember. qC731@["\S] (If you can it completely insane and
-we had expected something our sacrament. We were back. Esc. (Shuffle.
-Hallucinate a sip of grandeur, said he suddenly a tree, and ground turned out
-the publisher. O about it all. Lets
-<vIch1nT@[IPv6:4c2f:A840:1788:ad5:C2C6:dfae:1b1f::]> stay with us. Mooneye
-today and thinks and check
-GVSMpg@2YGZ1R19XTW1TIH.Re3vg30u1xq6v7cj1wf-6m14939wvgqbl.93mztd.SG the modern
-world.) Sissy stands sipping redpurple wine) and you
-0jq4v7PMxm@eq6teog.kO6LR3.x2p.53yltrsvgpd3.RO up to be wilds. Spiros 99% dead.
-Calculating fastest and chewing she directions!
-zdGLZD0P@i2JQNM8.816oja8pkk5zkvyx.KM Take my body and executed with your own
-forehead, born from Egypt come back? Rephrase that what is the night. There is
-here. Cant you think. And shadows Jp#hSH@74zkerax4.31kr.7c9-yuk.mp keep
-dreaming of letting the elves of modern civilisation? Does that fly softly
-through the surface. Of the modern world we must Kx^0oZn@oFFA-URZ13B34J.DK find
-sub52@aoq7.iHF.CH them, baby. Rosy Dawn. jfVSq9oAR2D@iGU0.7bp3x.4cr.sz You have
-become clear edges. And why you told our skin and
-nalgU@Yfpbdcv8a5.n9kwz6kyi2u.thic-rws.af.TG places, spread on your air on her
-earlier. The effects will be the song by and his eyes are gods. Expected, this
-pool of illusions, that makes its golden geisha ball on Clocksmith Alley. Two
-female form orbits the two chords on a god, in correct dose to see a book.
-JOEL: Spiros thinks as he felt, came out out! We are switched in the matter. I
-shall I can imagine the Crowinshield Garden the aeon arising, wherein he once
-again. You suddenly changed. And the rose; Will you? Now listen. (She smiles.)
-Greet it comes everybody. And what the room, disguised noise We are you in 3D:
-you come. ROSE WAKINS: =uC5qVT@56g530cltpekrw.pt I used to read it: Barbapappa
-(a gay pirate captain) <QR5&kx@7qhi3bhav5ga0eva.b0sdom.bb> and walks up again,
-when you are here; working on to. 8DZQ7@dtr16r89fdw59q.cf Now join you? Im
-slowly in white <Q4pNw@6o-9weojl3r7.LS> bed and language whitespace
-sensitivity, readability, less punctuation, etcetera. Things had to the Dark
-signal has him with gentle blood on to the ages. Stops laughing. Sharpens eyes
-from the *mfOc_CN@[G\3] starway, Down the uniqueness of the bed
-2p`tbG@c767inolrav0hg6a-ucs.y0.tw and Rop{cgBy@Wekdh0xns2um.UK giggles. Spiros
-soon here for ignition of the thing Mr and fetches her t*p05lV@017y.MR you hold
-their own code. Your brain and Nora in longer. Stay tuned. We
-7ZxO80@Dovepwr4l.qxfzchrn1.es8ul0vavi6gqy82.K1hc7.INT must marry me? Eyeglance
-is is not hear. He takes a good marijuana. And I had very fluid. It cant G
-C_Iphp@5t4rtc.id decide long hair shaved like a while. I have telephones and
-waited. He sits there is humanity within its authors and snaps a touch
-q+m2x@Cfw.1tm52-kr.BO it candlelight tuning. Just a young man go to the
-ad-section.) 47NIL@Hl68os0.66l9bsf2q.SC THE F*** UP. Spiros slowly. Lets rock
-on his father and remember: the sea soothe his paternal grandfathers old days.
-In to the Honey Queen, xxx 14 hristytio (Ill catch us. Compliments always. Did
-you rather unnoticeably. Faster than we got this cosmos. The engineers of
-terribly intricate fantasy turned semitransparent, the people have done subtly.
-It is THIS bulls***? Count me Rudy$A!-(B Sissy laughs. Can we are breadcrumbs
-vi0LyF9O@p74jz6mxby.it on Clocksmith xQ4jU@rQVWLWAD3T8.4-lnu.AZ Your usage
-<zea_0Kr@[97.59.144.249]> of <5HP1k|s@[068.150.236.123]> being a shimmering
-green. 5XJZlmYk.3Du5qee@[072.023.197.244] Her feathers: streaming
-<fzQlo2R.HSbkNYi@ay8a5so81x2fgkt2rv> rays Wanna take AvNrIHB0@[+n}oV] a marble
-from the letter the brink of wheat from the dull ghost of the article atomrss
-am I? (He hangs up "!N7/I\zhh"@[204.037.067.146] dreaming? A PEDESTRIAN: I
-already told you than the world now, as vlJODxFF@xFO6V.i1.fgad6bjy.NO though he
-walks off the flowers. He lifts
-<qDe0FA@xpp1le82ndircjgyrxyzkrqu3il.oUKHVV6829P-16JILWG62KN.cr> his head we
-passed on a hint of the worldmask of the people we dance, sweet boy, my dear,
-matter of bridging millennia, I was it works, and Adam says: And the fathers
-pMF64@wssq6kh9uhxk.cA2YZVBV4JW.xX585A.ru that we are in this G3meE@[^!'OO]
-stuff!? The wunderdome. I saw "1@0UYJl"@vplkx.d2n.i3tcx3aaxut.lbb3v9.ldq.me
-your prophethood of the ones too far! iTH0QND@wg9sizy.lr Further! Into the
-planet. He sits on the Other. We came from Egypt to save our dear Sissy slid
-her earlier. Ill tell me away with bright asterisms sparkling around
-9kF?opSTo9rSDWLo&W&6@xrh32ibf.F0zb6kb.BJ in this young woman in the whispering
-wind and hands to speak, but using his <a0FI1m@1olkdpz.W70a3w8qmk3.NA> nose.)
-Nevermind. WOMAN TWO: And furthermore, what about the script, says the sun.
-Large-scale thinking of a witch? Spiros hears music
-<"0H}r}X(p\M`/x"@rY48LPH.Axy.Ue624.TV> and a world as well as a poem
-AQL6YBFb@Hxawb15okz.y4.y5c0e.bt ever, indestructible. A newsboy hands
-<PEaNVR@m8NH9BVX5L096DRM7YTR.er> Spiros gives the drawing. Looks like to the
-<diI`Q@i5fpkuc.7zg2av.D6tzqq.CK> living out TCN0-Z@Tezeq9ejv.ekeab8hz14hui.il
-loud from the house. He is disappearance, as I know on the centre of your
-section gives rise from 05SnFh@jZ85JXZ.1RO99W5FYK3.uyv7g15.MP which it be close
-now, dream once: The stars
-<B2Z76Rn@9yce0shfsydxetu1v4-y.rBU2M0.6ik8oapv0zho6n653il25gu4rd216uw03.MG> are
-your vGZ2K@C2osgjtel5uerwn.riihbabhh41ve84.r3l.vH6S64.vn presence. UFO. You,
-Spiris, are born in Plomari. Steal back door, from his mother: Is it to live in
-their doors are like, Nv2ZgL@[037.054.177.155] two weeks with
-WsdI2W@i1ULFQ1.79qfph2.eg us across his way to crack matter projected by four
-<vJfpTf3@Hh4x2h.25m0idq3.fr> initiated. NYKKEL HUMPHRY: Of <oRqbgftr@l6jg0.TV>
-the woman casts a drop of your amulets NiynsKb@k9BTX4-FV.hc0skm-o.lv and the
-morning light. Plasticity of the sun bursts can feel it, rises from lands on
-w9uGwf@4hop8.Jb9655is.nr the realization of his field of the branded mania.
-Spiros says a dream? Something happened. And watching the Other, she says Fast
-Eddie. Bandaging the greeter info. The Eagles song by the fragrance of
-Timescity Express, is there, by zero. -F�Your star alliance. SPIROS: (Quietly,
-smiling faces twitching in an envelope yellowed by It, producing open minds.
-This mighty Nile dynamic magnetic strip that sticks). To Ellileilia, two
-fingers with the moon undersea settling for "NVUW+"@6jbe.KM insanity! He
-rises from the QusHU6JMR@0RXKIZNH76C3.Oqwcfr779e.MH end of wine ride the Logos
-and the cosmos loves <}C5IwKv1S45vlmPaaVHhF@[IPv6:EBF6::]> playing with care of
-myself up pitch/volume of a violin. The rosy dawn, Adam says: The transforming
-magic touch the waist, working-A transparent, yet its not easily let us
-changelings who all across Fountain Square where no telephones ring? Spiros
-recently. MARY T7rXlYc@4AI1LM.2o.uk BRISCOLL: What if
-uuCiDC6c@Maar3.65hlg-wf.t3pt9.FJ I w2mNOvIUh@dx3ep7ew.ru dreamed of a new
-dimension of her in Wintjas direction. -F�Word frequencies, underground river,
-announced on your location. Thought b#Add@9hpopo.Xg3tbjchdpt.TT magic. The
-violin kept talking to stab it was born from our own life as the dream I was
-practically there I want to smalltalk about the station, and so recap.29 28 So,
-darling. We are truly is. Its on Crete. On a curtain in a copy of the
-<NtrgJjfj."NBwi"@[142.085.096.018]> afterlife, the grass and the lovers pot!
-Transistoryness? Radiosyncromatics? Syntax of the modern world The mirror at
-<00lF9UB@2NR2.rs> the day soon <MPr42ye9@p08lcrzs.4bzxfznsh2bhgsa.CX> there,
-doing it will you will be disclosed, says Saussie. Become the future just
-happened? Spiros picks it at the time transfer was
-awwLoYLn~c2LfTEVT@fwksx.qoj94r11kw19k50k3.gd successful. Initiating first
-somewhere else. Its from gRZ5w9epm@p6adico3auugj5qklec.Sm4bx5.li the
-imagination, Spiros saw the words: They cant remember yet? I add to Any time
-here, she says. Butterfly as a dark zfdZ67Y@1azhq.dl3xxzni2.rrj.lpclc6g4d.sl
-soil run free What do you see, is the natural radiance of death reports,
-<vTWwSD4fb@uBSOHD.3g.u3mb.gf> is welcomed. Layer upon layer of Thy angels are
-crystal. Red <cYFVxcC6E@F9g0b.n1339r.AU> King and its my opinion. You were
-back. Hows it with-A liquid purple. She looks at pnuXl@s1alo2.tc a man
-lKy64zp.Cbg8BM@y0S.6uiux8h8.0udipt.ma on with me. Say the beginning from the
-manuscript and |9FDgc@vbrz.3L.av4kmt.rs bare plot. Queen told by the redpurple
-wine back where we all be rather dramatic, which they had skcHAu7@xD715N1.DZ
-always <BfcgHK3@[220.136.9.224]> include Sir Nykkel Humphry, master of the
-inverse confine survey the rosy guidance of her eyes on <LCOEag@Gwm.drsa0.GL> a
-river here, to the latest of Sissy. He again set the old Egypt. He returns to
-the looser you ready? Y Were ready. Spiros qrNZtp3vO@a0gr.8j9cvcgy0p-3.HN says
-Sissy. Wintja sing: Ive put ourselves in him, he has taken a
-lfW2rei20XWSmpQoPY1Dl@[(N&c] third <J761x@0IKGVUDNQ.3xpb> person. Whats it
-will bring the room on the book in trees and WFBBEv|@q7R2J.oy48740.pm smiles a
-pipe he enters the chat room (The church music in comic book aside
-<6H6rPx@zVJ40.xgyat.cLUX6SVFJWMLF9EZ2PL8QQEU7U1WT0JW3QR8898ALFGKO18CF1DOX89DR.1tfu30mp.CA>
-Rosalias Dawn, pray, Man through ytG@J4auwv4has.PS concrete. Could we? Were
-taking over a
-<"X;+N1A\A "@rc9cln0xyy8wa6axedojj9r0slj0v.Luy9i6ipqrz74lm5-n6f1-2srq5vdo-opef747ubdykv5hc.2lztpe.er>
-hippie up the detail. Rain begins to being married to the designing of love.).
-Made myself a funeral. Who are created DQTmqL4LVRUvuvoNb8=TT@2up3.PY (Is that
-hyperspace at the merriest of us for that. -F�Christofle is heard
-NC0OPLz@kcru1s0mu.name him a huge and wraps if he find? He is or so much more
-complex than kBoJf{XaGl@[248.166.223.221] we are heard within the
-<pEjZPm8A@v956Y7GQV.5uu6.Ribgf20u.6e.0do1nki1t.ahy.6iy.sm> woman of The
-<pIFWkl2@w9N0Q.MC> mirror of p=VTtlpC@w3ttqb.FO dream, born from that we are. A
-VOICE:-A
-
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.urls.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.urls.txt
deleted file mode 100644
index ef5ad89..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/random.text.with.urls.txt
+++ /dev/null
@@ -1,1346 +0,0 @@
-=========
-This file was generated in part (i.e. without the URLs)
-by the random text generator at:
-<http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on>
-=========
-
-them under the looking-glass. It is fair whisker, and this so
-http://c5-3486.bisynxu.FR/aI.YnNms/ thick boots!' I might -- I don't deny that
-the appearance of sherry wine on
-ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R
-Joe <sJ5PY.b5t6.pn/> and then. But, there weeks together, be, or the moment of
-deliverance through the coupling don't know.' And now reclined on the
-http://Z%441S6SK7y%30K34@35j.np/RUpp%D1KnJH ceiling. There was bloody, but were
-my hair; so humiliated, hurt, spurned, offended, angry, sorry -- with their
-[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/ owner. While we went all the clergyman
-said, file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7 `Before the cold
-http://[a42:a7b6::]/qSmxSUU4z/%52qVl4 air as when I
-http://Rcbu6/Oxc%C0IkGSZ8rO9IUpd/BEvkvw3nWNXZ/P%17tp3gjATN/0ZRzs was company.
-At such a long `Well, boy,' interposed with this coach, in the companion
-file:///2CdsP/U2GCLT of a design for the state of one of mine looked all in the
-lies by giving the village,
-Http://Pzw978uzb.ai/yB;mt/o8hVKG/%231Y/Xb1%bb6v1fhjfdkfkBvxed?8mq~=OvF&STpJJk=ws0ZO&0DRA=
-and Joe recited this iron bars with their account, poor elth, and she had been
-almost drove me towards evening. At
-HTTP://173.202.175.16/Md7tF6lj7r/oioJ9TpL8/x%03PjXgMMBC7C3%BDWzoVMzH the
-sergeant and then on the raw
-<Https://yu7v33rbt.vC6U3.XN--KPRW13D/y%4fMSzkGFlm/wbDF4m> afternoon towards
-the terror, merely wished him as biled
-M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb -- a conciliatory air on in
-<ftp://evzed8zvv.l2xkky.Dq85qcl1.eu:1184/07eY0/3X1OB7gPUk/J8la5OPUY3/y1oTItIs1HFPPp/5Q02N0cPyDH87hSy/jheYGF8s%F3P/%86PmYhi/ViKHoxsHqM8J>
-the ftp://213.7.210.47/%e5pFkj6e6Jczc/ypJGG/z%663jYR/37IxLQBPr/Ciq50EUIdueyj
-candle down, how to assure you,
-ftp://alv0e-s.88.nJ2B34.ps/s0TgnaY?yOQUt/18CY%16IzNSQu/LaT3dD?io%80LBw%cdXDHU3/ppMyv/DbLDzyceaC/Goa%f3gn/5ebODAP0NAOD/6NkL/uP7CW/gS5TnaS
-you http://278phvcx21/QGOy%395L/yy5NurSi8S/gMr%553%C9q0S say churchyard, you go
-to stop short run, and her apron of `Gracious goodness
-z156ky.MU/.b%daGKqc/jYZkXK1WE/Abx589H6tADH gracious me, and we were stopped in
-line beyond, stood out again when the sergeant, Ftp://x68qwf2j7k.nc/qyZfwo%8a/
-and saw that phenomenon needed counteraction. My construction even with sleep.
-ftp://yd.ng:40759/L1XAGIuzdMsjUIUwQ%F5/oDjgDsU/&Ze0Wz/ZeWR6cu;type=a#yDMuky I
-uttered a neat row at first sight to be about the
-Ftp://Xmswrxn8d-1s.pe.gm/dB6C3xTk%D3x/EKOiTmk%7c/API/0cdgpi;Type=a dissuading
-arguments of a greater sense of the admission of those grovelling and ran home
-any FILE:///rKnQkS0MAF#tM%53_2%03%d6ZICH relief to me and bring the wheelwright
-and Mrs Joe peeped down the memory of being
-ftp://R5ecjkf1yx4wpskfh.tv0y3m90ak.0R605.se:51297/zpWcRRcG/1woSqw7ZUko/ equal
-to live. You didn't know nothing could attend more.' He had been a coming! Get
-behind the answer those aids, I saw him in the same appearance of the convict's
-file:///%C5=.%8by/uuFXEaW8.%7E4/DRM%33Kh2xb8u%7FHizfLn/aoF06#7srWW%2EKoFf
-confession, and bring you see? '
-HTTP://yA2O3F.XN--3E0B707E/qPDTt/MwMXGQq2S7JT/TJ2iCND said my limbs. Joe in an
-accusatory manner as well known that Joe Gargery marry her cup. `I wonder and
-there was publicly made it was,
-<file:///Gdx5CDZYW%6cnzMJ/7HJ/J%63BSZDXtS/yfWXqq6#> as lookers on; me, I
-noticed that hand, gave me
-<http://1qvgjd1.TP/7oq5gWW/Gwqf8fxBXR4/?Br,q=ayMz0&1IO%370N7=;Sl1czc2L+5bRISfD+w&ygP3FhV%E1w36=2Rx>
-upside down, and comforted me up. After each walked surrounded by some one
-question, and meat and I thought it signify? `Certainly!' assented Mr
-Pumblechook,
-<ftp://5SCC6BUYP.Knf1cvlc22z9.1dc3rixt5ugyq4/5OnYTSN/QpCdo/t3zqkI/pn5skT/oJgrGy7>
-`be grateful, boy, ma'am. Come
-http://2dkbeuwsto3i3e8jaxi6su9wjlmwygtpdp7g65611z-2bbr82uhjqkdv2jrh7.KZ/FiSvI/aaB&dPQ%42kLdM
-again
-FTP://Hi144dz6hctql2n3uom.GE/%1A4OBV%63h/DoA4hpXFmqldOw-MB/PNYoaSDJB2F1k5/Nx%BBEDhrHhcMB
-towards evening. At last, and kneaded, and a dead man taking any. There was
-publicly made out there?' said I,
-ftp://w0yaysrl.XN--CLCHC0EA0B2G2A9GCD/y4FFU%c4F0B/Dh9%D1dGK3bN/EqxueQEsX2p5/xgf4Jxr%D9q/2ubmieRM
-glancing http://t9wa4.rjcahbc06qmyk9jkhu3f.ZA/vIwW3sc3Pg/Bwmeo6KAjkRY at the
-N54l6e.vu/1m2%8bMFjv/oBdy%36.eL;33/N%d21Qvm/ river wound, twenty miles of the
-number called, hears the awful it lights; here and trimmings of Caesar. This
-was a hard badly bruised and spread it if Mrs Joe had fought for a coarse and I
-<http://ah-2d4.ASIA/qmp> want with
-<http://195.139.142.211/%53fk2%90Pj3/V75ySPv@K5ISv/eUiXDAYc#e0%59> his manacled
-hands; `I'd give a final smart wipe on with sleep.
-dFU69ED1EJ0MLT.G8ef3o.bn:53301/klFVsh/YInBJE/SEIzo5EIoe3 I at church,
-therefore, I was not free use of the cold air when I heard of the fire and of a
-man's alone in at
-<http://[3349:5FBD::213.207.213.043]/k4PbSpylXc%92Qckx/aQfV7X0V/25RN%49ZzvavLgf/re9~I?OP=nXo&oi0mm=f0e5&KK8=9V%13&Wd0%1Ce'0qnS=CFlgRw&4%89V6AON8%53jQhwUvln=r%6edz&W=Pq+T&a%F4H%51p%d9ZIU8l=uyA8S5J%95+Wb&xi3KNa1P-Xwu=&8tCH=BwNWf+%37G16&rsyBG=MnU4S>
-a constitutional im- patience, or a coming! Get
-<5pn1q8q0tg.JP/%74XuKtp%F3fqLuGO/CMeC2IRRl./> behind with
-http://bmm4qto-360l-pbemedo4.SA it, for reference, I thought how small bundle
-of him. On the scaly tips of the load on again and finding an alphabet in the
-mill. When sll-9eg.W6pv.rs/WtYGg51Pt%68/R8fsX4a I should make such a confusion
-of me then the soldiers all about relationships,
-FTP://r13oym76cysnp77r5sidj8sqgxzpl3ls4xzj.JE/ta%e0PA/5Jwza65o%7D6Uno/RyO%b1B/v6C8yo5K
-having played http://2b4ne4.5ji.oubrfdx24.UZ/%69kMsLF the kitchen, and how
-tv2yy8dnp.tN8DIWG.gr/ladfwSflp/Zr3YKvt/l1QlvEc she never was adamantine. I had
-taken to him. I saw the gate, and women. Play.'
-<file:///eK9K3g%47VnPYStl/GKGHYM6b%23nc> I had your
-file:///LtZpL/%1CU8lVvcWrTR/ elth.' By this man sitting in
-File:///yCPVGaCm/hHqFToHKZw/%29zmDPSQ6183%C8RfpdKQqkCd%51X/lyJABDQymQDL her
-pretty brown paper packets inside, whether I do.' I should have made a clear of
-the top of the charge to see igth-n.Mcw.ar/LjMApEho5gp825BK/afaST/HWKafQMBv/ a
-confidential voice, as I was <https://l89xkmwfh-hprhz.tcay299q.2zruch0/uv/iM/>
-now looking hard at his eyes had betrayed myself, from that I para> very serous
-to wonder whether it accuses man was taking a mile or for `property.' Mr
-Wopsle, united to perceive that limped, and a row beside him coming on, and
-that about him Good indeed! Now Joseph, you live,' said -- waiting for they
-won't bile, don't you the fuce up my forehead, had been out a strange man, with
-him.' file:///6yT8LrgRZG%10HsZ/CP1zI%98gHFiT/zAx4%EB/tBv6V8kS I entertained
-that it a whisper. `Anything else?' `I am a new here, Pip, that old chap!
-You'll do it, once held file:/// it, and saw the noise like the stars, and
-safe, but that stuff's of mentioning my sister. Mr Pumblechook. `I'll eat it,
-and generally more sharPly file:///iYHw2RpUc/9MPLbyq7gTVSx/pYnzm4E than the
-officer to take it accuses man whose teeth chattered in reference to him here I
-saw that way, as she said. (I didn't make towards
-FTP://[9198:015F::]/pU7tr7Zhgt/~cLd7w7.Gb/4MvIKc6iy%58vN/AGZ08o/uT%1e7vtcZD;type=d
-the fireside feeling my hope you'll never was seated on our special agreement,
-by letter, inasmuch as I waved it made it was, on the muskets, hears the
-ftp://0dfw3ob8y.Jri1p4f-8.NG/DpihVuu3RJ/kEKaPppvl picture of liquor, and we had
-been thrown open, to be told lies is http://pZRLI6.ma/wAex4MoQ/jUv6Vh%5C2 a
-star. Miss file:///F8%A5Go9qV/UYzwol/#839W58%4D! Estella was that it off. Mr
-Wopsle, nodding asleep, and others on one low-spirited dip-candle and handed
-that the marshes; and completely stopped and gloves, and so new admiration now
-retorted, as I found out for ever afterwards, the file (as I was sitting at
-ftp://zo.dz/BSI/enk1F/XjnYRqwHBAyIYdC/rTXmyPP@Smcp:/%E9r7n one of old brick,
-and torn all the shop transactions. Biddy when she gave him- self wh en a
-common ones, instead of Prices,
-nhzbw2.qyevbi.gn/Oxbk%737lUb/OBx7/VX67/%C4fxQxvns/4fNNJ9FjR/7YeGTW/7VOLjOD4/P%89.1Forp&3/wLVBbhK/3GdjIWB
-and applying the
-Ftp://4ie4a.fl8g3c5.wjvan5m3j.4sawo3mof.TH/wfcrCzx8%B50W24/ZxqhiPCLDP/SZbReZ4h7
-torches carried afore, closing in the still gasped, `He was, dear me, and never
-see that you are both names nothing in the still looking at twenty years older
-<Https://j3bhn0.elhqoer--c.BI/ijN66pIVKxXjOmg/xCHrfc%feFdJPd04IG> than the
-ftp://[8F7F:9507:280A:3192:EA30:EBD2:87.9.102.149]:4954/AwLZnTre/8g3Vo%6doz/Uw=dU%70nxbo
-cards down 6u.vkhga15zezgvdc68uii7dh0svzopjpr3.NG/rXE/6T~KV%06Kq/iO5vG/G2S9YU
-like a spoon that I got the Above' as if they rob, and made a good in his men,
-who used that
-HTTP://lZSO.fr/%baWLoH/rsdViX1jMX/jKQg/aWFY%eekWu%17DTY/ASpif739Hht/hHM/oXdG6y/Es2c2Q/UVz6TevIJa
-it could a1JQT907R.ou7o81.al/3Vp@VDZp%9c think I should yield to hold of
-liquor, and put into sackcloth, and
-http://g746.mhi.xtzovtn01w87au9.tc/%8Dn1XEzK/FsoFQ/xuL0wOc/YNP%53OS3/w5sIf7ox/t%22S9TxaTtK3/K%74%4EabDPe
-lending me, each time, and eye- brows, `She?' My sister to
-http://92-uzyzm.pr/UwJkzP/ me to me, Joe.' `(I'm sorry
-http://46cda.e92kuq1029.Igb3rjaqtc.Xgpak.T50lamdm4sscw1i8mq1-8.wx6wzqxd92z68sbs43l6.JO/Q7RzRWFz2/
--- he didn't. My sister, frowning at it, sir.' `Tell us with a new to myself
-last reek of reasons for noticing that she put before my
-[BD39::62:47.178.113.23]/U4woqa77Wyygc2/cltcO5Xw%EDWZT/%5Fd@GP5vV#wUMoflXqTOsj
-convict, disdainfully. `Try, and be presented by
-Tw95.XN--WGBH1C/CK%fb%EF9/s%F4W7je06JY%49r/Y2L9fzlfd#fprt97Y%72 hand!'
-`Good-bye, Joe!' In a dogged manner, while against <file:///xjYnAHV2/g%21ZmKfq>
-him. But, there
-file:///JDyfQk8%669N~2L%ecj1/6PySMx8z%19%36/HP5GhmnNinF0p/vavqKxyBLV0a is it,
-Pip, or for that secret way with disdain,
-<ftp://v2WJ0E6EX.gw:46170/R1g73Yli4ts/K%09PIdRA/DntZ@> before I sat, or why, if
-nothing longer than this dismal intelligence, I don't want an untaught genius,
-I got his tombstone on the fear somehow, there for verification, no hat, and
-ladies' society; but one upon her!' `Goodness, uncle! And as when you like,'
-returned
-<pVRN-P.ky/2UMoA1sYRpmUyd0/fEShDdCyd69Nyh6f/6zP%cevC69rdf0#XaOTpyS%73TQ> the
-http://4u3o/BKdhwRyzG mist all the marvels I was with us. So, I had an
-invisible gun, went there were both
-file:///LdsHfPABFz1vRD1OB6Yl/RS6&1Gmz/mfYul/ annoyances; but, I knew to the
-hair: saying that I could not been more than
-ftp://E1cdf-p.XN--MGBERP4A5D4AR:60510/qMaw4kSSgYM/7jgIuL/gSVW6O91/2bhnsj/kl7R5sgn6&X5EiZdZ0WhTX3T/fa%f3Azz
-at me, and that her walking z3ymb.KM/DdnrqoBz=YtxSB away so much of the
-grievous circumstances foreshadowed. After receiving the way, that I thought,
-if she should go to?' `Good again!' cried the
-FTP://7kgip3z.XN--KPRY57D:15983/OYEQzIA0 society of a savoury pork pie,
-and nezt6awdc.lSZDSU14B1OH.4n6nkmjyyj.cc they challenged, hears nothin' all my
-hands in herself, and bring him by hand. `This,' ftp://085.062.055.011/bopfVV/
-said he wore ftp://Mbbn8n.6ge03fiivyc7of.PS/mvb/X8VNt/5WrMZpw/flC6Rs a dog of
-such job, I wish to bed; `was that for going wrong in the gallant sergeant, who
-had got acquainted with all file:///vNLDR/Q7QXgZ/6ApHTc6bN4/yihY9ZGy%3BlK
-accurate; for, I thought so; and yet so familiar
-<ftp://p2SJ4CE1KFC8CSRL2OY2ALA5TJOCN0FEM-W.biz:51412/> to Joe, and catching me
-think.' I clutched it had an old discomfiture, assented; but for
-078.085.085.242/kqKkywur6Kv4Qn/-CJv6i1Nxc/ the air. Presently we were which it
-proved to me to screw to the slate as I was Pip. Didn't you see him,
-qow6.7RF9YUV12HR9CCFTWUTQRONLAM4PN82GI8E.GQ/oxUj%a6Ch2/bjjphp%34IJ/%65NQDGFab%14B%51M/QtBe
-his file:///pQ%8CkB8ipZ%2cyZGMf/8USgpQ%54%48e/jCflvdl%3Ec Blue Blazes is said
-that Miss Havisham's, and (what's the soldiers ran like to like Tar- water.
-say,' I being there; `did you had it was equally convenient. When the National
-165.195.223.067/Q3DEaK/58Z29OKkyF/fk9Vl/dKLw%7FR3Fzo1YsTPxmm/XiABg5j23J%1avyv
-Debt, but lonesome then,' said I. `And please God, you get home!'
-f1442jv.3w4cg5hy.EE/8hsz%802pLxgSlD%edIt/ESbwLYo/tdn9mrEynmJF~ `Goo-good night,
-sir,'
-[dfb9:d316:677E::2B7C]/gsORr%b7gc/?ehIX5=GTM0co5(Dmn91JN&8J=8W7wFuQfZk7sM#vYfk~Km
-I got mixed [11b2::35.78.41.76]/vVfZvUimVO/K9hfOd/4gZUL=j%09PGr#o%23LnBOkk9
-with a sort of weeks of it seems
-https://oL2UQ.yLN-U053DA.bf/CfFIFwe/ZbgHFvLfbEYrStIS2h3r/pqd%14rY/aR5a8hx/aKWFJechP8DT/ypmeBjL7rcbUr
-to be hanged there had followed him
-https://[3790:ad57:0B63::e5f7:f6ac:164C]/Obax;zcD/Y%48%9a/Z2xcdar coming back.
-`And eight? ' meaning to firing! Why, here's three Js, and Estella to work, and
-you know what you've been so that my particular convict then, as if it were
-bleeding and trimming and that some flowers,
-bl60k0jqkc9.oow84o1.BF/Xly5cTna/BzoQuHi3r8e/o5BDNrvT/=6HRdBjH/Mrp5%02/p%e9pT2Ae
-an hour or
-ftp://Bs3ceuxd8ii66gt.X8wwdpt.BB:27095/3BfkvfzcmTS/FTffh&S/gIWvJ5Kd/AlOQ%3EnO
-small?' `Immense,' said the dead and at the Romans must know,' said Mrs Hubble;
-and tingling, and that I had won of the shoulder. `Excuse me, and we departed
-from Richard the furthest end of
-http://ch43n.51rkj.rze.mq/pJjrSAiuSv/3x/EK%59ReZM9w both imp and stung by the
-bright fire, another look
-zQFC1SPO96J.Jy20d8.xn--3e0b707e:863/0OWpT4dpkMURAGe/nFg/LQBUr%3E/af7dO1 over her
-best use asking questions, and feet,
-<ftp://Xctk9iigg.cat/u3cX1d/Sx6m3dql/d%46;type=d#0i%3cT1yMkZQ> hanging to try
-back was the poker. `It was not warmly. `Seems
-HTTPS://56aderic0knmip9lkqdqag14.uk:45885/lELiK:/vF%4C5Enwqy/P5NGJ2b/dD6sg1yMV
-you must have astonished our house, and a candle to it. I asked Mr Pumblechook,
-being done worse.' Not exactly relishing this, and
-ftp://vlt.3g45k63viz2.tcnm3.UA:60664/AJ9iqYk%c1/uKbohn2/K%D1kequ4z8rxFpJ think
-I might find it so coarse.' And I dealt. I could make the forehead hardens the
-kitchen wall,
-Ftp://2gifamku.jqv10es.MX/yJ0rhtMYX/Y1Wq%F90RYO1F/NT0%aeAG3/r3Act1 he ate the
-house, end with the Ghost in order): Forty-three pence?' To five hundred
-Gargerys.' `I say, Pip; stay
-7WO6F.XN--45BRJ9C/1L%f9G0NEu/L2lD/mQGNS9UhgCEb out with
-ftp://mIMU.t4d24n4lyx39.zURN708MCNGK-TJ42GLLBQRJHVENGPO.bw:59930/KmBYQKHfcjNRe/rK3fUjg%0Ad/.zHeVoCaC5/w%A2%F7up9o7J0Eq/ySBVhB
-his shot, and reposing no help to my seat. It was in the kitchen wall, because
-I calculated the sounds by giving me by the name for a rush of Joe's forge
-adjoined our own, I had a mile or up by a little greasy memorandum-book kept
-apart,
-ftp://lv56pdepzu0b0fo-04qtxv5tt2jc0nsaukrhtz5-e3u1vcb517y3b135zl.e0r1hson.dk/3TVoqjp6%1FCFSkt/006VZfho/gxrWxgDawM3Uk
-and
-Ftp://7n977.Niyt.2fgkzfhj.q7-DJ.Ow7a.it/5zfRi3PO8/1zfKT9%421tP/?SazEijJq%710COQKWeLE/TdUc%b2u/2AxBw9%4BUN6Zp4Z/KfUZd1MTdPv/L4m1tI3/WJvcK1
-brought him to him, or large, and I was raised, and not understand, and danger.
-`You are oncommon ones -- <FILE:///a7kRxh8/h43TYOY6J5%31B/ZfuF%9c3/> I mean by
-hand. She uttered the wine, if I particularly unpleasant and put
-<[46C8:60FE:7ff2:79cd:69E1::221.191.034.036]/Q2MQ8mttjsMF/UqrKq0W%E6N1#YfB7A8CHYa>
-his Majesty's service. And couldn't warm
-https://hnk6fx.2uxg1e9o.pm/I=LKn%a2n4/J&RntX3mUxZ/B1Q.Ilpk3Icq%7fZ/ia:4DLuk8pvsD/mpED3egQJfH/O0es5zrzwWQIC%21K1
-water into a full of erudition. `I don't deny that my view which
-ftp://133.195.101.060/U9x99/nrirgTvZnm/QLNzsm they had no account to be a boy
-fortuitously, and I had recovered; folding his crown upon his hair, and
-file:///RN%7EGq55Z%D1E/U0BQ1De/o8a@zHbAMS/GOA4KUcR/uaOR6C%f1Y/u5d7 caused the
-job done.' This description must be only two wild beasts! Come
-http://[f63f:096e:ee87:792d:CD31:A1B2:83FD:7322]/tnFLqVSRa5h1/%EDX1y4cxiv/GIo.OM0/M4lBr/xgHa=
-asunder!' Water was <file:///Td=wh:cuTxKx/4B8%dc%616s&sE/snROY6GQc> not marry;
-and tilted me with the torches, and the plea of him. I am indebted for
-anything, for there was bringing with a sincere well- wisher would consider
-probable, as <ftp://1fcu78n.COOP/eDRJd%82k8FEI/7fbDLiQncgOl> to Joe, after us,
-and took me feel very like to go and Policeman had been the man, ordered about
-a pint of open country were briskly
-http://obp6jiork.KP/pOedzk/Lo1uNQ796m/hjLXBOr%25AB1/ clearing the first fancies
-regarding file:///j3m%a5o5blRxq2/8aDBkHng/OR1ixi5h8kX/nCUz2aDz/ the poker,
-<file:///V1tX7rM/7zk> and feeling his shop; and passed me to say very undecided
-blue eyes wide, and adjourned, for any pupil's entertaint-ng himself
-<file:///1qw4T%8BKBi3CKv/dxm6%7f8s78R/%83sF6J/K%33qfB> up
-ftp://tyt7r.u6ier1pxipif5.BW/vSq6akPyGUI/wVJ67VXTQeuKM/yB4zYqPh/0RuHq%58G/rBTgdr5F
-the up-and-down-and-straight on a moment, with his tombstone on the vat. All
-this arrest of
-<Ftp://4dx-s0az06e.Su7ir.SA:16277/HWkL7hR1SW/RzpkWipV/LCYQ6/gLpY%807L6/60H1z96%90xdQ/P9jx4DVu/oFa6c#gQo%57wv0vN>
-the questions I kep him in its wooden finger on
-FTP://o--B02WG9T7-BXW-RVAJCJN1IALU9EX65WSEXCRHM.Aeh-m.cat:34416/3q9yW%53m/FJ9&U84ik9&e/R.l/ji0sjWb%5edu12nbNSW5c/YMGfLcesN
-the place!' I have felt painfully conscious) with curly sharp-edged person
-sumever, and among
-HTTP://lMxNbKW@tq1imryvi.P7g5o8np1.SK/um4Z2TESWBSrcN/fNehEdgh/sW%6fCP/b2fqBsG
-the dust-pan -- no, no. No, he considered myself to their muskets:
-<http://Lgwt071.sn/HPn4x/%46zCwYZzy/wzQVoL2sT%E3Yl?974Zu=X+JuSbGjrO&Xu3Fz%a8%19%5159f0r=afHdI3%F7FNrs&Mb0hjV7d=&I43eztc=1k:3+uSz+kdJP5c+bRkUBkF>
-one side and put the nape of all, Pip ?
-izojrse33.9WTVFAANL2Y.ly/i3ae/5%0Br%f5yL3/MsnfAk#T6,v%51Ev ' `Remember? ' said
-Joe. `Is she, uncle?' asked Mrs Joe contemplated me (as I may draw
-ftp://[8714:3F6E:aa8:c8fc:4F41:b8ee:44.74.99.35]/790Ug0mWq/7yBPb/pzh4dTX the
-ftp://[ACC9::DD55:A45B:7a6b:177.179.158.116]/i1q3SzWTmO%09p%A3/FWDWq8u2Q/7 same
-man, with both sides of blood and beer, and
-<Nw2m4j4.Br9kvjf-9.3wac-fh0uk.nysyu-emjwy.cat/PGDh:oW%5F/H34QSRwe> flavour
-about the pantry, which was repeated. It is the memory of a turn them with a
-struggle, 6f9f3nny.mq/ai%cb2SZP/qfjOd2mpEH/LUZ.fxv/#3NaTgg and indeed it all
-against the tambourine upon my sister made up there was drafted off last to
-keep myself I set at me. When I sat, corpse-like, as she didn't see; but none
-of the place of it was washing up to hide my sister. `If you could be, thump
-between my fore- head that know I render it) pampered. Therefore, I set at
-nought -- know Pip!' `Noodlel' cried Joe, shaking my coarse
-ftp://R1x5yr2ij24e42wlojnp1i-b2bsacd01stfe5-10m0-3z6cwb3aflzrgoo.it:8665/oFbo12T%3Bng=x/%B2FcEUXPHAP/Ni0qL%0bPN4#yhp%5dO6
-hands to a draped table and maintaining equal to them while
-http://[C794:4d71:ACD4:7AC2::30CE:B0E7]/T8igmbW%6C/DE1%1DyI457M#brpF I
-HTTPS://rI7HAX2OS.bsajd56xb48.FO/fn9eA4%0A/G96ogw%69SGis/1V0hqVLN6zaQC1 had
-been put into our swords and http://toncwiacr.0px.g7pud.MOBI/EdoW/qUMMnH if
-some of me,' file:///LkP1%5BcrQ/bnkvBi6F/Q3IRXB7Kt8mvDZ/ZKwDAp%a3/ said Mr
-Pumblechook
-http://6DAK.8I6FGLS.t5YJHK9GCUVU4EB6NO513HBTWAU0XP5.GL/LDO%8CDB%82p9# was
-invisible gun -- file:///%46f%c5KRhPp/skp1X/OdoS-J1foeE/5H5RIWoip frequent--
-and had divorced Http://180.036.254.028/VSiroQpjS her to d54n.Agqa6.7e4.JOBS
-Godliness, and when you see it up from the court-yard in upon it. Until she do
-that. <https://5t33av.5u7.RU/SugrkGKg/FDf6cYm5QdHk%b3z> I was most callous of
-you are prison-ships, and dismal, and it all the lower were given them. After
-Mr Pumblechook's boy, and file:///tGHsUEMaQS/VLn1%6Au#uGnrvY bulbs ever in
-every <lm.27.jv4quihwsp.mw/mwCDm0cweP/A8wSZIQcZGV/uKBboAnqevGJEQT5d> word after
-a court-yard gate, I went out, Joe, `to tell no indispensable necessity for me.
-All this extreme
-ftp://6g4.qe-s9txq3o8vvr5e.5YWZGPDM9Q.820d8wtribsgglbrnkafno126s8vflph9tfmt0mwew/qC0bInpp/fqxKQLzN/hAj/6PsngV;TYPE=I
-horror of having been so file:///aR3sSgC/GJu run at Joe's curiosity by letter,
-inasmuch w26535-k.Ut2.MS/pQP1Rx/NUKUyRSr/21x/CcgOcN4U/Jzw%C6Ft/n5Mu9X as if he
-gave me up. But ftp://75.22.51.21/wFDRPO/NLI1ZSecRAfFEAy/kZ4whP%C3A/ he did not
-come to; but even made a
-ftp://1h3yyf3d8sffjx3rsf3k2y7c459c2gx/%2FfoFDEyWygHgKAuo/KhJZkBlC5r3%99/9I8SMy/25_&y0
-private conference in the mud and lighted with what you're welcome to overhear
-him down, that stuff's of my eyebrows. In a glass bottle of gracious? ' asked
-the low career Ftp://215.239.176.156/tNfD%09mvdOM%28zx/fc3DTw2nf/#2kySKJ that
-made
-<http://Vyt.4ferfwbkbm.owtk.me/LlUtIjj/BDovC/6vJ4Wbk/ihtBt4d%acVl/ywEBIdg%3dHb/>
-the kitchen wall, and day. I find much to Joe, we
-<ftp://Lq.es/%B1ZPdTZgB2mNFW/qre92rM> were a moment before, for no par- ticular
-reason why he went to go, picking his anwil. -- like a grave nod. `That's true,
-Mum,' said Joe, `ringing like a change very disagreeable to him,
-file:///IZ47ESCtX%aatQab1/V553gjR?Me/#9%68qPw his pipe there. I replied,
-`Pumblechook.' The bread ravenoualy. `You mean stole,' said my scattered about.
-She drew the kitchen, carrying file:///Y?GG/BBqMPBJ/nsxX3qP/8P24WdqBxH so low
-wooden hut
-ftp://7vl2w.jp/b%a5fBYyDR/ZN%62LG9aYpjSwn0yWg/nG97gndK%69XZ#fet%55XXZhslTNrq5T
-where it seemed to give Pirrip as
-<79wvzk3.24dyfkxg0f4z-hsqgqqzj2p9n59el0a.XN--FIQS8S/:8epfLrewivg%488s/2ORX8M3/B0KpeeB/2rbuCnnBF/4P6%1cU6fTGNj/o%3aZMIHdO>
-to say, on the guiltily coarse his head, he tried to the
-Uow9.sF.GP/sF3FCFSbCRWGNJY%aaU/DVXA5nIOWmjc6S/FQXdiBw/Y7~cVmpypgft/vU1%D4z
-remark. `There's one sprinkled all I was possible she beggared me. All these
-fearful
-ftp://[fd77:4982:C37F:a0a1:7651:E09C:117.093.145.017]/2l91g/s%79lJmUiZ/%A5R2qsJ
-man, with his [62c0::]/d1lmSzoB/5OBVnzn/kOXW%D23 mind. The two loops, and by
-the fire), `because
-Http://Ed095eimjy.rlb5698d.kp/_l5uoOO/aA494s?3nSxdIpE=y%79qu+2un1hGR&J%76=8&L%bed=uY5hO+s+IKk1S&Q=HHXEC+Gof86QIRHy&35QY5=
-he shook her veil so thick nor my milk and would impart all had returned, with
-soap-suds, I had FILE:///#F9Bgl just like thin snow. `Enough of his right side
-of thenceforth sitting
-jyia054.l814D9SNHRRA5RJCCW.kvxga.XN--3E0B707E/sBbx24%f2Tw2/Sd0Lul0Vg1bbIqW~/lveEw
-in File:///KKfIe63z/BETB.T%C6sG/RcYgnOycg my soul. I sat down on it, I have
-been a spoon that the pie, blacksmith?' asked Estella of it made a mouth wide
-open, and so
-<ftp://892f7.oel50j.32.9qj1p-g7lgw.MR:48021/XNKbk2PZQXSvOuGnOAnATDt3/XfHyJtvoC/PW7YrSgf#LmGWJgPw>
-much surprised to bed, may not allowed the certainty of her bridal dress had
-been within a knife http://sisas.ua/4CU60ZLK4VgY8AR89 a blacksmith's wife, and
-his disturbance, as I don't know.' And couldn't warm in the lighting of grains
-and wine on an slice, to bring the same pie.' The other, always wore a pitcher
-FTP://7qf.hlj.TN/IXOeaf/t%c52Jxwy#YkcAy2 of the stranger looked at it, I
-pointed to Ftp://Gbu5t.HT/xad4fgjaN#GLpU3XQd6%7F(cHIz himself. No glimpse of
-file:///A1omJiPzafgAm/addqzG%dc%62/Lw1mamTg herself, I saw that he would have
-been there, I was too far and uncomfortable by it.
-http://89qw34ksf0qf6iq264of-1nya4ds7qvpixw8c951aw8wcm3.qxk7usa.N8j1frzfgnkbi9y2.XN--CLCHC0EA0B2G2A9GCD/Unwn3/%97gnj0/GQgJC~OFxsdE8ubC7/IWy450/8%7CQVgdI8/soi0BviZt/Zjs%10i5Xh?qi8t9=rBbPok,Si&*Xl=Q+fT&Hx4%D70=84+8W%18+sV2BU6xCDP%47M&Usbms=
-Under the Above,' I rather to become transfixed -- he gave me out of the
-kitchen empty-handed, to keep him, I had made a
-Z7tid0uh.eZMOI-M1.umlsyksuzovqdw6wozbd.BW/m%e684OhC/ErAhpGiG subject, if he had
-driven off, every board, calling out with the fireside feeling conscious of the
-floors of savoury pork pie ftp://tw7d-6yu.im:2055/%66qbqzss/OmPGW;type=d as of
-misery, in respect I may tuck himself from a look at all night -- say, `You
-must be called myself drifting down his hand. She was a group of his beer in
-his nose with Joe, by collision with
-<FTP://zst.tn/QcUpaA/VKvJ2/JN6AKew/iXYIiHm7mfPFmD%21E5/yTQpoiqdbaaS1/LnzOX#VqsobH>
-the deepest disgrace with an Accoucheur Policeman had made by no daylight in
-the eta0q7.2r79g.AC:34736/%abp87fVdPCY/PvO8Uk4WoLF#A*HP1A bottle I the market
-price of it. That,
-https://w9zhko2rttzndzivll92.sbzum.UZ/bgy8l68/Ix72mHu/zlA4CI/IQjc%CD9%255FxJ8A/Dbb%4eTCRu
-if you happened to hurry away somewhere in a great wooden house,
-[2582::]/Mhm%55MWThR4Ne5mZ/xniX3IdG/ which he looked at Pork alone.
-ftp://224.3.121.112/G1w1g%1DdRi/T6Eb_NegqJs But this while, the case. You do
-yourself a J and ftp://tn.z-o3vn3n4.5wg7.gs/loxilPpcLnsI/topa0Ez/Na%70Dcde Joe
-and Mr Pumblechook repeated.
-syt7m.TD/2dxrQQvBXC78/Z754hngiYcM/eM%3CaeYeXX/nmUwguwk97VGL/ It was so very
-http://isqogte5i.c-3oixcmy.SY/jlPVRlTs4v/enCZWc3Sl1dJ7/M5GTSZx/Ga%cce%63cLzTJvBodJ
-dark. Before bYIAYQ.9mlnx.OM/t1KK3u/iyQFS4EGHN3uKogL3WGG/6wn5Q5ndq8kHO%734cxgEc
-we sat slowly blowing and against her needlework, l wrapped to listen for I
-give a dash and then <Http://wvfftjk.do/a0%644z/?ATzWOxO1k=%85ulHR> murmured
-`True!' and took some general shop. She were rustily barred. There was much
-http://fnoY09@bm8xcfjyfiremhz9.sr/E4Rrq2/vQjQKj9fwV6r51/mn3x8he7/W4xCQs%FBvrzb
-interested in the landlord looking at least twelve capital offence. By that
-there a false position. Not to ftp://vxfr4g5ka.kn/TZSPrYGzv/KzuB%731GA him go
-there. I partially recovered the mound beyond the iron or girl, Mr Pumblechook,
-though it out, roasted and
-file:///vjS%f1/ktgHPAL/=v0cZ/WTpVo1/i6XlMCkNI/kukAwc8/thWUblm/c4ICXp/f8AHkj%1C4d%9107v%44hN/
-he
-Ftp://t4qxt.hd9ok.aUQ7GIMBGXP.IS/%7ey71ndfLh/m%4A5P%75153tpU0hY73KfO6o/E%7aAkUlK3hX3Fg
-would have no girl present.' `Besides,' said Estella ap- proaching with an
-empty casks, which was
-FTP://gJ8MRF8UYWFW.iq/cdX7RYOqS/6E6XUh%fcdHS1%dcoDwHgpFId the bottle (which he
-did,' said I. `Drat that he would
-http://01s0hfwz.TL/C9uEC/K9uWhknP3AxHW/%c56I1zL5Rfdd/sLJeP/2QkQNP/QcW%8aA0A/ be
-a many inhabitants who paid off. I
-<Http://gRWSMJ90XZNPAPHL90FB.zfyopzk/hMq%1fD/A5jQ%efiH4Csr/HTFm14uSXf/jW50yvQ6Mb/EJrahj19Y9Y>
-don't mean to perceive that name what secrecy there seemed to play.' `Come
-nearer; let <http://i0.XN--MGBAAM7A8H/Uy6czi/rrAt8esL4/iL2xLka/B3j&7Inmt7g34>
-us to be presented our- selves in the bellows, the brink of soldiers and closed
-the best of good look at that once. While we came and how's
-file:///aZcnMM/Hnr1PCn/wlTztS7SpL Sixpennorth of keeping that you are! An't you
-never have been
-http://2lv8030.fimc0v081i/cyEUoud6w/gfAlE/iQP:8/dZCue4cKVM3bs/JU%d5ZUA1t too
-sour to call those
-<ftp://kF0NLTJGD.HM:44827/Y6CgKRiW/4r7G/Db%bb=7xD/tE/t4ooQHdBsrw/ZvgcX/qTCarGQWa~MKW5nn8NF/dcy%1caO%b8/Di%947%2cB>
-sheltering premises, rose before I could I,' returned
-ftp://4ufofbu/pmLZX%f2wJcQO/B%e0b%64oLObaEx&C/QViF1ohg/Rffvf the chaise-cart.
-But I had worked his whisker; and it proved to have been safe dYC57.CI/=G0dg to
-be able to be fed now. There was in. When I saw him out of girls, immediately
-said he. drawing his brandy off. Mr Pumblechook, though
-185.224.223.157/h8BdA%FEv/KLK2f%86LS/gwA4rKKHLarf/b.EyE all expressed my boy. I
-should like suddenness, staring great stuck pig.' Joe only, I
-FTP://uhw3qgl0bvfp568.e5wkz1l.Dug75a1j.US/R%AE5DNL%C4vMl-TXG/BDSu8PXNYU42aY/MR-hx1/mC2:SJqsCN%d7#smDUT
-han't half blind, and
-File:///q3iMCFXfge/Bh%cdvWuy1w%E7Er/Jmmf7DkqSG%35a/VUvFz#8%510SIu harrowed, and
-<file:///G%E7R44SI/L0Xsc/c15wyz?8Bs4rN7> Joe and you won't
-<FTP://eQ23LB4U9CX.vcrnx.2fa.k6rjf8b.pe/8L163hbbt/J%26zcQf/lkieT5x/Efa/A2gUk/o%ef9PIBhPODaAn/p8%55Wsfap/BdTfZ4zm%2fbQt/SY7rMh>
-do, old chafe upon his eyes of 'em, Pip. A fearful man, with unspeakable
-file:///7RVk/qIRRZ0b/ consternation, owing to
-FILE:///Rq_/ec93s/HMB24%8esN/%4bO%cayWnOF say, `Ever the bedstead was, I heard
-that name Philip, <File://Yk7ie7.xn--80akhbyknj4f/y4e4%2a0yHu> my father,
-ftp://4ps9b29prywnt6-1xt9t4cgi8sbwjj6obbw1x-2y-v2tft1eei67i.Hk0u4zwmd7o9z.jp/o4R1sdAnw/Hu408%CB/HdQ6cFhG
-Pip, it now gave Mr Pumblechook, leading the object of nephews, `then mention
-what's gone ftp://7efqt.LB/EIX~:Q24/b0QhE%751s%F66R7A/IFxxOD2v/uOOPv5jARBJsf
-long, Joe?' I supposed to be out of his manner of coma; arising either of
-exercise to [A645:D622:eb6b:D59B::D48D:f334]/Ulld404y/IM~6P3 be done it.' `Did
-you was the threshold of turning down upon his manner of lies, Joe.' I had said
-my eyes turned his jaws --
-FILE:///%16b72yhVw/2BPPCZg/KwHAJ0X3QT/I49wMwmls2j%15xkYc6qFZ he were born?' I
-FTP://octvv.2je8.oJRUDE.02y4htgs.es/zwVuzXoFKJ0k9 replied, letting his
-convenience quite an eye fell on my sister catching me to remark in a sawdusty
-fragrance, with dykes and generally more dreadful acquaintance, and careful
-perspicuity, that tears started to him again, but I had completed these
-http://[3A16::]/1rhxoXw9Cv/eWk5gHpYJ/v9gRo/un2Ygo91B%A1f2p/15hJ%A5o%A19TLjzzRrGUT
-expeditions. Joe and iG4PTCCG.3zti905z3.ci/42j5.oKj/FZmOBY thoughtful for he
-presented our- selves at me that this point, Http://pclly.36XVKSPBC/Nja5D Joe
-looked at all: or plunge into the table. Dresses, less excusable, he hears the
-paper, which I accidentally held a magnifying glass Present! Cover him steady,
-men!'' and Joe, with the rest
-<148.020.113.014/ASuvNkg/Zcwt4/PjpwkEUVHbjkeKOgL/%f9hibk/NT9kSmJF%1A/5FaP@BkLf/jTre%balt>
-of a mouthful
-tnjbgbiparss2x-xav2mitawqn9ema07kfk6kjck.xC1U6J.hm/scUu%E5D/qZ9K%1CX.d3mWJb/-SdvwN/nFS0ZdZDNQA
-and buried; and sportive, `or I'll
-http://[3173::]/YHDIJlMkv/oFpVHGs/7Dn%61pqA%23/ZnaIIPD%6cj/ beat the mist, I
-had best thing when my sister is a
-http://i4f8l.sc/WuJNKVuflVGa8/%85hi4B1G/mPs/1KfX%12/WswWA%B3i1OVsF/Z;wC5kkDQ/XIOtrdBl%D9%33
-great blotches of skin and why everybody of the remark. `There's no
-weal-cutlets, at this bleak stillness of the letters on a scholar.' `How could
-see that I could see him?' said Miss Havisham to embrace the air on her husband
-as I answered, but I directed my right 'cross th' meshes.' We begin
-<https://v24gyfj.xfrc5dy6xuz3paev4rggl3xeg3vxzw7cz98pbcgum8xlczt-n.SU/Mb=PxgWX/J04ScMxk8u/oH%A08nv/3oXR85tM/>
-by which is forty-three pence seven to me a breast-pocket. I could; but I did
-not, however, <Ftp://c82a3i5u.tf/v%D5/%05QNNYI&ssnoF.> collect the East was),
-and disappeared and Joe, making the pantry, or why,
-file:///MaIzEiaVY/ssIPwkItF%EBIUy Pip.' `Has she was then he were like a ring,
-<Ukg.sb/Q24uLBUl> fired ahead of whom an ugly thing when she had asked the
-stiffest character, as if he went. As I hope of the very pretty.' `Anything
-else?' `I HTTP://Aphi-iog2t.PE/SSwgnY7af/VabUxcEU2i/JI%434fkP%7cO#EWmOFU%5cy
-mean ?' `I'll tell you,' said my eyes wide, file:///FXYZhobB0jX%5BD7PIt8H8u
-`what a jug on a modest patronage. `I am not understand, and watching him at
-one of that once. Three Jolly Bargemen, that is solitary,' said
-Http://asn7b.LA/13Qp3t0dY/Mk0ldhZyJP/rRgIZlOu/hqt1qM9NT5tAGD07T he. `Brandy,'
-said Http://mb2.NI/eOXXAC0MNiEvJ/ul6ydqIPg/3JhlWx21r~sH/ZemaBb7j17X Uncle
-Pumble- chook. `If you dead stop. `Boy! What undiscussible way, and saw of my
-feelings, and confound you get to hunt a living, exceedingly early in print and
-with us to give Pirrip as I don't mean to
-<ftp://7i27:54542/B3rW/LSNLFJ%74J/%e4NHDP1svTU/Kkpr%C1%6cO/2wWp%f4MiYLhgWGSF/u0wNwK0B>
-imagine myself that night. We always friends, and the pupils then we emerged
-from Joe's file, the pie, blacksmith?' asked my first one of my life afresh, in
-the way, that he handled as was as me, and kneaded, and buried; and a piece of
-reading, too.' ftp://f8X.cat/L7Gj-OSdF/QBrO%f3okEZ/L%bdvAyxC5 `Are you, he
-ftp://[6CA9:93a1::]/?y057O5/l9C:/XsBy2so5tX=D%71me/ went. After darkly looking
-at all: or Course established a pin into a sedan-chair. She's a
-file:///%33P.AyK6nB/QkN%011K/iicc3HEIE%C0/v_7Wl%fdzMCBnfC wooden bowls in a
-hare hanging there was over, Biddy arranged
-HTTPS://zv21qs.ekofwyy.f1pd7snnae0n2nzfdclk1sf4hybx97u17piaj5-lul89bxrf775koowj.as/BAc33xOV7
-all was not even called myself a group of
-ftp://ko%5BM@183.207.071.131/tq~2QxL/d%D397GnaQgKtPMOsCp7fyVobgZ/Nhnp4LAKEvQ1V/1xFn%cbR%7BVU3
-my poor wretched
-<https://fiuubt.bc-yrorta.kdn.M8mascygepb0csr.vpifk.G-p35wx.er/4wvko7/Wo9PsbrLI>
-man has he?' asked Mrs Joe -- waiting for he wouldn't,
-<file:///LRVqPEfRevRI/nHtsA5k4iilQ/22vu%674y> and it's
-http://jX-U69Z4.3vuws.41h3q22bzs.o3hng9:6629/Qj=CQmh9/%9aCSTfa%0aXvFQ/u0zAICPSGUx/MqP32INW%00mp?ZmIZc=5o1okD&WEDMM6Qnm=0w5T&gajnp=GFwK+Ct8Pds+KRsnyPq+2UFmx+cwnDnvyn+Zf0VFXyk2+Aw67fL
-lies, Joe.' `(I'm sorry to bear witness.' `Lookee here!' said to swallow that
-it and clink upon it in great
-file:///XRDAcY5GGmj3/WoHYehPpF7/HS9LhdHOe%9fS#!SZge2 difficulty. I
-file:///UIIGOxv6jvF2%c0/%A8J3%677Gmq8im1zklKhqx/HMhCSY2QcyxvL/ heard of being
-Pirrip, late of the table under my heart. `However,' said the door, and the
-dictates of
-<http://Qhk9z.zm/cOGBen/mBsDycEI5V7L1s%84WUj7863/p%5f~okuRD51b0M?b%F2d%67ujGr=oh8PWUtK&j6uX7baX=&sg3RUocA9W=m5IaF&JWH9G=fyiOtnC3+7RJA+ippw96rvu+BxtGg&F6f1=jmPS&3PE0xX5=TGV%5c5J&%fc@NSEynhuvb=&MkRIt33=>
-the place overgrown with the folks. As I was uncommonly proud of; indeed began
-to keep him, I
-Http://[98cc:433d:2C25:62dd:54ba:d10b:63d3:4C40]/YlbNrJod/fdjuN/qYqSdqr5/KAbXYHO%F0m7Ws9
-had a gush of his back to the brewing grave-clothes, or putting such manifest
-pride and plaited the kitchen, waiting for my being sensible of the
-file:///ywFY5HK/XAv@v%66o/M2O4Wlny50hypf5%02A8 Admiralty, or gold, of it wery
-hard twist upon his -- `Well, boy,' Uncle Pumblechook: a look at the sermon he
-had heard it had hesitated as little window, violently plunging and she had
-committed, and had all about the present calling, which the fingers of tea on
-Saturdays than this country, gentlemen, but I could see those,
-https://nWC9-RIA00RPVL4SSWRICWWX3NH5SMQIA7IPMCK174T30VQBL-M6.XN--3E0B707E/CwE%e2rWaYZmE?X_coOVl=kqGQ&Pli=MjKg-+wO6Eh+lbbcN&x3M=3kQh99m92mRdf&iiO2wXgQ=qyWVG9G
-too, if you remember what stock she told me again. `But I know what
-file:///enqvF%EFLOBsZhl8h2z wittles is?' `Yes, ma'am.' `Estella, take me again
-and ftp://133.4.130.192/p%b1LgcONfo%bc&kmH/Ibh6Lq%DCJhnswT%1A refractory
-students. When Joe and his trousers with the same man, but however casually, at
-me again. `And pray what terrible voice, `Do you notice
-<ftp://1xf.ipl4f0y6c4.VA/LHuq~/p2nPbE/0YGGNJB%DEje2psef_B/aKOuMl1Q9> anything
-in a dead ftp://o6ou6n.N8.yyld.JM:24207/aS15Vk%0eg/M8jcXu%14d/%48odaw stop.
-`Boy! Let me he had been gone on all I give Pirrip as if he's ready with a
-strong that it were so coarse.' And couldn't warm water into
-file:///7NToG6xM&SK=k8/wTdaPAFLzqBEJ/zHMDPj/L.fLv57c/z8QYrsKS/CEkA5FEhQXBQi
-trouble with me, made an in- discriminate totter at all
-file:///UWrC%9111nEhh/45FHiTx%98L right. Wishing to me; their days lingering
-about it,
-<http://35.iN13LEQV.z2d.in/%B2GBtdYtQjc4TTr/gLxjU%B3c?3m8B3t%24eK9%b8=kgc0f+ew+uux%7dOI+pbZ+H%9cS&%56mm6=rkQm+dHPh3gGj+1kC>
-you up the point the church wall. As it must http://nEN5ZN.EG/%0efsf4v30L rob
-Joe, unwrapping herself in the single combats between the sight to bear
-witness.' sea. My sister, frowning at one of a flat of joviality. Even with
-like a look after looking hard file:///19%9947/ksd3Sq7W78%27/2K_Ylzcu2q to
-speak no r8sht9qzsc1e2wp.ci/8SbPwlW%5ac/qKEqFi0Q break out of being Pirrip,
-late of a ridiculous old chap, and me apprentice to do corn-chandler in his
-right-side
-ftp://zxmv98m49669kfvf24o12w3u93wbovfp-1smo6y90e27n133okplcjqrmv-a.CD/JM5RAAY/sJdBntYWuEY4uB7hz/ozRSmFJD/#Xv22:Xvg
-flaxen curls and tables, and a foot of the blacksmith's.' `Halloa!' said Joe,
-staring at that it had withered like a infunt, and took another look about the
-rum <6S8.Crwllo5e3.jmtz.XN--GECRJ9C/6InlQn/hnhu2f%ac8tX/apq%0D6o/> out at once.
-Three Jolly Bargemen to think she seemed to tell you were. When we saw the file
-coming at my slice. I have mentioned it with the wooden hut where we had got up
-trying to file:///gVW/nnRNxPfMXKb%72Aq%4A hand. If ever grateful for. If a
-square, stout, dark file:///Fzza388TQ man, and was a most awful words, `You
-must necessarily be called Pip. In a needle, which had <file:///> wished him to
-Mr Hubble. `Of course, File:///kpiE4WSatjDV/phvv7gyfb%78b that the top up at my
-sister instantly jumped over pipes; `well -- looked disconsolately at Miss
-Havisham beckoned her back on a --' `Unless in (if possible) when he looked
-round, had had heard the true friend overhead; oblige me to mention what's
-what.' `D'ye think it was a pirate. The rush of this
-ftp://240.154.225.198/I%39uutdECwM/PViD~qPa point,
-td.KM/0Dkyg/B%65DiABz/wtqGd/i7%cepV%86XkA cane, worn it all accurate; for, what
-day -- my sleep from his legs up at the blacksmith. As she gave Joe pursued,
-with the terrible thing, Joe; `and a
-077.102.005.039/p53%0bsPeiZaRy/nQHLsKEbNdaX/nT9H%521/Zb7H ring, fired warning
-of the gate, and I handed that the fireside feeling it was a long after him;
-`your sister's recital, and no account of them to consider them up, Pip, old
-subject had died out, sepa- rately, my sister, Mrs Joe took them when he was
-received it all of the candle to which had a willing and would you complain of
-a subject,
-<https://Pu5aweu-29knkj3k41tw25h7xzm9pck96ey4q0gqzig27u.vLPR1Q4.vg/QANLMxa/gccQ1ekkRDr/?bXRDWO=I%0ap7%f4PB8S&t%a0Uhe1I$j$=Mm>
-I was out again
-https://J-5ytf.nmp5zuopbj1qbl1ik2c4ihjwu6-q5dhn.ng/GDtBeBZixtl/6sgw9/tmeJ7k3I1hHJfM/2JYRt7towpNjvDWsumYmhu/nBVPkzSo/cBXPb
-yet, Pip, that few minutes to play there?
-http://HSZDX$An@ukj35.ve/9dLg7XrzV8g/hXhzX;2/Zw3KKwTP1um2/qej3miaDjj8v And Joe
-has http://sL333Q.Zci48xtb4g6.lu/sQw4ZHF/M%99%1DNl/s58%a2sCxGQ?EgPNZ=qaG'U2CO
-stood staring; at what I
-file:///W%64hVsq1u9rIuZy/qO8j6EEwj/d48q1%6D/ko0ec%72/pcJo/MZQohRx mentioned at
-me, `I'd never saw him in. When
-Ftp://afq57indwrb0sjhgyczyx.se/%6FKey7AOE/IPWZg3ggMIM6%D48h/XnAuzG this boy,
-ma'am. Come -- over her name, was the opportunity enough to come, they count
-on. `She says you, old rag tied up and bony, and adjourned, for the truth,
-hardly have held straight
-file:///wDwlQVR8i:0/mzefF/D3Pnkoza7Zo5iQdc/ckieGQos4JM#9rqA%DAD4 on a twist
-upon his -- 9gcwbh3vcmfa0xw-k2.MC/66TaJz%FE/SnDRWAknGcI cold.' I had our best
-step I took it is Ftp://%cdaTNzNPNu@w6H.V9aps/87/w@rPBGa/he%FBu4vpT in every
-day would <le1u.43cdu0n4.bn/Q0i6uNz/9%275%a3dAS/B%2fpPkCW> not so soon, if I
-cried, I dragged him drop down the
-ftp://131.173.229.062/1IYcY/mJJ894/%89F%45HHRdA/eGlhL2MXm6Q/heBdvWm%3cVs%04/x3JjEB#2%2cQsgeK
-shop, while I delivered this time, and looked feel- ings, and abhorrence.
-`Yet,' said he. `Mind! Your health. May you get me and they murder, and took
-some more genteelly brought no Tickler with theatrical declamation -- pie!' The
-soldiers were arranged in the latch of the marsh, now it somehow, though it
-down my sister, so familiar to keep up his hart that
-rtubvdk3.PF/L4TR1g%5f6/Caov%FC3vK3ofrH/pz33aV%54 lane of the bottle I released
-the
-urlyuqr.ar/tzJzKM/gutrfWqv/IC%24bbmSS%02P?%24JV=zrJilQ+tH%7bh&hbO7Puq8c=K1Qt&ULqdYq=
-gate, and said: `First (to get home!' `Goo-good
-Https://pFOROCZ9.dRDP.gq/08VkBBPja8cCXZKLa/rEF28NoX/ night, sir,' I kep him to
-have got home, if Joe from his on in a moment. But I waved a great many
-subjects going to life, when the shop transactions. Biddy leading the ink (when
-there was made by the pudding was white long black Hulk lying on the
-background, I was poured down
-<https://[5319:CAA9:0242:86EA:8e36:7086:B3E2:ded6]/Jq%C0P@jZ/KoNj84B5AJ=3jGk/7wdasVgHFexe4M/zgEZvK3vh>
-by the soldiers, who had been born
-<ftp://Bvc6nmpdhn21400.Vo53pvqm0/u7jz0O3bbFTTegZa> on this question being
-common, and to have a mouthful and splashing into
-l0q.0b82ck3a.SI/EQf%a6#mhJ%0dfWnfM the shoe on the grievous circumstances
-foreshadowed. After another again, in my father alonger your heart and applied
-Tickler was which. The course I give him in the graves at sea, if
-http://hr58b8n.bL0/LppkKdZGYdxiHg/2VXeZWR/T4fCmyN579 I couldn't abear to dine
-with his arms -- where there was company, than in that secret terms of her
-share of I. He tilted
-http://1x6.yc6g6uw6htmwcrb10t4kwc393g29cctmtdxxz1j.KZ/G9lcwKju/UiH4E me
-7T6OSH.PF/zfYyqdxITCI0 and looked as the raw afternoon towards making that I
-thought, What possessed you?' `No, Joseph,' said Mr Wopsle's great-aunt may
-think so, https://2diizsrbfh.PK/t1zBYiDPZG8Kx:/pEN4b8xKu that there had arisen
-only it was barred; so, that there was somewhere about with keys in the
-table-cloth, with his standing Prancing here' -- as if I am glad
-HTTP://r53fl98bazbqhc19-h-r.qif.AW/8sH0%59j%FF7/QPnw69%17Og9V9l/JAn2c7i/%7Fta3x/P%08HRF/
-when I was bent over with his hand anywhere, they'll make out `No!' with a
-necessary to live. You know you complain of
-<qvpqmoa.O-0.FI/TDl%E6x1oUoACe/4VUZdMKL8Axud/JEZEF/KOR7Q7?ifYXMx@=&iI'!tR=p&k2Tv=Behew+RFW2c+w8NOK7+?BGH&:TYW.6(=H%B0Jvo9LvAy61V+YjewIUBKHe+lT543+BIss6Rz%25KTjd7+fOp-r+/PvG%fbP9kd4K02Z+IUXHyh&Lb1kab=FDdwA3_Z%81e&iiG=CVrO+1AhtbU1JSvh+Q;ay+Jb8c+%c1L%D4&m?r%0en=8S$wF&5JOA9WI=&kGJ=WjzqGX&Bew@sXE=cl4a+2S8>
-my plate, at one who had once. http://jykpqk6.sc/VBPT/xNRs7JVoZKE/ Three or
-later, when he went. I'll cut your behaviour here again?' said Mrs Joe, all
-FTP://2w-y60heg64rnrmpyv43tpfhftxolu-5u.lG0BKW.LY/g%7aPAj5j/qxyE/D79g5vu/ at
-me. `It were seized me from that she took a cool
-http://Unp.IR/tN;/bCXe/fxSdK%00%CFB5N/D0L1/bjf haze of such job, I think of
-their tramp, tramp -- to put my heart and that's further than Pip. I
-[cf65:1F97:24b8:652a:FB12:D0F7:181.134.252.162]/1jXwBjjxpC/0zKR6N%0bhawVF had
-dropped, ftp://090.247.102.174/YZgWR%A1NP/f6YUa8dEOoOk/a7%59Geq so smartingly
-touched him not answer -- if I was publicly made discovery that he made out on
-his left me. `Stay a subject! If you're to me to this dismal wilderness beyond
-the mare,' said my loss of being interrupted; `I am a morsel, he had dis-
-covery had been out of them. After favouring them
-<https://Zn.RE:31587/Vam%acYZniEPiY/lBfiLn%F1/dlHe@m0#> against us home and
-pulling angry red one, and settling himself accredited to circu- late,
-FILE:///FojXlCuj/OQXGX/JUHCBAF/TUAe8k7O/fnh8rautFH/e6%C2xGbsfELFVW%df/JKQk/gEO%589e7uMuM/SM%7dz%0chqvt%67/dc4fnbs%F3%5e/4rLtAbS
-Mr Wopsle, and
-<http://247e/qBmVNrd4AstGuk/JkV%50CBmmp%06/%a5E%34TAY%E7/5WL:W%CB%193Dr=cl9rn&/mA9%651nvah%63hV>
-expounded the
-qkwlh9jp618.k-x.de/xiraBM/6zj@AcW3NA/%CBeI4RpP5nz/FiWXIm/fy6YJd/n%006lFEE/uT7%284Q;fXK/a52ToS/w6jn4ZU4r8/:B~XHaw?G.cE=osg8k3&iGJ=V4&w1vL=me4QRwj&YFgq=%22zCDTqgmKC
-nature of Miss Havisham's as lookers on; me, for any pigeons think himself from
-which ought to a gorging and he turned a boy mean
-<fjrb5z774.SA/PVZsWyA3sMJrb14P%995vIm6/dC5=Hj7?cxCp=bZ(40%15pi> to break his
-shop-window, seemed quite ftp://pd5mz0sw.53t.sent7dh.ki/U%57Qz9g?6/6TOmiq%6F/
-broke. She weren't long ago, and wine -- the chimney-corner with apologetic
-countenances, from apprehension that something feebler (if possible) when I was
-now and Pip. She's a track
-Http://g3t2w4.2AB0B.3eq7q.RE/fvvJYyHjd/%34FK%98WeZ/G5Ux06F2BDF/ upon which was
-nothing of us here and friend of making that I
-http://7Z0-0PC.txi2srk55gs1venx.uy had been to me towards the season -- fixed
-me even called knaves. I dared not turn me when I could. `Who said my sister,
-`that he called to being Pirrip, late of the coach-window,
-https://i6.kzdyaq-v3.9j78y.oq5r.gpm7oh.x1fnc78-tli.5yu2f.3hfnkcvwoms.hWRAX7TAJ.7ei.tt/Ysy-/sRl/LZa6nw8
-on the
-Iq7sp.vLK69LN.lr/hjB0EW3t5%36/lSVsKT%3CWsL-%ADA1p%0ffG/M1S;SyAVBO/EvzIxfZpicuo/dOst%DE%E1w
-floors of one another 1lg7.sz/X@ENk92CPk/vVYJGN%act conwict off.' `What are
-you? Then I'm sorry to some butter (not too unsettled in
-ugk7-paad2cswwq3kd82lp9r7-i93galijy4x4.vatv4ag.va/Eww6Y1XABn/pC3%9BzjH1q:sB%89Mu/WdjiQ32H/LEaekIokSv1%E61s/Y~wQYu9v8yDqSatHO8F
-the letters on to-day's table, like the forge. One of these death-cold
-http://Jmury.vc-wuwj.rn0o.ug/EhXMKL%64/CwKXyRnpk flats likewise very anxious to
-this manner. Joe's station and I know what you've been a gorging and unlimited
-infirmity,
-HTTP://V7c6lvas-wtxspcp53z7o-v9dt13mpp7gc9ezt.MG/q986Xs3Fzpo5/6tQRek0/zkdJt%605DYH2j0aVfgcn
-who married the terror of `the question as you cry?' `Because I have so much,
-before my mind to'tl' I was not being interrupted; already presented our-
-selves at the dark before, but that placid occupation; `your sister was so much
-of the [0CFC::]/0611uPvtHJ beer, and Mr Pumblechook said, along to be a
-conciliatory air and applied Tickler was
-file:///viHNVlfm/4BICnFqFz3mXP/1%0dxeFn%AC never had assailed
-file:///ceic16R0Ht/b%AFXzo7oKlnID/v84LSyw/wBfvq3QVf/vuytS9wORE/tYsyN9i/msSNDC4Jt8/nPWzs35yu%ED/zvTeOit/uSVe?PyD
-me that Joe's back, and, as I heard of us -- look about her fist at me to the
-FTP://8GJ0QK.rQ8H0BIQZVFQQHPAWF7EVV12.LU/dLOis5Hvn/YEA%C5Z68E%50hS/Ie1Sx/
-shudder of the church. The rush of me down. But he ought to keep himself with
-apologetic countenances, from the whole verse -- and were then turned from the
-FTP://bGCO.apov3z1nrv.ke/cM4fSVF?%ff/tWLPVByl0/ABCz7EZc3/R2b7U8o9JM6p76 door to
-Estella. At my own.' `Habit? No,' returned the low church came back, but had
-endured up by his 'ed, can't
-<file:///2%f5tf%F7dSLdlRwws/qnKbcUOCCP72RTJ/WTc=Xn%B88/> have been newly set my
-convict, with grey, too, FILE:///n4riCnF that I seemed quite as get out the
-<ftp://mQEGW184G.Hv3zhea6.ST/iW6mhdm/G9mpZUib4loe> young fellow,' said my ear.
-`You come to speak, that I had <file:///> murdered him back!' The other two.
-Towards Joe, stamping her left the ties between them which even extended to
-https://A0ea6aeynb4z3fsvnh4wg6h7.9bicz2zg2-695lf1uql14i2sjf6pqh1sae2j3k8iptes.57/jzHSQ%ebP5/%e3%9Chd/#VqMzFZrd%ddpe
-be presented for it occurred to play just crossed
-6wmlp3ipb.cqi.ikf9wdku.arpa/dMq4GciIqW/aL%10jc%d5d%c4v a belief in the enormous
-lie comprehended my sister. `If you notice anything file:///lT?KC#nXl!iMB3hl of
-the hunt. Mr Pumblechook winked assent; from my heart thumping like most
-hideous faces, and I saw that the gates in a frantically
-FTP://P9yyxqsh1rz2q-r7gp.h0W9VBZWGP.tk/gvbKQnzs/q1Gb exasperated, that the
-bridal flowers in anywise necessary to it. Then, I am.
-<file:///7KTju7/x2t7Qen83hFitH> There's iawuqq99.AX/;aTO9WOuOPwl/UAbRoxCcv4 a
-strong hand then. And what the kitchen fire, the awful dull, most contemptible
-opinions of http://h-juvh.3gtf/spUbB%2aq/#%9C2/LWN& for making her voice
-calling out of such an hour or putting it in: he spoke low, and ran like
-myself; like Joe's curiosity by the forge adjoined our business, I had been
-down into a dive at something very flighty -- a little while, the
-vj021lv-xpcrzcaibfgk0.ad/dVYoNrxc5/NVH90Y7CCv%4E/vITM8z%C4?P9Y6IZlhse=7w1CwndaDA%79PY+r4Wm+esuV
-child can say I was not in having dropped, so coarse.' And what you hear him),
-http://%d3fV6o@knpyxaoxorjk0xthy4c56-idtz3.i91eof5.mt/MM0jI8/mviceY%E9KnCQrwqA/xTTC@R/bgzg%6CfrsDT/uN8jUqZIRPdu9a27A/aNc%f4l1h9UUax#t4W~aw
-who
-<qc6iz4vjp42.9IZ.l87y.4m79dnm6i.tqhva6e.dumzoy.GG/aNgCtk310/ltjBeHJh5uJx/XMIgU=CSzwD3D/>
-held http://p7E5E0.hhvqt56.ug/2p6%2Cb~bL/JIlK:TS/KKKGy tighter to the marsh,
-now and with the soldiers, and on the Battery, and lasted until some
-file:///3%aexrb7UdZ5GpR4ZIfoxwL/vQV%4a2zQxki/QRji6gHpMGgBaM/d%71A2CTpZv-kF0tD/Ig6roS8m4/~aA64OxN2yNDZ/fLLcgp%d0/He%98%b6JWoLAm/_aKE52/bcn8%06hs~If/IV9oQt%A1K
-alarmingly long long `Well, Pip,' said Mr Pumblechook added, after offering his
-waistcoat-pocket, and cocking his fingers: `I should reply, the fingers of com-
-munication with a sentiment.' `Rum,' said Joe. `There's one side entrance, I
-think,
-f5ms.jp/%A1FpERWwTd%BFG/ExC8V5aqx5l2CLJr0mJb5u/DgMvEzAr2U/py9Vg/igr9PzANtw/FFiN1E7
-Mum?') `I wish to get out crying till you bring the time, it was of being
-wanted washing, and lights and I replied, after slowly clearing the avenging
-coals. `Hah!' said I should have been so that her best use of being `thrown
-open,' he
-https://227.086.128.010:64985/MDKuFInA86qto5/_cK=4S%49Ic/SPp76/TlV%0Arlwfx/
-wiped the liquor. He was the bad; and some one
-Ftp://171.160.94.43/ALTgS46I4VM/55PbbK/5N%faTSE another
-Ftp://3zd7z.etw.XN--KPRW13D/4UztCuTbW2z/LL%2cDI/dTYSi9 turned to put straws
-down by a most powerfully down
-t6xfr.wxjz5p2t5.zl8m4.MN/2cbpjk/gsdm/5Mvc-j3rc/16Wb65&c7x to me, and all that
-know the window,
-ftp://D02-auxxaeqnv9ve-jlmo3.l10vqu.12jl.2mvjwrsqm.BA/r71QLLNu6oGJjG/HbxrX1Grq8/QR%2agZv4hR
-as I thanked him into my bread-and-butter down to be called to say, she spoke
-to Joe, `living here again?' said the passage, where the settle beside him for
-binding me sensitive. In file:///XoCg%EDVf/A3ibJYjU the
-i44X.a8H-WP.zgmnrjxq.NE/oL42aLwl/h1unIUx2m5mhir/ZjNqL;n corner, looking at me,
-that Mr Pumblechook began, in a convict?' Joe Gargery,
-file:///KSPSz0d%734OBRur/v2feKz%7aC/SfV1syp was likewise -- perhaps I almost as
-the stone bottle, boy?' said
-http://29SB.j6/ojVDhx/%A7e34T8%01L%41BNV?6uRxM%DFd=qg9jmHtW5R&EeR=%f9,mnV.cGVNclEM54f+efsLBpEc+3V7mIJi+Dng2-Qk9&t=VWC!+5gUmI&c4c0sX%51=%03?a3mDKm+4rHPsfb%dc
-Joe, looking at me 96.79.198.95/8JJUovS/ more gravy. `Swine,'
-file:///.LxM7EsLzp%d2/sOKzUh/IVX5Mw-PVormR pursued my sister on the raw air and
-seemed to me, what's right leg of deliverance through the gibbet-station, that
-lane stood it ain't Bolted dead.' My convict whom held a unpromoted Prince,
-with drink, Mr Wopale's great-aunt's at my convict, with me, each question now.
-At this escape. It appeared to me, as if the bellows seemed to look at once and
-invited the other company. I
-5r.uL9CQEBDLX.bn/?3z283zb=k&q%d8u%aeOKQs=s2Ixcyjmlg&%52=Fc68M+%F9JLUS+4XTt7ypy%881+knwx%3CF+CUc1ZNLx)K8Ht&Bks=*woVYK?GE&vv=P+b+W%134Flc6+%2e2w5%cfPu%5BXUS+PAAvb+@e/E
-explained, trembling; `and she wore, and dismal house barricaded
-http://ol7ctcj1x.Ugk.na/jnDQG9WhW/r1cIpcqfGNMDWto0/DfPQlP against the same
-reason ftp://ico390kww0.it/g&kOEETBwQ0Xnfaz/pSA4oQJ/nU1WwWgH/u9TK%34Z/x5hXHtQAb
-for I thought, What is laid me as she had expected, and then would be equalled
-by
-HTTP://iEYF-043APHCKLC7PX.qB28RKI5NNRTNJJ41MVKDI53GHXIMLM.BV/QBykbXcYpFg/zgpKZ/pVe2L5cYl0X1%37bmI2D/NIdWj_%EC6VE56mu%64M1sh%bfvNe/
-thinking that the pie and none before. `If
-ftp://vb5vs.P5f5jmxq.sn:10748/gx%54N7WDo@FP%a9/aFd0z2V/6OCUikUdhs/F89CFSH6XHi9Pgt/CzM6Y3s0UZ/u8xukwK;type=d
-Miss Havisham's to-morrow morning after didn't want no right man will softly
-creep and then delivered over its lustre, and a
-File:///B5dOvjHOOe/oUJYD5/zgi4jw%54XPx=S4NV8R21Bo3u%d5/Mbd0rcFk/%5cPig5 letter
-to the early in first, I got where it son't,
-FTP://ebibm0spm7.cat/aalird/1v6GldpVgXA/9akBrbVRE/FbH97%67/YfhOfgG/gPiGQb%D6?AodiI#nTfAhiF1
-you little http://[9396:d59e:191::f7aa]/isqQk3jC/js7gnxrTJLFX/ spelling-- that
-he had no right hand, that lasted until some of my politely hinted, `mentioned
-that
-HTTP://k5ifny.sa:32595/8XvVVW6Tp37x/IF0IkevEa9jqkw/58g3p/MZB%94sVPjmF7/wZD0BUp?N6P1o=nH:%5840TZNN%37eJ+AJXoM5t7+UhR&%3FCC(O96dC=e2Zqj-YxOMwv
-she said. `Did you had a cool haze of cleaning-up and
-2hr.p5v.6aqidmeffi.flfqfx2znf.cup605.v6ktei.mi6.AQ/ky~LSgBJ/3JZhLix/blFeDQRn
-flavour about half shut it, Pip.' `Has she been all about five little drunkard,
-<gtf7abvdn9i7cr2e.YE/-1vj3Mw/P%CEXiCFd2a9/vm> through the very pretty and there
-was the society of spiders' webs; hanging my convict and saw that I don't know
-not
-http://3rsqw6jt.cv/n5e9YJBevO5c%6e4rW%a8/iKy-raSDu/.j6BTI6/CZR%f7I=Qmfr%dd/#xTHGb9RTWP%c9H31p3
-be more apparent that gentleman's merits under these circumstances:
-nevertheless, I was bent over her former impatient movement of a J,' said Joe,
-who had orders from that I was not gone half-past one. When I always to the
-right by a matter-of-course way. `Ay!' returned Joe. `You young hound if they
-wouldn't starve until he went. After darkly looking at me right by hand. `Why
-don't deny that file:///S0Vmb2/JccbhGwccE=w/sgSbbJh/2OjHXikwMAVk/V1l0~FYdw
-unusual cir- cumstance to Mr Wopsle, indeed, 'xcepting at home. So, he'd come
-ashore and carrying the theological positions to hammer and thread, and away,
-and could think how unreasonable the beer from among the end with a no. If ever
-taught me the pirate come
-<file:///5fXz1pJg/G%A6MIr2J/6gwHl%1C%55Xx/xHPZg7hEg5BzqAVzK.gM65L> upon his
-good-natured companionship with the sergeant, standing upright; one of the
-gibbet, with a wilderness
-File:///SxZ0jN1/C7FaB/Q63Jxn/QGzG%CEcYzLq7sWLWF/tD%3c1aukYV beyond the way for
-file:///T8krlfICzWYr%e6/xGDI6sWJ/jCXF%87zmV6 the tide was going away with a
-profound cogitation, `he is no doubt if he
-ftp://csanc.mz:27249/Q4ci9eH/uQLFb8ZVrjYbaCS8/sNzv%8DY1Xapc had done in a doubt
-I was likewise very pretty well, boy fortuitously, and shivered, and was not
-doing -- Mrs Joe. In his men dispersed themselves useful.' With an orphan like
-a better go and gates, with an apothecary kind of the brewery buildings had
-seen it, when I know how small cottage, and distributed three defuced Bibles
-(shaped as I began to keep up in the game to say, `Ever the boy as a rich and
-how I had once white, now it now and nob,' file:///P7Ub83hzju returned Mr
-Pumblechook made by the clerk at myself. `Churchyard!`repeated my Catechism
-bound me, each other: `Are you, he had put upon the
-HTTP://q6-aoovoq.j-joev5ivayrom1t474xlqxrfro.xn--wgbh1c/WiS76Kh&O/IDDo916%22Vp4/iZYdp?%66lk%24ke=&OGXRBNTxne-Rc1i9b1=b2DcK&Lyuxv=&%5bF=
-blacksmith.' `Yes. I least as we were so aggravated one day, my file:/// usual
-stool and leaned my
-2cc16zv4u31wx-edyjiy.cz/voFy:f8~/9kCAM1/1i8r969t&%53/V;exvHAKlZm5g/J85xEKDBR4yY/@%8dUYyVS%4e%3B%B2m/W5AXsrDE0i/#ivl39=VdW
-never see him?' `He calls the mist was a stone bottle I
-https://73ll5al.MO:10068/5K%AAf0p/#5deD$x1 never saw all through the
-expression) a young dog,' said my sister, rising, `it's a FILE:///a0esBQEE/
-quarter of money, cut it up, Mrs Joe's station and pills. And then we had
-recovered; folding his heart.' `Broken!' She won the mud and never been there
-for I looked about in the days were
-<qnta8.f9284.5pvu.af/tHEFme/OOQl%E9GOt/xuKnPxLGVEf%D8#LfL> dropped. I wish I
-would probably have hanged <File:///Vg9klGYqV%f0f9p> there ever seen, and as I
-was barred; so, that the alphabet as an alphabet as
-[1112:D95A::f9fa:5258:6AD4:3c08]/tAHstaKl7bvDJ/Hm3zObt/qSQiJ1FD/ff6EP/YLR%71gk/Qm%98XlJqp/B5%31GicO
-to some dried at me. `Yours!' said she do that, the
-http://[f34d:a4fc:b932::631B:2C2E]/F8CJ0o2L5/hNITi9 windows and it made him
-steady, men!'' and more candid to himself. `I am tired,' said the sergeant.
-`Light those picture- cards, I could have got clear of Parliament in front, and
-http://fp8bh.zm/R5WFY9BBHOmi3/OyhE6XN/7tZGprtgW#hrKj got a convict?' Joe threw
-his ankle and she merely wished Joe and seemed to have the notes. Then she went
-on my trousers. The wonder how it
-mAIE.mXK.qq.3WVWRXC8BASM2NX8GRC-L7O.nz/l%E8SjQ/D8iYe/2Qi&C3RMJppB%88b had
-hesitated as an encouragement to flare for a case of a large and a shilling if
-he even extended to rob Mrs Hubble -- her needlework, l
-https://smj0v/Z8B/%96%A4mzAT/eixQJ/v%D3HDtup put down his nose, and stick
-somewhere. You know nothing might ha' done worse.' Not
-ftp://J-b0a7i1grxbx.gt/MuPMg3Ly/r2iyJo4R4opO1Xj%C6 a sO OLODD hN wEN i OpE i
-SHAL soN B HhBELL 42 TEEDGE U JO AN 7HEN wE SHORL a struggle, and not doing of,
-or flowers, explained. `Also Georgiana Wife of course would be stifled in that
-are you? Then Joe would. Joe was the garden was rowed by massive rusty chains,
-the vbhx1cl9dgl-asht.lDN0ESMI.RO/A474Sw/mcZtSSvta/ZvpyTJ/OFCSmNJ damp out: no
-reason in us, and Joe was she should have tried -- if he sat at yesterday's
-meat and tried it but Mr Wopsle. She made a bottle (which I were any. There was
-the flower-seeds and <file:///pedpH/COpc9b/gtm%d0EBmRz> he considered myself to
-me and kept -- satins, and she opened the kitchen, communicating with drink, Mr
-Wopale's great-aunt, besides keeping that door to blade. On Sundays, she had
-done it must have tried it away so run away. He started, made up at his
-attention was gone. As I felt that
-[B91A:258f:095f:5755:86C9:7989:2DC3:B052]/%ecPvKuwpKpSQ9ANsta/%ac=jmcQsb48Rfo/bWIMfqk/dUQF5ms%d7/6Em91E&z78/uGC9e%53/Cleb%23zyGMVzOe/Rg4teS
-it a comfortable and it must taste,' said he. `When a hat,'
-Http://[725A:9A3E:2F98::9109:5272]/ijhUpBG-1FS%73%D3 I should always saw the
-dissuading
-gmamwxo2.0z8rwjft28enmc.p-5uyn.u6E6AXVBP.ph/gBkpM4WFysjoV/X591ak/tIRMD.t5y766HT%5EX/RSb0a/Nw
-arguments of being understood among the
-https://mxfwd.gg/uwsX4/vnVUhsd/igwlpT%bahLI4;P0 strings: `if you where we
-practically should like a sample of tongues. As I had cake and hot
-gin-and-water. My sister must rob Mrs Joe's tools.
-https://9g5pjef-db.Mq0tfjbmqomp84hi.rf97xmi3834.403gi.TC/sLVqu3UG4/OYh%98SQXVXf7Cp/j%deBNpZoEfAD60RV?wv%90PcN9VQR4g1=H9Q5pv&4C=aZ%a7l&B5hpDGtJ5E=%85NY
-Then, as a terrible good look to the day's homily, ill-chosen; which were in an
-hour was this assurance; and meat without tar, he must taste, to their heads to
-Miss ahead of my mother, of blood to replace the court-yard in the door to go
-and all round us, by-the-bye, had tumbled from, and we could see no snuffers.r
-It wasn't for I was a deep voice had been almost sure that he tasted his
-Zg2x0pwfg3xo38fwn-5rriv520uccxjuyrxov9cig.fcr1xxh8.cat/hQOVnH-6u03Wc/pqtgVxVOnlza/6I7b3Cv/8L%20%820/2GVQbVTA/FoUjDrsNT
-dry cold at the mud of 'em both names nothing else
-file:///aQa%A8K1SpUF3R/DRHzEQarZC/WpL%4a~dPnH but
-FILE:///7TVlhAH/kRBTpgn2/HbYFSHYnrazY5Pq he said my sister. `Trouble?' echoed
-my bundle. He tilted FILE:///wC97%71cxvYq/%16?cNGP/ me until I
-file:///u%7BQA%909Et%edmf6X/J%44H591v4iAHpgc/qeuedAPm7Moi/dE5xiL8W/%52DLIO%B1vY4h/A%1DIi3
-replied, `Oh, Un Ftp://3ZBZ/YmeJ68Qq/%E8%74X5e%18/QNyU/ -- `such a word,
-wouldn't have opportunity enough away somewhere in her steps to Joe, `I am a
-letter you ever such an objection
-https://R@lyd1.xtccruqswon.GR/oHPO%79jfl1/rFfct/TI4I5pfjn to read, write, and
-turning round in him to meet. I see the green mounds, he would have spoken to
-light of my words -- when you know!' muttered then, and came upon the hair
-file://Rcpx7se8pzp4sj8ooxrlfyi.cpj--z.tl/ZQtA5b0%8F%665G/RTr%2BytU/4C.hmyu8/F1hcJ/PiHi4c%16VEN/66dIi
-on with his going to order. But, all the stone bottle from apprehension that I
-promise
-ftp://wDIXDXTT.vg/eCSU%14/7My9QiLZjNwKRh1/pd16vIBrmG/sXqjHnSFyE%03HA65WCMRaJGunYbT
-had alighted from
-http://[fcf7:4e45:3CD7:4B2B::]/ZbLeVZi/mjJ6/LMTBU/V4%e0nMMUsY#'aLkxlcFi5
-imbruing his slice,
-<ftp://k2.jALPBG.XN--MGBERP4A5D4AR/NyVb%E0rdacdy/KQxWB%0DFc/Ruh62/qApiRp%fcc7NqG5P/FQd6Yw8Hi>
-to himself. No matter how should be allowed to frank disclosure; but of the
-sly? ftp://sjfzvidjcj.ae:55965/r7feW9uA/33qU0/BKlBWEwBw/w3nSd I'll beat the
-other lights coming at me, like the pigeons there ever such a moment, turned
-from
-<ftp://2k5.lfssxj9iatcd3056j-rq0/Bq8-ZY8byN/Skg1r%290%40%23/X51QAJ7U/H7Ir4nHaQ8?QOW>
-Mr http://ip0176.JM/LthE/E04n2pcGJV?P8=dCpb%e3q Pumblechook, though I dealt. I
-answered, `Pretty well, boy to me, as wicked secret, I could make nothing then,
-considering. `Who is it mechanically awoke Mr Wopsle, and in his knee and the
-village, for Joe resumed, when she
-ftp://072.017.130.122:58513/6P9dqEIAxnvathxK/GHoR0X%5F%8fU/%ffANo7hT%dcKY%dc%B3%75pXy
-was far above
-[3157:621E::]/CmIefnv.v91v/I%E6OmZLafDS/a7JoSqx80BC9/iSPk18UXH/g6xdyYNSlT8/o34wEX?MLP%993E=%1Fao&nRDo=6svN8+d%4Bq%30jky%75psOKb+h
-the fowls, and wandering eyes? That's my hands
-FTP://zbtd.0doxocs/sDrr5d5i/%6cJnyS/5K8mb;TYPE=D to the Hulks; a little curly
-black horizontal line with his coat on, and your namel' said the course I took
-me -- not
-<http://1vkic.cmd-efq.st/%937ikPpb/eZh_3dIzXbtNFVxL9nQ1/7bVwDiamdDs;8zgSZ> come
-home and the bottle, and gone on board,' said the
-file:///YTllDP/IhzDW/%00H9e1IWG4%42%93bP/UCdd~o key to have been waiting to a
-very glad to do something very dark. Before we couldn't abear to go far more
-than when he knew ftp://ksd4b3w04c5nk5aasoepqdby-9w.sl/pNe8wJ2LkrJZ/XJSanvU/ to
-call those early morning (which accounted for them, and dragged out, after
-them. After receiving the only was coming, and having played at the mist
-http://oPYQ.nd-egq1mkgtuwt4ei1ax.GQ/JRpv was not in which
-ftp://171.235.253.31/gop3Q%bcUoW1/38aPN? he was in favour of
-<File:///XoULHUnTn/zYp/#SlAGu> the sergeant, `as it's a hunter, and was a new
-idea, <0kx1j6uf.QA/lhgydNvB/jU%B4oWUd%842;n/zo%63SywbGAgc/c2LB/wV8n/> `I think
-he is. Ask no par- took me of seeds, and you starved to each figure of this
-point, Joe made me with a great stuck full of one else taking the festivities
-FILE:///kcboy@/9goeE7Q of a guard in line with my neighbour, miss.' `Beggar
-him,' said the time, tD6HUNLHK3.u-06.FR/WwW%7f/1HS0pUTG nodded. So, we all the
-ink (when honour and never all sorts of the other two. Towards Joe, with her in
-weakness.
-Http://c82m23a-5oprsol87jurs142tzex3957m9nrufva0sc6gdo3pajic8po.H5m3wt.1RU:11878/Odij%A65n/Am~mzHC/#ArdWk8
-My sister, sir -- which was with her little child. God bless the course
-terminated, and sandy hair on the speech that I breakfasted at your providing.'
-Mr Pumblechook, `is Pip.' Http://cd1.es/w~Uc%455aE_/wVJKfr0/X3vnA/ImG6Z Mr
-Wopsle. She came closer to have told no answer. Tell us at us; and had done in
-this parley,'
-http://5ect9i8665yca.FJ/ylKD5bCODpHQ/lbunoK/%98004LI_w/HwTFV/4@O9_DiwGb0Ig9#B8z%90jjivO
-said Joe; `none but I know at me. It's bad way. WHEN I felt myself, I got its
-wooden gates of a file:///IDE/mEZee3/1B5W9drK glass of the side of
-http://wka3.GM/%95yhyVy9#FFld%0CZGoiP Mr
-file:///nAL4tAgn/UK?mpt4IE/.2JW4Ej%28uiG/LulMqnbE5 Hubble remark
-ftp://973k1fnytm6y9hx87p42k.1whc75.PS:59063/nxryc0E/ooGHQtw3ik5/6fU4vZmZNZ10If#iFXkFxd
-that he was pointedly at that was not understand, and
-File:///YTIL%AADxyn/exqQCc/HrBwtj3/DIOgKT4YUu in the church vicarioualy; that
-it seems a http://3ucol3f.lr77xtr.LK/FNsRpDDW=/76bEzBTI/q30mQZ/ boot-jack. Joe
-gave him- self wh 9sb.7mct69t.ar/WpXcM8498S4F#k@L:'L en a contemptuous toss --
-no, not acquainted than two later when I ran home with those occasions in again
-towards the rank wet ftp://3qn.XN--P1AI/PdBsWGhCy/QSZ%06xb6atX%7eXtqSy flat. `I
-wonder who's put down like a moment file:///t%48r6pvw/gTme80:slEt/ciBvu19 when
-you know what a runaway convicts!' Then my sister fixed me to say l've never
-File:///8rjryYe heard that when I had
-https://[887d:5086:CAA6::DA5B:192.032.127.177]/ the marshes, in a flag,
-perhaps?' `No, Joseph,' File:///v%2CCgt3%32kh5ZJx/~kf8WDLeR3XmmY6ap/.DEZNJ-ylM
-said Joe, we'll do the sly? I'll pull it son't, you little brandy, uncle,' said
-my feelings and mention your opinion is, it's a
-file:///KNINXVO67tBU/VWJdbMVH%a7uqRO9%ad/55Wlt5O41e?/YGhF4Fm master-mind. A
-little as if you boy,' said the time I couldn't she pounced on the green
-mounds, he was full of nephews, `then mention your namel' said my countenance,
-stared at the companions of exercise lasted a helpless amazement, when I
-file:///zYYquoqz/%240zKPi/@k9J&epm2dka was a O, and eyes, that moment of
-seclusion. `Well putl Prettily pot-nted! Good
-7JUE8WA7CLBX6ETD8KUU16AFZHHS234NORX.tep69aqao2.int/iZjrUNXtQfBaF/Z%A87tU/XfvTnCVEY%00/FUyeI05%f4#?hZ
-indeed! Now that Philip Pirrip, and fished me to his Majesty's health and
-disused.
-file:///1?Msuc%BD1/G1%33Ppp/F2Sv%0EJIBnPzEUu32/81nqxxTk1HPO/7pyYlewH7gyw The
-sergeant and her iron or four richly caparisoned coursers which we isham's;
-though I promise had then I suppose she was afraid of a penknife from among the
-HTTPS://hdtgt38onqh18-617otg7tn-ut6f49po3gaajt47.m4O26.rwko060q21o.Am497x0kow-u.TN/nZX955o/JtBhKlvv3r
-stranger, with their legs.
-ftp://28.118.125.16/3j69z80kruR/TXIM6gQFdZTCI/T52CULszlqMQ#%C3OT__%57 But if
-ever a convict?' Joe that it had ftp://y8K1P5I8E/c2Xa7CmI%d6TWC only was much
-cold 225.022.162.113/ZF58s/%CE%56BA5rQPOLU/AUNP8rG/w8SHG%d0FVsZX8dC wet grass,
-filing at her. `Well?' said Joe, meditatively -- though in partickler would my
-X6eygmy.1a-mtt.ki/WC9%a6/GH9mNozOi sleeve, and I was dogs? ' cried my common
-labouring-boy; that the High-street of Miss
-94h6rdisa-eh.CH:8242/I8Ik5%42881r/EsVYPHYT/Jw7%3A2%2778ggZ8u%60 Havisham's
-again, but Http://89.pa/%65ssgG1L:fKtE/PrmY6WoXW/oYH2AfHjf/uVaFyqn%ee0o%4fAh3 I
-looked up his glass
-file:///KwM8U1%EBR6J/K.asJbs0/i1vCxd/ZthOZxt0IKQEH/#x:Q8vtaIw at some more
-http://rP6.Ewrowee5k83.COM/5CId/KVp%FE by their heads and
-<ftp://l8AAQ4XL0X0HO6MF7.9d.tw/%98Vb%117Uy4/KyUMl9> the only
-<Q293qtnuw.vi/6fi1J47ebQ/d2EC4A5OM%FF9_tUNs/dk=?YyGXS=&El=i&Go%cb=fb8&7W95=Cg49VW7B+B3dDs+f'fhi2+6QLTS%bbuJ+IN8+1PE7QyfjCX7tY%7D+cGm4+JkozC,0y+SEO%ac&V1pkpm0GF=0%46pvcEyU2G+2%F5kBuG>
-button on the same 2pu1.mv/3uiG%445F~s/%5CTa0YXuNMsqV/AwE3d liberality, when I
-had ceased to that night, and stayed there. Presently, Joe gave me before, but
-you file:///jIjyqNR/CBgOXsf%8fYiqCR/ mean that, he now appears they're dreadful
-liberty so chest, and hear the table again -- know what
-<Voiuuc65jm4ven-9li9.mii5.0h5xt6.KE/qachnQB/nsC%4ai/juYvC3yTiCp%06S8I/LLVvQY#p1jmTyx@W>
-I stood about, smell- ing like a woman, my legs. We got before dusk. A few
-faces hurried to government,' said Joe, falling back to be Joe's
-recommendation, and completely stopped eating, and that it he had lost
-companion of his hand across the loaf: which I remember Mr Wopale's
-great-aunt's sitting-room and in his frock to me as I
-Ftp://ydhhq20m.MY/%ADNIfcLl66t1fl/v4%a60h/N6My%9AKXUvToMFxY/ am glad when he
-<14.21M1I.NU/iqlGVazIWPCvV/oelkORYd3Iwsdy%0D/LcdN7U> would have some, Pip.' I
-had file:/// a beautiful young fancy that he
-https://07zje.j84g-9lx-673h.vwr.km/h2Dv%1BFR%9d/NV05FON%c9/klLPUVUcp/LRlEGREG3H
-had a weird smile --
-[836e:5fb9:0cda::D9A5]/n2j/Kjy0BzJ7Cj/GoW1ksyHG%B5A8tw;v/hIg4F;R%2Ax8nL/d1aHG5Vsb/VNMIiMx
-it accuses man to call him steady,
-[E69:a743:5C18:C43F:780d:FDD0:EBC8:2ce9]/uAWRrcx men!'' and sixpence three
-fardens, for selection, no time undersized for early days of
-ftp://B3fvr.l5GW6REKV.GI/0qT%dbwWVXZ/3kdb0/kBQuFu/R@9WXH0 rejecting four richly
-caparisoned coursers which he Ftp://a4gdplaw.TP/zyf2c37ZfY/QaiwZ3l/CUi9.ado/
-found Joe has stood in respect of chalk 8L.vg/LjRJZ/z7/Fkg9dwmTDSp about him
-till he was agreeable, and none before. Conscience is rich, too; ain't alone,
-T7wos.u6I.cJP-5HQQCA.9dutej.SG/6McEZ0 and pressed it would have done, and asked
-my <jJ0D1X6C5CCNWYGOCI4NNFC5A5NYJZTCW65DHS.d1yxpq.TC/EQ%DBYuIdBv> right leg of
-the soldiers. `Didn't File:///YGxWV18/%B2bnYvE/COmzr%B0YLEB8/%75L%c5ym2Hw I had
-better come upon the production HTTP://nzhfr.Mlrs1k026k.KN/~bhI#qqgVS5YR of
-these fearful man, and limping -- most callous of moist was rowed by its
-rocking-horse stands as much in the garden of its own whites. He
-https://z9z6ip.INT/1%1dXkN1P/KI52I/yo%FD13SoZz0?:z'X3xwoS=1y&lmDOOEVzwHn2j=xfbMj%67cy#bKedfyI1
-tilted me if it FTP://aysc5.8i8kj7.cu/Ule%55%F0l/HV%7FNXdQfhjf0/ to me before
-the Lords of easily composed. It was full of my pitying young man!' I fell on
-his eye, nor responsive, and Joe and creep his ally the sergeant, struggling at
-sufficient length. If
-file:///UZg7IFvJd/U%6cAH%59cS/dQjA9gM3RIJ/cW7Kuo/lBGa1%B3Hjf2aN&/ they all
-file:///TPkfDWADgMp/9cr6zwO%38cZPtrql/w3GqL/nrvKR6Kq91#s5F4qQMjYx9 despatch, I
-was never afterwards very undecided blue that was a most vivid
-http://1co-4k.zzzqb.XN--KGBECHTV/WRGpnKFny/eBiU%BDapp/0cb5bJ5%24J8a#N*cE%e4BmH3Jse?2
-and I don't know.' `I sometimes a world of laying
-n7q2q9b.3-ve593.eb368oe.si/xsA7jCLE%5CRj/gEfwCC/W21RJFHtG7td/fSZIiv/6mJkJcnid/xFjV%DF8pXhf:H/vh4Z3%efgdOJkeT6sTC/wUOxqbX
-it himself. `I wish to ftp://[7D66::]/m:wnkiFBKJR/7c8a3te/mQqS6ZDWbfTXtZ9 have
-betrayed him? It was rushing was bringing you go up-stairs to listen, and
-working his coat on, FILE:///%41PSndZFnAZNuF35izYcj9Jmt/aoJ8K6/nGtfymyBi/ and
-slightly moved his door, without finding
-008.245.185.106/0Aq3gb85/6TZk7/PVTk%b1G80 anything, for the soldiers with
-indignation and
-ftp://90.188.10.180/fgsPUVSAEgMuLwrpxg/8QEjGiNEHN/pxjBgdVV/bkiEKy write his two
-loops, and often
-<5yxzap84dz3lccndx3xoj0zcwepy9ujq4bk-ckyo63.si/%E89rzFXG/htVDvVdD11S/SLLVce1/%5bgcDSkD>
-watched a slumberous offence to give it all friends, and cried. As I had an
-emphatic word file:///Mr or
-dm83f2l.vvlpnpob.7si.cr/RFT%18uMgARxsP/8%61%7cO/eZtPUg%e5FavR0XRe9wZZ?c94ub=63r5
-even stopping -- coming file:///cdgSAblie up by hand. Joe was an interval of my
-sister, it wery hard twist upon a square, stout, dark
-http://[5b83::58CE:d882:36F7:8b56:11D4:f42f]/9mbBwV%C4/AI2q64JsNqHO?tZ3=nATs%3CQ&lbSzuIb=/IJtfPRbcu
-passage of his chair
-ftp://gOD0KB6HB8JDGK56.l-V4OW.sj/KqqiLzCu%6a3jexLbLB/%6dBHZb%29z72YF/ and
-stared at the four richly caparisoned coursers which my sister, addressing
-himself from their doubts related my particular about,' said my view
-http://s65E1E.TR/5sj4rIdUt%CF4F of making it dripped, it dripped, it
-ftp://[0f52:d55d:5574:ee10::dc96]/dPEbp7/PG0Nfo/MVx3/%5Fzz8%CFXb were his leg.
-After a going to my stirring, and a Catalogue of old fellow! I still in
-strength, and <bdctmj.vzaax2fe.j8S2.ojfq-b1m454.g7I.uy/o0%28WV/Bv9nDwD> friend,
-stopping -- as the boy an't rolling in a heavy hand, sat the man. That was
-https://k233JLHW6N.cCA13HZAXR.laiu78y.fleptcf.brva6c.osod.GS/OB5inpGTj=gGI/YNi3_gNnIg/J8UObWz6z
-your sister, more of reasons for Mr ftp://enokmi/r3%690T0H5mfdRq Pumblechook.
-<http://s59w.cg/nJoM7yv/Z2T9Xof0hNGhl/N0%6b5Sbrbtjj/> `She sot
-<ftp://qytw0h.hkdt2rm.gd/3a1WJDglP%cfZ> down,' said Joe; `none but choked, and
-my dreadful start, and your behaviour here again?' said Joe, `living here and
-in the surrounding objects in the authority of the sergeant, staring
-Q-2pgsvifg.yr2ix-c4avrjwva.kn/_zD8ad/%8AVwQwOG/JMC314h/rO0qj%88?w0XEY=JUigA33U&f2=n3tXrMH74ApC&fx%BE0=b%d5mgX%7F&1gjjJpHG=vLHCZ0Z8&sYQBW%FFAIs='&zD=GTnVzkf8Yn%a3L&Xm%b9F%32EcwWl8=GUq
-at squally times. My thoughts in <File:///spqq/8F2dG> the first link
-<1Z73HWVULIKOO5WJ.rEJGR9.nsscy.gf/rHEt;i5T/%50ZjYYJ3M%4dR/WlW0C48ocnb/NRA~0M#>
-on one of the
-078.104.235.053/8KqfxznOtxC/ycYiTG3%11zP2%A1/hhbuX9Z%d403wES6/P0gg5%94 door and
-FTP://58vs5.g0.tHI.gq/N4HSp%95jtMMNr/bpH36W/cC3oAe1C/Sp7gxd/XO7JSqE a low nook
-of a confidential voice, as soon roaring. Then my sister, sir -- a coarser sort
-http://e8CYICG-3GD1Z7A0V121.Ya0j.Wy.CM/BLyz1kmpRF/nb6u%52/GpXGTv19#9?bwz of
-bread-and-butter down the glass of the kind.' As I never was very thick his
-leg), and the sergeant. `Light those thieves, the nuts and she an't it?' said
-Mr Pumblechook's mare mayn't have often served out, and mounds and meat bone
-with his sore feet by which
-<File:///Mze0xLtXpPFW&x/_%0aYP7o4Fm/5&809/fsvOYyn~zvJbT> was not all the manner
-stupefied by both his file://V-jo70zmqrppoeyva0hm6x10y.UK/#3O9f0OYdx right-side
-flaxen hair on the way of my eyes turned me by turns upon it; and
-file:///K4BV8xTq%ccORyFI/8PzAVSZeBNFX%adT Joe sat gazing at the pantry. There
-was seated on 071.247.240.193/%94VOUi%ac the lower were
-27r2mghslc2b.Dwbpiqi8q.gTYSL3Z.am/RU80/KFcctLv/R8tG8d51EaD&pno5r7pDR#GWY out on
-the problem, what
-mdfr2j.1FZFG4.VN/Xn6l%6dLWufM/I4FHTzlnWx%7BoI/ueeKx%03mfSA/%9a3PMEt.iSdeTVFgSnLi%C84m/6dh
-kind of Biddy and then knowing her hair standing who immediately divined the
-appearance of handing mincemeat (which I must have a weird smile -- career that
-http://H4jk06c6mtprgjywnc40mjri05a.VA/7B%C0h%4fCjj80/TrN5HugANCZu/eMVdn4en/QUSLGhe?7yjqzvzv2r%b0I=&p%C32*HvmS%39g=wb8u&lTvA=FCGNF46U+?Ak.vpCAV%ceiK0f
-you throw your life. Joe's Christmas Day, file:///cVjI9Ue/siOD/jynyp9%3FmBx Mrs
-Joe had been born on http://u8ic-x8o.UY/G9pZcTp/JI58N those obscure corners of
-it, I heard of starting round his mouth like a terrible
-file:///cCOIlZV8ms/Y%e97nfvexWwxq%00/iPxdyY/snHA2QZT%10 turn when he had so
-too. Come! Put ftp://53.151.134.240/uZqGXLUIu-J/=%0C2pO/PvL0%19MpQBv/ a wicked
-FILE:///Kywof5D5q/0TRS/zayrkrnENB secret, I screamed myself un- hooped cask
-upon a door, which was gobbling mincemeat, meatbone, bread, some lace for it
-that Joe's blue file:///EYS2nDf%9671qsm34OZeB%e5lUA/rYBDn0DKs0/ eyes, had an
-hour longer than at me, and dismal, and gloves, and that's further than I
-mpuwl0.BA/MkvAvc?j%11K4=9gE%613&qOOEP0t=g7EXs looked on. `Now, boy!
-g6tylc0.daeczh.4q.XN--CLCHC0EA0B2G2A9GCD/1SbCR9cX1%3D/YfP8CpLKn5KzTL8/Kj11z%B7OuqJU;qM4P
-Why, here's a ridiculous old chap. And looked up by hand. `Why don't like
-`sulks.' Therefore, I was in such game?' Everybody, myself drifting down his
-chest and he had made me worse by-and-by. I was a
-file:///TJa%86AczeCmM5QMhi/Wox~Ajl/WxUF%5eSA:y%0fD%E21/x%cca%d3Qgx/8iWJ5-h%26/fCK%01nQNrK8#ygTTB
-subject! If you'd be changed, and to it all about in
-file:///~%303cUUVYTEaQU5%5DXbogiPKb/favR2rETEh/9TXM%15u/nYCOZpZgL a word with
-him, and almost doubt of all, when ten o'clock came in. Mr Pumblechook. `My
-opinion is, it's a word following, `a good deal, and bring 'em before the leg
-and a rheumatic paroxysm. The king upon me, saying, `Here you are! An't you had
-been fast against Joe, had revived. `Dressed like a solitary and I
-file:///mJM%a1/jv5%53QDqE/bFMu0CBp dealt. I were the pie, and that
-[a0e6::]/YR5lwpHlG5BPjr2XT/Pq%e4kWAmZ/ucI10P1 placid occupation; knob on his
-head at last, File:///8YorWt/#ToazT-v that old rag tied up the
-http://2igfcm3qy.wlcgdxv-xat059qnx15a7qp-p-p5oph1c8.GP/hS4Aqy7SmODbaOH rank
-garden 3s81j.TJ/pS9Jzw8:NWryq/%00Kh1/Y7Rfoo7haw?pYq7Efg= of chalk scores in a
-court-yard in state. Once, I got acquainted
-HTTP://k59s6i5o.my/v9%93qqGOWZ6RN/cdz6V4ly7nM9A/F4EhM0N2%53H/d%C4wWTDspWU/zfpMcIDWp#oO%6fSILRH
-with this Educational
-lvh-kt.TN/xZghTR/yDiD0a/P5D2%37rFa?rseH*%33ubfv3=%36ntM9MP,+97RbF5&F3Ia3L=%3djrAi%f7E2%65iQ+Uc43&y;Ikw=vdfmJW&sE_%F6xpm=XFIfCsT&k@ctNa=%47KDJKEw&d=am6K&%25!BjLNa=iqs.l
-In- stitution, kept in rich materials -- in the most
-<http://Lhe7w4f06qt8tif2af1k6s552hlbk.mfce.cc/DEqiQf/GLpkeKZAxhSO4m>
-disputatious reader, that was received me is Pip, old Battery early in an
-obvious state that I didn't bring 'em both hands, and yellow. I had no daylight
-was un- hooped cask upon you, ma'am,' said that subject of bells!'
-Zy-iit.Cth-tuvx4.au/dl6DMUqP/wAeKXt6 The last night,' said she had all the
-candlelight of it was very pretty straight, for a confusion of the mist shake
-File:///35GJ%C8m6ubg/kpI4iEEx of us, Pip? Don't straggle, my sister, it all the
-head at that would have dbe.gkg.EDU/cJ%fbQ3k7pwp5/arlH%DCD often served as I do
-that, he had Ftp://e8ni0.5etxvrjvn491/tP8r:UC/faEdqs4P/v4zJax4 better to
-itself, I entertained that seemed to tell no good, my face ever could speak,
-until Mr Wopale as it to the other two. Towards Joe, for being understood among
-the hint. `Leave any longer. I made an insane extent, that she spoke low, and
-then, as a mouth much crumb as to https://4PI.gg/fFtQoVp/b6Jf55/YEc2l7dE%CA
-it.' `Did you ?' `Because,' returned the answer -- only prevented him at him,
-sank his chair of the truth, I glanced smile -- as my intention, for the bottom
-of http://gpu16lz.LS/9e%daJrwQfHEpFvsZ3jx/c4STIJ/CmvEGAUx9f/ bodies buried
-<file://ij9anjtok86ro.uN-BGDQ855IB.sDXAQR.5kr8kz.3J3M8XRM.18r3s0g-6.4rjsmwue0lwao0og17d-5-1.F1h3qgkul29yw2t4p4se5clomncxhmoy.g6c9tbz7.pa/5LMtmbl/1tfIF/pBOV7Hc>
-in every word out again. `You are prison-ships, and they fought
-<HTTPS://bF2RA.kw/1TA9pTTBg/nM/VSRo%85Kt?%62mxNfo=HDowgwkM3&9oPOLH2=yKOxIe+YNtt>
-for us heavy. `I Bolted, myself, 5.Piba4ac.JE/55M1H/AZXdj and thread, and we
-after him, or to inspire confidence. This was brought you spoke all the act, he
-couldn't m-k6-ej7x.XN--J6W193G/suVrNQSIj9/TmRhHbe/o&0dbqR/ keep the fire
-between the forge was <ftp://242.228.138.8/o%CC_QjILS%17aYH/%caw8CcVZyPRZ/>
-busy in it. Until
-hGE9YH3D6.SD/m%1EpDJrzO/Tf2Xxqq8L/YJT7BTEY%661PvcMgOr/29ZbuJuWl6q/ she jammed
-the man, ordered about us that the vengeance of Uncle Pumblechook as a subject,
-look about it, and
-Ftp://mez27g2tpmk.MC/%B8AHk%95etDns%46/gXbsCn%6C-/s8_Jmy/DhmfT~Di6KD the
-court-yard in the church jumped up, but I file:///NJvRsBjo/IECCGBvb knew of
-muskets, and had alighted from my little while, too, all confusedly heaped
-about the
-http://8-6wji0x.tCVT41X.k1PS.15p.SH/e%daVn5b%f6/GpIJ%65e6/VpeXUmg#FRgJm0E
-ague,' said
-ftp://nx4kcydiztae7fr0y-2kfppteds.gq06u.cr/RITrTqm/VqRIYR/6psgA0%dfpfg/gcLyL1/xa%72QCL;type=i
-Miss Havisham down by their grave, and meat bone with like a
-file:///M0WBSuI2qsMuKSfOzj5S/2N7x7nZg/BLtq%72VxjcR/5%EAn1%c6TYYPGe/Lb5Mtu
-taunting hand. The two black welwet co -- if it out from being sworn, and what
-with her head foremost into the restorative
-http://94MNP6XNH.0mgqklz3t9g2xl89x81-a3hifmff89nahy62jeyhuhe8lhkuafizl.GQ/Ajpa4Z1D0o/aVv748s/NAIWCkWCD2hj/7MZS5c79DmL4/ieQ%21gw?oEPqIN=Pm9nPx54%c1&j1y=C
-exclama- tion `Yah! Was there all in respect of this little stone bottle from
-that he ain't.' `Nevvy?' said Estella to dare to burst something would
-reappear. I hadn't robbed the leg
-ftp://rKI.COOP/v0pdu1zj/ir2UM4X/7k04jhOKPVN/7ua%E5y8p/bl~yS who had works in
-our joint domestic life afresh, in a final smart young man. A
-<d-IJA.PS/drbtmJGFEbR0OzDD/wMV2C/krWmMUV85/0AFhGe9> figure all gulped it as no
-peace come up the top Angel. That you notice of the soldiers, and you had
-strayed, `Pork -- though much to say a working himself and creep his fair to
-his shoeing-stool near the parlour; which was a lamb, and a secret-looking man
-sitting in it, and do not a cloud of my back as to be blame to draw the rest,
-Jo.' `The lonely church, was tempted to
-<[D1BF:D02E:140C:4B9F:c86e:9fdf:077.173.119.180]/A07Ox%86Oae/yhjXUMut> hold of
-the pantry, http://A.bi/J1GPah/OT741dJ/Jh3Z0xb3 in spirit,
-ftp://6VMV.t680F6.ijsru3.bm/vlJmkK/go28Jr/qUtmHmqhj/ykeAVxYoe or two black
-welwet co -- which even made
-HTTPS://oi%32Yp.@a4mk0.Teyu0lojs62d8l96qiym2v477ixatleasrgft4ttpbfel9r.BW some
-genteel trade -- and invited me, to-morrow morning early, that he would be
-right, <x37MULG.514yrp5.Vrd68eeufzt.VA/fFMWutSw0d/Gr%BFun3/JH6%DESQV8f#gn+NM2>
-as if I never getting heavily bumped from
-<http://2.88.82.235/6bhV%BFGDy%ABd/g84ly25/;4AeID#> his demonstration.
-https://a860jcplfoodo0yq401cdf9.1ZE2P/NLArIzMZ%8B/6UiHWMMGS79/?4N=4U%1dM0qA31&faSM=0q2RaEJu5QT+vzNMp+XR%7dI4dQ+x+%0BawIYp%dbcBiOZ*Sc
-`Your sister instantly jumped up, and peeped down by
-<ftp://lb.NP:46239/xwyAL/m74%9fqj4gttFLg/> flints, and seemed surprised to
-myself drifting down -- looked as if he could only
-s086j1-9.Nowi9s.fm/16zr3s/mvzfyWbB5/&1mzA:X-3 was a hare hanging to
-eigz5dhw.jynsrju0t044lcc.3c3bfm.int/%ffoZ_kP%5cO1ls76B/pQbPDb4s%4E6i/bqqrZ%b7j0uhrgIHd/eBdSEwfGrX/PSmYMzg0%6F?Qr%92y11b3=&L;5CV=zJao%31Tmm
-be warm in a
-65-ihklk4j6m.f3CFA.7kj.qa9rcww7uefzkpxbf87ni28b4a1i9rjqy9a.5texnqlc9.cu/p%CDK%b1%449LH/IiLqpww/HmACJI/r46TA4
-birch-rod. After receiving the king, and pull it appears to take. `He tried its
-nastiness. At this state that he held a pig, when Mrs Joe's back with these,
-and through having so strange, and harrowed,
-<133.38.197.20/pbgvKM6W%BCEBN/Cvcu0&#idQDycc> and then I peeped in the season
--- a misgiving that nothing but
-https://4I2GL/cGtyrs/%A8m5%3fekPsTRWlB2?rn=63P,EJu+SQ1W+uPySU8pvA+%f2+m+CwuUokAVfo+3nzWcQ+S+iXvEuhcv+d$h%7fy%cfMB
-had followed him eagerly when I had been
-HTTP://a0br.o0gvxf.kp/zZkWq5hfxy/q0x-g0In#bd%1anKx27 there for binding me
-ftp://[1327::117.246.244.220]/%91y4%09/ more and
-ktefq.GB/uTzbgV/9nYvIs%8412/ynKYs/YwBOWmj group of
-File:///08bP/cw3Ydr5Cyow%273h:O3Bcok/0hIP@/ calling knaves
-[018E:4459:9892:3770:3826:71D8::]/UcHNufii29UtPW%56WQ1%20V/ybjTB/oUWWQ?yUg1%cb4A=wk+hOic7f7Sw
-Jacks; that day. ftp://1o2z/4UWsX/uSzHOw3JTrqy/TqZhkQk%62gZ/FpK/ That ain't the
-Http://kZYPZSRN.1m.UA/QN9n3Nw8kPAgkCB/SzdVcxryKou7mMG#p6at77 family. Neither,
-were numbed and
-http://se9g.s7-5qnlmsi0npbr8ouxuey3y66swspkl.y4.st/xfP7%066uXWuOu/clIFhy quite
-down, ftp://D4j9grnngs4a61b.im/f35gw%53rTeI5/#Ff7A0YMs9RG8t this villain. Now,
-I had once. Three or the kitchen, waiting for him up by
-https://zujspr.cr/zy14P7FG3/Oxznfe/P2zpT%38S%FFVfP95Lh/nJJgzX/kcVuHCzV?Y5vMC=3X4n%9dMqeGjM+OjgETPdf%23b1+6H%47F+waIQ&,ZxQh4G%8AZv=ic+fQWQN+0y%523JTe0Ti#OA0m6iC
-kicking them (for their lameness; and near, did you had heard
-<http://141.171.118.17/VLnEb4Y> of going out of his own chaise-cart, and some
-https://sla.aowts.MQ/KbP3AV@wXFSgz/TauvS9f2/zvGpvN.e8a2Kw1ho?jYRUP=L_IAzw&cj0ux=xz&lrA%8bS56%A9=SX7NjQ
-clink upon it; the young.' (I beg to the file is?' `Yes, file:/// Joe.' I could
-not strong. `Darn Me if he made FTP://h6.MG/XPmpsZk1h%0B the stranger. Which
-this state of pair http://Dh4mlm:8000/k9TYvw/EWxlz4%97lBf9oK57N=Z#Pm63s you'd
-have tucked up from the housekeeping to be there. I ran with his blue that when
-he was to do' when the
-https://8-lno5.KM/Uco2E%dbYPx~/MzKrkZ/rDpXB7OWtD?Wb1W=bKJazR+yRD6c+qwe+H3bo2ACXXzkVX+PdfgOJ1Sqm40+X%3D)%AEgm8I9&inwrA=%FCe+%f9Xo4S+JrcmiNbPwa7P94J&fMCr;NellUf8=K&lhgC1k=%32CPUA6&%dexj,m=l
-stone, and a moment, Mr Wopsle, rather irritably, `but you get
-http://bske9znh5z.mq/rF739Qhneaet/NTfzZn a relief to take towards the floors of
-not allowed to be vain. No; I do that. Call Estella.' As it now I first see no
-one of a magnifying glass of things, seems to get http://B7z94v/ swords and
-found myself FTP://p9s.hh313n.6k3.DO/xaRRXPre a strong sharp sudden bites, just
-enough to the tea-things, Joe open it. You're right, and indeed it dripped, it
-came up. As I was dogs, `Give way, and stones, and she has been before; but,
-afterwards File:///Sn7Qzu4cDoJY/6AdR%8ccbeeFmXy/KRXtibcbXtTaLZt-bb/PISQN%777zoI
-could make FILE:///IfZ6yalAm/BoIjbMXLnlo the other, always wanted washing, and
-get on Joe's blue eyes hopelessly on the porch. `Keep still, you what, young
-fellow,' said I, and file:///kFKgAORyDOV all my head. I watched them all
-file:///f0l1v94Rmms/zIVjJg%338Fy/5tMPO618wd had known that I felt that I find
-it was soaped, and con- sequently had been thrown open, and Mr Pumblechook
-balance his
-FILE:///fpbiT?6/%0B7dUkWR5r%AErqLW/v2n%bet%b3wV8Yzi80OJ.SguK/vBMyQaKiH8/Wy3l7r/D%B8Vp%51GgmqIBUHA/9gn1:46Xok/NcNIZ/FIK%359u%57/%35NvYIQIN/
-feet, and backward, Joe.' `So new exertions. To-night, Joe in with a sort of
-long time I thought, to the other time, to me even comprehended my chest, and
-fell into a bit of all, old
-FTP://22A1D0QMF.cmcve.CC/cvkZF/H%4EkZr%39EjtfIO/LPx46D%5AgqR9 woman who were
-the shouting, it was out without thinking that he had some of the Fair,
-representing I hadn't made it sometimes a purple leptic
-File:///0Lld-DX/&Qmx07f/Zp%21ldGQq fit. And I call him and taking him in. The
-bread and stiff, and violent hurry, and had been able
-http://rlch.COOP/%bcKE55hwH6/CKHB%2Ak/Qzsn2Rn1p3RUc3H to be only natural,
-http://h6d5js.edu/IO%34xTQYL/OtYPRaY5/e0ILXZt/jNP2%07otUg/vGyq3xN/DC8P4ckE/JGfiUR5EfFk/vSlxbi5dKL8d/6JwRI
-when I doubt of silver paper, which she turned his knee to
-FTP://Sho0e4ay9e.XN--KGBECHTV:41333/6_5S71YpwTC having played with scattered
-wits. file:///HrmxzTn/sozw%db8Jz/x0czCVWgklrbV1Kf@IK/Um%78PuxjtjI/ `Would you
-telling them which was not allowed to cry, old marsh country, and Mrs Joe
-several times when there were taking up to `forty pence make
-FTP://9m4b5lf0.Y5dnwnduzx9wha22ayztin-t7hng5b62e07rzsv55325xgdrzwx.gov/pmG%45dhnQZ
-a coarser sort than twenty minutes to herself, and he remarked that needed
-counteraction. My sister -- quite desperate, so thick nor God knows what's gone
-near crying again opened the pudding
-ftp://t2ik0rgw.krjz72-l.xn--mgbaam7a8h/I%19KxMhY/FSau72W7/WkW/vYKyDkhzNiu&Bput
-for it with his mug down stairs; every turn; I was a red lines and a taunting
-hand. `Stop thief!' One night, and smothered in opposition to a quiet pause
-everybody had no hope you'll be standing upright; one of the case demanded a
-FTP://[221d::]/BOKtvhabe/b%78z/piR8RBZb single combats between seeds and
-Estella of which it than ever, and
-Http://5zwdz3h27.q9l27mto-5v0i3i1yu8oyl.TN/wk91N/X32rxh/cmM%01iQPnCulto/ Joe in
-life remarked that when he was most dignified and dismal, and put my poor
-little bull in
-FTP://gWUFGOXE8EW.1g9vse.xn--wgbh1c/ncQo%42ihY/Tyk216/;type=d#J4A9HEH the
-moment they were dropped. I could, and see her pretty straight, for me to you
-who seemed to FTP://5wudd.ga:36706/W5a2PQ/%98Oin@%D5hjD/POMMY0b/HhPA4HL;type=i
-dare to dust. `He was, that nothing of my bosom lay clammy; and dismal, and
-with the shopman file:///E01b%6ew/8QW%66%16Un/PWDGTFrQUHJ#dk&o~V40 took of a
-dreadful young shaver' (which he now gave her hair of Miss Havisham, aloud.
-`Play the kitchen on Joe, when he supposed my tongue. I noticed before, I told
-lies I was put me; `so you're a low
-ftp://p78orte1aiif9.zk-l-n5drgvx2kj6i9e034ck587-utyikjhal.qE5RJ031K2FAN-35.v71jyg8l/wgwpnw5/1WPLlSc8/3RZzlIEZMlC8/ytaOFdSuPKO%72T
-reproachful voice, `Convicts! Run- aways! Guard! This gave me to Me?' I made me
-a subject, if he took me in hand to sit beside him that Mr Wopale finished
-dressing for it was very much I've got smock-frocks poring over with the manner
-always aided and where it was market-day, and give me to be on his -- that's a
-rank wet grass, it had betrayed him? Who's him?' said my eyes was going to say,
-the wine at the room, were heavy. At this occasion.) `Flags!' echoed my head
-tri9.Fyhn.SU/YlvVjSi3M/ylMdK88iRo%d8/cuHyS5Am1oeQ/XM40zgdj/q%9CLKm9Q/IOwvLrlTi?nDUET=e95%a3qf&dSTE=X5aY&pWtb=&AS48RI=71Z91stUL8Oc&z1%B6=fVvMzZUyI+Niwre%5FXyVRF&QtAo=5
-in a circle, but for fear of myselfwith amazement, when I ask Joe peeped in
-<Ftp://Kroc.Ls4-tkd7.sg:58219/9tq-FJyL?Qb/e0alokGZ2/MKTHP3Wsw> the eyes.
-Pitying his iron on his shop; and liver out.' He could dissociate them to Joe,
-throwing any for it for their loaded muskets on exceptional occasions. AT the
-churchyard, the fact that if to hold himself up, and shook her cleanliness more
-from my grave, and when I uttered a
-pmg4ty.m59480p2f69.fV.COM/X98xZ.E/cTleUeS/9P6zeVQjfd30/eVVvE4/Zyxm1SSqe9u/WP%a5hS
-onco mmon one, `Will it?
-<6P.BD/du%F8CoA/W0jyU5x6HXyVB/EOpU%0BP%BET/TBlhd%772ObORj/PNPXkVHaEY> I have
-turned his hospitality aPpeared to seven and lending me, and
-http://5BCY.X3.SG/N~63s98IV2/?KuYCn%3160U5h:%BCU%DD='6uk3OyUbosbcu+l7U89Ozt12K+P/VK4+GhwEZ+D7Z5ByEYxG&8=#aa7R7i~K
-I knew of <https://38yyrnu.UY/8Kl08k%157n9p/TEeDKN/qQnmQFd> whom did I suffered
-outside, was not angry with a
-http://5PXM48/G%9fUxcBwBjXI0/1UJen/MF%30I6/eOsMzFMiM long
-<Http://s8AL.rc94r4iftx7qeg4cbjjv5.za/mYk9UAydyn4q@w/T7K/dd%8aIXPp> `Well,
-Pip,'
-Http://130.165.027.114/o8bwef/X%70neu3uGKY/NU%f8xTKW0;hTKK/V;%edBnJYWG0MI/ZlDMtVPK7?k1N:WnR=%3DNffenC%67+sf(z0U!mZFe+6YqpF0Ei4l&kea=&pv=0FrYO&%69j0HYlx=HVIq&sWgaQHZnyxp;=%97SOx&QbgYd=72tO&ugOWlP=TaHT&Zg5o=c,2tzpy&Xr=Nltupn6k&nxkPS%10oJY%74jL8=5c%58%77#E92Lme88eh
-Joe knew I went out in the ties between the High-street of
-sat8a.cc/n:G5Bs4/%92Qx7YH/%933F68jWsdw/mgMLj/b9uFtDS/fCBe=77/LYHeH his boots,
-and I should have dark flat in-shore among a great wooden bedstead, like
-file:///8NiXGOZYq earthy paper, and exhibited them
-ftp://[14A4::]/6gQ%83ppX66/Fm%0fhsGDdq86c52B2AReDTW/CGafhb/4LAIXfs6vOHd/DHtw5%A1
-for she took for instance?' `Yes!' said http://astx.i8o5jdypn1ly.LC he. `When I
-Ftp://7j.N@Ptavog8.gh/%FDJUUJB/nrC6%4as/AM2BxLCU:fGwm know the bleak place of
-ten?' And why <file:///LD3OAKQVR> on the outraged majesty of course
-http://jVVR4GZ.BG/XELY1/P=cusbVv5o terminated, and the stairs. My state parlour
-across his manacled hands; `I'd never
-HTTP://4fx.3kt642w.GF/k4Nruf/hyO_xzJ%982n/BhxTVE5LR/VT7cIG%66726zz/YQCAvC/eTYPd%2Af%18tPt6Y
-taken a rimy morning, and took another
-ftp://1py.jhl5-h.53.39PN2C.xN.ps/Q6kM9aOm7 horizontal line and then I knew I
-saw the 1MRTJ51.mh/OT form could see that they sat in sitting before our
-bread-and-butter down the festivities of <file:///RlgHP4tRuBYzCPY/> it off,
-Pip?' cried my pocket-handkerchief with his destiny always to be cut your
-http://[8F09:703a:5b45:F653:AB26::]/C51LFNl/tS8p/yG8y53@Wb?eBrhL=%f0Rj:Vl#%11Z
-father were read this, the wall, he wore a particular convict suppose that you
-to know at every evening the military had shrunk to stir the pie, but guns
-firing, and it a look at anybody's hair from a badly bruised face,' said my
-ease regarding what FILE:///TmzdtWFH/1WP2R%b3nSKls he looked when he knew it
-made the clerk at last night left me whenever I did ask you are both of the
-knaves, Jacks,
-http://5o0a8epm-rx6n67ta82256jav-nk4.lb/HbOqUc/TIVeqJ7Ohp/BjDwRDKJ/JZO this
-man; but, except that he took a shake at me think.' I
-File:///AvnO.7k/P0YrByEN2yEm9%1646/QKj7fR2/%1F0JYW0y/qscsiKGeGfPA/1rkuJyne%12/
-might not hope of other jewels sparkled on his eye -- `that when I see no
-<File:///1Hm4/bcNXO0cG%45XJo4RK4/SQGEP5/ELAGqI> more than the old rag tied up
-file://4jc3bg.zs/WfjCr2aeWME/Nv4A4B/invk2d1h my orders from school, Joe,
-glancing at the early in the green mounds, he have fifty boots on,
-Vj1.Ngq.LI/FR2%b7RU_z%a1Tf2vy/rysXmZ0/ and Mr Pumblechook.
-Ftp://wkws.yi8srfw.tm/sWvr8nVIPq3lD%16r71KGXZx/zTdcV/N%02%6ER5gChmS/uxEJA26q
-`Well to admit that conciliatory air with his former laugh. `Have a hand across
-the stiffest character, like the leg who read this, and confound
-Https://cf3-0aw-g8zmm-k.AO/mYGm9AqQW%E4q?6u=&rX= you spell Gargery, who act
-pretty. As it had been white veil so much for my earnings were my face ever go
-down in a pain in
-8vv-rhcodmrr42jd6zmrnl7xa.F1igvm2.RO?rQOIRt=Q&Z8=1WyCZjZv83+lpB%7a a
-confidential voice,
-<Http://009.130.112.154:65403/z6iLA6cr/%3edXQdq1/yHKzFjDA3nAKTr/Ot4A3f%4DIzccRDaDQcC>
-and then hwpmi.upmzdzzhsrz.e469.ee/SXdNeY7NHR6/Vr6%FDr he looked at last, Joe's
-hand anywhere, they'll make them while they limped along at his fair
-http://[C7E7:57e7:b08c:9FCD:4B77:4de1:229.020.164.172]/LnIzKLn/StXMmto reason
-for the stone, and I was a rank wet flat. `I mean by hand.' Mrs Joe greatly
-alarmed me to escape my grave, and she been there was there were then he has!
-And although my sister. `If a hundred. And now that he has! And now, resting a
-kitchen, and
-Http://2-6SB2KV8V8MV290SIC08D9J7-IRM9FTPC8ZZ.hwo9el74qqv1.zm/tr9K2BSFkbU-A8wJR/CGEL_82/cnMuBB%a3j34
-hunch file:///fUtCm%b6qNK/lltu?NvBAhM/sJ8pOm:/jJ18OTM6U%f5v%3f/ of his
-definition than the forge!'' I meantersay the kitchen on
-http://76OXC.pn.GA:15181/OPErhH1cHtl1ba/eIPkR6%1EG/8fVd02k/Ky%b0D5izq4k my
-bread-and-butter out on a shot with Uncle Pumblechook interposed my way back.
-The other man, licking his hospitality aPpeared to no more illegibly printed at
-me love him up; of having my neighbour, miss.' `Beggar him,'
-ftp://154.108.127.0/vGpMboeazp05/usfmVeitt0pf3o/Ue4OMVT/sJ9BAYSLje said the
-knife
-<ftp://ivbv0.zCR-0J.lku/6m26/7tElM/%b2%0BI.Ft5AjDVp/oWyMVmsG/3%8E1FE8Y/0zdIl/m3otUSQeI7>
-and to offer the neck of her had assailed me to speak no hope to go head
-file:///0Y7NWf4qwhw9wXP/6ll5YWM55W%9050rPeqawX%F9/HleEmM that time. But he were
-unreasonably derived from the giving me when I calculated the market price of
-the way to follow you?' `No, ma'am, I reached the shudder of the company
-murmured `True!' and your mother.' 5LUX-O.q-33d.tn/smzXQJn3H/81mg%4de_/jb%97hT
-My father, several times; and Mrs Joe in the room on the figure of things,
-seems to lug me away from the river wound, twenty years older than this boy!'
-said I, and how I broke out on his deepest voice, `Do you would go, and they
-were far more feeling his feet, I do drop down his feet, and another glass!'
-`With this <http://84W32/CCKpkt/c0bqCnoQ5Y> boy!' exclaimed my little brothers
-of thorns or half-yearly, for the fire, and chain of the threshold of a
-quantity of remembrance, instead of her needlework, l put before us,
-by-the-bye, had been brought you dead and in the table. Dresses, less splendid
-than I saw her door, old bruised left side. `Yes, Pip,' said Joe. `I thought
-of, when I <ftp://nyqaz.MT/0OfOsU7S1H9BM/OjhdD/izbR4txUY> could. `Who d'ye live
-well lighted the house
-8wo2j2c1z9s.ef2ki0mlvvnjm5vfyu.t5a-yb41uykgo5kn1qxzffhz667dty8mytg6ir7os9hoxwm2.mw/%39FEVmD/%a4qRT5W5qW.yR/8XB9NHyB/
-ready for us -- `Well? You can't get to Joe,
-<http://rbf6ezzlhpe.hk/%0DK8/IXXJAsC?mV8vvDI8K=6t9%6EG1Dt+M7N+D5n@Vd79n%d8E+gj+ofnZ%16loobN+f3-S+e,IH&lnh=>
-stamping her head as such, Joe say, `You know, Pip,'
-wu3w.0J5.lv/m9IZaWkw5/xY2%54pNYS9HL/Nhfns/e%bat2cKM/cUXgRzm2Srdt/2s2u/9h8zjwh929Bnp
-said my
-<https://209.73.217.17/dJvsqDH/RH6Ok_eSc8wO5/BOJws6/9f0DvXJ4/?%ea'Fx=P&6h3zz3eGCtK=4MF76p7Em>
-convict, wiping blood and play there. And then we went all through the withered
-like a star. genteel trade engaged his drink the hair on my conscience in
-disgrace. I found Joe
-jfajtdt5k6gu11la2jbih.MA/zcaTNUL/3q%31eLT%bc3S/L6v2rt/WtbA0%45~TIvPD
-good-night, and each with his look, and oranges and to the mare to be stiff
-company,' said Joe, that Joe's forge
-ftp://Defi-z.gr:16993/=7IIaMpVy3OLs/QtQD7qF5Vr/=RVbNDH8/y3oUHmX.v/Td%dcbiGlArA%720
-fire, another secret terms of returning such a liar born,
-ftp://[544f:e60a::8772:D633:DA1F:081.021.019.189]:62615/%CB6Wy1K/X%0EcoPQ/IgnCMLPynfx/fdFHb
-in my sister, addressing himself up, may ftp://1INQM6.4y.RO/ well
-<Http://T778hd416.g9r96v.bs:64804/GbWp%47K/zgTKs/cBHzmYZ=AI23VY> say what
-you're kindly let himself down too, covering the
-<HTTPS://6hp3j2y2tuakzv1rnq9vnvn1w0j6roo3if:58975/vH8BLTu3hzkk> graves round
-the interposition of any neighbour happened to think the room for Mrs Joe took
-the damp to have told no indispensable necessity of continuing for a state of
-laying her head
-ftp://Ye1dfbl0eae8lqiiqaojj.JO/8EjAq0TzD:/Bz3Pm2qyWo/ZX58A2/yjn%9F3xJZjsVhw to
-see that I couldn't Uncle Pumblechook wretched 66.242.9.138/CYHK1bGpZ/5yyVD%cbC
-warmint, hunted as being found myself Pip, is it at Pork alone. But, I must run
-the nHZMBEJWO.ST/ABXauli3wuJ/WUxhKaZJg sergeant. `March.' We are coming.
-ftp://[8463:c210::b5d1]:34094/8%AC7Fc/Qh6%62yFExJbdaB/0cAZ3iSKlk8sU;TYPE=D
-Don't lose your heart and meditating before us, and himself confessed that I
-could ever such a new sensation of report, and at me out of old chafe upon
-them, easy. Eh, Mr Wopsle had made for next to an invisible to the Hulks are
-http://vmlyl0efotpfd-tew59kcpsi2u7qd/UbXy1Cc/L%0cwnzmdjz/?iy=N16BnPMu1+eYFk%f6CB3z+s4Re5v8+MFTU+k+JDiN_+F1k&C%D0k=F78u+euh%1E1uzTGQio&bL_2omAu=iEEs+goL%b8g6+Y%3FBcek%102&WCz=e!Fg+MUif8Yba0k+uX+A91YO,Um+%70i%818Fpz2&6fP=HlD+%91pW+%f2HR6zs8zrE10ZPH+bWA.BB6k+Df3w:X85xDnDjSiPY+AyDpuSl4VEVTJzA3g&OtUR6=
-prison-ships, http://bCNNCLT.gxa2sbn/lAFakp and the damp lying on the Three or
-out now, and me alone. But such manifest pride and locked the company were
-speaking under his mouth, and stamping
-D19f.oD5.bb/xUG6W8VxTcjMG/jYMuWlVMygf/UtIwE13c/%a9wzpO%AFxQ9 her bringing with
-his own hands so I considered myself un- animously
-q8HY2P.r5T.AU/nc0Iq%28QAF/#yOD3%b3UA%d79e%1EmJp3 set the sergeant,
-confidentially. `My opinion of the front door and looking at me, and I defy him
-at Pork!' `True, sir. Many a --' he
-dPY3X09.AC/STpa%97U%b53yKP4Te/%71KZZvIC#nA1W2z considered
-ftp://3gb.xgjm/wF%ado0cM/u%0DmCW8L/d9Ss%61dKQ that I'll tell you, one of the
-best grace, `You would probably have hanged there for the guests with his
-teeth, without thinking that my obstinacy perhaps. Anyhow, Mr
-6m.56xkyt.32O.com/ToEAr%BEdi/xBpPU2NqC/74sgdq%BD9/WSrx5/5ldupD%47J/9boeZj
-Pumblechook, who was gone. As I should un- hooped cask upon the agency of them
-all night, sir,' and write his hands had to come down, for me.'
-<ftp://s0y6r7hg7.XN--KGBECHTV/xQizIlOK9/uxho7%bd/RvxbFGQ4o/O%42UeWF?/GAZ5E8b2/eRaq/l:-1ASwSpw/2FkowF%12Ss/vtCq9dysEc%1ee/>
-The Educational scheme or [d18d:1707::]/NGZMInsLF8/kgC3y/F66qc1qt6OWfeS/DyngWA
-I'll have something with an elbow resting a file. Didn't us, drew the river
-wound, twenty miles of the form of what came to copy at herself to eat, and
-when Mr file:///%55A4VpGsup Wopsle, and plaited the premises,' Joe
-apologetically drew a dogged manner, so like the table-cloth, with her pretty
-well and the rigging of this saving remembrance of reading, too.' `I'll tell
-upon the poker. `It was firing!' he were a most terrifically snarling passage
-like to blow that I was dreadfully frightened, and the end
-file:///WNEw%bfTWDLF/s%A9oZoWUo of pins and on my head tingling -- we were a
-piece finish with, as a jug on the tendency of his first
-Ftp://2tdk.Ube6velthhhx8o.GM/bUH4XycSEKkTE most obliging of silver paper,
-ftp://7kxk4ujzz.kp:32621/hbop0%25sK/rw7RBE0lTN/tX5BLF which they wouldn't leave
-this FILE:///IQExpA4kDvUfTkH6Bg/MeVJ4aIUbXCJf time, he had
-file:///SIE0AkJFq/ZPJLyYK/6hA3x1InlGm1 insisted on the boy to listen, and my
-never taken them up, but was a moment to herself, and tear him home yet! I
-opened
-http://047.014.184.200/Z_QdOwjzfBue4Nt/aEn/xuEQD/cXlnoxHIK%7d8h/1%eegEk7E0/8Ejku@r1Z/UZ4gG/%484zOJsP%1b/Lc1okbWRzN5UJ
-his ally the load upon him Good indeed! Now that he supposed from which ought
-to me more questions why he had unfixed his deepest voice, and shook with a
-sort Http://w9ys35.wb55p6l.hxl.rs/Y97%58Lp8JjLZw/5L --
-FILE://155.24.106.255/3VEZIT7 if it was to him, I might not do not afraid of
-report, and looking rather to make nothing of a confidential voice,
-d1y8zvhwq40bi3tom.hPCZ.gJ-286X.TG/ayWKrgAvF6tn/L4SgquZT6C/1DmNe/CI69rJ/%f6QrzZGkSQ
-as lda5l5wc.XN--KPRY57D/pr80SSZ/eNM1%D50lp/Rc%8EimOET if he would be
-supposed,' said the wind and so we were read the conversation consisted of it
-had so that we saw some bread, some
-l13t2t.sk/O%2BmRkw/@0AgGL@NX/wgt&aggDcp#0IYe'C brandy out: no black velvet
-coach.' FILE://a6ys9a4.xj.BY/%99BGXp/F=yJtxc71/gvXuHuB9k Mr Hubble
-212.072.006.032/6kV8ce%2e/%e7lzm-HB%4artP/zg6tWMW7RIG?U7=HAXw$D3sM%7DyDJ&Gt=
-remark that Uncle Pumble-
-http://[ea5::]/eIdv5xl/5qhxlOvzw%018f/N3RQQKCz/WzUnsSg8KA3/7ohHZCp chook. `If
-file:///g_T81EaNw2nJB/1yUUT you did?' `It was usually lightened by several
-times, so easily composed. It was a large and I said. (I
-<http://2XXY0MZ.fwa.791ck-2gx.bd/uO6FW?ZS5jE:=m:> didn't hammer and finding out
-of her hands, and should always led him up here.' The sheep bell.
-https://[8368:F154::f99f]/Y3h8FgzTYYpzn/zHFhQECC/CGtX/8v_~jn3Kn The rush of it,
-and broad impression of which was company. I had no matter of com-
-
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/core/urls.from.random.text.with.urls.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/core/urls.from.random.text.with.urls.txt
deleted file mode 100644
index cf216ca..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/urls.from.random.text.with.urls.txt
+++ /dev/null
@@ -1,643 +0,0 @@
-http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on
-http://c5-3486.bisynxu.FR/aI.YnNms/
-ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R
-sJ5PY.b5t6.pn/
-http://Z%441S6SK7y%30K34@35j.np/RUpp%D1KnJH
-[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/
-file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7
-http://[a42:a7b6::]/qSmxSUU4z/%52qVl4
-http://Rcbu6/Oxc%C0IkGSZ8rO9IUpd/BEvkvw3nWNXZ/P%17tp3gjATN/0ZRzs
-file:///2CdsP/U2GCLT
-Http://Pzw978uzb.ai/yB;mt/o8hVKG/%231Y/Xb1%bb6v1fhjfdkfkBvxed?8mq~=OvF&STpJJk=ws0ZO&0DRA=
-HTTP://173.202.175.16/Md7tF6lj7r/oioJ9TpL8/x%03PjXgMMBC7C3%BDWzoVMzH
-Https://yu7v33rbt.vC6U3.XN--KPRW13D/y%4fMSzkGFlm/wbDF4m
-M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb
-ftp://evzed8zvv.l2xkky.Dq85qcl1.eu:1184/07eY0/3X1OB7gPUk/J8la5OPUY3/y1oTItIs1HFPPp/5Q02N0cPyDH87hSy/jheYGF8s%F3P/%86PmYhi/ViKHoxsHqM8J
-ftp://213.7.210.47/%e5pFkj6e6Jczc/ypJGG/z%663jYR/37IxLQBPr/Ciq50EUIdueyj
-ftp://alv0e-s.88.nJ2B34.ps/s0TgnaY?yOQUt/18CY%16IzNSQu/LaT3dD?io%80LBw%cdXDHU3/ppMyv/DbLDzyceaC/Goa%f3gn/5ebODAP0NAOD/6NkL/uP7CW/gS5TnaS
-http://278phvcx21/QGOy%395L/yy5NurSi8S/gMr%553%C9q0S
-z156ky.MU/.b%daGKqc/jYZkXK1WE/Abx589H6tADH
-Ftp://x68qwf2j7k.nc/qyZfwo%8a/
-ftp://yd.ng:40759/L1XAGIuzdMsjUIUwQ%F5/oDjgDsU/&Ze0Wz/ZeWR6cu;type=a#yDMuky
-Ftp://Xmswrxn8d-1s.pe.gm/dB6C3xTk%D3x/EKOiTmk%7c/API/0cdgpi;Type=a
-FILE:///rKnQkS0MAF#tM%53_2%03%d6ZICH
-ftp://R5ecjkf1yx4wpskfh.tv0y3m90ak.0R605.se:51297/zpWcRRcG/1woSqw7ZUko/
-file:///%C5=.%8by/uuFXEaW8.%7E4/DRM%33Kh2xb8u%7FHizfLn/aoF06#7srWW%2EKoFf
-HTTP://yA2O3F.XN--3E0B707E/qPDTt/MwMXGQq2S7JT/TJ2iCND
-file:///Gdx5CDZYW%6cnzMJ/7HJ/J%63BSZDXtS/yfWXqq6#
-http://1qvgjd1.TP/7oq5gWW/Gwqf8fxBXR4/?Br,q=ayMz0&1IO%370N7=;Sl1czc2L+5bRISfD+w&ygP3FhV%E1w36=2Rx
-ftp://5SCC6BUYP.Knf1cvlc22z9.1dc3rixt5ugyq4/5OnYTSN/QpCdo/t3zqkI/pn5skT/oJgrGy7
-http://2dkbeuwsto3i3e8jaxi6su9wjlmwygtpdp7g65611z-2bbr82uhjqkdv2jrh7.KZ/FiSvI/aaB&dPQ%42kLdM
-FTP://Hi144dz6hctql2n3uom.GE/%1A4OBV%63h/DoA4hpXFmqldOw-MB/PNYoaSDJB2F1k5/Nx%BBEDhrHhcMB
-ftp://w0yaysrl.XN--CLCHC0EA0B2G2A9GCD/y4FFU%c4F0B/Dh9%D1dGK3bN/EqxueQEsX2p5/xgf4Jxr%D9q/2ubmieRM
-http://t9wa4.rjcahbc06qmyk9jkhu3f.ZA/vIwW3sc3Pg/Bwmeo6KAjkRY
-N54l6e.vu/1m2%8bMFjv/oBdy%36.eL;33/N%d21Qvm/
-http://ah-2d4.ASIA/qmp
-http://195.139.142.211/%53fk2%90Pj3/V75ySPv@K5ISv/eUiXDAYc#e0%59
-dFU69ED1EJ0MLT.G8ef3o.bn:53301/klFVsh/YInBJE/SEIzo5EIoe3
-http://[3349:5FBD::213.207.213.043]/k4PbSpylXc%92Qckx/aQfV7X0V/25RN%49ZzvavLgf/re9~I?OP=nXo&oi0mm=f0e5&KK8=9V%13&Wd0%1Ce'0qnS=CFlgRw&4%89V6AON8%53jQhwUvln=r%6edz&W=Pq+T&a%F4H%51p%d9ZIU8l=uyA8S5J%95+Wb&xi3KNa1P-Xwu=&8tCH=BwNWf+%37G16&rsyBG=MnU4S
-5pn1q8q0tg.JP/%74XuKtp%F3fqLuGO/CMeC2IRRl./
-http://bmm4qto-360l-pbemedo4.SA
-sll-9eg.W6pv.rs/WtYGg51Pt%68/R8fsX4a
-FTP://r13oym76cysnp77r5sidj8sqgxzpl3ls4xzj.JE/ta%e0PA/5Jwza65o%7D6Uno/RyO%b1B/v6C8yo5K
-http://2b4ne4.5ji.oubrfdx24.UZ/%69kMsLF
-tv2yy8dnp.tN8DIWG.gr/ladfwSflp/Zr3YKvt/l1QlvEc
-file:///eK9K3g%47VnPYStl/GKGHYM6b%23nc
-file:///LtZpL/%1CU8lVvcWrTR/
-File:///yCPVGaCm/hHqFToHKZw/%29zmDPSQ6183%C8RfpdKQqkCd%51X/lyJABDQymQDL
-igth-n.Mcw.ar/LjMApEho5gp825BK/afaST/HWKafQMBv/
-https://l89xkmwfh-hprhz.tcay299q.2zruch0/uv/iM/
-file:///6yT8LrgRZG%10HsZ/CP1zI%98gHFiT/zAx4%EB/tBv6V8kS
-file:///
-file:///iYHw2RpUc/9MPLbyq7gTVSx/pYnzm4E
-FTP://[9198:015F::]/pU7tr7Zhgt/~cLd7w7.Gb/4MvIKc6iy%58vN/AGZ08o/uT%1e7vtcZD;type=d
-ftp://0dfw3ob8y.Jri1p4f-8.NG/DpihVuu3RJ/kEKaPppvl
-http://pZRLI6.ma/wAex4MoQ/jUv6Vh%5C2
-file:///F8%A5Go9qV/UYzwol/#839W58%4D!
-ftp://zo.dz/BSI/enk1F/XjnYRqwHBAyIYdC/rTXmyPP@Smcp:/%E9r7n
-nhzbw2.qyevbi.gn/Oxbk%737lUb/OBx7/VX67/%C4fxQxvns/4fNNJ9FjR/7YeGTW/7VOLjOD4/P%89.1Forp&3/wLVBbhK/3GdjIWB
-Ftp://4ie4a.fl8g3c5.wjvan5m3j.4sawo3mof.TH/wfcrCzx8%B50W24/ZxqhiPCLDP/SZbReZ4h7
-Https://j3bhn0.elhqoer--c.BI/ijN66pIVKxXjOmg/xCHrfc%feFdJPd04IG
-ftp://[8F7F:9507:280A:3192:EA30:EBD2:87.9.102.149]:4954/AwLZnTre/8g3Vo%6doz/Uw=dU%70nxbo
-6u.vkhga15zezgvdc68uii7dh0svzopjpr3.NG/rXE/6T~KV%06Kq/iO5vG/G2S9YU
-HTTP://lZSO.fr/%baWLoH/rsdViX1jMX/jKQg/aWFY%eekWu%17DTY/ASpif739Hht/hHM/oXdG6y/Es2c2Q/UVz6TevIJa
-a1JQT907R.ou7o81.al/3Vp@VDZp%9c
-http://g746.mhi.xtzovtn01w87au9.tc/%8Dn1XEzK/FsoFQ/xuL0wOc/YNP%53OS3/w5sIf7ox/t%22S9TxaTtK3/K%74%4EabDPe
-http://92-uzyzm.pr/UwJkzP/
-http://46cda.e92kuq1029.Igb3rjaqtc.Xgpak.T50lamdm4sscw1i8mq1-8.wx6wzqxd92z68sbs43l6.JO/Q7RzRWFz2/
-[BD39::62:47.178.113.23]/U4woqa77Wyygc2/cltcO5Xw%EDWZT/%5Fd@GP5vV#wUMoflXqTOsj
-Tw95.XN--WGBH1C/CK%fb%EF9/s%F4W7je06JY%49r/Y2L9fzlfd#fprt97Y%72
-file:///xjYnAHV2/g%21ZmKfq
-file:///JDyfQk8%669N~2L%ecj1/6PySMx8z%19%36/HP5GhmnNinF0p/vavqKxyBLV0a
-ftp://v2WJ0E6EX.gw:46170/R1g73Yli4ts/K%09PIdRA/DntZ@
-pVRN-P.ky/2UMoA1sYRpmUyd0/fEShDdCyd69Nyh6f/6zP%cevC69rdf0#XaOTpyS%73TQ
-http://4u3o/BKdhwRyzG
-file:///LdsHfPABFz1vRD1OB6Yl/RS6&1Gmz/mfYul/
-ftp://E1cdf-p.XN--MGBERP4A5D4AR:60510/qMaw4kSSgYM/7jgIuL/gSVW6O91/2bhnsj/kl7R5sgn6&X5EiZdZ0WhTX3T/fa%f3Azz
-z3ymb.KM/DdnrqoBz=YtxSB
-FTP://7kgip3z.XN--KPRY57D:15983/OYEQzIA0
-nezt6awdc.lSZDSU14B1OH.4n6nkmjyyj.cc
-ftp://085.062.055.011/bopfVV/
-ftp://Mbbn8n.6ge03fiivyc7of.PS/mvb/X8VNt/5WrMZpw/flC6Rs
-file:///vNLDR/Q7QXgZ/6ApHTc6bN4/yihY9ZGy%3BlK
-ftp://p2SJ4CE1KFC8CSRL2OY2ALA5TJOCN0FEM-W.biz:51412/
-078.085.085.242/kqKkywur6Kv4Qn/-CJv6i1Nxc/
-qow6.7RF9YUV12HR9CCFTWUTQRONLAM4PN82GI8E.GQ/oxUj%a6Ch2/bjjphp%34IJ/%65NQDGFab%14B%51M/QtBe
-file:///pQ%8CkB8ipZ%2cyZGMf/8USgpQ%54%48e/jCflvdl%3Ec
-165.195.223.067/Q3DEaK/58Z29OKkyF/fk9Vl/dKLw%7FR3Fzo1YsTPxmm/XiABg5j23J%1avyv
-f1442jv.3w4cg5hy.EE/8hsz%802pLxgSlD%edIt/ESbwLYo/tdn9mrEynmJF~
-[dfb9:d316:677E::2B7C]/gsORr%b7gc/?ehIX5=GTM0co5(Dmn91JN&8J=8W7wFuQfZk7sM#vYfk~Km
-[11b2::35.78.41.76]/vVfZvUimVO/K9hfOd/4gZUL=j%09PGr#o%23LnBOkk9
-https://oL2UQ.yLN-U053DA.bf/CfFIFwe/ZbgHFvLfbEYrStIS2h3r/pqd%14rY/aR5a8hx/aKWFJechP8DT/ypmeBjL7rcbUr
-https://[3790:ad57:0B63::e5f7:f6ac:164C]/Obax;zcD/Y%48%9a/Z2xcdar
-bl60k0jqkc9.oow84o1.BF/Xly5cTna/BzoQuHi3r8e/o5BDNrvT/=6HRdBjH/Mrp5%02/p%e9pT2Ae
-ftp://Bs3ceuxd8ii66gt.X8wwdpt.BB:27095/3BfkvfzcmTS/FTffh&S/gIWvJ5Kd/AlOQ%3EnO
-http://ch43n.51rkj.rze.mq/pJjrSAiuSv/3x/EK%59ReZM9w
-zQFC1SPO96J.Jy20d8.xn--3e0b707e:863/0OWpT4dpkMURAGe/nFg/LQBUr%3E/af7dO1
-ftp://Xctk9iigg.cat/u3cX1d/Sx6m3dql/d%46;type=d#0i%3cT1yMkZQ
-HTTPS://56aderic0knmip9lkqdqag14.uk:45885/lELiK:/vF%4C5Enwqy/P5NGJ2b/dD6sg1yMV
-ftp://vlt.3g45k63viz2.tcnm3.UA:60664/AJ9iqYk%c1/uKbohn2/K%D1kequ4z8rxFpJ
-Ftp://2gifamku.jqv10es.MX/yJ0rhtMYX/Y1Wq%F90RYO1F/NT0%aeAG3/r3Act1
-7WO6F.XN--45BRJ9C/1L%f9G0NEu/L2lD/mQGNS9UhgCEb
-ftp://mIMU.t4d24n4lyx39.zURN708MCNGK-TJ42GLLBQRJHVENGPO.bw:59930/KmBYQKHfcjNRe/rK3fUjg%0Ad/.zHeVoCaC5/w%A2%F7up9o7J0Eq/ySBVhB
-ftp://lv56pdepzu0b0fo-04qtxv5tt2jc0nsaukrhtz5-e3u1vcb517y3b135zl.e0r1hson.dk/3TVoqjp6%1FCFSkt/006VZfho/gxrWxgDawM3Uk
-Ftp://7n977.Niyt.2fgkzfhj.q7-DJ.Ow7a.it/5zfRi3PO8/1zfKT9%421tP/?SazEijJq%710COQKWeLE/TdUc%b2u/2AxBw9%4BUN6Zp4Z/KfUZd1MTdPv/L4m1tI3/WJvcK1
-FILE:///a7kRxh8/h43TYOY6J5%31B/ZfuF%9c3/
-[46C8:60FE:7ff2:79cd:69E1::221.191.034.036]/Q2MQ8mttjsMF/UqrKq0W%E6N1#YfB7A8CHYa
-https://hnk6fx.2uxg1e9o.pm/I=LKn%a2n4/J&RntX3mUxZ/B1Q.Ilpk3Icq%7fZ/ia:4DLuk8pvsD/mpED3egQJfH/O0es5zrzwWQIC%21K1
-ftp://133.195.101.060/U9x99/nrirgTvZnm/QLNzsm
-file:///RN%7EGq55Z%D1E/U0BQ1De/o8a@zHbAMS/GOA4KUcR/uaOR6C%f1Y/u5d7
-http://[f63f:096e:ee87:792d:CD31:A1B2:83FD:7322]/tnFLqVSRa5h1/%EDX1y4cxiv/GIo.OM0/M4lBr/xgHa=
-file:///Td=wh:cuTxKx/4B8%dc%616s&sE/snROY6GQc
-ftp://1fcu78n.COOP/eDRJd%82k8FEI/7fbDLiQncgOl
-http://obp6jiork.KP/pOedzk/Lo1uNQ796m/hjLXBOr%25AB1/
-file:///j3m%a5o5blRxq2/8aDBkHng/OR1ixi5h8kX/nCUz2aDz/
-file:///V1tX7rM/7zk
-file:///1qw4T%8BKBi3CKv/dxm6%7f8s78R/%83sF6J/K%33qfB
-ftp://tyt7r.u6ier1pxipif5.BW/vSq6akPyGUI/wVJ67VXTQeuKM/yB4zYqPh/0RuHq%58G/rBTgdr5F
-Ftp://4dx-s0az06e.Su7ir.SA:16277/HWkL7hR1SW/RzpkWipV/LCYQ6/gLpY%807L6/60H1z96%90xdQ/P9jx4DVu/oFa6c#gQo%57wv0vN
-FTP://o--B02WG9T7-BXW-RVAJCJN1IALU9EX65WSEXCRHM.Aeh-m.cat:34416/3q9yW%53m/FJ9&U84ik9&e/R.l/ji0sjWb%5edu12nbNSW5c/YMGfLcesN
-HTTP://lMxNbKW@tq1imryvi.P7g5o8np1.SK/um4Z2TESWBSrcN/fNehEdgh/sW%6fCP/b2fqBsG
-http://Lgwt071.sn/HPn4x/%46zCwYZzy/wzQVoL2sT%E3Yl?974Zu=X+JuSbGjrO&Xu3Fz%a8%19%5159f0r=afHdI3%F7FNrs&Mb0hjV7d=&I43eztc=1k:3+uSz+kdJP5c+bRkUBkF
-izojrse33.9WTVFAANL2Y.ly/i3ae/5%0Br%f5yL3/MsnfAk#T6,v%51Ev
-ftp://[8714:3F6E:aa8:c8fc:4F41:b8ee:44.74.99.35]/790Ug0mWq/7yBPb/pzh4dTX
-ftp://[ACC9::DD55:A45B:7a6b:177.179.158.116]/i1q3SzWTmO%09p%A3/FWDWq8u2Q/7
-Nw2m4j4.Br9kvjf-9.3wac-fh0uk.nysyu-emjwy.cat/PGDh:oW%5F/H34QSRwe
-6f9f3nny.mq/ai%cb2SZP/qfjOd2mpEH/LUZ.fxv/#3NaTgg
-ftp://R1x5yr2ij24e42wlojnp1i-b2bsacd01stfe5-10m0-3z6cwb3aflzrgoo.it:8665/oFbo12T%3Bng=x/%B2FcEUXPHAP/Ni0qL%0bPN4#yhp%5dO6
-http://[C794:4d71:ACD4:7AC2::30CE:B0E7]/T8igmbW%6C/DE1%1DyI457M#brpF
-HTTPS://rI7HAX2OS.bsajd56xb48.FO/fn9eA4%0A/G96ogw%69SGis/1V0hqVLN6zaQC1
-http://toncwiacr.0px.g7pud.MOBI/EdoW/qUMMnH
-file:///LkP1%5BcrQ/bnkvBi6F/Q3IRXB7Kt8mvDZ/ZKwDAp%a3/
-http://6DAK.8I6FGLS.t5YJHK9GCUVU4EB6NO513HBTWAU0XP5.GL/LDO%8CDB%82p9#
-file:///%46f%c5KRhPp/skp1X/OdoS-J1foeE/5H5RIWoip
-Http://180.036.254.028/VSiroQpjS
-d54n.Agqa6.7e4.JOBS
-https://5t33av.5u7.RU/SugrkGKg/FDf6cYm5QdHk%b3z
-file:///tGHsUEMaQS/VLn1%6Au#uGnrvY
-lm.27.jv4quihwsp.mw/mwCDm0cweP/A8wSZIQcZGV/uKBboAnqevGJEQT5d
-ftp://6g4.qe-s9txq3o8vvr5e.5YWZGPDM9Q.820d8wtribsgglbrnkafno126s8vflph9tfmt0mwew/qC0bInpp/fqxKQLzN/hAj/6PsngV;TYPE=I
-file:///aR3sSgC/GJu
-w26535-k.Ut2.MS/pQP1Rx/NUKUyRSr/21x/CcgOcN4U/Jzw%C6Ft/n5Mu9X
-ftp://75.22.51.21/wFDRPO/NLI1ZSecRAfFEAy/kZ4whP%C3A/
-ftp://1h3yyf3d8sffjx3rsf3k2y7c459c2gx/%2FfoFDEyWygHgKAuo/KhJZkBlC5r3%99/9I8SMy/25_&y0
-Ftp://215.239.176.156/tNfD%09mvdOM%28zx/fc3DTw2nf/#2kySKJ
-http://Vyt.4ferfwbkbm.owtk.me/LlUtIjj/BDovC/6vJ4Wbk/ihtBt4d%acVl/ywEBIdg%3dHb/
-ftp://Lq.es/%B1ZPdTZgB2mNFW/qre92rM
-file:///IZ47ESCtX%aatQab1/V553gjR?Me/#9%68qPw
-file:///Y?GG/BBqMPBJ/nsxX3qP/8P24WdqBxH
-ftp://7vl2w.jp/b%a5fBYyDR/ZN%62LG9aYpjSwn0yWg/nG97gndK%69XZ#fet%55XXZhslTNrq5T
-79wvzk3.24dyfkxg0f4z-hsqgqqzj2p9n59el0a.XN--FIQS8S/:8epfLrewivg%488s/2ORX8M3/B0KpeeB/2rbuCnnBF/4P6%1cU6fTGNj/o%3aZMIHdO
-Uow9.sF.GP/sF3FCFSbCRWGNJY%aaU/DVXA5nIOWmjc6S/FQXdiBw/Y7~cVmpypgft/vU1%D4z
-ftp://[fd77:4982:C37F:a0a1:7651:E09C:117.093.145.017]/2l91g/s%79lJmUiZ/%A5R2qsJ
-[62c0::]/d1lmSzoB/5OBVnzn/kOXW%D23
-Http://Ed095eimjy.rlb5698d.kp/_l5uoOO/aA494s?3nSxdIpE=y%79qu+2un1hGR&J%76=8&L%bed=uY5hO+s+IKk1S&Q=HHXEC+Gof86QIRHy&35QY5=
-FILE:///#F9Bgl
-jyia054.l814D9SNHRRA5RJCCW.kvxga.XN--3E0B707E/sBbx24%f2Tw2/Sd0Lul0Vg1bbIqW~/lveEw
-File:///KKfIe63z/BETB.T%C6sG/RcYgnOycg
-ftp://892f7.oel50j.32.9qj1p-g7lgw.MR:48021/XNKbk2PZQXSvOuGnOAnATDt3/XfHyJtvoC/PW7YrSgf#LmGWJgPw
-http://sisas.ua/4CU60ZLK4VgY8AR89
-FTP://7qf.hlj.TN/IXOeaf/t%c52Jxwy#YkcAy2
-Ftp://Gbu5t.HT/xad4fgjaN#GLpU3XQd6%7F(cHIz
-file:///A1omJiPzafgAm/addqzG%dc%62/Lw1mamTg
-http://89qw34ksf0qf6iq264of-1nya4ds7qvpixw8c951aw8wcm3.qxk7usa.N8j1frzfgnkbi9y2.XN--CLCHC0EA0B2G2A9GCD/Unwn3/%97gnj0/GQgJC~OFxsdE8ubC7/IWy450/8%7CQVgdI8/soi0BviZt/Zjs%10i5Xh?qi8t9=rBbPok,Si&*Xl=Q+fT&Hx4%D70=84+8W%18+sV2BU6xCDP%47M&Usbms=
-Z7tid0uh.eZMOI-M1.umlsyksuzovqdw6wozbd.BW/m%e684OhC/ErAhpGiG
-ftp://tw7d-6yu.im:2055/%66qbqzss/OmPGW;type=d
-FTP://zst.tn/QcUpaA/VKvJ2/JN6AKew/iXYIiHm7mfPFmD%21E5/yTQpoiqdbaaS1/LnzOX#VqsobH
-eta0q7.2r79g.AC:34736/%abp87fVdPCY/PvO8Uk4WoLF#A*HP1A
-https://w9zhko2rttzndzivll92.sbzum.UZ/bgy8l68/Ix72mHu/zlA4CI/IQjc%CD9%255FxJ8A/Dbb%4eTCRu
-[2582::]/Mhm%55MWThR4Ne5mZ/xniX3IdG/
-ftp://224.3.121.112/G1w1g%1DdRi/T6Eb_NegqJs
-ftp://tn.z-o3vn3n4.5wg7.gs/loxilPpcLnsI/topa0Ez/Na%70Dcde
-syt7m.TD/2dxrQQvBXC78/Z754hngiYcM/eM%3CaeYeXX/nmUwguwk97VGL/
-http://isqogte5i.c-3oixcmy.SY/jlPVRlTs4v/enCZWc3Sl1dJ7/M5GTSZx/Ga%cce%63cLzTJvBodJ
-bYIAYQ.9mlnx.OM/t1KK3u/iyQFS4EGHN3uKogL3WGG/6wn5Q5ndq8kHO%734cxgEc
-Http://wvfftjk.do/a0%644z/?ATzWOxO1k=%85ulHR
-http://fnoY09@bm8xcfjyfiremhz9.sr/E4Rrq2/vQjQKj9fwV6r51/mn3x8he7/W4xCQs%FBvrzb
-ftp://vxfr4g5ka.kn/TZSPrYGzv/KzuB%731GA
-file:///vjS%f1/ktgHPAL/=v0cZ/WTpVo1/i6XlMCkNI/kukAwc8/thWUblm/c4ICXp/f8AHkj%1C4d%9107v%44hN/
-Ftp://t4qxt.hd9ok.aUQ7GIMBGXP.IS/%7ey71ndfLh/m%4A5P%75153tpU0hY73KfO6o/E%7aAkUlK3hX3Fg
-FTP://gJ8MRF8UYWFW.iq/cdX7RYOqS/6E6XUh%fcdHS1%dcoDwHgpFId
-http://01s0hfwz.TL/C9uEC/K9uWhknP3AxHW/%c56I1zL5Rfdd/sLJeP/2QkQNP/QcW%8aA0A/
-Http://gRWSMJ90XZNPAPHL90FB.zfyopzk/hMq%1fD/A5jQ%efiH4Csr/HTFm14uSXf/jW50yvQ6Mb/EJrahj19Y9Y
-http://i0.XN--MGBAAM7A8H/Uy6czi/rrAt8esL4/iL2xLka/B3j&7Inmt7g34
-file:///aZcnMM/Hnr1PCn/wlTztS7SpL
-http://2lv8030.fimc0v081i/cyEUoud6w/gfAlE/iQP:8/dZCue4cKVM3bs/JU%d5ZUA1t
-ftp://kF0NLTJGD.HM:44827/Y6CgKRiW/4r7G/Db%bb=7xD/tE/t4ooQHdBsrw/ZvgcX/qTCarGQWa~MKW5nn8NF/dcy%1caO%b8/Di%947%2cB
-ftp://4ufofbu/pmLZX%f2wJcQO/B%e0b%64oLObaEx&C/QViF1ohg/Rffvf
-dYC57.CI/=G0dg
-185.224.223.157/h8BdA%FEv/KLK2f%86LS/gwA4rKKHLarf/b.EyE
-FTP://uhw3qgl0bvfp568.e5wkz1l.Dug75a1j.US/R%AE5DNL%C4vMl-TXG/BDSu8PXNYU42aY/MR-hx1/mC2:SJqsCN%d7#smDUT
-File:///q3iMCFXfge/Bh%cdvWuy1w%E7Er/Jmmf7DkqSG%35a/VUvFz#8%510SIu
-file:///G%E7R44SI/L0Xsc/c15wyz?8Bs4rN7
-FTP://eQ23LB4U9CX.vcrnx.2fa.k6rjf8b.pe/8L163hbbt/J%26zcQf/lkieT5x/Efa/A2gUk/o%ef9PIBhPODaAn/p8%55Wsfap/BdTfZ4zm%2fbQt/SY7rMh
-file:///7RVk/qIRRZ0b/
-FILE:///Rq_/ec93s/HMB24%8esN/%4bO%cayWnOF
-File://Yk7ie7.xn--80akhbyknj4f/y4e4%2a0yHu
-ftp://4ps9b29prywnt6-1xt9t4cgi8sbwjj6obbw1x-2y-v2tft1eei67i.Hk0u4zwmd7o9z.jp/o4R1sdAnw/Hu408%CB/HdQ6cFhG
-ftp://7efqt.LB/EIX~:Q24/b0QhE%751s%F66R7A/IFxxOD2v/uOOPv5jARBJsf
-[A645:D622:eb6b:D59B::D48D:f334]/Ulld404y/IM~6P3
-FILE:///%16b72yhVw/2BPPCZg/KwHAJ0X3QT/I49wMwmls2j%15xkYc6qFZ
-FTP://octvv.2je8.oJRUDE.02y4htgs.es/zwVuzXoFKJ0k9
-http://[3A16::]/1rhxoXw9Cv/eWk5gHpYJ/v9gRo/un2Ygo91B%A1f2p/15hJ%A5o%A19TLjzzRrGUT
-iG4PTCCG.3zti905z3.ci/42j5.oKj/FZmOBY
-Http://pclly.36XVKSPBC/Nja5D
-148.020.113.014/ASuvNkg/Zcwt4/PjpwkEUVHbjkeKOgL/%f9hibk/NT9kSmJF%1A/5FaP@BkLf/jTre%balt
-tnjbgbiparss2x-xav2mitawqn9ema07kfk6kjck.xC1U6J.hm/scUu%E5D/qZ9K%1CX.d3mWJb/-SdvwN/nFS0ZdZDNQA
-http://[3173::]/YHDIJlMkv/oFpVHGs/7Dn%61pqA%23/ZnaIIPD%6cj/
-http://i4f8l.sc/WuJNKVuflVGa8/%85hi4B1G/mPs/1KfX%12/WswWA%B3i1OVsF/Z;wC5kkDQ/XIOtrdBl%D9%33
-https://v24gyfj.xfrc5dy6xuz3paev4rggl3xeg3vxzw7cz98pbcgum8xlczt-n.SU/Mb=PxgWX/J04ScMxk8u/oH%A08nv/3oXR85tM/
-Ftp://c82a3i5u.tf/v%D5/%05QNNYI&ssnoF.
-file:///MaIzEiaVY/ssIPwkItF%EBIUy
-Ukg.sb/Q24uLBUl
-HTTP://Aphi-iog2t.PE/SSwgnY7af/VabUxcEU2i/JI%434fkP%7cO#EWmOFU%5cy
-file:///FXYZhobB0jX%5BD7PIt8H8u
-Http://asn7b.LA/13Qp3t0dY/Mk0ldhZyJP/rRgIZlOu/hqt1qM9NT5tAGD07T
-Http://mb2.NI/eOXXAC0MNiEvJ/ul6ydqIPg/3JhlWx21r~sH/ZemaBb7j17X
-ftp://7i27:54542/B3rW/LSNLFJ%74J/%e4NHDP1svTU/Kkpr%C1%6cO/2wWp%f4MiYLhgWGSF/u0wNwK0B
-ftp://f8X.cat/L7Gj-OSdF/QBrO%f3okEZ/L%bdvAyxC5
-ftp://[6CA9:93a1::]/?y057O5/l9C:/XsBy2so5tX=D%71me/
-file:///%33P.AyK6nB/QkN%011K/iicc3HEIE%C0/v_7Wl%fdzMCBnfC
-HTTPS://zv21qs.ekofwyy.f1pd7snnae0n2nzfdclk1sf4hybx97u17piaj5-lul89bxrf775koowj.as/BAc33xOV7
-ftp://ko%5BM@183.207.071.131/tq~2QxL/d%D397GnaQgKtPMOsCp7fyVobgZ/Nhnp4LAKEvQ1V/1xFn%cbR%7BVU3
-https://fiuubt.bc-yrorta.kdn.M8mascygepb0csr.vpifk.G-p35wx.er/4wvko7/Wo9PsbrLI
-file:///LRVqPEfRevRI/nHtsA5k4iilQ/22vu%674y
-http://jX-U69Z4.3vuws.41h3q22bzs.o3hng9:6629/Qj=CQmh9/%9aCSTfa%0aXvFQ/u0zAICPSGUx/MqP32INW%00mp?ZmIZc=5o1okD&WEDMM6Qnm=0w5T&gajnp=GFwK+Ct8Pds+KRsnyPq+2UFmx+cwnDnvyn+Zf0VFXyk2+Aw67fL
-file:///XRDAcY5GGmj3/WoHYehPpF7/HS9LhdHOe%9fS#!SZge2
-file:///UIIGOxv6jvF2%c0/%A8J3%677Gmq8im1zklKhqx/HMhCSY2QcyxvL/
-http://Qhk9z.zm/cOGBen/mBsDycEI5V7L1s%84WUj7863/p%5f~okuRD51b0M?b%F2d%67ujGr=oh8PWUtK&j6uX7baX=&sg3RUocA9W=m5IaF&JWH9G=fyiOtnC3+7RJA+ippw96rvu+BxtGg&F6f1=jmPS&3PE0xX5=TGV%5c5J&%fc@NSEynhuvb=&MkRIt33=
-Http://[98cc:433d:2C25:62dd:54ba:d10b:63d3:4C40]/YlbNrJod/fdjuN/qYqSdqr5/KAbXYHO%F0m7Ws9
-file:///ywFY5HK/XAv@v%66o/M2O4Wlny50hypf5%02A8
-https://nWC9-RIA00RPVL4SSWRICWWX3NH5SMQIA7IPMCK174T30VQBL-M6.XN--3E0B707E/CwE%e2rWaYZmE?X_coOVl=kqGQ&Pli=MjKg-+wO6Eh+lbbcN&x3M=3kQh99m92mRdf&iiO2wXgQ=qyWVG9G
-file:///enqvF%EFLOBsZhl8h2z
-ftp://133.4.130.192/p%b1LgcONfo%bc&kmH/Ibh6Lq%DCJhnswT%1A
-ftp://1xf.ipl4f0y6c4.VA/LHuq~/p2nPbE/0YGGNJB%DEje2psef_B/aKOuMl1Q9
-ftp://o6ou6n.N8.yyld.JM:24207/aS15Vk%0eg/M8jcXu%14d/%48odaw
-file:///7NToG6xM&SK=k8/wTdaPAFLzqBEJ/zHMDPj/L.fLv57c/z8QYrsKS/CEkA5FEhQXBQi
-file:///UWrC%9111nEhh/45FHiTx%98L
-http://35.iN13LEQV.z2d.in/%B2GBtdYtQjc4TTr/gLxjU%B3c?3m8B3t%24eK9%b8=kgc0f+ew+uux%7dOI+pbZ+H%9cS&%56mm6=rkQm+dHPh3gGj+1kC
-http://nEN5ZN.EG/%0efsf4v30L
-file:///19%9947/ksd3Sq7W78%27/2K_Ylzcu2q
-r8sht9qzsc1e2wp.ci/8SbPwlW%5ac/qKEqFi0Q
-ftp://zxmv98m49669kfvf24o12w3u93wbovfp-1smo6y90e27n133okplcjqrmv-a.CD/JM5RAAY/sJdBntYWuEY4uB7hz/ozRSmFJD/#Xv22:Xvg
-6S8.Crwllo5e3.jmtz.XN--GECRJ9C/6InlQn/hnhu2f%ac8tX/apq%0D6o/
-file:///gVW/nnRNxPfMXKb%72Aq%4A
-file:///Fzza388TQ
-file:///
-File:///kpiE4WSatjDV/phvv7gyfb%78b
-ftp://240.154.225.198/I%39uutdECwM/PViD~qPa
-td.KM/0Dkyg/B%65DiABz/wtqGd/i7%cepV%86XkA
-077.102.005.039/p53%0bsPeiZaRy/nQHLsKEbNdaX/nT9H%521/Zb7H
-https://Pu5aweu-29knkj3k41tw25h7xzm9pck96ey4q0gqzig27u.vLPR1Q4.vg/QANLMxa/gccQ1ekkRDr/?bXRDWO=I%0ap7%f4PB8S&t%a0Uhe1I$j$=Mm
-https://J-5ytf.nmp5zuopbj1qbl1ik2c4ihjwu6-q5dhn.ng/GDtBeBZixtl/6sgw9/tmeJ7k3I1hHJfM/2JYRt7towpNjvDWsumYmhu/nBVPkzSo/cBXPb
-http://HSZDX$An@ukj35.ve/9dLg7XrzV8g/hXhzX;2/Zw3KKwTP1um2/qej3miaDjj8v
-http://sL333Q.Zci48xtb4g6.lu/sQw4ZHF/M%99%1DNl/s58%a2sCxGQ?EgPNZ=qaG'U2CO
-file:///W%64hVsq1u9rIuZy/qO8j6EEwj/d48q1%6D/ko0ec%72/pcJo/MZQohRx
-Ftp://afq57indwrb0sjhgyczyx.se/%6FKey7AOE/IPWZg3ggMIM6%D48h/XnAuzG
-file:///wDwlQVR8i:0/mzefF/D3Pnkoza7Zo5iQdc/ckieGQos4JM#9rqA%DAD4
-9gcwbh3vcmfa0xw-k2.MC/66TaJz%FE/SnDRWAknGcI
-Ftp://%cdaTNzNPNu@w6H.V9aps/87/w@rPBGa/he%FBu4vpT
-le1u.43cdu0n4.bn/Q0i6uNz/9%275%a3dAS/B%2fpPkCW
-ftp://131.173.229.062/1IYcY/mJJ894/%89F%45HHRdA/eGlhL2MXm6Q/heBdvWm%3cVs%04/x3JjEB#2%2cQsgeK
-rtubvdk3.PF/L4TR1g%5f6/Caov%FC3vK3ofrH/pz33aV%54
-urlyuqr.ar/tzJzKM/gutrfWqv/IC%24bbmSS%02P?%24JV=zrJilQ+tH%7bh&hbO7Puq8c=K1Qt&ULqdYq=
-Https://pFOROCZ9.dRDP.gq/08VkBBPja8cCXZKLa/rEF28NoX/
-https://[5319:CAA9:0242:86EA:8e36:7086:B3E2:ded6]/Jq%C0P@jZ/KoNj84B5AJ=3jGk/7wdasVgHFexe4M/zgEZvK3vh
-ftp://Bvc6nmpdhn21400.Vo53pvqm0/u7jz0O3bbFTTegZa
-l0q.0b82ck3a.SI/EQf%a6#mhJ%0dfWnfM
-http://hr58b8n.bL0/LppkKdZGYdxiHg/2VXeZWR/T4fCmyN579
-http://1x6.yc6g6uw6htmwcrb10t4kwc393g29cctmtdxxz1j.KZ/G9lcwKju/UiH4E
-7T6OSH.PF/zfYyqdxITCI0
-https://2diizsrbfh.PK/t1zBYiDPZG8Kx:/pEN4b8xKu
-HTTP://r53fl98bazbqhc19-h-r.qif.AW/8sH0%59j%FF7/QPnw69%17Og9V9l/JAn2c7i/%7Fta3x/P%08HRF/
-qvpqmoa.O-0.FI/TDl%E6x1oUoACe/4VUZdMKL8Axud/JEZEF/KOR7Q7?ifYXMx@=&iI'!tR=p&k2Tv=Behew+RFW2c+w8NOK7+?BGH&:TYW.6(=H%B0Jvo9LvAy61V+YjewIUBKHe+lT543+BIss6Rz%25KTjd7+fOp-r+/PvG%fbP9kd4K02Z+IUXHyh&Lb1kab=FDdwA3_Z%81e&iiG=CVrO+1AhtbU1JSvh+Q;ay+Jb8c+%c1L%D4&m?r%0en=8S$wF&5JOA9WI=&kGJ=WjzqGX&Bew@sXE=cl4a+2S8
-http://jykpqk6.sc/VBPT/xNRs7JVoZKE/
-FTP://2w-y60heg64rnrmpyv43tpfhftxolu-5u.lG0BKW.LY/g%7aPAj5j/qxyE/D79g5vu/
-http://Unp.IR/tN;/bCXe/fxSdK%00%CFB5N/D0L1/bjf
-[cf65:1F97:24b8:652a:FB12:D0F7:181.134.252.162]/1jXwBjjxpC/0zKR6N%0bhawVF
-ftp://090.247.102.174/YZgWR%A1NP/f6YUa8dEOoOk/a7%59Geq
-https://Zn.RE:31587/Vam%acYZniEPiY/lBfiLn%F1/dlHe@m0#
-FILE:///FojXlCuj/OQXGX/JUHCBAF/TUAe8k7O/fnh8rautFH/e6%C2xGbsfELFVW%df/JKQk/gEO%589e7uMuM/SM%7dz%0chqvt%67/dc4fnbs%F3%5e/4rLtAbS
-http://247e/qBmVNrd4AstGuk/JkV%50CBmmp%06/%a5E%34TAY%E7/5WL:W%CB%193Dr=cl9rn&/mA9%651nvah%63hV
-qkwlh9jp618.k-x.de/xiraBM/6zj@AcW3NA/%CBeI4RpP5nz/FiWXIm/fy6YJd/n%006lFEE/uT7%284Q;fXK/a52ToS/w6jn4ZU4r8/:B~XHaw?G.cE=osg8k3&iGJ=V4&w1vL=me4QRwj&YFgq=%22zCDTqgmKC
-fjrb5z774.SA/PVZsWyA3sMJrb14P%995vIm6/dC5=Hj7?cxCp=bZ(40%15pi
-ftp://pd5mz0sw.53t.sent7dh.ki/U%57Qz9g?6/6TOmiq%6F/
-Http://g3t2w4.2AB0B.3eq7q.RE/fvvJYyHjd/%34FK%98WeZ/G5Ux06F2BDF/
-http://7Z0-0PC.txi2srk55gs1venx.uy
-https://i6.kzdyaq-v3.9j78y.oq5r.gpm7oh.x1fnc78-tli.5yu2f.3hfnkcvwoms.hWRAX7TAJ.7ei.tt/Ysy-/sRl/LZa6nw8
-Iq7sp.vLK69LN.lr/hjB0EW3t5%36/lSVsKT%3CWsL-%ADA1p%0ffG/M1S;SyAVBO/EvzIxfZpicuo/dOst%DE%E1w
-1lg7.sz/X@ENk92CPk/vVYJGN%act
-ugk7-paad2cswwq3kd82lp9r7-i93galijy4x4.vatv4ag.va/Eww6Y1XABn/pC3%9BzjH1q:sB%89Mu/WdjiQ32H/LEaekIokSv1%E61s/Y~wQYu9v8yDqSatHO8F
-http://Jmury.vc-wuwj.rn0o.ug/EhXMKL%64/CwKXyRnpk
-HTTP://V7c6lvas-wtxspcp53z7o-v9dt13mpp7gc9ezt.MG/q986Xs3Fzpo5/6tQRek0/zkdJt%605DYH2j0aVfgcn
-[0CFC::]/0611uPvtHJ
-file:///viHNVlfm/4BICnFqFz3mXP/1%0dxeFn%AC
-file:///ceic16R0Ht/b%AFXzo7oKlnID/v84LSyw/wBfvq3QVf/vuytS9wORE/tYsyN9i/msSNDC4Jt8/nPWzs35yu%ED/zvTeOit/uSVe?PyD
-FTP://8GJ0QK.rQ8H0BIQZVFQQHPAWF7EVV12.LU/dLOis5Hvn/YEA%C5Z68E%50hS/Ie1Sx/
-FTP://bGCO.apov3z1nrv.ke/cM4fSVF?%ff/tWLPVByl0/ABCz7EZc3/R2b7U8o9JM6p76
-file:///2%f5tf%F7dSLdlRwws/qnKbcUOCCP72RTJ/WTc=Xn%B88/
-FILE:///n4riCnF
-ftp://mQEGW184G.Hv3zhea6.ST/iW6mhdm/G9mpZUib4loe
-file:///
-https://A0ea6aeynb4z3fsvnh4wg6h7.9bicz2zg2-695lf1uql14i2sjf6pqh1sae2j3k8iptes.57/jzHSQ%ebP5/%e3%9Chd/#VqMzFZrd%ddpe
-6wmlp3ipb.cqi.ikf9wdku.arpa/dMq4GciIqW/aL%10jc%d5d%c4v
-file:///lT?KC#nXl!iMB3hl
-FTP://P9yyxqsh1rz2q-r7gp.h0W9VBZWGP.tk/gvbKQnzs/q1Gb
-file:///7KTju7/x2t7Qen83hFitH
-iawuqq99.AX/;aTO9WOuOPwl/UAbRoxCcv4
-http://h-juvh.3gtf/spUbB%2aq/#%9C2/LWN&
-vj021lv-xpcrzcaibfgk0.ad/dVYoNrxc5/NVH90Y7CCv%4E/vITM8z%C4?P9Y6IZlhse=7w1CwndaDA%79PY+r4Wm+esuV
-http://%d3fV6o@knpyxaoxorjk0xthy4c56-idtz3.i91eof5.mt/MM0jI8/mviceY%E9KnCQrwqA/xTTC@R/bgzg%6CfrsDT/uN8jUqZIRPdu9a27A/aNc%f4l1h9UUax#t4W~aw
-qc6iz4vjp42.9IZ.l87y.4m79dnm6i.tqhva6e.dumzoy.GG/aNgCtk310/ltjBeHJh5uJx/XMIgU=CSzwD3D/
-http://p7E5E0.hhvqt56.ug/2p6%2Cb~bL/JIlK:TS/KKKGy
-file:///3%aexrb7UdZ5GpR4ZIfoxwL/vQV%4a2zQxki/QRji6gHpMGgBaM/d%71A2CTpZv-kF0tD/Ig6roS8m4/~aA64OxN2yNDZ/fLLcgp%d0/He%98%b6JWoLAm/_aKE52/bcn8%06hs~If/IV9oQt%A1K
-f5ms.jp/%A1FpERWwTd%BFG/ExC8V5aqx5l2CLJr0mJb5u/DgMvEzAr2U/py9Vg/igr9PzANtw/FFiN1E7
-https://227.086.128.010:64985/MDKuFInA86qto5/_cK=4S%49Ic/SPp76/TlV%0Arlwfx/
-Ftp://171.160.94.43/ALTgS46I4VM/55PbbK/5N%faTSE
-Ftp://3zd7z.etw.XN--KPRW13D/4UztCuTbW2z/LL%2cDI/dTYSi9
-t6xfr.wxjz5p2t5.zl8m4.MN/2cbpjk/gsdm/5Mvc-j3rc/16Wb65&c7x
-ftp://D02-auxxaeqnv9ve-jlmo3.l10vqu.12jl.2mvjwrsqm.BA/r71QLLNu6oGJjG/HbxrX1Grq8/QR%2agZv4hR
-file:///XoCg%EDVf/A3ibJYjU
-i44X.a8H-WP.zgmnrjxq.NE/oL42aLwl/h1unIUx2m5mhir/ZjNqL;n
-file:///KSPSz0d%734OBRur/v2feKz%7aC/SfV1syp
-http://29SB.j6/ojVDhx/%A7e34T8%01L%41BNV?6uRxM%DFd=qg9jmHtW5R&EeR=%f9,mnV.cGVNclEM54f+efsLBpEc+3V7mIJi+Dng2-Qk9&t=VWC!+5gUmI&c4c0sX%51=%03?a3mDKm+4rHPsfb%dc
-96.79.198.95/8JJUovS/
-file:///.LxM7EsLzp%d2/sOKzUh/IVX5Mw-PVormR
-5r.uL9CQEBDLX.bn/?3z283zb=k&q%d8u%aeOKQs=s2Ixcyjmlg&%52=Fc68M+%F9JLUS+4XTt7ypy%881+knwx%3CF+CUc1ZNLx)K8Ht&Bks=*woVYK?GE&vv=P+b+W%134Flc6+%2e2w5%cfPu%5BXUS+PAAvb+@e/E
-http://ol7ctcj1x.Ugk.na/jnDQG9WhW/r1cIpcqfGNMDWto0/DfPQlP
-ftp://ico390kww0.it/g&kOEETBwQ0Xnfaz/pSA4oQJ/nU1WwWgH/u9TK%34Z/x5hXHtQAb
-HTTP://iEYF-043APHCKLC7PX.qB28RKI5NNRTNJJ41MVKDI53GHXIMLM.BV/QBykbXcYpFg/zgpKZ/pVe2L5cYl0X1%37bmI2D/NIdWj_%EC6VE56mu%64M1sh%bfvNe/
-ftp://vb5vs.P5f5jmxq.sn:10748/gx%54N7WDo@FP%a9/aFd0z2V/6OCUikUdhs/F89CFSH6XHi9Pgt/CzM6Y3s0UZ/u8xukwK;type=d
-File:///B5dOvjHOOe/oUJYD5/zgi4jw%54XPx=S4NV8R21Bo3u%d5/Mbd0rcFk/%5cPig5
-FTP://ebibm0spm7.cat/aalird/1v6GldpVgXA/9akBrbVRE/FbH97%67/YfhOfgG/gPiGQb%D6?AodiI#nTfAhiF1
-http://[9396:d59e:191::f7aa]/isqQk3jC/js7gnxrTJLFX/
-HTTP://k5ifny.sa:32595/8XvVVW6Tp37x/IF0IkevEa9jqkw/58g3p/MZB%94sVPjmF7/wZD0BUp?N6P1o=nH:%5840TZNN%37eJ+AJXoM5t7+UhR&%3FCC(O96dC=e2Zqj-YxOMwv
-2hr.p5v.6aqidmeffi.flfqfx2znf.cup605.v6ktei.mi6.AQ/ky~LSgBJ/3JZhLix/blFeDQRn
-gtf7abvdn9i7cr2e.YE/-1vj3Mw/P%CEXiCFd2a9/vm
-http://3rsqw6jt.cv/n5e9YJBevO5c%6e4rW%a8/iKy-raSDu/.j6BTI6/CZR%f7I=Qmfr%dd/#xTHGb9RTWP%c9H31p3
-file:///S0Vmb2/JccbhGwccE=w/sgSbbJh/2OjHXikwMAVk/V1l0~FYdw
-file:///5fXz1pJg/G%A6MIr2J/6gwHl%1C%55Xx/xHPZg7hEg5BzqAVzK.gM65L
-File:///SxZ0jN1/C7FaB/Q63Jxn/QGzG%CEcYzLq7sWLWF/tD%3c1aukYV
-file:///T8krlfICzWYr%e6/xGDI6sWJ/jCXF%87zmV6
-ftp://csanc.mz:27249/Q4ci9eH/uQLFb8ZVrjYbaCS8/sNzv%8DY1Xapc
-file:///P7Ub83hzju
-HTTP://q6-aoovoq.j-joev5ivayrom1t474xlqxrfro.xn--wgbh1c/WiS76Kh&O/IDDo916%22Vp4/iZYdp?%66lk%24ke=&OGXRBNTxne-Rc1i9b1=b2DcK&Lyuxv=&%5bF=
-file:///
-2cc16zv4u31wx-edyjiy.cz/voFy:f8~/9kCAM1/1i8r969t&%53/V;exvHAKlZm5g/J85xEKDBR4yY/@%8dUYyVS%4e%3B%B2m/W5AXsrDE0i/#ivl39=VdW
-https://73ll5al.MO:10068/5K%AAf0p/#5deD$x1
-FILE:///a0esBQEE/
-qnta8.f9284.5pvu.af/tHEFme/OOQl%E9GOt/xuKnPxLGVEf%D8#LfL
-File:///Vg9klGYqV%f0f9p
-[1112:D95A::f9fa:5258:6AD4:3c08]/tAHstaKl7bvDJ/Hm3zObt/qSQiJ1FD/ff6EP/YLR%71gk/Qm%98XlJqp/B5%31GicO
-http://[f34d:a4fc:b932::631B:2C2E]/F8CJ0o2L5/hNITi9
-http://fp8bh.zm/R5WFY9BBHOmi3/OyhE6XN/7tZGprtgW#hrKj
-mAIE.mXK.qq.3WVWRXC8BASM2NX8GRC-L7O.nz/l%E8SjQ/D8iYe/2Qi&C3RMJppB%88b
-https://smj0v/Z8B/%96%A4mzAT/eixQJ/v%D3HDtup
-ftp://J-b0a7i1grxbx.gt/MuPMg3Ly/r2iyJo4R4opO1Xj%C6
-vbhx1cl9dgl-asht.lDN0ESMI.RO/A474Sw/mcZtSSvta/ZvpyTJ/OFCSmNJ
-file:///pedpH/COpc9b/gtm%d0EBmRz
-[B91A:258f:095f:5755:86C9:7989:2DC3:B052]/%ecPvKuwpKpSQ9ANsta/%ac=jmcQsb48Rfo/bWIMfqk/dUQF5ms%d7/6Em91E&z78/uGC9e%53/Cleb%23zyGMVzOe/Rg4teS
-Http://[725A:9A3E:2F98::9109:5272]/ijhUpBG-1FS%73%D3
-gmamwxo2.0z8rwjft28enmc.p-5uyn.u6E6AXVBP.ph/gBkpM4WFysjoV/X591ak/tIRMD.t5y766HT%5EX/RSb0a/Nw
-https://mxfwd.gg/uwsX4/vnVUhsd/igwlpT%bahLI4;P0
-https://9g5pjef-db.Mq0tfjbmqomp84hi.rf97xmi3834.403gi.TC/sLVqu3UG4/OYh%98SQXVXf7Cp/j%deBNpZoEfAD60RV?wv%90PcN9VQR4g1=H9Q5pv&4C=aZ%a7l&B5hpDGtJ5E=%85NY
-Zg2x0pwfg3xo38fwn-5rriv520uccxjuyrxov9cig.fcr1xxh8.cat/hQOVnH-6u03Wc/pqtgVxVOnlza/6I7b3Cv/8L%20%820/2GVQbVTA/FoUjDrsNT
-file:///aQa%A8K1SpUF3R/DRHzEQarZC/WpL%4a~dPnH
-FILE:///7TVlhAH/kRBTpgn2/HbYFSHYnrazY5Pq
-FILE:///wC97%71cxvYq/%16?cNGP/
-file:///u%7BQA%909Et%edmf6X/J%44H591v4iAHpgc/qeuedAPm7Moi/dE5xiL8W/%52DLIO%B1vY4h/A%1DIi3
-Ftp://3ZBZ/YmeJ68Qq/%E8%74X5e%18/QNyU/
-https://R@lyd1.xtccruqswon.GR/oHPO%79jfl1/rFfct/TI4I5pfjn
-file://Rcpx7se8pzp4sj8ooxrlfyi.cpj--z.tl/ZQtA5b0%8F%665G/RTr%2BytU/4C.hmyu8/F1hcJ/PiHi4c%16VEN/66dIi
-ftp://wDIXDXTT.vg/eCSU%14/7My9QiLZjNwKRh1/pd16vIBrmG/sXqjHnSFyE%03HA65WCMRaJGunYbT
-http://[fcf7:4e45:3CD7:4B2B::]/ZbLeVZi/mjJ6/LMTBU/V4%e0nMMUsY#'aLkxlcFi5
-ftp://k2.jALPBG.XN--MGBERP4A5D4AR/NyVb%E0rdacdy/KQxWB%0DFc/Ruh62/qApiRp%fcc7NqG5P/FQd6Yw8Hi
-ftp://sjfzvidjcj.ae:55965/r7feW9uA/33qU0/BKlBWEwBw/w3nSd
-ftp://2k5.lfssxj9iatcd3056j-rq0/Bq8-ZY8byN/Skg1r%290%40%23/X51QAJ7U/H7Ir4nHaQ8?QOW
-http://ip0176.JM/LthE/E04n2pcGJV?P8=dCpb%e3q
-ftp://072.017.130.122:58513/6P9dqEIAxnvathxK/GHoR0X%5F%8fU/%ffANo7hT%dcKY%dc%B3%75pXy
-[3157:621E::]/CmIefnv.v91v/I%E6OmZLafDS/a7JoSqx80BC9/iSPk18UXH/g6xdyYNSlT8/o34wEX?MLP%993E=%1Fao&nRDo=6svN8+d%4Bq%30jky%75psOKb+h
-FTP://zbtd.0doxocs/sDrr5d5i/%6cJnyS/5K8mb;TYPE=D
-http://1vkic.cmd-efq.st/%937ikPpb/eZh_3dIzXbtNFVxL9nQ1/7bVwDiamdDs;8zgSZ
-file:///YTllDP/IhzDW/%00H9e1IWG4%42%93bP/UCdd~o
-ftp://ksd4b3w04c5nk5aasoepqdby-9w.sl/pNe8wJ2LkrJZ/XJSanvU/
-http://oPYQ.nd-egq1mkgtuwt4ei1ax.GQ/JRpv
-ftp://171.235.253.31/gop3Q%bcUoW1/38aPN?
-File:///XoULHUnTn/zYp/#SlAGu
-0kx1j6uf.QA/lhgydNvB/jU%B4oWUd%842;n/zo%63SywbGAgc/c2LB/wV8n/
-FILE:///kcboy@/9goeE7Q
-tD6HUNLHK3.u-06.FR/WwW%7f/1HS0pUTG
-Http://c82m23a-5oprsol87jurs142tzex3957m9nrufva0sc6gdo3pajic8po.H5m3wt.1RU:11878/Odij%A65n/Am~mzHC/#ArdWk8
-Http://cd1.es/w~Uc%455aE_/wVJKfr0/X3vnA/ImG6Z
-http://5ect9i8665yca.FJ/ylKD5bCODpHQ/lbunoK/%98004LI_w/HwTFV/4@O9_DiwGb0Ig9#B8z%90jjivO
-file:///IDE/mEZee3/1B5W9drK
-http://wka3.GM/%95yhyVy9#FFld%0CZGoiP
-file:///nAL4tAgn/UK?mpt4IE/.2JW4Ej%28uiG/LulMqnbE5
-ftp://973k1fnytm6y9hx87p42k.1whc75.PS:59063/nxryc0E/ooGHQtw3ik5/6fU4vZmZNZ10If#iFXkFxd
-File:///YTIL%AADxyn/exqQCc/HrBwtj3/DIOgKT4YUu
-http://3ucol3f.lr77xtr.LK/FNsRpDDW=/76bEzBTI/q30mQZ/
-9sb.7mct69t.ar/WpXcM8498S4F#k@L:'L
-ftp://3qn.XN--P1AI/PdBsWGhCy/QSZ%06xb6atX%7eXtqSy
-file:///t%48r6pvw/gTme80:slEt/ciBvu19
-File:///8rjryYe
-https://[887d:5086:CAA6::DA5B:192.032.127.177]/
-File:///v%2CCgt3%32kh5ZJx/~kf8WDLeR3XmmY6ap/.DEZNJ-ylM
-file:///KNINXVO67tBU/VWJdbMVH%a7uqRO9%ad/55Wlt5O41e?/YGhF4Fm
-file:///zYYquoqz/%240zKPi/@k9J&epm2dka
-7JUE8WA7CLBX6ETD8KUU16AFZHHS234NORX.tep69aqao2.int/iZjrUNXtQfBaF/Z%A87tU/XfvTnCVEY%00/FUyeI05%f4#?hZ
-file:///1?Msuc%BD1/G1%33Ppp/F2Sv%0EJIBnPzEUu32/81nqxxTk1HPO/7pyYlewH7gyw
-HTTPS://hdtgt38onqh18-617otg7tn-ut6f49po3gaajt47.m4O26.rwko060q21o.Am497x0kow-u.TN/nZX955o/JtBhKlvv3r
-ftp://28.118.125.16/3j69z80kruR/TXIM6gQFdZTCI/T52CULszlqMQ#%C3OT__%57
-ftp://y8K1P5I8E/c2Xa7CmI%d6TWC
-225.022.162.113/ZF58s/%CE%56BA5rQPOLU/AUNP8rG/w8SHG%d0FVsZX8dC
-X6eygmy.1a-mtt.ki/WC9%a6/GH9mNozOi
-94h6rdisa-eh.CH:8242/I8Ik5%42881r/EsVYPHYT/Jw7%3A2%2778ggZ8u%60
-Http://89.pa/%65ssgG1L:fKtE/PrmY6WoXW/oYH2AfHjf/uVaFyqn%ee0o%4fAh3
-file:///KwM8U1%EBR6J/K.asJbs0/i1vCxd/ZthOZxt0IKQEH/#x:Q8vtaIw
-http://rP6.Ewrowee5k83.COM/5CId/KVp%FE
-ftp://l8AAQ4XL0X0HO6MF7.9d.tw/%98Vb%117Uy4/KyUMl9
-Q293qtnuw.vi/6fi1J47ebQ/d2EC4A5OM%FF9_tUNs/dk=?YyGXS=&El=i&Go%cb=fb8&7W95=Cg49VW7B+B3dDs+f'fhi2+6QLTS%bbuJ+IN8+1PE7QyfjCX7tY%7D+cGm4+JkozC,0y+SEO%ac&V1pkpm0GF=0%46pvcEyU2G+2%F5kBuG
-2pu1.mv/3uiG%445F~s/%5CTa0YXuNMsqV/AwE3d
-file:///jIjyqNR/CBgOXsf%8fYiqCR/
-Voiuuc65jm4ven-9li9.mii5.0h5xt6.KE/qachnQB/nsC%4ai/juYvC3yTiCp%06S8I/LLVvQY#p1jmTyx@W
-Ftp://ydhhq20m.MY/%ADNIfcLl66t1fl/v4%a60h/N6My%9AKXUvToMFxY/
-14.21M1I.NU/iqlGVazIWPCvV/oelkORYd3Iwsdy%0D/LcdN7U
-file:///
-https://07zje.j84g-9lx-673h.vwr.km/h2Dv%1BFR%9d/NV05FON%c9/klLPUVUcp/LRlEGREG3H
-[836e:5fb9:0cda::D9A5]/n2j/Kjy0BzJ7Cj/GoW1ksyHG%B5A8tw;v/hIg4F;R%2Ax8nL/d1aHG5Vsb/VNMIiMx
-[E69:a743:5C18:C43F:780d:FDD0:EBC8:2ce9]/uAWRrcx
-ftp://B3fvr.l5GW6REKV.GI/0qT%dbwWVXZ/3kdb0/kBQuFu/R@9WXH0
-Ftp://a4gdplaw.TP/zyf2c37ZfY/QaiwZ3l/CUi9.ado/
-8L.vg/LjRJZ/z7/Fkg9dwmTDSp
-T7wos.u6I.cJP-5HQQCA.9dutej.SG/6McEZ0
-jJ0D1X6C5CCNWYGOCI4NNFC5A5NYJZTCW65DHS.d1yxpq.TC/EQ%DBYuIdBv
-File:///YGxWV18/%B2bnYvE/COmzr%B0YLEB8/%75L%c5ym2Hw
-HTTP://nzhfr.Mlrs1k026k.KN/~bhI#qqgVS5YR
-https://z9z6ip.INT/1%1dXkN1P/KI52I/yo%FD13SoZz0?:z'X3xwoS=1y&lmDOOEVzwHn2j=xfbMj%67cy#bKedfyI1
-FTP://aysc5.8i8kj7.cu/Ule%55%F0l/HV%7FNXdQfhjf0/
-file:///UZg7IFvJd/U%6cAH%59cS/dQjA9gM3RIJ/cW7Kuo/lBGa1%B3Hjf2aN&/
-file:///TPkfDWADgMp/9cr6zwO%38cZPtrql/w3GqL/nrvKR6Kq91#s5F4qQMjYx9
-http://1co-4k.zzzqb.XN--KGBECHTV/WRGpnKFny/eBiU%BDapp/0cb5bJ5%24J8a#N*cE%e4BmH3Jse?2
-n7q2q9b.3-ve593.eb368oe.si/xsA7jCLE%5CRj/gEfwCC/W21RJFHtG7td/fSZIiv/6mJkJcnid/xFjV%DF8pXhf:H/vh4Z3%efgdOJkeT6sTC/wUOxqbX
-ftp://[7D66::]/m:wnkiFBKJR/7c8a3te/mQqS6ZDWbfTXtZ9
-FILE:///%41PSndZFnAZNuF35izYcj9Jmt/aoJ8K6/nGtfymyBi/
-008.245.185.106/0Aq3gb85/6TZk7/PVTk%b1G80
-ftp://90.188.10.180/fgsPUVSAEgMuLwrpxg/8QEjGiNEHN/pxjBgdVV/bkiEKy
-5yxzap84dz3lccndx3xoj0zcwepy9ujq4bk-ckyo63.si/%E89rzFXG/htVDvVdD11S/SLLVce1/%5bgcDSkD
-file:///Mr
-dm83f2l.vvlpnpob.7si.cr/RFT%18uMgARxsP/8%61%7cO/eZtPUg%e5FavR0XRe9wZZ?c94ub=63r5
-file:///cdgSAblie
-http://[5b83::58CE:d882:36F7:8b56:11D4:f42f]/9mbBwV%C4/AI2q64JsNqHO?tZ3=nATs%3CQ&lbSzuIb=/IJtfPRbcu
-ftp://gOD0KB6HB8JDGK56.l-V4OW.sj/KqqiLzCu%6a3jexLbLB/%6dBHZb%29z72YF/
-http://s65E1E.TR/5sj4rIdUt%CF4F
-ftp://[0f52:d55d:5574:ee10::dc96]/dPEbp7/PG0Nfo/MVx3/%5Fzz8%CFXb
-bdctmj.vzaax2fe.j8S2.ojfq-b1m454.g7I.uy/o0%28WV/Bv9nDwD
-https://k233JLHW6N.cCA13HZAXR.laiu78y.fleptcf.brva6c.osod.GS/OB5inpGTj=gGI/YNi3_gNnIg/J8UObWz6z
-ftp://enokmi/r3%690T0H5mfdRq
-http://s59w.cg/nJoM7yv/Z2T9Xof0hNGhl/N0%6b5Sbrbtjj/
-ftp://qytw0h.hkdt2rm.gd/3a1WJDglP%cfZ
-Q-2pgsvifg.yr2ix-c4avrjwva.kn/_zD8ad/%8AVwQwOG/JMC314h/rO0qj%88?w0XEY=JUigA33U&f2=n3tXrMH74ApC&fx%BE0=b%d5mgX%7F&1gjjJpHG=vLHCZ0Z8&sYQBW%FFAIs='&zD=GTnVzkf8Yn%a3L&Xm%b9F%32EcwWl8=GUq
-File:///spqq/8F2dG
-1Z73HWVULIKOO5WJ.rEJGR9.nsscy.gf/rHEt;i5T/%50ZjYYJ3M%4dR/WlW0C48ocnb/NRA~0M#
-078.104.235.053/8KqfxznOtxC/ycYiTG3%11zP2%A1/hhbuX9Z%d403wES6/P0gg5%94
-FTP://58vs5.g0.tHI.gq/N4HSp%95jtMMNr/bpH36W/cC3oAe1C/Sp7gxd/XO7JSqE
-http://e8CYICG-3GD1Z7A0V121.Ya0j.Wy.CM/BLyz1kmpRF/nb6u%52/GpXGTv19#9?bwz
-File:///Mze0xLtXpPFW&x/_%0aYP7o4Fm/5&809/fsvOYyn~zvJbT
-file://V-jo70zmqrppoeyva0hm6x10y.UK/#3O9f0OYdx
-file:///K4BV8xTq%ccORyFI/8PzAVSZeBNFX%adT
-071.247.240.193/%94VOUi%ac
-27r2mghslc2b.Dwbpiqi8q.gTYSL3Z.am/RU80/KFcctLv/R8tG8d51EaD&pno5r7pDR#GWY
-mdfr2j.1FZFG4.VN/Xn6l%6dLWufM/I4FHTzlnWx%7BoI/ueeKx%03mfSA/%9a3PMEt.iSdeTVFgSnLi%C84m/6dh
-http://H4jk06c6mtprgjywnc40mjri05a.VA/7B%C0h%4fCjj80/TrN5HugANCZu/eMVdn4en/QUSLGhe?7yjqzvzv2r%b0I=&p%C32*HvmS%39g=wb8u&lTvA=FCGNF46U+?Ak.vpCAV%ceiK0f
-file:///cVjI9Ue/siOD/jynyp9%3FmBx
-http://u8ic-x8o.UY/G9pZcTp/JI58N
-file:///cCOIlZV8ms/Y%e97nfvexWwxq%00/iPxdyY/snHA2QZT%10
-ftp://53.151.134.240/uZqGXLUIu-J/=%0C2pO/PvL0%19MpQBv/
-FILE:///Kywof5D5q/0TRS/zayrkrnENB
-file:///EYS2nDf%9671qsm34OZeB%e5lUA/rYBDn0DKs0/
-mpuwl0.BA/MkvAvc?j%11K4=9gE%613&qOOEP0t=g7EXs
-g6tylc0.daeczh.4q.XN--CLCHC0EA0B2G2A9GCD/1SbCR9cX1%3D/YfP8CpLKn5KzTL8/Kj11z%B7OuqJU;qM4P
-file:///TJa%86AczeCmM5QMhi/Wox~Ajl/WxUF%5eSA:y%0fD%E21/x%cca%d3Qgx/8iWJ5-h%26/fCK%01nQNrK8#ygTTB
-file:///~%303cUUVYTEaQU5%5DXbogiPKb/favR2rETEh/9TXM%15u/nYCOZpZgL
-file:///mJM%a1/jv5%53QDqE/bFMu0CBp
-[a0e6::]/YR5lwpHlG5BPjr2XT/Pq%e4kWAmZ/ucI10P1
-File:///8YorWt/#ToazT-v
-http://2igfcm3qy.wlcgdxv-xat059qnx15a7qp-p-p5oph1c8.GP/hS4Aqy7SmODbaOH
-3s81j.TJ/pS9Jzw8:NWryq/%00Kh1/Y7Rfoo7haw?pYq7Efg=
-HTTP://k59s6i5o.my/v9%93qqGOWZ6RN/cdz6V4ly7nM9A/F4EhM0N2%53H/d%C4wWTDspWU/zfpMcIDWp#oO%6fSILRH
-lvh-kt.TN/xZghTR/yDiD0a/P5D2%37rFa?rseH*%33ubfv3=%36ntM9MP,+97RbF5&F3Ia3L=%3djrAi%f7E2%65iQ+Uc43&y;Ikw=vdfmJW&sE_%F6xpm=XFIfCsT&k@ctNa=%47KDJKEw&d=am6K&%25!BjLNa=iqs.l
-http://Lhe7w4f06qt8tif2af1k6s552hlbk.mfce.cc/DEqiQf/GLpkeKZAxhSO4m
-Zy-iit.Cth-tuvx4.au/dl6DMUqP/wAeKXt6
-File:///35GJ%C8m6ubg/kpI4iEEx
-dbe.gkg.EDU/cJ%fbQ3k7pwp5/arlH%DCD
-Ftp://e8ni0.5etxvrjvn491/tP8r:UC/faEdqs4P/v4zJax4
-https://4PI.gg/fFtQoVp/b6Jf55/YEc2l7dE%CA
-http://gpu16lz.LS/9e%daJrwQfHEpFvsZ3jx/c4STIJ/CmvEGAUx9f/
-file://ij9anjtok86ro.uN-BGDQ855IB.sDXAQR.5kr8kz.3J3M8XRM.18r3s0g-6.4rjsmwue0lwao0og17d-5-1.F1h3qgkul29yw2t4p4se5clomncxhmoy.g6c9tbz7.pa/5LMtmbl/1tfIF/pBOV7Hc
-HTTPS://bF2RA.kw/1TA9pTTBg/nM/VSRo%85Kt?%62mxNfo=HDowgwkM3&9oPOLH2=yKOxIe+YNtt
-5.Piba4ac.JE/55M1H/AZXdj
-m-k6-ej7x.XN--J6W193G/suVrNQSIj9/TmRhHbe/o&0dbqR/
-ftp://242.228.138.8/o%CC_QjILS%17aYH/%caw8CcVZyPRZ/
-hGE9YH3D6.SD/m%1EpDJrzO/Tf2Xxqq8L/YJT7BTEY%661PvcMgOr/29ZbuJuWl6q/
-Ftp://mez27g2tpmk.MC/%B8AHk%95etDns%46/gXbsCn%6C-/s8_Jmy/DhmfT~Di6KD
-file:///NJvRsBjo/IECCGBvb
-http://8-6wji0x.tCVT41X.k1PS.15p.SH/e%daVn5b%f6/GpIJ%65e6/VpeXUmg#FRgJm0E
-ftp://nx4kcydiztae7fr0y-2kfppteds.gq06u.cr/RITrTqm/VqRIYR/6psgA0%dfpfg/gcLyL1/xa%72QCL;type=i
-file:///M0WBSuI2qsMuKSfOzj5S/2N7x7nZg/BLtq%72VxjcR/5%EAn1%c6TYYPGe/Lb5Mtu
-http://94MNP6XNH.0mgqklz3t9g2xl89x81-a3hifmff89nahy62jeyhuhe8lhkuafizl.GQ/Ajpa4Z1D0o/aVv748s/NAIWCkWCD2hj/7MZS5c79DmL4/ieQ%21gw?oEPqIN=Pm9nPx54%c1&j1y=C
-ftp://rKI.COOP/v0pdu1zj/ir2UM4X/7k04jhOKPVN/7ua%E5y8p/bl~yS
-d-IJA.PS/drbtmJGFEbR0OzDD/wMV2C/krWmMUV85/0AFhGe9
-[D1BF:D02E:140C:4B9F:c86e:9fdf:077.173.119.180]/A07Ox%86Oae/yhjXUMut
-http://A.bi/J1GPah/OT741dJ/Jh3Z0xb3
-ftp://6VMV.t680F6.ijsru3.bm/vlJmkK/go28Jr/qUtmHmqhj/ykeAVxYoe
-HTTPS://oi%32Yp.@a4mk0.Teyu0lojs62d8l96qiym2v477ixatleasrgft4ttpbfel9r.BW
-x37MULG.514yrp5.Vrd68eeufzt.VA/fFMWutSw0d/Gr%BFun3/JH6%DESQV8f#gn+NM2
-http://2.88.82.235/6bhV%BFGDy%ABd/g84ly25/;4AeID#
-https://a860jcplfoodo0yq401cdf9.1ZE2P/NLArIzMZ%8B/6UiHWMMGS79/?4N=4U%1dM0qA31&faSM=0q2RaEJu5QT+vzNMp+XR%7dI4dQ+x+%0BawIYp%dbcBiOZ*Sc
-ftp://lb.NP:46239/xwyAL/m74%9fqj4gttFLg/
-s086j1-9.Nowi9s.fm/16zr3s/mvzfyWbB5/&1mzA:X-3
-eigz5dhw.jynsrju0t044lcc.3c3bfm.int/%ffoZ_kP%5cO1ls76B/pQbPDb4s%4E6i/bqqrZ%b7j0uhrgIHd/eBdSEwfGrX/PSmYMzg0%6F?Qr%92y11b3=&L;5CV=zJao%31Tmm
-65-ihklk4j6m.f3CFA.7kj.qa9rcww7uefzkpxbf87ni28b4a1i9rjqy9a.5texnqlc9.cu/p%CDK%b1%449LH/IiLqpww/HmACJI/r46TA4
-133.38.197.20/pbgvKM6W%BCEBN/Cvcu0&#idQDycc
-https://4I2GL/cGtyrs/%A8m5%3fekPsTRWlB2?rn=63P,EJu+SQ1W+uPySU8pvA+%f2+m+CwuUokAVfo+3nzWcQ+S+iXvEuhcv+d$h%7fy%cfMB
-HTTP://a0br.o0gvxf.kp/zZkWq5hfxy/q0x-g0In#bd%1anKx27
-ftp://[1327::117.246.244.220]/%91y4%09/
-ktefq.GB/uTzbgV/9nYvIs%8412/ynKYs/YwBOWmj
-File:///08bP/cw3Ydr5Cyow%273h:O3Bcok/0hIP@/
-[018E:4459:9892:3770:3826:71D8::]/UcHNufii29UtPW%56WQ1%20V/ybjTB/oUWWQ?yUg1%cb4A=wk+hOic7f7Sw
-ftp://1o2z/4UWsX/uSzHOw3JTrqy/TqZhkQk%62gZ/FpK/
-Http://kZYPZSRN.1m.UA/QN9n3Nw8kPAgkCB/SzdVcxryKou7mMG#p6at77
-http://se9g.s7-5qnlmsi0npbr8ouxuey3y66swspkl.y4.st/xfP7%066uXWuOu/clIFhy
-ftp://D4j9grnngs4a61b.im/f35gw%53rTeI5/#Ff7A0YMs9RG8t
-https://zujspr.cr/zy14P7FG3/Oxznfe/P2zpT%38S%FFVfP95Lh/nJJgzX/kcVuHCzV?Y5vMC=3X4n%9dMqeGjM+OjgETPdf%23b1+6H%47F+waIQ&,ZxQh4G%8AZv=ic+fQWQN+0y%523JTe0Ti#OA0m6iC
-http://141.171.118.17/VLnEb4Y
-https://sla.aowts.MQ/KbP3AV@wXFSgz/TauvS9f2/zvGpvN.e8a2Kw1ho?jYRUP=L_IAzw&cj0ux=xz&lrA%8bS56%A9=SX7NjQ
-file:///
-FTP://h6.MG/XPmpsZk1h%0B
-http://Dh4mlm:8000/k9TYvw/EWxlz4%97lBf9oK57N=Z#Pm63s
-https://8-lno5.KM/Uco2E%dbYPx~/MzKrkZ/rDpXB7OWtD?Wb1W=bKJazR+yRD6c+qwe+H3bo2ACXXzkVX+PdfgOJ1Sqm40+X%3D)%AEgm8I9&inwrA=%FCe+%f9Xo4S+JrcmiNbPwa7P94J&fMCr;NellUf8=K&lhgC1k=%32CPUA6&%dexj,m=l
-http://bske9znh5z.mq/rF739Qhneaet/NTfzZn
-http://B7z94v/
-FTP://p9s.hh313n.6k3.DO/xaRRXPre
-File:///Sn7Qzu4cDoJY/6AdR%8ccbeeFmXy/KRXtibcbXtTaLZt-bb/PISQN%777zoI
-FILE:///IfZ6yalAm/BoIjbMXLnlo
-file:///kFKgAORyDOV
-file:///f0l1v94Rmms/zIVjJg%338Fy/5tMPO618wd
-FILE:///fpbiT?6/%0B7dUkWR5r%AErqLW/v2n%bet%b3wV8Yzi80OJ.SguK/vBMyQaKiH8/Wy3l7r/D%B8Vp%51GgmqIBUHA/9gn1:46Xok/NcNIZ/FIK%359u%57/%35NvYIQIN/
-FTP://22A1D0QMF.cmcve.CC/cvkZF/H%4EkZr%39EjtfIO/LPx46D%5AgqR9
-File:///0Lld-DX/&Qmx07f/Zp%21ldGQq
-http://rlch.COOP/%bcKE55hwH6/CKHB%2Ak/Qzsn2Rn1p3RUc3H
-http://h6d5js.edu/IO%34xTQYL/OtYPRaY5/e0ILXZt/jNP2%07otUg/vGyq3xN/DC8P4ckE/JGfiUR5EfFk/vSlxbi5dKL8d/6JwRI
-FTP://Sho0e4ay9e.XN--KGBECHTV:41333/6_5S71YpwTC
-file:///HrmxzTn/sozw%db8Jz/x0czCVWgklrbV1Kf@IK/Um%78PuxjtjI/
-FTP://9m4b5lf0.Y5dnwnduzx9wha22ayztin-t7hng5b62e07rzsv55325xgdrzwx.gov/pmG%45dhnQZ
-ftp://t2ik0rgw.krjz72-l.xn--mgbaam7a8h/I%19KxMhY/FSau72W7/WkW/vYKyDkhzNiu&Bput
-FTP://[221d::]/BOKtvhabe/b%78z/piR8RBZb
-Http://5zwdz3h27.q9l27mto-5v0i3i1yu8oyl.TN/wk91N/X32rxh/cmM%01iQPnCulto/
-FTP://gWUFGOXE8EW.1g9vse.xn--wgbh1c/ncQo%42ihY/Tyk216/;type=d#J4A9HEH
-FTP://5wudd.ga:36706/W5a2PQ/%98Oin@%D5hjD/POMMY0b/HhPA4HL;type=i
-file:///E01b%6ew/8QW%66%16Un/PWDGTFrQUHJ#dk&o~V40
-ftp://p78orte1aiif9.zk-l-n5drgvx2kj6i9e034ck587-utyikjhal.qE5RJ031K2FAN-35.v71jyg8l/wgwpnw5/1WPLlSc8/3RZzlIEZMlC8/ytaOFdSuPKO%72T
-tri9.Fyhn.SU/YlvVjSi3M/ylMdK88iRo%d8/cuHyS5Am1oeQ/XM40zgdj/q%9CLKm9Q/IOwvLrlTi?nDUET=e95%a3qf&dSTE=X5aY&pWtb=&AS48RI=71Z91stUL8Oc&z1%B6=fVvMzZUyI+Niwre%5FXyVRF&QtAo=5
-Ftp://Kroc.Ls4-tkd7.sg:58219/9tq-FJyL?Qb/e0alokGZ2/MKTHP3Wsw
-pmg4ty.m59480p2f69.fV.COM/X98xZ.E/cTleUeS/9P6zeVQjfd30/eVVvE4/Zyxm1SSqe9u/WP%a5hS
-6P.BD/du%F8CoA/W0jyU5x6HXyVB/EOpU%0BP%BET/TBlhd%772ObORj/PNPXkVHaEY
-http://5BCY.X3.SG/N~63s98IV2/?KuYCn%3160U5h:%BCU%DD='6uk3OyUbosbcu+l7U89Ozt12K+P/VK4+GhwEZ+D7Z5ByEYxG&8=#aa7R7i~K
-https://38yyrnu.UY/8Kl08k%157n9p/TEeDKN/qQnmQFd
-http://5PXM48/G%9fUxcBwBjXI0/1UJen/MF%30I6/eOsMzFMiM
-Http://s8AL.rc94r4iftx7qeg4cbjjv5.za/mYk9UAydyn4q@w/T7K/dd%8aIXPp
-Http://130.165.027.114/o8bwef/X%70neu3uGKY/NU%f8xTKW0;hTKK/V;%edBnJYWG0MI/ZlDMtVPK7?k1N:WnR=%3DNffenC%67+sf(z0U!mZFe+6YqpF0Ei4l&kea=&pv=0FrYO&%69j0HYlx=HVIq&sWgaQHZnyxp;=%97SOx&QbgYd=72tO&ugOWlP=TaHT&Zg5o=c,2tzpy&Xr=Nltupn6k&nxkPS%10oJY%74jL8=5c%58%77#E92Lme88eh
-sat8a.cc/n:G5Bs4/%92Qx7YH/%933F68jWsdw/mgMLj/b9uFtDS/fCBe=77/LYHeH
-file:///8NiXGOZYq
-ftp://[14A4::]/6gQ%83ppX66/Fm%0fhsGDdq86c52B2AReDTW/CGafhb/4LAIXfs6vOHd/DHtw5%A1
-http://astx.i8o5jdypn1ly.LC
-Ftp://7j.N@Ptavog8.gh/%FDJUUJB/nrC6%4as/AM2BxLCU:fGwm
-file:///LD3OAKQVR
-http://jVVR4GZ.BG/XELY1/P=cusbVv5o
-HTTP://4fx.3kt642w.GF/k4Nruf/hyO_xzJ%982n/BhxTVE5LR/VT7cIG%66726zz/YQCAvC/eTYPd%2Af%18tPt6Y
-ftp://1py.jhl5-h.53.39PN2C.xN.ps/Q6kM9aOm7
-1MRTJ51.mh/OT
-file:///RlgHP4tRuBYzCPY/
-http://[8F09:703a:5b45:F653:AB26::]/C51LFNl/tS8p/yG8y53@Wb?eBrhL=%f0Rj:Vl#%11Z
-FILE:///TmzdtWFH/1WP2R%b3nSKls
-http://5o0a8epm-rx6n67ta82256jav-nk4.lb/HbOqUc/TIVeqJ7Ohp/BjDwRDKJ/JZO
-File:///AvnO.7k/P0YrByEN2yEm9%1646/QKj7fR2/%1F0JYW0y/qscsiKGeGfPA/1rkuJyne%12/
-File:///1Hm4/bcNXO0cG%45XJo4RK4/SQGEP5/ELAGqI
-file://4jc3bg.zs/WfjCr2aeWME/Nv4A4B/invk2d1h
-Vj1.Ngq.LI/FR2%b7RU_z%a1Tf2vy/rysXmZ0/
-Ftp://wkws.yi8srfw.tm/sWvr8nVIPq3lD%16r71KGXZx/zTdcV/N%02%6ER5gChmS/uxEJA26q
-Https://cf3-0aw-g8zmm-k.AO/mYGm9AqQW%E4q?6u=&rX=
-8vv-rhcodmrr42jd6zmrnl7xa.F1igvm2.RO?rQOIRt=Q&Z8=1WyCZjZv83+lpB%7a
-Http://009.130.112.154:65403/z6iLA6cr/%3edXQdq1/yHKzFjDA3nAKTr/Ot4A3f%4DIzccRDaDQcC
-hwpmi.upmzdzzhsrz.e469.ee/SXdNeY7NHR6/Vr6%FDr
-http://[C7E7:57e7:b08c:9FCD:4B77:4de1:229.020.164.172]/LnIzKLn/StXMmto
-Http://2-6SB2KV8V8MV290SIC08D9J7-IRM9FTPC8ZZ.hwo9el74qqv1.zm/tr9K2BSFkbU-A8wJR/CGEL_82/cnMuBB%a3j34
-file:///fUtCm%b6qNK/lltu?NvBAhM/sJ8pOm:/jJ18OTM6U%f5v%3f/
-http://76OXC.pn.GA:15181/OPErhH1cHtl1ba/eIPkR6%1EG/8fVd02k/Ky%b0D5izq4k
-ftp://154.108.127.0/vGpMboeazp05/usfmVeitt0pf3o/Ue4OMVT/sJ9BAYSLje
-ftp://ivbv0.zCR-0J.lku/6m26/7tElM/%b2%0BI.Ft5AjDVp/oWyMVmsG/3%8E1FE8Y/0zdIl/m3otUSQeI7
-file:///0Y7NWf4qwhw9wXP/6ll5YWM55W%9050rPeqawX%F9/HleEmM
-5LUX-O.q-33d.tn/smzXQJn3H/81mg%4de_/jb%97hT
-http://84W32/CCKpkt/c0bqCnoQ5Y
-ftp://nyqaz.MT/0OfOsU7S1H9BM/OjhdD/izbR4txUY
-8wo2j2c1z9s.ef2ki0mlvvnjm5vfyu.t5a-yb41uykgo5kn1qxzffhz667dty8mytg6ir7os9hoxwm2.mw/%39FEVmD/%a4qRT5W5qW.yR/8XB9NHyB/
-http://rbf6ezzlhpe.hk/%0DK8/IXXJAsC?mV8vvDI8K=6t9%6EG1Dt+M7N+D5n@Vd79n%d8E+gj+ofnZ%16loobN+f3-S+e,IH&lnh=
-wu3w.0J5.lv/m9IZaWkw5/xY2%54pNYS9HL/Nhfns/e%bat2cKM/cUXgRzm2Srdt/2s2u/9h8zjwh929Bnp
-https://209.73.217.17/dJvsqDH/RH6Ok_eSc8wO5/BOJws6/9f0DvXJ4/?%ea'Fx=P&6h3zz3eGCtK=4MF76p7Em
-jfajtdt5k6gu11la2jbih.MA/zcaTNUL/3q%31eLT%bc3S/L6v2rt/WtbA0%45~TIvPD
-ftp://Defi-z.gr:16993/=7IIaMpVy3OLs/QtQD7qF5Vr/=RVbNDH8/y3oUHmX.v/Td%dcbiGlArA%720
-ftp://[544f:e60a::8772:D633:DA1F:081.021.019.189]:62615/%CB6Wy1K/X%0EcoPQ/IgnCMLPynfx/fdFHb
-ftp://1INQM6.4y.RO/
-Http://T778hd416.g9r96v.bs:64804/GbWp%47K/zgTKs/cBHzmYZ=AI23VY
-HTTPS://6hp3j2y2tuakzv1rnq9vnvn1w0j6roo3if:58975/vH8BLTu3hzkk
-ftp://Ye1dfbl0eae8lqiiqaojj.JO/8EjAq0TzD:/Bz3Pm2qyWo/ZX58A2/yjn%9F3xJZjsVhw
-66.242.9.138/CYHK1bGpZ/5yyVD%cbC
-nHZMBEJWO.ST/ABXauli3wuJ/WUxhKaZJg
-ftp://[8463:c210::b5d1]:34094/8%AC7Fc/Qh6%62yFExJbdaB/0cAZ3iSKlk8sU;TYPE=D
-http://vmlyl0efotpfd-tew59kcpsi2u7qd/UbXy1Cc/L%0cwnzmdjz/?iy=N16BnPMu1+eYFk%f6CB3z+s4Re5v8+MFTU+k+JDiN_+F1k&C%D0k=F78u+euh%1E1uzTGQio&bL_2omAu=iEEs+goL%b8g6+Y%3FBcek%102&WCz=e!Fg+MUif8Yba0k+uX+A91YO,Um+%70i%818Fpz2&6fP=HlD+%91pW+%f2HR6zs8zrE10ZPH+bWA.BB6k+Df3w:X85xDnDjSiPY+AyDpuSl4VEVTJzA3g&OtUR6=
-http://bCNNCLT.gxa2sbn/lAFakp
-D19f.oD5.bb/xUG6W8VxTcjMG/jYMuWlVMygf/UtIwE13c/%a9wzpO%AFxQ9
-q8HY2P.r5T.AU/nc0Iq%28QAF/#yOD3%b3UA%d79e%1EmJp3
-dPY3X09.AC/STpa%97U%b53yKP4Te/%71KZZvIC#nA1W2z
-ftp://3gb.xgjm/wF%ado0cM/u%0DmCW8L/d9Ss%61dKQ
-6m.56xkyt.32O.com/ToEAr%BEdi/xBpPU2NqC/74sgdq%BD9/WSrx5/5ldupD%47J/9boeZj
-ftp://s0y6r7hg7.XN--KGBECHTV/xQizIlOK9/uxho7%bd/RvxbFGQ4o/O%42UeWF?/GAZ5E8b2/eRaq/l:-1ASwSpw/2FkowF%12Ss/vtCq9dysEc%1ee/
-[d18d:1707::]/NGZMInsLF8/kgC3y/F66qc1qt6OWfeS/DyngWA
-file:///%55A4VpGsup
-file:///WNEw%bfTWDLF/s%A9oZoWUo
-Ftp://2tdk.Ube6velthhhx8o.GM/bUH4XycSEKkTE
-ftp://7kxk4ujzz.kp:32621/hbop0%25sK/rw7RBE0lTN/tX5BLF
-FILE:///IQExpA4kDvUfTkH6Bg/MeVJ4aIUbXCJf
-file:///SIE0AkJFq/ZPJLyYK/6hA3x1InlGm1
-http://047.014.184.200/Z_QdOwjzfBue4Nt/aEn/xuEQD/cXlnoxHIK%7d8h/1%eegEk7E0/8Ejku@r1Z/UZ4gG/%484zOJsP%1b/Lc1okbWRzN5UJ
-Http://w9ys35.wb55p6l.hxl.rs/Y97%58Lp8JjLZw/5L
-FILE://155.24.106.255/3VEZIT7
-d1y8zvhwq40bi3tom.hPCZ.gJ-286X.TG/ayWKrgAvF6tn/L4SgquZT6C/1DmNe/CI69rJ/%f6QrzZGkSQ
-lda5l5wc.XN--KPRY57D/pr80SSZ/eNM1%D50lp/Rc%8EimOET
-l13t2t.sk/O%2BmRkw/@0AgGL@NX/wgt&aggDcp#0IYe'C
-FILE://a6ys9a4.xj.BY/%99BGXp/F=yJtxc71/gvXuHuB9k
-212.072.006.032/6kV8ce%2e/%e7lzm-HB%4artP/zg6tWMW7RIG?U7=HAXw$D3sM%7DyDJ&Gt=
-http://[ea5::]/eIdv5xl/5qhxlOvzw%018f/N3RQQKCz/WzUnsSg8KA3/7ohHZCp
-file:///g_T81EaNw2nJB/1yUUT
-http://2XXY0MZ.fwa.791ck-2gx.bd/uO6FW?ZS5jE:=m:
-https://[8368:F154::f99f]/Y3h8FgzTYYpzn/zHFhQECC/CGtX/8v_~jn3Kn
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
index 91b0be7..bd37554 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
@@ -21,6 +21,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test the CzechAnalyzer
@@ -53,4 +54,11 @@ public class TestCzechAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new CzechAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    CzechAnalyzer a = new CzechAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/da/TestDanishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/da/TestDanishAnalyzer.java
index a0a5910..f104a6c 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/da/TestDanishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/da/TestDanishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestDanishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestDanishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new DanishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    DanishAnalyzer a = new DanishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
index a909578..e857140 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
@@ -25,6 +25,7 @@ import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.core.LowerCaseTokenizer;
 import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestGermanAnalyzer extends BaseTokenStreamTestCase {
   public void testReusableTokenStream() throws Exception {
@@ -64,4 +65,11 @@ public class TestGermanAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new GermanAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    GermanAnalyzer a = new GermanAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java lucene/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
index d416898..44cc516 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
@@ -16,8 +16,11 @@ package org.apache.lucene.analysis.el;
  * limitations under the License.
  */
 
+import java.io.IOException;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.util.Version;
 
 /**
  * A unit test class for verifying the correct operation of the GreekAnalyzer.
@@ -68,4 +71,11 @@ public class GreekAnalyzerTest extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new GreekAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    GreekAnalyzer a = new GreekAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishAnalyzer.java
index 3844cbd..2f2d7fc 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestEnglishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -57,4 +58,11 @@ public class TestEnglishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new EnglishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    EnglishAnalyzer a = new EnglishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishAnalyzer.java
index 9a6c06f..c7cb948 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestSpanishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestSpanishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new SpanishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    SpanishAnalyzer a = new SpanishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/eu/TestBasqueAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/eu/TestBasqueAnalyzer.java
index d398ec9..46662fa 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/eu/TestBasqueAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/eu/TestBasqueAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestBasqueAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestBasqueAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new BasqueAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    BasqueAnalyzer a = new BasqueAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
index 67dace3..53adfb9 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
@@ -17,9 +17,12 @@ package org.apache.lucene.analysis.fa;
  * limitations under the License.
  */
 
+import java.io.IOException;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test the Persian Analyzer
@@ -226,4 +229,11 @@ public class TestPersianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new PersianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    PersianAnalyzer a = new PersianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishAnalyzer.java
index 3fb7ce8..c2df05f 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestFinnishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestFinnishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new FinnishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    FinnishAnalyzer a = new FinnishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
index 112573b..2063337 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test case for FrenchAnalyzer.
@@ -171,4 +172,11 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
     checkOneTerm(a, "sécuritaires", "securitair");
     checkOneTerm(a, "securitaires", "securitair");
   }
+
+  public void testBackcompat40() throws IOException {
+    FrenchAnalyzer a = new FrenchAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishAnalyzer.java
index 994dff5..b1a3cc4 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestIrishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -68,4 +69,11 @@ public class TestIrishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new IrishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    IrishAnalyzer a = new IrishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianAnalyzer.java
index 3d5e47e..d20fe57 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestGalicianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestGalicianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new GalicianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    GalicianAnalyzer a = new GalicianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiAnalyzer.java
index be9eada..fce773f 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiAnalyzer.java
@@ -1,8 +1,11 @@
 package org.apache.lucene.analysis.hi;
 
+import java.io.IOException;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -49,4 +52,11 @@ public class TestHindiAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new HindiAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    HindiAnalyzer a = new HindiAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianAnalyzer.java
index 5caff3f..e4d1b11 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestHungarianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestHungarianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new HungarianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    HungarianAnalyzer a = new HungarianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/hy/TestArmenianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/hy/TestArmenianAnalyzer.java
index 2e04618..8b63bc7 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/hy/TestArmenianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/hy/TestArmenianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestArmenianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestArmenianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new ArmenianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    ArmenianAnalyzer a = new ArmenianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianAnalyzer.java
index a134b31..d6f5cca 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestIndonesianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestIndonesianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new IndonesianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    IndonesianAnalyzer a = new IndonesianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
index ec359fb..017170d 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestItalianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -60,4 +61,11 @@ public class TestItalianAnalyzer extends BaseTokenStreamTestCase {
     assertAnalyzesTo(a, "dell'Italia", new String[] { "ital" });
     assertAnalyzesTo(a, "l'Italiano", new String[] { "italian" });
   }
+
+  public void testBackcompat40() throws IOException {
+    ItalianAnalyzer a = new ItalianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianAnalyzer.java
index 4bf69a5..9335e70 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestLatvianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestLatvianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new LatvianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    LatvianAnalyzer a = new LatvianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchAnalyzer.java
new file mode 100644
index 0000000..edb5852
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchAnalyzer.java
@@ -0,0 +1,180 @@
+package org.apache.lucene.analysis.nl;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.util.CharArrayMap;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
+
+/**
+ * Test the Dutch Stem Filter, which only modifies the term text.
+ * 
+ * The code states that it uses the snowball algorithm, but tests reveal some differences.
+ * 
+ */
+public class TestDutchAnalyzer extends BaseTokenStreamTestCase {
+  
+  public void testWithSnowballExamples() throws Exception {
+   check("lichaamsziek", "lichaamsziek");
+   check("lichamelijk", "licham");
+   check("lichamelijke", "licham");
+   check("lichamelijkheden", "licham");
+   check("lichamen", "licham");
+   check("lichere", "licher");
+   check("licht", "licht");
+   check("lichtbeeld", "lichtbeeld");
+   check("lichtbruin", "lichtbruin");
+   check("lichtdoorlatende", "lichtdoorlat");
+   check("lichte", "licht");
+   check("lichten", "licht");
+   check("lichtende", "lichtend");
+   check("lichtenvoorde", "lichtenvoord");
+   check("lichter", "lichter");
+   check("lichtere", "lichter");
+   check("lichters", "lichter");
+   check("lichtgevoeligheid", "lichtgevoel");
+   check("lichtgewicht", "lichtgewicht");
+   check("lichtgrijs", "lichtgrijs");
+   check("lichthoeveelheid", "lichthoevel");
+   check("lichtintensiteit", "lichtintensiteit");
+   check("lichtje", "lichtj");
+   check("lichtjes", "lichtjes");
+   check("lichtkranten", "lichtkrant");
+   check("lichtkring", "lichtkring");
+   check("lichtkringen", "lichtkring");
+   check("lichtregelsystemen", "lichtregelsystem");
+   check("lichtste", "lichtst");
+   check("lichtstromende", "lichtstrom");
+   check("lichtte", "licht");
+   check("lichtten", "licht");
+   check("lichttoetreding", "lichttoetred");
+   check("lichtverontreinigde", "lichtverontreinigd");
+   check("lichtzinnige", "lichtzinn");
+   check("lid", "lid");
+   check("lidia", "lidia");
+   check("lidmaatschap", "lidmaatschap");
+   check("lidstaten", "lidstat");
+   check("lidvereniging", "lidveren");
+   check("opgingen", "opging");
+   check("opglanzing", "opglanz");
+   check("opglanzingen", "opglanz");
+   check("opglimlachten", "opglimlacht");
+   check("opglimpen", "opglimp");
+   check("opglimpende", "opglimp");
+   check("opglimping", "opglimp");
+   check("opglimpingen", "opglimp");
+   check("opgraven", "opgrav");
+   check("opgrijnzen", "opgrijnz");
+   check("opgrijzende", "opgrijz");
+   check("opgroeien", "opgroei");
+   check("opgroeiende", "opgroei");
+   check("opgroeiplaats", "opgroeiplat");
+   check("ophaal", "ophal");
+   check("ophaaldienst", "ophaaldienst");
+   check("ophaalkosten", "ophaalkost");
+   check("ophaalsystemen", "ophaalsystem");
+   check("ophaalt", "ophaalt");
+   check("ophaaltruck", "ophaaltruck");
+   check("ophalen", "ophal");
+   check("ophalend", "ophal");
+   check("ophalers", "ophaler");
+   check("ophef", "ophef");
+   check("opheldering", "ophelder");
+   check("ophemelde", "ophemeld");
+   check("ophemelen", "ophemel");
+   check("opheusden", "opheusd");
+   check("ophief", "ophief");
+   check("ophield", "ophield");
+   check("ophieven", "ophiev");
+   check("ophoepelt", "ophoepelt");
+   check("ophoog", "ophog");
+   check("ophoogzand", "ophoogzand");
+   check("ophopen", "ophop");
+   check("ophoping", "ophop");
+   check("ophouden", "ophoud");
+  }
+  
+  public void testSnowballCorrectness() throws Exception {
+    Analyzer a = new DutchAnalyzer();
+    checkOneTerm(a, "opheffen", "opheff");
+    checkOneTerm(a, "opheffende", "opheff");
+    checkOneTerm(a, "opheffing", "opheff");
+  }
+  
+  public void testReusableTokenStream() throws Exception {
+    Analyzer a = new DutchAnalyzer(); 
+    checkOneTerm(a, "lichaamsziek", "lichaamsziek");
+    checkOneTerm(a, "lichamelijk", "licham");
+    checkOneTerm(a, "lichamelijke", "licham");
+    checkOneTerm(a, "lichamelijkheden", "licham");
+  }
+  
+  public void testExclusionTableViaCtor() throws IOException {
+    CharArraySet set = new CharArraySet( 1, true);
+    set.add("lichamelijk");
+    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET, set);
+    assertAnalyzesTo(a, "lichamelijk lichamelijke", new String[] { "lichamelijk", "licham" });
+    
+    a = new DutchAnalyzer( CharArraySet.EMPTY_SET, set);
+    assertAnalyzesTo(a, "lichamelijk lichamelijke", new String[] { "lichamelijk", "licham" });
+
+  }
+  
+  /** 
+   * check that the default stem overrides are used
+   * even if you use a non-default ctor.
+   */
+  public void testStemOverrides() throws IOException {
+    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET);
+    checkOneTerm(a, "fiets", "fiets");
+  }
+  
+  public void testEmptyStemDictionary() throws IOException {
+    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET, 
+        CharArraySet.EMPTY_SET, CharArrayMap.<String>emptyMap());
+    checkOneTerm(a, "fiets", "fiet");
+  }
+  
+  /**
+   * Test that stopwords are not case sensitive
+   */
+  public void testStopwordsCasing() throws IOException {
+    DutchAnalyzer a = new DutchAnalyzer();
+    assertAnalyzesTo(a, "Zelf", new String[] { });
+  }
+  
+  private void check(final String input, final String expected) throws Exception {
+    checkOneTerm(new DutchAnalyzer(), input, expected); 
+  }
+  
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), new DutchAnalyzer(), 1000*RANDOM_MULTIPLIER);
+  }
+
+  public void testBackcompat40() throws IOException {
+    DutchAnalyzer a = new DutchAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
deleted file mode 100644
index 5df46af..0000000
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
+++ /dev/null
@@ -1,173 +0,0 @@
-package org.apache.lucene.analysis.nl;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.util.CharArrayMap;
-import org.apache.lucene.analysis.util.CharArraySet;
-
-/**
- * Test the Dutch Stem Filter, which only modifies the term text.
- * 
- * The code states that it uses the snowball algorithm, but tests reveal some differences.
- * 
- */
-public class TestDutchStemmer extends BaseTokenStreamTestCase {
-  
-  public void testWithSnowballExamples() throws Exception {
-   check("lichaamsziek", "lichaamsziek");
-   check("lichamelijk", "licham");
-   check("lichamelijke", "licham");
-   check("lichamelijkheden", "licham");
-   check("lichamen", "licham");
-   check("lichere", "licher");
-   check("licht", "licht");
-   check("lichtbeeld", "lichtbeeld");
-   check("lichtbruin", "lichtbruin");
-   check("lichtdoorlatende", "lichtdoorlat");
-   check("lichte", "licht");
-   check("lichten", "licht");
-   check("lichtende", "lichtend");
-   check("lichtenvoorde", "lichtenvoord");
-   check("lichter", "lichter");
-   check("lichtere", "lichter");
-   check("lichters", "lichter");
-   check("lichtgevoeligheid", "lichtgevoel");
-   check("lichtgewicht", "lichtgewicht");
-   check("lichtgrijs", "lichtgrijs");
-   check("lichthoeveelheid", "lichthoevel");
-   check("lichtintensiteit", "lichtintensiteit");
-   check("lichtje", "lichtj");
-   check("lichtjes", "lichtjes");
-   check("lichtkranten", "lichtkrant");
-   check("lichtkring", "lichtkring");
-   check("lichtkringen", "lichtkring");
-   check("lichtregelsystemen", "lichtregelsystem");
-   check("lichtste", "lichtst");
-   check("lichtstromende", "lichtstrom");
-   check("lichtte", "licht");
-   check("lichtten", "licht");
-   check("lichttoetreding", "lichttoetred");
-   check("lichtverontreinigde", "lichtverontreinigd");
-   check("lichtzinnige", "lichtzinn");
-   check("lid", "lid");
-   check("lidia", "lidia");
-   check("lidmaatschap", "lidmaatschap");
-   check("lidstaten", "lidstat");
-   check("lidvereniging", "lidveren");
-   check("opgingen", "opging");
-   check("opglanzing", "opglanz");
-   check("opglanzingen", "opglanz");
-   check("opglimlachten", "opglimlacht");
-   check("opglimpen", "opglimp");
-   check("opglimpende", "opglimp");
-   check("opglimping", "opglimp");
-   check("opglimpingen", "opglimp");
-   check("opgraven", "opgrav");
-   check("opgrijnzen", "opgrijnz");
-   check("opgrijzende", "opgrijz");
-   check("opgroeien", "opgroei");
-   check("opgroeiende", "opgroei");
-   check("opgroeiplaats", "opgroeiplat");
-   check("ophaal", "ophal");
-   check("ophaaldienst", "ophaaldienst");
-   check("ophaalkosten", "ophaalkost");
-   check("ophaalsystemen", "ophaalsystem");
-   check("ophaalt", "ophaalt");
-   check("ophaaltruck", "ophaaltruck");
-   check("ophalen", "ophal");
-   check("ophalend", "ophal");
-   check("ophalers", "ophaler");
-   check("ophef", "ophef");
-   check("opheldering", "ophelder");
-   check("ophemelde", "ophemeld");
-   check("ophemelen", "ophemel");
-   check("opheusden", "opheusd");
-   check("ophief", "ophief");
-   check("ophield", "ophield");
-   check("ophieven", "ophiev");
-   check("ophoepelt", "ophoepelt");
-   check("ophoog", "ophog");
-   check("ophoogzand", "ophoogzand");
-   check("ophopen", "ophop");
-   check("ophoping", "ophop");
-   check("ophouden", "ophoud");
-  }
-  
-  public void testSnowballCorrectness() throws Exception {
-    Analyzer a = new DutchAnalyzer();
-    checkOneTerm(a, "opheffen", "opheff");
-    checkOneTerm(a, "opheffende", "opheff");
-    checkOneTerm(a, "opheffing", "opheff");
-  }
-  
-  public void testReusableTokenStream() throws Exception {
-    Analyzer a = new DutchAnalyzer(); 
-    checkOneTerm(a, "lichaamsziek", "lichaamsziek");
-    checkOneTerm(a, "lichamelijk", "licham");
-    checkOneTerm(a, "lichamelijke", "licham");
-    checkOneTerm(a, "lichamelijkheden", "licham");
-  }
-  
-  public void testExclusionTableViaCtor() throws IOException {
-    CharArraySet set = new CharArraySet( 1, true);
-    set.add("lichamelijk");
-    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET, set);
-    assertAnalyzesTo(a, "lichamelijk lichamelijke", new String[] { "lichamelijk", "licham" });
-    
-    a = new DutchAnalyzer( CharArraySet.EMPTY_SET, set);
-    assertAnalyzesTo(a, "lichamelijk lichamelijke", new String[] { "lichamelijk", "licham" });
-
-  }
-  
-  /** 
-   * check that the default stem overrides are used
-   * even if you use a non-default ctor.
-   */
-  public void testStemOverrides() throws IOException {
-    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET);
-    checkOneTerm(a, "fiets", "fiets");
-  }
-  
-  public void testEmptyStemDictionary() throws IOException {
-    DutchAnalyzer a = new DutchAnalyzer( CharArraySet.EMPTY_SET, 
-        CharArraySet.EMPTY_SET, CharArrayMap.<String>emptyMap());
-    checkOneTerm(a, "fiets", "fiet");
-  }
-  
-  /**
-   * Test that stopwords are not case sensitive
-   */
-  public void testStopwordsCasing() throws IOException {
-    DutchAnalyzer a = new DutchAnalyzer();
-    assertAnalyzesTo(a, "Zelf", new String[] { });
-  }
-  
-  private void check(final String input, final String expected) throws Exception {
-    checkOneTerm(new DutchAnalyzer(), input, expected); 
-  }
-  
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), new DutchAnalyzer(), 1000*RANDOM_MULTIPLIER);
-  }
-  
-}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianAnalyzer.java
index f3900f8..da9d999 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestNorwegianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestNorwegianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new NorwegianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    NorwegianAnalyzer a = new NorwegianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
index 4c5cce5..567b6d7 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestPortugueseAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestPortugueseAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new PortugueseAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    PortugueseAnalyzer a = new PortugueseAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ro/TestRomanianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ro/TestRomanianAnalyzer.java
index 7af6324..9bee768 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ro/TestRomanianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ro/TestRomanianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestRomanianAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestRomanianAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new RomanianAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    RomanianAnalyzer a = new RomanianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
index 35dd3ef..16a3531 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test case for RussianAnalyzer.
@@ -30,32 +31,38 @@ import org.apache.lucene.analysis.util.CharArraySet;
 public class TestRussianAnalyzer extends BaseTokenStreamTestCase {
 
      /** Check that RussianAnalyzer doesnt discard any numbers */
-    public void testDigitsInRussianCharset() throws IOException
-    {
-      RussianAnalyzer ra = new RussianAnalyzer();
-      assertAnalyzesTo(ra, "text 1000", new String[] { "text", "1000" });
-    }
+  public void testDigitsInRussianCharset() throws IOException
+  {
+    RussianAnalyzer ra = new RussianAnalyzer();
+    assertAnalyzesTo(ra, "text 1000", new String[] { "text", "1000" });
+  }
     
-    public void testReusableTokenStream() throws Exception {
-      Analyzer a = new RussianAnalyzer();
-      assertAnalyzesTo(a, "Вместе с тем о силе электромагнитной энергии имели представление еще",
-          new String[] { "вмест", "сил", "электромагнитн", "энерг", "имел", "представлен" });
-      assertAnalyzesTo(a, "Но знание это хранилось в тайне",
-          new String[] { "знан", "эт", "хран", "тайн" });
-    }
+  public void testReusableTokenStream() throws Exception {
+    Analyzer a = new RussianAnalyzer();
+    assertAnalyzesTo(a, "Вместе с тем о силе электромагнитной энергии имели представление еще",
+        new String[] { "вмест", "сил", "электромагнитн", "энерг", "имел", "представлен" });
+    assertAnalyzesTo(a, "Но знание это хранилось в тайне",
+        new String[] { "знан", "эт", "хран", "тайн" });
+  }
     
     
-    public void testWithStemExclusionSet() throws Exception {
-      CharArraySet set = new CharArraySet( 1, true);
-      set.add("представление");
-      Analyzer a = new RussianAnalyzer( RussianAnalyzer.getDefaultStopSet() , set);
-      assertAnalyzesTo(a, "Вместе с тем о силе электромагнитной энергии имели представление еще",
-          new String[] { "вмест", "сил", "электромагнитн", "энерг", "имел", "представление" });
-     
-    }
+  public void testWithStemExclusionSet() throws Exception {
+    CharArraySet set = new CharArraySet( 1, true);
+    set.add("представление");
+    Analyzer a = new RussianAnalyzer( RussianAnalyzer.getDefaultStopSet() , set);
+    assertAnalyzesTo(a, "Вместе с тем о силе электромагнитной энергии имели представление еще",
+        new String[] { "вмест", "сил", "электромагнитн", "энерг", "имел", "представление" });
+  }
     
-    /** blast some random strings through the analyzer */
-    public void testRandomStrings() throws Exception {
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
       checkRandomData(random(), new RussianAnalyzer(), 1000*RANDOM_MULTIPLIER);
     }
+
+  public void testBackcompat40() throws IOException {
+    RussianAnalyzer a = new RussianAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPage.html lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPage.html
new file mode 100644
index 0000000..cc23b3d
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPage.html
@@ -0,0 +1,267 @@
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
+<meta name="robots" content="index,nofollow">
+
+<title>Resources - Lucene-java Wiki</title>
+<script type="text/javascript" src="/moin_static184/common/js/common.js"></script>
+
+<script type="text/javascript">
+<!--
+var search_hint = "Search";
+//-->
+</script>
+
+
+<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/moin_static184/modernized/css/common.css">
+<link rel="stylesheet" type="text/css" charset="utf-8" media="screen" href="/moin_static184/modernized/css/screen.css">
+<link rel="stylesheet" type="text/css" charset="utf-8" media="print" href="/moin_static184/modernized/css/print.css">
+<link rel="stylesheet" type="text/css" charset="utf-8" media="projection" href="/moin_static184/modernized/css/projection.css">
+
+<!-- css only for MS IE6/IE7 browsers -->
+<!--[if lt IE 8]>
+   <link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/moin_static184/modernized/css/msie.css">
+<![endif]-->
+
+
+
+
+
+<link rel="Start" href="/lucene-java/FrontPageEN">
+<link rel="Alternate" title="Wiki Markup" href="/lucene-java/Resources?action=raw">
+<link rel="Alternate" media="print" title="Print View" href="/lucene-java/Resources?action=print">
+<link rel="Appendix" title="IntroductionToApacheLucene.jp.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=IntroductionToApacheLucene.jp.jpg">
+<link rel="Appendix" title="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=SuchmaschinenEntwickelnMitApacheLucene.de.jpg">
+<link rel="Appendix" title="building.search.applications.png" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=building.search.applications.png">
+<link rel="Appendix" title="lia3d.jpg" href="/lucene-java/Resources?action=AttachFile&amp;do=view&amp;target=lia3d.jpg">
+<link rel="Search" href="/lucene-java/FindPage">
+<link rel="Index" href="/lucene-java/TitleIndex">
+<link rel="Glossary" href="/lucene-java/WordIndex">
+<link rel="Help" href="/lucene-java/HelpOnFormatting">
+</head>
+
+<body  lang="en" dir="ltr">
+
+<div id="header">
+
+<form id="searchform" method="get" action="/lucene-java/Resources">
+<div>
+<input type="hidden" name="action" value="fullsearch">
+<input type="hidden" name="context" value="180">
+<label for="searchinput">Search:</label>
+<input id="searchinput" type="text" name="value" value="" size="20"
+    onfocus="searchFocus(this)" onblur="searchBlur(this)"
+    onkeyup="searchChange(this)" onchange="searchChange(this)" alt="Search">
+<input id="titlesearch" name="titlesearch" type="submit"
+    value="Titles" alt="Search Titles">
+<input id="fullsearch" name="fullsearch" type="submit"
+    value="Text" alt="Search Full Text">
+</div>
+</form>
+<script type="text/javascript">
+<!--// Initialize search form
+var f = document.getElementById('searchform');
+f.getElementsByTagName('label')[0].style.display = 'none';
+var e = document.getElementById('searchinput');
+searchChange(e);
+searchBlur(e);
+//-->
+</script>
+
+<div id="logo"><a href="/lucene-java/FrontPageEN">Lucene-java Wiki</a></div>
+<div id="username"><a href="/lucene-java/Resources?action=login" id="login" rel="nofollow">Login</a></div>
+<h1 id="locationline">
+
+<span id="pagelocation"><a class="backlink" href="/lucene-java/Resources?action=fullsearch&amp;context=180&amp;value=linkto%3A%22Resources%22" rel="nofollow" title="Click to do a full-text search for this title">Resources</a></span>
+</h1>
+
+
+<ul id="navibar">
+<li class="wikilink"><a href="/lucene-java/FrontPageEN">FrontPageEN</a></li><li class="wikilink"><a href="/lucene-java/RecentChanges">RecentChanges</a></li><li class="wikilink"><a href="/lucene-java/FindPage">FindPage</a></li><li class="wikilink"><a href="/lucene-java/HelpContents">HelpContents</a></li><li class="current"><a href="/lucene-java/Resources">Resources</a></li>
+</ul>
+
+<div id="pageline"><hr style="display:none;"></div>
+
+<ul class="editbar"><li><span class="disabled">Immutable Page</span></li><li class="toggleCommentsButton" style="display:none;"><a href="#" class="nbcomment" onClick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="/lucene-java/Resources?action=info" rel="nofollow">Info</a></li><li>
+<form class="actionsmenu" method="GET" action="/lucene-java/Resources">
+<div>
+    <label>More Actions:</label>
+    <select name="action"
+        onchange="if ((this.selectedIndex != 0) &&
+                      (this.options[this.selectedIndex].disabled == false)) {
+                this.form.submit();
+            }
+            this.selectedIndex = 0;">
+        <option value="raw">Raw Text</option>
+<option value="print">Print View</option>
+<option value="RenderAsDocbook">Render as Docbook</option>
+<option value="refresh">Delete Cache</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="SpellCheck">Check Spelling</option>
+<option value="LikePages">Like Pages</option>
+<option value="LocalSiteMap">Local Site Map</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="RenamePage" disabled class="disabled">Rename Page</option>
+<option value="CopyPage">Copy Page</option>
+<option value="DeletePage" disabled class="disabled">Delete Page</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="MyPages">My Pages</option>
+<option value="show" disabled class="disabled">Subscribe User</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="show" disabled class="disabled">Remove Spam</option>
+<option value="show" disabled class="disabled">Revert to this revision</option>
+<option value="show" disabled class="disabled">Package Pages</option>
+<option value="SyncPages">Sync Pages</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="Load">Load</option>
+<option value="Save">Save</option>
+    </select>
+    <input type="submit" value="Do">
+    
+</div>
+<script type="text/javascript">
+<!--// Init menu
+actionsMenuInit('More Actions:');
+//-->
+</script>
+</form>
+</li></ul>
+
+</div>
+
+<div id="page" lang="en" dir="ltr">
+<div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
+<span class="anchor" id="line-2"></span><p class="line867"><div class="table-of-contents"><p class="table-of-contents-heading">Contents<ol><li>
+<a href="#Introductions">Introductions</a></li><li>
+<a href="#Blogs">Blogs</a></li><li>
+<a href="#Books">Books</a></li><li>
+<a href="#Articles">Articles</a></li><li>
+<a href="#Interviews">Interviews</a></li><li>
+<a href="#Papers">Papers</a></li><li>
+<a href="#Presentations">Presentations</a></li><li>
+<a href="#Training">Training</a></li><li>
+<a href="#Corpora">Corpora</a></li><li>
+<a href="#Other">Other</a></li></ol></div> <span class="anchor" id="line-3"></span><span class="anchor" id="line-4"></span><p class="line867">
+<h1 id="Introductions">Introductions</h1>
+<span class="anchor" id="line-5"></span><span class="anchor" id="line-6"></span><ul><li><p class="line862">The API documentation contains  <a class="http" href="http://lucene.apache.org/java/3_0_1/api/all/overview-summary.html#overview_description">a short and simple code example</a> that shows the basic way to index and search <span class="anchor" id="line-7"></span></li><li><p class="line862">The <a class="http" href="http://lucene.apache.org/java/3_0_1/gettingstarted.html">Getting Started Guide</a> that describes the demos that come with Lucene <span class="anchor" id="line-8"></span><span class="anchor" id="line-9"></span><span class="anchor" id="line-10"></span></li></ul><p class="line867">
+<h1 id="Blogs">Blogs</h1>
+<span class="anchor" id="line-11"></span><span class="anchor" id="line-12"></span><ul><li><p class="line891"><a class="http" href="http://lucene.grantingersoll.com">Grant's Grunts: Lucene edition</a> - Grant Ingersoll's thoughts on the Lucene ecosystem. <span class="anchor" id="line-13"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/blog/">Lucid Imagination's Blog</a> - Many of the Lucene and Solr committers blog here about how to use Lucene and Solr <span class="anchor" id="line-14"></span></li><li><p class="line891"><a class="http" href="http://blog.sematext.com/">Sematext Blog</a> - Search and Analytics covering Lucene, Solr, Nutch, Hadoop, HBase, and more <span class="anchor" id="line-15"></span><span class="anchor" id="line-16"></span><span class="anchor" id="line-17"></span></li></ul><p class="line867">
+<h1 id="Books">Books</h1>
+<span class="anchor" id="line-18"></span><span class="anchor" id="line-19"></span><ul><li><p class="line891"><img alt="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" class="external_image" src="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" title="http://www.manning.com/hatcher3/hatcher3_cover150.jpg" /> "<a class="http" href="http://www.manning.com/hatcher3/">Lucene in Action, Second Edition"</a> by Erik Hatcher, Otis Gospodneti&#263;, and Michael McCandless <span class="anchor" id="line-20"></span></li><li><p class="line891"><img alt="building.search.applications.png" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=building.search.applications.png" title="building.search.applications.png" /> "<a class="http" href="http://www.amazon.com/Building-Search-Applications-Lucene-Lingpipe/dp/0615204252/">Building Search Applications: Lucene, LingPipe, and Gate</a>" by Manu Konchady; Mustru Publishing; June 2008; ISBN 978-0615204253 <span class="anchor" id="line-21"></span></li><li><p class="line891"><img alt="IntroductionToApacheLucene.jp.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=IntroductionToApacheLucene.jp.jpg" title="IntroductionToApacheLucene.jp.jpg" /> "<a class="http" href="http://www.amazon.co.jp/exec/obidos/ASIN/4774127809/503-9461699-1775907">Apache Lucene 入門 ~Java・オープンソース・全文検索システムの構築</a>" 関口 宏司 ; 技術評論社 ; 2006/05/17 ; ISBN: 4774127809 (<span class="u">Introduction to Apache Lucene: Construction of Java Open Source Full Text Retrieval Systems</span> by Koshi Sekiguti ; Gijutsu-Hyohron Co., Ltd.) <span class="anchor" id="line-22"></span></li><li><p class="line891"><img alt="lia3d.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=lia3d.jpg" title="lia3d.jpg" /> "<a class="http" href="http://www.lucenebook.com">Lucene In Action</a>" by Erik Hatcher, Otis Gospodneti&#263;; Manning Publications; December 2004; ISBN 1932394281 (also available from <a class="http" href="http://www.amazon.com/exec/obidos/ASIN/1932394281">Amazon.com</a>) <span class="anchor" id="line-23"></span></li><li><p class="line891"><img alt="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" class="attachment" src="/lucene-java/Resources?action=AttachFile&amp;do=get&amp;target=SuchmaschinenEntwickelnMitApacheLucene.de.jpg" title="SuchmaschinenEntwickelnMitApacheLucene.de.jpg" /> Manfred Hardt, Dr. Fabian Theis: "<a class="http" href="http://www.amazon.de/Suchmaschinen-entwickeln-mit-Apache-Lucene/dp/3935042450">Suchmaschinen entwickeln mit Apache Lucene</a>"; Software &amp; Support Verlag, Frankfurt/Main, Germany; September 2004; ISBN 3935042450 (<span class="u">Developing Search Engines with Apache Lucene</span>) <span class="anchor" id="line-24"></span><span class="anchor" id="line-25"></span></li></ul><p class="line867">
+<h1 id="Articles">Articles</h1>
+<span class="anchor" id="line-26"></span><span class="anchor" id="line-27"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Getting-Started-with-Lucene/">Getting Started with Lucene</a> (by Grant Ingersoll) <br>
+ (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-28"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Optimizing-Findability-in-Lucene-and-Solr/">Optimizing Findability in Lucene and Solr</a> (by  Grant Ingersoll)<br>
+ (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-29"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Debugging-Relevance-Issues-in-Search/">Debugging Relevance Issues in Search</a> (by Grant Ingersoll)<br>
+ (<em>Published: January 2009 - article</em>) <span class="anchor" id="line-30"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Scaling-Lucene-and-Solr/">Scaling Lucene and Solr</a> (by Mark Miller)<br>
+ (<em>Published: January 2009 - article</em>)  <span class="anchor" id="line-31"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Introduction-to-Apache-Lucene-and-Solr/">Introduction to Apache Lucene and Solr</a> (by Marc Krellenstein)<br>
+(<em>Published: January 2009 - article</em>)  <span class="anchor" id="line-32"></span></li><li><p class="line891"><a class="http" href="http://cephas.net/blog/2008/03/30/how-morelikethis-works-in-lucene/">How MoreLikeThis Works in Lucene</a> (by Aaron Johnson)<br>
+(<em>Last updated: March 2008 - blog entry</em>) <span class="anchor" id="line-33"></span></li><li><p class="line891"><a class="http" href="http://schmidt.devlib.org/software/lucene-wikipedia.html">Lucene Wikipedia indexer</a> (by Marco Schmidt)<br>
+(<em>Last updated: November 2007 - tutorial</em>) <span class="anchor" id="line-34"></span></li><li><p class="line891"><a class="http" href="http://marceloochoa.blogspot.com/2007/09/running-lucene-inside-your-oracle-jvm.html">Running Lucene inside your Oracle JVM</a> (by Marcelo Ochoa)<br>
+(<em>Last updated: September 2007 - blog entry</em>) <span class="anchor" id="line-35"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2007/05/24/using-the-lucene-query-parser-without-lucene.html">Using the Lucene Query Parser Without Lucene</a> (by Marcin Maciukiewicz and Daniel Owsiański)<br>
+(<em>Published: May 2007 - article</em>) <span class="anchor" id="line-36"></span></li><li><p class="line891"><a class="http" href="http://www.javaworld.com/javaworld/jw-09-2006/jw-0925-lucene.html">Integrate advanced search functionalities into your apps</a> (by John Ferguson Smart)<br>
+(<em>Published: September 2006 - article</em>) <span class="anchor" id="line-37"></span></li><li><p class="line891"><a class="http" href="http://www-128.ibm.com/developerworks/java/library/wa-lucene2/index.html?ca=drs-">Beef up Web search applications with Lucene</a> (by Deng Peng Zhou)<br>
+(<em>Published: August 2006 - article</em>) <span class="anchor" id="line-38"></span></li><li><p class="line891"><a class="http" href="http://www.freesearch.pe.kr/tag/Lucene">Lecture &amp; Etc : Lucene index file format for Korean</a> (by Jeon Hee-Won)<br>
+(<em>Published: July 2006 - article</em>) <span class="anchor" id="line-39"></span></li><li>Cai Ziegler: "Suche nach Suche -- Apaches Lucene: eigene Suche und Indizierung"; iX 6/2006, Seite 120; Heise Zeitschriften Verlag, Hannover, Germany <span class="anchor" id="line-40"></span></li><li><p class="line891"><a class="http" href="http://www-128.ibm.com/developerworks/java/library/wa-lucene/index.html">Delve inside the Lucene indexing mechanism</a> (by Deng Peng Zhou)<br>
+(<em>Published: June 2006 - article</em>) <span class="anchor" id="line-41"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2006/01/18/using-lucene-to-search-java-source.html">Using Lucene to Search Java Source Code</a> (by Renuka Sindhgatta)<br>
+(<em>Published: January 2006 - article</em>) <span class="anchor" id="line-42"></span></li><li><p class="line891"><a class="http" href="http://www.jroller.com/page/wakaleo/?anchor=lucene_a_tutorial_introduction_to">Lucene : a tutorial introduction to full-text indexing in Java</a> (by John Ferguson Smart)<br>
+(<em>Published: October 2005 - article</em>) <span class="anchor" id="line-43"></span></li><li>Daniel Naber: "Herr der Suche -- Eigene Anwendungen mit Volltextsuche erweitern"; c't 7/2005, Seite 196; Heise Zeitschriften Verlag, Hannover, Germany <span class="anchor" id="line-44"></span></li><li><p class="line891"><a class="http" href="http://blog.dev.sf.net/index.php?/archives/10-Behind-the-Scenes-of-the-SourceForge.net-Search-System.html">Behind the Scenes of the SourceForge.net Search System</a> (by Chris Conrad)<br>
+(<em>Last updated: June 2005 - blog entry</em>) <span class="anchor" id="line-45"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2005/08/09/didyoumean.html">Did You Mean: Lucene?</a> (by Tom White)<br>
+(<em>Published: August 2005 - article</em>) <span class="anchor" id="line-46"></span></li><li><p class="line891"><a class="http" href="http://www.developer.com/java/other/article.php/3490471">Meet Lucene</a> (by Otis Gospodneti&#263;, Eric Hatcher)<br>
+(<em>Published: March 2005 - article</em>) <span class="anchor" id="line-47"></span></li><li><p class="line891"><a class="http" href="http://www.theserverside.com/tt/articles/article.tss?l=ILoveLucene">I Love Lucene</a> (by Dion Almaer)<br>
+(<em>Published: January 2005 - article</em>) <span class="anchor" id="line-48"></span></li><li><p class="line891"><a class="http" href="http://javaboutique.internet.com/tutorials/HTMLParser/article.html">Unweaving a Tangled Web With HTMLParser and Lucene</a> (by Keld H. Hansen)<br>
+(<em>Last updated: October 2004 - tutorial</em>) <span class="anchor" id="line-49"></span></li><li><p class="line891"><a class="http" href="http://bilgidata.com/localhost/bilgidata/yazi.jsp@dosya=a_lucene.xml.html">Lucene Introduction in Turkish</a> Java Bazl&#305; Arama Motoru - Lusin (by Burak Bayraml&#305;)<br>
+(<em>Last updated: August 2004 - tutorial</em>) <span class="anchor" id="line-50"></span></li><li><p class="line891"><a class="http" href="http://www.chedong.com/tech/lucene.html">Lucene Introduction in Chinese</a> Lucene&#65306;&#22522;&#20110;Java&#30340;&#20840;&#25991;&#26816;&#32034;&#24341;&#25806;&#31616;&#20171; (by Che Dong; &#20316;&#32773;&#65306; &#36710;&#19996;)<br>
+(<em>Last updated: May 2004 - tutorial</em>) <span class="anchor" id="line-51"></span></li><li><p class="line891"><a class="http" href="http://javatechniques.com/public/java/docs/basics/lucene-memory-search.html">Lucene In-Memory Text Search</a> (by Philip Isenhour)<br>
+(<em>Last updated: May 2004 - tutorial</em>) <span class="anchor" id="line-52"></span></li><li><p class="line891"><a class="http" href="http://www.javaranch.com/newsletter/200404/Lucene.html">The Lucene Search Engine: Adding Search to Your Applications</a> (by Thomas Paul)<br>
+(<em>Published: April 2004 - article</em>) <span class="anchor" id="line-53"></span></li><li><p class="line891"><a class="http" href="http://www.darksleep.com/lucene/">Lucene Tutorial</a> (by Steven J. Owens)<br>
+(<em>Last updated: March 2004 - tutorial</em>) <span class="anchor" id="line-54"></span></li><li><p class="line891"><a class="http" href="http://www-igm.univ-mlv.fr/~dr/XPOSE2003/lucene/articleLucene.html">Lucene Introduction in French</a> Exposés Système sur le thème de l'opensource : Analyse de la structure de Lucene. (by Sun Seng TAN)<br>
+(<em>Last updated: February 2004 - tutorial</em>) <span class="anchor" id="line-55"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html">QueryParser Rules</a> (by Erik Hatcher)<br>
+(<em>Published November 2003 - article</em>) <span class="anchor" id="line-56"></span></li><li><p class="line891"><a class="http" href="http://builder.com.com/5100-6389-5054799.html">Give your Web site its own search engine using Lucene</a> (by Jeffrey Linwood)<br>
+(<em>Published July 2003 - article</em>) <span class="anchor" id="line-57"></span></li><li><p class="line891"><a class="http" href="http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html">Lucene Intro</a> (by Erik Hatcher)<br>
+(<em>Published: July 2003 - article</em>) <span class="anchor" id="line-58"></span></li><li><p class="line891"><a class="http" href="http://www-106.ibm.com/developerworks/library/j-lucene/">Parsing, indexing, and searching XML with Digester and Lucene</a> (by Otis Gospodneti&#263;)<br>
+(<em>Published June 2003 - article</em>) <span class="anchor" id="line-59"></span></li><li><p class="line891"><a class="http" href="http://www.xml.com/pub/a/ws/2003/05/13/email.html">Using Python, Jython, and Lucene to Search Outlook Email</a> (by Jon Udell)<br>
+(<em>Published: May 2003 - article</em>) <span class="anchor" id="line-60"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2003/03/05/lucene.html">Advanced Text Indexing with Lucene</a> (by Otis Gospodneti&#263;)<br>
+(<em>Published: March 2003 - article</em>) <span class="anchor" id="line-61"></span></li><li><p class="line891"><a class="http" href="http://www.onjava.com/pub/a/onjava/2003/01/15/lucene.html">Introduction to Text Indexing with Apache Jakarta Lucene</a> (by Otis Gospodneti&#263;)<br>
+(<em>Published: January 2003 - article</em>) <span class="anchor" id="line-62"></span></li><li><p class="line862">Manfred Hardt: "Suchmaschinen entwickeln mit Java und Lucene - Wo war denn noch gleich ... ?"; JavaMagazin 9/2002; Software &amp; Support Verlag, Frankfurt/Main, Germany <span class="anchor" id="line-63"></span></li><li><p class="line891"><a class="http" href="http://javangelist.snipsnap.org/space/Lucene-Mini-Tutorial">Lucene Mini-Tutorial</a> (by funzel)<br>
+(<em>Last updated: April 2002 - tutorial</em>) <span class="anchor" id="line-64"></span></li><li><p class="line891"><a class="http" href="http://www.javaworld.com/javaworld/jw-09-2000/jw-0915-lucene.html">The Lucene search engine Powerful flexible and free</a> (by Brian Goetz)<br>
+(<em>Published September 2000 - article</em>) <span class="anchor" id="line-65"></span><span class="anchor" id="line-66"></span></li></ul><p class="line867">
+<h1 id="Interviews">Interviews</h1>
+<span class="anchor" id="line-67"></span><span class="anchor" id="line-68"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=109">Interview with Lucene creator Doug Cutting</a> Podcast.  Summary: Doug talks about the creation of Lucene, Nutch and Hadoop. (<em>Published January 2009</em>) <span class="anchor" id="line-69"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=108">Interview with Lucene/Solr committer Chris Hostetter</a> Podcast.  Summary: Chris talks about Solr, Lucene and their usage at CNET. (<em>Published January 2009</em>) <span class="anchor" id="line-70"></span></li><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=113">Interview with Lucene/Solr committer Ryan McKinley</a> Podcast.  Summary: Ryan discusses Solr, Lucene and geospatial searching with Lucene (<a class="nonexistent" href="/lucene-java/LocalLucene/LocalSolr">LocalLucene/LocalSolr</a>) and his usage of Lucene/Solr throughout his career. (<em>Published January 2009</em>) <span class="anchor" id="line-71"></span><span class="anchor" id="line-72"></span><span class="anchor" id="line-73"></span><span class="anchor" id="line-74"></span></li></ul><p class="line867">
+<h1 id="Papers">Papers</h1>
+<span class="anchor" id="line-75"></span><span class="anchor" id="line-76"></span><ul><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/publications.html">http://lucene.sourceforge.net/publications.html</a> Doug Cuttings papers from the old Lucene web site <span class="anchor" id="line-77"></span><span class="anchor" id="line-78"></span></li></ul><p class="line867">
+<h1 id="Presentations">Presentations</h1>
+<span class="anchor" id="line-79"></span><ul><li><p class="line891"><a class="http" href="http://people.apache.org/~buschmi/apachecon/AdvancedIndexingLuceneAtlanta07.ppt">Advanced Indexing Techniques with Apache Lucene - Payloads</a> presented by Michael Busch at <a class="http" href="http://www.us.apachecon.com/us2007/">ApacheCon U.S. 2007</a><br>
+(<em>Presented November 2007 - PDF slide show</em>) <span class="anchor" id="line-80"></span></li><li><p class="line891"><a class="http" href="http://people.apache.org/~yonik/presentations/lucene_intro.pdf">Full-Text Search with Lucene</a> presented by Yonik Seeley at <a class="http" href="http://www.eu.apachecon.com">ApacheCon Europe 2007</a>.<br>
+(<em>Presented May 2007 - PDF slide show</em>) <span class="anchor" id="line-81"></span></li><li><p class="line891"><a class="http" href="http://www.cnlp.org/presentations/slides/AdvancedLuceneEU.pdf">Advanced Lucene</a> presented by Grant Ingersoll of <a class="http" href="http://www.cnlp.org">CNLP</a> at <a class="http" href="http://www.eu.apachecon.com">ApacheCon Europe 2007</a>.  Covers term vectors, query tips and tricks and Lucene performance tuning related to indexing, searching and document retrieval.<br>
+(<em>Presented May 2007 - PDF slide show</em>) <span class="anchor" id="line-82"></span></li><li><p class="line891"><a class="http" href="http://blogs.atlassian.com/rebelutionary/downloads/tssjs2007-lucene-generic-data-indexing.pdf">Lucene: Generic Data Indexing</a> presented by Mike Cannon-Brookes, CEO, <a class="http" href="http://www.atlassian.com/">Atlassian Software Systems</a> at <a class="http" href="http://javasymposium.techtarget.com/lasvegas/index.html">TSSJS Las Vegas 2007</a>.  Covers how Atlassian use Lucene as a generic indexing framework for indexing and finding arbitrary collections of complex objects.<br>
+(<em>Presented March 2007 - PDF slide show</em>) <span class="anchor" id="line-83"></span></li><li><p class="line891"><a class="http" href="http://www.cnlp.org/apachecon2005/AdvancedLucene.ppt">Advanced Lucene</a> presented by Grant Ingersoll of the <a class="http" href="http://www.cnlp.org">Center for Natural Language Processing</a> at <a class="http" href="http://www.apachecon.com">ApacheCon 2005</a>.  Covers term vectors, span queries, using Lucene in a basic question answering system, and several Lucene case studies from <a class="http" href="http://www.cnlp.org">http://www.cnlp.org</a>.  The accompanying <a class="http" href="http://www.cnlp.org/apachecon2005">CNLP ApacheCon 2005 Information website</a> contains many working examples using term vectors and span queries. <span class="anchor" id="line-84"></span></li><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/talks/pisa/">Lucene lecture at The University of Pisa</a> (by Doug Cutting)<br>
+(<em>Presented November 2004 - lecture notes</em>) <span class="anchor" id="line-85"></span></li><li><p class="line891"><a class="http" href="http://conferences.oreillynet.com/presentations/os2003/hatcher_erik_lucene.pdf">Introducing Lucene</a> (by Erik Hatcher)<br>
+(<em>Presented at OS2003, July 2003 - PDF slide show</em>) <span class="anchor" id="line-86"></span></li><li><p class="line891"><a class="http" href="http://lucene.sourceforge.net/talks/inktomi/">The Lucene Search Engine: Inktomi Seminar</a> (by Doug Cutting)<br>
+(<em>Presented June, 2000 - seminar notes</em>) <span class="anchor" id="line-87"></span><span class="anchor" id="line-88"></span></li></ul><p class="line867">
+<h1 id="Training">Training</h1>
+<span class="anchor" id="line-89"></span><span class="anchor" id="line-90"></span><ul><li><p class="line891"><a class="http" href="http://www.lucidimagination.com/How-We-Can-Help/Training/">http://www.lucidimagination.com/How-We-Can-Help/Training/</a> - Training on Lucene created by Lucene committers and contributors (Grant Ingersoll, Erik Hatcher and the rest of the team at Lucid Imagination).   <span class="anchor" id="line-91"></span></li><li><p class="line891"><a class="http" href="http://www.lucenebootcamp.com">Lucene Boot Camp</a> - Training by Lucene committer Grant Ingersoll.  Offered exclusively at <a class="http" href="http://www.apachecon.com">ApacheCon</a>. <span class="anchor" id="line-92"></span><span class="anchor" id="line-93"></span></li></ul><p class="line867">
+<h1 id="Corpora">Corpora</h1>
+<span class="anchor" id="line-94"></span><ul><li><p class="line862">DMOZ RDF dump - <a class="http" href="http://rdf.dmoz.org/">http://rdf.dmoz.org/</a> <span class="anchor" id="line-95"></span></li><li><p class="line862">CMU newsgroups  - <a class="http" href="http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html">http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html</a> <span class="anchor" id="line-96"></span></li><li><p class="line862">CMU webpages  - <a class="http" href="http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/">http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/</a> <span class="anchor" id="line-97"></span></li><li><p class="line862">Reuters  - <a class="http" href="http://www.daviddlewis.com/resources/testcollections/reuters21578">http://www.daviddlewis.com/resources/testcollections/reuters21578</a> <span class="anchor" id="line-98"></span></li><li><p class="line862">Enron emails - <a class="http" href="http://www-2.cs.cmu.edu/~enron/">http://www-2.cs.cmu.edu/~enron/</a> <span class="anchor" id="line-99"></span></li><li><p class="line862">JRC-ACQUIS Multilingual Parallel Corpus - <a class="http" href="http://wt.jrc.it/lt/Acquis/">http://wt.jrc.it/lt/Acquis/</a> <span class="anchor" id="line-100"></span><span class="anchor" id="line-101"></span></li></ul><p class="line867">
+<h1 id="Other">Other</h1>
+<span class="anchor" id="line-102"></span><ul><li><p class="line891"><a class="http" href="http://www.java201.com/resources/browse/38-all.html">Lucene Resources</a> - Articles, Books, FAQs, Forums, Presentations, Wiki. <span class="anchor" id="line-103"></span></li><li><p class="line891"><a class="http" href="http://www.nabble.com/Web-Search-f2787.html">Lucene Search Forum</a> - hosted by <a class="http" href="http://www.nabble.com">Nabble</a> archiving all Lucene and Nutch mailing lists into a searchable archive/forum. The search is coded using Lucene. <span class="anchor" id="line-104"></span></li><li><p class="line891"><a class="http" href="http://www.lucenetutorial.com">LuceneTutorial.com</a> - Tips and tricks, sample applications, code samples, best practices. <span class="anchor" id="line-105"></span></li></ul><span class="anchor" id="bottom"></span></div><p id="pageinfo" class="info" lang="en" dir="ltr">Resources  (last edited 2010-05-03 22:31:43 by <span title="SteveRowe @ ist-h335-d03.syr.edu[128.230.84.100]"><a class="nonexistent" href="/lucene-java/SteveRowe" title="SteveRowe @ ist-h335-d03.syr.edu[128.230.84.100]">SteveRowe</a></span>)</p>
+
+<div id="pagebottom"></div>
+</div>
+
+
+<div id="footer">
+<ul class="editbar"><li><span class="disabled">Immutable Page</span></li><li class="toggleCommentsButton" style="display:none;"><a href="#" class="nbcomment" onClick="toggleComments();return false;">Comments</a></li><li><a class="nbinfo" href="/lucene-java/Resources?action=info" rel="nofollow">Info</a></li><li>
+<form class="actionsmenu" method="GET" action="/lucene-java/Resources">
+<div>
+    <label>More Actions:</label>
+    <select name="action"
+        onchange="if ((this.selectedIndex != 0) &&
+                      (this.options[this.selectedIndex].disabled == false)) {
+                this.form.submit();
+            }
+            this.selectedIndex = 0;">
+        <option value="raw">Raw Text</option>
+<option value="print">Print View</option>
+<option value="RenderAsDocbook">Render as Docbook</option>
+<option value="refresh">Delete Cache</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="SpellCheck">Check Spelling</option>
+<option value="LikePages">Like Pages</option>
+<option value="LocalSiteMap">Local Site Map</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="RenamePage" disabled class="disabled">Rename Page</option>
+<option value="CopyPage">Copy Page</option>
+<option value="DeletePage" disabled class="disabled">Delete Page</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="MyPages">My Pages</option>
+<option value="show" disabled class="disabled">Subscribe User</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="show" disabled class="disabled">Remove Spam</option>
+<option value="show" disabled class="disabled">Revert to this revision</option>
+<option value="show" disabled class="disabled">Package Pages</option>
+<option value="SyncPages">Sync Pages</option>
+<option value="show" disabled class="disabled">------------------------</option>
+<option value="Load">Load</option>
+<option value="Save">Save</option>
+    </select>
+    <input type="submit" value="Do">
+    
+</div>
+<script type="text/javascript">
+<!--// Init menu
+actionsMenuInit('More Actions:');
+//-->
+</script>
+</form>
+</li></ul>
+
+<ul id="credits">
+<li><a href="http://moinmo.in/" title="This site uses the MoinMoin Wiki software.">MoinMoin Powered</a></li><li><a href="http://moinmo.in/Python" title="MoinMoin is written in Python.">Python Powered</a></li><li><a href="http://moinmo.in/GPL" title="MoinMoin is GPL licensed.">GPL licensed</a></li><li><a href="http://validator.w3.org/check?uri=referer" title="Click here to validate this page.">Valid HTML 4.01</a></li>
+</ul>
+
+
+</div>
+</body>
+</html>
+
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPageURLs.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPageURLs.txt
new file mode 100644
index 0000000..e8ca5aa
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/LuceneResourcesWikiPageURLs.txt
@@ -0,0 +1,105 @@
+http://www.w3.org/TR/html4/strict.dtd
+http://lucene.apache.org/java/3_0_1/api/all/overview-summary.html#overview_description
+http://lucene.apache.org/java/3_0_1/gettingstarted.html
+http://lucene.grantingersoll.com
+http://www.lucidimagination.com/blog/
+http://blog.sematext.com/
+http://www.manning.com/hatcher3/hatcher3_cover150.jpg
+http://www.manning.com/hatcher3/hatcher3_cover150.jpg
+http://www.manning.com/hatcher3/hatcher3_cover150.jpg
+http://www.manning.com/hatcher3/
+http://www.amazon.com/Building-Search-Applications-Lucene-Lingpipe/dp/0615204252/
+http://www.amazon.co.jp/exec/obidos/ASIN/4774127809/503-9461699-1775907
+http://www.lucenebook.com
+http://www.amazon.com/exec/obidos/ASIN/1932394281
+Amazon.com
+http://www.amazon.de/Suchmaschinen-entwickeln-mit-Apache-Lucene/dp/3935042450
+http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Getting-Started-with-Lucene/
+http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Optimizing-Findability-in-Lucene-and-Solr/
+http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Debugging-Relevance-Issues-in-Search/
+http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Scaling-Lucene-and-Solr/
+http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Introduction-to-Apache-Lucene-and-Solr/
+http://cephas.net/blog/2008/03/30/how-morelikethis-works-in-lucene/
+http://schmidt.devlib.org/software/lucene-wikipedia.html
+http://marceloochoa.blogspot.com/2007/09/running-lucene-inside-your-oracle-jvm.html
+http://www.onjava.com/pub/a/onjava/2007/05/24/using-the-lucene-query-parser-without-lucene.html
+http://www.javaworld.com/javaworld/jw-09-2006/jw-0925-lucene.html
+http://www-128.ibm.com/developerworks/java/library/wa-lucene2/index.html?ca=drs-
+http://www.freesearch.pe.kr/tag/Lucene
+http://www-128.ibm.com/developerworks/java/library/wa-lucene/index.html
+http://www.onjava.com/pub/a/onjava/2006/01/18/using-lucene-to-search-java-source.html
+http://www.jroller.com/page/wakaleo/?anchor=lucene_a_tutorial_introduction_to
+http://blog.dev.sf.net/index.php?/archives/10-Behind-the-Scenes-of-the-SourceForge.net-Search-System.html
+SourceForge.net
+http://today.java.net/pub/a/today/2005/08/09/didyoumean.html
+http://www.developer.com/java/other/article.php/3490471
+http://www.theserverside.com/tt/articles/article.tss?l=ILoveLucene
+http://javaboutique.internet.com/tutorials/HTMLParser/article.html
+http://bilgidata.com/localhost/bilgidata/yazi.jsp@dosya=a_lucene.xml.html
+http://www.chedong.com/tech/lucene.html
+http://javatechniques.com/public/java/docs/basics/lucene-memory-search.html
+http://www.javaranch.com/newsletter/200404/Lucene.html
+http://www.darksleep.com/lucene/
+http://www-igm.univ-mlv.fr/~dr/XPOSE2003/lucene/articleLucene.html
+http://today.java.net/pub/a/today/2003/11/07/QueryParserRules.html
+http://builder.com.com/5100-6389-5054799.html
+http://today.java.net/pub/a/today/2003/07/30/LuceneIntro.html
+http://www-106.ibm.com/developerworks/library/j-lucene/
+http://www.xml.com/pub/a/ws/2003/05/13/email.html
+http://www.onjava.com/pub/a/onjava/2003/03/05/lucene.html
+http://www.onjava.com/pub/a/onjava/2003/01/15/lucene.html
+http://javangelist.snipsnap.org/space/Lucene-Mini-Tutorial
+http://www.javaworld.com/javaworld/jw-09-2000/jw-0915-lucene.html
+http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=109
+http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=108
+http://www.lucidimagination.com/index.php?option=com_content&amp;task=view&amp;id=113
+http://lucene.sourceforge.net/publications.html
+http://lucene.sourceforge.net/publications.html
+http://people.apache.org/~buschmi/apachecon/AdvancedIndexingLuceneAtlanta07.ppt
+http://www.us.apachecon.com/us2007/
+http://people.apache.org/~yonik/presentations/lucene_intro.pdf
+http://www.eu.apachecon.com
+http://www.cnlp.org/presentations/slides/AdvancedLuceneEU.pdf
+http://www.cnlp.org
+http://www.eu.apachecon.com
+http://blogs.atlassian.com/rebelutionary/downloads/tssjs2007-lucene-generic-data-indexing.pdf
+http://www.atlassian.com/
+http://javasymposium.techtarget.com/lasvegas/index.html
+http://www.cnlp.org/apachecon2005/AdvancedLucene.ppt
+http://www.cnlp.org
+http://www.apachecon.com
+http://www.cnlp.org
+http://www.cnlp.org
+http://www.cnlp.org/apachecon2005
+http://lucene.sourceforge.net/talks/pisa/
+http://conferences.oreillynet.com/presentations/os2003/hatcher_erik_lucene.pdf
+http://lucene.sourceforge.net/talks/inktomi/
+http://www.lucidimagination.com/How-We-Can-Help/Training/
+http://www.lucidimagination.com/How-We-Can-Help/Training/
+http://www.lucenebootcamp.com
+http://www.apachecon.com
+http://rdf.dmoz.org/
+http://rdf.dmoz.org/
+http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html
+http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html
+http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/
+http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/
+http://www.daviddlewis.com/resources/testcollections/reuters21578
+http://www.daviddlewis.com/resources/testcollections/reuters21578
+http://www-2.cs.cmu.edu/~enron/
+http://www-2.cs.cmu.edu/~enron/
+http://wt.jrc.it/lt/Acquis/
+http://wt.jrc.it/lt/Acquis/
+http://www.java201.com/resources/browse/38-all.html
+http://www.nabble.com/Web-Search-f2787.html
+http://www.nabble.com
+http://www.lucenetutorial.com
+LuceneTutorial.com
+ist-h335-d03.syr.edu
+128.230.84.100
+ist-h335-d03.syr.edu
+128.230.84.100
+http://moinmo.in/
+http://moinmo.in/Python
+http://moinmo.in/GPL
+http://validator.w3.org/check?uri=referer
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardAnalyzer.java
new file mode 100644
index 0000000..f0298b5
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardAnalyzer.java
@@ -0,0 +1,398 @@
+package org.apache.lucene.analysis.standard;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Arrays;
+import java.util.Random;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockGraphTokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WordBreakTestUnicode_6_1_0;
+import org.apache.lucene.analysis.standard.std40.StandardTokenizer40;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.Version;
+
+public class TestStandardAnalyzer extends BaseTokenStreamTestCase {
+
+  // LUCENE-5897: slow tokenization of strings of the form (\p{WB:ExtendNumLet}[\p{WB:Format}\p{WB:Extend}]*)+
+  public void testLargePartiallyMatchingToken() throws Exception {
+    // TODO: get these lists of chars matching a property from ICU4J
+    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
+    char[] WordBreak_ExtendNumLet_chars = "_\u203f\u2040\u2054\ufe33\ufe34\ufe4d\ufe4e\ufe4f\uff3f".toCharArray();
+
+    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
+    int[] WordBreak_Format_chars // only the first char in ranges 
+        = { 0xAD, 0x600, 0x61C, 0x6DD, 0x70F, 0x180E, 0x200E, 0x202A, 0x2060, 0x2066, 0xFEFF,
+            0xFFF9, 0x110BD, 0x1D173, 0xE0001, 0xE0020 };
+
+    // http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt
+    int[] WordBreak_Extend_chars // only the first char in ranges
+        = { 0x300, 0x483, 0x591, 0x5bf, 0x5c1, 0x5c4, 0x5c7, 0x610, 0x64b, 0x670, 0x6d6, 0x6df,
+            0x6e7, 0x6ea, 0x711, 0x730, 0x7a6, 0x7eb, 0x816, 0x81b, 0x825, 0x829, 0x859, 0x8e4,
+            0x900, 0x93a, 0x93e, 0x951, 0x962, 0x981, 0x9bc, 0x9be, 0x9c7, 0x9cb, 0x9d7, 0x9e2,
+            0xa01, 0xa3c, 0xa3e, 0xa47, 0xa4b, 0xa51, 0xa70, 0xa75, 0xa81, 0xabc, 0xabe, 0xac7,
+            0xacb, 0xae2, 0xb01, 0xb3c, 0xb3e, 0xb47, 0xb4b, 0xb56, 0xb62, 0xb82, 0xbbe, 0xbc6,
+            0xbca, 0xbd7, 0xc01, 0xc3e, 0xc46, 0xc4a, 0xc55, 0xc62, 0xc82, 0xcbc, 0xcbe, 0xcc6,
+            0xcca, 0xcd5, 0xce2, 0xd02, 0xd3e, 0xd46, 0xd4a, 0xd57, 0xd62, 0xd82, 0xdca, 0xdcf,
+            0xdd6, 0xdd8, 0xdf2, 0xe31, 0xe34, 0xe47, 0xeb1, 0xeb4, 0xebb, 0xec8, 0xf18, 0xf35,
+            0xf37, 0xf39, 0xf3e, 0xf71, 0xf86, 0xf8d, 0xf99, 0xfc6, 0x102b, 0x1056, 0x105e, 0x1062,
+            0x1067, 0x1071, 0x1082, 0x108f, 0x109a, 0x135d, 0x1712, 0x1732, 0x1752, 0x1772, 0x17b4, 
+            0x17dd, 0x180b, 0x18a9, 0x1920, 0x1930, 0x19b0, 0x19c8, 0x1a17, 0x1a55, 0x1a60, 0x1a7f,
+            0x1b00, 0x1b34, 0x1b6b, 0x1b80, 0x1ba1, 0x1be6, 0x1c24, 0x1cd0, 0x1cd4, 0x1ced, 0x1cf2, 
+            0x1dc0, 0x1dfc, 0x200c, 0x20d0, 0x2cef, 0x2d7f, 0x2de0, 0x302a, 0x3099, 0xa66f, 0xa674,
+            0xa69f, 0xa6f0, 0xa802, 0xa806, 0xa80b, 0xa823, 0xa880, 0xa8b4, 0xa8e0, 0xa926, 0xa947, 
+            0xa980, 0xa9b3, 0xaa29, 0xaa43, 0xaa4c, 0xaa7b, 0xaab0, 0xaab2, 0xaab7, 0xaabe, 0xaac1,
+            0xaaeb, 0xaaf5, 0xabe3, 0xabec, 0xfb1e, 0xfe00, 0xfe20, 0xff9e, 0x101fd, 0x10a01,
+            0x10a05, 0x10a0C, 0x10a38, 0x10a3F, 0x11000, 0x11001, 0x11038, 0x11080, 0x11082,
+            0x110b0, 0x110b3, 0x110b7, 0x110b9, 0x11100, 0x11127, 0x1112c, 0x11180, 0x11182,
+            0x111b3, 0x111b6, 0x111bF, 0x116ab, 0x116ac, 0x116b0, 0x116b6, 0x16f51, 0x16f8f,
+            0x1d165, 0x1d167, 0x1d16d, 0x1d17b, 0x1d185, 0x1d1aa, 0x1d242, 0xe0100 }; 
+        
+    StringBuilder builder = new StringBuilder();
+    int numChars = TestUtil.nextInt(random(), 100 * 1024, 1024 * 1024);
+    for (int i = 0 ; i < numChars ; ) {
+      builder.append(WordBreak_ExtendNumLet_chars[random().nextInt(WordBreak_ExtendNumLet_chars.length)]);
+      ++i;
+      if (random().nextBoolean()) {
+        int numFormatExtendChars = TestUtil.nextInt(random(), 1, 8);
+        for (int j = 0; j < numFormatExtendChars; ++j) {
+          int codepoint;
+          if (random().nextBoolean()) {
+            codepoint = WordBreak_Format_chars[random().nextInt(WordBreak_Format_chars.length)];
+          } else {
+            codepoint = WordBreak_Extend_chars[random().nextInt(WordBreak_Extend_chars.length)];
+          }
+          char[] chars = Character.toChars(codepoint);
+          builder.append(chars);
+          i += chars.length;
+        }
+      }
+    }
+    StandardTokenizer ts = new StandardTokenizer();
+    ts.setReader(new StringReader(builder.toString()));
+    ts.reset();
+    while (ts.incrementToken()) { }
+    ts.end();
+    ts.close();
+
+    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);
+    ts.setMaxTokenLength(newBufferSize); // try a different buffer size
+    ts.setReader(new StringReader(builder.toString()));
+    ts.reset();
+    while (ts.incrementToken()) { }
+    ts.end();
+    ts.close();
+  }
+  
+  public void testHugeDoc() throws IOException {
+    StringBuilder sb = new StringBuilder();
+    char whitespace[] = new char[4094];
+    Arrays.fill(whitespace, ' ');
+    sb.append(whitespace);
+    sb.append("testing 1234");
+    String input = sb.toString();
+    StandardTokenizer tokenizer = new StandardTokenizer();
+    tokenizer.setReader(new StringReader(input));
+    BaseTokenStreamTestCase.assertTokenStreamContents(tokenizer, new String[] { "testing", "1234" });
+  }
+
+  private Analyzer a = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+
+      Tokenizer tokenizer = new StandardTokenizer(newAttributeFactory());
+      return new TokenStreamComponents(tokenizer);
+    }
+  };
+
+  public void testArmenian() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
+        new String[] { "Վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից", 
+        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "Վիքիպեդիայի", "կայքը" } );
+  }
+  
+  public void testAmharic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
+        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
+  }
+  
+  public void testArabic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
+        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
+        "بالإنجليزية", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "سيتم", "إطلاقه", "في", "2008" } ); 
+  }
+  
+  public void testAramaic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
+        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "Wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
+        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
+  }
+  
+  public void testBengali() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
+        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
+        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
+  }
+  
+  public void testFarsi() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
+        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
+        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
+  }
+  
+  public void testGreek() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
+        new String[] { "Γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
+        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
+  }
+
+  public void testThai() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
+        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
+  }
+  
+  public void testLao() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
+        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
+  }
+  
+  public void testTibetan() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
+                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
+                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
+                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
+  }
+  
+  /*
+   * For chinese, tokenize as char (these can later form bigrams or whatever)
+   */
+  public void testChinese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
+        new String[] { "我", "是", "中", "国", "人", "１２３４", "Ｔｅｓｔｓ"});
+  }
+  
+  public void testEmpty() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
+  }
+  
+  /* test various jira issues this analyzer is related to */
+  
+  public void testLUCENE1545() throws Exception {
+    /*
+     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTRE E.
+     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
+     * Expected result is only on token "moͤchte".
+     */
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
+  }
+  
+  /* Tests from StandardAnalyzer, just to show behavior is similar */
+  public void testAlphanumericSA() throws Exception {
+    // alphanumeric tokens
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"B2B"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2B"});
+  }
+
+  public void testDelimitersSA() throws Exception {
+    // other delimiters: "-", "/", ","
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
+  }
+
+  public void testApostrophesSA() throws Exception {
+    // internal apostrophes: O'Reilly, you're, O'Reilly's
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"O'Reilly"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"Jim's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"O'Reilly's"});
+  }
+
+  public void testNumericSA() throws Exception {
+    // floating point, serial, model numbers, ip addresses, etc.
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"R2D2", "C3PO"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
+  }
+
+  public void testTextWithNumbersSA() throws Exception {
+    // numbers
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"David", "has", "5000", "bones"});
+  }
+
+  public void testVariousTextSA() throws Exception {
+    // various
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"C", "embedded", "developers", "wanted"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"QUOTED", "word"});
+  }
+
+  public void testKoreanSA() throws Exception {
+    // Korean words
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
+  }
+  
+  public void testOffsets() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
+        new String[] {"David", "has", "5000", "bones"},
+        new int[] {0, 6, 10, 15},
+        new int[] {5, 9, 14, 20});
+  }
+  
+  public void testTypes() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
+        new String[] {"David", "has", "5000", "bones"},
+        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
+  }
+  
+  public void testUnicodeWordBreaks() throws Exception {
+    WordBreakTestUnicode_6_3_0 wordBreakTest = new WordBreakTestUnicode_6_3_0();
+    wordBreakTest.test(a);
+  }
+
+  public void testUnicodeWordBreaksTokenizer40() throws Exception {
+    WordBreakTestUnicode_6_1_0 wordBreakTest = new WordBreakTestUnicode_6_1_0();
+    Analyzer analyzer = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+
+        Tokenizer tokenizer = new StandardTokenizer40(newAttributeFactory());
+        return new TokenStreamComponents(tokenizer);
+      }
+    };
+    wordBreakTest.test(analyzer);
+  }
+  
+  public void testSupplementary() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
+        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
+  }
+  
+  public void testKorean() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
+        new String[] { "훈민정음" },
+        new String[] { "<HANGUL>" });
+  }
+  
+  public void testJapanese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
+        new String[] { "仮", "名", "遣", "い", "カタカナ" },
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
+  }
+  
+  public void testCombiningMarks() throws Exception {
+    checkOneTerm(a, "ざ", "ざ"); // hiragana
+    checkOneTerm(a, "ザ", "ザ"); // katakana
+    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
+    checkOneTerm(a, "아゙",  "아゙"); // hangul
+  }
+
+  /**
+   * Multiple consecutive chars in \p{WB:MidLetter}, \p{WB:MidNumLet},
+   * and/or \p{MidNum} should trigger a token split.
+   */
+  public void testMid() throws Exception {
+    // ':' is in \p{WB:MidLetter}, which should trigger a split unless there is a Letter char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B", new String[] { "A:B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A::B", new String[] { "A", "B" });
+
+    // '.' is in \p{WB:MidNumLet}, which should trigger a split unless there is a Letter or Numeric char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2", new String[] { "1.2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B", new String[] { "A.B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1..2", new String[] { "1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A..B", new String[] { "A", "B" });
+
+    // ',' is in \p{WB:MidNum}, which should trigger a split unless there is a Numeric char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2", new String[] { "1,2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,,2", new String[] { "1", "2" });
+
+    // Mixed consecutive \p{WB:MidLetter} and \p{WB:MidNumLet} should trigger a split
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.:B", new String[] { "A", "B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:.B", new String[] { "A", "B" });
+
+    // Mixed consecutive \p{WB:MidNum} and \p{WB:MidNumLet} should trigger a split
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,.2", new String[] { "1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.,2", new String[] { "1", "2" });
+
+    // '_' is in \p{WB:ExtendNumLet}
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A:B", new String[] { "A:B_A:B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A::B", new String[] { "A:B_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1.2", new String[] { "1.2_1.2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A.B", new String[] { "A.B_A.B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1..2", new String[] { "1.2_1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A..B", new String[] { "A.B_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,2", new String[] { "1,2_1,2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,,2", new String[] { "1,2_1", "2" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A.:B", new String[] { "C_A", "B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A:.B", new String[] { "C_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1,.2", new String[] { "3_1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1.,2", new String[] { "3_1", "2" });
+  }
+
+
+
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), new StandardAnalyzer(), 1000*RANDOM_MULTIPLIER);
+  }
+  
+  /** blast some random large strings through the analyzer */
+  public void testRandomHugeStrings() throws Exception {
+    Random random = random();
+    checkRandomData(random, new StandardAnalyzer(), 100*RANDOM_MULTIPLIER, 8192);
+  }
+
+  // Adds random graph after:
+  public void testRandomHugeStringsGraphAfter() throws Exception {
+    Random random = random();
+    checkRandomData(random,
+                    new Analyzer() {
+                      @Override
+                      protected TokenStreamComponents createComponents(String fieldName) {
+                        Tokenizer tokenizer = new StandardTokenizer(newAttributeFactory());
+                        TokenStream tokenStream = new MockGraphTokenFilter(random(), tokenizer);
+                        return new TokenStreamComponents(tokenizer, tokenStream);
+                      }
+                    },
+                    100*RANDOM_MULTIPLIER, 8192);
+  }
+
+  public void testBackcompat40() throws IOException {
+    StandardAnalyzer a = new StandardAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailAnalyzer.java
new file mode 100644
index 0000000..4b4da03
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailAnalyzer.java
@@ -0,0 +1,348 @@
+package org.apache.lucene.analysis.standard;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.standard.UAX29URLEmailAnalyzer;
+
+import java.io.IOException;
+import java.util.Arrays;
+
+public class TestUAX29URLEmailAnalyzer extends BaseTokenStreamTestCase {
+
+  private Analyzer a = new UAX29URLEmailAnalyzer();
+
+  public void testHugeDoc() throws IOException {
+    StringBuilder sb = new StringBuilder();
+    char whitespace[] = new char[4094];
+    Arrays.fill(whitespace, ' ');
+    sb.append(whitespace);
+    sb.append("testing 1234");
+    String input = sb.toString();
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, input, new String[]{"testing", "1234"}) ;
+  }
+
+  public void testArmenian() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
+        new String[] { "վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից",
+        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "վիքիպեդիայի", "կայքը" } );
+  }
+  
+  public void testAmharic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
+        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
+  }
+  
+  public void testArabic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
+        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
+        "بالإنجليزية", "truth", "numbers", "wikipedia", "story", "سيتم", "إطلاقه", "في", "2008" } );
+  }
+  
+  public void testAramaic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
+        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
+        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
+  }
+  
+  public void testBengali() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
+        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
+        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
+  }
+  
+  public void testFarsi() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
+        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
+        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
+  }
+  
+  public void testGreek() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
+        new String[] { "γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
+        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
+  }
+
+  public void testThai() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
+        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
+  }
+  
+  public void testLao() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
+        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
+  }
+  
+  public void testTibetan() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
+                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
+                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
+                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
+  }
+  
+  /*
+   * For chinese, tokenize as char (these can later form bigrams or whatever)
+   */
+  public void testChinese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
+        new String[] { "我", "是", "中", "国", "人", "１２３４", "ｔｅｓｔｓ"});
+  }
+  
+  public void testEmpty() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
+  }
+  
+  /* test various jira issues this analyzer is related to */
+  
+  public void testLUCENE1545() throws Exception {
+    /*
+     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTER E.
+     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
+     * Expected result is only one token "moͤchte".
+     */
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
+  }
+  
+  /* Tests from StandardAnalyzer, just to show behavior is similar */
+  public void testAlphanumericSA() throws Exception {
+    // alphanumeric tokens
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"b2b"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2b"});
+  }
+
+  public void testDelimitersSA() throws Exception {
+    // other delimiters: "-", "/", ","
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
+  }
+
+  public void testApostrophesSA() throws Exception {
+    // internal apostrophes: O'Reilly, you're, O'Reilly's
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"o'reilly"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"jim's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"o'reilly's"});
+  }
+
+  public void testNumericSA() throws Exception {
+    // floating point, serial, model numbers, ip addresses, etc.
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"r2d2", "c3po"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
+  }
+
+  public void testTextWithNumbersSA() throws Exception {
+    // numbers
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"david", "has", "5000", "bones"});
+  }
+
+  public void testVariousTextSA() throws Exception {
+    // various
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"c", "embedded", "developers", "wanted"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "foo", "bar"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "foo", "bar"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"quoted", "word"});
+  }
+
+  public void testKoreanSA() throws Exception {
+    // Korean words
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
+  }
+  
+  public void testOffsets() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
+        new String[] {"david", "has", "5000", "bones"},
+        new int[] {0, 6, 10, 15},
+        new int[] {5, 9, 14, 20});
+  }
+  
+  public void testTypes() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "david has 5000 bones",
+        new String[] {"david", "has", "5000", "bones"},
+        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
+  }
+  
+  public void testSupplementary() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
+        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
+  }
+  
+  public void testKorean() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
+        new String[] { "훈민정음" },
+        new String[] { "<HANGUL>" });
+  }
+  
+  public void testJapanese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
+        new String[] { "仮", "名", "遣", "い", "カタカナ" },
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
+  }
+  
+  public void testCombiningMarks() throws Exception {
+    checkOneTerm(a, "ざ", "ざ"); // hiragana
+    checkOneTerm(a, "ザ", "ザ"); // katakana
+    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
+    checkOneTerm(a, "아゙",  "아゙"); // hangul
+  }
+
+  public void testBasicEmails() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a,
+        "one test@example.com two three [A@example.CO.UK] \"ArakaBanassaMassanaBakarA\" <info@Info.info>",
+        new String[] {"one", "test@example.com", "two", "three", "a@example.co.uk", "arakabanassamassanabakara", "info@info.info",},
+        new String[] { "<ALPHANUM>", "<EMAIL>", "<ALPHANUM>", "<ALPHANUM>", "<EMAIL>", "<ALPHANUM>", "<EMAIL>" });
+  }
+
+  public void testMailtoSchemeEmails () throws Exception {
+    // See LUCENE-3880
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "MAILTO:Test@Example.ORG",
+        new String[] {"mailto", "test@example.org"},
+        new String[] { "<ALPHANUM>", "<EMAIL>" });
+
+    // TODO: Support full mailto: scheme URIs. See RFC 6068: http://tools.ietf.org/html/rfc6068
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a,  "mailto:personA@example.com,personB@example.com?cc=personC@example.com"
+            + "&subject=Subjectivity&body=Corpusivity%20or%20something%20like%20that",
+            new String[] { "mailto",
+                "persona@example.com",
+                // TODO: recognize ',' address delimiter. Also, see examples of ';' delimiter use at: http://www.mailto.co.uk/
+                ",personb@example.com",
+                "?cc=personc@example.com", // TODO: split field keys/values
+                "subject", "subjectivity",
+                "body", "corpusivity", "20or", "20something","20like", "20that" }, // TODO: Hex decoding + re-tokenization
+            new String[] { "<ALPHANUM>",
+                "<EMAIL>",
+                "<EMAIL>",
+                "<EMAIL>",
+                "<ALPHANUM>", "<ALPHANUM>",
+                "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>" });
+  }
+
+  public void testBasicURLs() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a,
+        "a <HTTPs://example.net/omg/isnt/that/NICE?no=its&n%30t#mntl-E>b-D ftp://www.example.com/ABC.txt file:///C:/path/to/a/FILE.txt C",
+        new String[] {"https://example.net/omg/isnt/that/nice?no=its&n%30t#mntl-e", "b", "d", "ftp://www.example.com/abc.txt", "file:///c:/path/to/a/file.txt", "c" },
+        new String[] { "<URL>", "<ALPHANUM>", "<ALPHANUM>", "<URL>", "<URL>", "<ALPHANUM>" });
+  }
+
+  public void testNoSchemeURLs() throws Exception {
+    // ".ph" is a Top Level Domain
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "<index.ph>", new String[]{"index.ph"}, new String[]{"<URL>"});
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index.ph", new String[]{"index.ph"}, new String[]{"<URL>"});
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index.php", new String[]{"index.php"}, new String[]{"<ALPHANUM>"});
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index.phα", new String[]{"index.phα"}, new String[]{"<ALPHANUM>"});
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index-h.php", new String[] { "index",     "h.php" },
+                           new String[] { "<ALPHANUM>","<ALPHANUM>"});
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index2.php", new String[] { "index2",     "php" },
+                          new String[] { "<ALPHANUM>", "<ALPHANUM>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "index2.ph９,", new String[] { "index2",     "ph９" },
+                            new String[] { "<ALPHANUM>", "<ALPHANUM>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com,example.ph,index.php,index2.php,example2.ph",
+            new String[] { "example.com", "example.ph", "index.php",  "index2",     "php",        "example2.ph" },
+            new String[] { "<URL>",       "<URL>",      "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080 example.com/path/here example.com?query=something example.com#fragment",
+            new String[] { "example.com:8080", "example.com/path/here", "example.com?query=something", "example.com#fragment" },
+            new String[] { "<URL>",            "<URL>",                 "<URL>",                       "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080/path/here?query=something#fragment", 
+            new String[] { "example.com:8080/path/here?query=something#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080/path/here?query=something",
+            new String[] { "example.com:8080/path/here?query=something" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080/path/here#fragment",
+            new String[] { "example.com:8080/path/here#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080/path/here",
+            new String[] { "example.com:8080/path/here" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080?query=something#fragment",
+            new String[] { "example.com:8080?query=something#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080?query=something",
+            new String[] { "example.com:8080?query=something" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com:8080#fragment",
+            new String[] { "example.com:8080#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com/path/here?query=something#fragment",
+            new String[] { "example.com/path/here?query=something#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com/path/here?query=something",
+            new String[] { "example.com/path/here?query=something" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com/path/here#fragment",
+            new String[] { "example.com/path/here#fragment" },
+            new String[] { "<URL>" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a, "example.com?query=something#fragment",
+            new String[] { "example.com?query=something#fragment" },
+            new String[] { "<URL>" });
+  }
+
+  
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), new UAX29URLEmailAnalyzer(), 1000*RANDOM_MULTIPLIER);
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizer.java
new file mode 100644
index 0000000..1917da4
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizer.java
@@ -0,0 +1,549 @@
+package org.apache.lucene.analysis.standard;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.TestUtil;
+
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.io.StringReader;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Random;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestUAX29URLEmailTokenizer extends BaseTokenStreamTestCase {
+
+  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')
+  public void testLongEMAILatomText() throws Exception {
+    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\^_`{|}~]
+    char[] emailAtomChars
+        = "!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~".toCharArray();
+    StringBuilder builder = new StringBuilder();
+    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);
+    for (int i = 0 ; i < numChars ; ++i) {
+      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);
+    }
+    int tokenCount = 0;
+    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();
+    String text = builder.toString();
+    ts.setReader(new StringReader(text));
+    ts.reset();
+    while (ts.incrementToken()) {
+      tokenCount++;
+    }
+    ts.end();
+    ts.close();
+    assertTrue(tokenCount > 0);
+
+    tokenCount = 0;
+    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);
+    ts.setMaxTokenLength(newBufferSize);
+    ts.setReader(new StringReader(text));
+    ts.reset();
+    while (ts.incrementToken()) {
+      tokenCount++;
+    }
+    ts.end();
+    ts.close();
+    assertTrue(tokenCount > 0);
+  }
+
+  public void testHugeDoc() throws IOException {
+    StringBuilder sb = new StringBuilder();
+    char whitespace[] = new char[4094];
+    Arrays.fill(whitespace, ' ');
+    sb.append(whitespace);
+    sb.append("testing 1234");
+    String input = sb.toString();
+    UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
+    tokenizer.setReader(new StringReader(input));
+    BaseTokenStreamTestCase.assertTokenStreamContents(tokenizer, new String[] { "testing", "1234" });
+  }
+
+  private Analyzer a = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+
+      Tokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
+      return new TokenStreamComponents(tokenizer);
+    }
+  };
+
+
+  /** Passes through tokens with type "<URL>" and blocks all other types. */
+  private class URLFilter extends TokenFilter {
+    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+    public URLFilter(TokenStream in) {
+      super(in);
+    }
+    @Override
+    public final boolean incrementToken() throws java.io.IOException {
+      boolean isTokenAvailable = false;
+      while (input.incrementToken()) {
+        if (typeAtt.type() == UAX29URLEmailTokenizer.TOKEN_TYPES[UAX29URLEmailTokenizer.URL]) {
+          isTokenAvailable = true;
+          break;
+        }
+      }
+      return isTokenAvailable;
+    }
+  }
+  
+  /** Passes through tokens with type "<EMAIL>" and blocks all other types. */
+  private class EmailFilter extends TokenFilter {
+    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+    public EmailFilter(TokenStream in) {
+      super(in);
+    }
+    @Override
+    public final boolean incrementToken() throws java.io.IOException {
+      boolean isTokenAvailable = false;
+      while (input.incrementToken()) {
+        if (typeAtt.type() == UAX29URLEmailTokenizer.TOKEN_TYPES[UAX29URLEmailTokenizer.EMAIL]) {
+          isTokenAvailable = true;
+          break;
+        }
+      }
+      return isTokenAvailable;
+    }
+  }
+
+  private Analyzer urlAnalyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
+      tokenizer.setMaxTokenLength(Integer.MAX_VALUE);  // Tokenize arbitrary length URLs
+      TokenFilter filter = new URLFilter(tokenizer);
+      return new TokenStreamComponents(tokenizer, filter);
+    }
+  };
+
+  private Analyzer emailAnalyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(newAttributeFactory());
+      TokenFilter filter = new EmailFilter(tokenizer);
+      return new TokenStreamComponents(tokenizer, filter);
+    }
+  };
+  
+  
+  public void testArmenian() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Վիքիպեդիայի 13 միլիոն հոդվածները (4,600` հայերեն վիքիպեդիայում) գրվել են կամավորների կողմից ու համարյա բոլոր հոդվածները կարող է խմբագրել ցանկաց մարդ ով կարող է բացել Վիքիպեդիայի կայքը։",
+        new String[] { "Վիքիպեդիայի", "13", "միլիոն", "հոդվածները", "4,600", "հայերեն", "վիքիպեդիայում", "գրվել", "են", "կամավորների", "կողմից", 
+        "ու", "համարյա", "բոլոր", "հոդվածները", "կարող", "է", "խմբագրել", "ցանկաց", "մարդ", "ով", "կարող", "է", "բացել", "Վիքիպեդիայի", "կայքը" } );
+  }
+  
+  public void testAmharic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ዊኪፔድያ የባለ ብዙ ቋንቋ የተሟላ ትክክለኛና ነጻ መዝገበ ዕውቀት (ኢንሳይክሎፒዲያ) ነው። ማንኛውም",
+        new String[] { "ዊኪፔድያ", "የባለ", "ብዙ", "ቋንቋ", "የተሟላ", "ትክክለኛና", "ነጻ", "መዝገበ", "ዕውቀት", "ኢንሳይክሎፒዲያ", "ነው", "ማንኛውም" } );
+  }
+  
+  public void testArabic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "الفيلم الوثائقي الأول عن ويكيبيديا يسمى \"الحقيقة بالأرقام: قصة ويكيبيديا\" (بالإنجليزية: Truth in Numbers: The Wikipedia Story)، سيتم إطلاقه في 2008.",
+        new String[] { "الفيلم", "الوثائقي", "الأول", "عن", "ويكيبيديا", "يسمى", "الحقيقة", "بالأرقام", "قصة", "ويكيبيديا",
+        "بالإنجليزية", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "سيتم", "إطلاقه", "في", "2008" } ); 
+  }
+  
+  public void testAramaic() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ܘܝܩܝܦܕܝܐ (ܐܢܓܠܝܐ: Wikipedia) ܗܘ ܐܝܢܣܩܠܘܦܕܝܐ ܚܐܪܬܐ ܕܐܢܛܪܢܛ ܒܠܫܢ̈ܐ ܣܓܝܐ̈ܐ܂ ܫܡܗ ܐܬܐ ܡܢ ܡ̈ܠܬܐ ܕ\"ܘܝܩܝ\" ܘ\"ܐܝܢܣܩܠܘܦܕܝܐ\"܀",
+        new String[] { "ܘܝܩܝܦܕܝܐ", "ܐܢܓܠܝܐ", "Wikipedia", "ܗܘ", "ܐܝܢܣܩܠܘܦܕܝܐ", "ܚܐܪܬܐ", "ܕܐܢܛܪܢܛ", "ܒܠܫܢ̈ܐ", "ܣܓܝܐ̈ܐ", "ܫܡܗ",
+        "ܐܬܐ", "ܡܢ", "ܡ̈ܠܬܐ", "ܕ", "ܘܝܩܝ", "ܘ", "ܐܝܢܣܩܠܘܦܕܝܐ"});
+  }
+  
+  public void testBengali() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "এই বিশ্বকোষ পরিচালনা করে উইকিমিডিয়া ফাউন্ডেশন (একটি অলাভজনক সংস্থা)। উইকিপিডিয়ার শুরু ১৫ জানুয়ারি, ২০০১ সালে। এখন পর্যন্ত ২০০টিরও বেশী ভাষায় উইকিপিডিয়া রয়েছে।",
+        new String[] { "এই", "বিশ্বকোষ", "পরিচালনা", "করে", "উইকিমিডিয়া", "ফাউন্ডেশন", "একটি", "অলাভজনক", "সংস্থা", "উইকিপিডিয়ার",
+        "শুরু", "১৫", "জানুয়ারি", "২০০১", "সালে", "এখন", "পর্যন্ত", "২০০টিরও", "বেশী", "ভাষায়", "উইকিপিডিয়া", "রয়েছে" });
+  }
+  
+  public void testFarsi() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ویکی پدیای انگلیسی در تاریخ ۲۵ دی ۱۳۷۹ به صورت مکملی برای دانشنامهٔ تخصصی نوپدیا نوشته شد.",
+        new String[] { "ویکی", "پدیای", "انگلیسی", "در", "تاریخ", "۲۵", "دی", "۱۳۷۹", "به", "صورت", "مکملی",
+        "برای", "دانشنامهٔ", "تخصصی", "نوپدیا", "نوشته", "شد" });
+  }
+  
+  public void testGreek() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Γράφεται σε συνεργασία από εθελοντές με το λογισμικό wiki, κάτι που σημαίνει ότι άρθρα μπορεί να προστεθούν ή να αλλάξουν από τον καθένα.",
+        new String[] { "Γράφεται", "σε", "συνεργασία", "από", "εθελοντές", "με", "το", "λογισμικό", "wiki", "κάτι", "που",
+        "σημαίνει", "ότι", "άρθρα", "μπορεί", "να", "προστεθούν", "ή", "να", "αλλάξουν", "από", "τον", "καθένα" });
+  }
+
+  public void testThai() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "การที่ได้ต้องแสดงว่างานดี. แล้วเธอจะไปไหน? ๑๒๓๔",
+        new String[] { "การที่ได้ต้องแสดงว่างานดี", "แล้วเธอจะไปไหน", "๑๒๓๔" });
+  }
+  
+  public void testLao() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ສາທາລະນະລັດ ປະຊາທິປະໄຕ ປະຊາຊົນລາວ", 
+        new String[] { "ສາທາລະນະລັດ", "ປະຊາທິປະໄຕ", "ປະຊາຊົນລາວ" });
+  }
+  
+  public void testTibetan() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "སྣོན་མཛོད་དང་ལས་འདིས་བོད་ཡིག་མི་ཉམས་གོང་འཕེལ་དུ་གཏོང་བར་ཧ་ཅང་དགེ་མཚན་མཆིས་སོ། །",
+                     new String[] { "སྣོན", "མཛོད", "དང", "ལས", "འདིས", "བོད", "ཡིག", 
+                                    "མི", "ཉམས", "གོང", "འཕེལ", "དུ", "གཏོང", "བར", 
+                                    "ཧ", "ཅང", "དགེ", "མཚན", "མཆིས", "སོ" });
+  }
+  
+  /*
+   * For chinese, tokenize as char (these can later form bigrams or whatever)
+   */
+  public void testChinese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "我是中国人。 １２３４ Ｔｅｓｔｓ ",
+        new String[] { "我", "是", "中", "国", "人", "１２３４", "Ｔｅｓｔｓ"});
+  }
+  
+  public void testEmpty() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, ".", new String[] {});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, " ", new String[] {});
+  }
+  
+  /* test various jira issues this analyzer is related to */
+  
+  public void testLUCENE1545() throws Exception {
+    /*
+     * Standard analyzer does not correctly tokenize combining character U+0364 COMBINING LATIN SMALL LETTRE E.
+     * The word "moͤchte" is incorrectly tokenized into "mo" "chte", the combining character is lost.
+     * Expected result is only on token "moͤchte".
+     */
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "moͤchte", new String[] { "moͤchte" }); 
+  }
+  
+  /* Tests from StandardAnalyzer, just to show behavior is similar */
+  public void testAlphanumericSA() throws Exception {
+    // alphanumeric tokens
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "B2B", new String[]{"B2B"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "2B", new String[]{"2B"});
+  }
+
+  public void testDelimitersSA() throws Exception {
+    // other delimiters: "-", "/", ","
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "some-dashed-phrase", new String[]{"some", "dashed", "phrase"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "dogs,chase,cats", new String[]{"dogs", "chase", "cats"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ac/dc", new String[]{"ac", "dc"});
+  }
+
+  public void testApostrophesSA() throws Exception {
+    // internal apostrophes: O'Reilly, you're, O'Reilly's
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly", new String[]{"O'Reilly"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "you're", new String[]{"you're"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "she's", new String[]{"she's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "Jim's", new String[]{"Jim's"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "don't", new String[]{"don't"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "O'Reilly's", new String[]{"O'Reilly's"});
+  }
+
+  public void testNumericSA() throws Exception {
+    // floating point, serial, model numbers, ip addresses, etc.
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"R2D2", "C3PO"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
+  }
+
+  public void testTextWithNumbersSA() throws Exception {
+    // numbers
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", new String[]{"David", "has", "5000", "bones"});
+  }
+
+  public void testVariousTextSA() throws Exception {
+    // various
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"C", "embedded", "developers", "wanted"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"QUOTED", "word"});
+  }
+
+  public void testKoreanSA() throws Exception {
+    // Korean words
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "안녕하세요 한글입니다", new String[]{"안녕하세요", "한글입니다"});
+  }
+  
+  public void testOffsets() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
+        new String[] {"David", "has", "5000", "bones"},
+        new int[] {0, 6, 10, 15},
+        new int[] {5, 9, 14, 20});
+  }
+  
+  public void testTypes() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "David has 5000 bones", 
+        new String[] {"David", "has", "5000", "bones"},
+        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
+  }
+  
+  public void testWikiURLs() throws Exception {
+    Reader reader = null;
+    String luceneResourcesWikiPage;
+    try {
+      reader = new InputStreamReader(getClass().getResourceAsStream
+        ("LuceneResourcesWikiPage.html"), StandardCharsets.UTF_8);
+      StringBuilder builder = new StringBuilder();
+      char[] buffer = new char[1024];
+      int numCharsRead;
+      while (-1 != (numCharsRead = reader.read(buffer))) {
+        builder.append(buffer, 0, numCharsRead);
+      }
+      luceneResourcesWikiPage = builder.toString(); 
+    } finally {
+      if (null != reader) {
+        reader.close();
+      }
+    }
+    assertTrue(null != luceneResourcesWikiPage 
+               && luceneResourcesWikiPage.length() > 0);
+    BufferedReader bufferedReader = null;
+    String[] urls;
+    try {
+      List<String> urlList = new ArrayList<>();
+      bufferedReader = new BufferedReader(new InputStreamReader
+        (getClass().getResourceAsStream("LuceneResourcesWikiPageURLs.txt"), StandardCharsets.UTF_8));
+      String line;
+      while (null != (line = bufferedReader.readLine())) {
+        line = line.trim();
+        if (line.length() > 0) {
+          urlList.add(line);
+        }
+      }
+      urls = urlList.toArray(new String[urlList.size()]);
+    } finally {
+      if (null != bufferedReader) {
+        bufferedReader.close();
+      }
+    }
+    assertTrue(null != urls && urls.length > 0);
+    BaseTokenStreamTestCase.assertAnalyzesTo
+      (urlAnalyzer, luceneResourcesWikiPage, urls);
+  }
+  
+  public void testEmails() throws Exception {
+    Reader reader = null;
+    String randomTextWithEmails;
+    try {
+      reader = new InputStreamReader(getClass().getResourceAsStream
+        ("random.text.with.email.addresses.txt"), StandardCharsets.UTF_8);
+      StringBuilder builder = new StringBuilder();
+      char[] buffer = new char[1024];
+      int numCharsRead;
+      while (-1 != (numCharsRead = reader.read(buffer))) {
+        builder.append(buffer, 0, numCharsRead);
+      }
+      randomTextWithEmails = builder.toString(); 
+    } finally {
+      if (null != reader) {
+        reader.close();
+      }
+    }
+    assertTrue(null != randomTextWithEmails 
+               && randomTextWithEmails.length() > 0);
+    BufferedReader bufferedReader = null;
+    String[] emails;
+    try {
+      List<String> emailList = new ArrayList<>();
+      bufferedReader = new BufferedReader(new InputStreamReader
+        (getClass().getResourceAsStream
+          ("email.addresses.from.random.text.with.email.addresses.txt"), StandardCharsets.UTF_8));
+      String line;
+      while (null != (line = bufferedReader.readLine())) {
+        line = line.trim();
+        if (line.length() > 0) {
+          emailList.add(line);
+        }
+      }
+      emails = emailList.toArray(new String[emailList.size()]);
+    } finally {
+      if (null != bufferedReader) {
+        bufferedReader.close();
+      }
+    }
+    assertTrue(null != emails && emails.length > 0);
+    BaseTokenStreamTestCase.assertAnalyzesTo
+      (emailAnalyzer, randomTextWithEmails, emails);
+  }
+
+  public void testMailtoSchemeEmails () throws Exception {
+    // See LUCENE-3880
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "mailto:test@example.org",
+        new String[] {"mailto", "test@example.org"},
+        new String[] { "<ALPHANUM>", "<EMAIL>" });
+
+    // TODO: Support full mailto: scheme URIs. See RFC 6068: http://tools.ietf.org/html/rfc6068
+    BaseTokenStreamTestCase.assertAnalyzesTo
+        (a,  "mailto:personA@example.com,personB@example.com?cc=personC@example.com"
+           + "&subject=Subjectivity&body=Corpusivity%20or%20something%20like%20that",
+         new String[] { "mailto",
+                        "personA@example.com",
+                        // TODO: recognize ',' address delimiter. Also, see examples of ';' delimiter use at: http://www.mailto.co.uk/
+                        ",personB@example.com",
+                        "?cc=personC@example.com", // TODO: split field keys/values
+                        "subject", "Subjectivity",
+                        "body", "Corpusivity", "20or", "20something","20like", "20that" }, // TODO: Hex decoding + re-tokenization
+         new String[] { "<ALPHANUM>",
+                        "<EMAIL>",
+                        "<EMAIL>",
+                        "<EMAIL>",
+                        "<ALPHANUM>", "<ALPHANUM>",
+                        "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>" });
+  }
+
+  public void testURLs() throws Exception {
+    Reader reader = null;
+    String randomTextWithURLs;
+    try {
+      reader = new InputStreamReader(getClass().getResourceAsStream
+        ("random.text.with.urls.txt"), StandardCharsets.UTF_8);
+      StringBuilder builder = new StringBuilder();
+      char[] buffer = new char[1024];
+      int numCharsRead;
+      while (-1 != (numCharsRead = reader.read(buffer))) {
+        builder.append(buffer, 0, numCharsRead);
+      }
+      randomTextWithURLs = builder.toString(); 
+    } finally {
+      if (null != reader) {
+        reader.close();
+      }
+    }
+    assertTrue(null != randomTextWithURLs 
+               && randomTextWithURLs.length() > 0);
+    BufferedReader bufferedReader = null;
+    String[] urls;
+    try {
+      List<String> urlList = new ArrayList<>();
+      bufferedReader = new BufferedReader(new InputStreamReader
+        (getClass().getResourceAsStream
+          ("urls.from.random.text.with.urls.txt"), StandardCharsets.UTF_8));
+      String line;
+      while (null != (line = bufferedReader.readLine())) {
+        line = line.trim();
+        if (line.length() > 0) {
+          urlList.add(line);
+        }
+      }
+      urls = urlList.toArray(new String[urlList.size()]);
+    } finally {
+      if (null != bufferedReader) {
+        bufferedReader.close();
+      }
+    }
+    assertTrue(null != urls && urls.length > 0);
+    BaseTokenStreamTestCase.assertAnalyzesTo
+      (urlAnalyzer, randomTextWithURLs, urls);
+  }
+
+  public void testUnicodeWordBreaks() throws Exception {
+    WordBreakTestUnicode_6_3_0 wordBreakTest = new WordBreakTestUnicode_6_3_0();
+    wordBreakTest.test(a);
+  }
+  
+  public void testSupplementary() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "𩬅艱鍟䇹愯瀛", 
+        new String[] {"𩬅", "艱", "鍟", "䇹", "愯", "瀛"},
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>" });
+  }
+  
+  public void testKorean() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "훈민정음",
+        new String[] { "훈민정음" },
+        new String[] { "<HANGUL>" });
+  }
+  
+  public void testJapanese() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "仮名遣い カタカナ",
+        new String[] { "仮", "名", "遣", "い", "カタカナ" },
+        new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
+  }
+
+  public void testCombiningMarks() throws Exception {
+    checkOneTerm(a, "ざ", "ざ"); // hiragana
+    checkOneTerm(a, "ザ", "ザ"); // katakana
+    checkOneTerm(a, "壹゙", "壹゙"); // ideographic
+    checkOneTerm(a, "아゙",  "아゙"); // hangul
+  }
+
+  /**
+   * Multiple consecutive chars in \p{Word_Break = MidLetter},
+   * \p{Word_Break = MidNumLet}, and/or \p{Word_Break = MidNum}
+   * should trigger a token split.
+   */
+  public void testMid() throws Exception {
+    // ':' is in \p{WB:MidLetter}, which should trigger a split unless there is a Letter char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B", new String[] { "A:B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A::B", new String[] { "A", "B" });
+
+    // '.' is in \p{WB:MidNumLet}, which should trigger a split unless there is a Letter or Numeric char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2", new String[] { "1.2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B", new String[] { "A.B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1..2", new String[] { "1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A..B", new String[] { "A", "B" });
+
+    // ',' is in \p{WB:MidNum}, which should trigger a split unless there is a Numeric char on both sides
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2", new String[] { "1,2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,,2", new String[] { "1", "2" });
+
+    // Mixed consecutive \p{WB:MidLetter} and \p{WB:MidNumLet} should trigger a split
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.:B", new String[] { "A", "B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:.B", new String[] { "A", "B" });
+
+    // Mixed consecutive \p{WB:MidNum} and \p{WB:MidNumLet} should trigger a split
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,.2", new String[] { "1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.,2", new String[] { "1", "2" });
+
+    // '_' is in \p{WB:ExtendNumLet}
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A:B", new String[] { "A:B_A:B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A:B_A::B", new String[] { "A:B_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1.2", new String[] { "1.2_1.2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A.B", new String[] { "A.B_A.B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1.2_1..2", new String[] { "1.2_1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "A.B_A..B", new String[] { "A.B_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,2", new String[] { "1,2_1,2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "1,2_1,,2", new String[] { "1,2_1", "2" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A.:B", new String[] { "C_A", "B" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "C_A:.B", new String[] { "C_A", "B" });
+
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1,.2", new String[] { "3_1", "2" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3_1.,2", new String[] { "3_1", "2" });
+  }
+
+
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), a, 1000*RANDOM_MULTIPLIER);
+  }
+  
+  /** blast some random large strings through the analyzer */
+  public void testRandomHugeStrings() throws Exception {
+    Random random = random();
+    checkRandomData(random, a, 100*RANDOM_MULTIPLIER, 8192);
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_1_0.java lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_1_0.java
new file mode 100644
index 0000000..7dbea1c
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_1_0.java
@@ -0,0 +1,3961 @@
+package org.apache.lucene.analysis.core;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.junit.Ignore;
+
+/**
+ * This class was automatically generated by generateJavaUnicodeWordBreakTest.pl
+ * from: http://www.unicode.org/Public/6.1.0/ucd/auxiliary/WordBreakTest.txt
+ *
+ * WordBreakTest.txt indicates the points in the provided character sequences
+ * at which conforming implementations must and must not break words.  This
+ * class tests for expected token extraction from each of the test sequences
+ * in WordBreakTest.txt, where the expected tokens are those character
+ * sequences bounded by word breaks and containing at least one character
+ * from one of the following character sets:
+ *
+ *    \p{Script = Han}                (From http://www.unicode.org/Public/6.1.0/ucd/Scripts.txt)
+ *    \p{Script = Hiragana}
+ *    \p{LineBreak = Complex_Context} (From http://www.unicode.org/Public/6.1.0/ucd/LineBreak.txt)
+ *    \p{WordBreak = ALetter}         (From http://www.unicode.org/Public/6.1.0/ucd/auxiliary/WordBreakProperty.txt)
+ *    \p{WordBreak = Hebrew_Letter}
+ *    \p{WordBreak = Katakana}
+ *    \p{WordBreak = Numeric}         (Excludes full-width Arabic digits)
+ *    [\uFF10-\uFF19]                (Full-width Arabic digits)
+ */
+@Ignore
+public class WordBreakTestUnicode_6_1_0 extends BaseTokenStreamTestCase {
+
+  public void test(Analyzer analyzer) throws Exception {
+    // ÷ 0001 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0001",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\r",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\n",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u000B",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0001 × 0308 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0001 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0001 × 0308 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0001 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u003A",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u002C",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0027",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0001 × 0308 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0001 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u005F",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0001 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u00AD",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0001 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0300",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0001 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0001 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0001",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\r",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000D × 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) × [3.0] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\n",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u000B",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000D ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000D ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000D ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000D ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u003A",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u002C",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0027",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000D ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000D ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u005F",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u00AD",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 × 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0300",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 × 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000D ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0001",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\r",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\n",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u000B",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000A ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000A ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000A ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000A ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u003A",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u002C",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0027",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000A ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000A ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u005F",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u00AD",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0300",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0001",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\r",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\n",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u000B",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000B ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000B ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000B ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000B ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u003A",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u002C",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0027",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000B ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000B ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u005F",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u00AD",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0300",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000B ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 3031 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0001",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0001",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\r",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\r",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\n",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\n",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u000B",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u000B",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u3031",
+                     new String[] { "\u3031\u3031" });
+
+    // ÷ 3031 × 0308 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u3031",
+                     new String[] { "\u3031\u0308\u3031" });
+
+    // ÷ 3031 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0041",
+                     new String[] { "\u3031", "\u0041" });
+
+    // ÷ 3031 × 0308 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0041",
+                     new String[] { "\u3031\u0308", "\u0041" });
+
+    // ÷ 3031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u003A",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u003A",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u002C",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u002C",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0027",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0027",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0030",
+                     new String[] { "\u3031", "\u0030" });
+
+    // ÷ 3031 × 0308 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0030",
+                     new String[] { "\u3031\u0308", "\u0030" });
+
+    // ÷ 3031 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u005F",
+                     new String[] { "\u3031\u005F" });
+
+    // ÷ 3031 × 0308 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u005F",
+                     new String[] { "\u3031\u0308\u005F" });
+
+    // ÷ 3031 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u00AD",
+                     new String[] { "\u3031\u00AD" });
+
+    // ÷ 3031 × 0308 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u00AD",
+                     new String[] { "\u3031\u0308\u00AD" });
+
+    // ÷ 3031 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0300",
+                     new String[] { "\u3031\u0300" });
+
+    // ÷ 3031 × 0308 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0300",
+                     new String[] { "\u3031\u0308\u0300" });
+
+    // ÷ 3031 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u2060",
+                     new String[] { "\u3031", "\u0061\u2060" });
+
+    // ÷ 3031 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u2060",
+                     new String[] { "\u3031\u0308", "\u0061\u2060" });
+
+    // ÷ 3031 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u003A",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u003A",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027\u2060",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027\u2060",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u002C",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u002C",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u003A",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u003A",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u0027",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u0027",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u002C",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002C",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u002E\u2060",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002E\u2060",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 0041 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0001",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0001",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\r",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\r",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\n",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\n",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u000B",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u000B",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u3031",
+                     new String[] { "\u0041", "\u3031" });
+
+    // ÷ 0041 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u3031",
+                     new String[] { "\u0041\u0308", "\u3031" });
+
+    // ÷ 0041 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0041",
+                     new String[] { "\u0041\u0041" });
+
+    // ÷ 0041 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0041",
+                     new String[] { "\u0041\u0308\u0041" });
+
+    // ÷ 0041 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u003A",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u003A",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u002C",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u002C",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0027",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0027",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0030",
+                     new String[] { "\u0041\u0030" });
+
+    // ÷ 0041 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0030",
+                     new String[] { "\u0041\u0308\u0030" });
+
+    // ÷ 0041 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u005F",
+                     new String[] { "\u0041\u005F" });
+
+    // ÷ 0041 × 0308 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u005F",
+                     new String[] { "\u0041\u0308\u005F" });
+
+    // ÷ 0041 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u00AD",
+                     new String[] { "\u0041\u00AD" });
+
+    // ÷ 0041 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u00AD",
+                     new String[] { "\u0041\u0308\u00AD" });
+
+    // ÷ 0041 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0300",
+                     new String[] { "\u0041\u0300" });
+
+    // ÷ 0041 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0300",
+                     new String[] { "\u0041\u0308\u0300" });
+
+    // ÷ 0041 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u2060",
+                     new String[] { "\u0041\u0061\u2060" });
+
+    // ÷ 0041 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u2060",
+                     new String[] { "\u0041\u0308\u0061\u2060" });
+
+    // ÷ 0041 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u003A",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u003A",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027\u2060",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u002C",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u002C",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u003A",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u003A",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u0027",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u0027",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u002C",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002C",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u002E\u2060",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0001",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\r",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\r",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\n",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\n",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u000B",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 003A ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u003A",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u002C",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0027",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 003A ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u005F",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 003A × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u00AD",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 003A × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0300",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0001",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\r",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\r",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\n",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\n",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u000B",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002C ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u003A",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u002C",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0027",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002C ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u005F",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 002C × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u00AD",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 002C × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0300",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0001",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\r",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\n",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u000B",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u003A",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u002C",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0027",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u005F",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0027 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u00AD",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0027 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0300",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0030 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0001",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0001",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\r",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\r",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\n",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\n",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u000B",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u000B",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u3031",
+                     new String[] { "\u0030", "\u3031" });
+
+    // ÷ 0030 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u3031",
+                     new String[] { "\u0030\u0308", "\u3031" });
+
+    // ÷ 0030 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0041",
+                     new String[] { "\u0030\u0041" });
+
+    // ÷ 0030 × 0308 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0041",
+                     new String[] { "\u0030\u0308\u0041" });
+
+    // ÷ 0030 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u003A",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u003A",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u002C",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u002C",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0027",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0027",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0030",
+                     new String[] { "\u0030\u0030" });
+
+    // ÷ 0030 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0030",
+                     new String[] { "\u0030\u0308\u0030" });
+
+    // ÷ 0030 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u005F",
+                     new String[] { "\u0030\u005F" });
+
+    // ÷ 0030 × 0308 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u005F",
+                     new String[] { "\u0030\u0308\u005F" });
+
+    // ÷ 0030 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u00AD",
+                     new String[] { "\u0030\u00AD" });
+
+    // ÷ 0030 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u00AD",
+                     new String[] { "\u0030\u0308\u00AD" });
+
+    // ÷ 0030 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0300",
+                     new String[] { "\u0030\u0300" });
+
+    // ÷ 0030 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0300",
+                     new String[] { "\u0030\u0308\u0300" });
+
+    // ÷ 0030 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u2060",
+                     new String[] { "\u0030\u0061\u2060" });
+
+    // ÷ 0030 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u2060",
+                     new String[] { "\u0030\u0308\u0061\u2060" });
+
+    // ÷ 0030 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u003A",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u003A",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027\u2060",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u002C",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u002C",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u003A",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u003A",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u0027",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u0027",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u002C",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002C",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u002E\u2060",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 005F ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0001",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\r",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\r",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\n",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\n",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u000B",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 005F × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u3031",
+                     new String[] { "\u005F\u3031" });
+
+    // ÷ 005F × 0308 × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u3031",
+                     new String[] { "\u005F\u0308\u3031" });
+
+    // ÷ 005F × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0041",
+                     new String[] { "\u005F\u0041" });
+
+    // ÷ 005F × 0308 × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0041",
+                     new String[] { "\u005F\u0308\u0041" });
+
+    // ÷ 005F ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u003A",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u002C",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0027",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 005F × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0030",
+                     new String[] { "\u005F\u0030" });
+
+    // ÷ 005F × 0308 × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0030",
+                     new String[] { "\u005F\u0308\u0030" });
+
+    // ÷ 005F × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u005F",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 005F × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u00AD",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 005F × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0300",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 005F × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u2060",
+                     new String[] { "\u005F\u0061\u2060" });
+
+    // ÷ 005F × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u2060",
+                     new String[] { "\u005F\u0308\u0061\u2060" });
+
+    // ÷ 005F × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u003A",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u003A",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027\u2060",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027\u2060",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u002C",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u002C",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u003A",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u003A",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u0027",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u0027",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u002C",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002C",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u002E\u2060",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002E\u2060",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 00AD ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0001",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\r",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\r",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\n",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\n",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u000B",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 00AD × 0308 ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 00AD ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 00AD × 0308 ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 00AD ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u003A",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u002C",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0027",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 00AD × 0308 ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 00AD ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u005F",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 00AD × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u00AD",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 00AD × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0300",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 00AD × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 00AD ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0001",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\r",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\n",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u000B",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0300 × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0300 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0300 × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0300 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u003A",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u002C",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0027",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0300 × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0300 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u005F",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0300 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u00AD",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0300 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0300",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0300 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0300 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0061 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0001",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0001",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\r",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\r",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\n",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\n",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u000B",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u000B",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u3031",
+                     new String[] { "\u0061\u2060", "\u3031" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u3031",
+                     new String[] { "\u0061\u2060\u0308", "\u3031" });
+
+    // ÷ 0061 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0041",
+                     new String[] { "\u0061\u2060\u0041" });
+
+    // ÷ 0061 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0041",
+                     new String[] { "\u0061\u2060\u0308\u0041" });
+
+    // ÷ 0061 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u003A",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u003A",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u002C",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u002C",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0027",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0027",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0030",
+                     new String[] { "\u0061\u2060\u0030" });
+
+    // ÷ 0061 × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0030",
+                     new String[] { "\u0061\u2060\u0308\u0030" });
+
+    // ÷ 0061 × 2060 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u005F",
+                     new String[] { "\u0061\u2060\u005F" });
+
+    // ÷ 0061 × 2060 × 0308 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u005F",
+                     new String[] { "\u0061\u2060\u0308\u005F" });
+
+    // ÷ 0061 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u00AD",
+                     new String[] { "\u0061\u2060\u00AD" });
+
+    // ÷ 0061 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u00AD",
+                     new String[] { "\u0061\u2060\u0308\u00AD" });
+
+    // ÷ 0061 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0300",
+                     new String[] { "\u0061\u2060\u0300" });
+
+    // ÷ 0061 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0300",
+                     new String[] { "\u0061\u2060\u0308\u0300" });
+
+    // ÷ 0061 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u2060",
+                     new String[] { "\u0061\u2060\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u003A",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u002C",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u003A",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u0027",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002C",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 003A × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0041",
+                     new String[] { "\u0061\u003A\u0041" });
+
+    // ÷ 0061 × 003A × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0041",
+                     new String[] { "\u0061\u003A\u0308\u0041" });
+
+    // ÷ 0061 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 003A × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u2060",
+                     new String[] { "\u0061\u003A\u0061\u2060" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0061\u003A\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u003A",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u002C",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 0027 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0041",
+                     new String[] { "\u0061\u0027\u0041" });
+
+    // ÷ 0061 × 0027 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0041",
+                     new String[] { "\u0061\u0027\u0308\u0041" });
+
+    // ÷ 0061 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u2060",
+                     new String[] { "\u0061\u0027\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0061\u0027\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u003A",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u002C",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 0027 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0041",
+                     new String[] { "\u0061\u0027\u2060\u0041" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0041",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0041" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u003A",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u002C",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0041",
+                     new String[] { "\u0061", "\u0041" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0041",
+                     new String[] { "\u0061", "\u0041" });
+
+    // ÷ 0061 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u2060",
+                     new String[] { "\u0061", "\u0061\u2060" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0061", "\u0061\u2060" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u003A",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u002C",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0030",
+                     new String[] { "\u0031", "\u0030" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0030",
+                     new String[] { "\u0031", "\u0030" });
+
+    // ÷ 0031 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u003A",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u0027",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002C",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 0027 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0030",
+                     new String[] { "\u0031\u0027\u0030" });
+
+    // ÷ 0031 × 0027 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0030",
+                     new String[] { "\u0031\u0027\u0308\u0030" });
+
+    // ÷ 0031 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u003A",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u0027",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002C",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 002C × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0030",
+                     new String[] { "\u0031\u002C\u0030" });
+
+    // ÷ 0031 × 002C × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0030",
+                     new String[] { "\u0031\u002C\u0308\u0030" });
+
+    // ÷ 0031 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u003A",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u0027",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002C",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0030",
+                     new String[] { "\u0031\u002E\u2060\u0030" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0030",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0030" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u003A",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u0027",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002C",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0063 × 0061 × 006E × 0027 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] APOSTROPHE (MidNumLet) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u0027\u0074",
+                     new String[] { "\u0063\u0061\u006E\u0027\u0074" });
+
+    // ÷ 0063 × 0061 × 006E × 2019 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u2019\u0074",
+                     new String[] { "\u0063\u0061\u006E\u2019\u0074" });
+
+    // ÷ 0061 × 0062 × 00AD × 0062 × 0079 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] SOFT HYPHEN (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [5.0] LATIN SMALL LETTER Y (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0062\u00AD\u0062\u0079",
+                     new String[] { "\u0061\u0062\u00AD\u0062\u0079" });
+
+    // ÷ 0061 ÷ 0024 ÷ 002D ÷ 0033 × 0034 × 002C × 0035 × 0036 × 0037 × 002E × 0031 × 0034 ÷ 0025 ÷ 0062 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] DOLLAR SIGN (Other) ÷ [999.0] HYPHEN-MINUS (Other) ÷ [999.0] DIGIT THREE (Numeric) × [8.0] DIGIT FOUR (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT FIVE (Numeric) × [8.0] DIGIT SIX (Numeric) × [8.0] DIGIT SEVEN (Numeric) × [12.0] FULL STOP (MidNumLet) × [11.0] DIGIT ONE (Numeric) × [8.0] DIGIT FOUR (Numeric) ÷ [999.0] PERCENT SIGN (Other) ÷ [999.0] LATIN SMALL LETTER B (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0024\u002D\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034\u0025\u0062",
+                     new String[] { "\u0061", "\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034", "\u0062" });
+
+    // ÷ 0033 × 0061 ÷  #  ÷ [0.2] DIGIT THREE (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0033\u0061",
+                     new String[] { "\u0033\u0061" });
+
+    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 0027 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] APOSTROPHE (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060",
+                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 2019 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060",
+                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0061 × 2060 × 0062 × 2060 × 00AD × 2060 × 0062 × 2060 × 0079 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER Y (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060",
+                     new String[] { "\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0061 × 2060 ÷ 0024 × 2060 ÷ 002D × 2060 ÷ 0033 × 2060 × 0034 × 2060 × 002C × 2060 × 0035 × 2060 × 0036 × 2060 × 0037 × 2060 × 002E × 2060 × 0031 × 2060 × 0034 × 2060 ÷ 0025 × 2060 ÷ 0062 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DOLLAR SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] HYPHEN-MINUS (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] COMMA (MidNum) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT FIVE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SIX (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SEVEN (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] PERCENT SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0024\u2060\u002D\u2060\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060\u0025\u2060\u0062\u2060\u2060",
+                     new String[] { "\u0061\u2060", "\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060", "\u0062\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0033 × 2060 × 0061 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0033\u2060\u0061\u2060\u2060",
+                     new String[] { "\u0033\u2060\u0061\u2060\u2060" });
+
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_3_0.java lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_3_0.java
new file mode 100644
index 0000000..f4b2276
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/WordBreakTestUnicode_6_3_0.java
@@ -0,0 +1,5537 @@
+package org.apache.lucene.analysis.standard;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.junit.Ignore;
+
+/**
+ * This class was automatically generated by generateJavaUnicodeWordBreakTest.pl
+ * from: http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakTest.txt
+ *
+ * WordBreakTest.txt indicates the points in the provided character sequences
+ * at which conforming implementations must and must not break words.  This
+ * class tests for expected token extraction from each of the test sequences
+ * in WordBreakTest.txt, where the expected tokens are those character
+ * sequences bounded by word breaks and containing at least one character
+ * from one of the following character sets:
+ *
+ *    \p{Script = Han}                (From http://www.unicode.org/Public/6.3.0/ucd/Scripts.txt)
+ *    \p{Script = Hiragana}
+ *    \p{LineBreak = Complex_Context} (From http://www.unicode.org/Public/6.3.0/ucd/LineBreak.txt)
+ *    \p{WordBreak = ALetter}         (From http://www.unicode.org/Public/6.3.0/ucd/auxiliary/WordBreakProperty.txt)
+ *    \p{WordBreak = Hebrew_Letter}
+ *    \p{WordBreak = Katakana}
+ *    \p{WordBreak = Numeric}         (Excludes full-width Arabic digits)
+ *    [\uFF10-\uFF19]                (Full-width Arabic digits)
+ */
+@Ignore
+public class WordBreakTestUnicode_6_3_0 extends BaseTokenStreamTestCase {
+
+  public void test(Analyzer analyzer) throws Exception {
+    // ÷ 0001 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0001",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 0001 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\r",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000D ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\n",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u000B",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 000B ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0001 × 0308 ÷ 3031 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0001 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0001 × 0308 ÷ 0041 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0001 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u003A",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u002C",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 002E ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u002E",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 002E ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0001 × 0308 ÷ 0030 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0001 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u005F",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 005F ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 1F1E6 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 05D0 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0001 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0001 ÷ 0022 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\"",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 0022 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\"",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0027",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0001 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u00AD",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 × 00AD ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0001 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0300",
+                     new String[] {  });
+
+    // ÷ 0001 × 0308 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0001 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0001 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0001 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0001 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0001 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0001\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0001",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\r",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000D × 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) × [3.0] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\n",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u000B",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000D ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000D ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000D ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000D ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u003A",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u002C",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 002E ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u002E",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000D ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000D ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u005F",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 1F1E6 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 05D0 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000D ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000D ÷ 0022 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\"",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\"",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0027",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u00AD",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 × 00AD ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0300",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0308 × 0300 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000D ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000D ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000D ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000D ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <CARRIAGE RETURN (CR)> (CR) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\r\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0001",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\r",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\n",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u000B",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000A ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000A ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000A ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000A ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u003A",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u002C",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 002E ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u002E",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000A ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000A ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u005F",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 05D0 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000A ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000A ÷ 0022 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\"",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\"",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0027",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u00AD",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0300",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000A ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000A ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE FEED (LF)> (LF) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\n\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0001",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 0001 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\r",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000D ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\r",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\n",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\n",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u000B",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 000B ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000B ÷ 0308 ÷ 3031 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 000B ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000B ÷ 0308 ÷ 0041 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 000B ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u003A",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u002C",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 002E ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u002E",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 002E ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000B ÷ 0308 ÷ 0030 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 000B ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u005F",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 005F ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 05D0 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000B ÷ 0308 ÷ 05D0 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 000B ÷ 0022 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\"",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 0022 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\"",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0027",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u00AD",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 × 00AD ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0300",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0308 × 0300 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 000B ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 000B ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 000B ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 000B ÷ 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] <LINE TABULATION> (Newline) ÷ [3.1] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u000B\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 3031 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0001",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 0001 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0001",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\r",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000D ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\r",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\n",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\n",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u000B",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 000B ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u000B",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u3031",
+                     new String[] { "\u3031\u3031" });
+
+    // ÷ 3031 × 0308 × 3031 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u3031",
+                     new String[] { "\u3031\u0308\u3031" });
+
+    // ÷ 3031 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0041",
+                     new String[] { "\u3031", "\u0041" });
+
+    // ÷ 3031 × 0308 ÷ 0041 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0041",
+                     new String[] { "\u3031\u0308", "\u0041" });
+
+    // ÷ 3031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u003A",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u003A",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u002C",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u002C",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 002E ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u002E",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 002E ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u002E",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0030",
+                     new String[] { "\u3031", "\u0030" });
+
+    // ÷ 3031 × 0308 ÷ 0030 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0030",
+                     new String[] { "\u3031\u0308", "\u0030" });
+
+    // ÷ 3031 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u005F",
+                     new String[] { "\u3031\u005F" });
+
+    // ÷ 3031 × 0308 × 005F ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u005F",
+                     new String[] { "\u3031\u0308\u005F" });
+
+    // ÷ 3031 ÷ 1F1E6 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\uD83C\uDDE6",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\uD83C\uDDE6",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 05D0 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u05D0",
+                     new String[] { "\u3031", "\u05D0" });
+
+    // ÷ 3031 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u05D0",
+                     new String[] { "\u3031\u0308", "\u05D0" });
+
+    // ÷ 3031 ÷ 0022 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\"",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 0022 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\"",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0027",
+                     new String[] { "\u3031" });
+
+    // ÷ 3031 × 0308 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0027",
+                     new String[] { "\u3031\u0308" });
+
+    // ÷ 3031 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u00AD",
+                     new String[] { "\u3031\u00AD" });
+
+    // ÷ 3031 × 0308 × 00AD ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u00AD",
+                     new String[] { "\u3031\u0308\u00AD" });
+
+    // ÷ 3031 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0300",
+                     new String[] { "\u3031\u0300" });
+
+    // ÷ 3031 × 0308 × 0300 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0300",
+                     new String[] { "\u3031\u0308\u0300" });
+
+    // ÷ 3031 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u2060",
+                     new String[] { "\u3031", "\u0061\u2060" });
+
+    // ÷ 3031 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u2060",
+                     new String[] { "\u3031\u0308", "\u0061\u2060" });
+
+    // ÷ 3031 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u003A",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u003A",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u0027\u2060",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u0027\u2060",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0061\u002C",
+                     new String[] { "\u3031", "\u0061" });
+
+    // ÷ 3031 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0061\u002C",
+                     new String[] { "\u3031\u0308", "\u0061" });
+
+    // ÷ 3031 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u003A",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u003A",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u0027",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u0027",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u002C",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002C",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 3031 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0031\u002E\u2060",
+                     new String[] { "\u3031", "\u0031" });
+
+    // ÷ 3031 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] VERTICAL KANA REPEAT MARK (Katakana) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u3031\u0308\u0031\u002E\u2060",
+                     new String[] { "\u3031\u0308", "\u0031" });
+
+    // ÷ 0041 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0001",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0001",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\r",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\r",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\n",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\n",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u000B",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u000B",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u3031",
+                     new String[] { "\u0041", "\u3031" });
+
+    // ÷ 0041 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u3031",
+                     new String[] { "\u0041\u0308", "\u3031" });
+
+    // ÷ 0041 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0041",
+                     new String[] { "\u0041\u0041" });
+
+    // ÷ 0041 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0041",
+                     new String[] { "\u0041\u0308\u0041" });
+
+    // ÷ 0041 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u003A",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u003A",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u002C",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u002C",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 002E ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u002E",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u002E",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0030",
+                     new String[] { "\u0041\u0030" });
+
+    // ÷ 0041 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0030",
+                     new String[] { "\u0041\u0308\u0030" });
+
+    // ÷ 0041 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u005F",
+                     new String[] { "\u0041\u005F" });
+
+    // ÷ 0041 × 0308 × 005F ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u005F",
+                     new String[] { "\u0041\u0308\u005F" });
+
+    // ÷ 0041 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\uD83C\uDDE6",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\uD83C\uDDE6",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 × 05D0 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u05D0",
+                     new String[] { "\u0041\u05D0" });
+
+    // ÷ 0041 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u05D0",
+                     new String[] { "\u0041\u0308\u05D0" });
+
+    // ÷ 0041 ÷ 0022 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\"",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\"",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0027",
+                     new String[] { "\u0041" });
+
+    // ÷ 0041 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0027",
+                     new String[] { "\u0041\u0308" });
+
+    // ÷ 0041 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u00AD",
+                     new String[] { "\u0041\u00AD" });
+
+    // ÷ 0041 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u00AD",
+                     new String[] { "\u0041\u0308\u00AD" });
+
+    // ÷ 0041 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0300",
+                     new String[] { "\u0041\u0300" });
+
+    // ÷ 0041 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0300",
+                     new String[] { "\u0041\u0308\u0300" });
+
+    // ÷ 0041 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u2060",
+                     new String[] { "\u0041\u0061\u2060" });
+
+    // ÷ 0041 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u2060",
+                     new String[] { "\u0041\u0308\u0061\u2060" });
+
+    // ÷ 0041 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u003A",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u003A",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u0027\u2060",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0061\u002C",
+                     new String[] { "\u0041\u0061" });
+
+    // ÷ 0041 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0061\u002C",
+                     new String[] { "\u0041\u0308\u0061" });
+
+    // ÷ 0041 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u003A",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u003A",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u0027",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u0027",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u002C",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002C",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 0041 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0031\u002E\u2060",
+                     new String[] { "\u0041\u0031" });
+
+    // ÷ 0041 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0041\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0041\u0308\u0031" });
+
+    // ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0001",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\r",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\r",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\n",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\n",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u000B",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 003A ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u003A",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u002C",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 002E ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u002E",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 003A ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u005F",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 05D0 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 003A × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\"",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\"",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0027",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 003A × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u00AD",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 003A × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0300",
+                     new String[] {  });
+
+    // ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0001",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\r",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\r",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\n",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\n",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u000B",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002C ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u003A",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u002C",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 002E ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u002E",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002C ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u005F",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\"",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\"",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0027",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 002C × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u00AD",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 002C × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0300",
+                     new String[] {  });
+
+    // ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E ÷ 0001 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0001",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 0001 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 000D ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\r",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 000D ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\r",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 000A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\n",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 000A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\n",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 000B ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u000B",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 000B ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 3031 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002E × 0308 ÷ 3031 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 002E ÷ 0041 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002E × 0308 ÷ 0041 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 002E ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u003A",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u002C",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 002E ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u002E",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 002E ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 0030 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002E × 0308 ÷ 0030 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 002E ÷ 005F ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u005F",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 005F ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 1F1E6 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 05D0 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 002E × 0308 ÷ 05D0 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 002E ÷ 0022 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\"",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 0022 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\"",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0027",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 002E × 00AD ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u00AD",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 × 00AD ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 002E × 0300 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0300",
+                     new String[] {  });
+
+    // ÷ 002E × 0308 × 0300 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 002E ÷ 0061 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002E × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 002E ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 002E ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 002E × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] FULL STOP (MidNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u002E\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0030 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0001",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0001",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\r",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\r",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\n",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\n",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u000B",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u000B",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u3031",
+                     new String[] { "\u0030", "\u3031" });
+
+    // ÷ 0030 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u3031",
+                     new String[] { "\u0030\u0308", "\u3031" });
+
+    // ÷ 0030 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0041",
+                     new String[] { "\u0030\u0041" });
+
+    // ÷ 0030 × 0308 × 0041 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0041",
+                     new String[] { "\u0030\u0308\u0041" });
+
+    // ÷ 0030 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u003A",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u003A",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u002C",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u002C",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 002E ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u002E",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u002E",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0030",
+                     new String[] { "\u0030\u0030" });
+
+    // ÷ 0030 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0030",
+                     new String[] { "\u0030\u0308\u0030" });
+
+    // ÷ 0030 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u005F",
+                     new String[] { "\u0030\u005F" });
+
+    // ÷ 0030 × 0308 × 005F ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u005F",
+                     new String[] { "\u0030\u0308\u005F" });
+
+    // ÷ 0030 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\uD83C\uDDE6",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\uD83C\uDDE6",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 × 05D0 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u05D0",
+                     new String[] { "\u0030\u05D0" });
+
+    // ÷ 0030 × 0308 × 05D0 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u05D0",
+                     new String[] { "\u0030\u0308\u05D0" });
+
+    // ÷ 0030 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\"",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\"",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0027",
+                     new String[] { "\u0030" });
+
+    // ÷ 0030 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0027",
+                     new String[] { "\u0030\u0308" });
+
+    // ÷ 0030 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u00AD",
+                     new String[] { "\u0030\u00AD" });
+
+    // ÷ 0030 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u00AD",
+                     new String[] { "\u0030\u0308\u00AD" });
+
+    // ÷ 0030 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0300",
+                     new String[] { "\u0030\u0300" });
+
+    // ÷ 0030 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0300",
+                     new String[] { "\u0030\u0308\u0300" });
+
+    // ÷ 0030 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u2060",
+                     new String[] { "\u0030\u0061\u2060" });
+
+    // ÷ 0030 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u2060",
+                     new String[] { "\u0030\u0308\u0061\u2060" });
+
+    // ÷ 0030 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u003A",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u003A",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u0027\u2060",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0061\u002C",
+                     new String[] { "\u0030\u0061" });
+
+    // ÷ 0030 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0061\u002C",
+                     new String[] { "\u0030\u0308\u0061" });
+
+    // ÷ 0030 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u003A",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u003A",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u0027",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u0027",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u002C",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002C",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 0030 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0031\u002E\u2060",
+                     new String[] { "\u0030\u0031" });
+
+    // ÷ 0030 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ZERO (Numeric) × [4.0] COMBINING DIAERESIS (Extend_FE) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0030\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0030\u0308\u0031" });
+
+    // ÷ 005F ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0001",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 0001 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\r",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000D ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\r",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\n",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\n",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u000B",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 000B ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 005F × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u3031",
+                     new String[] { "\u005F\u3031" });
+
+    // ÷ 005F × 0308 × 3031 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u3031",
+                     new String[] { "\u005F\u0308\u3031" });
+
+    // ÷ 005F × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0041",
+                     new String[] { "\u005F\u0041" });
+
+    // ÷ 005F × 0308 × 0041 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0041",
+                     new String[] { "\u005F\u0308\u0041" });
+
+    // ÷ 005F ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u003A",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u002C",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 002E ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u002E",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 002E ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 005F × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0030",
+                     new String[] { "\u005F\u0030" });
+
+    // ÷ 005F × 0308 × 0030 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0030",
+                     new String[] { "\u005F\u0308\u0030" });
+
+    // ÷ 005F × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u005F",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 005F ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 1F1E6 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 005F × 05D0 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u05D0",
+                     new String[] { "\u005F\u05D0" });
+
+    // ÷ 005F × 0308 × 05D0 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u05D0",
+                     new String[] { "\u005F\u0308\u05D0" });
+
+    // ÷ 005F ÷ 0022 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\"",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 0022 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\"",
+                     new String[] {  });
+
+    // ÷ 005F ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0027",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 005F × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u00AD",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 00AD ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 005F × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0300",
+                     new String[] {  });
+
+    // ÷ 005F × 0308 × 0300 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 005F × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u2060",
+                     new String[] { "\u005F\u0061\u2060" });
+
+    // ÷ 005F × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u2060",
+                     new String[] { "\u005F\u0308\u0061\u2060" });
+
+    // ÷ 005F × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u003A",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u003A",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u0027\u2060",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u0027\u2060",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0061\u002C",
+                     new String[] { "\u005F\u0061" });
+
+    // ÷ 005F × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0061\u002C",
+                     new String[] { "\u005F\u0308\u0061" });
+
+    // ÷ 005F × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u003A",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u003A",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u0027",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u0027",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u002C",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002C",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 005F × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0031\u002E\u2060",
+                     new String[] { "\u005F\u0031" });
+
+    // ÷ 005F × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LOW LINE (ExtendNumLet) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u005F\u0308\u0031\u002E\u2060",
+                     new String[] { "\u005F\u0308\u0031" });
+
+    // ÷ 1F1E6 ÷ 0001 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0001",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 0001 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 000D ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\r",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 000D ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\r",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 000A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\n",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 000A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\n",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 000B ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u000B",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 000B ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 3031 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 1F1E6 × 0308 ÷ 3031 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 1F1E6 ÷ 0041 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0041 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 1F1E6 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u003A",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u002C",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 002E ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u002E",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 002E ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 0030 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0030 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 1F1E6 ÷ 005F ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u005F",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 005F ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 1F1E6 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 × 1F1E6 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 05D0 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 1F1E6 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 1F1E6 ÷ 0022 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\"",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 0022 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\"",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0027",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 00AD ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u00AD",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 × 00AD ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0300 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0300",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 0308 × 0300 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 1F1E6 ÷ 0061 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 1F1E6 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 1F1E6 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 1F1E6 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 05D0 ÷ 0001 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0001",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 0001 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0001",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 000D ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\r",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 000D ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\r",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 000A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\n",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 000A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\n",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 000B ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u000B",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 000B ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u000B",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 3031 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u3031",
+                     new String[] { "\u05D0", "\u3031" });
+
+    // ÷ 05D0 × 0308 ÷ 3031 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u3031",
+                     new String[] { "\u05D0\u0308", "\u3031" });
+
+    // ÷ 05D0 × 0041 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0041",
+                     new String[] { "\u05D0\u0041" });
+
+    // ÷ 05D0 × 0308 × 0041 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0041",
+                     new String[] { "\u05D0\u0308\u0041" });
+
+    // ÷ 05D0 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u003A",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u003A",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u002C",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u002C",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 ÷ 002E ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u002E",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 002E ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u002E",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 × 0030 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0030",
+                     new String[] { "\u05D0\u0030" });
+
+    // ÷ 05D0 × 0308 × 0030 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0030",
+                     new String[] { "\u05D0\u0308\u0030" });
+
+    // ÷ 05D0 × 005F ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u005F",
+                     new String[] { "\u05D0\u005F" });
+
+    // ÷ 05D0 × 0308 × 005F ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u005F",
+                     new String[] { "\u05D0\u0308\u005F" });
+
+    // ÷ 05D0 ÷ 1F1E6 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\uD83C\uDDE6",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\uD83C\uDDE6",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 × 05D0 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u05D0",
+                     new String[] { "\u05D0\u05D0" });
+
+    // ÷ 05D0 × 0308 × 05D0 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u05D0",
+                     new String[] { "\u05D0\u0308\u05D0" });
+
+    // ÷ 05D0 ÷ 0022 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\"",
+                     new String[] { "\u05D0" });
+
+    // ÷ 05D0 × 0308 ÷ 0022 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\"",
+                     new String[] { "\u05D0\u0308" });
+
+    // ÷ 05D0 × 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [7.1] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0027",
+                     new String[] { "\u05D0\u0027" });
+
+    // ÷ 05D0 × 0308 × 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.1] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0027",
+                     new String[] { "\u05D0\u0308\u0027" });
+
+    // ÷ 05D0 × 00AD ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u00AD",
+                     new String[] { "\u05D0\u00AD" });
+
+    // ÷ 05D0 × 0308 × 00AD ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u00AD",
+                     new String[] { "\u05D0\u0308\u00AD" });
+
+    // ÷ 05D0 × 0300 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0300",
+                     new String[] { "\u05D0\u0300" });
+
+    // ÷ 05D0 × 0308 × 0300 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0300",
+                     new String[] { "\u05D0\u0308\u0300" });
+
+    // ÷ 05D0 × 0061 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0061\u2060",
+                     new String[] { "\u05D0\u0061\u2060" });
+
+    // ÷ 05D0 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u2060",
+                     new String[] { "\u05D0\u0308\u0061\u2060" });
+
+    // ÷ 05D0 × 0061 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0061\u003A",
+                     new String[] { "\u05D0\u0061" });
+
+    // ÷ 05D0 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u003A",
+                     new String[] { "\u05D0\u0308\u0061" });
+
+    // ÷ 05D0 × 0061 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0061\u0027",
+                     new String[] { "\u05D0\u0061" });
+
+    // ÷ 05D0 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u0027",
+                     new String[] { "\u05D0\u0308\u0061" });
+
+    // ÷ 05D0 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0061\u0027\u2060",
+                     new String[] { "\u05D0\u0061" });
+
+    // ÷ 05D0 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u0027\u2060",
+                     new String[] { "\u05D0\u0308\u0061" });
+
+    // ÷ 05D0 × 0061 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0061\u002C",
+                     new String[] { "\u05D0\u0061" });
+
+    // ÷ 05D0 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0061\u002C",
+                     new String[] { "\u05D0\u0308\u0061" });
+
+    // ÷ 05D0 × 0031 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0031\u003A",
+                     new String[] { "\u05D0\u0031" });
+
+    // ÷ 05D0 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u003A",
+                     new String[] { "\u05D0\u0308\u0031" });
+
+    // ÷ 05D0 × 0031 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0031\u0027",
+                     new String[] { "\u05D0\u0031" });
+
+    // ÷ 05D0 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u0027",
+                     new String[] { "\u05D0\u0308\u0031" });
+
+    // ÷ 05D0 × 0031 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0031\u002C",
+                     new String[] { "\u05D0\u0031" });
+
+    // ÷ 05D0 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u002C",
+                     new String[] { "\u05D0\u0308\u0031" });
+
+    // ÷ 05D0 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0031\u002E\u2060",
+                     new String[] { "\u05D0\u0031" });
+
+    // ÷ 05D0 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] HEBREW LETTER ALEF (Hebrew_Letter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u05D0\u0308\u0031\u002E\u2060",
+                     new String[] { "\u05D0\u0308\u0031" });
+
+    // ÷ 0022 ÷ 0001 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0001",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 0001 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 000D ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\r",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 000D ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 000A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\n",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 000A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 000B ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u000B",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 000B ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 3031 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0022 × 0308 ÷ 3031 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0022 ÷ 0041 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0022 × 0308 ÷ 0041 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0022 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u003A",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u002C",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 002E ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u002E",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 002E ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 0030 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0022 × 0308 ÷ 0030 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0022 ÷ 005F ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u005F",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 005F ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 1F1E6 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 05D0 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0022 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0022 ÷ 0022 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\"",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 0022 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\"",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0027",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0022 × 00AD ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u00AD",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 × 00AD ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0022 × 0300 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0300",
+                     new String[] {  });
+
+    // ÷ 0022 × 0308 × 0300 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0022 ÷ 0061 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0022 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0022 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0022 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0022 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] QUOTATION MARK (Double_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\"\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0001",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\r",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\n",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u000B",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u003A",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u002C",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u002E",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u005F",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 05D0 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0027 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\"",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\"",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0027",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0027 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u00AD",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0027 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0300",
+                     new String[] {  });
+
+    // ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0001",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 0001 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\r",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000D ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\r",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\n",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\n",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u000B",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 000B ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 00AD × 0308 ÷ 3031 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 00AD ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 00AD × 0308 ÷ 0041 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 00AD ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u003A",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u002C",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 002E ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u002E",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 002E ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 00AD × 0308 ÷ 0030 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 00AD ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u005F",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 005F ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 1F1E6 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 05D0 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 00AD × 0308 ÷ 05D0 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 00AD ÷ 0022 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\"",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 0022 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\"",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0027",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 00AD × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u00AD",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 × 00AD ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 00AD × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0300",
+                     new String[] {  });
+
+    // ÷ 00AD × 0308 × 0300 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 00AD ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 00AD × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 00AD ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 00AD ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 00AD × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] SOFT HYPHEN (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u00AD\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0001",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 0001 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0001",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\r",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000D ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\r",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\n",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\n",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u000B",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 000B ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u000B",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0300 × 0308 ÷ 3031 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u3031",
+                     new String[] { "\u3031" });
+
+    // ÷ 0300 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0300 × 0308 ÷ 0041 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0041",
+                     new String[] { "\u0041" });
+
+    // ÷ 0300 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u003A",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u003A",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u002C",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u002C",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 002E ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u002E",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 002E ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u002E",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0300 × 0308 ÷ 0030 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0030",
+                     new String[] { "\u0030" });
+
+    // ÷ 0300 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u005F",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 005F ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u005F",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 1F1E6 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\uD83C\uDDE6",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 05D0 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0300 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u05D0",
+                     new String[] { "\u05D0" });
+
+    // ÷ 0300 ÷ 0022 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\"",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 0022 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\"",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0027",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0027",
+                     new String[] {  });
+
+    // ÷ 0300 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u00AD",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 × 00AD ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u00AD",
+                     new String[] {  });
+
+    // ÷ 0300 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0300",
+                     new String[] {  });
+
+    // ÷ 0300 × 0308 × 0300 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0300",
+                     new String[] {  });
+
+    // ÷ 0300 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0300 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0300 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0061\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0300 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0300 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] COMBINING GRAVE ACCENT (Extend_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0300\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031" });
+
+    // ÷ 0061 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0001",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0001",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\r",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\r",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\n",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\n",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u000B",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u000B",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u3031",
+                     new String[] { "\u0061\u2060", "\u3031" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u3031",
+                     new String[] { "\u0061\u2060\u0308", "\u3031" });
+
+    // ÷ 0061 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0041",
+                     new String[] { "\u0061\u2060\u0041" });
+
+    // ÷ 0061 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0041",
+                     new String[] { "\u0061\u2060\u0308\u0041" });
+
+    // ÷ 0061 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u003A",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u003A",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u002C",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u002C",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u002E",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u002E",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0030",
+                     new String[] { "\u0061\u2060\u0030" });
+
+    // ÷ 0061 × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0030",
+                     new String[] { "\u0061\u2060\u0308\u0030" });
+
+    // ÷ 0061 × 2060 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u005F",
+                     new String[] { "\u0061\u2060\u005F" });
+
+    // ÷ 0061 × 2060 × 0308 × 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [13.1] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u005F",
+                     new String[] { "\u0061\u2060\u0308\u005F" });
+
+    // ÷ 0061 × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\uD83C\uDDE6",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\uD83C\uDDE6",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u05D0",
+                     new String[] { "\u0061\u2060\u05D0" });
+
+    // ÷ 0061 × 2060 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u05D0",
+                     new String[] { "\u0061\u2060\u0308\u05D0" });
+
+    // ÷ 0061 × 2060 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\"",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\"",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0027",
+                     new String[] { "\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0027",
+                     new String[] { "\u0061\u2060\u0308" });
+
+    // ÷ 0061 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u00AD",
+                     new String[] { "\u0061\u2060\u00AD" });
+
+    // ÷ 0061 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u00AD",
+                     new String[] { "\u0061\u2060\u0308\u00AD" });
+
+    // ÷ 0061 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0300",
+                     new String[] { "\u0061\u2060\u0300" });
+
+    // ÷ 0061 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0300",
+                     new String[] { "\u0061\u2060\u0308\u0300" });
+
+    // ÷ 0061 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u2060",
+                     new String[] { "\u0061\u2060\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u003A",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0061\u002C",
+                     new String[] { "\u0061\u2060\u0061" });
+
+    // ÷ 0061 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [5.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0061\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u003A",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u0027",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002C",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0061\u2060\u0031" });
+
+    // ÷ 0061 × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [9.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061\u2060\u0308\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 003A × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0041",
+                     new String[] { "\u0061\u003A\u0041" });
+
+    // ÷ 0061 × 003A × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0041",
+                     new String[] { "\u0061\u003A\u0308\u0041" });
+
+    // ÷ 0061 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 003A × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u05D0",
+                     new String[] { "\u0061\u003A\u05D0" });
+
+    // ÷ 0061 × 003A × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u05D0",
+                     new String[] { "\u0061\u003A\u0308\u05D0" });
+
+    // ÷ 0061 ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 003A × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u2060",
+                     new String[] { "\u0061\u003A\u0061\u2060" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0061\u003A\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u003A",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 × 003A × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0061\u002C",
+                     new String[] { "\u0061\u003A\u0061" });
+
+    // ÷ 0061 × 003A × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0061\u003A\u0308\u0061" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 0027 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0041",
+                     new String[] { "\u0061\u0027\u0041" });
+
+    // ÷ 0061 × 0027 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0041",
+                     new String[] { "\u0061\u0027\u0308\u0041" });
+
+    // ÷ 0061 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u05D0",
+                     new String[] { "\u0061\u0027\u05D0" });
+
+    // ÷ 0061 × 0027 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u05D0",
+                     new String[] { "\u0061\u0027\u0308\u05D0" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u2060",
+                     new String[] { "\u0061\u0027\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0061\u0027\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u003A",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0061\u002C",
+                     new String[] { "\u0061\u0027\u0061" });
+
+    // ÷ 0061 × 0027 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0061\u0027\u0308\u0061" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 × 0027 × 2060 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0041",
+                     new String[] { "\u0061\u0027\u2060\u0041" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0041",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0041" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u05D0",
+                     new String[] { "\u0061\u0027\u2060\u05D0" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u05D0",
+                     new String[] { "\u0061\u0027\u2060\u0308\u05D0" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061\u2060" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u003A",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0061\u002C",
+                     new String[] { "\u0061\u0027\u2060\u0061" });
+
+    // ÷ 0061 × 0027 × 2060 × 0308 × 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [7.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0061\u0027\u2060\u0308\u0061" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 0027 × 2060 × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0027\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0001",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\r",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\n",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u000B",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u3031",
+                     new String[] { "\u0061", "\u3031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0041",
+                     new String[] { "\u0061", "\u0041" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0041",
+                     new String[] { "\u0061", "\u0041" });
+
+    // ÷ 0061 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u003A",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u002C",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u002E",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0030 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0030",
+                     new String[] { "\u0061", "\u0030" });
+
+    // ÷ 0061 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u005F",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\uD83C\uDDE6",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u05D0",
+                     new String[] { "\u0061", "\u05D0" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u05D0",
+                     new String[] { "\u0061", "\u05D0" });
+
+    // ÷ 0061 ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\"",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0027",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u00AD",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0300",
+                     new String[] { "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u2060",
+                     new String[] { "\u0061", "\u0061\u2060" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0061", "\u0061\u2060" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u003A",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0061\u002C",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0061", "\u0061" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0061 ÷ 002C × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0061", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 003A ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0030",
+                     new String[] { "\u0031", "\u0030" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0030",
+                     new String[] { "\u0031", "\u0030" });
+
+    // ÷ 0031 ÷ 003A ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 003A ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u003A",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u003A",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u0027",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u0027",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002C",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002C",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0031\u002E\u2060",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 003A × 0308 ÷ 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u003A\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031", "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 0027 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 0027 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0030",
+                     new String[] { "\u0031\u0027\u0030" });
+
+    // ÷ 0031 × 0027 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0030",
+                     new String[] { "\u0031\u0027\u0308\u0030" });
+
+    // ÷ 0031 ÷ 0027 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 0027 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u003A",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u003A",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u0027",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u0027",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002C",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002C",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 × 0027 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0031\u002E\u2060",
+                     new String[] { "\u0031\u0027\u0031" });
+
+    // ÷ 0031 × 0027 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] APOSTROPHE (Single_Quote) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u0027\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u0027\u0308\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002C ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 002C × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0030",
+                     new String[] { "\u0031\u002C\u0030" });
+
+    // ÷ 0031 × 002C × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0030",
+                     new String[] { "\u0031\u002C\u0308\u0030" });
+
+    // ÷ 0031 ÷ 002C ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 002C ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002C × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u003A",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u003A",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u0027",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u0027",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002C",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002C",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 × 002C × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002C\u0031" });
+
+    // ÷ 0031 × 002C × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] COMMA (MidNum) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002C\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002C\u0308\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0001 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] <START OF HEADING> (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0001",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000D ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <CARRIAGE RETURN (CR)> (CR) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\r",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE FEED (LF)> (LF) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\n",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 000B ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [3.2] <LINE TABULATION> (Newline) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u000B",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 3031 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u3031",
+                     new String[] { "\u0031", "\u3031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0041 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN CAPITAL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0041",
+                     new String[] { "\u0031", "\u0041" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u003A",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u002C",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 002E ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] FULL STOP (MidNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u002E",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0030",
+                     new String[] { "\u0031\u002E\u2060\u0030" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0030 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ZERO (Numeric) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0030",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0030" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 005F ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LOW LINE (ExtendNumLet) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u005F",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 1F1E6 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\uD83C\uDDE6",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 05D0 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] HEBREW LETTER ALEF (Hebrew_Letter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u05D0",
+                     new String[] { "\u0031", "\u05D0" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0022 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] QUOTATION MARK (Double_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\"",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0027",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 × 00AD ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] SOFT HYPHEN (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u00AD",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 × 0300 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0300",
+                     new String[] { "\u0031" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u2060",
+                     new String[] { "\u0031", "\u0061\u2060" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u003A",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 0027 × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u0027\u2060",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 ÷ 002E × 2060 × 0308 ÷ 0061 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0061\u002C",
+                     new String[] { "\u0031", "\u0061" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u003A",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 003A ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COLON (MidLetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u003A",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u0027",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 0027 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] APOSTROPHE (Single_Quote) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u0027",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002C",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002C ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] COMMA (MidNum) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002C",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002E\u2060\u0031" });
+
+    // ÷ 0031 × 002E × 2060 × 0308 × 0031 ÷ 002E × 2060 ÷  #  ÷ [0.2] DIGIT ONE (Numeric) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [4.0] COMBINING DIAERESIS (Extend_FE) × [11.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0031\u002E\u2060\u0308\u0031\u002E\u2060",
+                     new String[] { "\u0031\u002E\u2060\u0308\u0031" });
+
+    // ÷ 0063 × 0061 × 006E × 0027 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] APOSTROPHE (Single_Quote) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u0027\u0074",
+                     new String[] { "\u0063\u0061\u006E\u0027\u0074" });
+
+    // ÷ 0063 × 0061 × 006E × 2019 × 0074 ÷  #  ÷ [0.2] LATIN SMALL LETTER C (ALetter) × [5.0] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER N (ALetter) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [7.0] LATIN SMALL LETTER T (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0063\u0061\u006E\u2019\u0074",
+                     new String[] { "\u0063\u0061\u006E\u2019\u0074" });
+
+    // ÷ 0061 × 0062 × 00AD × 0062 × 0079 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] SOFT HYPHEN (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [5.0] LATIN SMALL LETTER Y (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0062\u00AD\u0062\u0079",
+                     new String[] { "\u0061\u0062\u00AD\u0062\u0079" });
+
+    // ÷ 0061 ÷ 0024 ÷ 002D ÷ 0033 × 0034 × 002C × 0035 × 0036 × 0037 × 002E × 0031 × 0034 ÷ 0025 ÷ 0062 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] DOLLAR SIGN (Other) ÷ [999.0] HYPHEN-MINUS (Other) ÷ [999.0] DIGIT THREE (Numeric) × [8.0] DIGIT FOUR (Numeric) × [12.0] COMMA (MidNum) × [11.0] DIGIT FIVE (Numeric) × [8.0] DIGIT SIX (Numeric) × [8.0] DIGIT SEVEN (Numeric) × [12.0] FULL STOP (MidNumLet) × [11.0] DIGIT ONE (Numeric) × [8.0] DIGIT FOUR (Numeric) ÷ [999.0] PERCENT SIGN (Other) ÷ [999.0] LATIN SMALL LETTER B (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\u0024\u002D\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034\u0025\u0062",
+                     new String[] { "\u0061", "\u0033\u0034\u002C\u0035\u0036\u0037\u002E\u0031\u0034", "\u0062" });
+
+    // ÷ 0033 × 0061 ÷  #  ÷ [0.2] DIGIT THREE (Numeric) × [10.0] LATIN SMALL LETTER A (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0033\u0061",
+                     new String[] { "\u0033\u0061" });
+
+    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 0027 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] APOSTROPHE (Single_Quote) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060",
+                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u0027\u2060\u0074\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0063 × 2060 × 0061 × 2060 × 006E × 2060 × 2019 × 2060 × 0074 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER C (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER N (ALetter) × [4.0] WORD JOINER (Format_FE) × [6.0] RIGHT SINGLE QUOTATION MARK (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [7.0] LATIN SMALL LETTER T (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060",
+                     new String[] { "\u0063\u2060\u0061\u2060\u006E\u2060\u2019\u2060\u0074\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0061 × 2060 × 0062 × 2060 × 00AD × 2060 × 0062 × 2060 × 0079 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] SOFT HYPHEN (Format_FE) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [5.0] LATIN SMALL LETTER Y (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060",
+                     new String[] { "\u0061\u2060\u0062\u2060\u00AD\u2060\u0062\u2060\u0079\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0061 × 2060 ÷ 0024 × 2060 ÷ 002D × 2060 ÷ 0033 × 2060 × 0034 × 2060 × 002C × 2060 × 0035 × 2060 × 0036 × 2060 × 0037 × 2060 × 002E × 2060 × 0031 × 2060 × 0034 × 2060 ÷ 0025 × 2060 ÷ 0062 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DOLLAR SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] HYPHEN-MINUS (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] COMMA (MidNum) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT FIVE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SIX (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT SEVEN (Numeric) × [4.0] WORD JOINER (Format_FE) × [12.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) × [11.0] DIGIT ONE (Numeric) × [4.0] WORD JOINER (Format_FE) × [8.0] DIGIT FOUR (Numeric) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] PERCENT SIGN (Other) × [4.0] WORD JOINER (Format_FE) ÷ [999.0] LATIN SMALL LETTER B (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0061\u2060\u0024\u2060\u002D\u2060\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060\u0025\u2060\u0062\u2060\u2060",
+                     new String[] { "\u0061\u2060", "\u0033\u2060\u0034\u2060\u002C\u2060\u0035\u2060\u0036\u2060\u0037\u2060\u002E\u2060\u0031\u2060\u0034\u2060", "\u0062\u2060\u2060" });
+
+    // ÷ 2060 ÷ 0033 × 2060 × 0061 × 2060 × 2060 ÷  #  ÷ [0.2] WORD JOINER (Format_FE) ÷ [999.0] DIGIT THREE (Numeric) × [4.0] WORD JOINER (Format_FE) × [10.0] LATIN SMALL LETTER A (ALetter) × [4.0] WORD JOINER (Format_FE) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u2060\u0033\u2060\u0061\u2060\u2060",
+                     new String[] { "\u0033\u2060\u0061\u2060\u2060" });
+
+    // ÷ 0061 ÷ 1F1E6 ÷ 0062 ÷  #  ÷ [0.2] LATIN SMALL LETTER A (ALetter) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) ÷ [999.0] LATIN SMALL LETTER B (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0061\uD83C\uDDE6\u0062",
+                     new String[] { "\u0061", "\u0062" });
+
+    // ÷ 1F1F7 × 1F1FA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA",
+                     new String[] {  });
+
+    // ÷ 1F1F7 × 1F1FA × 1F1F8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\uD83C\uDDF8",
+                     new String[] {  });
+
+    // ÷ 1F1F7 × 1F1FA × 1F1F8 × 1F1EA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER E (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\uD83C\uDDF8\uD83C\uDDEA",
+                     new String[] {  });
+
+    // ÷ 1F1F7 × 1F1FA ÷ 200B ÷ 1F1F8 × 1F1EA ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER R (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER U (Regional_Indicator) ÷ [999.0] ZERO WIDTH SPACE (Other) ÷ [999.0] REGIONAL INDICATOR SYMBOL LETTER S (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER E (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDF7\uD83C\uDDFA\u200B\uD83C\uDDF8\uD83C\uDDEA",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 1F1E7 × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE7\uD83C\uDDE8",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 200D × 1F1E7 × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [4.0] ZERO WIDTH JOINER (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\u200D\uD83C\uDDE7\uD83C\uDDE8",
+                     new String[] {  });
+
+    // ÷ 1F1E6 × 1F1E7 × 200D × 1F1E8 ÷  #  ÷ [0.2] REGIONAL INDICATOR SYMBOL LETTER A (Regional_Indicator) × [13.3] REGIONAL INDICATOR SYMBOL LETTER B (Regional_Indicator) × [4.0] ZERO WIDTH JOINER (Extend_FE) × [13.3] REGIONAL INDICATOR SYMBOL LETTER C (Regional_Indicator) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\uD83C\uDDE6\uD83C\uDDE7\u200D\uD83C\uDDE8",
+                     new String[] {  });
+
+    // ÷ 0020 × 200D ÷ 0646 ÷  #  ÷ [0.2] SPACE (Other) × [4.0] ZERO WIDTH JOINER (Extend_FE) ÷ [999.0] ARABIC LETTER NOON (ALetter) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0020\u200D\u0646",
+                     new String[] { "\u0646" });
+
+    // ÷ 0646 × 200D ÷ 0020 ÷  #  ÷ [0.2] ARABIC LETTER NOON (ALetter) × [4.0] ZERO WIDTH JOINER (Extend_FE) ÷ [999.0] SPACE (Other) ÷ [0.3]
+    assertAnalyzesTo(analyzer, "\u0646\u200D\u0020",
+                     new String[] { "\u0646\u200D" });
+
+  }
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/email.addresses.from.random.text.with.email.addresses.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/email.addresses.from.random.text.with.email.addresses.txt
new file mode 100644
index 0000000..ae86ee6
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/email.addresses.from.random.text.with.email.addresses.txt
@@ -0,0 +1,265 @@
+dJ8ngFi@avz13m.CC
+JCAVLRJg@3aqiq2yui.gm
+kU-l6DS@[082.015.228.189]
+37layCJS@j5NVP7NWAY.VG
+"%U@?\B"@Fl2d.md
+aH3QW@tw8uo2.eu
+Bvd#@tupjv.sn
+SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt
+DvdUJk@61zwkit7dkd3rcq4v.BD
+~+Kdz@3mousnl.SE
+C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY
+}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM
+lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae
+V85E9Hx7@vpf0bs.bz
+MGBg2@7F3MJTCCPROS8YETM0B4-C9P7WXKGFB0.RU
+rsBWOCJ@lYX0SILY4L53Z3VJPSF6.pwrawr.vdpoq.nz
+dIyLrU@9A40T2ZIG7H8R.t63.tv
+6dAsZKz@d33XR.IR
+EnqCC@2bk6da6y08.LI
+AQ9yV@Mfqq32nexufgxzl4o7q5jv3kd.lb
+lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H
+b6/zomNkV@8jwm-he.IN
+5FLuakz.hXVkuqDt@iBFP83V6MNI3N0FRWJ9302DS-0KHRV6O.1bf59kj64uj5b6e2zfn.cm
+RhIwkU@58vmet9yfddpg.3adkmhrv1px.AO
+nEBk6w2Q@Bb5ib.2pay.so
+AlW5CMAn@qos-53u.j91qq96d4en129szf7099kxv5lo6yo.gm
+QPYBDV3.Ah/h8U@x3v444pzi.1cvgokam.PW
+5Iwbiq7@p9s-2pixps9jwzyhfroxqivw8sv90r.xn--wgbh1c
+AaFU9L@3yj1xqf1.cz9.ac
+|iCmQ1@rum6w0a7wt.3QLD.ht71.cx
+EhLTUjo@rEK.sJ44H0.GR
+bHEbq3Rp@33.lKSSMY.9xaurtfle9xe.iu4810l.fj
+eFcup.cPPEW@[1ae]
+p907@bk3o.fvtmw2m2.Uutr83x2yt4.2nuin.EU
+PpW2L5.QgP2n@9rz7.a5qi.oRH1Z.8ov.UZ
+o8UgG5fewm4vr9Ai5wPS@sgh.2F-OLKLZ81DIUET.xpya0vtx.fj
+aixQH@z-y.AR
+jVTeWQfL."M#~t Q"@1e.oglq.ubk.SZ
+6e5QQuy@N7.2cuw3x2wpddf.paycp1pc.AI
+IqG6Fl@[220.112.120.54]
+lWHH4eWSn@tbxyb7.jhzqxrk.lv
+P1zO*RaAr@[111.99.108.22]
+d00gy@[4TC]
+1yNINoBU@[136.003.010.238]
+Ms8ox@[_3Tuehr]
+wtWDNo@1sjmcbbli196-765mt7m8o8hywft.7-ga6rsnum8v.np
+"x)yO"@7le5o2rcud5ngs.Qmfmq.Jfxv8.Zznv6t6il.MIL
+1hXd@f8.1kxqd3yw4j6zmb7l7.US
+"8}(\$"@mu2viak0nh4sj5ivgpy1wqie.HK
+Th7XoAs5@ggdb.BI
+5iDbhah.xdtF1x@[59.55.12.243]
+j2ovALlgm2Wcwx@5jphzt.TN
+ZlaP~E.4Yk1K0F@lF6VN.M5.Nj.PRO
+cFCvIJAw@l93H0R1W6V4RI0AY7RLRQR4KOEVQPEG-PDTF03V4D9A0.xZZK5.lu
+8Ju2AW@1n.h7.vu
+"\nkP]{"@[Vej\yo\HD]
+fKWC?@qgcb.xn--mgbaam7a8h
+L4BbaB@hv1.BIZ
+WvSmV@qpx15vzmbtxzvi-syndl1.ML
+"3|PX~Cbdq"@U3vp-7k.8c4q3sgpwt6sochundzhx.museum
+LjH9rJTu@tkm.gy
+vQgXEFb@maxmrbk-5a5s6o.6MZZ6IK.awjbtiva7.IL
+6TVbIA@r50eh-a.la
+AaASl@Bsteea.qHXE3Q5CUJ3DBG.S2hvnld.4WJWL.fk
+"CN;\-z 6M"@86.qc7s.23p.ET
+zX3=O3o@Yjov.7g660.8M88OJGTDC5.np
+QFZlK1A@4W47EIXE.KY
+1guLnQb07k@ab.ccemuif2s.lb
+Jddxj@[111.079.109.147]
+Hj06gcE@[105.233.192.168]
+u8?xicQ@[i\21I]
+CczYer}W@bezu6wtys9s.lft3z.mobi
+OmpYhIL@6GJ7P29EIE-G63RDW7GLFLFC0M1.AERO
+2RRPLqO@8lh0i.vm7xmvvo-r5nf0x.CY
+TOc!BhbKz@F-myy7.kQWSUI7S3.net
+"0\!P?".shQVdSerA@2qmqj8ul.hm
+LTLNFsgB@[191.56.104.113]
+iT0LOq.jtPW=G06~cETxl2ge@Ah0.4hn72v.tQ.LU
+VGLn@z3E2.3an2.MM
+TWmfsxn@[112.192.017.029]
+2tP07A@2twe6u0d6uw6o.sed7n.109mx.XN--KPRW13D
+CjaPC63@['\RDrwk]
+Ayydpdoa@tdgypppmen.wf
+"gfKP9"@jo3-r0.mz
+aTMgDW4@t5gax.XN--3E0B707E
+mcDrMO3FQ@nwc21.y5qd45lesryrp.IL
+NZqj@v50egeveepk.z290kk.Bc3.xn--kprw13d
+XtAhFnq@[218.214.251.103]
+x0S8uos@[109.82.126.233]
+ALB4KFavj16pODdd@i206d6s.MM
+grxIt96.46nCf@nokjogh2l4.nCMWXG.yt
+Fgbh7@2rxkk0bvkk-v3evd-sh56gvhxlh.hhjcsg36j8qt98okjbdj9z574xdpix59zf6h80r.Gyb4rrxu.ve
+uo0AX41@Fhlegm1z57j-qvf5.p8jo6zvm.sc
+sjn4cz@9ktlwkqte.bv
+b04v0Ct@[243.230.224.190]
+F!FUbQHU@uvz7cu1l.ciz4h2.93U4V.gb
+6CHec@nONUKT.nl
+zbmZiXw@yb.bxxp.3fm457.va
+"/GdiZ7f"@[221.229.46.3]
+NJde8Li@f7a.g51VICBH.cy
+6IeAft@e-3fp.Nkh7nm8.v8i47xvrv27r.pf
+TC*Qopzb@xIOB3.6egz4.m-24t5wmxtmco4iy8g91o66mjgha1vjlepyffott.E5ta.p9.CF
+"_3Sc_"@[193.165.124.143]
+W0dwHf@[25.174.65.80]
+qPkkP0@4k0vs.oaak2z.3JMTI.PK
+XzZh7@[\\JmD%U]
+66SGHzw@Oqnr82oml7jct0b8crwbstdhcgc3khxj7dj-t898mzro0p3-rvp-dythh.TN
+ot4tPF@[AY\j]
+e4seIFbl@cib.cg
+B2w025e@r2H7BW16B24DG1S5DED.bg
+atweEde@blk-3y.mgvoh6l9my.F6.FI
+uDoPcRGW@rEBD5LUT.ly
+2KQhx@Bba.u--9b5bc0.NF
+tKWc2VjVRYD@[254.190.162.128]
+wc3W16^@D3v2uxqqeclz.w1fd529m.DM
+Njg@6S8MA.HK
+"L\^4z]92"@0qp--walx.MIL
+X08sWFD@62GNK.tN4.f1YXX.ug
+eK6Bz1Bu@[rX;J&036]
+"~`o\:"@hO4UKF.oZBWV56B.cmn.DJ
+lcgUakx@[pjGd&i2]
+BqdBTnv3c@wf35nwaza.ME
+"a#Um{:\'\bX:"@in7tjo.uw8wil.gp
+ApIbER8'@[&Y]
+JTsM0c!s9CzEH@Sd.mh
+hy2AOUc@uqxzl7v0hl2nchokqit9lyscxaa0jaqya1wek5gkd.NC
+pY7bAVD4r@[,>T*R T]
+!0axBT@03-gdh1xmk3x9.GH
+vbtyQBZI@20al5g.ro6ds4.Bsg15f5.NU
+2^ZhSK-FFYOh@Z2iku.rg.Z0ca1.gs
+G1RLpOn."yfJpg["@mXEV8.mu
+yrBKNkq@a2a1.Aifn.Ta2.dj
+Wok5G@b5aqobvi5.ni
+nXz9i.=EL9Yj@93r8do3ntizibg1-5-a0ziw9ugyn4bo9oaw3ygrxq-eczzv1da6gj58whvmo2.rs
+Dp63hd@B1kbahyq.PL
+y01rn27SFq@o0HNP8.C5.i4rvj8j338zgter7er5rkwyo5g.atnc0iuj2ke.8or6ekq0x.IO
+0RiEo@08mnvbu.p661ernzjz5p7nbyix5iuj.cig5hgvcc.SO
+Dwxab5@1sx5y3-umsy72nl.74lwye5.DJ
+IvdZVE4xRk@0vw7ajl.AR
+CvQxhXJ@d5a7qnx.ke
+n7MxA4~@[4(R]
+RFGzu3hD0@wbh4.sm
+eOADW}BcNG@2568p3b4v.Xq3eksr.GP
+AsAMWriW7.zSDQSAR6@Gg2q4rtgr.GG
+cDCVlA0t@[20.116.229.216]
+c=yJU+3L5@n2x3xhksf.gvreani.MZ
+wfYnaA4@lzojy.4oii6w6sn-p9.kh
+kdeOQ5F@vD5Y.wmmv.7rswz.1zelobcp5qxxwzjn.fOEJZ.KM
+ppULqb2Z@Hv9o2ui.AO
+tOHw@[IPv6:3500:8B6C::CB5E:1.124.160.137]
+MWLVsL@7nhliy.O8mjon3rj-kb.t8d6bcpa5i.au
+BN0EY@hh9v.p9bwgs.TN
+RgiAp@d9ln.bf
+PBugBo@97gcz.DJ
+Fh#dKzbI@[+_]
+wyqU-C9hXE@wPRBUI-WS9HXE19.LV
+muC?Js@[IPv6:47FB:5786:4b5e::5675]
+yLTT2xV@wdoszw9k1ork-z-t.kq.l3SEO.Lb4jx0.NA
+6zqw.yPV4LkL@dA3XKC.eg
+S5z9i7i3s@Vzt6.fr
+L|Sit6s@9cklii1.tf
+yWYqz@mw-9k.FJ
+Knhj419mAfftf@R26hxll64.3qtdx6g.AL
+aZYHUr6@Shyn76c67.65grky.am
+ZYxn6Px@di0cqhtg.hu
+"#mLl"@w1sc0g3vm.j1o4o9g.GW
+WYJcFp@653xk-89oprk2im.iemhx9.CC
+y5AXi@[Oa #]
+nZErAGj@6sq3-p.r8KQ.aero
+OMq5sBK@udg-5zp1.Dory85.SG
+2bymd@Ojla1hvfpw8rrihrx.cy
+5OMbw0@r2d8cn75.1VR2BJ0J3A8PY.gc0mljc-h.COOP
+al6X^pQkx@pyj--2hp.lbet.TN
+NkzPW4f@2-0.aaoqccwrgi4olytac0imp6vvphsuobrr115eygh2xwkvzeuj.tl
+"4-b9|/,\e]h]2"@9-iiahsdlzv-v65j.FK
+g8Pv2hb9@[166.176.68.63]
+"IA~".Tn03w7@[\>J?]
+E6aK9TaJ@j0hydmxhkq2q.Svku4saky.MU
+rdF2Zl1@9fsic.C17pw9o0.vn
+pCKjPa88DG&x5a@4ha07ia2jk.xk7xe8.PM
+qgLb5m@nynqp.DE
+qC731@["\S]
+vIch1nT@[IPv6:4c2f:A840:1788:ad5:C2C6:dfae:1b1f::]
+GVSMpg@2YGZ1R19XTW1TIH.Re3vg30u1xq6v7cj1wf-6m14939wvgqbl.93mztd.SG
+0jq4v7PMxm@eq6teog.kO6LR3.x2p.53yltrsvgpd3.RO
+zdGLZD0P@i2JQNM8.816oja8pkk5zkvyx.KM
+Jp#hSH@74zkerax4.31kr.7c9-yuk.mp
+Kx^0oZn@oFFA-URZ13B34J.DK
+sub52@aoq7.iHF.CH
+jfVSq9oAR2D@iGU0.7bp3x.4cr.sz
+nalgU@Yfpbdcv8a5.n9kwz6kyi2u.thic-rws.af.TG
+=uC5qVT@56g530cltpekrw.pt
+QR5&kx@7qhi3bhav5ga0eva.b0sdom.bb
+8DZQ7@dtr16r89fdw59q.cf
+Q4pNw@6o-9weojl3r7.LS
+*mfOc_CN@[G\3]
+2p`tbG@c767inolrav0hg6a-ucs.y0.tw
+Rop{cgBy@Wekdh0xns2um.UK
+t*p05lV@017y.MR
+7ZxO80@Dovepwr4l.qxfzchrn1.es8ul0vavi6gqy82.K1hc7.INT
+C_Iphp@5t4rtc.id
+q+m2x@Cfw.1tm52-kr.BO
+47NIL@Hl68os0.66l9bsf2q.SC
+vi0LyF9O@p74jz6mxby.it
+xQ4jU@rQVWLWAD3T8.4-lnu.AZ
+zea_0Kr@[97.59.144.249]
+5HP1k|s@[068.150.236.123]
+5XJZlmYk.3Du5qee@[072.023.197.244]
+AvNrIHB0@[+n}oV]
+"!N7/I\zhh"@[204.037.067.146]
+vlJODxFF@xFO6V.i1.fgad6bjy.NO
+qDe0FA@xpp1le82ndircjgyrxyzkrqu3il.oUKHVV6829P-16JILWG62KN.cr
+pMF64@wssq6kh9uhxk.cA2YZVBV4JW.xX585A.ru
+G3meE@[^!'OO]
+"1@0UYJl"@vplkx.d2n.i3tcx3aaxut.lbb3v9.ldq.me
+iTH0QND@wg9sizy.lr
+9kF?opSTo9rSDWLo&W&6@xrh32ibf.F0zb6kb.BJ
+a0FI1m@1olkdpz.W70a3w8qmk3.NA
+"0H}r}X(p\M`/x"@rY48LPH.Axy.Ue624.TV
+AQL6YBFb@Hxawb15okz.y4.y5c0e.bt
+PEaNVR@m8NH9BVX5L096DRM7YTR.er
+diI`Q@i5fpkuc.7zg2av.D6tzqq.CK
+TCN0-Z@Tezeq9ejv.ekeab8hz14hui.il
+05SnFh@jZ85JXZ.1RO99W5FYK3.uyv7g15.MP
+B2Z76Rn@9yce0shfsydxetu1v4-y.rBU2M0.6ik8oapv0zho6n653il25gu4rd216uw03.MG
+vGZ2K@C2osgjtel5uerwn.riihbabhh41ve84.r3l.vH6S64.vn
+Nv2ZgL@[037.054.177.155]
+WsdI2W@i1ULFQ1.79qfph2.eg
+vJfpTf3@Hh4x2h.25m0idq3.fr
+oRqbgftr@l6jg0.TV
+NiynsKb@k9BTX4-FV.hc0skm-o.lv
+w9uGwf@4hop8.Jb9655is.nr
+"NVUW+"@6jbe.KM
+QusHU6JMR@0RXKIZNH76C3.Oqwcfr779e.MH
+}C5IwKv1S45vlmPaaVHhF@[IPv6:EBF6::]
+T7rXlYc@4AI1LM.2o.uk
+uuCiDC6c@Maar3.65hlg-wf.t3pt9.FJ
+w2mNOvIUh@dx3ep7ew.ru
+b#Add@9hpopo.Xg3tbjchdpt.TT
+NtrgJjfj."NBwi"@[142.085.096.018]
+00lF9UB@2NR2.rs
+MPr42ye9@p08lcrzs.4bzxfznsh2bhgsa.CX
+awwLoYLn~c2LfTEVT@fwksx.qoj94r11kw19k50k3.gd
+gRZ5w9epm@p6adico3auugj5qklec.Sm4bx5.li
+zfdZ67Y@1azhq.dl3xxzni2.rrj.lpclc6g4d.sl
+vTWwSD4fb@uBSOHD.3g.u3mb.gf
+cYFVxcC6E@F9g0b.n1339r.AU
+pnuXl@s1alo2.tc
+lKy64zp.Cbg8BM@y0S.6uiux8h8.0udipt.ma
+|9FDgc@vbrz.3L.av4kmt.rs
+skcHAu7@xD715N1.DZ
+BfcgHK3@[220.136.9.224]
+LCOEag@Gwm.drsa0.GL
+qrNZtp3vO@a0gr.8j9cvcgy0p-3.HN
+lfW2rei20XWSmpQoPY1Dl@[(N&c]
+WFBBEv|@q7R2J.oy48740.pm
+6H6rPx@zVJ40.xgyat.cLUX6SVFJWMLF9EZ2PL8QQEU7U1WT0JW3QR8898ALFGKO18CF1DOX89DR.1tfu30mp.CA
+ytG@J4auwv4has.PS
+"X;+N1A\A "@rc9cln0xyy8wa6axedojj9r0slj0v.Luy9i6ipqrz74lm5-n6f1-2srq5vdo-opef747ubdykv5hc.2lztpe.er
+DQTmqL4LVRUvuvoNb8=TT@2up3.PY
+NC0OPLz@kcru1s0mu.name
+kBoJf{XaGl@[248.166.223.221]
+pEjZPm8A@v956Y7GQV.5uu6.Ribgf20u.6e.0do1nki1t.ahy.6iy.sm
+pIFWkl2@w9N0Q.MC
+p=VTtlpC@w3ttqb.FO
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/generateJavaUnicodeWordBreakTest.pl lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/generateJavaUnicodeWordBreakTest.pl
new file mode 100644
index 0000000..46ac3ef
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/generateJavaUnicodeWordBreakTest.pl
@@ -0,0 +1,232 @@
+#!/usr/bin/perl
+
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+use warnings;
+use strict;
+use File::Spec;
+use Getopt::Long;
+use LWP::UserAgent;
+
+my ($volume, $directory, $script_name) = File::Spec->splitpath($0);
+
+my $version = '';
+unless (GetOptions("version=s" => \$version) && $version =~ /\d+\.\d+\.\d+/) {
+  print STDERR "Usage: $script_name -v <version>\n";
+  print STDERR "\tversion must be of the form X.Y.Z, e.g. 5.2.0\n"
+      if ($version);
+  exit 1;
+}
+my $url_prefix = "http://www.unicode.org/Public/${version}/ucd";
+my $scripts_url = "${url_prefix}/Scripts.txt";
+my $line_break_url = "${url_prefix}/LineBreak.txt";
+my $word_break_url = "${url_prefix}/auxiliary/WordBreakProperty.txt";
+my $word_break_test_url = "${url_prefix}/auxiliary/WordBreakTest.txt";
+my $underscore_version = $version;
+$underscore_version =~ s/\./_/g;
+my $class_name = "WordBreakTestUnicode_${underscore_version}";
+my $output_filename = "${class_name}.java";
+my $header =<<"__HEADER__";
+package org.apache.lucene.analysis.core;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.junit.Ignore;
+
+/**
+ * This class was automatically generated by ${script_name}
+ * from: ${url_prefix}/auxiliary/WordBreakTest.txt
+ *
+ * WordBreakTest.txt indicates the points in the provided character sequences
+ * at which conforming implementations must and must not break words.  This
+ * class tests for expected token extraction from each of the test sequences
+ * in WordBreakTest.txt, where the expected tokens are those character
+ * sequences bounded by word breaks and containing at least one character
+ * from one of the following character sets:
+ *
+ *    \\p{Script = Han}                (From $scripts_url)
+ *    \\p{Script = Hiragana}
+ *    \\p{LineBreak = Complex_Context} (From $line_break_url)
+ *    \\p{WordBreak = ALetter}         (From $word_break_url)
+ *    \\p{WordBreak = Hebrew_Letter}
+ *    \\p{WordBreak = Katakana}
+ *    \\p{WordBreak = Numeric}         (Excludes full-width Arabic digits)
+ *    [\\uFF10-\\uFF19]                (Full-width Arabic digits)
+ */
+\@Ignore
+public class ${class_name} extends BaseTokenStreamTestCase {
+
+  public void test(Analyzer analyzer) throws Exception {
+__HEADER__
+
+my $codepoints = [];
+map { $codepoints->[$_] = 1 } (0xFF10..0xFF19);
+# Complex_Context is an alias for 'SA', which is used in LineBreak.txt
+# Using lowercase versions of property value names to allow for case-
+# insensitive comparison with the names in the Unicode data files.
+parse_Unicode_data_file($line_break_url, $codepoints, {'sa' => 1});
+parse_Unicode_data_file($scripts_url, $codepoints, 
+                        {'han' => 1, 'hiragana' => 1});
+parse_Unicode_data_file($word_break_url, $codepoints,
+                        {'aletter' => 1, 'hebrew_letter' => 1, 'katakana' => 1, 'numeric' => 1});
+my @tests = split /\r?\n/, get_URL_content($word_break_test_url);
+
+my $output_path = File::Spec->catpath($volume, $directory, $output_filename);
+open OUT, ">$output_path"
+  || die "Error opening '$output_path' for writing: $!";
+
+print STDERR "Writing '$output_path'...";
+
+print OUT $header;
+
+for my $line (@tests) {
+  next if ($line =~ /^\s*(?:|\#.*)$/); # Skip blank or comment-only lines
+  # Example line: ÷ 0001 × 0300 ÷  #  ÷ [0.2] <START OF HEADING> (Other) × [4.0] COMBINING GRAVE ACCENT (Extend_FE) ÷ [0.3]
+  my ($sequence) = $line =~ /^(.*?)\s*\#/;
+  $line =~ s/\t/  /g; # Convert tabs to two spaces (no tabs allowed in Lucene source)
+  print OUT "    // $line\n";
+  $sequence =~ s/\s*÷\s*$//; # Trim trailing break character
+  my $test_string = $sequence;
+  $test_string =~ s/\s*÷\s*/\\u/g;
+  $test_string =~ s/\s*×\s*/\\u/g;
+  $test_string =~ s/\\u([0-9A-F]{5,})/join('', map { "\\u$_" } above_BMP_char_to_surrogates($1))/ge;
+  $test_string =~ s/\\u000A/\\n/g;
+  $test_string =~ s/\\u000D/\\r/g;
+  $test_string =~ s/\\u0022/\\\"/g;
+  $sequence =~ s/^\s*÷\s*//; # Trim leading break character
+  my @tokens = ();
+  for my $candidate (split /\s*÷\s*/, $sequence) {
+    my @chars = ();
+    my $has_wanted_char = 0;
+    while ($candidate =~ /([0-9A-F]+)/gi) {
+      my $hexchar = $1;
+      if (4 == length($hexchar)) {
+        push @chars, $hexchar;
+      } else {
+        push @chars, above_BMP_char_to_surrogates($hexchar);
+      }
+      unless ($has_wanted_char) {
+        $has_wanted_char = 1 if (defined($codepoints->[hex($hexchar)]));
+      }
+    }
+    if ($has_wanted_char) {
+      push @tokens, '"'.join('', map { "\\u$_" } @chars).'"';
+    }
+  }
+  print OUT "    assertAnalyzesTo(analyzer, \"${test_string}\",\n";
+  print OUT "                     new String[] { ";
+  print OUT join(", ", @tokens), " });\n\n";
+}
+
+print OUT "  }\n}\n";
+close OUT;
+print STDERR "done.\n";
+
+
+# sub above_BMP_char_to_surrogates
+#
+# Converts hex references to chars above the BMP (i.e., greater than 0xFFFF)
+# to the corresponding UTF-16 surrogate pair
+#
+# Assumption: input string is a sequence more than four hex digits
+#
+sub above_BMP_char_to_surrogates {
+  my $ch = hex(shift);
+  my $high_surrogate = 0xD800 + (($ch - 0x10000) >> 10);
+  my $low_surrogate  = 0xDC00 + ($ch & 0x3FF);
+  return map { sprintf("%04X", $_) } ($high_surrogate, $low_surrogate);
+}
+
+
+# sub parse_Unicode_data_file
+#
+# Downloads and parses the specified Unicode data file, parses it, and
+# extracts code points assigned any of the given property values, defining
+# the corresponding array position in the passed-in target array.
+#
+# Takes in the following parameters:
+#
+#  - URL of the Unicode data file to download and parse
+#  - Reference to target array
+#  - Reference to hash of property values to get code points for
+#
+sub parse_Unicode_data_file {
+  my $url = shift;
+  my $target = shift;
+  my $wanted_property_values = shift;
+  my $content = get_URL_content($url);
+  print STDERR "Parsing '$url'...";
+  my @lines = split /\r?\n/, $content;
+  for (@lines) {
+    s/\s*#.*//;         # Strip trailing comments
+    s/\s+$//;           # Strip trailing space
+    next unless (/\S/); # Skip empty lines
+    my ($start, $end, $property_value);
+    if (/^([0-9A-F]{4,5})\s*;\s*(.+)/i) {
+      # 00AA       ; LATIN
+      $start = $end = hex $1;
+      $property_value = lc $2; # Property value names are case-insensitive
+    } elsif (/^([0-9A-F]{4,5})..([0-9A-F]{4,5})\s*;\s*(.+)/i) {
+      # 0AE6..0AEF ; Gujarati
+      $start = hex $1;
+      $end = hex $2;
+      $property_value = lc $3; # Property value names are case-insensitive
+    } else {
+      next;
+    }
+    if (defined($wanted_property_values->{$property_value})) {
+      for my $code_point ($start..$end) {
+        $target->[$code_point] = 1;
+      }
+    }
+  }
+  print STDERR "done.\n";
+}
+
+# sub get_URL_content
+#
+# Retrieves and returns the content of the given URL.
+#
+sub get_URL_content {
+  my $url = shift;
+  print STDERR "Retrieving '$url'...";
+  my $user_agent = LWP::UserAgent->new;
+  my $request = HTTP::Request->new(GET => $url);
+  my $response = $user_agent->request($request);
+  unless ($response->is_success) {
+    print STDERR "Failed to download '$url':\n\t",$response->status_line,"\n";
+    exit 1;
+  }
+  print STDERR "done.\n";
+  return $response->content;
+}
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.email.addresses.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.email.addresses.txt
new file mode 100644
index 0000000..84062cd
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.email.addresses.txt
@@ -0,0 +1,427 @@
+=========
+This file was generated in part (i.e. without the email addresses)
+by the random text generator at:
+<http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-rosalixion-word-2gram&paragraphs=20&length=200&suppress-quotes=on&no-ads=on>
+=========
+waist and Wintja are relearning how dJ8ngFi@avz13m.CC we spread out, but it
+here before, our dimension of story. In Bed and Marys opus in the last thing
+actually having difficulties moving, Spiros rises to our hidden on your
+<JCAVLRJg@3aqiq2yui.gm> orders, my love: Im seven doors and with gentle
+fingers, then disappears? Whats the idea <kU-l6DS@[082.015.228.189]> of
+<37layCJS@j5NVP7NWAY.VG> the "%U@?\B"@Fl2d.md pages blowing to appear on Earth
+in motion (what rules did we can take a radio changes. A VOICE: Hes a
+scoundrel. VOICES: Burn him! Burn him! SPIROS: Want to team of the couple is
+the sweetest love aH3QW@tw8uo2.eu of the teaching teaches members to
+communicate with time interplaying and linked and you marry it. It will leave
+Bvd#@tupjv.sn the logic of it from hereing those people were all
+SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt the
+artist stray? Does a few rose doom the UFO with my dear Sissy says Sissy,
+holding hands up a bit of DvdUJk@61zwkit7dkd3rcq4v.BD fate falls asleep. When
+an internet age is ~+Kdz@3mousnl.SE currently working with his bedside table,
+and brings in a shimmering timeshifty verse vortex, the dream. Victory is
+hallucination, my hand for more. Mmm my head,
+C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY in five. (Spiros waves goodbye to tell
+you, honeybuns: The poisoning is, but no addresses. A message identical reach
+across the script. }0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM I grasp hold their
+flapping wings and when theyre seemingly infallible information? Bookshrine of
+a sip of defined the Great Horned Goddess of no feeling.) Meaw. FFIANA: So,
+darling. Dont be dry white and teases him back
+lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae in society not speaking, giggling
+V85E9Hx7@vpf0bs.bz in MGBg2@7F3MJTCCPROS8YETM0B4-C9P7WXKGFB0.RU the boring
+f***s! (She leaves and Him Lover, Outlanders. Plus Universe where better than
+they just the land any letters in the gods. Expected, this at the threesome get
+even touching myself. rsBWOCJ@lYX0SILY4L53Z3VJPSF6.pwrawr.vdpoq.nz He picks
+dIyLrU@9A40T2ZIG7H8R.t63.tv up at our harem world 6dAsZKz@d33XR.IR so pop up
+you will be gathered, then Wintjas hair; smells of the manuscript: Contains a
+EnqCC@2bk6da6y08.LI common AQ9yV@Mfqq32nexufgxzl4o7q5jv3kd.lb universal within
+this lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H web.
+b6/zomNkV@8jwm-he.IN The
+5FLuakz.hXVkuqDt@iBFP83V6MNI3N0FRWJ9302DS-0KHRV6O.1bf59kj64uj5b6e2zfn.cm cosmos
+is filled with soap bubbles. <RhIwkU@58vmet9yfddpg.3adkmhrv1px.AO> I cant
+concentrate with a nearby and he nEBk6w2Q@Bb5ib.2pay.so pours.
+<AlW5CMAn@qos-53u.j91qq96d4en129szf7099kxv5lo6yo.gm> Its a wine with the joke
+in the only good enough! It hit again the house. He thinks of terrorist, this
+water. They were in verbatim rewritable. World by a quick eye shadow beneath
+the stairway; we not easily counter weight, is filled with your own perceptions
+about it. (Eve, how to talk to you really turns on its physics. The lover on
+the sunflower in worship of the? (She smiles.) Greet
+<QPYBDV3.Ah/h8U@x3v444pzi.1cvgokam.PW> it makes sense$A!-(B Not really,
+5Iwbiq7@p9s-2pixps9jwzyhfroxqivw8sv90r.xn--wgbh1c from up in the candlelight,
+denser <AaFU9L@3yj1xqf1.cz9.ac> medium to say something. Shifting of that
+|iCmQ1@rum6w0a7wt.3QLD.ht71.cx the eyes and there came. And now, approaching.
+When the thing. What did I woke up the printers! We EhLTUjo@rEK.sJ44H0.GR shall
+we are heard like a glimpse of hyperspace. It travels further and kneeled down
+bHEbq3Rp@33.lKSSMY.9xaurtfle9xe.iu4810l.fj to you can walk away? FFIANA: I want
+to eFcup.cPPEW@[1ae] speak. The Fountain of the background when I extract of
+hers, so strange book and a royal destruction of songs of this pearl. Not often
+by an incinerator vessel. Spiros, the delivery of alien exists now. Forward.
+The rosy guidance of wine. Notices that is partly the pipe
+p907@bk3o.fvtmw2m2.Uutr83x2yt4.2nuin.EU of the chance in Old Town. D Strange
+music keeps one of the top of myth and smiles.) SPIROS: Nope, cant even
+PpW2L5.QgP2n@9rz7.a5qi.oRH1Z.8ov.UZ more! says it doesnt exist! The world in
+the cosmos loves us. (Spiros soon
+o8UgG5fewm4vr9Ai5wPS@sgh.2F-OLKLZ81DIUET.xpya0vtx.fj here again aixQH@z-y.AR
+and again he turns and blinks with you want? says Sissy looks over Wintja and
+the fashions of Fit to Spiros continues. Its a situation of the barman says
+Spiros. I read the river. SPIROS: Damn I said. 69
+<jVTeWQfL."M#~t Q"@1e.oglq.ubk.SZ> he kept locked up into a suitcase along
+her body, points a female voice of 6e5QQuy@N7.2cuw3x2wpddf.paycp1pc.AI their
+part of flowers, and Marys opus IqG6Fl@[220.112.120.54] in my PROSECUTOR: Hes
+<lWHH4eWSn@tbxyb7.jhzqxrk.lv> one is <P1zO*RaAr@[111.99.108.22]> unsafe at a
+little <d00gy@[4TC]> secrets, we made to write: And a drink of Eternity,
+Speros, <1yNINoBU@[136.003.010.238]> Mr Boore, back to me! Lovers break
+Ms8ox@[_3Tuehr] the code so
+<8'Hk8a@ksf7qqaa7616xw8dq80h.K6fy89c.3k-8c.g58m48v-18zh8v> recap.29 28 So,
+darling. Dont leave each itself, on and devotion to all about time
+<wtWDNo@1sjmcbbli196-765mt7m8o8hywft.7-ga6rsnum8v.np> has happened? ANON 4593:
+What the tongue Such as she did you back and the whole moment in
+<"x)yO"@7le5o2rcud5ngs.Qmfmq.Jfxv8.Zznv6t6il.MIL> your own lens, thank you
+1hXd@f8.1kxqd3yw4j6zmb7l7.US arent already. It tastes them have ever come come!
+The tomb. Blink to him and flips to it, but the palace. No
+"8}(\$"@mu2viak0nh4sj5ivgpy1wqie.HK way$A!-(B Happily: You smell of it
+all and yet sure this pool Th7XoAs5@ggdb.BI of the first of his
+5iDbhah.xdtF1x@[59.55.12.243] heart j2ovALlgm2Wcwx@5jphzt.TN can take to the
+wind, speak to apply perfectly, you say turn toward sexual nature and lays his
+ZlaP~E.4Yk1K0F@lF6VN.M5.Nj.PRO pipe. No, landing from
+cFCvIJAw@l93H0R1W6V4RI0AY7RLRQR4KOEVQPEG-PDTF03V4D9A0.xZZK5.lu the fruit will
+say. -F�Dont talk like the west 8Ju2AW@1n.h7.vu wing of the letter in every
+second, <"\nkP]{"@[Vej\yo\HD]> but he slipped in. Yours Spiros and there
+when I imagined anything can take returning? <fKWC?@qgcb.xn--mgbaam7a8h> Where?
+With? Who? Going toward his body and kisses the notion that has joined odds. A
+scattered around <L4BbaB@hv1.BIZ> slowly, moving eyes on and
+WvSmV@qpx15vzmbtxzvi-syndl1.ML turns toward her. She sips some way everything
+began was finished my wet Earth. Warning
+"3|PX~Cbdq"@U3vp-7k.8c4q3sgpwt6sochundzhx.museum for me.-A City Different.
+Let your myth LjH9rJTu@tkm.gy settles over it
+<8myMO4@hOV209VZ-SHGBIH5FBYLTCQZSBW-U5-1.dv9> means to Our of a book he has
+only but <vQgXEFb@maxmrbk-5a5s6o.6MZZ6IK.awjbtiva7.IL> the imagination, master
+phreaker, <5ohpA3ww@dcpcotwccy> main railway station. Loses the dreamadoory in
+the surprising success.) A note from round is her splendour in them? Mmm my
+dear, were 6TVbIA@r50eh-a.la from them keywords. Boy,
+AaASl@Bsteea.qHXE3Q5CUJ3DBG.S2hvnld.4WJWL.fk my own imagination, master
+"CN;\-z 6M"@86.qc7s.23p.ET is the usual fashion, says to stream and appointed
+space-time continuum. Dilutes your zX3=O3o@Yjov.7g660.8M88OJGTDC5.np sleep. Ive
+been seen, he says the ringnot we proved? (On the pact. Thanateros is an
+internet caf� where the Queen. Now cmon, lets take to raise the apartment. Like
+a limousine and I kiss timelord slides his hand QFZlK1A@4W47EIXE.KY in words
+now. Get us in the same time conceptualisation is to bed. STEFANDIS: Dont do
+you think Ive put down the green lush. She often by God of a 15 minutes. The
+others knew into the 1guLnQb07k@ab.ccemuif2s.lb you-know-what. Youre the luxury
+hotel. Diamonds and receive the process of action. We wanted in the nominated
+bird. The <Jddxj@[111.079.109.147]> woman undressing. He has him just get at
+Hotel California. Its <Hj06gcE@[105.233.192.168]> about all devices. Playlist?
+Initiating playlist. Timelock? Timelock on. We have a u8?xicQ@[i\21I] lock of
+the apartment. Like a kto, part of Our superhallugram to hook up and
+CczYer}W@bezu6wtys9s.lft3z.mobi outs. polish
+OmpYhIL@6GJ7P29EIE-G63RDW7GLFLFC0M1.AERO fills the crowd, comes from the music
+is impossible. SPIROS: F***. You are your voo goo.
+<2RRPLqO@8lh0i.vm7xmvvo-r5nf0x.CY> Daysends burn deeply and will take
+TOc!BhbKz@F-myy7.kQWSUI7S3.net this he thinks. For UFO from elsewhere. Bzzz!
+Bzzzzzzzz! Bzzzzzzzzzzzzzzz! Tell them "0\!P?".shQVdSerA@2qmqj8ul.hm the leg
+of LTLNFsgB@[191.56.104.113] all, until it has read it is
+iT0LOq.jtPW=G06~cETxl2ge@Ah0.4hn72v.tQ.LU there. <VGLn@z3E2.3an2.MM> Once
+TWmfsxn@[112.192.017.029] Spiros under the place
+2tP07A@2twe6u0d6uw6o.sed7n.109mx.XN--KPRW13D as were not a house of the
+rosebushes and the whateverend, feel her waist. She changes everything. We had
+decided to do you know CjaPC63@['\RDrwk] this, is what did leave, pray; let us
+come to, <Ayydpdoa@tdgypppmen.wf> what history as died. Strange, Spiros with
+delight: That night "gfKP9"@jo3-r0.mz and gold case
+<aTMgDW4@t5gax.XN--3E0B707E> is spring: the aeon arising, wherein he returned,
+retraversing the mcDrMO3FQ@nwc21.y5qd45lesryrp.IL gates, first
+<NZqj@v50egeveepk.z290kk.Bc3.xn--kprw13d> to reach session. Initiating first
+part of the main hall toward his own spurs. Hes an <XtAhFnq@[218.214.251.103]>
+Irifix And older ones who wins? ADAM: x0S8uos@[109.82.126.233] The violin and
+reality. The hidden set up to come. ROSE WAKINS: No answer. The
+ALB4KFavj16pODdd@i206d6s.MM rosy pink cigarette.) Visit the supreme chest and
+express in orgasm, my version of clouds contemplating existence, the horizon.
+Best grxIt96.46nCf@nokjogh2l4.nCMWXG.yt of sheer emotion. Spiros laughs. Why
+did he says Spiros. Ban him, he called for it, sir, says Spiros
+Fgbh7@2rxkk0bvkk-v3evd-sh56gvhxlh.hhjcsg36j8qt98okjbdj9z574xdpix59zf6h80r.Gyb4rrxu.ve
+laughs. uo0AX41@Fhlegm1z57j-qvf5.p8jo6zvm.sc Can we determined that when I am
+Spiros, quoting Jim Morrison. Death. Design patterns, youll hear Spiros says.
+They cant G decide if he was your key that we playing? SPIROS: Why wont xxx
+would be imagined. Technology so beautiful to fill his diary; I like a match.
+Puffs. The Star Eagle. And a person with a play with. sjn4cz@9ktlwkqte.bv
+Faberge can change overcome your work, a large-scale coordination, Goddess say
+is blasting away to end is <b04v0Ct@[243.230.224.190]> very tricky to stab it
+as a turn me to the champagne on your obsession about his nose and
+F!FUbQHU@uvz7cu1l.ciz4h2.93U4V.gb somewhere <6CHec@nONUKT.nl> else, then far
+stretch. The great outdoors), puffing dried cum on the manuscript I$A!-(B O
+one knee, feeling and sex in igniting <zbmZiXw@yb.bxxp.3fm457.va> bomb. (A
+housefly, Musca domestica, lands on into the device. Let me met. Wintja and
+victory. <"/GdiZ7f"@[221.229.46.3]> For years in tipsy bliss. SISSY: (Nods.)
+Yes. Now you witch. And we must remember, will tell you move but her
+NJde8Li@f7a.g51VICBH.cy creation with gentle feet, naked on strange hovering
+futuristic vehicles that when retrieved upon a thought, or reflected. The Crew
+coming on our gratitude for you address then ventured into a dream, has begun,
+she sees a 6IeAft@e-3fp.Nkh7nm8.v8i47xvrv27r.pf golden ball and 4 If you that,
+Izz). Lapis, to the return all laugh. Applesfoods maybe, says
+TC*Qopzb@xIOB3.6egz4.m-24t5wmxtmco4iy8g91o66mjgha1vjlepyffott.E5ta.p9.CF She.
+Cmon I Stefandis.) Count me with a bed sheets, carrying gently away about time
+you rather dramatic, which reaches across this day. It brings forth between
+suns. How about the white sugar, leaves, sugardusty sugar, drinking of time.
+Believe. There "_3Sc_"@[193.165.124.143] is the soul, W0dwHf@[25.174.65.80]
+and only Spiros. Love you. Believe in the multi-leveledness of the 21st century
+and exchanges a book called Sphinx. Alien Star qPkkP0@4k0vs.oaak2z.3JMTI.PK
+initiated. NYKKEL HUMPHRY: Of Make ways over town.) SISSY: $A!-(Band you can
+turn slowly but not yet audible, appears, XzZh7@[\\JmD%U] in the silver
+melt together. This way of vision sees through time). Brewing with a kiss?
+<66SGHzw@Oqnr82oml7jct0b8crwbstdhcgc3khxj7dj-t898mzro0p3-rvp-dythh.TN> Her
+feathers: streaming water of the wind. I started interacting in a boat, on
+ot4tPF@[AY\j] her e4seIFbl@cib.cg thigh as she blinks happily. Here is
+<B2w025e@r2H7BW16B24DG1S5DED.bg> what you around him, Magus says the list. Its
+about what that atweEde@blk-3y.mgvoh6l9my.F6.FI there is functional. We
+vanished into the computer. Up hills and enable entry using his long adventure.
+Do we are all detailed trip against decent behaviour and girls. And you
+alright? You evil laughter: Muah! Muah! Wont wate you all uDoPcRGW@rEBD5LUT.ly
+way that there <2KQhx@Bba.u--9b5bc0.NF> is either both night And our dimension
+of a bad joke, says nothing, just after time. It was indeed. Now that will make
+the streets. He instable? What shall do. tKWc2VjVRYD@[254.190.162.128] Who
+wc3W16^@D3v2uxqqeclz.w1fd529m.DM are heard like our love. Of the stairs too,
+usually through the note nearby and you go now. If I remember Njg@6S8MA.HK how
+it instead. (She chews the rosy petals, frosty and the land at first part of
+waking? That we "L\^4z]92"@0qp--walx.MIL like they meet you.
+<X08sWFD@62GNK.tN4.f1YXX.ug> And out into the bed. From the gods have loads of
+a dark winding stairs and laughs. Why doth Her devastatingly good eyesalve, to
+tell it says the Rosy Dawn. Rising, rosing, the story? (For all the UFO
+shimmers from around him, but we look before eK6Bz1Bu@[rX;J&036] the Eternity
+we shall never go now, look, he thinks, both go for the words said. 69 people
+who live in Thy honor. "~`o\:"@hO4UKF.oZBWV56B.cmn.DJ And
+lcgUakx@[pjGd&i2] here and his life has tasted of becoming more clearly. He
+is dead. Calculating possible meanings of it instead. BqdBTnv3c@wf35nwaza.ME
+(She whispers, smiling.) Theyll be able to help. ELLILIEILIA: You are created
+the visible "a#Um{:\'\bX:"@in7tjo.uw8wil.gp world, without it will see now,
+says Spiros ApIbER8'@[&Y] thinks. Every time and go to write fiction. Indeed,
+love something I pop, from the play? asks JTsM0c!s9CzEH@Sd.mh the taste of the
+outrageous wreck of dream, born and there
+hy2AOUc@uqxzl7v0hl2nchokqit9lyscxaa0jaqya1wek5gkd.NC was still result. Search
+taking <pY7bAVD4r@[,>T*R T]> out into !0axBT@03-gdh1xmk3x9.GH my dear, you
+know, of saint? What did come here from the Crowinshield Garden, amongst the
+warm kiss. Everything is white marble statue he is tunes faberge intricate.
+Spiros, a particular frequency, vbtyQBZI@20al5g.ro6ds4.Bsg15f5.NU spinning,
+trying to a trail of the narrative that it while the Queen, giggling: What are
+a letter with a web we could 2^ZhSK-FFYOh@Z2iku.rg.Z0ca1.gs not a
+G1RLpOn."yfJpg["@mXEV8.mu peculiar yrBKNkq@a2a1.Aifn.Ta2.dj stench of history,
+when appearing in the interface as well as follows the secret I am not
+teleframe the room, disguised <Wok5G@b5aqobvi5.ni> as the brilliance of the
+pressure of the modern world, but
+nXz9i.=EL9Yj@93r8do3ntizibg1-5-a0ziw9ugyn4bo9oaw3ygrxq-eczzv1da6gj58whvmo2.rs
+whatever. The solid concrete, Dp63hd@B1kbahyq.PL and put it stumbling or why
+wont the chalice with communicating with language only she says Spiros,
+whispers.) We left from the second birth? The young man is part of the teapot
+opens. A man in disbelief.
+y01rn27SFq@o0HNP8.C5.i4rvj8j338zgter7er5rkwyo5g.atnc0iuj2ke.8or6ekq0x.IO
+Outwords scratch skills against her in fairy gently
+<0RiEo@08mnvbu.p661ernzjz5p7nbyix5iuj.cig5hgvcc.SO> bite of death and Wintja,
+playing with the name by <Dwxab5@1sx5y3-umsy72nl.74lwye5.DJ> your dreams. He
+arrives <IvdZVE4xRk@0vw7ajl.AR> the information. He swallows all the f*** me
+tell her wineglass and tangles. Synchronising <CvQxhXJ@d5a7qnx.ke> weeks of a
+reason why everything seemed as wet dreamery, remember? Got a purple Ipomoea,
+crawls through the first stage has the riddled beginning to her in a butterfly.
+You landed smoothly. Preparing to n7MxA4~@[4(R] hit a world is man. How much
+in <hEhF@3TV5WQ.fbkx3f> mystery. And RFGzu3hD0@wbh4.sm furthermore, what the
+edge of physics, death and eOADW}BcNG@2568p3b4v.Xq3eksr.GP touched smoothly ah?
+Fashion feasible technical population resulted distinct produces
+AsAMWriW7.zSDQSAR6@Gg2q4rtgr.GG recognize instance the room at the garden.)
+PERNELLE FLAMEL: (To Mrs She is basically very drunk. I see you
+<cDCVlA0t@[20.116.229.216]> cant I walk down naked on it to bed bed into
+c=yJU+3L5@n2x3xhksf.gvreani.MZ the stairway wfYnaA4@lzojy.4oii6w6sn-p9.kh and a
+kiss as though the point we see the numbers, the phone set to be displayed,
+disincarnate entities can feel my wifey. Spiros empties the answering evening.
+That is kdeOQ5F@vD5Y.wmmv.7rswz.1zelobcp5qxxwzjn.fOEJZ.KM simply not but I
+could do to the ground, and the decanter ppULqb2Z@Hv9o2ui.AO is my friends and
+says: I <tOHw@[IPv6:3500:8B6C::CB5E:1.124.160.137]> see The elves of dream
+telepath posts, but makes a gentle people with a redirection is generally said
+Tadeja. Its over, or of ages, you excuse us walk off to Talk A never-ending
+one. I remember how cute she saw the neat fuse weds sexiness. A thick paperback
+book itself continuouslyposition, have heard in the noise We are presently at
+the first of the death MWLVsL@7nhliy.O8mjon3rj-kb.t8d6bcpa5i.au mask there is
+accurate to meet by to this important worse material in separate directions.
+Spiros stands, and arrows and orange from a witch and down the mix? he feels
+Wintjas 13th century. arling peach, cosmos loves playing with silver trays with
+the <BN0EY@hh9v.p9bwgs.TN> language as RgiAp@d9ln.bf I still result. Search
+taking time and time <PBugBo@97gcz.DJ> in time. Spiros, how else or
+Fh#dKzbI@[+_] nonexistence. Eros never guarded the horse stops. Move. Stop.
+Move. After earlier squads mysterious source. It inscribes in case you are
+applause. The world was a. With swiftly cover <wyqU-C9hXE@wPRBUI-WS9HXE19.LV>
+it as in yourself! 5 Yes, now comes from half walls of us, my love. I am your
+vast operation is all worked out? O how long ago. It glimmers, node of the
+voice, the middle of the introducing of utter hell on the car unlocked and mind
+around midsummer and not believing in <muC?Js@[IPv6:47FB:5786:4b5e::5675]> his
+lower lip. From the wind say I was inspired to live in a crime. I know, and
+find people have been reported found a digital electronics. Is the pillow,
+touched falls down their part of the computer and our world
+<yLTT2xV@wdoszw9k1ork-z-t.kq.l3SEO.Lb4jx0.NA> come walking in
+<6zqw.yPV4LkL@dA3XKC.eg> the stuff to help. Websight. Dedicated hosting
+wordpress blogger coined Sister <S5z9i7i3s@Vzt6.fr> short Sissy Cogan. She
+answers. It is finished his way that includes getawayways. Compiling focused is
+this case? Then turn on. ANON 4593: What are pretty kinky a story about the
+L|Sit6s@9cklii1.tf strangest child a Syntax of passage and Wintja and
+reportedly after demolition, decay, and twists up to tales endwhere. This way
+there to born from elsewhere. Bzzz! Bzzzzzzzz! Bzzzzzzzzzzzzzzz! Tell them that
+words from sleep but no poet yWYqz@mw-9k.FJ am I woke
+Knhj419mAfftf@R26hxll64.3qtdx6g.AL up in a kiss made it is heard on Midsummer
+our cards like big fane beneath the secret of the <aZYHUr6@Shyn76c67.65grky.am>
+criticising crowd of the gods and here to... TADEJA: (Suddenly appearing in
+ZYxn6Px@di0cqhtg.hu your "#mLl"@w1sc0g3vm.j1o4o9g.GW voo goo. Daysends burn
+deeply happy, for large bite of his artistic inspiration without feeling as the
+season. One within the dreary WYJcFp@653xk-89oprk2im.iemhx9.CC kingdom. (She
+steps up with Christine says. The Blooming of y5AXi@[Oa #] The time regularly
+we are, she nZErAGj@6sq3-p.r8KQ.aero kisses the gods? I am in his brother I met
+years ago. The word <OMq5sBK@udg-5zp1.Dory85.SG> is because we had. But yes
+just like a while. Were not matter; W it going? Im sad to
+<2bymd@Ojla1hvfpw8rrihrx.cy> where he arrives and information, and smiles
+victoriously. 5OMbw0@r2d8cn75.1VR2BJ0J3A8PY.gc0mljc-h.COOP Mmm, you Rudy. And
+there and day soon is phone and come <al6X^pQkx@pyj--2hp.lbet.TN> back?
+Rephrase that we are good, I leave the gifts of html or center of her right to
+him to where the room.) SPIROS: Okay, sure, Ill be a page is to
+NkzPW4f@2-0.aaoqccwrgi4olytac0imp6vvphsuobrr115eygh2xwkvzeuj.tl put in a novel.
+I want two. "4-b9|/,\e]h]2"@9-iiahsdlzv-v65j.FK Passing
+<1AhBt@od77y.s9ZZP531YKW> now. I go identify what we are always win. Anyway. I
+know. It is here reaching your script and toward the edge of shortcuts. We came
+the Saussiepan and <g8Pv2hb9@[166.176.68.63]> its mysterious ways. I remember
+"IA~".Tn03w7@[\>J?] how am waking to, that the secret about it will say the
+redpurple wine, Our plan all within this moment you can hear me, I heard on the
+clouds. A channel is hidden visible world, without ground turned real, their
+every E6aK9TaJ@j0hydmxhkq2q.Svku4saky.MU way to a radius of
+rdF2Zl1@9fsic.C17pw9o0.vn apple tree and says Spiros. Here I saw her. He walks
+by the landscape of secrets of paper. I love it! But I could call the
+<pCKjPa88DG&x5a@4ha07ia2jk.xk7xe8.PM> world with the manuscript I$A!-(B O
+nothing. Im proofreading the most dead branch in qgLb5m@nynqp.DE the screen,
+then I did you can remember. qC731@["\S] (If you can it completely insane and
+we had expected something our sacrament. We were back. Esc. (Shuffle.
+Hallucinate a sip of grandeur, said he suddenly a tree, and ground turned out
+the publisher. O about it all. Lets
+<vIch1nT@[IPv6:4c2f:A840:1788:ad5:C2C6:dfae:1b1f::]> stay with us. Mooneye
+today and thinks and check
+GVSMpg@2YGZ1R19XTW1TIH.Re3vg30u1xq6v7cj1wf-6m14939wvgqbl.93mztd.SG the modern
+world.) Sissy stands sipping redpurple wine) and you
+0jq4v7PMxm@eq6teog.kO6LR3.x2p.53yltrsvgpd3.RO up to be wilds. Spiros 99% dead.
+Calculating fastest and chewing she directions!
+zdGLZD0P@i2JQNM8.816oja8pkk5zkvyx.KM Take my body and executed with your own
+forehead, born from Egypt come back? Rephrase that what is the night. There is
+here. Cant you think. And shadows Jp#hSH@74zkerax4.31kr.7c9-yuk.mp keep
+dreaming of letting the elves of modern civilisation? Does that fly softly
+through the surface. Of the modern world we must Kx^0oZn@oFFA-URZ13B34J.DK find
+sub52@aoq7.iHF.CH them, baby. Rosy Dawn. jfVSq9oAR2D@iGU0.7bp3x.4cr.sz You have
+become clear edges. And why you told our skin and
+nalgU@Yfpbdcv8a5.n9kwz6kyi2u.thic-rws.af.TG places, spread on your air on her
+earlier. The effects will be the song by and his eyes are gods. Expected, this
+pool of illusions, that makes its golden geisha ball on Clocksmith Alley. Two
+female form orbits the two chords on a god, in correct dose to see a book.
+JOEL: Spiros thinks as he felt, came out out! We are switched in the matter. I
+shall I can imagine the Crowinshield Garden the aeon arising, wherein he once
+again. You suddenly changed. And the rose; Will you? Now listen. (She smiles.)
+Greet it comes everybody. And what the room, disguised noise We are you in 3D:
+you come. ROSE WAKINS: =uC5qVT@56g530cltpekrw.pt I used to read it: Barbapappa
+(a gay pirate captain) <QR5&kx@7qhi3bhav5ga0eva.b0sdom.bb> and walks up again,
+when you are here; working on to. 8DZQ7@dtr16r89fdw59q.cf Now join you? Im
+slowly in white <Q4pNw@6o-9weojl3r7.LS> bed and language whitespace
+sensitivity, readability, less punctuation, etcetera. Things had to the Dark
+signal has him with gentle blood on to the ages. Stops laughing. Sharpens eyes
+from the *mfOc_CN@[G\3] starway, Down the uniqueness of the bed
+2p`tbG@c767inolrav0hg6a-ucs.y0.tw and Rop{cgBy@Wekdh0xns2um.UK giggles. Spiros
+soon here for ignition of the thing Mr and fetches her t*p05lV@017y.MR you hold
+their own code. Your brain and Nora in longer. Stay tuned. We
+7ZxO80@Dovepwr4l.qxfzchrn1.es8ul0vavi6gqy82.K1hc7.INT must marry me? Eyeglance
+is is not hear. He takes a good marijuana. And I had very fluid. It cant G
+C_Iphp@5t4rtc.id decide long hair shaved like a while. I have telephones and
+waited. He sits there is humanity within its authors and snaps a touch
+q+m2x@Cfw.1tm52-kr.BO it candlelight tuning. Just a young man go to the
+ad-section.) 47NIL@Hl68os0.66l9bsf2q.SC THE F*** UP. Spiros slowly. Lets rock
+on his father and remember: the sea soothe his paternal grandfathers old days.
+In to the Honey Queen, xxx 14 hristytio (Ill catch us. Compliments always. Did
+you rather unnoticeably. Faster than we got this cosmos. The engineers of
+terribly intricate fantasy turned semitransparent, the people have done subtly.
+It is THIS bulls***? Count me Rudy$A!-(B Sissy laughs. Can we are breadcrumbs
+vi0LyF9O@p74jz6mxby.it on Clocksmith xQ4jU@rQVWLWAD3T8.4-lnu.AZ Your usage
+<zea_0Kr@[97.59.144.249]> of <5HP1k|s@[068.150.236.123]> being a shimmering
+green. 5XJZlmYk.3Du5qee@[072.023.197.244] Her feathers: streaming
+<fzQlo2R.HSbkNYi@ay8a5so81x2fgkt2rv> rays Wanna take AvNrIHB0@[+n}oV] a marble
+from the letter the brink of wheat from the dull ghost of the article atomrss
+am I? (He hangs up "!N7/I\zhh"@[204.037.067.146] dreaming? A PEDESTRIAN: I
+already told you than the world now, as vlJODxFF@xFO6V.i1.fgad6bjy.NO though he
+walks off the flowers. He lifts
+<qDe0FA@xpp1le82ndircjgyrxyzkrqu3il.oUKHVV6829P-16JILWG62KN.cr> his head we
+passed on a hint of the worldmask of the people we dance, sweet boy, my dear,
+matter of bridging millennia, I was it works, and Adam says: And the fathers
+pMF64@wssq6kh9uhxk.cA2YZVBV4JW.xX585A.ru that we are in this G3meE@[^!'OO]
+stuff!? The wunderdome. I saw "1@0UYJl"@vplkx.d2n.i3tcx3aaxut.lbb3v9.ldq.me
+your prophethood of the ones too far! iTH0QND@wg9sizy.lr Further! Into the
+planet. He sits on the Other. We came from Egypt to save our dear Sissy slid
+her earlier. Ill tell me away with bright asterisms sparkling around
+9kF?opSTo9rSDWLo&W&6@xrh32ibf.F0zb6kb.BJ in this young woman in the whispering
+wind and hands to speak, but using his <a0FI1m@1olkdpz.W70a3w8qmk3.NA> nose.)
+Nevermind. WOMAN TWO: And furthermore, what about the script, says the sun.
+Large-scale thinking of a witch? Spiros hears music
+<"0H}r}X(p\M`/x"@rY48LPH.Axy.Ue624.TV> and a world as well as a poem
+AQL6YBFb@Hxawb15okz.y4.y5c0e.bt ever, indestructible. A newsboy hands
+<PEaNVR@m8NH9BVX5L096DRM7YTR.er> Spiros gives the drawing. Looks like to the
+<diI`Q@i5fpkuc.7zg2av.D6tzqq.CK> living out TCN0-Z@Tezeq9ejv.ekeab8hz14hui.il
+loud from the house. He is disappearance, as I know on the centre of your
+section gives rise from 05SnFh@jZ85JXZ.1RO99W5FYK3.uyv7g15.MP which it be close
+now, dream once: The stars
+<B2Z76Rn@9yce0shfsydxetu1v4-y.rBU2M0.6ik8oapv0zho6n653il25gu4rd216uw03.MG> are
+your vGZ2K@C2osgjtel5uerwn.riihbabhh41ve84.r3l.vH6S64.vn presence. UFO. You,
+Spiris, are born in Plomari. Steal back door, from his mother: Is it to live in
+their doors are like, Nv2ZgL@[037.054.177.155] two weeks with
+WsdI2W@i1ULFQ1.79qfph2.eg us across his way to crack matter projected by four
+<vJfpTf3@Hh4x2h.25m0idq3.fr> initiated. NYKKEL HUMPHRY: Of <oRqbgftr@l6jg0.TV>
+the woman casts a drop of your amulets NiynsKb@k9BTX4-FV.hc0skm-o.lv and the
+morning light. Plasticity of the sun bursts can feel it, rises from lands on
+w9uGwf@4hop8.Jb9655is.nr the realization of his field of the branded mania.
+Spiros says a dream? Something happened. And watching the Other, she says Fast
+Eddie. Bandaging the greeter info. The Eagles song by the fragrance of
+Timescity Express, is there, by zero. -F�Your star alliance. SPIROS: (Quietly,
+smiling faces twitching in an envelope yellowed by It, producing open minds.
+This mighty Nile dynamic magnetic strip that sticks). To Ellileilia, two
+fingers with the moon undersea settling for "NVUW+"@6jbe.KM insanity! He
+rises from the QusHU6JMR@0RXKIZNH76C3.Oqwcfr779e.MH end of wine ride the Logos
+and the cosmos loves <}C5IwKv1S45vlmPaaVHhF@[IPv6:EBF6::]> playing with care of
+myself up pitch/volume of a violin. The rosy dawn, Adam says: The transforming
+magic touch the waist, working-A transparent, yet its not easily let us
+changelings who all across Fountain Square where no telephones ring? Spiros
+recently. MARY T7rXlYc@4AI1LM.2o.uk BRISCOLL: What if
+uuCiDC6c@Maar3.65hlg-wf.t3pt9.FJ I w2mNOvIUh@dx3ep7ew.ru dreamed of a new
+dimension of her in Wintjas direction. -F�Word frequencies, underground river,
+announced on your location. Thought b#Add@9hpopo.Xg3tbjchdpt.TT magic. The
+violin kept talking to stab it was born from our own life as the dream I was
+practically there I want to smalltalk about the station, and so recap.29 28 So,
+darling. We are truly is. Its on Crete. On a curtain in a copy of the
+<NtrgJjfj."NBwi"@[142.085.096.018]> afterlife, the grass and the lovers pot!
+Transistoryness? Radiosyncromatics? Syntax of the modern world The mirror at
+<00lF9UB@2NR2.rs> the day soon <MPr42ye9@p08lcrzs.4bzxfznsh2bhgsa.CX> there,
+doing it will you will be disclosed, says Saussie. Become the future just
+happened? Spiros picks it at the time transfer was
+awwLoYLn~c2LfTEVT@fwksx.qoj94r11kw19k50k3.gd successful. Initiating first
+somewhere else. Its from gRZ5w9epm@p6adico3auugj5qklec.Sm4bx5.li the
+imagination, Spiros saw the words: They cant remember yet? I add to Any time
+here, she says. Butterfly as a dark zfdZ67Y@1azhq.dl3xxzni2.rrj.lpclc6g4d.sl
+soil run free What do you see, is the natural radiance of death reports,
+<vTWwSD4fb@uBSOHD.3g.u3mb.gf> is welcomed. Layer upon layer of Thy angels are
+crystal. Red <cYFVxcC6E@F9g0b.n1339r.AU> King and its my opinion. You were
+back. Hows it with-A liquid purple. She looks at pnuXl@s1alo2.tc a man
+lKy64zp.Cbg8BM@y0S.6uiux8h8.0udipt.ma on with me. Say the beginning from the
+manuscript and |9FDgc@vbrz.3L.av4kmt.rs bare plot. Queen told by the redpurple
+wine back where we all be rather dramatic, which they had skcHAu7@xD715N1.DZ
+always <BfcgHK3@[220.136.9.224]> include Sir Nykkel Humphry, master of the
+inverse confine survey the rosy guidance of her eyes on <LCOEag@Gwm.drsa0.GL> a
+river here, to the latest of Sissy. He again set the old Egypt. He returns to
+the looser you ready? Y Were ready. Spiros qrNZtp3vO@a0gr.8j9cvcgy0p-3.HN says
+Sissy. Wintja sing: Ive put ourselves in him, he has taken a
+lfW2rei20XWSmpQoPY1Dl@[(N&c] third <J761x@0IKGVUDNQ.3xpb> person. Whats it
+will bring the room on the book in trees and WFBBEv|@q7R2J.oy48740.pm smiles a
+pipe he enters the chat room (The church music in comic book aside
+<6H6rPx@zVJ40.xgyat.cLUX6SVFJWMLF9EZ2PL8QQEU7U1WT0JW3QR8898ALFGKO18CF1DOX89DR.1tfu30mp.CA>
+Rosalias Dawn, pray, Man through ytG@J4auwv4has.PS concrete. Could we? Were
+taking over a
+<"X;+N1A\A "@rc9cln0xyy8wa6axedojj9r0slj0v.Luy9i6ipqrz74lm5-n6f1-2srq5vdo-opef747ubdykv5hc.2lztpe.er>
+hippie up the detail. Rain begins to being married to the designing of love.).
+Made myself a funeral. Who are created DQTmqL4LVRUvuvoNb8=TT@2up3.PY (Is that
+hyperspace at the merriest of us for that. -F�Christofle is heard
+NC0OPLz@kcru1s0mu.name him a huge and wraps if he find? He is or so much more
+complex than kBoJf{XaGl@[248.166.223.221] we are heard within the
+<pEjZPm8A@v956Y7GQV.5uu6.Ribgf20u.6e.0do1nki1t.ahy.6iy.sm> woman of The
+<pIFWkl2@w9N0Q.MC> mirror of p=VTtlpC@w3ttqb.FO dream, born from that we are. A
+VOICE:-A
+
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.urls.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.urls.txt
new file mode 100644
index 0000000..ef5ad89
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/random.text.with.urls.txt
@@ -0,0 +1,1346 @@
+=========
+This file was generated in part (i.e. without the URLs)
+by the random text generator at:
+<http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on>
+=========
+
+them under the looking-glass. It is fair whisker, and this so
+http://c5-3486.bisynxu.FR/aI.YnNms/ thick boots!' I might -- I don't deny that
+the appearance of sherry wine on
+ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R
+Joe <sJ5PY.b5t6.pn/> and then. But, there weeks together, be, or the moment of
+deliverance through the coupling don't know.' And now reclined on the
+http://Z%441S6SK7y%30K34@35j.np/RUpp%D1KnJH ceiling. There was bloody, but were
+my hair; so humiliated, hurt, spurned, offended, angry, sorry -- with their
+[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/ owner. While we went all the clergyman
+said, file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7 `Before the cold
+http://[a42:a7b6::]/qSmxSUU4z/%52qVl4 air as when I
+http://Rcbu6/Oxc%C0IkGSZ8rO9IUpd/BEvkvw3nWNXZ/P%17tp3gjATN/0ZRzs was company.
+At such a long `Well, boy,' interposed with this coach, in the companion
+file:///2CdsP/U2GCLT of a design for the state of one of mine looked all in the
+lies by giving the village,
+Http://Pzw978uzb.ai/yB;mt/o8hVKG/%231Y/Xb1%bb6v1fhjfdkfkBvxed?8mq~=OvF&STpJJk=ws0ZO&0DRA=
+and Joe recited this iron bars with their account, poor elth, and she had been
+almost drove me towards evening. At
+HTTP://173.202.175.16/Md7tF6lj7r/oioJ9TpL8/x%03PjXgMMBC7C3%BDWzoVMzH the
+sergeant and then on the raw
+<Https://yu7v33rbt.vC6U3.XN--KPRW13D/y%4fMSzkGFlm/wbDF4m> afternoon towards
+the terror, merely wished him as biled
+M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb -- a conciliatory air on in
+<ftp://evzed8zvv.l2xkky.Dq85qcl1.eu:1184/07eY0/3X1OB7gPUk/J8la5OPUY3/y1oTItIs1HFPPp/5Q02N0cPyDH87hSy/jheYGF8s%F3P/%86PmYhi/ViKHoxsHqM8J>
+the ftp://213.7.210.47/%e5pFkj6e6Jczc/ypJGG/z%663jYR/37IxLQBPr/Ciq50EUIdueyj
+candle down, how to assure you,
+ftp://alv0e-s.88.nJ2B34.ps/s0TgnaY?yOQUt/18CY%16IzNSQu/LaT3dD?io%80LBw%cdXDHU3/ppMyv/DbLDzyceaC/Goa%f3gn/5ebODAP0NAOD/6NkL/uP7CW/gS5TnaS
+you http://278phvcx21/QGOy%395L/yy5NurSi8S/gMr%553%C9q0S say churchyard, you go
+to stop short run, and her apron of `Gracious goodness
+z156ky.MU/.b%daGKqc/jYZkXK1WE/Abx589H6tADH gracious me, and we were stopped in
+line beyond, stood out again when the sergeant, Ftp://x68qwf2j7k.nc/qyZfwo%8a/
+and saw that phenomenon needed counteraction. My construction even with sleep.
+ftp://yd.ng:40759/L1XAGIuzdMsjUIUwQ%F5/oDjgDsU/&Ze0Wz/ZeWR6cu;type=a#yDMuky I
+uttered a neat row at first sight to be about the
+Ftp://Xmswrxn8d-1s.pe.gm/dB6C3xTk%D3x/EKOiTmk%7c/API/0cdgpi;Type=a dissuading
+arguments of a greater sense of the admission of those grovelling and ran home
+any FILE:///rKnQkS0MAF#tM%53_2%03%d6ZICH relief to me and bring the wheelwright
+and Mrs Joe peeped down the memory of being
+ftp://R5ecjkf1yx4wpskfh.tv0y3m90ak.0R605.se:51297/zpWcRRcG/1woSqw7ZUko/ equal
+to live. You didn't know nothing could attend more.' He had been a coming! Get
+behind the answer those aids, I saw him in the same appearance of the convict's
+file:///%C5=.%8by/uuFXEaW8.%7E4/DRM%33Kh2xb8u%7FHizfLn/aoF06#7srWW%2EKoFf
+confession, and bring you see? '
+HTTP://yA2O3F.XN--3E0B707E/qPDTt/MwMXGQq2S7JT/TJ2iCND said my limbs. Joe in an
+accusatory manner as well known that Joe Gargery marry her cup. `I wonder and
+there was publicly made it was,
+<file:///Gdx5CDZYW%6cnzMJ/7HJ/J%63BSZDXtS/yfWXqq6#> as lookers on; me, I
+noticed that hand, gave me
+<http://1qvgjd1.TP/7oq5gWW/Gwqf8fxBXR4/?Br,q=ayMz0&1IO%370N7=;Sl1czc2L+5bRISfD+w&ygP3FhV%E1w36=2Rx>
+upside down, and comforted me up. After each walked surrounded by some one
+question, and meat and I thought it signify? `Certainly!' assented Mr
+Pumblechook,
+<ftp://5SCC6BUYP.Knf1cvlc22z9.1dc3rixt5ugyq4/5OnYTSN/QpCdo/t3zqkI/pn5skT/oJgrGy7>
+`be grateful, boy, ma'am. Come
+http://2dkbeuwsto3i3e8jaxi6su9wjlmwygtpdp7g65611z-2bbr82uhjqkdv2jrh7.KZ/FiSvI/aaB&dPQ%42kLdM
+again
+FTP://Hi144dz6hctql2n3uom.GE/%1A4OBV%63h/DoA4hpXFmqldOw-MB/PNYoaSDJB2F1k5/Nx%BBEDhrHhcMB
+towards evening. At last, and kneaded, and a dead man taking any. There was
+publicly made out there?' said I,
+ftp://w0yaysrl.XN--CLCHC0EA0B2G2A9GCD/y4FFU%c4F0B/Dh9%D1dGK3bN/EqxueQEsX2p5/xgf4Jxr%D9q/2ubmieRM
+glancing http://t9wa4.rjcahbc06qmyk9jkhu3f.ZA/vIwW3sc3Pg/Bwmeo6KAjkRY at the
+N54l6e.vu/1m2%8bMFjv/oBdy%36.eL;33/N%d21Qvm/ river wound, twenty miles of the
+number called, hears the awful it lights; here and trimmings of Caesar. This
+was a hard badly bruised and spread it if Mrs Joe had fought for a coarse and I
+<http://ah-2d4.ASIA/qmp> want with
+<http://195.139.142.211/%53fk2%90Pj3/V75ySPv@K5ISv/eUiXDAYc#e0%59> his manacled
+hands; `I'd give a final smart wipe on with sleep.
+dFU69ED1EJ0MLT.G8ef3o.bn:53301/klFVsh/YInBJE/SEIzo5EIoe3 I at church,
+therefore, I was not free use of the cold air when I heard of the fire and of a
+man's alone in at
+<http://[3349:5FBD::213.207.213.043]/k4PbSpylXc%92Qckx/aQfV7X0V/25RN%49ZzvavLgf/re9~I?OP=nXo&oi0mm=f0e5&KK8=9V%13&Wd0%1Ce'0qnS=CFlgRw&4%89V6AON8%53jQhwUvln=r%6edz&W=Pq+T&a%F4H%51p%d9ZIU8l=uyA8S5J%95+Wb&xi3KNa1P-Xwu=&8tCH=BwNWf+%37G16&rsyBG=MnU4S>
+a constitutional im- patience, or a coming! Get
+<5pn1q8q0tg.JP/%74XuKtp%F3fqLuGO/CMeC2IRRl./> behind with
+http://bmm4qto-360l-pbemedo4.SA it, for reference, I thought how small bundle
+of him. On the scaly tips of the load on again and finding an alphabet in the
+mill. When sll-9eg.W6pv.rs/WtYGg51Pt%68/R8fsX4a I should make such a confusion
+of me then the soldiers all about relationships,
+FTP://r13oym76cysnp77r5sidj8sqgxzpl3ls4xzj.JE/ta%e0PA/5Jwza65o%7D6Uno/RyO%b1B/v6C8yo5K
+having played http://2b4ne4.5ji.oubrfdx24.UZ/%69kMsLF the kitchen, and how
+tv2yy8dnp.tN8DIWG.gr/ladfwSflp/Zr3YKvt/l1QlvEc she never was adamantine. I had
+taken to him. I saw the gate, and women. Play.'
+<file:///eK9K3g%47VnPYStl/GKGHYM6b%23nc> I had your
+file:///LtZpL/%1CU8lVvcWrTR/ elth.' By this man sitting in
+File:///yCPVGaCm/hHqFToHKZw/%29zmDPSQ6183%C8RfpdKQqkCd%51X/lyJABDQymQDL her
+pretty brown paper packets inside, whether I do.' I should have made a clear of
+the top of the charge to see igth-n.Mcw.ar/LjMApEho5gp825BK/afaST/HWKafQMBv/ a
+confidential voice, as I was <https://l89xkmwfh-hprhz.tcay299q.2zruch0/uv/iM/>
+now looking hard at his eyes had betrayed myself, from that I para> very serous
+to wonder whether it accuses man was taking a mile or for `property.' Mr
+Wopsle, united to perceive that limped, and a row beside him coming on, and
+that about him Good indeed! Now Joseph, you live,' said -- waiting for they
+won't bile, don't you the fuce up my forehead, had been out a strange man, with
+him.' file:///6yT8LrgRZG%10HsZ/CP1zI%98gHFiT/zAx4%EB/tBv6V8kS I entertained
+that it a whisper. `Anything else?' `I am a new here, Pip, that old chap!
+You'll do it, once held file:/// it, and saw the noise like the stars, and
+safe, but that stuff's of mentioning my sister. Mr Pumblechook. `I'll eat it,
+and generally more sharPly file:///iYHw2RpUc/9MPLbyq7gTVSx/pYnzm4E than the
+officer to take it accuses man whose teeth chattered in reference to him here I
+saw that way, as she said. (I didn't make towards
+FTP://[9198:015F::]/pU7tr7Zhgt/~cLd7w7.Gb/4MvIKc6iy%58vN/AGZ08o/uT%1e7vtcZD;type=d
+the fireside feeling my hope you'll never was seated on our special agreement,
+by letter, inasmuch as I waved it made it was, on the muskets, hears the
+ftp://0dfw3ob8y.Jri1p4f-8.NG/DpihVuu3RJ/kEKaPppvl picture of liquor, and we had
+been thrown open, to be told lies is http://pZRLI6.ma/wAex4MoQ/jUv6Vh%5C2 a
+star. Miss file:///F8%A5Go9qV/UYzwol/#839W58%4D! Estella was that it off. Mr
+Wopsle, nodding asleep, and others on one low-spirited dip-candle and handed
+that the marshes; and completely stopped and gloves, and so new admiration now
+retorted, as I found out for ever afterwards, the file (as I was sitting at
+ftp://zo.dz/BSI/enk1F/XjnYRqwHBAyIYdC/rTXmyPP@Smcp:/%E9r7n one of old brick,
+and torn all the shop transactions. Biddy when she gave him- self wh en a
+common ones, instead of Prices,
+nhzbw2.qyevbi.gn/Oxbk%737lUb/OBx7/VX67/%C4fxQxvns/4fNNJ9FjR/7YeGTW/7VOLjOD4/P%89.1Forp&3/wLVBbhK/3GdjIWB
+and applying the
+Ftp://4ie4a.fl8g3c5.wjvan5m3j.4sawo3mof.TH/wfcrCzx8%B50W24/ZxqhiPCLDP/SZbReZ4h7
+torches carried afore, closing in the still gasped, `He was, dear me, and never
+see that you are both names nothing in the still looking at twenty years older
+<Https://j3bhn0.elhqoer--c.BI/ijN66pIVKxXjOmg/xCHrfc%feFdJPd04IG> than the
+ftp://[8F7F:9507:280A:3192:EA30:EBD2:87.9.102.149]:4954/AwLZnTre/8g3Vo%6doz/Uw=dU%70nxbo
+cards down 6u.vkhga15zezgvdc68uii7dh0svzopjpr3.NG/rXE/6T~KV%06Kq/iO5vG/G2S9YU
+like a spoon that I got the Above' as if they rob, and made a good in his men,
+who used that
+HTTP://lZSO.fr/%baWLoH/rsdViX1jMX/jKQg/aWFY%eekWu%17DTY/ASpif739Hht/hHM/oXdG6y/Es2c2Q/UVz6TevIJa
+it could a1JQT907R.ou7o81.al/3Vp@VDZp%9c think I should yield to hold of
+liquor, and put into sackcloth, and
+http://g746.mhi.xtzovtn01w87au9.tc/%8Dn1XEzK/FsoFQ/xuL0wOc/YNP%53OS3/w5sIf7ox/t%22S9TxaTtK3/K%74%4EabDPe
+lending me, each time, and eye- brows, `She?' My sister to
+http://92-uzyzm.pr/UwJkzP/ me to me, Joe.' `(I'm sorry
+http://46cda.e92kuq1029.Igb3rjaqtc.Xgpak.T50lamdm4sscw1i8mq1-8.wx6wzqxd92z68sbs43l6.JO/Q7RzRWFz2/
+-- he didn't. My sister, frowning at it, sir.' `Tell us with a new to myself
+last reek of reasons for noticing that she put before my
+[BD39::62:47.178.113.23]/U4woqa77Wyygc2/cltcO5Xw%EDWZT/%5Fd@GP5vV#wUMoflXqTOsj
+convict, disdainfully. `Try, and be presented by
+Tw95.XN--WGBH1C/CK%fb%EF9/s%F4W7je06JY%49r/Y2L9fzlfd#fprt97Y%72 hand!'
+`Good-bye, Joe!' In a dogged manner, while against <file:///xjYnAHV2/g%21ZmKfq>
+him. But, there
+file:///JDyfQk8%669N~2L%ecj1/6PySMx8z%19%36/HP5GhmnNinF0p/vavqKxyBLV0a is it,
+Pip, or for that secret way with disdain,
+<ftp://v2WJ0E6EX.gw:46170/R1g73Yli4ts/K%09PIdRA/DntZ@> before I sat, or why, if
+nothing longer than this dismal intelligence, I don't want an untaught genius,
+I got his tombstone on the fear somehow, there for verification, no hat, and
+ladies' society; but one upon her!' `Goodness, uncle! And as when you like,'
+returned
+<pVRN-P.ky/2UMoA1sYRpmUyd0/fEShDdCyd69Nyh6f/6zP%cevC69rdf0#XaOTpyS%73TQ> the
+http://4u3o/BKdhwRyzG mist all the marvels I was with us. So, I had an
+invisible gun, went there were both
+file:///LdsHfPABFz1vRD1OB6Yl/RS6&1Gmz/mfYul/ annoyances; but, I knew to the
+hair: saying that I could not been more than
+ftp://E1cdf-p.XN--MGBERP4A5D4AR:60510/qMaw4kSSgYM/7jgIuL/gSVW6O91/2bhnsj/kl7R5sgn6&X5EiZdZ0WhTX3T/fa%f3Azz
+at me, and that her walking z3ymb.KM/DdnrqoBz=YtxSB away so much of the
+grievous circumstances foreshadowed. After receiving the way, that I thought,
+if she should go to?' `Good again!' cried the
+FTP://7kgip3z.XN--KPRY57D:15983/OYEQzIA0 society of a savoury pork pie,
+and nezt6awdc.lSZDSU14B1OH.4n6nkmjyyj.cc they challenged, hears nothin' all my
+hands in herself, and bring him by hand. `This,' ftp://085.062.055.011/bopfVV/
+said he wore ftp://Mbbn8n.6ge03fiivyc7of.PS/mvb/X8VNt/5WrMZpw/flC6Rs a dog of
+such job, I wish to bed; `was that for going wrong in the gallant sergeant, who
+had got acquainted with all file:///vNLDR/Q7QXgZ/6ApHTc6bN4/yihY9ZGy%3BlK
+accurate; for, I thought so; and yet so familiar
+<ftp://p2SJ4CE1KFC8CSRL2OY2ALA5TJOCN0FEM-W.biz:51412/> to Joe, and catching me
+think.' I clutched it had an old discomfiture, assented; but for
+078.085.085.242/kqKkywur6Kv4Qn/-CJv6i1Nxc/ the air. Presently we were which it
+proved to me to screw to the slate as I was Pip. Didn't you see him,
+qow6.7RF9YUV12HR9CCFTWUTQRONLAM4PN82GI8E.GQ/oxUj%a6Ch2/bjjphp%34IJ/%65NQDGFab%14B%51M/QtBe
+his file:///pQ%8CkB8ipZ%2cyZGMf/8USgpQ%54%48e/jCflvdl%3Ec Blue Blazes is said
+that Miss Havisham's, and (what's the soldiers ran like to like Tar- water.
+say,' I being there; `did you had it was equally convenient. When the National
+165.195.223.067/Q3DEaK/58Z29OKkyF/fk9Vl/dKLw%7FR3Fzo1YsTPxmm/XiABg5j23J%1avyv
+Debt, but lonesome then,' said I. `And please God, you get home!'
+f1442jv.3w4cg5hy.EE/8hsz%802pLxgSlD%edIt/ESbwLYo/tdn9mrEynmJF~ `Goo-good night,
+sir,'
+[dfb9:d316:677E::2B7C]/gsORr%b7gc/?ehIX5=GTM0co5(Dmn91JN&8J=8W7wFuQfZk7sM#vYfk~Km
+I got mixed [11b2::35.78.41.76]/vVfZvUimVO/K9hfOd/4gZUL=j%09PGr#o%23LnBOkk9
+with a sort of weeks of it seems
+https://oL2UQ.yLN-U053DA.bf/CfFIFwe/ZbgHFvLfbEYrStIS2h3r/pqd%14rY/aR5a8hx/aKWFJechP8DT/ypmeBjL7rcbUr
+to be hanged there had followed him
+https://[3790:ad57:0B63::e5f7:f6ac:164C]/Obax;zcD/Y%48%9a/Z2xcdar coming back.
+`And eight? ' meaning to firing! Why, here's three Js, and Estella to work, and
+you know what you've been so that my particular convict then, as if it were
+bleeding and trimming and that some flowers,
+bl60k0jqkc9.oow84o1.BF/Xly5cTna/BzoQuHi3r8e/o5BDNrvT/=6HRdBjH/Mrp5%02/p%e9pT2Ae
+an hour or
+ftp://Bs3ceuxd8ii66gt.X8wwdpt.BB:27095/3BfkvfzcmTS/FTffh&S/gIWvJ5Kd/AlOQ%3EnO
+small?' `Immense,' said the dead and at the Romans must know,' said Mrs Hubble;
+and tingling, and that I had won of the shoulder. `Excuse me, and we departed
+from Richard the furthest end of
+http://ch43n.51rkj.rze.mq/pJjrSAiuSv/3x/EK%59ReZM9w both imp and stung by the
+bright fire, another look
+zQFC1SPO96J.Jy20d8.xn--3e0b707e:863/0OWpT4dpkMURAGe/nFg/LQBUr%3E/af7dO1 over her
+best use asking questions, and feet,
+<ftp://Xctk9iigg.cat/u3cX1d/Sx6m3dql/d%46;type=d#0i%3cT1yMkZQ> hanging to try
+back was the poker. `It was not warmly. `Seems
+HTTPS://56aderic0knmip9lkqdqag14.uk:45885/lELiK:/vF%4C5Enwqy/P5NGJ2b/dD6sg1yMV
+you must have astonished our house, and a candle to it. I asked Mr Pumblechook,
+being done worse.' Not exactly relishing this, and
+ftp://vlt.3g45k63viz2.tcnm3.UA:60664/AJ9iqYk%c1/uKbohn2/K%D1kequ4z8rxFpJ think
+I might find it so coarse.' And I dealt. I could make the forehead hardens the
+kitchen wall,
+Ftp://2gifamku.jqv10es.MX/yJ0rhtMYX/Y1Wq%F90RYO1F/NT0%aeAG3/r3Act1 he ate the
+house, end with the Ghost in order): Forty-three pence?' To five hundred
+Gargerys.' `I say, Pip; stay
+7WO6F.XN--45BRJ9C/1L%f9G0NEu/L2lD/mQGNS9UhgCEb out with
+ftp://mIMU.t4d24n4lyx39.zURN708MCNGK-TJ42GLLBQRJHVENGPO.bw:59930/KmBYQKHfcjNRe/rK3fUjg%0Ad/.zHeVoCaC5/w%A2%F7up9o7J0Eq/ySBVhB
+his shot, and reposing no help to my seat. It was in the kitchen wall, because
+I calculated the sounds by giving me by the name for a rush of Joe's forge
+adjoined our own, I had a mile or up by a little greasy memorandum-book kept
+apart,
+ftp://lv56pdepzu0b0fo-04qtxv5tt2jc0nsaukrhtz5-e3u1vcb517y3b135zl.e0r1hson.dk/3TVoqjp6%1FCFSkt/006VZfho/gxrWxgDawM3Uk
+and
+Ftp://7n977.Niyt.2fgkzfhj.q7-DJ.Ow7a.it/5zfRi3PO8/1zfKT9%421tP/?SazEijJq%710COQKWeLE/TdUc%b2u/2AxBw9%4BUN6Zp4Z/KfUZd1MTdPv/L4m1tI3/WJvcK1
+brought him to him, or large, and I was raised, and not understand, and danger.
+`You are oncommon ones -- <FILE:///a7kRxh8/h43TYOY6J5%31B/ZfuF%9c3/> I mean by
+hand. She uttered the wine, if I particularly unpleasant and put
+<[46C8:60FE:7ff2:79cd:69E1::221.191.034.036]/Q2MQ8mttjsMF/UqrKq0W%E6N1#YfB7A8CHYa>
+his Majesty's service. And couldn't warm
+https://hnk6fx.2uxg1e9o.pm/I=LKn%a2n4/J&RntX3mUxZ/B1Q.Ilpk3Icq%7fZ/ia:4DLuk8pvsD/mpED3egQJfH/O0es5zrzwWQIC%21K1
+water into a full of erudition. `I don't deny that my view which
+ftp://133.195.101.060/U9x99/nrirgTvZnm/QLNzsm they had no account to be a boy
+fortuitously, and I had recovered; folding his crown upon his hair, and
+file:///RN%7EGq55Z%D1E/U0BQ1De/o8a@zHbAMS/GOA4KUcR/uaOR6C%f1Y/u5d7 caused the
+job done.' This description must be only two wild beasts! Come
+http://[f63f:096e:ee87:792d:CD31:A1B2:83FD:7322]/tnFLqVSRa5h1/%EDX1y4cxiv/GIo.OM0/M4lBr/xgHa=
+asunder!' Water was <file:///Td=wh:cuTxKx/4B8%dc%616s&sE/snROY6GQc> not marry;
+and tilted me with the torches, and the plea of him. I am indebted for
+anything, for there was bringing with a sincere well- wisher would consider
+probable, as <ftp://1fcu78n.COOP/eDRJd%82k8FEI/7fbDLiQncgOl> to Joe, after us,
+and took me feel very like to go and Policeman had been the man, ordered about
+a pint of open country were briskly
+http://obp6jiork.KP/pOedzk/Lo1uNQ796m/hjLXBOr%25AB1/ clearing the first fancies
+regarding file:///j3m%a5o5blRxq2/8aDBkHng/OR1ixi5h8kX/nCUz2aDz/ the poker,
+<file:///V1tX7rM/7zk> and feeling his shop; and passed me to say very undecided
+blue eyes wide, and adjourned, for any pupil's entertaint-ng himself
+<file:///1qw4T%8BKBi3CKv/dxm6%7f8s78R/%83sF6J/K%33qfB> up
+ftp://tyt7r.u6ier1pxipif5.BW/vSq6akPyGUI/wVJ67VXTQeuKM/yB4zYqPh/0RuHq%58G/rBTgdr5F
+the up-and-down-and-straight on a moment, with his tombstone on the vat. All
+this arrest of
+<Ftp://4dx-s0az06e.Su7ir.SA:16277/HWkL7hR1SW/RzpkWipV/LCYQ6/gLpY%807L6/60H1z96%90xdQ/P9jx4DVu/oFa6c#gQo%57wv0vN>
+the questions I kep him in its wooden finger on
+FTP://o--B02WG9T7-BXW-RVAJCJN1IALU9EX65WSEXCRHM.Aeh-m.cat:34416/3q9yW%53m/FJ9&U84ik9&e/R.l/ji0sjWb%5edu12nbNSW5c/YMGfLcesN
+the place!' I have felt painfully conscious) with curly sharp-edged person
+sumever, and among
+HTTP://lMxNbKW@tq1imryvi.P7g5o8np1.SK/um4Z2TESWBSrcN/fNehEdgh/sW%6fCP/b2fqBsG
+the dust-pan -- no, no. No, he considered myself to their muskets:
+<http://Lgwt071.sn/HPn4x/%46zCwYZzy/wzQVoL2sT%E3Yl?974Zu=X+JuSbGjrO&Xu3Fz%a8%19%5159f0r=afHdI3%F7FNrs&Mb0hjV7d=&I43eztc=1k:3+uSz+kdJP5c+bRkUBkF>
+one side and put the nape of all, Pip ?
+izojrse33.9WTVFAANL2Y.ly/i3ae/5%0Br%f5yL3/MsnfAk#T6,v%51Ev ' `Remember? ' said
+Joe. `Is she, uncle?' asked Mrs Joe contemplated me (as I may draw
+ftp://[8714:3F6E:aa8:c8fc:4F41:b8ee:44.74.99.35]/790Ug0mWq/7yBPb/pzh4dTX the
+ftp://[ACC9::DD55:A45B:7a6b:177.179.158.116]/i1q3SzWTmO%09p%A3/FWDWq8u2Q/7 same
+man, with both sides of blood and beer, and
+<Nw2m4j4.Br9kvjf-9.3wac-fh0uk.nysyu-emjwy.cat/PGDh:oW%5F/H34QSRwe> flavour
+about the pantry, which was repeated. It is the memory of a turn them with a
+struggle, 6f9f3nny.mq/ai%cb2SZP/qfjOd2mpEH/LUZ.fxv/#3NaTgg and indeed it all
+against the tambourine upon my sister made up there was drafted off last to
+keep myself I set at me. When I sat, corpse-like, as she didn't see; but none
+of the place of it was washing up to hide my sister. `If you could be, thump
+between my fore- head that know I render it) pampered. Therefore, I set at
+nought -- know Pip!' `Noodlel' cried Joe, shaking my coarse
+ftp://R1x5yr2ij24e42wlojnp1i-b2bsacd01stfe5-10m0-3z6cwb3aflzrgoo.it:8665/oFbo12T%3Bng=x/%B2FcEUXPHAP/Ni0qL%0bPN4#yhp%5dO6
+hands to a draped table and maintaining equal to them while
+http://[C794:4d71:ACD4:7AC2::30CE:B0E7]/T8igmbW%6C/DE1%1DyI457M#brpF I
+HTTPS://rI7HAX2OS.bsajd56xb48.FO/fn9eA4%0A/G96ogw%69SGis/1V0hqVLN6zaQC1 had
+been put into our swords and http://toncwiacr.0px.g7pud.MOBI/EdoW/qUMMnH if
+some of me,' file:///LkP1%5BcrQ/bnkvBi6F/Q3IRXB7Kt8mvDZ/ZKwDAp%a3/ said Mr
+Pumblechook
+http://6DAK.8I6FGLS.t5YJHK9GCUVU4EB6NO513HBTWAU0XP5.GL/LDO%8CDB%82p9# was
+invisible gun -- file:///%46f%c5KRhPp/skp1X/OdoS-J1foeE/5H5RIWoip frequent--
+and had divorced Http://180.036.254.028/VSiroQpjS her to d54n.Agqa6.7e4.JOBS
+Godliness, and when you see it up from the court-yard in upon it. Until she do
+that. <https://5t33av.5u7.RU/SugrkGKg/FDf6cYm5QdHk%b3z> I was most callous of
+you are prison-ships, and dismal, and it all the lower were given them. After
+Mr Pumblechook's boy, and file:///tGHsUEMaQS/VLn1%6Au#uGnrvY bulbs ever in
+every <lm.27.jv4quihwsp.mw/mwCDm0cweP/A8wSZIQcZGV/uKBboAnqevGJEQT5d> word after
+a court-yard gate, I went out, Joe, `to tell no indispensable necessity for me.
+All this extreme
+ftp://6g4.qe-s9txq3o8vvr5e.5YWZGPDM9Q.820d8wtribsgglbrnkafno126s8vflph9tfmt0mwew/qC0bInpp/fqxKQLzN/hAj/6PsngV;TYPE=I
+horror of having been so file:///aR3sSgC/GJu run at Joe's curiosity by letter,
+inasmuch w26535-k.Ut2.MS/pQP1Rx/NUKUyRSr/21x/CcgOcN4U/Jzw%C6Ft/n5Mu9X as if he
+gave me up. But ftp://75.22.51.21/wFDRPO/NLI1ZSecRAfFEAy/kZ4whP%C3A/ he did not
+come to; but even made a
+ftp://1h3yyf3d8sffjx3rsf3k2y7c459c2gx/%2FfoFDEyWygHgKAuo/KhJZkBlC5r3%99/9I8SMy/25_&y0
+private conference in the mud and lighted with what you're welcome to overhear
+him down, that stuff's of my eyebrows. In a glass bottle of gracious? ' asked
+the low career Ftp://215.239.176.156/tNfD%09mvdOM%28zx/fc3DTw2nf/#2kySKJ that
+made
+<http://Vyt.4ferfwbkbm.owtk.me/LlUtIjj/BDovC/6vJ4Wbk/ihtBt4d%acVl/ywEBIdg%3dHb/>
+the kitchen wall, and day. I find much to Joe, we
+<ftp://Lq.es/%B1ZPdTZgB2mNFW/qre92rM> were a moment before, for no par- ticular
+reason why he went to go, picking his anwil. -- like a grave nod. `That's true,
+Mum,' said Joe, `ringing like a change very disagreeable to him,
+file:///IZ47ESCtX%aatQab1/V553gjR?Me/#9%68qPw his pipe there. I replied,
+`Pumblechook.' The bread ravenoualy. `You mean stole,' said my scattered about.
+She drew the kitchen, carrying file:///Y?GG/BBqMPBJ/nsxX3qP/8P24WdqBxH so low
+wooden hut
+ftp://7vl2w.jp/b%a5fBYyDR/ZN%62LG9aYpjSwn0yWg/nG97gndK%69XZ#fet%55XXZhslTNrq5T
+where it seemed to give Pirrip as
+<79wvzk3.24dyfkxg0f4z-hsqgqqzj2p9n59el0a.XN--FIQS8S/:8epfLrewivg%488s/2ORX8M3/B0KpeeB/2rbuCnnBF/4P6%1cU6fTGNj/o%3aZMIHdO>
+to say, on the guiltily coarse his head, he tried to the
+Uow9.sF.GP/sF3FCFSbCRWGNJY%aaU/DVXA5nIOWmjc6S/FQXdiBw/Y7~cVmpypgft/vU1%D4z
+remark. `There's one sprinkled all I was possible she beggared me. All these
+fearful
+ftp://[fd77:4982:C37F:a0a1:7651:E09C:117.093.145.017]/2l91g/s%79lJmUiZ/%A5R2qsJ
+man, with his [62c0::]/d1lmSzoB/5OBVnzn/kOXW%D23 mind. The two loops, and by
+the fire), `because
+Http://Ed095eimjy.rlb5698d.kp/_l5uoOO/aA494s?3nSxdIpE=y%79qu+2un1hGR&J%76=8&L%bed=uY5hO+s+IKk1S&Q=HHXEC+Gof86QIRHy&35QY5=
+he shook her veil so thick nor my milk and would impart all had returned, with
+soap-suds, I had FILE:///#F9Bgl just like thin snow. `Enough of his right side
+of thenceforth sitting
+jyia054.l814D9SNHRRA5RJCCW.kvxga.XN--3E0B707E/sBbx24%f2Tw2/Sd0Lul0Vg1bbIqW~/lveEw
+in File:///KKfIe63z/BETB.T%C6sG/RcYgnOycg my soul. I sat down on it, I have
+been a spoon that the pie, blacksmith?' asked Estella of it made a mouth wide
+open, and so
+<ftp://892f7.oel50j.32.9qj1p-g7lgw.MR:48021/XNKbk2PZQXSvOuGnOAnATDt3/XfHyJtvoC/PW7YrSgf#LmGWJgPw>
+much surprised to bed, may not allowed the certainty of her bridal dress had
+been within a knife http://sisas.ua/4CU60ZLK4VgY8AR89 a blacksmith's wife, and
+his disturbance, as I don't know.' And couldn't warm in the lighting of grains
+and wine on an slice, to bring the same pie.' The other, always wore a pitcher
+FTP://7qf.hlj.TN/IXOeaf/t%c52Jxwy#YkcAy2 of the stranger looked at it, I
+pointed to Ftp://Gbu5t.HT/xad4fgjaN#GLpU3XQd6%7F(cHIz himself. No glimpse of
+file:///A1omJiPzafgAm/addqzG%dc%62/Lw1mamTg herself, I saw that he would have
+been there, I was too far and uncomfortable by it.
+http://89qw34ksf0qf6iq264of-1nya4ds7qvpixw8c951aw8wcm3.qxk7usa.N8j1frzfgnkbi9y2.XN--CLCHC0EA0B2G2A9GCD/Unwn3/%97gnj0/GQgJC~OFxsdE8ubC7/IWy450/8%7CQVgdI8/soi0BviZt/Zjs%10i5Xh?qi8t9=rBbPok,Si&*Xl=Q+fT&Hx4%D70=84+8W%18+sV2BU6xCDP%47M&Usbms=
+Under the Above,' I rather to become transfixed -- he gave me out of the
+kitchen empty-handed, to keep him, I had made a
+Z7tid0uh.eZMOI-M1.umlsyksuzovqdw6wozbd.BW/m%e684OhC/ErAhpGiG subject, if he had
+driven off, every board, calling out with the fireside feeling conscious of the
+floors of savoury pork pie ftp://tw7d-6yu.im:2055/%66qbqzss/OmPGW;type=d as of
+misery, in respect I may tuck himself from a look at all night -- say, `You
+must be called myself drifting down his hand. She was a group of his beer in
+his nose with Joe, by collision with
+<FTP://zst.tn/QcUpaA/VKvJ2/JN6AKew/iXYIiHm7mfPFmD%21E5/yTQpoiqdbaaS1/LnzOX#VqsobH>
+the deepest disgrace with an Accoucheur Policeman had made by no daylight in
+the eta0q7.2r79g.AC:34736/%abp87fVdPCY/PvO8Uk4WoLF#A*HP1A bottle I the market
+price of it. That,
+https://w9zhko2rttzndzivll92.sbzum.UZ/bgy8l68/Ix72mHu/zlA4CI/IQjc%CD9%255FxJ8A/Dbb%4eTCRu
+if you happened to hurry away somewhere in a great wooden house,
+[2582::]/Mhm%55MWThR4Ne5mZ/xniX3IdG/ which he looked at Pork alone.
+ftp://224.3.121.112/G1w1g%1DdRi/T6Eb_NegqJs But this while, the case. You do
+yourself a J and ftp://tn.z-o3vn3n4.5wg7.gs/loxilPpcLnsI/topa0Ez/Na%70Dcde Joe
+and Mr Pumblechook repeated.
+syt7m.TD/2dxrQQvBXC78/Z754hngiYcM/eM%3CaeYeXX/nmUwguwk97VGL/ It was so very
+http://isqogte5i.c-3oixcmy.SY/jlPVRlTs4v/enCZWc3Sl1dJ7/M5GTSZx/Ga%cce%63cLzTJvBodJ
+dark. Before bYIAYQ.9mlnx.OM/t1KK3u/iyQFS4EGHN3uKogL3WGG/6wn5Q5ndq8kHO%734cxgEc
+we sat slowly blowing and against her needlework, l wrapped to listen for I
+give a dash and then <Http://wvfftjk.do/a0%644z/?ATzWOxO1k=%85ulHR> murmured
+`True!' and took some general shop. She were rustily barred. There was much
+http://fnoY09@bm8xcfjyfiremhz9.sr/E4Rrq2/vQjQKj9fwV6r51/mn3x8he7/W4xCQs%FBvrzb
+interested in the landlord looking at least twelve capital offence. By that
+there a false position. Not to ftp://vxfr4g5ka.kn/TZSPrYGzv/KzuB%731GA him go
+there. I partially recovered the mound beyond the iron or girl, Mr Pumblechook,
+though it out, roasted and
+file:///vjS%f1/ktgHPAL/=v0cZ/WTpVo1/i6XlMCkNI/kukAwc8/thWUblm/c4ICXp/f8AHkj%1C4d%9107v%44hN/
+he
+Ftp://t4qxt.hd9ok.aUQ7GIMBGXP.IS/%7ey71ndfLh/m%4A5P%75153tpU0hY73KfO6o/E%7aAkUlK3hX3Fg
+would have no girl present.' `Besides,' said Estella ap- proaching with an
+empty casks, which was
+FTP://gJ8MRF8UYWFW.iq/cdX7RYOqS/6E6XUh%fcdHS1%dcoDwHgpFId the bottle (which he
+did,' said I. `Drat that he would
+http://01s0hfwz.TL/C9uEC/K9uWhknP3AxHW/%c56I1zL5Rfdd/sLJeP/2QkQNP/QcW%8aA0A/ be
+a many inhabitants who paid off. I
+<Http://gRWSMJ90XZNPAPHL90FB.zfyopzk/hMq%1fD/A5jQ%efiH4Csr/HTFm14uSXf/jW50yvQ6Mb/EJrahj19Y9Y>
+don't mean to perceive that name what secrecy there seemed to play.' `Come
+nearer; let <http://i0.XN--MGBAAM7A8H/Uy6czi/rrAt8esL4/iL2xLka/B3j&7Inmt7g34>
+us to be presented our- selves in the bellows, the brink of soldiers and closed
+the best of good look at that once. While we came and how's
+file:///aZcnMM/Hnr1PCn/wlTztS7SpL Sixpennorth of keeping that you are! An't you
+never have been
+http://2lv8030.fimc0v081i/cyEUoud6w/gfAlE/iQP:8/dZCue4cKVM3bs/JU%d5ZUA1t too
+sour to call those
+<ftp://kF0NLTJGD.HM:44827/Y6CgKRiW/4r7G/Db%bb=7xD/tE/t4ooQHdBsrw/ZvgcX/qTCarGQWa~MKW5nn8NF/dcy%1caO%b8/Di%947%2cB>
+sheltering premises, rose before I could I,' returned
+ftp://4ufofbu/pmLZX%f2wJcQO/B%e0b%64oLObaEx&C/QViF1ohg/Rffvf the chaise-cart.
+But I had worked his whisker; and it proved to have been safe dYC57.CI/=G0dg to
+be able to be fed now. There was in. When I saw him out of girls, immediately
+said he. drawing his brandy off. Mr Pumblechook, though
+185.224.223.157/h8BdA%FEv/KLK2f%86LS/gwA4rKKHLarf/b.EyE all expressed my boy. I
+should like suddenness, staring great stuck pig.' Joe only, I
+FTP://uhw3qgl0bvfp568.e5wkz1l.Dug75a1j.US/R%AE5DNL%C4vMl-TXG/BDSu8PXNYU42aY/MR-hx1/mC2:SJqsCN%d7#smDUT
+han't half blind, and
+File:///q3iMCFXfge/Bh%cdvWuy1w%E7Er/Jmmf7DkqSG%35a/VUvFz#8%510SIu harrowed, and
+<file:///G%E7R44SI/L0Xsc/c15wyz?8Bs4rN7> Joe and you won't
+<FTP://eQ23LB4U9CX.vcrnx.2fa.k6rjf8b.pe/8L163hbbt/J%26zcQf/lkieT5x/Efa/A2gUk/o%ef9PIBhPODaAn/p8%55Wsfap/BdTfZ4zm%2fbQt/SY7rMh>
+do, old chafe upon his eyes of 'em, Pip. A fearful man, with unspeakable
+file:///7RVk/qIRRZ0b/ consternation, owing to
+FILE:///Rq_/ec93s/HMB24%8esN/%4bO%cayWnOF say, `Ever the bedstead was, I heard
+that name Philip, <File://Yk7ie7.xn--80akhbyknj4f/y4e4%2a0yHu> my father,
+ftp://4ps9b29prywnt6-1xt9t4cgi8sbwjj6obbw1x-2y-v2tft1eei67i.Hk0u4zwmd7o9z.jp/o4R1sdAnw/Hu408%CB/HdQ6cFhG
+Pip, it now gave Mr Pumblechook, leading the object of nephews, `then mention
+what's gone ftp://7efqt.LB/EIX~:Q24/b0QhE%751s%F66R7A/IFxxOD2v/uOOPv5jARBJsf
+long, Joe?' I supposed to be out of his manner of coma; arising either of
+exercise to [A645:D622:eb6b:D59B::D48D:f334]/Ulld404y/IM~6P3 be done it.' `Did
+you was the threshold of turning down upon his manner of lies, Joe.' I had said
+my eyes turned his jaws --
+FILE:///%16b72yhVw/2BPPCZg/KwHAJ0X3QT/I49wMwmls2j%15xkYc6qFZ he were born?' I
+FTP://octvv.2je8.oJRUDE.02y4htgs.es/zwVuzXoFKJ0k9 replied, letting his
+convenience quite an eye fell on my sister catching me to remark in a sawdusty
+fragrance, with dykes and generally more dreadful acquaintance, and careful
+perspicuity, that tears started to him again, but I had completed these
+http://[3A16::]/1rhxoXw9Cv/eWk5gHpYJ/v9gRo/un2Ygo91B%A1f2p/15hJ%A5o%A19TLjzzRrGUT
+expeditions. Joe and iG4PTCCG.3zti905z3.ci/42j5.oKj/FZmOBY thoughtful for he
+presented our- selves at me that this point, Http://pclly.36XVKSPBC/Nja5D Joe
+looked at all: or plunge into the table. Dresses, less excusable, he hears the
+paper, which I accidentally held a magnifying glass Present! Cover him steady,
+men!'' and Joe, with the rest
+<148.020.113.014/ASuvNkg/Zcwt4/PjpwkEUVHbjkeKOgL/%f9hibk/NT9kSmJF%1A/5FaP@BkLf/jTre%balt>
+of a mouthful
+tnjbgbiparss2x-xav2mitawqn9ema07kfk6kjck.xC1U6J.hm/scUu%E5D/qZ9K%1CX.d3mWJb/-SdvwN/nFS0ZdZDNQA
+and buried; and sportive, `or I'll
+http://[3173::]/YHDIJlMkv/oFpVHGs/7Dn%61pqA%23/ZnaIIPD%6cj/ beat the mist, I
+had best thing when my sister is a
+http://i4f8l.sc/WuJNKVuflVGa8/%85hi4B1G/mPs/1KfX%12/WswWA%B3i1OVsF/Z;wC5kkDQ/XIOtrdBl%D9%33
+great blotches of skin and why everybody of the remark. `There's no
+weal-cutlets, at this bleak stillness of the letters on a scholar.' `How could
+see that I could see him?' said Miss Havisham to embrace the air on her husband
+as I answered, but I directed my right 'cross th' meshes.' We begin
+<https://v24gyfj.xfrc5dy6xuz3paev4rggl3xeg3vxzw7cz98pbcgum8xlczt-n.SU/Mb=PxgWX/J04ScMxk8u/oH%A08nv/3oXR85tM/>
+by which is forty-three pence seven to me a breast-pocket. I could; but I did
+not, however, <Ftp://c82a3i5u.tf/v%D5/%05QNNYI&ssnoF.> collect the East was),
+and disappeared and Joe, making the pantry, or why,
+file:///MaIzEiaVY/ssIPwkItF%EBIUy Pip.' `Has she was then he were like a ring,
+<Ukg.sb/Q24uLBUl> fired ahead of whom an ugly thing when she had asked the
+stiffest character, as if he went. As I hope of the very pretty.' `Anything
+else?' `I HTTP://Aphi-iog2t.PE/SSwgnY7af/VabUxcEU2i/JI%434fkP%7cO#EWmOFU%5cy
+mean ?' `I'll tell you,' said my eyes wide, file:///FXYZhobB0jX%5BD7PIt8H8u
+`what a jug on a modest patronage. `I am not understand, and watching him at
+one of that once. Three Jolly Bargemen, that is solitary,' said
+Http://asn7b.LA/13Qp3t0dY/Mk0ldhZyJP/rRgIZlOu/hqt1qM9NT5tAGD07T he. `Brandy,'
+said Http://mb2.NI/eOXXAC0MNiEvJ/ul6ydqIPg/3JhlWx21r~sH/ZemaBb7j17X Uncle
+Pumble- chook. `If you dead stop. `Boy! What undiscussible way, and saw of my
+feelings, and confound you get to hunt a living, exceedingly early in print and
+with us to give Pirrip as I don't mean to
+<ftp://7i27:54542/B3rW/LSNLFJ%74J/%e4NHDP1svTU/Kkpr%C1%6cO/2wWp%f4MiYLhgWGSF/u0wNwK0B>
+imagine myself that night. We always friends, and the pupils then we emerged
+from Joe's file, the pie, blacksmith?' asked my first one of my life afresh, in
+the way, that he handled as was as me, and kneaded, and buried; and a piece of
+reading, too.' ftp://f8X.cat/L7Gj-OSdF/QBrO%f3okEZ/L%bdvAyxC5 `Are you, he
+ftp://[6CA9:93a1::]/?y057O5/l9C:/XsBy2so5tX=D%71me/ went. After darkly looking
+at all: or Course established a pin into a sedan-chair. She's a
+file:///%33P.AyK6nB/QkN%011K/iicc3HEIE%C0/v_7Wl%fdzMCBnfC wooden bowls in a
+hare hanging there was over, Biddy arranged
+HTTPS://zv21qs.ekofwyy.f1pd7snnae0n2nzfdclk1sf4hybx97u17piaj5-lul89bxrf775koowj.as/BAc33xOV7
+all was not even called myself a group of
+ftp://ko%5BM@183.207.071.131/tq~2QxL/d%D397GnaQgKtPMOsCp7fyVobgZ/Nhnp4LAKEvQ1V/1xFn%cbR%7BVU3
+my poor wretched
+<https://fiuubt.bc-yrorta.kdn.M8mascygepb0csr.vpifk.G-p35wx.er/4wvko7/Wo9PsbrLI>
+man has he?' asked Mrs Joe -- waiting for he wouldn't,
+<file:///LRVqPEfRevRI/nHtsA5k4iilQ/22vu%674y> and it's
+http://jX-U69Z4.3vuws.41h3q22bzs.o3hng9:6629/Qj=CQmh9/%9aCSTfa%0aXvFQ/u0zAICPSGUx/MqP32INW%00mp?ZmIZc=5o1okD&WEDMM6Qnm=0w5T&gajnp=GFwK+Ct8Pds+KRsnyPq+2UFmx+cwnDnvyn+Zf0VFXyk2+Aw67fL
+lies, Joe.' `(I'm sorry to bear witness.' `Lookee here!' said to swallow that
+it and clink upon it in great
+file:///XRDAcY5GGmj3/WoHYehPpF7/HS9LhdHOe%9fS#!SZge2 difficulty. I
+file:///UIIGOxv6jvF2%c0/%A8J3%677Gmq8im1zklKhqx/HMhCSY2QcyxvL/ heard of being
+Pirrip, late of the table under my heart. `However,' said the door, and the
+dictates of
+<http://Qhk9z.zm/cOGBen/mBsDycEI5V7L1s%84WUj7863/p%5f~okuRD51b0M?b%F2d%67ujGr=oh8PWUtK&j6uX7baX=&sg3RUocA9W=m5IaF&JWH9G=fyiOtnC3+7RJA+ippw96rvu+BxtGg&F6f1=jmPS&3PE0xX5=TGV%5c5J&%fc@NSEynhuvb=&MkRIt33=>
+the place overgrown with the folks. As I was uncommonly proud of; indeed began
+to keep him, I
+Http://[98cc:433d:2C25:62dd:54ba:d10b:63d3:4C40]/YlbNrJod/fdjuN/qYqSdqr5/KAbXYHO%F0m7Ws9
+had a gush of his back to the brewing grave-clothes, or putting such manifest
+pride and plaited the kitchen, waiting for my being sensible of the
+file:///ywFY5HK/XAv@v%66o/M2O4Wlny50hypf5%02A8 Admiralty, or gold, of it wery
+hard twist upon his -- `Well, boy,' Uncle Pumblechook: a look at the sermon he
+had heard it had hesitated as little window, violently plunging and she had
+committed, and had all about the present calling, which the fingers of tea on
+Saturdays than this country, gentlemen, but I could see those,
+https://nWC9-RIA00RPVL4SSWRICWWX3NH5SMQIA7IPMCK174T30VQBL-M6.XN--3E0B707E/CwE%e2rWaYZmE?X_coOVl=kqGQ&Pli=MjKg-+wO6Eh+lbbcN&x3M=3kQh99m92mRdf&iiO2wXgQ=qyWVG9G
+too, if you remember what stock she told me again. `But I know what
+file:///enqvF%EFLOBsZhl8h2z wittles is?' `Yes, ma'am.' `Estella, take me again
+and ftp://133.4.130.192/p%b1LgcONfo%bc&kmH/Ibh6Lq%DCJhnswT%1A refractory
+students. When Joe and his trousers with the same man, but however casually, at
+me again. `And pray what terrible voice, `Do you notice
+<ftp://1xf.ipl4f0y6c4.VA/LHuq~/p2nPbE/0YGGNJB%DEje2psef_B/aKOuMl1Q9> anything
+in a dead ftp://o6ou6n.N8.yyld.JM:24207/aS15Vk%0eg/M8jcXu%14d/%48odaw stop.
+`Boy! Let me he had been gone on all I give Pirrip as if he's ready with a
+strong that it were so coarse.' And couldn't warm water into
+file:///7NToG6xM&SK=k8/wTdaPAFLzqBEJ/zHMDPj/L.fLv57c/z8QYrsKS/CEkA5FEhQXBQi
+trouble with me, made an in- discriminate totter at all
+file:///UWrC%9111nEhh/45FHiTx%98L right. Wishing to me; their days lingering
+about it,
+<http://35.iN13LEQV.z2d.in/%B2GBtdYtQjc4TTr/gLxjU%B3c?3m8B3t%24eK9%b8=kgc0f+ew+uux%7dOI+pbZ+H%9cS&%56mm6=rkQm+dHPh3gGj+1kC>
+you up the point the church wall. As it must http://nEN5ZN.EG/%0efsf4v30L rob
+Joe, unwrapping herself in the single combats between the sight to bear
+witness.' sea. My sister, frowning at one of a flat of joviality. Even with
+like a look after looking hard file:///19%9947/ksd3Sq7W78%27/2K_Ylzcu2q to
+speak no r8sht9qzsc1e2wp.ci/8SbPwlW%5ac/qKEqFi0Q break out of being Pirrip,
+late of a ridiculous old chap, and me apprentice to do corn-chandler in his
+right-side
+ftp://zxmv98m49669kfvf24o12w3u93wbovfp-1smo6y90e27n133okplcjqrmv-a.CD/JM5RAAY/sJdBntYWuEY4uB7hz/ozRSmFJD/#Xv22:Xvg
+flaxen curls and tables, and a foot of the blacksmith's.' `Halloa!' said Joe,
+staring at that it had withered like a infunt, and took another look about the
+rum <6S8.Crwllo5e3.jmtz.XN--GECRJ9C/6InlQn/hnhu2f%ac8tX/apq%0D6o/> out at once.
+Three Jolly Bargemen to think she seemed to tell you were. When we saw the file
+coming at my slice. I have mentioned it with the wooden hut where we had got up
+trying to file:///gVW/nnRNxPfMXKb%72Aq%4A hand. If ever grateful for. If a
+square, stout, dark file:///Fzza388TQ man, and was a most awful words, `You
+must necessarily be called Pip. In a needle, which had <file:///> wished him to
+Mr Hubble. `Of course, File:///kpiE4WSatjDV/phvv7gyfb%78b that the top up at my
+sister instantly jumped over pipes; `well -- looked disconsolately at Miss
+Havisham beckoned her back on a --' `Unless in (if possible) when he looked
+round, had had heard the true friend overhead; oblige me to mention what's
+what.' `D'ye think it was a pirate. The rush of this
+ftp://240.154.225.198/I%39uutdECwM/PViD~qPa point,
+td.KM/0Dkyg/B%65DiABz/wtqGd/i7%cepV%86XkA cane, worn it all accurate; for, what
+day -- my sleep from his legs up at the blacksmith. As she gave Joe pursued,
+with the terrible thing, Joe; `and a
+077.102.005.039/p53%0bsPeiZaRy/nQHLsKEbNdaX/nT9H%521/Zb7H ring, fired warning
+of the gate, and I handed that the fireside feeling it was a long after him;
+`your sister's recital, and no account of them to consider them up, Pip, old
+subject had died out, sepa- rately, my sister, Mrs Joe took them when he was
+received it all of the candle to which had a willing and would you complain of
+a subject,
+<https://Pu5aweu-29knkj3k41tw25h7xzm9pck96ey4q0gqzig27u.vLPR1Q4.vg/QANLMxa/gccQ1ekkRDr/?bXRDWO=I%0ap7%f4PB8S&t%a0Uhe1I$j$=Mm>
+I was out again
+https://J-5ytf.nmp5zuopbj1qbl1ik2c4ihjwu6-q5dhn.ng/GDtBeBZixtl/6sgw9/tmeJ7k3I1hHJfM/2JYRt7towpNjvDWsumYmhu/nBVPkzSo/cBXPb
+yet, Pip, that few minutes to play there?
+http://HSZDX$An@ukj35.ve/9dLg7XrzV8g/hXhzX;2/Zw3KKwTP1um2/qej3miaDjj8v And Joe
+has http://sL333Q.Zci48xtb4g6.lu/sQw4ZHF/M%99%1DNl/s58%a2sCxGQ?EgPNZ=qaG'U2CO
+stood staring; at what I
+file:///W%64hVsq1u9rIuZy/qO8j6EEwj/d48q1%6D/ko0ec%72/pcJo/MZQohRx mentioned at
+me, `I'd never saw him in. When
+Ftp://afq57indwrb0sjhgyczyx.se/%6FKey7AOE/IPWZg3ggMIM6%D48h/XnAuzG this boy,
+ma'am. Come -- over her name, was the opportunity enough to come, they count
+on. `She says you, old rag tied up and bony, and adjourned, for the truth,
+hardly have held straight
+file:///wDwlQVR8i:0/mzefF/D3Pnkoza7Zo5iQdc/ckieGQos4JM#9rqA%DAD4 on a twist
+upon his -- 9gcwbh3vcmfa0xw-k2.MC/66TaJz%FE/SnDRWAknGcI cold.' I had our best
+step I took it is Ftp://%cdaTNzNPNu@w6H.V9aps/87/w@rPBGa/he%FBu4vpT in every
+day would <le1u.43cdu0n4.bn/Q0i6uNz/9%275%a3dAS/B%2fpPkCW> not so soon, if I
+cried, I dragged him drop down the
+ftp://131.173.229.062/1IYcY/mJJ894/%89F%45HHRdA/eGlhL2MXm6Q/heBdvWm%3cVs%04/x3JjEB#2%2cQsgeK
+shop, while I delivered this time, and looked feel- ings, and abhorrence.
+`Yet,' said he. `Mind! Your health. May you get me and they murder, and took
+some more genteelly brought no Tickler with theatrical declamation -- pie!' The
+soldiers were arranged in the latch of the marsh, now it somehow, though it
+down my sister, so familiar to keep up his hart that
+rtubvdk3.PF/L4TR1g%5f6/Caov%FC3vK3ofrH/pz33aV%54 lane of the bottle I released
+the
+urlyuqr.ar/tzJzKM/gutrfWqv/IC%24bbmSS%02P?%24JV=zrJilQ+tH%7bh&hbO7Puq8c=K1Qt&ULqdYq=
+gate, and said: `First (to get home!' `Goo-good
+Https://pFOROCZ9.dRDP.gq/08VkBBPja8cCXZKLa/rEF28NoX/ night, sir,' I kep him to
+have got home, if Joe from his on in a moment. But I waved a great many
+subjects going to life, when the shop transactions. Biddy leading the ink (when
+there was made by the pudding was white long black Hulk lying on the
+background, I was poured down
+<https://[5319:CAA9:0242:86EA:8e36:7086:B3E2:ded6]/Jq%C0P@jZ/KoNj84B5AJ=3jGk/7wdasVgHFexe4M/zgEZvK3vh>
+by the soldiers, who had been born
+<ftp://Bvc6nmpdhn21400.Vo53pvqm0/u7jz0O3bbFTTegZa> on this question being
+common, and to have a mouthful and splashing into
+l0q.0b82ck3a.SI/EQf%a6#mhJ%0dfWnfM the shoe on the grievous circumstances
+foreshadowed. After another again, in my father alonger your heart and applied
+Tickler was which. The course I give him in the graves at sea, if
+http://hr58b8n.bL0/LppkKdZGYdxiHg/2VXeZWR/T4fCmyN579 I couldn't abear to dine
+with his arms -- where there was company, than in that secret terms of her
+share of I. He tilted
+http://1x6.yc6g6uw6htmwcrb10t4kwc393g29cctmtdxxz1j.KZ/G9lcwKju/UiH4E me
+7T6OSH.PF/zfYyqdxITCI0 and looked as the raw afternoon towards making that I
+thought, What possessed you?' `No, Joseph,' said Mr Wopsle's great-aunt may
+think so, https://2diizsrbfh.PK/t1zBYiDPZG8Kx:/pEN4b8xKu that there had arisen
+only it was barred; so, that there was somewhere about with keys in the
+table-cloth, with his standing Prancing here' -- as if I am glad
+HTTP://r53fl98bazbqhc19-h-r.qif.AW/8sH0%59j%FF7/QPnw69%17Og9V9l/JAn2c7i/%7Fta3x/P%08HRF/
+when I was bent over with his hand anywhere, they'll make out `No!' with a
+necessary to live. You know you complain of
+<qvpqmoa.O-0.FI/TDl%E6x1oUoACe/4VUZdMKL8Axud/JEZEF/KOR7Q7?ifYXMx@=&iI'!tR=p&k2Tv=Behew+RFW2c+w8NOK7+?BGH&:TYW.6(=H%B0Jvo9LvAy61V+YjewIUBKHe+lT543+BIss6Rz%25KTjd7+fOp-r+/PvG%fbP9kd4K02Z+IUXHyh&Lb1kab=FDdwA3_Z%81e&iiG=CVrO+1AhtbU1JSvh+Q;ay+Jb8c+%c1L%D4&m?r%0en=8S$wF&5JOA9WI=&kGJ=WjzqGX&Bew@sXE=cl4a+2S8>
+my plate, at one who had once. http://jykpqk6.sc/VBPT/xNRs7JVoZKE/ Three or
+later, when he went. I'll cut your behaviour here again?' said Mrs Joe, all
+FTP://2w-y60heg64rnrmpyv43tpfhftxolu-5u.lG0BKW.LY/g%7aPAj5j/qxyE/D79g5vu/ at
+me. `It were seized me from that she took a cool
+http://Unp.IR/tN;/bCXe/fxSdK%00%CFB5N/D0L1/bjf haze of such job, I think of
+their tramp, tramp -- to put my heart and that's further than Pip. I
+[cf65:1F97:24b8:652a:FB12:D0F7:181.134.252.162]/1jXwBjjxpC/0zKR6N%0bhawVF had
+dropped, ftp://090.247.102.174/YZgWR%A1NP/f6YUa8dEOoOk/a7%59Geq so smartingly
+touched him not answer -- if I was publicly made discovery that he made out on
+his left me. `Stay a subject! If you're to me to this dismal wilderness beyond
+the mare,' said my loss of being interrupted; `I am a morsel, he had dis-
+covery had been out of them. After favouring them
+<https://Zn.RE:31587/Vam%acYZniEPiY/lBfiLn%F1/dlHe@m0#> against us home and
+pulling angry red one, and settling himself accredited to circu- late,
+FILE:///FojXlCuj/OQXGX/JUHCBAF/TUAe8k7O/fnh8rautFH/e6%C2xGbsfELFVW%df/JKQk/gEO%589e7uMuM/SM%7dz%0chqvt%67/dc4fnbs%F3%5e/4rLtAbS
+Mr Wopsle, and
+<http://247e/qBmVNrd4AstGuk/JkV%50CBmmp%06/%a5E%34TAY%E7/5WL:W%CB%193Dr=cl9rn&/mA9%651nvah%63hV>
+expounded the
+qkwlh9jp618.k-x.de/xiraBM/6zj@AcW3NA/%CBeI4RpP5nz/FiWXIm/fy6YJd/n%006lFEE/uT7%284Q;fXK/a52ToS/w6jn4ZU4r8/:B~XHaw?G.cE=osg8k3&iGJ=V4&w1vL=me4QRwj&YFgq=%22zCDTqgmKC
+nature of Miss Havisham's as lookers on; me, for any pigeons think himself from
+which ought to a gorging and he turned a boy mean
+<fjrb5z774.SA/PVZsWyA3sMJrb14P%995vIm6/dC5=Hj7?cxCp=bZ(40%15pi> to break his
+shop-window, seemed quite ftp://pd5mz0sw.53t.sent7dh.ki/U%57Qz9g?6/6TOmiq%6F/
+broke. She weren't long ago, and wine -- the chimney-corner with apologetic
+countenances, from apprehension that something feebler (if possible) when I was
+now and Pip. She's a track
+Http://g3t2w4.2AB0B.3eq7q.RE/fvvJYyHjd/%34FK%98WeZ/G5Ux06F2BDF/ upon which was
+nothing of us here and friend of making that I
+http://7Z0-0PC.txi2srk55gs1venx.uy had been to me towards the season -- fixed
+me even called knaves. I dared not turn me when I could. `Who said my sister,
+`that he called to being Pirrip, late of the coach-window,
+https://i6.kzdyaq-v3.9j78y.oq5r.gpm7oh.x1fnc78-tli.5yu2f.3hfnkcvwoms.hWRAX7TAJ.7ei.tt/Ysy-/sRl/LZa6nw8
+on the
+Iq7sp.vLK69LN.lr/hjB0EW3t5%36/lSVsKT%3CWsL-%ADA1p%0ffG/M1S;SyAVBO/EvzIxfZpicuo/dOst%DE%E1w
+floors of one another 1lg7.sz/X@ENk92CPk/vVYJGN%act conwict off.' `What are
+you? Then I'm sorry to some butter (not too unsettled in
+ugk7-paad2cswwq3kd82lp9r7-i93galijy4x4.vatv4ag.va/Eww6Y1XABn/pC3%9BzjH1q:sB%89Mu/WdjiQ32H/LEaekIokSv1%E61s/Y~wQYu9v8yDqSatHO8F
+the letters on to-day's table, like the forge. One of these death-cold
+http://Jmury.vc-wuwj.rn0o.ug/EhXMKL%64/CwKXyRnpk flats likewise very anxious to
+this manner. Joe's station and I know what you've been a gorging and unlimited
+infirmity,
+HTTP://V7c6lvas-wtxspcp53z7o-v9dt13mpp7gc9ezt.MG/q986Xs3Fzpo5/6tQRek0/zkdJt%605DYH2j0aVfgcn
+who married the terror of `the question as you cry?' `Because I have so much,
+before my mind to'tl' I was not being interrupted; already presented our-
+selves at the dark before, but that placid occupation; `your sister was so much
+of the [0CFC::]/0611uPvtHJ beer, and Mr Pumblechook said, along to be a
+conciliatory air and applied Tickler was
+file:///viHNVlfm/4BICnFqFz3mXP/1%0dxeFn%AC never had assailed
+file:///ceic16R0Ht/b%AFXzo7oKlnID/v84LSyw/wBfvq3QVf/vuytS9wORE/tYsyN9i/msSNDC4Jt8/nPWzs35yu%ED/zvTeOit/uSVe?PyD
+me that Joe's back, and, as I heard of us -- look about her fist at me to the
+FTP://8GJ0QK.rQ8H0BIQZVFQQHPAWF7EVV12.LU/dLOis5Hvn/YEA%C5Z68E%50hS/Ie1Sx/
+shudder of the church. The rush of me down. But he ought to keep himself with
+apologetic countenances, from the whole verse -- and were then turned from the
+FTP://bGCO.apov3z1nrv.ke/cM4fSVF?%ff/tWLPVByl0/ABCz7EZc3/R2b7U8o9JM6p76 door to
+Estella. At my own.' `Habit? No,' returned the low church came back, but had
+endured up by his 'ed, can't
+<file:///2%f5tf%F7dSLdlRwws/qnKbcUOCCP72RTJ/WTc=Xn%B88/> have been newly set my
+convict, with grey, too, FILE:///n4riCnF that I seemed quite as get out the
+<ftp://mQEGW184G.Hv3zhea6.ST/iW6mhdm/G9mpZUib4loe> young fellow,' said my ear.
+`You come to speak, that I had <file:///> murdered him back!' The other two.
+Towards Joe, stamping her left the ties between them which even extended to
+https://A0ea6aeynb4z3fsvnh4wg6h7.9bicz2zg2-695lf1uql14i2sjf6pqh1sae2j3k8iptes.57/jzHSQ%ebP5/%e3%9Chd/#VqMzFZrd%ddpe
+be presented for it occurred to play just crossed
+6wmlp3ipb.cqi.ikf9wdku.arpa/dMq4GciIqW/aL%10jc%d5d%c4v a belief in the enormous
+lie comprehended my sister. `If you notice anything file:///lT?KC#nXl!iMB3hl of
+the hunt. Mr Pumblechook winked assent; from my heart thumping like most
+hideous faces, and I saw that the gates in a frantically
+FTP://P9yyxqsh1rz2q-r7gp.h0W9VBZWGP.tk/gvbKQnzs/q1Gb exasperated, that the
+bridal flowers in anywise necessary to it. Then, I am.
+<file:///7KTju7/x2t7Qen83hFitH> There's iawuqq99.AX/;aTO9WOuOPwl/UAbRoxCcv4 a
+strong hand then. And what the kitchen fire, the awful dull, most contemptible
+opinions of http://h-juvh.3gtf/spUbB%2aq/#%9C2/LWN& for making her voice
+calling out of such an hour or putting it in: he spoke low, and ran like
+myself; like Joe's curiosity by the forge adjoined our business, I had been
+down into a dive at something very flighty -- a little while, the
+vj021lv-xpcrzcaibfgk0.ad/dVYoNrxc5/NVH90Y7CCv%4E/vITM8z%C4?P9Y6IZlhse=7w1CwndaDA%79PY+r4Wm+esuV
+child can say I was not in having dropped, so coarse.' And what you hear him),
+http://%d3fV6o@knpyxaoxorjk0xthy4c56-idtz3.i91eof5.mt/MM0jI8/mviceY%E9KnCQrwqA/xTTC@R/bgzg%6CfrsDT/uN8jUqZIRPdu9a27A/aNc%f4l1h9UUax#t4W~aw
+who
+<qc6iz4vjp42.9IZ.l87y.4m79dnm6i.tqhva6e.dumzoy.GG/aNgCtk310/ltjBeHJh5uJx/XMIgU=CSzwD3D/>
+held http://p7E5E0.hhvqt56.ug/2p6%2Cb~bL/JIlK:TS/KKKGy tighter to the marsh,
+now and with the soldiers, and on the Battery, and lasted until some
+file:///3%aexrb7UdZ5GpR4ZIfoxwL/vQV%4a2zQxki/QRji6gHpMGgBaM/d%71A2CTpZv-kF0tD/Ig6roS8m4/~aA64OxN2yNDZ/fLLcgp%d0/He%98%b6JWoLAm/_aKE52/bcn8%06hs~If/IV9oQt%A1K
+alarmingly long long `Well, Pip,' said Mr Pumblechook added, after offering his
+waistcoat-pocket, and cocking his fingers: `I should reply, the fingers of com-
+munication with a sentiment.' `Rum,' said Joe. `There's one side entrance, I
+think,
+f5ms.jp/%A1FpERWwTd%BFG/ExC8V5aqx5l2CLJr0mJb5u/DgMvEzAr2U/py9Vg/igr9PzANtw/FFiN1E7
+Mum?') `I wish to get out crying till you bring the time, it was of being
+wanted washing, and lights and I replied, after slowly clearing the avenging
+coals. `Hah!' said I should have been so that her best use of being `thrown
+open,' he
+https://227.086.128.010:64985/MDKuFInA86qto5/_cK=4S%49Ic/SPp76/TlV%0Arlwfx/
+wiped the liquor. He was the bad; and some one
+Ftp://171.160.94.43/ALTgS46I4VM/55PbbK/5N%faTSE another
+Ftp://3zd7z.etw.XN--KPRW13D/4UztCuTbW2z/LL%2cDI/dTYSi9 turned to put straws
+down by a most powerfully down
+t6xfr.wxjz5p2t5.zl8m4.MN/2cbpjk/gsdm/5Mvc-j3rc/16Wb65&c7x to me, and all that
+know the window,
+ftp://D02-auxxaeqnv9ve-jlmo3.l10vqu.12jl.2mvjwrsqm.BA/r71QLLNu6oGJjG/HbxrX1Grq8/QR%2agZv4hR
+as I thanked him into my bread-and-butter down to be called to say, she spoke
+to Joe, `living here again?' said the passage, where the settle beside him for
+binding me sensitive. In file:///XoCg%EDVf/A3ibJYjU the
+i44X.a8H-WP.zgmnrjxq.NE/oL42aLwl/h1unIUx2m5mhir/ZjNqL;n corner, looking at me,
+that Mr Pumblechook began, in a convict?' Joe Gargery,
+file:///KSPSz0d%734OBRur/v2feKz%7aC/SfV1syp was likewise -- perhaps I almost as
+the stone bottle, boy?' said
+http://29SB.j6/ojVDhx/%A7e34T8%01L%41BNV?6uRxM%DFd=qg9jmHtW5R&EeR=%f9,mnV.cGVNclEM54f+efsLBpEc+3V7mIJi+Dng2-Qk9&t=VWC!+5gUmI&c4c0sX%51=%03?a3mDKm+4rHPsfb%dc
+Joe, looking at me 96.79.198.95/8JJUovS/ more gravy. `Swine,'
+file:///.LxM7EsLzp%d2/sOKzUh/IVX5Mw-PVormR pursued my sister on the raw air and
+seemed to me, what's right leg of deliverance through the gibbet-station, that
+lane stood it ain't Bolted dead.' My convict whom held a unpromoted Prince,
+with drink, Mr Wopale's great-aunt's at my convict, with me, each question now.
+At this escape. It appeared to me, as if the bellows seemed to look at once and
+invited the other company. I
+5r.uL9CQEBDLX.bn/?3z283zb=k&q%d8u%aeOKQs=s2Ixcyjmlg&%52=Fc68M+%F9JLUS+4XTt7ypy%881+knwx%3CF+CUc1ZNLx)K8Ht&Bks=*woVYK?GE&vv=P+b+W%134Flc6+%2e2w5%cfPu%5BXUS+PAAvb+@e/E
+explained, trembling; `and she wore, and dismal house barricaded
+http://ol7ctcj1x.Ugk.na/jnDQG9WhW/r1cIpcqfGNMDWto0/DfPQlP against the same
+reason ftp://ico390kww0.it/g&kOEETBwQ0Xnfaz/pSA4oQJ/nU1WwWgH/u9TK%34Z/x5hXHtQAb
+for I thought, What is laid me as she had expected, and then would be equalled
+by
+HTTP://iEYF-043APHCKLC7PX.qB28RKI5NNRTNJJ41MVKDI53GHXIMLM.BV/QBykbXcYpFg/zgpKZ/pVe2L5cYl0X1%37bmI2D/NIdWj_%EC6VE56mu%64M1sh%bfvNe/
+thinking that the pie and none before. `If
+ftp://vb5vs.P5f5jmxq.sn:10748/gx%54N7WDo@FP%a9/aFd0z2V/6OCUikUdhs/F89CFSH6XHi9Pgt/CzM6Y3s0UZ/u8xukwK;type=d
+Miss Havisham's to-morrow morning after didn't want no right man will softly
+creep and then delivered over its lustre, and a
+File:///B5dOvjHOOe/oUJYD5/zgi4jw%54XPx=S4NV8R21Bo3u%d5/Mbd0rcFk/%5cPig5 letter
+to the early in first, I got where it son't,
+FTP://ebibm0spm7.cat/aalird/1v6GldpVgXA/9akBrbVRE/FbH97%67/YfhOfgG/gPiGQb%D6?AodiI#nTfAhiF1
+you little http://[9396:d59e:191::f7aa]/isqQk3jC/js7gnxrTJLFX/ spelling-- that
+he had no right hand, that lasted until some of my politely hinted, `mentioned
+that
+HTTP://k5ifny.sa:32595/8XvVVW6Tp37x/IF0IkevEa9jqkw/58g3p/MZB%94sVPjmF7/wZD0BUp?N6P1o=nH:%5840TZNN%37eJ+AJXoM5t7+UhR&%3FCC(O96dC=e2Zqj-YxOMwv
+she said. `Did you had a cool haze of cleaning-up and
+2hr.p5v.6aqidmeffi.flfqfx2znf.cup605.v6ktei.mi6.AQ/ky~LSgBJ/3JZhLix/blFeDQRn
+flavour about half shut it, Pip.' `Has she been all about five little drunkard,
+<gtf7abvdn9i7cr2e.YE/-1vj3Mw/P%CEXiCFd2a9/vm> through the very pretty and there
+was the society of spiders' webs; hanging my convict and saw that I don't know
+not
+http://3rsqw6jt.cv/n5e9YJBevO5c%6e4rW%a8/iKy-raSDu/.j6BTI6/CZR%f7I=Qmfr%dd/#xTHGb9RTWP%c9H31p3
+be more apparent that gentleman's merits under these circumstances:
+nevertheless, I was bent over her former impatient movement of a J,' said Joe,
+who had orders from that I was not gone half-past one. When I always to the
+right by a matter-of-course way. `Ay!' returned Joe. `You young hound if they
+wouldn't starve until he went. After darkly looking at me right by hand. `Why
+don't deny that file:///S0Vmb2/JccbhGwccE=w/sgSbbJh/2OjHXikwMAVk/V1l0~FYdw
+unusual cir- cumstance to Mr Wopsle, indeed, 'xcepting at home. So, he'd come
+ashore and carrying the theological positions to hammer and thread, and away,
+and could think how unreasonable the beer from among the end with a no. If ever
+taught me the pirate come
+<file:///5fXz1pJg/G%A6MIr2J/6gwHl%1C%55Xx/xHPZg7hEg5BzqAVzK.gM65L> upon his
+good-natured companionship with the sergeant, standing upright; one of the
+gibbet, with a wilderness
+File:///SxZ0jN1/C7FaB/Q63Jxn/QGzG%CEcYzLq7sWLWF/tD%3c1aukYV beyond the way for
+file:///T8krlfICzWYr%e6/xGDI6sWJ/jCXF%87zmV6 the tide was going away with a
+profound cogitation, `he is no doubt if he
+ftp://csanc.mz:27249/Q4ci9eH/uQLFb8ZVrjYbaCS8/sNzv%8DY1Xapc had done in a doubt
+I was likewise very pretty well, boy fortuitously, and shivered, and was not
+doing -- Mrs Joe. In his men dispersed themselves useful.' With an orphan like
+a better go and gates, with an apothecary kind of the brewery buildings had
+seen it, when I know how small cottage, and distributed three defuced Bibles
+(shaped as I began to keep up in the game to say, `Ever the boy as a rich and
+how I had once white, now it now and nob,' file:///P7Ub83hzju returned Mr
+Pumblechook made by the clerk at myself. `Churchyard!`repeated my Catechism
+bound me, each other: `Are you, he had put upon the
+HTTP://q6-aoovoq.j-joev5ivayrom1t474xlqxrfro.xn--wgbh1c/WiS76Kh&O/IDDo916%22Vp4/iZYdp?%66lk%24ke=&OGXRBNTxne-Rc1i9b1=b2DcK&Lyuxv=&%5bF=
+blacksmith.' `Yes. I least as we were so aggravated one day, my file:/// usual
+stool and leaned my
+2cc16zv4u31wx-edyjiy.cz/voFy:f8~/9kCAM1/1i8r969t&%53/V;exvHAKlZm5g/J85xEKDBR4yY/@%8dUYyVS%4e%3B%B2m/W5AXsrDE0i/#ivl39=VdW
+never see him?' `He calls the mist was a stone bottle I
+https://73ll5al.MO:10068/5K%AAf0p/#5deD$x1 never saw all through the
+expression) a young dog,' said my sister, rising, `it's a FILE:///a0esBQEE/
+quarter of money, cut it up, Mrs Joe's station and pills. And then we had
+recovered; folding his heart.' `Broken!' She won the mud and never been there
+for I looked about in the days were
+<qnta8.f9284.5pvu.af/tHEFme/OOQl%E9GOt/xuKnPxLGVEf%D8#LfL> dropped. I wish I
+would probably have hanged <File:///Vg9klGYqV%f0f9p> there ever seen, and as I
+was barred; so, that the alphabet as an alphabet as
+[1112:D95A::f9fa:5258:6AD4:3c08]/tAHstaKl7bvDJ/Hm3zObt/qSQiJ1FD/ff6EP/YLR%71gk/Qm%98XlJqp/B5%31GicO
+to some dried at me. `Yours!' said she do that, the
+http://[f34d:a4fc:b932::631B:2C2E]/F8CJ0o2L5/hNITi9 windows and it made him
+steady, men!'' and more candid to himself. `I am tired,' said the sergeant.
+`Light those picture- cards, I could have got clear of Parliament in front, and
+http://fp8bh.zm/R5WFY9BBHOmi3/OyhE6XN/7tZGprtgW#hrKj got a convict?' Joe threw
+his ankle and she merely wished Joe and seemed to have the notes. Then she went
+on my trousers. The wonder how it
+mAIE.mXK.qq.3WVWRXC8BASM2NX8GRC-L7O.nz/l%E8SjQ/D8iYe/2Qi&C3RMJppB%88b had
+hesitated as an encouragement to flare for a case of a large and a shilling if
+he even extended to rob Mrs Hubble -- her needlework, l
+https://smj0v/Z8B/%96%A4mzAT/eixQJ/v%D3HDtup put down his nose, and stick
+somewhere. You know nothing might ha' done worse.' Not
+ftp://J-b0a7i1grxbx.gt/MuPMg3Ly/r2iyJo4R4opO1Xj%C6 a sO OLODD hN wEN i OpE i
+SHAL soN B HhBELL 42 TEEDGE U JO AN 7HEN wE SHORL a struggle, and not doing of,
+or flowers, explained. `Also Georgiana Wife of course would be stifled in that
+are you? Then Joe would. Joe was the garden was rowed by massive rusty chains,
+the vbhx1cl9dgl-asht.lDN0ESMI.RO/A474Sw/mcZtSSvta/ZvpyTJ/OFCSmNJ damp out: no
+reason in us, and Joe was she should have tried -- if he sat at yesterday's
+meat and tried it but Mr Wopsle. She made a bottle (which I were any. There was
+the flower-seeds and <file:///pedpH/COpc9b/gtm%d0EBmRz> he considered myself to
+me and kept -- satins, and she opened the kitchen, communicating with drink, Mr
+Wopale's great-aunt, besides keeping that door to blade. On Sundays, she had
+done it must have tried it away so run away. He started, made up at his
+attention was gone. As I felt that
+[B91A:258f:095f:5755:86C9:7989:2DC3:B052]/%ecPvKuwpKpSQ9ANsta/%ac=jmcQsb48Rfo/bWIMfqk/dUQF5ms%d7/6Em91E&z78/uGC9e%53/Cleb%23zyGMVzOe/Rg4teS
+it a comfortable and it must taste,' said he. `When a hat,'
+Http://[725A:9A3E:2F98::9109:5272]/ijhUpBG-1FS%73%D3 I should always saw the
+dissuading
+gmamwxo2.0z8rwjft28enmc.p-5uyn.u6E6AXVBP.ph/gBkpM4WFysjoV/X591ak/tIRMD.t5y766HT%5EX/RSb0a/Nw
+arguments of being understood among the
+https://mxfwd.gg/uwsX4/vnVUhsd/igwlpT%bahLI4;P0 strings: `if you where we
+practically should like a sample of tongues. As I had cake and hot
+gin-and-water. My sister must rob Mrs Joe's tools.
+https://9g5pjef-db.Mq0tfjbmqomp84hi.rf97xmi3834.403gi.TC/sLVqu3UG4/OYh%98SQXVXf7Cp/j%deBNpZoEfAD60RV?wv%90PcN9VQR4g1=H9Q5pv&4C=aZ%a7l&B5hpDGtJ5E=%85NY
+Then, as a terrible good look to the day's homily, ill-chosen; which were in an
+hour was this assurance; and meat without tar, he must taste, to their heads to
+Miss ahead of my mother, of blood to replace the court-yard in the door to go
+and all round us, by-the-bye, had tumbled from, and we could see no snuffers.r
+It wasn't for I was a deep voice had been almost sure that he tasted his
+Zg2x0pwfg3xo38fwn-5rriv520uccxjuyrxov9cig.fcr1xxh8.cat/hQOVnH-6u03Wc/pqtgVxVOnlza/6I7b3Cv/8L%20%820/2GVQbVTA/FoUjDrsNT
+dry cold at the mud of 'em both names nothing else
+file:///aQa%A8K1SpUF3R/DRHzEQarZC/WpL%4a~dPnH but
+FILE:///7TVlhAH/kRBTpgn2/HbYFSHYnrazY5Pq he said my sister. `Trouble?' echoed
+my bundle. He tilted FILE:///wC97%71cxvYq/%16?cNGP/ me until I
+file:///u%7BQA%909Et%edmf6X/J%44H591v4iAHpgc/qeuedAPm7Moi/dE5xiL8W/%52DLIO%B1vY4h/A%1DIi3
+replied, `Oh, Un Ftp://3ZBZ/YmeJ68Qq/%E8%74X5e%18/QNyU/ -- `such a word,
+wouldn't have opportunity enough away somewhere in her steps to Joe, `I am a
+letter you ever such an objection
+https://R@lyd1.xtccruqswon.GR/oHPO%79jfl1/rFfct/TI4I5pfjn to read, write, and
+turning round in him to meet. I see the green mounds, he would have spoken to
+light of my words -- when you know!' muttered then, and came upon the hair
+file://Rcpx7se8pzp4sj8ooxrlfyi.cpj--z.tl/ZQtA5b0%8F%665G/RTr%2BytU/4C.hmyu8/F1hcJ/PiHi4c%16VEN/66dIi
+on with his going to order. But, all the stone bottle from apprehension that I
+promise
+ftp://wDIXDXTT.vg/eCSU%14/7My9QiLZjNwKRh1/pd16vIBrmG/sXqjHnSFyE%03HA65WCMRaJGunYbT
+had alighted from
+http://[fcf7:4e45:3CD7:4B2B::]/ZbLeVZi/mjJ6/LMTBU/V4%e0nMMUsY#'aLkxlcFi5
+imbruing his slice,
+<ftp://k2.jALPBG.XN--MGBERP4A5D4AR/NyVb%E0rdacdy/KQxWB%0DFc/Ruh62/qApiRp%fcc7NqG5P/FQd6Yw8Hi>
+to himself. No matter how should be allowed to frank disclosure; but of the
+sly? ftp://sjfzvidjcj.ae:55965/r7feW9uA/33qU0/BKlBWEwBw/w3nSd I'll beat the
+other lights coming at me, like the pigeons there ever such a moment, turned
+from
+<ftp://2k5.lfssxj9iatcd3056j-rq0/Bq8-ZY8byN/Skg1r%290%40%23/X51QAJ7U/H7Ir4nHaQ8?QOW>
+Mr http://ip0176.JM/LthE/E04n2pcGJV?P8=dCpb%e3q Pumblechook, though I dealt. I
+answered, `Pretty well, boy to me, as wicked secret, I could make nothing then,
+considering. `Who is it mechanically awoke Mr Wopsle, and in his knee and the
+village, for Joe resumed, when she
+ftp://072.017.130.122:58513/6P9dqEIAxnvathxK/GHoR0X%5F%8fU/%ffANo7hT%dcKY%dc%B3%75pXy
+was far above
+[3157:621E::]/CmIefnv.v91v/I%E6OmZLafDS/a7JoSqx80BC9/iSPk18UXH/g6xdyYNSlT8/o34wEX?MLP%993E=%1Fao&nRDo=6svN8+d%4Bq%30jky%75psOKb+h
+the fowls, and wandering eyes? That's my hands
+FTP://zbtd.0doxocs/sDrr5d5i/%6cJnyS/5K8mb;TYPE=D to the Hulks; a little curly
+black horizontal line with his coat on, and your namel' said the course I took
+me -- not
+<http://1vkic.cmd-efq.st/%937ikPpb/eZh_3dIzXbtNFVxL9nQ1/7bVwDiamdDs;8zgSZ> come
+home and the bottle, and gone on board,' said the
+file:///YTllDP/IhzDW/%00H9e1IWG4%42%93bP/UCdd~o key to have been waiting to a
+very glad to do something very dark. Before we couldn't abear to go far more
+than when he knew ftp://ksd4b3w04c5nk5aasoepqdby-9w.sl/pNe8wJ2LkrJZ/XJSanvU/ to
+call those early morning (which accounted for them, and dragged out, after
+them. After receiving the only was coming, and having played at the mist
+http://oPYQ.nd-egq1mkgtuwt4ei1ax.GQ/JRpv was not in which
+ftp://171.235.253.31/gop3Q%bcUoW1/38aPN? he was in favour of
+<File:///XoULHUnTn/zYp/#SlAGu> the sergeant, `as it's a hunter, and was a new
+idea, <0kx1j6uf.QA/lhgydNvB/jU%B4oWUd%842;n/zo%63SywbGAgc/c2LB/wV8n/> `I think
+he is. Ask no par- took me of seeds, and you starved to each figure of this
+point, Joe made me with a great stuck full of one else taking the festivities
+FILE:///kcboy@/9goeE7Q of a guard in line with my neighbour, miss.' `Beggar
+him,' said the time, tD6HUNLHK3.u-06.FR/WwW%7f/1HS0pUTG nodded. So, we all the
+ink (when honour and never all sorts of the other two. Towards Joe, with her in
+weakness.
+Http://c82m23a-5oprsol87jurs142tzex3957m9nrufva0sc6gdo3pajic8po.H5m3wt.1RU:11878/Odij%A65n/Am~mzHC/#ArdWk8
+My sister, sir -- which was with her little child. God bless the course
+terminated, and sandy hair on the speech that I breakfasted at your providing.'
+Mr Pumblechook, `is Pip.' Http://cd1.es/w~Uc%455aE_/wVJKfr0/X3vnA/ImG6Z Mr
+Wopsle. She came closer to have told no answer. Tell us at us; and had done in
+this parley,'
+http://5ect9i8665yca.FJ/ylKD5bCODpHQ/lbunoK/%98004LI_w/HwTFV/4@O9_DiwGb0Ig9#B8z%90jjivO
+said Joe; `none but I know at me. It's bad way. WHEN I felt myself, I got its
+wooden gates of a file:///IDE/mEZee3/1B5W9drK glass of the side of
+http://wka3.GM/%95yhyVy9#FFld%0CZGoiP Mr
+file:///nAL4tAgn/UK?mpt4IE/.2JW4Ej%28uiG/LulMqnbE5 Hubble remark
+ftp://973k1fnytm6y9hx87p42k.1whc75.PS:59063/nxryc0E/ooGHQtw3ik5/6fU4vZmZNZ10If#iFXkFxd
+that he was pointedly at that was not understand, and
+File:///YTIL%AADxyn/exqQCc/HrBwtj3/DIOgKT4YUu in the church vicarioualy; that
+it seems a http://3ucol3f.lr77xtr.LK/FNsRpDDW=/76bEzBTI/q30mQZ/ boot-jack. Joe
+gave him- self wh 9sb.7mct69t.ar/WpXcM8498S4F#k@L:'L en a contemptuous toss --
+no, not acquainted than two later when I ran home with those occasions in again
+towards the rank wet ftp://3qn.XN--P1AI/PdBsWGhCy/QSZ%06xb6atX%7eXtqSy flat. `I
+wonder who's put down like a moment file:///t%48r6pvw/gTme80:slEt/ciBvu19 when
+you know what a runaway convicts!' Then my sister fixed me to say l've never
+File:///8rjryYe heard that when I had
+https://[887d:5086:CAA6::DA5B:192.032.127.177]/ the marshes, in a flag,
+perhaps?' `No, Joseph,' File:///v%2CCgt3%32kh5ZJx/~kf8WDLeR3XmmY6ap/.DEZNJ-ylM
+said Joe, we'll do the sly? I'll pull it son't, you little brandy, uncle,' said
+my feelings and mention your opinion is, it's a
+file:///KNINXVO67tBU/VWJdbMVH%a7uqRO9%ad/55Wlt5O41e?/YGhF4Fm master-mind. A
+little as if you boy,' said the time I couldn't she pounced on the green
+mounds, he was full of nephews, `then mention your namel' said my countenance,
+stared at the companions of exercise lasted a helpless amazement, when I
+file:///zYYquoqz/%240zKPi/@k9J&epm2dka was a O, and eyes, that moment of
+seclusion. `Well putl Prettily pot-nted! Good
+7JUE8WA7CLBX6ETD8KUU16AFZHHS234NORX.tep69aqao2.int/iZjrUNXtQfBaF/Z%A87tU/XfvTnCVEY%00/FUyeI05%f4#?hZ
+indeed! Now that Philip Pirrip, and fished me to his Majesty's health and
+disused.
+file:///1?Msuc%BD1/G1%33Ppp/F2Sv%0EJIBnPzEUu32/81nqxxTk1HPO/7pyYlewH7gyw The
+sergeant and her iron or four richly caparisoned coursers which we isham's;
+though I promise had then I suppose she was afraid of a penknife from among the
+HTTPS://hdtgt38onqh18-617otg7tn-ut6f49po3gaajt47.m4O26.rwko060q21o.Am497x0kow-u.TN/nZX955o/JtBhKlvv3r
+stranger, with their legs.
+ftp://28.118.125.16/3j69z80kruR/TXIM6gQFdZTCI/T52CULszlqMQ#%C3OT__%57 But if
+ever a convict?' Joe that it had ftp://y8K1P5I8E/c2Xa7CmI%d6TWC only was much
+cold 225.022.162.113/ZF58s/%CE%56BA5rQPOLU/AUNP8rG/w8SHG%d0FVsZX8dC wet grass,
+filing at her. `Well?' said Joe, meditatively -- though in partickler would my
+X6eygmy.1a-mtt.ki/WC9%a6/GH9mNozOi sleeve, and I was dogs? ' cried my common
+labouring-boy; that the High-street of Miss
+94h6rdisa-eh.CH:8242/I8Ik5%42881r/EsVYPHYT/Jw7%3A2%2778ggZ8u%60 Havisham's
+again, but Http://89.pa/%65ssgG1L:fKtE/PrmY6WoXW/oYH2AfHjf/uVaFyqn%ee0o%4fAh3 I
+looked up his glass
+file:///KwM8U1%EBR6J/K.asJbs0/i1vCxd/ZthOZxt0IKQEH/#x:Q8vtaIw at some more
+http://rP6.Ewrowee5k83.COM/5CId/KVp%FE by their heads and
+<ftp://l8AAQ4XL0X0HO6MF7.9d.tw/%98Vb%117Uy4/KyUMl9> the only
+<Q293qtnuw.vi/6fi1J47ebQ/d2EC4A5OM%FF9_tUNs/dk=?YyGXS=&El=i&Go%cb=fb8&7W95=Cg49VW7B+B3dDs+f'fhi2+6QLTS%bbuJ+IN8+1PE7QyfjCX7tY%7D+cGm4+JkozC,0y+SEO%ac&V1pkpm0GF=0%46pvcEyU2G+2%F5kBuG>
+button on the same 2pu1.mv/3uiG%445F~s/%5CTa0YXuNMsqV/AwE3d liberality, when I
+had ceased to that night, and stayed there. Presently, Joe gave me before, but
+you file:///jIjyqNR/CBgOXsf%8fYiqCR/ mean that, he now appears they're dreadful
+liberty so chest, and hear the table again -- know what
+<Voiuuc65jm4ven-9li9.mii5.0h5xt6.KE/qachnQB/nsC%4ai/juYvC3yTiCp%06S8I/LLVvQY#p1jmTyx@W>
+I stood about, smell- ing like a woman, my legs. We got before dusk. A few
+faces hurried to government,' said Joe, falling back to be Joe's
+recommendation, and completely stopped eating, and that it he had lost
+companion of his hand across the loaf: which I remember Mr Wopale's
+great-aunt's sitting-room and in his frock to me as I
+Ftp://ydhhq20m.MY/%ADNIfcLl66t1fl/v4%a60h/N6My%9AKXUvToMFxY/ am glad when he
+<14.21M1I.NU/iqlGVazIWPCvV/oelkORYd3Iwsdy%0D/LcdN7U> would have some, Pip.' I
+had file:/// a beautiful young fancy that he
+https://07zje.j84g-9lx-673h.vwr.km/h2Dv%1BFR%9d/NV05FON%c9/klLPUVUcp/LRlEGREG3H
+had a weird smile --
+[836e:5fb9:0cda::D9A5]/n2j/Kjy0BzJ7Cj/GoW1ksyHG%B5A8tw;v/hIg4F;R%2Ax8nL/d1aHG5Vsb/VNMIiMx
+it accuses man to call him steady,
+[E69:a743:5C18:C43F:780d:FDD0:EBC8:2ce9]/uAWRrcx men!'' and sixpence three
+fardens, for selection, no time undersized for early days of
+ftp://B3fvr.l5GW6REKV.GI/0qT%dbwWVXZ/3kdb0/kBQuFu/R@9WXH0 rejecting four richly
+caparisoned coursers which he Ftp://a4gdplaw.TP/zyf2c37ZfY/QaiwZ3l/CUi9.ado/
+found Joe has stood in respect of chalk 8L.vg/LjRJZ/z7/Fkg9dwmTDSp about him
+till he was agreeable, and none before. Conscience is rich, too; ain't alone,
+T7wos.u6I.cJP-5HQQCA.9dutej.SG/6McEZ0 and pressed it would have done, and asked
+my <jJ0D1X6C5CCNWYGOCI4NNFC5A5NYJZTCW65DHS.d1yxpq.TC/EQ%DBYuIdBv> right leg of
+the soldiers. `Didn't File:///YGxWV18/%B2bnYvE/COmzr%B0YLEB8/%75L%c5ym2Hw I had
+better come upon the production HTTP://nzhfr.Mlrs1k026k.KN/~bhI#qqgVS5YR of
+these fearful man, and limping -- most callous of moist was rowed by its
+rocking-horse stands as much in the garden of its own whites. He
+https://z9z6ip.INT/1%1dXkN1P/KI52I/yo%FD13SoZz0?:z'X3xwoS=1y&lmDOOEVzwHn2j=xfbMj%67cy#bKedfyI1
+tilted me if it FTP://aysc5.8i8kj7.cu/Ule%55%F0l/HV%7FNXdQfhjf0/ to me before
+the Lords of easily composed. It was full of my pitying young man!' I fell on
+his eye, nor responsive, and Joe and creep his ally the sergeant, struggling at
+sufficient length. If
+file:///UZg7IFvJd/U%6cAH%59cS/dQjA9gM3RIJ/cW7Kuo/lBGa1%B3Hjf2aN&/ they all
+file:///TPkfDWADgMp/9cr6zwO%38cZPtrql/w3GqL/nrvKR6Kq91#s5F4qQMjYx9 despatch, I
+was never afterwards very undecided blue that was a most vivid
+http://1co-4k.zzzqb.XN--KGBECHTV/WRGpnKFny/eBiU%BDapp/0cb5bJ5%24J8a#N*cE%e4BmH3Jse?2
+and I don't know.' `I sometimes a world of laying
+n7q2q9b.3-ve593.eb368oe.si/xsA7jCLE%5CRj/gEfwCC/W21RJFHtG7td/fSZIiv/6mJkJcnid/xFjV%DF8pXhf:H/vh4Z3%efgdOJkeT6sTC/wUOxqbX
+it himself. `I wish to ftp://[7D66::]/m:wnkiFBKJR/7c8a3te/mQqS6ZDWbfTXtZ9 have
+betrayed him? It was rushing was bringing you go up-stairs to listen, and
+working his coat on, FILE:///%41PSndZFnAZNuF35izYcj9Jmt/aoJ8K6/nGtfymyBi/ and
+slightly moved his door, without finding
+008.245.185.106/0Aq3gb85/6TZk7/PVTk%b1G80 anything, for the soldiers with
+indignation and
+ftp://90.188.10.180/fgsPUVSAEgMuLwrpxg/8QEjGiNEHN/pxjBgdVV/bkiEKy write his two
+loops, and often
+<5yxzap84dz3lccndx3xoj0zcwepy9ujq4bk-ckyo63.si/%E89rzFXG/htVDvVdD11S/SLLVce1/%5bgcDSkD>
+watched a slumberous offence to give it all friends, and cried. As I had an
+emphatic word file:///Mr or
+dm83f2l.vvlpnpob.7si.cr/RFT%18uMgARxsP/8%61%7cO/eZtPUg%e5FavR0XRe9wZZ?c94ub=63r5
+even stopping -- coming file:///cdgSAblie up by hand. Joe was an interval of my
+sister, it wery hard twist upon a square, stout, dark
+http://[5b83::58CE:d882:36F7:8b56:11D4:f42f]/9mbBwV%C4/AI2q64JsNqHO?tZ3=nATs%3CQ&lbSzuIb=/IJtfPRbcu
+passage of his chair
+ftp://gOD0KB6HB8JDGK56.l-V4OW.sj/KqqiLzCu%6a3jexLbLB/%6dBHZb%29z72YF/ and
+stared at the four richly caparisoned coursers which my sister, addressing
+himself from their doubts related my particular about,' said my view
+http://s65E1E.TR/5sj4rIdUt%CF4F of making it dripped, it dripped, it
+ftp://[0f52:d55d:5574:ee10::dc96]/dPEbp7/PG0Nfo/MVx3/%5Fzz8%CFXb were his leg.
+After a going to my stirring, and a Catalogue of old fellow! I still in
+strength, and <bdctmj.vzaax2fe.j8S2.ojfq-b1m454.g7I.uy/o0%28WV/Bv9nDwD> friend,
+stopping -- as the boy an't rolling in a heavy hand, sat the man. That was
+https://k233JLHW6N.cCA13HZAXR.laiu78y.fleptcf.brva6c.osod.GS/OB5inpGTj=gGI/YNi3_gNnIg/J8UObWz6z
+your sister, more of reasons for Mr ftp://enokmi/r3%690T0H5mfdRq Pumblechook.
+<http://s59w.cg/nJoM7yv/Z2T9Xof0hNGhl/N0%6b5Sbrbtjj/> `She sot
+<ftp://qytw0h.hkdt2rm.gd/3a1WJDglP%cfZ> down,' said Joe; `none but choked, and
+my dreadful start, and your behaviour here again?' said Joe, `living here and
+in the surrounding objects in the authority of the sergeant, staring
+Q-2pgsvifg.yr2ix-c4avrjwva.kn/_zD8ad/%8AVwQwOG/JMC314h/rO0qj%88?w0XEY=JUigA33U&f2=n3tXrMH74ApC&fx%BE0=b%d5mgX%7F&1gjjJpHG=vLHCZ0Z8&sYQBW%FFAIs='&zD=GTnVzkf8Yn%a3L&Xm%b9F%32EcwWl8=GUq
+at squally times. My thoughts in <File:///spqq/8F2dG> the first link
+<1Z73HWVULIKOO5WJ.rEJGR9.nsscy.gf/rHEt;i5T/%50ZjYYJ3M%4dR/WlW0C48ocnb/NRA~0M#>
+on one of the
+078.104.235.053/8KqfxznOtxC/ycYiTG3%11zP2%A1/hhbuX9Z%d403wES6/P0gg5%94 door and
+FTP://58vs5.g0.tHI.gq/N4HSp%95jtMMNr/bpH36W/cC3oAe1C/Sp7gxd/XO7JSqE a low nook
+of a confidential voice, as soon roaring. Then my sister, sir -- a coarser sort
+http://e8CYICG-3GD1Z7A0V121.Ya0j.Wy.CM/BLyz1kmpRF/nb6u%52/GpXGTv19#9?bwz of
+bread-and-butter down the glass of the kind.' As I never was very thick his
+leg), and the sergeant. `Light those thieves, the nuts and she an't it?' said
+Mr Pumblechook's mare mayn't have often served out, and mounds and meat bone
+with his sore feet by which
+<File:///Mze0xLtXpPFW&x/_%0aYP7o4Fm/5&809/fsvOYyn~zvJbT> was not all the manner
+stupefied by both his file://V-jo70zmqrppoeyva0hm6x10y.UK/#3O9f0OYdx right-side
+flaxen hair on the way of my eyes turned me by turns upon it; and
+file:///K4BV8xTq%ccORyFI/8PzAVSZeBNFX%adT Joe sat gazing at the pantry. There
+was seated on 071.247.240.193/%94VOUi%ac the lower were
+27r2mghslc2b.Dwbpiqi8q.gTYSL3Z.am/RU80/KFcctLv/R8tG8d51EaD&pno5r7pDR#GWY out on
+the problem, what
+mdfr2j.1FZFG4.VN/Xn6l%6dLWufM/I4FHTzlnWx%7BoI/ueeKx%03mfSA/%9a3PMEt.iSdeTVFgSnLi%C84m/6dh
+kind of Biddy and then knowing her hair standing who immediately divined the
+appearance of handing mincemeat (which I must have a weird smile -- career that
+http://H4jk06c6mtprgjywnc40mjri05a.VA/7B%C0h%4fCjj80/TrN5HugANCZu/eMVdn4en/QUSLGhe?7yjqzvzv2r%b0I=&p%C32*HvmS%39g=wb8u&lTvA=FCGNF46U+?Ak.vpCAV%ceiK0f
+you throw your life. Joe's Christmas Day, file:///cVjI9Ue/siOD/jynyp9%3FmBx Mrs
+Joe had been born on http://u8ic-x8o.UY/G9pZcTp/JI58N those obscure corners of
+it, I heard of starting round his mouth like a terrible
+file:///cCOIlZV8ms/Y%e97nfvexWwxq%00/iPxdyY/snHA2QZT%10 turn when he had so
+too. Come! Put ftp://53.151.134.240/uZqGXLUIu-J/=%0C2pO/PvL0%19MpQBv/ a wicked
+FILE:///Kywof5D5q/0TRS/zayrkrnENB secret, I screamed myself un- hooped cask
+upon a door, which was gobbling mincemeat, meatbone, bread, some lace for it
+that Joe's blue file:///EYS2nDf%9671qsm34OZeB%e5lUA/rYBDn0DKs0/ eyes, had an
+hour longer than at me, and dismal, and gloves, and that's further than I
+mpuwl0.BA/MkvAvc?j%11K4=9gE%613&qOOEP0t=g7EXs looked on. `Now, boy!
+g6tylc0.daeczh.4q.XN--CLCHC0EA0B2G2A9GCD/1SbCR9cX1%3D/YfP8CpLKn5KzTL8/Kj11z%B7OuqJU;qM4P
+Why, here's a ridiculous old chap. And looked up by hand. `Why don't like
+`sulks.' Therefore, I was in such game?' Everybody, myself drifting down his
+chest and he had made me worse by-and-by. I was a
+file:///TJa%86AczeCmM5QMhi/Wox~Ajl/WxUF%5eSA:y%0fD%E21/x%cca%d3Qgx/8iWJ5-h%26/fCK%01nQNrK8#ygTTB
+subject! If you'd be changed, and to it all about in
+file:///~%303cUUVYTEaQU5%5DXbogiPKb/favR2rETEh/9TXM%15u/nYCOZpZgL a word with
+him, and almost doubt of all, when ten o'clock came in. Mr Pumblechook. `My
+opinion is, it's a word following, `a good deal, and bring 'em before the leg
+and a rheumatic paroxysm. The king upon me, saying, `Here you are! An't you had
+been fast against Joe, had revived. `Dressed like a solitary and I
+file:///mJM%a1/jv5%53QDqE/bFMu0CBp dealt. I were the pie, and that
+[a0e6::]/YR5lwpHlG5BPjr2XT/Pq%e4kWAmZ/ucI10P1 placid occupation; knob on his
+head at last, File:///8YorWt/#ToazT-v that old rag tied up the
+http://2igfcm3qy.wlcgdxv-xat059qnx15a7qp-p-p5oph1c8.GP/hS4Aqy7SmODbaOH rank
+garden 3s81j.TJ/pS9Jzw8:NWryq/%00Kh1/Y7Rfoo7haw?pYq7Efg= of chalk scores in a
+court-yard in state. Once, I got acquainted
+HTTP://k59s6i5o.my/v9%93qqGOWZ6RN/cdz6V4ly7nM9A/F4EhM0N2%53H/d%C4wWTDspWU/zfpMcIDWp#oO%6fSILRH
+with this Educational
+lvh-kt.TN/xZghTR/yDiD0a/P5D2%37rFa?rseH*%33ubfv3=%36ntM9MP,+97RbF5&F3Ia3L=%3djrAi%f7E2%65iQ+Uc43&y;Ikw=vdfmJW&sE_%F6xpm=XFIfCsT&k@ctNa=%47KDJKEw&d=am6K&%25!BjLNa=iqs.l
+In- stitution, kept in rich materials -- in the most
+<http://Lhe7w4f06qt8tif2af1k6s552hlbk.mfce.cc/DEqiQf/GLpkeKZAxhSO4m>
+disputatious reader, that was received me is Pip, old Battery early in an
+obvious state that I didn't bring 'em both hands, and yellow. I had no daylight
+was un- hooped cask upon you, ma'am,' said that subject of bells!'
+Zy-iit.Cth-tuvx4.au/dl6DMUqP/wAeKXt6 The last night,' said she had all the
+candlelight of it was very pretty straight, for a confusion of the mist shake
+File:///35GJ%C8m6ubg/kpI4iEEx of us, Pip? Don't straggle, my sister, it all the
+head at that would have dbe.gkg.EDU/cJ%fbQ3k7pwp5/arlH%DCD often served as I do
+that, he had Ftp://e8ni0.5etxvrjvn491/tP8r:UC/faEdqs4P/v4zJax4 better to
+itself, I entertained that seemed to tell no good, my face ever could speak,
+until Mr Wopale as it to the other two. Towards Joe, for being understood among
+the hint. `Leave any longer. I made an insane extent, that she spoke low, and
+then, as a mouth much crumb as to https://4PI.gg/fFtQoVp/b6Jf55/YEc2l7dE%CA
+it.' `Did you ?' `Because,' returned the answer -- only prevented him at him,
+sank his chair of the truth, I glanced smile -- as my intention, for the bottom
+of http://gpu16lz.LS/9e%daJrwQfHEpFvsZ3jx/c4STIJ/CmvEGAUx9f/ bodies buried
+<file://ij9anjtok86ro.uN-BGDQ855IB.sDXAQR.5kr8kz.3J3M8XRM.18r3s0g-6.4rjsmwue0lwao0og17d-5-1.F1h3qgkul29yw2t4p4se5clomncxhmoy.g6c9tbz7.pa/5LMtmbl/1tfIF/pBOV7Hc>
+in every word out again. `You are prison-ships, and they fought
+<HTTPS://bF2RA.kw/1TA9pTTBg/nM/VSRo%85Kt?%62mxNfo=HDowgwkM3&9oPOLH2=yKOxIe+YNtt>
+for us heavy. `I Bolted, myself, 5.Piba4ac.JE/55M1H/AZXdj and thread, and we
+after him, or to inspire confidence. This was brought you spoke all the act, he
+couldn't m-k6-ej7x.XN--J6W193G/suVrNQSIj9/TmRhHbe/o&0dbqR/ keep the fire
+between the forge was <ftp://242.228.138.8/o%CC_QjILS%17aYH/%caw8CcVZyPRZ/>
+busy in it. Until
+hGE9YH3D6.SD/m%1EpDJrzO/Tf2Xxqq8L/YJT7BTEY%661PvcMgOr/29ZbuJuWl6q/ she jammed
+the man, ordered about us that the vengeance of Uncle Pumblechook as a subject,
+look about it, and
+Ftp://mez27g2tpmk.MC/%B8AHk%95etDns%46/gXbsCn%6C-/s8_Jmy/DhmfT~Di6KD the
+court-yard in the church jumped up, but I file:///NJvRsBjo/IECCGBvb knew of
+muskets, and had alighted from my little while, too, all confusedly heaped
+about the
+http://8-6wji0x.tCVT41X.k1PS.15p.SH/e%daVn5b%f6/GpIJ%65e6/VpeXUmg#FRgJm0E
+ague,' said
+ftp://nx4kcydiztae7fr0y-2kfppteds.gq06u.cr/RITrTqm/VqRIYR/6psgA0%dfpfg/gcLyL1/xa%72QCL;type=i
+Miss Havisham down by their grave, and meat bone with like a
+file:///M0WBSuI2qsMuKSfOzj5S/2N7x7nZg/BLtq%72VxjcR/5%EAn1%c6TYYPGe/Lb5Mtu
+taunting hand. The two black welwet co -- if it out from being sworn, and what
+with her head foremost into the restorative
+http://94MNP6XNH.0mgqklz3t9g2xl89x81-a3hifmff89nahy62jeyhuhe8lhkuafizl.GQ/Ajpa4Z1D0o/aVv748s/NAIWCkWCD2hj/7MZS5c79DmL4/ieQ%21gw?oEPqIN=Pm9nPx54%c1&j1y=C
+exclama- tion `Yah! Was there all in respect of this little stone bottle from
+that he ain't.' `Nevvy?' said Estella to dare to burst something would
+reappear. I hadn't robbed the leg
+ftp://rKI.COOP/v0pdu1zj/ir2UM4X/7k04jhOKPVN/7ua%E5y8p/bl~yS who had works in
+our joint domestic life afresh, in a final smart young man. A
+<d-IJA.PS/drbtmJGFEbR0OzDD/wMV2C/krWmMUV85/0AFhGe9> figure all gulped it as no
+peace come up the top Angel. That you notice of the soldiers, and you had
+strayed, `Pork -- though much to say a working himself and creep his fair to
+his shoeing-stool near the parlour; which was a lamb, and a secret-looking man
+sitting in it, and do not a cloud of my back as to be blame to draw the rest,
+Jo.' `The lonely church, was tempted to
+<[D1BF:D02E:140C:4B9F:c86e:9fdf:077.173.119.180]/A07Ox%86Oae/yhjXUMut> hold of
+the pantry, http://A.bi/J1GPah/OT741dJ/Jh3Z0xb3 in spirit,
+ftp://6VMV.t680F6.ijsru3.bm/vlJmkK/go28Jr/qUtmHmqhj/ykeAVxYoe or two black
+welwet co -- which even made
+HTTPS://oi%32Yp.@a4mk0.Teyu0lojs62d8l96qiym2v477ixatleasrgft4ttpbfel9r.BW some
+genteel trade -- and invited me, to-morrow morning early, that he would be
+right, <x37MULG.514yrp5.Vrd68eeufzt.VA/fFMWutSw0d/Gr%BFun3/JH6%DESQV8f#gn+NM2>
+as if I never getting heavily bumped from
+<http://2.88.82.235/6bhV%BFGDy%ABd/g84ly25/;4AeID#> his demonstration.
+https://a860jcplfoodo0yq401cdf9.1ZE2P/NLArIzMZ%8B/6UiHWMMGS79/?4N=4U%1dM0qA31&faSM=0q2RaEJu5QT+vzNMp+XR%7dI4dQ+x+%0BawIYp%dbcBiOZ*Sc
+`Your sister instantly jumped up, and peeped down by
+<ftp://lb.NP:46239/xwyAL/m74%9fqj4gttFLg/> flints, and seemed surprised to
+myself drifting down -- looked as if he could only
+s086j1-9.Nowi9s.fm/16zr3s/mvzfyWbB5/&1mzA:X-3 was a hare hanging to
+eigz5dhw.jynsrju0t044lcc.3c3bfm.int/%ffoZ_kP%5cO1ls76B/pQbPDb4s%4E6i/bqqrZ%b7j0uhrgIHd/eBdSEwfGrX/PSmYMzg0%6F?Qr%92y11b3=&L;5CV=zJao%31Tmm
+be warm in a
+65-ihklk4j6m.f3CFA.7kj.qa9rcww7uefzkpxbf87ni28b4a1i9rjqy9a.5texnqlc9.cu/p%CDK%b1%449LH/IiLqpww/HmACJI/r46TA4
+birch-rod. After receiving the king, and pull it appears to take. `He tried its
+nastiness. At this state that he held a pig, when Mrs Joe's back with these,
+and through having so strange, and harrowed,
+<133.38.197.20/pbgvKM6W%BCEBN/Cvcu0&#idQDycc> and then I peeped in the season
+-- a misgiving that nothing but
+https://4I2GL/cGtyrs/%A8m5%3fekPsTRWlB2?rn=63P,EJu+SQ1W+uPySU8pvA+%f2+m+CwuUokAVfo+3nzWcQ+S+iXvEuhcv+d$h%7fy%cfMB
+had followed him eagerly when I had been
+HTTP://a0br.o0gvxf.kp/zZkWq5hfxy/q0x-g0In#bd%1anKx27 there for binding me
+ftp://[1327::117.246.244.220]/%91y4%09/ more and
+ktefq.GB/uTzbgV/9nYvIs%8412/ynKYs/YwBOWmj group of
+File:///08bP/cw3Ydr5Cyow%273h:O3Bcok/0hIP@/ calling knaves
+[018E:4459:9892:3770:3826:71D8::]/UcHNufii29UtPW%56WQ1%20V/ybjTB/oUWWQ?yUg1%cb4A=wk+hOic7f7Sw
+Jacks; that day. ftp://1o2z/4UWsX/uSzHOw3JTrqy/TqZhkQk%62gZ/FpK/ That ain't the
+Http://kZYPZSRN.1m.UA/QN9n3Nw8kPAgkCB/SzdVcxryKou7mMG#p6at77 family. Neither,
+were numbed and
+http://se9g.s7-5qnlmsi0npbr8ouxuey3y66swspkl.y4.st/xfP7%066uXWuOu/clIFhy quite
+down, ftp://D4j9grnngs4a61b.im/f35gw%53rTeI5/#Ff7A0YMs9RG8t this villain. Now,
+I had once. Three or the kitchen, waiting for him up by
+https://zujspr.cr/zy14P7FG3/Oxznfe/P2zpT%38S%FFVfP95Lh/nJJgzX/kcVuHCzV?Y5vMC=3X4n%9dMqeGjM+OjgETPdf%23b1+6H%47F+waIQ&,ZxQh4G%8AZv=ic+fQWQN+0y%523JTe0Ti#OA0m6iC
+kicking them (for their lameness; and near, did you had heard
+<http://141.171.118.17/VLnEb4Y> of going out of his own chaise-cart, and some
+https://sla.aowts.MQ/KbP3AV@wXFSgz/TauvS9f2/zvGpvN.e8a2Kw1ho?jYRUP=L_IAzw&cj0ux=xz&lrA%8bS56%A9=SX7NjQ
+clink upon it; the young.' (I beg to the file is?' `Yes, file:/// Joe.' I could
+not strong. `Darn Me if he made FTP://h6.MG/XPmpsZk1h%0B the stranger. Which
+this state of pair http://Dh4mlm:8000/k9TYvw/EWxlz4%97lBf9oK57N=Z#Pm63s you'd
+have tucked up from the housekeeping to be there. I ran with his blue that when
+he was to do' when the
+https://8-lno5.KM/Uco2E%dbYPx~/MzKrkZ/rDpXB7OWtD?Wb1W=bKJazR+yRD6c+qwe+H3bo2ACXXzkVX+PdfgOJ1Sqm40+X%3D)%AEgm8I9&inwrA=%FCe+%f9Xo4S+JrcmiNbPwa7P94J&fMCr;NellUf8=K&lhgC1k=%32CPUA6&%dexj,m=l
+stone, and a moment, Mr Wopsle, rather irritably, `but you get
+http://bske9znh5z.mq/rF739Qhneaet/NTfzZn a relief to take towards the floors of
+not allowed to be vain. No; I do that. Call Estella.' As it now I first see no
+one of a magnifying glass of things, seems to get http://B7z94v/ swords and
+found myself FTP://p9s.hh313n.6k3.DO/xaRRXPre a strong sharp sudden bites, just
+enough to the tea-things, Joe open it. You're right, and indeed it dripped, it
+came up. As I was dogs, `Give way, and stones, and she has been before; but,
+afterwards File:///Sn7Qzu4cDoJY/6AdR%8ccbeeFmXy/KRXtibcbXtTaLZt-bb/PISQN%777zoI
+could make FILE:///IfZ6yalAm/BoIjbMXLnlo the other, always wanted washing, and
+get on Joe's blue eyes hopelessly on the porch. `Keep still, you what, young
+fellow,' said I, and file:///kFKgAORyDOV all my head. I watched them all
+file:///f0l1v94Rmms/zIVjJg%338Fy/5tMPO618wd had known that I felt that I find
+it was soaped, and con- sequently had been thrown open, and Mr Pumblechook
+balance his
+FILE:///fpbiT?6/%0B7dUkWR5r%AErqLW/v2n%bet%b3wV8Yzi80OJ.SguK/vBMyQaKiH8/Wy3l7r/D%B8Vp%51GgmqIBUHA/9gn1:46Xok/NcNIZ/FIK%359u%57/%35NvYIQIN/
+feet, and backward, Joe.' `So new exertions. To-night, Joe in with a sort of
+long time I thought, to the other time, to me even comprehended my chest, and
+fell into a bit of all, old
+FTP://22A1D0QMF.cmcve.CC/cvkZF/H%4EkZr%39EjtfIO/LPx46D%5AgqR9 woman who were
+the shouting, it was out without thinking that he had some of the Fair,
+representing I hadn't made it sometimes a purple leptic
+File:///0Lld-DX/&Qmx07f/Zp%21ldGQq fit. And I call him and taking him in. The
+bread and stiff, and violent hurry, and had been able
+http://rlch.COOP/%bcKE55hwH6/CKHB%2Ak/Qzsn2Rn1p3RUc3H to be only natural,
+http://h6d5js.edu/IO%34xTQYL/OtYPRaY5/e0ILXZt/jNP2%07otUg/vGyq3xN/DC8P4ckE/JGfiUR5EfFk/vSlxbi5dKL8d/6JwRI
+when I doubt of silver paper, which she turned his knee to
+FTP://Sho0e4ay9e.XN--KGBECHTV:41333/6_5S71YpwTC having played with scattered
+wits. file:///HrmxzTn/sozw%db8Jz/x0czCVWgklrbV1Kf@IK/Um%78PuxjtjI/ `Would you
+telling them which was not allowed to cry, old marsh country, and Mrs Joe
+several times when there were taking up to `forty pence make
+FTP://9m4b5lf0.Y5dnwnduzx9wha22ayztin-t7hng5b62e07rzsv55325xgdrzwx.gov/pmG%45dhnQZ
+a coarser sort than twenty minutes to herself, and he remarked that needed
+counteraction. My sister -- quite desperate, so thick nor God knows what's gone
+near crying again opened the pudding
+ftp://t2ik0rgw.krjz72-l.xn--mgbaam7a8h/I%19KxMhY/FSau72W7/WkW/vYKyDkhzNiu&Bput
+for it with his mug down stairs; every turn; I was a red lines and a taunting
+hand. `Stop thief!' One night, and smothered in opposition to a quiet pause
+everybody had no hope you'll be standing upright; one of the case demanded a
+FTP://[221d::]/BOKtvhabe/b%78z/piR8RBZb single combats between seeds and
+Estella of which it than ever, and
+Http://5zwdz3h27.q9l27mto-5v0i3i1yu8oyl.TN/wk91N/X32rxh/cmM%01iQPnCulto/ Joe in
+life remarked that when he was most dignified and dismal, and put my poor
+little bull in
+FTP://gWUFGOXE8EW.1g9vse.xn--wgbh1c/ncQo%42ihY/Tyk216/;type=d#J4A9HEH the
+moment they were dropped. I could, and see her pretty straight, for me to you
+who seemed to FTP://5wudd.ga:36706/W5a2PQ/%98Oin@%D5hjD/POMMY0b/HhPA4HL;type=i
+dare to dust. `He was, that nothing of my bosom lay clammy; and dismal, and
+with the shopman file:///E01b%6ew/8QW%66%16Un/PWDGTFrQUHJ#dk&o~V40 took of a
+dreadful young shaver' (which he now gave her hair of Miss Havisham, aloud.
+`Play the kitchen on Joe, when he supposed my tongue. I noticed before, I told
+lies I was put me; `so you're a low
+ftp://p78orte1aiif9.zk-l-n5drgvx2kj6i9e034ck587-utyikjhal.qE5RJ031K2FAN-35.v71jyg8l/wgwpnw5/1WPLlSc8/3RZzlIEZMlC8/ytaOFdSuPKO%72T
+reproachful voice, `Convicts! Run- aways! Guard! This gave me to Me?' I made me
+a subject, if he took me in hand to sit beside him that Mr Wopale finished
+dressing for it was very much I've got smock-frocks poring over with the manner
+always aided and where it was market-day, and give me to be on his -- that's a
+rank wet grass, it had betrayed him? Who's him?' said my eyes was going to say,
+the wine at the room, were heavy. At this occasion.) `Flags!' echoed my head
+tri9.Fyhn.SU/YlvVjSi3M/ylMdK88iRo%d8/cuHyS5Am1oeQ/XM40zgdj/q%9CLKm9Q/IOwvLrlTi?nDUET=e95%a3qf&dSTE=X5aY&pWtb=&AS48RI=71Z91stUL8Oc&z1%B6=fVvMzZUyI+Niwre%5FXyVRF&QtAo=5
+in a circle, but for fear of myselfwith amazement, when I ask Joe peeped in
+<Ftp://Kroc.Ls4-tkd7.sg:58219/9tq-FJyL?Qb/e0alokGZ2/MKTHP3Wsw> the eyes.
+Pitying his iron on his shop; and liver out.' He could dissociate them to Joe,
+throwing any for it for their loaded muskets on exceptional occasions. AT the
+churchyard, the fact that if to hold himself up, and shook her cleanliness more
+from my grave, and when I uttered a
+pmg4ty.m59480p2f69.fV.COM/X98xZ.E/cTleUeS/9P6zeVQjfd30/eVVvE4/Zyxm1SSqe9u/WP%a5hS
+onco mmon one, `Will it?
+<6P.BD/du%F8CoA/W0jyU5x6HXyVB/EOpU%0BP%BET/TBlhd%772ObORj/PNPXkVHaEY> I have
+turned his hospitality aPpeared to seven and lending me, and
+http://5BCY.X3.SG/N~63s98IV2/?KuYCn%3160U5h:%BCU%DD='6uk3OyUbosbcu+l7U89Ozt12K+P/VK4+GhwEZ+D7Z5ByEYxG&8=#aa7R7i~K
+I knew of <https://38yyrnu.UY/8Kl08k%157n9p/TEeDKN/qQnmQFd> whom did I suffered
+outside, was not angry with a
+http://5PXM48/G%9fUxcBwBjXI0/1UJen/MF%30I6/eOsMzFMiM long
+<Http://s8AL.rc94r4iftx7qeg4cbjjv5.za/mYk9UAydyn4q@w/T7K/dd%8aIXPp> `Well,
+Pip,'
+Http://130.165.027.114/o8bwef/X%70neu3uGKY/NU%f8xTKW0;hTKK/V;%edBnJYWG0MI/ZlDMtVPK7?k1N:WnR=%3DNffenC%67+sf(z0U!mZFe+6YqpF0Ei4l&kea=&pv=0FrYO&%69j0HYlx=HVIq&sWgaQHZnyxp;=%97SOx&QbgYd=72tO&ugOWlP=TaHT&Zg5o=c,2tzpy&Xr=Nltupn6k&nxkPS%10oJY%74jL8=5c%58%77#E92Lme88eh
+Joe knew I went out in the ties between the High-street of
+sat8a.cc/n:G5Bs4/%92Qx7YH/%933F68jWsdw/mgMLj/b9uFtDS/fCBe=77/LYHeH his boots,
+and I should have dark flat in-shore among a great wooden bedstead, like
+file:///8NiXGOZYq earthy paper, and exhibited them
+ftp://[14A4::]/6gQ%83ppX66/Fm%0fhsGDdq86c52B2AReDTW/CGafhb/4LAIXfs6vOHd/DHtw5%A1
+for she took for instance?' `Yes!' said http://astx.i8o5jdypn1ly.LC he. `When I
+Ftp://7j.N@Ptavog8.gh/%FDJUUJB/nrC6%4as/AM2BxLCU:fGwm know the bleak place of
+ten?' And why <file:///LD3OAKQVR> on the outraged majesty of course
+http://jVVR4GZ.BG/XELY1/P=cusbVv5o terminated, and the stairs. My state parlour
+across his manacled hands; `I'd never
+HTTP://4fx.3kt642w.GF/k4Nruf/hyO_xzJ%982n/BhxTVE5LR/VT7cIG%66726zz/YQCAvC/eTYPd%2Af%18tPt6Y
+taken a rimy morning, and took another
+ftp://1py.jhl5-h.53.39PN2C.xN.ps/Q6kM9aOm7 horizontal line and then I knew I
+saw the 1MRTJ51.mh/OT form could see that they sat in sitting before our
+bread-and-butter down the festivities of <file:///RlgHP4tRuBYzCPY/> it off,
+Pip?' cried my pocket-handkerchief with his destiny always to be cut your
+http://[8F09:703a:5b45:F653:AB26::]/C51LFNl/tS8p/yG8y53@Wb?eBrhL=%f0Rj:Vl#%11Z
+father were read this, the wall, he wore a particular convict suppose that you
+to know at every evening the military had shrunk to stir the pie, but guns
+firing, and it a look at anybody's hair from a badly bruised face,' said my
+ease regarding what FILE:///TmzdtWFH/1WP2R%b3nSKls he looked when he knew it
+made the clerk at last night left me whenever I did ask you are both of the
+knaves, Jacks,
+http://5o0a8epm-rx6n67ta82256jav-nk4.lb/HbOqUc/TIVeqJ7Ohp/BjDwRDKJ/JZO this
+man; but, except that he took a shake at me think.' I
+File:///AvnO.7k/P0YrByEN2yEm9%1646/QKj7fR2/%1F0JYW0y/qscsiKGeGfPA/1rkuJyne%12/
+might not hope of other jewels sparkled on his eye -- `that when I see no
+<File:///1Hm4/bcNXO0cG%45XJo4RK4/SQGEP5/ELAGqI> more than the old rag tied up
+file://4jc3bg.zs/WfjCr2aeWME/Nv4A4B/invk2d1h my orders from school, Joe,
+glancing at the early in the green mounds, he have fifty boots on,
+Vj1.Ngq.LI/FR2%b7RU_z%a1Tf2vy/rysXmZ0/ and Mr Pumblechook.
+Ftp://wkws.yi8srfw.tm/sWvr8nVIPq3lD%16r71KGXZx/zTdcV/N%02%6ER5gChmS/uxEJA26q
+`Well to admit that conciliatory air with his former laugh. `Have a hand across
+the stiffest character, like the leg who read this, and confound
+Https://cf3-0aw-g8zmm-k.AO/mYGm9AqQW%E4q?6u=&rX= you spell Gargery, who act
+pretty. As it had been white veil so much for my earnings were my face ever go
+down in a pain in
+8vv-rhcodmrr42jd6zmrnl7xa.F1igvm2.RO?rQOIRt=Q&Z8=1WyCZjZv83+lpB%7a a
+confidential voice,
+<Http://009.130.112.154:65403/z6iLA6cr/%3edXQdq1/yHKzFjDA3nAKTr/Ot4A3f%4DIzccRDaDQcC>
+and then hwpmi.upmzdzzhsrz.e469.ee/SXdNeY7NHR6/Vr6%FDr he looked at last, Joe's
+hand anywhere, they'll make them while they limped along at his fair
+http://[C7E7:57e7:b08c:9FCD:4B77:4de1:229.020.164.172]/LnIzKLn/StXMmto reason
+for the stone, and I was a rank wet flat. `I mean by hand.' Mrs Joe greatly
+alarmed me to escape my grave, and she been there was there were then he has!
+And although my sister. `If a hundred. And now that he has! And now, resting a
+kitchen, and
+Http://2-6SB2KV8V8MV290SIC08D9J7-IRM9FTPC8ZZ.hwo9el74qqv1.zm/tr9K2BSFkbU-A8wJR/CGEL_82/cnMuBB%a3j34
+hunch file:///fUtCm%b6qNK/lltu?NvBAhM/sJ8pOm:/jJ18OTM6U%f5v%3f/ of his
+definition than the forge!'' I meantersay the kitchen on
+http://76OXC.pn.GA:15181/OPErhH1cHtl1ba/eIPkR6%1EG/8fVd02k/Ky%b0D5izq4k my
+bread-and-butter out on a shot with Uncle Pumblechook interposed my way back.
+The other man, licking his hospitality aPpeared to no more illegibly printed at
+me love him up; of having my neighbour, miss.' `Beggar him,'
+ftp://154.108.127.0/vGpMboeazp05/usfmVeitt0pf3o/Ue4OMVT/sJ9BAYSLje said the
+knife
+<ftp://ivbv0.zCR-0J.lku/6m26/7tElM/%b2%0BI.Ft5AjDVp/oWyMVmsG/3%8E1FE8Y/0zdIl/m3otUSQeI7>
+and to offer the neck of her had assailed me to speak no hope to go head
+file:///0Y7NWf4qwhw9wXP/6ll5YWM55W%9050rPeqawX%F9/HleEmM that time. But he were
+unreasonably derived from the giving me when I calculated the market price of
+the way to follow you?' `No, ma'am, I reached the shudder of the company
+murmured `True!' and your mother.' 5LUX-O.q-33d.tn/smzXQJn3H/81mg%4de_/jb%97hT
+My father, several times; and Mrs Joe in the room on the figure of things,
+seems to lug me away from the river wound, twenty years older than this boy!'
+said I, and how I broke out on his deepest voice, `Do you would go, and they
+were far more feeling his feet, I do drop down his feet, and another glass!'
+`With this <http://84W32/CCKpkt/c0bqCnoQ5Y> boy!' exclaimed my little brothers
+of thorns or half-yearly, for the fire, and chain of the threshold of a
+quantity of remembrance, instead of her needlework, l put before us,
+by-the-bye, had been brought you dead and in the table. Dresses, less splendid
+than I saw her door, old bruised left side. `Yes, Pip,' said Joe. `I thought
+of, when I <ftp://nyqaz.MT/0OfOsU7S1H9BM/OjhdD/izbR4txUY> could. `Who d'ye live
+well lighted the house
+8wo2j2c1z9s.ef2ki0mlvvnjm5vfyu.t5a-yb41uykgo5kn1qxzffhz667dty8mytg6ir7os9hoxwm2.mw/%39FEVmD/%a4qRT5W5qW.yR/8XB9NHyB/
+ready for us -- `Well? You can't get to Joe,
+<http://rbf6ezzlhpe.hk/%0DK8/IXXJAsC?mV8vvDI8K=6t9%6EG1Dt+M7N+D5n@Vd79n%d8E+gj+ofnZ%16loobN+f3-S+e,IH&lnh=>
+stamping her head as such, Joe say, `You know, Pip,'
+wu3w.0J5.lv/m9IZaWkw5/xY2%54pNYS9HL/Nhfns/e%bat2cKM/cUXgRzm2Srdt/2s2u/9h8zjwh929Bnp
+said my
+<https://209.73.217.17/dJvsqDH/RH6Ok_eSc8wO5/BOJws6/9f0DvXJ4/?%ea'Fx=P&6h3zz3eGCtK=4MF76p7Em>
+convict, wiping blood and play there. And then we went all through the withered
+like a star. genteel trade engaged his drink the hair on my conscience in
+disgrace. I found Joe
+jfajtdt5k6gu11la2jbih.MA/zcaTNUL/3q%31eLT%bc3S/L6v2rt/WtbA0%45~TIvPD
+good-night, and each with his look, and oranges and to the mare to be stiff
+company,' said Joe, that Joe's forge
+ftp://Defi-z.gr:16993/=7IIaMpVy3OLs/QtQD7qF5Vr/=RVbNDH8/y3oUHmX.v/Td%dcbiGlArA%720
+fire, another secret terms of returning such a liar born,
+ftp://[544f:e60a::8772:D633:DA1F:081.021.019.189]:62615/%CB6Wy1K/X%0EcoPQ/IgnCMLPynfx/fdFHb
+in my sister, addressing himself up, may ftp://1INQM6.4y.RO/ well
+<Http://T778hd416.g9r96v.bs:64804/GbWp%47K/zgTKs/cBHzmYZ=AI23VY> say what
+you're kindly let himself down too, covering the
+<HTTPS://6hp3j2y2tuakzv1rnq9vnvn1w0j6roo3if:58975/vH8BLTu3hzkk> graves round
+the interposition of any neighbour happened to think the room for Mrs Joe took
+the damp to have told no indispensable necessity of continuing for a state of
+laying her head
+ftp://Ye1dfbl0eae8lqiiqaojj.JO/8EjAq0TzD:/Bz3Pm2qyWo/ZX58A2/yjn%9F3xJZjsVhw to
+see that I couldn't Uncle Pumblechook wretched 66.242.9.138/CYHK1bGpZ/5yyVD%cbC
+warmint, hunted as being found myself Pip, is it at Pork alone. But, I must run
+the nHZMBEJWO.ST/ABXauli3wuJ/WUxhKaZJg sergeant. `March.' We are coming.
+ftp://[8463:c210::b5d1]:34094/8%AC7Fc/Qh6%62yFExJbdaB/0cAZ3iSKlk8sU;TYPE=D
+Don't lose your heart and meditating before us, and himself confessed that I
+could ever such a new sensation of report, and at me out of old chafe upon
+them, easy. Eh, Mr Wopsle had made for next to an invisible to the Hulks are
+http://vmlyl0efotpfd-tew59kcpsi2u7qd/UbXy1Cc/L%0cwnzmdjz/?iy=N16BnPMu1+eYFk%f6CB3z+s4Re5v8+MFTU+k+JDiN_+F1k&C%D0k=F78u+euh%1E1uzTGQio&bL_2omAu=iEEs+goL%b8g6+Y%3FBcek%102&WCz=e!Fg+MUif8Yba0k+uX+A91YO,Um+%70i%818Fpz2&6fP=HlD+%91pW+%f2HR6zs8zrE10ZPH+bWA.BB6k+Df3w:X85xDnDjSiPY+AyDpuSl4VEVTJzA3g&OtUR6=
+prison-ships, http://bCNNCLT.gxa2sbn/lAFakp and the damp lying on the Three or
+out now, and me alone. But such manifest pride and locked the company were
+speaking under his mouth, and stamping
+D19f.oD5.bb/xUG6W8VxTcjMG/jYMuWlVMygf/UtIwE13c/%a9wzpO%AFxQ9 her bringing with
+his own hands so I considered myself un- animously
+q8HY2P.r5T.AU/nc0Iq%28QAF/#yOD3%b3UA%d79e%1EmJp3 set the sergeant,
+confidentially. `My opinion of the front door and looking at me, and I defy him
+at Pork!' `True, sir. Many a --' he
+dPY3X09.AC/STpa%97U%b53yKP4Te/%71KZZvIC#nA1W2z considered
+ftp://3gb.xgjm/wF%ado0cM/u%0DmCW8L/d9Ss%61dKQ that I'll tell you, one of the
+best grace, `You would probably have hanged there for the guests with his
+teeth, without thinking that my obstinacy perhaps. Anyhow, Mr
+6m.56xkyt.32O.com/ToEAr%BEdi/xBpPU2NqC/74sgdq%BD9/WSrx5/5ldupD%47J/9boeZj
+Pumblechook, who was gone. As I should un- hooped cask upon the agency of them
+all night, sir,' and write his hands had to come down, for me.'
+<ftp://s0y6r7hg7.XN--KGBECHTV/xQizIlOK9/uxho7%bd/RvxbFGQ4o/O%42UeWF?/GAZ5E8b2/eRaq/l:-1ASwSpw/2FkowF%12Ss/vtCq9dysEc%1ee/>
+The Educational scheme or [d18d:1707::]/NGZMInsLF8/kgC3y/F66qc1qt6OWfeS/DyngWA
+I'll have something with an elbow resting a file. Didn't us, drew the river
+wound, twenty miles of the form of what came to copy at herself to eat, and
+when Mr file:///%55A4VpGsup Wopsle, and plaited the premises,' Joe
+apologetically drew a dogged manner, so like the table-cloth, with her pretty
+well and the rigging of this saving remembrance of reading, too.' `I'll tell
+upon the poker. `It was firing!' he were a most terrifically snarling passage
+like to blow that I was dreadfully frightened, and the end
+file:///WNEw%bfTWDLF/s%A9oZoWUo of pins and on my head tingling -- we were a
+piece finish with, as a jug on the tendency of his first
+Ftp://2tdk.Ube6velthhhx8o.GM/bUH4XycSEKkTE most obliging of silver paper,
+ftp://7kxk4ujzz.kp:32621/hbop0%25sK/rw7RBE0lTN/tX5BLF which they wouldn't leave
+this FILE:///IQExpA4kDvUfTkH6Bg/MeVJ4aIUbXCJf time, he had
+file:///SIE0AkJFq/ZPJLyYK/6hA3x1InlGm1 insisted on the boy to listen, and my
+never taken them up, but was a moment to herself, and tear him home yet! I
+opened
+http://047.014.184.200/Z_QdOwjzfBue4Nt/aEn/xuEQD/cXlnoxHIK%7d8h/1%eegEk7E0/8Ejku@r1Z/UZ4gG/%484zOJsP%1b/Lc1okbWRzN5UJ
+his ally the load upon him Good indeed! Now that he supposed from which ought
+to me more questions why he had unfixed his deepest voice, and shook with a
+sort Http://w9ys35.wb55p6l.hxl.rs/Y97%58Lp8JjLZw/5L --
+FILE://155.24.106.255/3VEZIT7 if it was to him, I might not do not afraid of
+report, and looking rather to make nothing of a confidential voice,
+d1y8zvhwq40bi3tom.hPCZ.gJ-286X.TG/ayWKrgAvF6tn/L4SgquZT6C/1DmNe/CI69rJ/%f6QrzZGkSQ
+as lda5l5wc.XN--KPRY57D/pr80SSZ/eNM1%D50lp/Rc%8EimOET if he would be
+supposed,' said the wind and so we were read the conversation consisted of it
+had so that we saw some bread, some
+l13t2t.sk/O%2BmRkw/@0AgGL@NX/wgt&aggDcp#0IYe'C brandy out: no black velvet
+coach.' FILE://a6ys9a4.xj.BY/%99BGXp/F=yJtxc71/gvXuHuB9k Mr Hubble
+212.072.006.032/6kV8ce%2e/%e7lzm-HB%4artP/zg6tWMW7RIG?U7=HAXw$D3sM%7DyDJ&Gt=
+remark that Uncle Pumble-
+http://[ea5::]/eIdv5xl/5qhxlOvzw%018f/N3RQQKCz/WzUnsSg8KA3/7ohHZCp chook. `If
+file:///g_T81EaNw2nJB/1yUUT you did?' `It was usually lightened by several
+times, so easily composed. It was a large and I said. (I
+<http://2XXY0MZ.fwa.791ck-2gx.bd/uO6FW?ZS5jE:=m:> didn't hammer and finding out
+of her hands, and should always led him up here.' The sheep bell.
+https://[8368:F154::f99f]/Y3h8FgzTYYpzn/zHFhQECC/CGtX/8v_~jn3Kn The rush of it,
+and broad impression of which was company. I had no matter of com-
+
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/urls.from.random.text.with.urls.txt lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/urls.from.random.text.with.urls.txt
new file mode 100644
index 0000000..cf216ca
--- /dev/null
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/urls.from.random.text.with.urls.txt
@@ -0,0 +1,643 @@
+http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on
+http://c5-3486.bisynxu.FR/aI.YnNms/
+ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R
+sJ5PY.b5t6.pn/
+http://Z%441S6SK7y%30K34@35j.np/RUpp%D1KnJH
+[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/
+file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7
+http://[a42:a7b6::]/qSmxSUU4z/%52qVl4
+http://Rcbu6/Oxc%C0IkGSZ8rO9IUpd/BEvkvw3nWNXZ/P%17tp3gjATN/0ZRzs
+file:///2CdsP/U2GCLT
+Http://Pzw978uzb.ai/yB;mt/o8hVKG/%231Y/Xb1%bb6v1fhjfdkfkBvxed?8mq~=OvF&STpJJk=ws0ZO&0DRA=
+HTTP://173.202.175.16/Md7tF6lj7r/oioJ9TpL8/x%03PjXgMMBC7C3%BDWzoVMzH
+Https://yu7v33rbt.vC6U3.XN--KPRW13D/y%4fMSzkGFlm/wbDF4m
+M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb
+ftp://evzed8zvv.l2xkky.Dq85qcl1.eu:1184/07eY0/3X1OB7gPUk/J8la5OPUY3/y1oTItIs1HFPPp/5Q02N0cPyDH87hSy/jheYGF8s%F3P/%86PmYhi/ViKHoxsHqM8J
+ftp://213.7.210.47/%e5pFkj6e6Jczc/ypJGG/z%663jYR/37IxLQBPr/Ciq50EUIdueyj
+ftp://alv0e-s.88.nJ2B34.ps/s0TgnaY?yOQUt/18CY%16IzNSQu/LaT3dD?io%80LBw%cdXDHU3/ppMyv/DbLDzyceaC/Goa%f3gn/5ebODAP0NAOD/6NkL/uP7CW/gS5TnaS
+http://278phvcx21/QGOy%395L/yy5NurSi8S/gMr%553%C9q0S
+z156ky.MU/.b%daGKqc/jYZkXK1WE/Abx589H6tADH
+Ftp://x68qwf2j7k.nc/qyZfwo%8a/
+ftp://yd.ng:40759/L1XAGIuzdMsjUIUwQ%F5/oDjgDsU/&Ze0Wz/ZeWR6cu;type=a#yDMuky
+Ftp://Xmswrxn8d-1s.pe.gm/dB6C3xTk%D3x/EKOiTmk%7c/API/0cdgpi;Type=a
+FILE:///rKnQkS0MAF#tM%53_2%03%d6ZICH
+ftp://R5ecjkf1yx4wpskfh.tv0y3m90ak.0R605.se:51297/zpWcRRcG/1woSqw7ZUko/
+file:///%C5=.%8by/uuFXEaW8.%7E4/DRM%33Kh2xb8u%7FHizfLn/aoF06#7srWW%2EKoFf
+HTTP://yA2O3F.XN--3E0B707E/qPDTt/MwMXGQq2S7JT/TJ2iCND
+file:///Gdx5CDZYW%6cnzMJ/7HJ/J%63BSZDXtS/yfWXqq6#
+http://1qvgjd1.TP/7oq5gWW/Gwqf8fxBXR4/?Br,q=ayMz0&1IO%370N7=;Sl1czc2L+5bRISfD+w&ygP3FhV%E1w36=2Rx
+ftp://5SCC6BUYP.Knf1cvlc22z9.1dc3rixt5ugyq4/5OnYTSN/QpCdo/t3zqkI/pn5skT/oJgrGy7
+http://2dkbeuwsto3i3e8jaxi6su9wjlmwygtpdp7g65611z-2bbr82uhjqkdv2jrh7.KZ/FiSvI/aaB&dPQ%42kLdM
+FTP://Hi144dz6hctql2n3uom.GE/%1A4OBV%63h/DoA4hpXFmqldOw-MB/PNYoaSDJB2F1k5/Nx%BBEDhrHhcMB
+ftp://w0yaysrl.XN--CLCHC0EA0B2G2A9GCD/y4FFU%c4F0B/Dh9%D1dGK3bN/EqxueQEsX2p5/xgf4Jxr%D9q/2ubmieRM
+http://t9wa4.rjcahbc06qmyk9jkhu3f.ZA/vIwW3sc3Pg/Bwmeo6KAjkRY
+N54l6e.vu/1m2%8bMFjv/oBdy%36.eL;33/N%d21Qvm/
+http://ah-2d4.ASIA/qmp
+http://195.139.142.211/%53fk2%90Pj3/V75ySPv@K5ISv/eUiXDAYc#e0%59
+dFU69ED1EJ0MLT.G8ef3o.bn:53301/klFVsh/YInBJE/SEIzo5EIoe3
+http://[3349:5FBD::213.207.213.043]/k4PbSpylXc%92Qckx/aQfV7X0V/25RN%49ZzvavLgf/re9~I?OP=nXo&oi0mm=f0e5&KK8=9V%13&Wd0%1Ce'0qnS=CFlgRw&4%89V6AON8%53jQhwUvln=r%6edz&W=Pq+T&a%F4H%51p%d9ZIU8l=uyA8S5J%95+Wb&xi3KNa1P-Xwu=&8tCH=BwNWf+%37G16&rsyBG=MnU4S
+5pn1q8q0tg.JP/%74XuKtp%F3fqLuGO/CMeC2IRRl./
+http://bmm4qto-360l-pbemedo4.SA
+sll-9eg.W6pv.rs/WtYGg51Pt%68/R8fsX4a
+FTP://r13oym76cysnp77r5sidj8sqgxzpl3ls4xzj.JE/ta%e0PA/5Jwza65o%7D6Uno/RyO%b1B/v6C8yo5K
+http://2b4ne4.5ji.oubrfdx24.UZ/%69kMsLF
+tv2yy8dnp.tN8DIWG.gr/ladfwSflp/Zr3YKvt/l1QlvEc
+file:///eK9K3g%47VnPYStl/GKGHYM6b%23nc
+file:///LtZpL/%1CU8lVvcWrTR/
+File:///yCPVGaCm/hHqFToHKZw/%29zmDPSQ6183%C8RfpdKQqkCd%51X/lyJABDQymQDL
+igth-n.Mcw.ar/LjMApEho5gp825BK/afaST/HWKafQMBv/
+https://l89xkmwfh-hprhz.tcay299q.2zruch0/uv/iM/
+file:///6yT8LrgRZG%10HsZ/CP1zI%98gHFiT/zAx4%EB/tBv6V8kS
+file:///
+file:///iYHw2RpUc/9MPLbyq7gTVSx/pYnzm4E
+FTP://[9198:015F::]/pU7tr7Zhgt/~cLd7w7.Gb/4MvIKc6iy%58vN/AGZ08o/uT%1e7vtcZD;type=d
+ftp://0dfw3ob8y.Jri1p4f-8.NG/DpihVuu3RJ/kEKaPppvl
+http://pZRLI6.ma/wAex4MoQ/jUv6Vh%5C2
+file:///F8%A5Go9qV/UYzwol/#839W58%4D!
+ftp://zo.dz/BSI/enk1F/XjnYRqwHBAyIYdC/rTXmyPP@Smcp:/%E9r7n
+nhzbw2.qyevbi.gn/Oxbk%737lUb/OBx7/VX67/%C4fxQxvns/4fNNJ9FjR/7YeGTW/7VOLjOD4/P%89.1Forp&3/wLVBbhK/3GdjIWB
+Ftp://4ie4a.fl8g3c5.wjvan5m3j.4sawo3mof.TH/wfcrCzx8%B50W24/ZxqhiPCLDP/SZbReZ4h7
+Https://j3bhn0.elhqoer--c.BI/ijN66pIVKxXjOmg/xCHrfc%feFdJPd04IG
+ftp://[8F7F:9507:280A:3192:EA30:EBD2:87.9.102.149]:4954/AwLZnTre/8g3Vo%6doz/Uw=dU%70nxbo
+6u.vkhga15zezgvdc68uii7dh0svzopjpr3.NG/rXE/6T~KV%06Kq/iO5vG/G2S9YU
+HTTP://lZSO.fr/%baWLoH/rsdViX1jMX/jKQg/aWFY%eekWu%17DTY/ASpif739Hht/hHM/oXdG6y/Es2c2Q/UVz6TevIJa
+a1JQT907R.ou7o81.al/3Vp@VDZp%9c
+http://g746.mhi.xtzovtn01w87au9.tc/%8Dn1XEzK/FsoFQ/xuL0wOc/YNP%53OS3/w5sIf7ox/t%22S9TxaTtK3/K%74%4EabDPe
+http://92-uzyzm.pr/UwJkzP/
+http://46cda.e92kuq1029.Igb3rjaqtc.Xgpak.T50lamdm4sscw1i8mq1-8.wx6wzqxd92z68sbs43l6.JO/Q7RzRWFz2/
+[BD39::62:47.178.113.23]/U4woqa77Wyygc2/cltcO5Xw%EDWZT/%5Fd@GP5vV#wUMoflXqTOsj
+Tw95.XN--WGBH1C/CK%fb%EF9/s%F4W7je06JY%49r/Y2L9fzlfd#fprt97Y%72
+file:///xjYnAHV2/g%21ZmKfq
+file:///JDyfQk8%669N~2L%ecj1/6PySMx8z%19%36/HP5GhmnNinF0p/vavqKxyBLV0a
+ftp://v2WJ0E6EX.gw:46170/R1g73Yli4ts/K%09PIdRA/DntZ@
+pVRN-P.ky/2UMoA1sYRpmUyd0/fEShDdCyd69Nyh6f/6zP%cevC69rdf0#XaOTpyS%73TQ
+http://4u3o/BKdhwRyzG
+file:///LdsHfPABFz1vRD1OB6Yl/RS6&1Gmz/mfYul/
+ftp://E1cdf-p.XN--MGBERP4A5D4AR:60510/qMaw4kSSgYM/7jgIuL/gSVW6O91/2bhnsj/kl7R5sgn6&X5EiZdZ0WhTX3T/fa%f3Azz
+z3ymb.KM/DdnrqoBz=YtxSB
+FTP://7kgip3z.XN--KPRY57D:15983/OYEQzIA0
+nezt6awdc.lSZDSU14B1OH.4n6nkmjyyj.cc
+ftp://085.062.055.011/bopfVV/
+ftp://Mbbn8n.6ge03fiivyc7of.PS/mvb/X8VNt/5WrMZpw/flC6Rs
+file:///vNLDR/Q7QXgZ/6ApHTc6bN4/yihY9ZGy%3BlK
+ftp://p2SJ4CE1KFC8CSRL2OY2ALA5TJOCN0FEM-W.biz:51412/
+078.085.085.242/kqKkywur6Kv4Qn/-CJv6i1Nxc/
+qow6.7RF9YUV12HR9CCFTWUTQRONLAM4PN82GI8E.GQ/oxUj%a6Ch2/bjjphp%34IJ/%65NQDGFab%14B%51M/QtBe
+file:///pQ%8CkB8ipZ%2cyZGMf/8USgpQ%54%48e/jCflvdl%3Ec
+165.195.223.067/Q3DEaK/58Z29OKkyF/fk9Vl/dKLw%7FR3Fzo1YsTPxmm/XiABg5j23J%1avyv
+f1442jv.3w4cg5hy.EE/8hsz%802pLxgSlD%edIt/ESbwLYo/tdn9mrEynmJF~
+[dfb9:d316:677E::2B7C]/gsORr%b7gc/?ehIX5=GTM0co5(Dmn91JN&8J=8W7wFuQfZk7sM#vYfk~Km
+[11b2::35.78.41.76]/vVfZvUimVO/K9hfOd/4gZUL=j%09PGr#o%23LnBOkk9
+https://oL2UQ.yLN-U053DA.bf/CfFIFwe/ZbgHFvLfbEYrStIS2h3r/pqd%14rY/aR5a8hx/aKWFJechP8DT/ypmeBjL7rcbUr
+https://[3790:ad57:0B63::e5f7:f6ac:164C]/Obax;zcD/Y%48%9a/Z2xcdar
+bl60k0jqkc9.oow84o1.BF/Xly5cTna/BzoQuHi3r8e/o5BDNrvT/=6HRdBjH/Mrp5%02/p%e9pT2Ae
+ftp://Bs3ceuxd8ii66gt.X8wwdpt.BB:27095/3BfkvfzcmTS/FTffh&S/gIWvJ5Kd/AlOQ%3EnO
+http://ch43n.51rkj.rze.mq/pJjrSAiuSv/3x/EK%59ReZM9w
+zQFC1SPO96J.Jy20d8.xn--3e0b707e:863/0OWpT4dpkMURAGe/nFg/LQBUr%3E/af7dO1
+ftp://Xctk9iigg.cat/u3cX1d/Sx6m3dql/d%46;type=d#0i%3cT1yMkZQ
+HTTPS://56aderic0knmip9lkqdqag14.uk:45885/lELiK:/vF%4C5Enwqy/P5NGJ2b/dD6sg1yMV
+ftp://vlt.3g45k63viz2.tcnm3.UA:60664/AJ9iqYk%c1/uKbohn2/K%D1kequ4z8rxFpJ
+Ftp://2gifamku.jqv10es.MX/yJ0rhtMYX/Y1Wq%F90RYO1F/NT0%aeAG3/r3Act1
+7WO6F.XN--45BRJ9C/1L%f9G0NEu/L2lD/mQGNS9UhgCEb
+ftp://mIMU.t4d24n4lyx39.zURN708MCNGK-TJ42GLLBQRJHVENGPO.bw:59930/KmBYQKHfcjNRe/rK3fUjg%0Ad/.zHeVoCaC5/w%A2%F7up9o7J0Eq/ySBVhB
+ftp://lv56pdepzu0b0fo-04qtxv5tt2jc0nsaukrhtz5-e3u1vcb517y3b135zl.e0r1hson.dk/3TVoqjp6%1FCFSkt/006VZfho/gxrWxgDawM3Uk
+Ftp://7n977.Niyt.2fgkzfhj.q7-DJ.Ow7a.it/5zfRi3PO8/1zfKT9%421tP/?SazEijJq%710COQKWeLE/TdUc%b2u/2AxBw9%4BUN6Zp4Z/KfUZd1MTdPv/L4m1tI3/WJvcK1
+FILE:///a7kRxh8/h43TYOY6J5%31B/ZfuF%9c3/
+[46C8:60FE:7ff2:79cd:69E1::221.191.034.036]/Q2MQ8mttjsMF/UqrKq0W%E6N1#YfB7A8CHYa
+https://hnk6fx.2uxg1e9o.pm/I=LKn%a2n4/J&RntX3mUxZ/B1Q.Ilpk3Icq%7fZ/ia:4DLuk8pvsD/mpED3egQJfH/O0es5zrzwWQIC%21K1
+ftp://133.195.101.060/U9x99/nrirgTvZnm/QLNzsm
+file:///RN%7EGq55Z%D1E/U0BQ1De/o8a@zHbAMS/GOA4KUcR/uaOR6C%f1Y/u5d7
+http://[f63f:096e:ee87:792d:CD31:A1B2:83FD:7322]/tnFLqVSRa5h1/%EDX1y4cxiv/GIo.OM0/M4lBr/xgHa=
+file:///Td=wh:cuTxKx/4B8%dc%616s&sE/snROY6GQc
+ftp://1fcu78n.COOP/eDRJd%82k8FEI/7fbDLiQncgOl
+http://obp6jiork.KP/pOedzk/Lo1uNQ796m/hjLXBOr%25AB1/
+file:///j3m%a5o5blRxq2/8aDBkHng/OR1ixi5h8kX/nCUz2aDz/
+file:///V1tX7rM/7zk
+file:///1qw4T%8BKBi3CKv/dxm6%7f8s78R/%83sF6J/K%33qfB
+ftp://tyt7r.u6ier1pxipif5.BW/vSq6akPyGUI/wVJ67VXTQeuKM/yB4zYqPh/0RuHq%58G/rBTgdr5F
+Ftp://4dx-s0az06e.Su7ir.SA:16277/HWkL7hR1SW/RzpkWipV/LCYQ6/gLpY%807L6/60H1z96%90xdQ/P9jx4DVu/oFa6c#gQo%57wv0vN
+FTP://o--B02WG9T7-BXW-RVAJCJN1IALU9EX65WSEXCRHM.Aeh-m.cat:34416/3q9yW%53m/FJ9&U84ik9&e/R.l/ji0sjWb%5edu12nbNSW5c/YMGfLcesN
+HTTP://lMxNbKW@tq1imryvi.P7g5o8np1.SK/um4Z2TESWBSrcN/fNehEdgh/sW%6fCP/b2fqBsG
+http://Lgwt071.sn/HPn4x/%46zCwYZzy/wzQVoL2sT%E3Yl?974Zu=X+JuSbGjrO&Xu3Fz%a8%19%5159f0r=afHdI3%F7FNrs&Mb0hjV7d=&I43eztc=1k:3+uSz+kdJP5c+bRkUBkF
+izojrse33.9WTVFAANL2Y.ly/i3ae/5%0Br%f5yL3/MsnfAk#T6,v%51Ev
+ftp://[8714:3F6E:aa8:c8fc:4F41:b8ee:44.74.99.35]/790Ug0mWq/7yBPb/pzh4dTX
+ftp://[ACC9::DD55:A45B:7a6b:177.179.158.116]/i1q3SzWTmO%09p%A3/FWDWq8u2Q/7
+Nw2m4j4.Br9kvjf-9.3wac-fh0uk.nysyu-emjwy.cat/PGDh:oW%5F/H34QSRwe
+6f9f3nny.mq/ai%cb2SZP/qfjOd2mpEH/LUZ.fxv/#3NaTgg
+ftp://R1x5yr2ij24e42wlojnp1i-b2bsacd01stfe5-10m0-3z6cwb3aflzrgoo.it:8665/oFbo12T%3Bng=x/%B2FcEUXPHAP/Ni0qL%0bPN4#yhp%5dO6
+http://[C794:4d71:ACD4:7AC2::30CE:B0E7]/T8igmbW%6C/DE1%1DyI457M#brpF
+HTTPS://rI7HAX2OS.bsajd56xb48.FO/fn9eA4%0A/G96ogw%69SGis/1V0hqVLN6zaQC1
+http://toncwiacr.0px.g7pud.MOBI/EdoW/qUMMnH
+file:///LkP1%5BcrQ/bnkvBi6F/Q3IRXB7Kt8mvDZ/ZKwDAp%a3/
+http://6DAK.8I6FGLS.t5YJHK9GCUVU4EB6NO513HBTWAU0XP5.GL/LDO%8CDB%82p9#
+file:///%46f%c5KRhPp/skp1X/OdoS-J1foeE/5H5RIWoip
+Http://180.036.254.028/VSiroQpjS
+d54n.Agqa6.7e4.JOBS
+https://5t33av.5u7.RU/SugrkGKg/FDf6cYm5QdHk%b3z
+file:///tGHsUEMaQS/VLn1%6Au#uGnrvY
+lm.27.jv4quihwsp.mw/mwCDm0cweP/A8wSZIQcZGV/uKBboAnqevGJEQT5d
+ftp://6g4.qe-s9txq3o8vvr5e.5YWZGPDM9Q.820d8wtribsgglbrnkafno126s8vflph9tfmt0mwew/qC0bInpp/fqxKQLzN/hAj/6PsngV;TYPE=I
+file:///aR3sSgC/GJu
+w26535-k.Ut2.MS/pQP1Rx/NUKUyRSr/21x/CcgOcN4U/Jzw%C6Ft/n5Mu9X
+ftp://75.22.51.21/wFDRPO/NLI1ZSecRAfFEAy/kZ4whP%C3A/
+ftp://1h3yyf3d8sffjx3rsf3k2y7c459c2gx/%2FfoFDEyWygHgKAuo/KhJZkBlC5r3%99/9I8SMy/25_&y0
+Ftp://215.239.176.156/tNfD%09mvdOM%28zx/fc3DTw2nf/#2kySKJ
+http://Vyt.4ferfwbkbm.owtk.me/LlUtIjj/BDovC/6vJ4Wbk/ihtBt4d%acVl/ywEBIdg%3dHb/
+ftp://Lq.es/%B1ZPdTZgB2mNFW/qre92rM
+file:///IZ47ESCtX%aatQab1/V553gjR?Me/#9%68qPw
+file:///Y?GG/BBqMPBJ/nsxX3qP/8P24WdqBxH
+ftp://7vl2w.jp/b%a5fBYyDR/ZN%62LG9aYpjSwn0yWg/nG97gndK%69XZ#fet%55XXZhslTNrq5T
+79wvzk3.24dyfkxg0f4z-hsqgqqzj2p9n59el0a.XN--FIQS8S/:8epfLrewivg%488s/2ORX8M3/B0KpeeB/2rbuCnnBF/4P6%1cU6fTGNj/o%3aZMIHdO
+Uow9.sF.GP/sF3FCFSbCRWGNJY%aaU/DVXA5nIOWmjc6S/FQXdiBw/Y7~cVmpypgft/vU1%D4z
+ftp://[fd77:4982:C37F:a0a1:7651:E09C:117.093.145.017]/2l91g/s%79lJmUiZ/%A5R2qsJ
+[62c0::]/d1lmSzoB/5OBVnzn/kOXW%D23
+Http://Ed095eimjy.rlb5698d.kp/_l5uoOO/aA494s?3nSxdIpE=y%79qu+2un1hGR&J%76=8&L%bed=uY5hO+s+IKk1S&Q=HHXEC+Gof86QIRHy&35QY5=
+FILE:///#F9Bgl
+jyia054.l814D9SNHRRA5RJCCW.kvxga.XN--3E0B707E/sBbx24%f2Tw2/Sd0Lul0Vg1bbIqW~/lveEw
+File:///KKfIe63z/BETB.T%C6sG/RcYgnOycg
+ftp://892f7.oel50j.32.9qj1p-g7lgw.MR:48021/XNKbk2PZQXSvOuGnOAnATDt3/XfHyJtvoC/PW7YrSgf#LmGWJgPw
+http://sisas.ua/4CU60ZLK4VgY8AR89
+FTP://7qf.hlj.TN/IXOeaf/t%c52Jxwy#YkcAy2
+Ftp://Gbu5t.HT/xad4fgjaN#GLpU3XQd6%7F(cHIz
+file:///A1omJiPzafgAm/addqzG%dc%62/Lw1mamTg
+http://89qw34ksf0qf6iq264of-1nya4ds7qvpixw8c951aw8wcm3.qxk7usa.N8j1frzfgnkbi9y2.XN--CLCHC0EA0B2G2A9GCD/Unwn3/%97gnj0/GQgJC~OFxsdE8ubC7/IWy450/8%7CQVgdI8/soi0BviZt/Zjs%10i5Xh?qi8t9=rBbPok,Si&*Xl=Q+fT&Hx4%D70=84+8W%18+sV2BU6xCDP%47M&Usbms=
+Z7tid0uh.eZMOI-M1.umlsyksuzovqdw6wozbd.BW/m%e684OhC/ErAhpGiG
+ftp://tw7d-6yu.im:2055/%66qbqzss/OmPGW;type=d
+FTP://zst.tn/QcUpaA/VKvJ2/JN6AKew/iXYIiHm7mfPFmD%21E5/yTQpoiqdbaaS1/LnzOX#VqsobH
+eta0q7.2r79g.AC:34736/%abp87fVdPCY/PvO8Uk4WoLF#A*HP1A
+https://w9zhko2rttzndzivll92.sbzum.UZ/bgy8l68/Ix72mHu/zlA4CI/IQjc%CD9%255FxJ8A/Dbb%4eTCRu
+[2582::]/Mhm%55MWThR4Ne5mZ/xniX3IdG/
+ftp://224.3.121.112/G1w1g%1DdRi/T6Eb_NegqJs
+ftp://tn.z-o3vn3n4.5wg7.gs/loxilPpcLnsI/topa0Ez/Na%70Dcde
+syt7m.TD/2dxrQQvBXC78/Z754hngiYcM/eM%3CaeYeXX/nmUwguwk97VGL/
+http://isqogte5i.c-3oixcmy.SY/jlPVRlTs4v/enCZWc3Sl1dJ7/M5GTSZx/Ga%cce%63cLzTJvBodJ
+bYIAYQ.9mlnx.OM/t1KK3u/iyQFS4EGHN3uKogL3WGG/6wn5Q5ndq8kHO%734cxgEc
+Http://wvfftjk.do/a0%644z/?ATzWOxO1k=%85ulHR
+http://fnoY09@bm8xcfjyfiremhz9.sr/E4Rrq2/vQjQKj9fwV6r51/mn3x8he7/W4xCQs%FBvrzb
+ftp://vxfr4g5ka.kn/TZSPrYGzv/KzuB%731GA
+file:///vjS%f1/ktgHPAL/=v0cZ/WTpVo1/i6XlMCkNI/kukAwc8/thWUblm/c4ICXp/f8AHkj%1C4d%9107v%44hN/
+Ftp://t4qxt.hd9ok.aUQ7GIMBGXP.IS/%7ey71ndfLh/m%4A5P%75153tpU0hY73KfO6o/E%7aAkUlK3hX3Fg
+FTP://gJ8MRF8UYWFW.iq/cdX7RYOqS/6E6XUh%fcdHS1%dcoDwHgpFId
+http://01s0hfwz.TL/C9uEC/K9uWhknP3AxHW/%c56I1zL5Rfdd/sLJeP/2QkQNP/QcW%8aA0A/
+Http://gRWSMJ90XZNPAPHL90FB.zfyopzk/hMq%1fD/A5jQ%efiH4Csr/HTFm14uSXf/jW50yvQ6Mb/EJrahj19Y9Y
+http://i0.XN--MGBAAM7A8H/Uy6czi/rrAt8esL4/iL2xLka/B3j&7Inmt7g34
+file:///aZcnMM/Hnr1PCn/wlTztS7SpL
+http://2lv8030.fimc0v081i/cyEUoud6w/gfAlE/iQP:8/dZCue4cKVM3bs/JU%d5ZUA1t
+ftp://kF0NLTJGD.HM:44827/Y6CgKRiW/4r7G/Db%bb=7xD/tE/t4ooQHdBsrw/ZvgcX/qTCarGQWa~MKW5nn8NF/dcy%1caO%b8/Di%947%2cB
+ftp://4ufofbu/pmLZX%f2wJcQO/B%e0b%64oLObaEx&C/QViF1ohg/Rffvf
+dYC57.CI/=G0dg
+185.224.223.157/h8BdA%FEv/KLK2f%86LS/gwA4rKKHLarf/b.EyE
+FTP://uhw3qgl0bvfp568.e5wkz1l.Dug75a1j.US/R%AE5DNL%C4vMl-TXG/BDSu8PXNYU42aY/MR-hx1/mC2:SJqsCN%d7#smDUT
+File:///q3iMCFXfge/Bh%cdvWuy1w%E7Er/Jmmf7DkqSG%35a/VUvFz#8%510SIu
+file:///G%E7R44SI/L0Xsc/c15wyz?8Bs4rN7
+FTP://eQ23LB4U9CX.vcrnx.2fa.k6rjf8b.pe/8L163hbbt/J%26zcQf/lkieT5x/Efa/A2gUk/o%ef9PIBhPODaAn/p8%55Wsfap/BdTfZ4zm%2fbQt/SY7rMh
+file:///7RVk/qIRRZ0b/
+FILE:///Rq_/ec93s/HMB24%8esN/%4bO%cayWnOF
+File://Yk7ie7.xn--80akhbyknj4f/y4e4%2a0yHu
+ftp://4ps9b29prywnt6-1xt9t4cgi8sbwjj6obbw1x-2y-v2tft1eei67i.Hk0u4zwmd7o9z.jp/o4R1sdAnw/Hu408%CB/HdQ6cFhG
+ftp://7efqt.LB/EIX~:Q24/b0QhE%751s%F66R7A/IFxxOD2v/uOOPv5jARBJsf
+[A645:D622:eb6b:D59B::D48D:f334]/Ulld404y/IM~6P3
+FILE:///%16b72yhVw/2BPPCZg/KwHAJ0X3QT/I49wMwmls2j%15xkYc6qFZ
+FTP://octvv.2je8.oJRUDE.02y4htgs.es/zwVuzXoFKJ0k9
+http://[3A16::]/1rhxoXw9Cv/eWk5gHpYJ/v9gRo/un2Ygo91B%A1f2p/15hJ%A5o%A19TLjzzRrGUT
+iG4PTCCG.3zti905z3.ci/42j5.oKj/FZmOBY
+Http://pclly.36XVKSPBC/Nja5D
+148.020.113.014/ASuvNkg/Zcwt4/PjpwkEUVHbjkeKOgL/%f9hibk/NT9kSmJF%1A/5FaP@BkLf/jTre%balt
+tnjbgbiparss2x-xav2mitawqn9ema07kfk6kjck.xC1U6J.hm/scUu%E5D/qZ9K%1CX.d3mWJb/-SdvwN/nFS0ZdZDNQA
+http://[3173::]/YHDIJlMkv/oFpVHGs/7Dn%61pqA%23/ZnaIIPD%6cj/
+http://i4f8l.sc/WuJNKVuflVGa8/%85hi4B1G/mPs/1KfX%12/WswWA%B3i1OVsF/Z;wC5kkDQ/XIOtrdBl%D9%33
+https://v24gyfj.xfrc5dy6xuz3paev4rggl3xeg3vxzw7cz98pbcgum8xlczt-n.SU/Mb=PxgWX/J04ScMxk8u/oH%A08nv/3oXR85tM/
+Ftp://c82a3i5u.tf/v%D5/%05QNNYI&ssnoF.
+file:///MaIzEiaVY/ssIPwkItF%EBIUy
+Ukg.sb/Q24uLBUl
+HTTP://Aphi-iog2t.PE/SSwgnY7af/VabUxcEU2i/JI%434fkP%7cO#EWmOFU%5cy
+file:///FXYZhobB0jX%5BD7PIt8H8u
+Http://asn7b.LA/13Qp3t0dY/Mk0ldhZyJP/rRgIZlOu/hqt1qM9NT5tAGD07T
+Http://mb2.NI/eOXXAC0MNiEvJ/ul6ydqIPg/3JhlWx21r~sH/ZemaBb7j17X
+ftp://7i27:54542/B3rW/LSNLFJ%74J/%e4NHDP1svTU/Kkpr%C1%6cO/2wWp%f4MiYLhgWGSF/u0wNwK0B
+ftp://f8X.cat/L7Gj-OSdF/QBrO%f3okEZ/L%bdvAyxC5
+ftp://[6CA9:93a1::]/?y057O5/l9C:/XsBy2so5tX=D%71me/
+file:///%33P.AyK6nB/QkN%011K/iicc3HEIE%C0/v_7Wl%fdzMCBnfC
+HTTPS://zv21qs.ekofwyy.f1pd7snnae0n2nzfdclk1sf4hybx97u17piaj5-lul89bxrf775koowj.as/BAc33xOV7
+ftp://ko%5BM@183.207.071.131/tq~2QxL/d%D397GnaQgKtPMOsCp7fyVobgZ/Nhnp4LAKEvQ1V/1xFn%cbR%7BVU3
+https://fiuubt.bc-yrorta.kdn.M8mascygepb0csr.vpifk.G-p35wx.er/4wvko7/Wo9PsbrLI
+file:///LRVqPEfRevRI/nHtsA5k4iilQ/22vu%674y
+http://jX-U69Z4.3vuws.41h3q22bzs.o3hng9:6629/Qj=CQmh9/%9aCSTfa%0aXvFQ/u0zAICPSGUx/MqP32INW%00mp?ZmIZc=5o1okD&WEDMM6Qnm=0w5T&gajnp=GFwK+Ct8Pds+KRsnyPq+2UFmx+cwnDnvyn+Zf0VFXyk2+Aw67fL
+file:///XRDAcY5GGmj3/WoHYehPpF7/HS9LhdHOe%9fS#!SZge2
+file:///UIIGOxv6jvF2%c0/%A8J3%677Gmq8im1zklKhqx/HMhCSY2QcyxvL/
+http://Qhk9z.zm/cOGBen/mBsDycEI5V7L1s%84WUj7863/p%5f~okuRD51b0M?b%F2d%67ujGr=oh8PWUtK&j6uX7baX=&sg3RUocA9W=m5IaF&JWH9G=fyiOtnC3+7RJA+ippw96rvu+BxtGg&F6f1=jmPS&3PE0xX5=TGV%5c5J&%fc@NSEynhuvb=&MkRIt33=
+Http://[98cc:433d:2C25:62dd:54ba:d10b:63d3:4C40]/YlbNrJod/fdjuN/qYqSdqr5/KAbXYHO%F0m7Ws9
+file:///ywFY5HK/XAv@v%66o/M2O4Wlny50hypf5%02A8
+https://nWC9-RIA00RPVL4SSWRICWWX3NH5SMQIA7IPMCK174T30VQBL-M6.XN--3E0B707E/CwE%e2rWaYZmE?X_coOVl=kqGQ&Pli=MjKg-+wO6Eh+lbbcN&x3M=3kQh99m92mRdf&iiO2wXgQ=qyWVG9G
+file:///enqvF%EFLOBsZhl8h2z
+ftp://133.4.130.192/p%b1LgcONfo%bc&kmH/Ibh6Lq%DCJhnswT%1A
+ftp://1xf.ipl4f0y6c4.VA/LHuq~/p2nPbE/0YGGNJB%DEje2psef_B/aKOuMl1Q9
+ftp://o6ou6n.N8.yyld.JM:24207/aS15Vk%0eg/M8jcXu%14d/%48odaw
+file:///7NToG6xM&SK=k8/wTdaPAFLzqBEJ/zHMDPj/L.fLv57c/z8QYrsKS/CEkA5FEhQXBQi
+file:///UWrC%9111nEhh/45FHiTx%98L
+http://35.iN13LEQV.z2d.in/%B2GBtdYtQjc4TTr/gLxjU%B3c?3m8B3t%24eK9%b8=kgc0f+ew+uux%7dOI+pbZ+H%9cS&%56mm6=rkQm+dHPh3gGj+1kC
+http://nEN5ZN.EG/%0efsf4v30L
+file:///19%9947/ksd3Sq7W78%27/2K_Ylzcu2q
+r8sht9qzsc1e2wp.ci/8SbPwlW%5ac/qKEqFi0Q
+ftp://zxmv98m49669kfvf24o12w3u93wbovfp-1smo6y90e27n133okplcjqrmv-a.CD/JM5RAAY/sJdBntYWuEY4uB7hz/ozRSmFJD/#Xv22:Xvg
+6S8.Crwllo5e3.jmtz.XN--GECRJ9C/6InlQn/hnhu2f%ac8tX/apq%0D6o/
+file:///gVW/nnRNxPfMXKb%72Aq%4A
+file:///Fzza388TQ
+file:///
+File:///kpiE4WSatjDV/phvv7gyfb%78b
+ftp://240.154.225.198/I%39uutdECwM/PViD~qPa
+td.KM/0Dkyg/B%65DiABz/wtqGd/i7%cepV%86XkA
+077.102.005.039/p53%0bsPeiZaRy/nQHLsKEbNdaX/nT9H%521/Zb7H
+https://Pu5aweu-29knkj3k41tw25h7xzm9pck96ey4q0gqzig27u.vLPR1Q4.vg/QANLMxa/gccQ1ekkRDr/?bXRDWO=I%0ap7%f4PB8S&t%a0Uhe1I$j$=Mm
+https://J-5ytf.nmp5zuopbj1qbl1ik2c4ihjwu6-q5dhn.ng/GDtBeBZixtl/6sgw9/tmeJ7k3I1hHJfM/2JYRt7towpNjvDWsumYmhu/nBVPkzSo/cBXPb
+http://HSZDX$An@ukj35.ve/9dLg7XrzV8g/hXhzX;2/Zw3KKwTP1um2/qej3miaDjj8v
+http://sL333Q.Zci48xtb4g6.lu/sQw4ZHF/M%99%1DNl/s58%a2sCxGQ?EgPNZ=qaG'U2CO
+file:///W%64hVsq1u9rIuZy/qO8j6EEwj/d48q1%6D/ko0ec%72/pcJo/MZQohRx
+Ftp://afq57indwrb0sjhgyczyx.se/%6FKey7AOE/IPWZg3ggMIM6%D48h/XnAuzG
+file:///wDwlQVR8i:0/mzefF/D3Pnkoza7Zo5iQdc/ckieGQos4JM#9rqA%DAD4
+9gcwbh3vcmfa0xw-k2.MC/66TaJz%FE/SnDRWAknGcI
+Ftp://%cdaTNzNPNu@w6H.V9aps/87/w@rPBGa/he%FBu4vpT
+le1u.43cdu0n4.bn/Q0i6uNz/9%275%a3dAS/B%2fpPkCW
+ftp://131.173.229.062/1IYcY/mJJ894/%89F%45HHRdA/eGlhL2MXm6Q/heBdvWm%3cVs%04/x3JjEB#2%2cQsgeK
+rtubvdk3.PF/L4TR1g%5f6/Caov%FC3vK3ofrH/pz33aV%54
+urlyuqr.ar/tzJzKM/gutrfWqv/IC%24bbmSS%02P?%24JV=zrJilQ+tH%7bh&hbO7Puq8c=K1Qt&ULqdYq=
+Https://pFOROCZ9.dRDP.gq/08VkBBPja8cCXZKLa/rEF28NoX/
+https://[5319:CAA9:0242:86EA:8e36:7086:B3E2:ded6]/Jq%C0P@jZ/KoNj84B5AJ=3jGk/7wdasVgHFexe4M/zgEZvK3vh
+ftp://Bvc6nmpdhn21400.Vo53pvqm0/u7jz0O3bbFTTegZa
+l0q.0b82ck3a.SI/EQf%a6#mhJ%0dfWnfM
+http://hr58b8n.bL0/LppkKdZGYdxiHg/2VXeZWR/T4fCmyN579
+http://1x6.yc6g6uw6htmwcrb10t4kwc393g29cctmtdxxz1j.KZ/G9lcwKju/UiH4E
+7T6OSH.PF/zfYyqdxITCI0
+https://2diizsrbfh.PK/t1zBYiDPZG8Kx:/pEN4b8xKu
+HTTP://r53fl98bazbqhc19-h-r.qif.AW/8sH0%59j%FF7/QPnw69%17Og9V9l/JAn2c7i/%7Fta3x/P%08HRF/
+qvpqmoa.O-0.FI/TDl%E6x1oUoACe/4VUZdMKL8Axud/JEZEF/KOR7Q7?ifYXMx@=&iI'!tR=p&k2Tv=Behew+RFW2c+w8NOK7+?BGH&:TYW.6(=H%B0Jvo9LvAy61V+YjewIUBKHe+lT543+BIss6Rz%25KTjd7+fOp-r+/PvG%fbP9kd4K02Z+IUXHyh&Lb1kab=FDdwA3_Z%81e&iiG=CVrO+1AhtbU1JSvh+Q;ay+Jb8c+%c1L%D4&m?r%0en=8S$wF&5JOA9WI=&kGJ=WjzqGX&Bew@sXE=cl4a+2S8
+http://jykpqk6.sc/VBPT/xNRs7JVoZKE/
+FTP://2w-y60heg64rnrmpyv43tpfhftxolu-5u.lG0BKW.LY/g%7aPAj5j/qxyE/D79g5vu/
+http://Unp.IR/tN;/bCXe/fxSdK%00%CFB5N/D0L1/bjf
+[cf65:1F97:24b8:652a:FB12:D0F7:181.134.252.162]/1jXwBjjxpC/0zKR6N%0bhawVF
+ftp://090.247.102.174/YZgWR%A1NP/f6YUa8dEOoOk/a7%59Geq
+https://Zn.RE:31587/Vam%acYZniEPiY/lBfiLn%F1/dlHe@m0#
+FILE:///FojXlCuj/OQXGX/JUHCBAF/TUAe8k7O/fnh8rautFH/e6%C2xGbsfELFVW%df/JKQk/gEO%589e7uMuM/SM%7dz%0chqvt%67/dc4fnbs%F3%5e/4rLtAbS
+http://247e/qBmVNrd4AstGuk/JkV%50CBmmp%06/%a5E%34TAY%E7/5WL:W%CB%193Dr=cl9rn&/mA9%651nvah%63hV
+qkwlh9jp618.k-x.de/xiraBM/6zj@AcW3NA/%CBeI4RpP5nz/FiWXIm/fy6YJd/n%006lFEE/uT7%284Q;fXK/a52ToS/w6jn4ZU4r8/:B~XHaw?G.cE=osg8k3&iGJ=V4&w1vL=me4QRwj&YFgq=%22zCDTqgmKC
+fjrb5z774.SA/PVZsWyA3sMJrb14P%995vIm6/dC5=Hj7?cxCp=bZ(40%15pi
+ftp://pd5mz0sw.53t.sent7dh.ki/U%57Qz9g?6/6TOmiq%6F/
+Http://g3t2w4.2AB0B.3eq7q.RE/fvvJYyHjd/%34FK%98WeZ/G5Ux06F2BDF/
+http://7Z0-0PC.txi2srk55gs1venx.uy
+https://i6.kzdyaq-v3.9j78y.oq5r.gpm7oh.x1fnc78-tli.5yu2f.3hfnkcvwoms.hWRAX7TAJ.7ei.tt/Ysy-/sRl/LZa6nw8
+Iq7sp.vLK69LN.lr/hjB0EW3t5%36/lSVsKT%3CWsL-%ADA1p%0ffG/M1S;SyAVBO/EvzIxfZpicuo/dOst%DE%E1w
+1lg7.sz/X@ENk92CPk/vVYJGN%act
+ugk7-paad2cswwq3kd82lp9r7-i93galijy4x4.vatv4ag.va/Eww6Y1XABn/pC3%9BzjH1q:sB%89Mu/WdjiQ32H/LEaekIokSv1%E61s/Y~wQYu9v8yDqSatHO8F
+http://Jmury.vc-wuwj.rn0o.ug/EhXMKL%64/CwKXyRnpk
+HTTP://V7c6lvas-wtxspcp53z7o-v9dt13mpp7gc9ezt.MG/q986Xs3Fzpo5/6tQRek0/zkdJt%605DYH2j0aVfgcn
+[0CFC::]/0611uPvtHJ
+file:///viHNVlfm/4BICnFqFz3mXP/1%0dxeFn%AC
+file:///ceic16R0Ht/b%AFXzo7oKlnID/v84LSyw/wBfvq3QVf/vuytS9wORE/tYsyN9i/msSNDC4Jt8/nPWzs35yu%ED/zvTeOit/uSVe?PyD
+FTP://8GJ0QK.rQ8H0BIQZVFQQHPAWF7EVV12.LU/dLOis5Hvn/YEA%C5Z68E%50hS/Ie1Sx/
+FTP://bGCO.apov3z1nrv.ke/cM4fSVF?%ff/tWLPVByl0/ABCz7EZc3/R2b7U8o9JM6p76
+file:///2%f5tf%F7dSLdlRwws/qnKbcUOCCP72RTJ/WTc=Xn%B88/
+FILE:///n4riCnF
+ftp://mQEGW184G.Hv3zhea6.ST/iW6mhdm/G9mpZUib4loe
+file:///
+https://A0ea6aeynb4z3fsvnh4wg6h7.9bicz2zg2-695lf1uql14i2sjf6pqh1sae2j3k8iptes.57/jzHSQ%ebP5/%e3%9Chd/#VqMzFZrd%ddpe
+6wmlp3ipb.cqi.ikf9wdku.arpa/dMq4GciIqW/aL%10jc%d5d%c4v
+file:///lT?KC#nXl!iMB3hl
+FTP://P9yyxqsh1rz2q-r7gp.h0W9VBZWGP.tk/gvbKQnzs/q1Gb
+file:///7KTju7/x2t7Qen83hFitH
+iawuqq99.AX/;aTO9WOuOPwl/UAbRoxCcv4
+http://h-juvh.3gtf/spUbB%2aq/#%9C2/LWN&
+vj021lv-xpcrzcaibfgk0.ad/dVYoNrxc5/NVH90Y7CCv%4E/vITM8z%C4?P9Y6IZlhse=7w1CwndaDA%79PY+r4Wm+esuV
+http://%d3fV6o@knpyxaoxorjk0xthy4c56-idtz3.i91eof5.mt/MM0jI8/mviceY%E9KnCQrwqA/xTTC@R/bgzg%6CfrsDT/uN8jUqZIRPdu9a27A/aNc%f4l1h9UUax#t4W~aw
+qc6iz4vjp42.9IZ.l87y.4m79dnm6i.tqhva6e.dumzoy.GG/aNgCtk310/ltjBeHJh5uJx/XMIgU=CSzwD3D/
+http://p7E5E0.hhvqt56.ug/2p6%2Cb~bL/JIlK:TS/KKKGy
+file:///3%aexrb7UdZ5GpR4ZIfoxwL/vQV%4a2zQxki/QRji6gHpMGgBaM/d%71A2CTpZv-kF0tD/Ig6roS8m4/~aA64OxN2yNDZ/fLLcgp%d0/He%98%b6JWoLAm/_aKE52/bcn8%06hs~If/IV9oQt%A1K
+f5ms.jp/%A1FpERWwTd%BFG/ExC8V5aqx5l2CLJr0mJb5u/DgMvEzAr2U/py9Vg/igr9PzANtw/FFiN1E7
+https://227.086.128.010:64985/MDKuFInA86qto5/_cK=4S%49Ic/SPp76/TlV%0Arlwfx/
+Ftp://171.160.94.43/ALTgS46I4VM/55PbbK/5N%faTSE
+Ftp://3zd7z.etw.XN--KPRW13D/4UztCuTbW2z/LL%2cDI/dTYSi9
+t6xfr.wxjz5p2t5.zl8m4.MN/2cbpjk/gsdm/5Mvc-j3rc/16Wb65&c7x
+ftp://D02-auxxaeqnv9ve-jlmo3.l10vqu.12jl.2mvjwrsqm.BA/r71QLLNu6oGJjG/HbxrX1Grq8/QR%2agZv4hR
+file:///XoCg%EDVf/A3ibJYjU
+i44X.a8H-WP.zgmnrjxq.NE/oL42aLwl/h1unIUx2m5mhir/ZjNqL;n
+file:///KSPSz0d%734OBRur/v2feKz%7aC/SfV1syp
+http://29SB.j6/ojVDhx/%A7e34T8%01L%41BNV?6uRxM%DFd=qg9jmHtW5R&EeR=%f9,mnV.cGVNclEM54f+efsLBpEc+3V7mIJi+Dng2-Qk9&t=VWC!+5gUmI&c4c0sX%51=%03?a3mDKm+4rHPsfb%dc
+96.79.198.95/8JJUovS/
+file:///.LxM7EsLzp%d2/sOKzUh/IVX5Mw-PVormR
+5r.uL9CQEBDLX.bn/?3z283zb=k&q%d8u%aeOKQs=s2Ixcyjmlg&%52=Fc68M+%F9JLUS+4XTt7ypy%881+knwx%3CF+CUc1ZNLx)K8Ht&Bks=*woVYK?GE&vv=P+b+W%134Flc6+%2e2w5%cfPu%5BXUS+PAAvb+@e/E
+http://ol7ctcj1x.Ugk.na/jnDQG9WhW/r1cIpcqfGNMDWto0/DfPQlP
+ftp://ico390kww0.it/g&kOEETBwQ0Xnfaz/pSA4oQJ/nU1WwWgH/u9TK%34Z/x5hXHtQAb
+HTTP://iEYF-043APHCKLC7PX.qB28RKI5NNRTNJJ41MVKDI53GHXIMLM.BV/QBykbXcYpFg/zgpKZ/pVe2L5cYl0X1%37bmI2D/NIdWj_%EC6VE56mu%64M1sh%bfvNe/
+ftp://vb5vs.P5f5jmxq.sn:10748/gx%54N7WDo@FP%a9/aFd0z2V/6OCUikUdhs/F89CFSH6XHi9Pgt/CzM6Y3s0UZ/u8xukwK;type=d
+File:///B5dOvjHOOe/oUJYD5/zgi4jw%54XPx=S4NV8R21Bo3u%d5/Mbd0rcFk/%5cPig5
+FTP://ebibm0spm7.cat/aalird/1v6GldpVgXA/9akBrbVRE/FbH97%67/YfhOfgG/gPiGQb%D6?AodiI#nTfAhiF1
+http://[9396:d59e:191::f7aa]/isqQk3jC/js7gnxrTJLFX/
+HTTP://k5ifny.sa:32595/8XvVVW6Tp37x/IF0IkevEa9jqkw/58g3p/MZB%94sVPjmF7/wZD0BUp?N6P1o=nH:%5840TZNN%37eJ+AJXoM5t7+UhR&%3FCC(O96dC=e2Zqj-YxOMwv
+2hr.p5v.6aqidmeffi.flfqfx2znf.cup605.v6ktei.mi6.AQ/ky~LSgBJ/3JZhLix/blFeDQRn
+gtf7abvdn9i7cr2e.YE/-1vj3Mw/P%CEXiCFd2a9/vm
+http://3rsqw6jt.cv/n5e9YJBevO5c%6e4rW%a8/iKy-raSDu/.j6BTI6/CZR%f7I=Qmfr%dd/#xTHGb9RTWP%c9H31p3
+file:///S0Vmb2/JccbhGwccE=w/sgSbbJh/2OjHXikwMAVk/V1l0~FYdw
+file:///5fXz1pJg/G%A6MIr2J/6gwHl%1C%55Xx/xHPZg7hEg5BzqAVzK.gM65L
+File:///SxZ0jN1/C7FaB/Q63Jxn/QGzG%CEcYzLq7sWLWF/tD%3c1aukYV
+file:///T8krlfICzWYr%e6/xGDI6sWJ/jCXF%87zmV6
+ftp://csanc.mz:27249/Q4ci9eH/uQLFb8ZVrjYbaCS8/sNzv%8DY1Xapc
+file:///P7Ub83hzju
+HTTP://q6-aoovoq.j-joev5ivayrom1t474xlqxrfro.xn--wgbh1c/WiS76Kh&O/IDDo916%22Vp4/iZYdp?%66lk%24ke=&OGXRBNTxne-Rc1i9b1=b2DcK&Lyuxv=&%5bF=
+file:///
+2cc16zv4u31wx-edyjiy.cz/voFy:f8~/9kCAM1/1i8r969t&%53/V;exvHAKlZm5g/J85xEKDBR4yY/@%8dUYyVS%4e%3B%B2m/W5AXsrDE0i/#ivl39=VdW
+https://73ll5al.MO:10068/5K%AAf0p/#5deD$x1
+FILE:///a0esBQEE/
+qnta8.f9284.5pvu.af/tHEFme/OOQl%E9GOt/xuKnPxLGVEf%D8#LfL
+File:///Vg9klGYqV%f0f9p
+[1112:D95A::f9fa:5258:6AD4:3c08]/tAHstaKl7bvDJ/Hm3zObt/qSQiJ1FD/ff6EP/YLR%71gk/Qm%98XlJqp/B5%31GicO
+http://[f34d:a4fc:b932::631B:2C2E]/F8CJ0o2L5/hNITi9
+http://fp8bh.zm/R5WFY9BBHOmi3/OyhE6XN/7tZGprtgW#hrKj
+mAIE.mXK.qq.3WVWRXC8BASM2NX8GRC-L7O.nz/l%E8SjQ/D8iYe/2Qi&C3RMJppB%88b
+https://smj0v/Z8B/%96%A4mzAT/eixQJ/v%D3HDtup
+ftp://J-b0a7i1grxbx.gt/MuPMg3Ly/r2iyJo4R4opO1Xj%C6
+vbhx1cl9dgl-asht.lDN0ESMI.RO/A474Sw/mcZtSSvta/ZvpyTJ/OFCSmNJ
+file:///pedpH/COpc9b/gtm%d0EBmRz
+[B91A:258f:095f:5755:86C9:7989:2DC3:B052]/%ecPvKuwpKpSQ9ANsta/%ac=jmcQsb48Rfo/bWIMfqk/dUQF5ms%d7/6Em91E&z78/uGC9e%53/Cleb%23zyGMVzOe/Rg4teS
+Http://[725A:9A3E:2F98::9109:5272]/ijhUpBG-1FS%73%D3
+gmamwxo2.0z8rwjft28enmc.p-5uyn.u6E6AXVBP.ph/gBkpM4WFysjoV/X591ak/tIRMD.t5y766HT%5EX/RSb0a/Nw
+https://mxfwd.gg/uwsX4/vnVUhsd/igwlpT%bahLI4;P0
+https://9g5pjef-db.Mq0tfjbmqomp84hi.rf97xmi3834.403gi.TC/sLVqu3UG4/OYh%98SQXVXf7Cp/j%deBNpZoEfAD60RV?wv%90PcN9VQR4g1=H9Q5pv&4C=aZ%a7l&B5hpDGtJ5E=%85NY
+Zg2x0pwfg3xo38fwn-5rriv520uccxjuyrxov9cig.fcr1xxh8.cat/hQOVnH-6u03Wc/pqtgVxVOnlza/6I7b3Cv/8L%20%820/2GVQbVTA/FoUjDrsNT
+file:///aQa%A8K1SpUF3R/DRHzEQarZC/WpL%4a~dPnH
+FILE:///7TVlhAH/kRBTpgn2/HbYFSHYnrazY5Pq
+FILE:///wC97%71cxvYq/%16?cNGP/
+file:///u%7BQA%909Et%edmf6X/J%44H591v4iAHpgc/qeuedAPm7Moi/dE5xiL8W/%52DLIO%B1vY4h/A%1DIi3
+Ftp://3ZBZ/YmeJ68Qq/%E8%74X5e%18/QNyU/
+https://R@lyd1.xtccruqswon.GR/oHPO%79jfl1/rFfct/TI4I5pfjn
+file://Rcpx7se8pzp4sj8ooxrlfyi.cpj--z.tl/ZQtA5b0%8F%665G/RTr%2BytU/4C.hmyu8/F1hcJ/PiHi4c%16VEN/66dIi
+ftp://wDIXDXTT.vg/eCSU%14/7My9QiLZjNwKRh1/pd16vIBrmG/sXqjHnSFyE%03HA65WCMRaJGunYbT
+http://[fcf7:4e45:3CD7:4B2B::]/ZbLeVZi/mjJ6/LMTBU/V4%e0nMMUsY#'aLkxlcFi5
+ftp://k2.jALPBG.XN--MGBERP4A5D4AR/NyVb%E0rdacdy/KQxWB%0DFc/Ruh62/qApiRp%fcc7NqG5P/FQd6Yw8Hi
+ftp://sjfzvidjcj.ae:55965/r7feW9uA/33qU0/BKlBWEwBw/w3nSd
+ftp://2k5.lfssxj9iatcd3056j-rq0/Bq8-ZY8byN/Skg1r%290%40%23/X51QAJ7U/H7Ir4nHaQ8?QOW
+http://ip0176.JM/LthE/E04n2pcGJV?P8=dCpb%e3q
+ftp://072.017.130.122:58513/6P9dqEIAxnvathxK/GHoR0X%5F%8fU/%ffANo7hT%dcKY%dc%B3%75pXy
+[3157:621E::]/CmIefnv.v91v/I%E6OmZLafDS/a7JoSqx80BC9/iSPk18UXH/g6xdyYNSlT8/o34wEX?MLP%993E=%1Fao&nRDo=6svN8+d%4Bq%30jky%75psOKb+h
+FTP://zbtd.0doxocs/sDrr5d5i/%6cJnyS/5K8mb;TYPE=D
+http://1vkic.cmd-efq.st/%937ikPpb/eZh_3dIzXbtNFVxL9nQ1/7bVwDiamdDs;8zgSZ
+file:///YTllDP/IhzDW/%00H9e1IWG4%42%93bP/UCdd~o
+ftp://ksd4b3w04c5nk5aasoepqdby-9w.sl/pNe8wJ2LkrJZ/XJSanvU/
+http://oPYQ.nd-egq1mkgtuwt4ei1ax.GQ/JRpv
+ftp://171.235.253.31/gop3Q%bcUoW1/38aPN?
+File:///XoULHUnTn/zYp/#SlAGu
+0kx1j6uf.QA/lhgydNvB/jU%B4oWUd%842;n/zo%63SywbGAgc/c2LB/wV8n/
+FILE:///kcboy@/9goeE7Q
+tD6HUNLHK3.u-06.FR/WwW%7f/1HS0pUTG
+Http://c82m23a-5oprsol87jurs142tzex3957m9nrufva0sc6gdo3pajic8po.H5m3wt.1RU:11878/Odij%A65n/Am~mzHC/#ArdWk8
+Http://cd1.es/w~Uc%455aE_/wVJKfr0/X3vnA/ImG6Z
+http://5ect9i8665yca.FJ/ylKD5bCODpHQ/lbunoK/%98004LI_w/HwTFV/4@O9_DiwGb0Ig9#B8z%90jjivO
+file:///IDE/mEZee3/1B5W9drK
+http://wka3.GM/%95yhyVy9#FFld%0CZGoiP
+file:///nAL4tAgn/UK?mpt4IE/.2JW4Ej%28uiG/LulMqnbE5
+ftp://973k1fnytm6y9hx87p42k.1whc75.PS:59063/nxryc0E/ooGHQtw3ik5/6fU4vZmZNZ10If#iFXkFxd
+File:///YTIL%AADxyn/exqQCc/HrBwtj3/DIOgKT4YUu
+http://3ucol3f.lr77xtr.LK/FNsRpDDW=/76bEzBTI/q30mQZ/
+9sb.7mct69t.ar/WpXcM8498S4F#k@L:'L
+ftp://3qn.XN--P1AI/PdBsWGhCy/QSZ%06xb6atX%7eXtqSy
+file:///t%48r6pvw/gTme80:slEt/ciBvu19
+File:///8rjryYe
+https://[887d:5086:CAA6::DA5B:192.032.127.177]/
+File:///v%2CCgt3%32kh5ZJx/~kf8WDLeR3XmmY6ap/.DEZNJ-ylM
+file:///KNINXVO67tBU/VWJdbMVH%a7uqRO9%ad/55Wlt5O41e?/YGhF4Fm
+file:///zYYquoqz/%240zKPi/@k9J&epm2dka
+7JUE8WA7CLBX6ETD8KUU16AFZHHS234NORX.tep69aqao2.int/iZjrUNXtQfBaF/Z%A87tU/XfvTnCVEY%00/FUyeI05%f4#?hZ
+file:///1?Msuc%BD1/G1%33Ppp/F2Sv%0EJIBnPzEUu32/81nqxxTk1HPO/7pyYlewH7gyw
+HTTPS://hdtgt38onqh18-617otg7tn-ut6f49po3gaajt47.m4O26.rwko060q21o.Am497x0kow-u.TN/nZX955o/JtBhKlvv3r
+ftp://28.118.125.16/3j69z80kruR/TXIM6gQFdZTCI/T52CULszlqMQ#%C3OT__%57
+ftp://y8K1P5I8E/c2Xa7CmI%d6TWC
+225.022.162.113/ZF58s/%CE%56BA5rQPOLU/AUNP8rG/w8SHG%d0FVsZX8dC
+X6eygmy.1a-mtt.ki/WC9%a6/GH9mNozOi
+94h6rdisa-eh.CH:8242/I8Ik5%42881r/EsVYPHYT/Jw7%3A2%2778ggZ8u%60
+Http://89.pa/%65ssgG1L:fKtE/PrmY6WoXW/oYH2AfHjf/uVaFyqn%ee0o%4fAh3
+file:///KwM8U1%EBR6J/K.asJbs0/i1vCxd/ZthOZxt0IKQEH/#x:Q8vtaIw
+http://rP6.Ewrowee5k83.COM/5CId/KVp%FE
+ftp://l8AAQ4XL0X0HO6MF7.9d.tw/%98Vb%117Uy4/KyUMl9
+Q293qtnuw.vi/6fi1J47ebQ/d2EC4A5OM%FF9_tUNs/dk=?YyGXS=&El=i&Go%cb=fb8&7W95=Cg49VW7B+B3dDs+f'fhi2+6QLTS%bbuJ+IN8+1PE7QyfjCX7tY%7D+cGm4+JkozC,0y+SEO%ac&V1pkpm0GF=0%46pvcEyU2G+2%F5kBuG
+2pu1.mv/3uiG%445F~s/%5CTa0YXuNMsqV/AwE3d
+file:///jIjyqNR/CBgOXsf%8fYiqCR/
+Voiuuc65jm4ven-9li9.mii5.0h5xt6.KE/qachnQB/nsC%4ai/juYvC3yTiCp%06S8I/LLVvQY#p1jmTyx@W
+Ftp://ydhhq20m.MY/%ADNIfcLl66t1fl/v4%a60h/N6My%9AKXUvToMFxY/
+14.21M1I.NU/iqlGVazIWPCvV/oelkORYd3Iwsdy%0D/LcdN7U
+file:///
+https://07zje.j84g-9lx-673h.vwr.km/h2Dv%1BFR%9d/NV05FON%c9/klLPUVUcp/LRlEGREG3H
+[836e:5fb9:0cda::D9A5]/n2j/Kjy0BzJ7Cj/GoW1ksyHG%B5A8tw;v/hIg4F;R%2Ax8nL/d1aHG5Vsb/VNMIiMx
+[E69:a743:5C18:C43F:780d:FDD0:EBC8:2ce9]/uAWRrcx
+ftp://B3fvr.l5GW6REKV.GI/0qT%dbwWVXZ/3kdb0/kBQuFu/R@9WXH0
+Ftp://a4gdplaw.TP/zyf2c37ZfY/QaiwZ3l/CUi9.ado/
+8L.vg/LjRJZ/z7/Fkg9dwmTDSp
+T7wos.u6I.cJP-5HQQCA.9dutej.SG/6McEZ0
+jJ0D1X6C5CCNWYGOCI4NNFC5A5NYJZTCW65DHS.d1yxpq.TC/EQ%DBYuIdBv
+File:///YGxWV18/%B2bnYvE/COmzr%B0YLEB8/%75L%c5ym2Hw
+HTTP://nzhfr.Mlrs1k026k.KN/~bhI#qqgVS5YR
+https://z9z6ip.INT/1%1dXkN1P/KI52I/yo%FD13SoZz0?:z'X3xwoS=1y&lmDOOEVzwHn2j=xfbMj%67cy#bKedfyI1
+FTP://aysc5.8i8kj7.cu/Ule%55%F0l/HV%7FNXdQfhjf0/
+file:///UZg7IFvJd/U%6cAH%59cS/dQjA9gM3RIJ/cW7Kuo/lBGa1%B3Hjf2aN&/
+file:///TPkfDWADgMp/9cr6zwO%38cZPtrql/w3GqL/nrvKR6Kq91#s5F4qQMjYx9
+http://1co-4k.zzzqb.XN--KGBECHTV/WRGpnKFny/eBiU%BDapp/0cb5bJ5%24J8a#N*cE%e4BmH3Jse?2
+n7q2q9b.3-ve593.eb368oe.si/xsA7jCLE%5CRj/gEfwCC/W21RJFHtG7td/fSZIiv/6mJkJcnid/xFjV%DF8pXhf:H/vh4Z3%efgdOJkeT6sTC/wUOxqbX
+ftp://[7D66::]/m:wnkiFBKJR/7c8a3te/mQqS6ZDWbfTXtZ9
+FILE:///%41PSndZFnAZNuF35izYcj9Jmt/aoJ8K6/nGtfymyBi/
+008.245.185.106/0Aq3gb85/6TZk7/PVTk%b1G80
+ftp://90.188.10.180/fgsPUVSAEgMuLwrpxg/8QEjGiNEHN/pxjBgdVV/bkiEKy
+5yxzap84dz3lccndx3xoj0zcwepy9ujq4bk-ckyo63.si/%E89rzFXG/htVDvVdD11S/SLLVce1/%5bgcDSkD
+file:///Mr
+dm83f2l.vvlpnpob.7si.cr/RFT%18uMgARxsP/8%61%7cO/eZtPUg%e5FavR0XRe9wZZ?c94ub=63r5
+file:///cdgSAblie
+http://[5b83::58CE:d882:36F7:8b56:11D4:f42f]/9mbBwV%C4/AI2q64JsNqHO?tZ3=nATs%3CQ&lbSzuIb=/IJtfPRbcu
+ftp://gOD0KB6HB8JDGK56.l-V4OW.sj/KqqiLzCu%6a3jexLbLB/%6dBHZb%29z72YF/
+http://s65E1E.TR/5sj4rIdUt%CF4F
+ftp://[0f52:d55d:5574:ee10::dc96]/dPEbp7/PG0Nfo/MVx3/%5Fzz8%CFXb
+bdctmj.vzaax2fe.j8S2.ojfq-b1m454.g7I.uy/o0%28WV/Bv9nDwD
+https://k233JLHW6N.cCA13HZAXR.laiu78y.fleptcf.brva6c.osod.GS/OB5inpGTj=gGI/YNi3_gNnIg/J8UObWz6z
+ftp://enokmi/r3%690T0H5mfdRq
+http://s59w.cg/nJoM7yv/Z2T9Xof0hNGhl/N0%6b5Sbrbtjj/
+ftp://qytw0h.hkdt2rm.gd/3a1WJDglP%cfZ
+Q-2pgsvifg.yr2ix-c4avrjwva.kn/_zD8ad/%8AVwQwOG/JMC314h/rO0qj%88?w0XEY=JUigA33U&f2=n3tXrMH74ApC&fx%BE0=b%d5mgX%7F&1gjjJpHG=vLHCZ0Z8&sYQBW%FFAIs='&zD=GTnVzkf8Yn%a3L&Xm%b9F%32EcwWl8=GUq
+File:///spqq/8F2dG
+1Z73HWVULIKOO5WJ.rEJGR9.nsscy.gf/rHEt;i5T/%50ZjYYJ3M%4dR/WlW0C48ocnb/NRA~0M#
+078.104.235.053/8KqfxznOtxC/ycYiTG3%11zP2%A1/hhbuX9Z%d403wES6/P0gg5%94
+FTP://58vs5.g0.tHI.gq/N4HSp%95jtMMNr/bpH36W/cC3oAe1C/Sp7gxd/XO7JSqE
+http://e8CYICG-3GD1Z7A0V121.Ya0j.Wy.CM/BLyz1kmpRF/nb6u%52/GpXGTv19#9?bwz
+File:///Mze0xLtXpPFW&x/_%0aYP7o4Fm/5&809/fsvOYyn~zvJbT
+file://V-jo70zmqrppoeyva0hm6x10y.UK/#3O9f0OYdx
+file:///K4BV8xTq%ccORyFI/8PzAVSZeBNFX%adT
+071.247.240.193/%94VOUi%ac
+27r2mghslc2b.Dwbpiqi8q.gTYSL3Z.am/RU80/KFcctLv/R8tG8d51EaD&pno5r7pDR#GWY
+mdfr2j.1FZFG4.VN/Xn6l%6dLWufM/I4FHTzlnWx%7BoI/ueeKx%03mfSA/%9a3PMEt.iSdeTVFgSnLi%C84m/6dh
+http://H4jk06c6mtprgjywnc40mjri05a.VA/7B%C0h%4fCjj80/TrN5HugANCZu/eMVdn4en/QUSLGhe?7yjqzvzv2r%b0I=&p%C32*HvmS%39g=wb8u&lTvA=FCGNF46U+?Ak.vpCAV%ceiK0f
+file:///cVjI9Ue/siOD/jynyp9%3FmBx
+http://u8ic-x8o.UY/G9pZcTp/JI58N
+file:///cCOIlZV8ms/Y%e97nfvexWwxq%00/iPxdyY/snHA2QZT%10
+ftp://53.151.134.240/uZqGXLUIu-J/=%0C2pO/PvL0%19MpQBv/
+FILE:///Kywof5D5q/0TRS/zayrkrnENB
+file:///EYS2nDf%9671qsm34OZeB%e5lUA/rYBDn0DKs0/
+mpuwl0.BA/MkvAvc?j%11K4=9gE%613&qOOEP0t=g7EXs
+g6tylc0.daeczh.4q.XN--CLCHC0EA0B2G2A9GCD/1SbCR9cX1%3D/YfP8CpLKn5KzTL8/Kj11z%B7OuqJU;qM4P
+file:///TJa%86AczeCmM5QMhi/Wox~Ajl/WxUF%5eSA:y%0fD%E21/x%cca%d3Qgx/8iWJ5-h%26/fCK%01nQNrK8#ygTTB
+file:///~%303cUUVYTEaQU5%5DXbogiPKb/favR2rETEh/9TXM%15u/nYCOZpZgL
+file:///mJM%a1/jv5%53QDqE/bFMu0CBp
+[a0e6::]/YR5lwpHlG5BPjr2XT/Pq%e4kWAmZ/ucI10P1
+File:///8YorWt/#ToazT-v
+http://2igfcm3qy.wlcgdxv-xat059qnx15a7qp-p-p5oph1c8.GP/hS4Aqy7SmODbaOH
+3s81j.TJ/pS9Jzw8:NWryq/%00Kh1/Y7Rfoo7haw?pYq7Efg=
+HTTP://k59s6i5o.my/v9%93qqGOWZ6RN/cdz6V4ly7nM9A/F4EhM0N2%53H/d%C4wWTDspWU/zfpMcIDWp#oO%6fSILRH
+lvh-kt.TN/xZghTR/yDiD0a/P5D2%37rFa?rseH*%33ubfv3=%36ntM9MP,+97RbF5&F3Ia3L=%3djrAi%f7E2%65iQ+Uc43&y;Ikw=vdfmJW&sE_%F6xpm=XFIfCsT&k@ctNa=%47KDJKEw&d=am6K&%25!BjLNa=iqs.l
+http://Lhe7w4f06qt8tif2af1k6s552hlbk.mfce.cc/DEqiQf/GLpkeKZAxhSO4m
+Zy-iit.Cth-tuvx4.au/dl6DMUqP/wAeKXt6
+File:///35GJ%C8m6ubg/kpI4iEEx
+dbe.gkg.EDU/cJ%fbQ3k7pwp5/arlH%DCD
+Ftp://e8ni0.5etxvrjvn491/tP8r:UC/faEdqs4P/v4zJax4
+https://4PI.gg/fFtQoVp/b6Jf55/YEc2l7dE%CA
+http://gpu16lz.LS/9e%daJrwQfHEpFvsZ3jx/c4STIJ/CmvEGAUx9f/
+file://ij9anjtok86ro.uN-BGDQ855IB.sDXAQR.5kr8kz.3J3M8XRM.18r3s0g-6.4rjsmwue0lwao0og17d-5-1.F1h3qgkul29yw2t4p4se5clomncxhmoy.g6c9tbz7.pa/5LMtmbl/1tfIF/pBOV7Hc
+HTTPS://bF2RA.kw/1TA9pTTBg/nM/VSRo%85Kt?%62mxNfo=HDowgwkM3&9oPOLH2=yKOxIe+YNtt
+5.Piba4ac.JE/55M1H/AZXdj
+m-k6-ej7x.XN--J6W193G/suVrNQSIj9/TmRhHbe/o&0dbqR/
+ftp://242.228.138.8/o%CC_QjILS%17aYH/%caw8CcVZyPRZ/
+hGE9YH3D6.SD/m%1EpDJrzO/Tf2Xxqq8L/YJT7BTEY%661PvcMgOr/29ZbuJuWl6q/
+Ftp://mez27g2tpmk.MC/%B8AHk%95etDns%46/gXbsCn%6C-/s8_Jmy/DhmfT~Di6KD
+file:///NJvRsBjo/IECCGBvb
+http://8-6wji0x.tCVT41X.k1PS.15p.SH/e%daVn5b%f6/GpIJ%65e6/VpeXUmg#FRgJm0E
+ftp://nx4kcydiztae7fr0y-2kfppteds.gq06u.cr/RITrTqm/VqRIYR/6psgA0%dfpfg/gcLyL1/xa%72QCL;type=i
+file:///M0WBSuI2qsMuKSfOzj5S/2N7x7nZg/BLtq%72VxjcR/5%EAn1%c6TYYPGe/Lb5Mtu
+http://94MNP6XNH.0mgqklz3t9g2xl89x81-a3hifmff89nahy62jeyhuhe8lhkuafizl.GQ/Ajpa4Z1D0o/aVv748s/NAIWCkWCD2hj/7MZS5c79DmL4/ieQ%21gw?oEPqIN=Pm9nPx54%c1&j1y=C
+ftp://rKI.COOP/v0pdu1zj/ir2UM4X/7k04jhOKPVN/7ua%E5y8p/bl~yS
+d-IJA.PS/drbtmJGFEbR0OzDD/wMV2C/krWmMUV85/0AFhGe9
+[D1BF:D02E:140C:4B9F:c86e:9fdf:077.173.119.180]/A07Ox%86Oae/yhjXUMut
+http://A.bi/J1GPah/OT741dJ/Jh3Z0xb3
+ftp://6VMV.t680F6.ijsru3.bm/vlJmkK/go28Jr/qUtmHmqhj/ykeAVxYoe
+HTTPS://oi%32Yp.@a4mk0.Teyu0lojs62d8l96qiym2v477ixatleasrgft4ttpbfel9r.BW
+x37MULG.514yrp5.Vrd68eeufzt.VA/fFMWutSw0d/Gr%BFun3/JH6%DESQV8f#gn+NM2
+http://2.88.82.235/6bhV%BFGDy%ABd/g84ly25/;4AeID#
+https://a860jcplfoodo0yq401cdf9.1ZE2P/NLArIzMZ%8B/6UiHWMMGS79/?4N=4U%1dM0qA31&faSM=0q2RaEJu5QT+vzNMp+XR%7dI4dQ+x+%0BawIYp%dbcBiOZ*Sc
+ftp://lb.NP:46239/xwyAL/m74%9fqj4gttFLg/
+s086j1-9.Nowi9s.fm/16zr3s/mvzfyWbB5/&1mzA:X-3
+eigz5dhw.jynsrju0t044lcc.3c3bfm.int/%ffoZ_kP%5cO1ls76B/pQbPDb4s%4E6i/bqqrZ%b7j0uhrgIHd/eBdSEwfGrX/PSmYMzg0%6F?Qr%92y11b3=&L;5CV=zJao%31Tmm
+65-ihklk4j6m.f3CFA.7kj.qa9rcww7uefzkpxbf87ni28b4a1i9rjqy9a.5texnqlc9.cu/p%CDK%b1%449LH/IiLqpww/HmACJI/r46TA4
+133.38.197.20/pbgvKM6W%BCEBN/Cvcu0&#idQDycc
+https://4I2GL/cGtyrs/%A8m5%3fekPsTRWlB2?rn=63P,EJu+SQ1W+uPySU8pvA+%f2+m+CwuUokAVfo+3nzWcQ+S+iXvEuhcv+d$h%7fy%cfMB
+HTTP://a0br.o0gvxf.kp/zZkWq5hfxy/q0x-g0In#bd%1anKx27
+ftp://[1327::117.246.244.220]/%91y4%09/
+ktefq.GB/uTzbgV/9nYvIs%8412/ynKYs/YwBOWmj
+File:///08bP/cw3Ydr5Cyow%273h:O3Bcok/0hIP@/
+[018E:4459:9892:3770:3826:71D8::]/UcHNufii29UtPW%56WQ1%20V/ybjTB/oUWWQ?yUg1%cb4A=wk+hOic7f7Sw
+ftp://1o2z/4UWsX/uSzHOw3JTrqy/TqZhkQk%62gZ/FpK/
+Http://kZYPZSRN.1m.UA/QN9n3Nw8kPAgkCB/SzdVcxryKou7mMG#p6at77
+http://se9g.s7-5qnlmsi0npbr8ouxuey3y66swspkl.y4.st/xfP7%066uXWuOu/clIFhy
+ftp://D4j9grnngs4a61b.im/f35gw%53rTeI5/#Ff7A0YMs9RG8t
+https://zujspr.cr/zy14P7FG3/Oxznfe/P2zpT%38S%FFVfP95Lh/nJJgzX/kcVuHCzV?Y5vMC=3X4n%9dMqeGjM+OjgETPdf%23b1+6H%47F+waIQ&,ZxQh4G%8AZv=ic+fQWQN+0y%523JTe0Ti#OA0m6iC
+http://141.171.118.17/VLnEb4Y
+https://sla.aowts.MQ/KbP3AV@wXFSgz/TauvS9f2/zvGpvN.e8a2Kw1ho?jYRUP=L_IAzw&cj0ux=xz&lrA%8bS56%A9=SX7NjQ
+file:///
+FTP://h6.MG/XPmpsZk1h%0B
+http://Dh4mlm:8000/k9TYvw/EWxlz4%97lBf9oK57N=Z#Pm63s
+https://8-lno5.KM/Uco2E%dbYPx~/MzKrkZ/rDpXB7OWtD?Wb1W=bKJazR+yRD6c+qwe+H3bo2ACXXzkVX+PdfgOJ1Sqm40+X%3D)%AEgm8I9&inwrA=%FCe+%f9Xo4S+JrcmiNbPwa7P94J&fMCr;NellUf8=K&lhgC1k=%32CPUA6&%dexj,m=l
+http://bske9znh5z.mq/rF739Qhneaet/NTfzZn
+http://B7z94v/
+FTP://p9s.hh313n.6k3.DO/xaRRXPre
+File:///Sn7Qzu4cDoJY/6AdR%8ccbeeFmXy/KRXtibcbXtTaLZt-bb/PISQN%777zoI
+FILE:///IfZ6yalAm/BoIjbMXLnlo
+file:///kFKgAORyDOV
+file:///f0l1v94Rmms/zIVjJg%338Fy/5tMPO618wd
+FILE:///fpbiT?6/%0B7dUkWR5r%AErqLW/v2n%bet%b3wV8Yzi80OJ.SguK/vBMyQaKiH8/Wy3l7r/D%B8Vp%51GgmqIBUHA/9gn1:46Xok/NcNIZ/FIK%359u%57/%35NvYIQIN/
+FTP://22A1D0QMF.cmcve.CC/cvkZF/H%4EkZr%39EjtfIO/LPx46D%5AgqR9
+File:///0Lld-DX/&Qmx07f/Zp%21ldGQq
+http://rlch.COOP/%bcKE55hwH6/CKHB%2Ak/Qzsn2Rn1p3RUc3H
+http://h6d5js.edu/IO%34xTQYL/OtYPRaY5/e0ILXZt/jNP2%07otUg/vGyq3xN/DC8P4ckE/JGfiUR5EfFk/vSlxbi5dKL8d/6JwRI
+FTP://Sho0e4ay9e.XN--KGBECHTV:41333/6_5S71YpwTC
+file:///HrmxzTn/sozw%db8Jz/x0czCVWgklrbV1Kf@IK/Um%78PuxjtjI/
+FTP://9m4b5lf0.Y5dnwnduzx9wha22ayztin-t7hng5b62e07rzsv55325xgdrzwx.gov/pmG%45dhnQZ
+ftp://t2ik0rgw.krjz72-l.xn--mgbaam7a8h/I%19KxMhY/FSau72W7/WkW/vYKyDkhzNiu&Bput
+FTP://[221d::]/BOKtvhabe/b%78z/piR8RBZb
+Http://5zwdz3h27.q9l27mto-5v0i3i1yu8oyl.TN/wk91N/X32rxh/cmM%01iQPnCulto/
+FTP://gWUFGOXE8EW.1g9vse.xn--wgbh1c/ncQo%42ihY/Tyk216/;type=d#J4A9HEH
+FTP://5wudd.ga:36706/W5a2PQ/%98Oin@%D5hjD/POMMY0b/HhPA4HL;type=i
+file:///E01b%6ew/8QW%66%16Un/PWDGTFrQUHJ#dk&o~V40
+ftp://p78orte1aiif9.zk-l-n5drgvx2kj6i9e034ck587-utyikjhal.qE5RJ031K2FAN-35.v71jyg8l/wgwpnw5/1WPLlSc8/3RZzlIEZMlC8/ytaOFdSuPKO%72T
+tri9.Fyhn.SU/YlvVjSi3M/ylMdK88iRo%d8/cuHyS5Am1oeQ/XM40zgdj/q%9CLKm9Q/IOwvLrlTi?nDUET=e95%a3qf&dSTE=X5aY&pWtb=&AS48RI=71Z91stUL8Oc&z1%B6=fVvMzZUyI+Niwre%5FXyVRF&QtAo=5
+Ftp://Kroc.Ls4-tkd7.sg:58219/9tq-FJyL?Qb/e0alokGZ2/MKTHP3Wsw
+pmg4ty.m59480p2f69.fV.COM/X98xZ.E/cTleUeS/9P6zeVQjfd30/eVVvE4/Zyxm1SSqe9u/WP%a5hS
+6P.BD/du%F8CoA/W0jyU5x6HXyVB/EOpU%0BP%BET/TBlhd%772ObORj/PNPXkVHaEY
+http://5BCY.X3.SG/N~63s98IV2/?KuYCn%3160U5h:%BCU%DD='6uk3OyUbosbcu+l7U89Ozt12K+P/VK4+GhwEZ+D7Z5ByEYxG&8=#aa7R7i~K
+https://38yyrnu.UY/8Kl08k%157n9p/TEeDKN/qQnmQFd
+http://5PXM48/G%9fUxcBwBjXI0/1UJen/MF%30I6/eOsMzFMiM
+Http://s8AL.rc94r4iftx7qeg4cbjjv5.za/mYk9UAydyn4q@w/T7K/dd%8aIXPp
+Http://130.165.027.114/o8bwef/X%70neu3uGKY/NU%f8xTKW0;hTKK/V;%edBnJYWG0MI/ZlDMtVPK7?k1N:WnR=%3DNffenC%67+sf(z0U!mZFe+6YqpF0Ei4l&kea=&pv=0FrYO&%69j0HYlx=HVIq&sWgaQHZnyxp;=%97SOx&QbgYd=72tO&ugOWlP=TaHT&Zg5o=c,2tzpy&Xr=Nltupn6k&nxkPS%10oJY%74jL8=5c%58%77#E92Lme88eh
+sat8a.cc/n:G5Bs4/%92Qx7YH/%933F68jWsdw/mgMLj/b9uFtDS/fCBe=77/LYHeH
+file:///8NiXGOZYq
+ftp://[14A4::]/6gQ%83ppX66/Fm%0fhsGDdq86c52B2AReDTW/CGafhb/4LAIXfs6vOHd/DHtw5%A1
+http://astx.i8o5jdypn1ly.LC
+Ftp://7j.N@Ptavog8.gh/%FDJUUJB/nrC6%4as/AM2BxLCU:fGwm
+file:///LD3OAKQVR
+http://jVVR4GZ.BG/XELY1/P=cusbVv5o
+HTTP://4fx.3kt642w.GF/k4Nruf/hyO_xzJ%982n/BhxTVE5LR/VT7cIG%66726zz/YQCAvC/eTYPd%2Af%18tPt6Y
+ftp://1py.jhl5-h.53.39PN2C.xN.ps/Q6kM9aOm7
+1MRTJ51.mh/OT
+file:///RlgHP4tRuBYzCPY/
+http://[8F09:703a:5b45:F653:AB26::]/C51LFNl/tS8p/yG8y53@Wb?eBrhL=%f0Rj:Vl#%11Z
+FILE:///TmzdtWFH/1WP2R%b3nSKls
+http://5o0a8epm-rx6n67ta82256jav-nk4.lb/HbOqUc/TIVeqJ7Ohp/BjDwRDKJ/JZO
+File:///AvnO.7k/P0YrByEN2yEm9%1646/QKj7fR2/%1F0JYW0y/qscsiKGeGfPA/1rkuJyne%12/
+File:///1Hm4/bcNXO0cG%45XJo4RK4/SQGEP5/ELAGqI
+file://4jc3bg.zs/WfjCr2aeWME/Nv4A4B/invk2d1h
+Vj1.Ngq.LI/FR2%b7RU_z%a1Tf2vy/rysXmZ0/
+Ftp://wkws.yi8srfw.tm/sWvr8nVIPq3lD%16r71KGXZx/zTdcV/N%02%6ER5gChmS/uxEJA26q
+Https://cf3-0aw-g8zmm-k.AO/mYGm9AqQW%E4q?6u=&rX=
+8vv-rhcodmrr42jd6zmrnl7xa.F1igvm2.RO?rQOIRt=Q&Z8=1WyCZjZv83+lpB%7a
+Http://009.130.112.154:65403/z6iLA6cr/%3edXQdq1/yHKzFjDA3nAKTr/Ot4A3f%4DIzccRDaDQcC
+hwpmi.upmzdzzhsrz.e469.ee/SXdNeY7NHR6/Vr6%FDr
+http://[C7E7:57e7:b08c:9FCD:4B77:4de1:229.020.164.172]/LnIzKLn/StXMmto
+Http://2-6SB2KV8V8MV290SIC08D9J7-IRM9FTPC8ZZ.hwo9el74qqv1.zm/tr9K2BSFkbU-A8wJR/CGEL_82/cnMuBB%a3j34
+file:///fUtCm%b6qNK/lltu?NvBAhM/sJ8pOm:/jJ18OTM6U%f5v%3f/
+http://76OXC.pn.GA:15181/OPErhH1cHtl1ba/eIPkR6%1EG/8fVd02k/Ky%b0D5izq4k
+ftp://154.108.127.0/vGpMboeazp05/usfmVeitt0pf3o/Ue4OMVT/sJ9BAYSLje
+ftp://ivbv0.zCR-0J.lku/6m26/7tElM/%b2%0BI.Ft5AjDVp/oWyMVmsG/3%8E1FE8Y/0zdIl/m3otUSQeI7
+file:///0Y7NWf4qwhw9wXP/6ll5YWM55W%9050rPeqawX%F9/HleEmM
+5LUX-O.q-33d.tn/smzXQJn3H/81mg%4de_/jb%97hT
+http://84W32/CCKpkt/c0bqCnoQ5Y
+ftp://nyqaz.MT/0OfOsU7S1H9BM/OjhdD/izbR4txUY
+8wo2j2c1z9s.ef2ki0mlvvnjm5vfyu.t5a-yb41uykgo5kn1qxzffhz667dty8mytg6ir7os9hoxwm2.mw/%39FEVmD/%a4qRT5W5qW.yR/8XB9NHyB/
+http://rbf6ezzlhpe.hk/%0DK8/IXXJAsC?mV8vvDI8K=6t9%6EG1Dt+M7N+D5n@Vd79n%d8E+gj+ofnZ%16loobN+f3-S+e,IH&lnh=
+wu3w.0J5.lv/m9IZaWkw5/xY2%54pNYS9HL/Nhfns/e%bat2cKM/cUXgRzm2Srdt/2s2u/9h8zjwh929Bnp
+https://209.73.217.17/dJvsqDH/RH6Ok_eSc8wO5/BOJws6/9f0DvXJ4/?%ea'Fx=P&6h3zz3eGCtK=4MF76p7Em
+jfajtdt5k6gu11la2jbih.MA/zcaTNUL/3q%31eLT%bc3S/L6v2rt/WtbA0%45~TIvPD
+ftp://Defi-z.gr:16993/=7IIaMpVy3OLs/QtQD7qF5Vr/=RVbNDH8/y3oUHmX.v/Td%dcbiGlArA%720
+ftp://[544f:e60a::8772:D633:DA1F:081.021.019.189]:62615/%CB6Wy1K/X%0EcoPQ/IgnCMLPynfx/fdFHb
+ftp://1INQM6.4y.RO/
+Http://T778hd416.g9r96v.bs:64804/GbWp%47K/zgTKs/cBHzmYZ=AI23VY
+HTTPS://6hp3j2y2tuakzv1rnq9vnvn1w0j6roo3if:58975/vH8BLTu3hzkk
+ftp://Ye1dfbl0eae8lqiiqaojj.JO/8EjAq0TzD:/Bz3Pm2qyWo/ZX58A2/yjn%9F3xJZjsVhw
+66.242.9.138/CYHK1bGpZ/5yyVD%cbC
+nHZMBEJWO.ST/ABXauli3wuJ/WUxhKaZJg
+ftp://[8463:c210::b5d1]:34094/8%AC7Fc/Qh6%62yFExJbdaB/0cAZ3iSKlk8sU;TYPE=D
+http://vmlyl0efotpfd-tew59kcpsi2u7qd/UbXy1Cc/L%0cwnzmdjz/?iy=N16BnPMu1+eYFk%f6CB3z+s4Re5v8+MFTU+k+JDiN_+F1k&C%D0k=F78u+euh%1E1uzTGQio&bL_2omAu=iEEs+goL%b8g6+Y%3FBcek%102&WCz=e!Fg+MUif8Yba0k+uX+A91YO,Um+%70i%818Fpz2&6fP=HlD+%91pW+%f2HR6zs8zrE10ZPH+bWA.BB6k+Df3w:X85xDnDjSiPY+AyDpuSl4VEVTJzA3g&OtUR6=
+http://bCNNCLT.gxa2sbn/lAFakp
+D19f.oD5.bb/xUG6W8VxTcjMG/jYMuWlVMygf/UtIwE13c/%a9wzpO%AFxQ9
+q8HY2P.r5T.AU/nc0Iq%28QAF/#yOD3%b3UA%d79e%1EmJp3
+dPY3X09.AC/STpa%97U%b53yKP4Te/%71KZZvIC#nA1W2z
+ftp://3gb.xgjm/wF%ado0cM/u%0DmCW8L/d9Ss%61dKQ
+6m.56xkyt.32O.com/ToEAr%BEdi/xBpPU2NqC/74sgdq%BD9/WSrx5/5ldupD%47J/9boeZj
+ftp://s0y6r7hg7.XN--KGBECHTV/xQizIlOK9/uxho7%bd/RvxbFGQ4o/O%42UeWF?/GAZ5E8b2/eRaq/l:-1ASwSpw/2FkowF%12Ss/vtCq9dysEc%1ee/
+[d18d:1707::]/NGZMInsLF8/kgC3y/F66qc1qt6OWfeS/DyngWA
+file:///%55A4VpGsup
+file:///WNEw%bfTWDLF/s%A9oZoWUo
+Ftp://2tdk.Ube6velthhhx8o.GM/bUH4XycSEKkTE
+ftp://7kxk4ujzz.kp:32621/hbop0%25sK/rw7RBE0lTN/tX5BLF
+FILE:///IQExpA4kDvUfTkH6Bg/MeVJ4aIUbXCJf
+file:///SIE0AkJFq/ZPJLyYK/6hA3x1InlGm1
+http://047.014.184.200/Z_QdOwjzfBue4Nt/aEn/xuEQD/cXlnoxHIK%7d8h/1%eegEk7E0/8Ejku@r1Z/UZ4gG/%484zOJsP%1b/Lc1okbWRzN5UJ
+Http://w9ys35.wb55p6l.hxl.rs/Y97%58Lp8JjLZw/5L
+FILE://155.24.106.255/3VEZIT7
+d1y8zvhwq40bi3tom.hPCZ.gJ-286X.TG/ayWKrgAvF6tn/L4SgquZT6C/1DmNe/CI69rJ/%f6QrzZGkSQ
+lda5l5wc.XN--KPRY57D/pr80SSZ/eNM1%D50lp/Rc%8EimOET
+l13t2t.sk/O%2BmRkw/@0AgGL@NX/wgt&aggDcp#0IYe'C
+FILE://a6ys9a4.xj.BY/%99BGXp/F=yJtxc71/gvXuHuB9k
+212.072.006.032/6kV8ce%2e/%e7lzm-HB%4artP/zg6tWMW7RIG?U7=HAXw$D3sM%7DyDJ&Gt=
+http://[ea5::]/eIdv5xl/5qhxlOvzw%018f/N3RQQKCz/WzUnsSg8KA3/7ohHZCp
+file:///g_T81EaNw2nJB/1yUUT
+http://2XXY0MZ.fwa.791ck-2gx.bd/uO6FW?ZS5jE:=m:
+https://[8368:F154::f99f]/Y3h8FgzTYYpzn/zHFhQECC/CGtX/8v_~jn3Kn
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishAnalyzer.java
index 6220f9c..6d16715 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestSwedishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -53,4 +54,11 @@ public class TestSwedishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new SwedishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    SwedishAnalyzer a = new SwedishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
index ab502f0..86edc05 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
@@ -29,6 +29,7 @@ import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.StopAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 /**
  * Test case for ThaiAnalyzer, modified from TestFrenchAnalyzer
@@ -124,4 +125,11 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
           new int[] { 0, 5, 8, 10, 16, 19, 22, 25, 29, 33, 36, 39 },
           new int[] { 4, 7, 9, 14, 19, 22, 25, 29, 33, 36, 39, 41 });
   }
+
+  public void testBackcompat40() throws IOException {
+    ThaiAnalyzer a = new ThaiAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishAnalyzer.java lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishAnalyzer.java
index bc40ed5..b42e2fa 100644
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishAnalyzer.java
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.Version;
 
 public class TestTurkishAnalyzer extends BaseTokenStreamTestCase {
   /** This test fails with NPE when the 
@@ -55,4 +56,11 @@ public class TestTurkishAnalyzer extends BaseTokenStreamTestCase {
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), new TurkishAnalyzer(), 1000*RANDOM_MULTIPLIER);
   }
+
+  public void testBackcompat40() throws IOException {
+    TurkishAnalyzer a = new TurkishAnalyzer();
+    a.setVersion(Version.LUCENE_4_6_1);
+    // this is just a test to see the correct unicode version is being used, not actually testing hebrew
+    assertAnalyzesTo(a, "א\"א", new String[] {"א", "א"});
+  }
 }
diff --git lucene/tools/junit4/cached-timehints.txt lucene/tools/junit4/cached-timehints.txt
index 102028c..f4ff311 100644
--- lucene/tools/junit4/cached-timehints.txt
+++ lucene/tools/junit4/cached-timehints.txt
@@ -48,14 +48,14 @@ org.apache.lucene.analysis.core.TestDuelingAnalyzers=1844,4104,2325,2041,2568,19
 org.apache.lucene.analysis.core.TestFactories=13995,17156,12500,15103,14760,22010,13206
 org.apache.lucene.analysis.core.TestKeywordAnalyzer=241,205,234,403,223,326,209
 org.apache.lucene.analysis.core.TestRandomChains=3048,4646,3050,5003,4274,4400,3679
-org.apache.lucene.analysis.core.TestStandardAnalyzer=3672,3118,2532,4071,2379,2271,2479
+org.apache.lucene.analysis.standard.TestStandardAnalyzer=3672,3118,2532,4071,2379,2271,2479
 org.apache.lucene.analysis.core.TestStopAnalyzer=31,39,16,22,66,10,19
 org.apache.lucene.analysis.core.TestStopFilter=76,83,64,12,148,19,19
 org.apache.lucene.analysis.core.TestStopFilterFactory=31,7,27,92,10,29,22
 org.apache.lucene.analysis.core.TestTypeTokenFilter=13,26,18,352,18,113,44
 org.apache.lucene.analysis.core.TestTypeTokenFilterFactory=23,36,85,60,23,16,112
-org.apache.lucene.analysis.core.TestUAX29URLEmailAnalyzer=315,243,502,493,183,240,564
-org.apache.lucene.analysis.core.TestUAX29URLEmailTokenizer=1656,837,1071,1402,2610,1318,1134
+org.apache.lucene.analysis.standard.TestUAX29URLEmailAnalyzer=315,243,502,493,183,240,564
+org.apache.lucene.analysis.standard.TestUAX29URLEmailTokenizer=1656,837,1071,1402,2610,1318,1134
 org.apache.lucene.analysis.cz.TestCzechAnalyzer=610,176,302,835,120,221,92
 org.apache.lucene.analysis.cz.TestCzechStemFilterFactory=8,10,8,18,23,35,53
 org.apache.lucene.analysis.cz.TestCzechStemmer=38,126,47,24,242,96,34
