diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldHighlighter.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldHighlighter.java
index a0e6d0a966..50850834a9 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldHighlighter.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldHighlighter.java
@@ -27,7 +27,6 @@ import java.util.PriorityQueue;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
 
 /**
  * Internal highlighter abstraction that operates on a per field basis.
@@ -76,27 +75,22 @@ public class FieldHighlighter {
 
     breakIterator.setText(content);
 
-    List<OffsetsEnum> offsetsEnums = fieldOffsetStrategy.getOffsetsEnums(reader, docId, content);
+    try (OffsetsEnum offsetsEnums = fieldOffsetStrategy.getOffsetsEnum(reader, docId, content)) {
 
-    Passage[] passages;
-    try {
       // Highlight the offsetsEnum list against the content to produce Passages.
-      passages = highlightOffsetsEnums(offsetsEnums);// and breakIterator & scorer
-    } finally {
-      // Ensure closeable resources get closed
-      IOUtils.close(offsetsEnums);
-    }
+      Passage[] passages = highlightOffsetsEnums(offsetsEnums);// and breakIterator & scorer
 
-    // Format the resulting Passages.
-    if (passages.length == 0) {
-      // no passages were returned, so ask for a default summary
-      passages = getSummaryPassagesNoHighlight(maxNoHighlightPassages == -1 ? maxPassages : maxNoHighlightPassages);
-    }
+      // Format the resulting Passages.
+      if (passages.length == 0) {
+        // no passages were returned, so ask for a default summary
+        passages = getSummaryPassagesNoHighlight(maxNoHighlightPassages == -1 ? maxPassages : maxNoHighlightPassages);
+      }
 
-    if (passages.length > 0) {
-      return passageFormatter.format(passages, content);
-    } else {
-      return null;
+      if (passages.length > 0) {
+        return passageFormatter.format(passages, content);
+      } else {
+        return null;
+      }
     }
   }
 
@@ -118,7 +112,6 @@ public class FieldHighlighter {
         break;
       }
       Passage passage = new Passage();
-      passage.setScore(Float.NaN);
       passage.setStartOffset(pos);
       passage.setEndOffset(next);
       passages.add(passage);
@@ -131,21 +124,13 @@ public class FieldHighlighter {
   // algorithm: treat sentence snippets as miniature documents
   // we can intersect these with the postings lists via BreakIterator.preceding(offset),s
   // score each sentence as norm(sentenceStartOffset) * sum(weight * tf(freq))
-  protected Passage[] highlightOffsetsEnums(List<OffsetsEnum> offsetsEnums)
+  protected Passage[] highlightOffsetsEnums(OffsetsEnum off)
       throws IOException {
-    PassageScorer scorer = passageScorer;
-    BreakIterator breakIterator = this.breakIterator;
-    final int contentLength = breakIterator.getText().getEndIndex();
-
-    //TODO consider moving this part to an aggregate OffsetsEnum subclass so we have one enum that already has its weight
-    PriorityQueue<OffsetsEnum> offsetsEnumQueue = new PriorityQueue<>(offsetsEnums.size() + 1);
-    for (OffsetsEnum off : offsetsEnums) {
-      off.setWeight(scorer.weight(contentLength, off.freq()));
-      if (off.nextPosition()) {// go to first position
-        offsetsEnumQueue.add(off);
-      }
-    }
-    offsetsEnumQueue.add(new OffsetsEnum.OfPostings(new BytesRef(), EMPTY)); // a sentinel for termination
+
+    final int contentLength = this.breakIterator.getText().getEndIndex();
+
+    if (off.nextPosition() == false)
+      return new Passage[0];
 
     PriorityQueue<Passage> passageQueue = new PriorityQueue<>(Math.min(64, maxPassages + 1), (left, right) -> {
       if (left.getScore() < right.getScore()) {
@@ -158,8 +143,7 @@ public class FieldHighlighter {
     });
     Passage passage = new Passage(); // the current passage in-progress.  Will either get reset or added to queue.
 
-    OffsetsEnum off;
-    while ((off = offsetsEnumQueue.poll()) != null) {
+    do {
       int start = off.startOffset();
       if (start == -1) {
         throw new IllegalArgumentException("field '" + field + "' was indexed without offsets, cannot highlight");
@@ -175,59 +159,50 @@ public class FieldHighlighter {
       // See if this term should be part of a new passage.
       if (start >= passage.getEndOffset()) {
         if (passage.getStartOffset() >= 0) { // true if this passage has terms; otherwise couldn't find any (yet)
-          // finalize passage
-          passage.setScore(passage.getScore() * scorer.norm(passage.getStartOffset()));
-          // new sentence: first add 'passage' to queue
-          if (passageQueue.size() == maxPassages && passage.getScore() < passageQueue.peek().getScore()) {
-            passage.reset(); // can't compete, just reset it
-          } else {
-            passageQueue.offer(passage);
-            if (passageQueue.size() > maxPassages) {
-              passage = passageQueue.poll();
-              passage.reset();
-            } else {
-              passage = new Passage();
-            }
-          }
+          passage = maybeAddPassage(passageQueue, passageScorer, passage, contentLength);
         }
         // if we exceed limit, we are done
         if (start >= contentLength) {
           break;
         }
         // advance breakIterator
-        passage.setStartOffset(Math.max(breakIterator.preceding(start + 1), 0));
-        passage.setEndOffset(Math.min(breakIterator.following(start), contentLength));
+        passage.setStartOffset(Math.max(this.breakIterator.preceding(start + 1), 0));
+        passage.setEndOffset(Math.min(this.breakIterator.following(start), contentLength));
       }
       // Add this term to the passage.
-      int tf = 0;
-      while (true) {
-        tf++;
-        BytesRef term = off.getTerm();// a reference; safe to refer to
-        assert term != null;
-        passage.addMatch(start, end, term);
-        // see if there are multiple occurrences of this term in this passage. If so, add them.
-        if (!off.nextPosition()) {
-          break; // No more in the entire text. Already removed from pq; move on
-        }
-        start = off.startOffset();
-        end = off.endOffset();
-        if (start >= passage.getEndOffset() || end > contentLength) { // it's beyond this passage
-          offsetsEnumQueue.offer(off);
-          break;
-        }
-      }
-      passage.setScore(passage.getScore() + off.getWeight() * scorer.tf(tf, passage.getEndOffset() - passage.getStartOffset()));
+      BytesRef term = off.getTerm();// a reference; safe to refer to
+      assert term != null;
+      passage.addMatch(start, end, term, off.freq());
     }
+    while (off.nextPosition());
+    maybeAddPassage(passageQueue, passageScorer, passage, contentLength);
 
     Passage[] passages = passageQueue.toArray(new Passage[passageQueue.size()]);
-    for (Passage p : passages) {
-      p.sort();
-    }
     // sort in ascending order
     Arrays.sort(passages, Comparator.comparingInt(Passage::getStartOffset));
     return passages;
   }
 
+  private Passage maybeAddPassage(PriorityQueue<Passage> passageQueue, PassageScorer scorer, Passage passage, int contentLength) {
+    // finalize passage
+    if (passage.getStartOffset() == -1)
+      return passage;
+    passage.setScore(scorer, contentLength);
+    // new sentence: first add 'passage' to queue
+    if (passageQueue.size() == maxPassages && passage.getScore() < passageQueue.peek().getScore()) {
+      passage.reset(); // can't compete, just reset it
+    } else {
+      passageQueue.offer(passage);
+      if (passageQueue.size() > maxPassages) {
+        passage = passageQueue.poll();
+        passage.reset();
+      } else {
+        passage = new Passage();
+      }
+    }
+    return passage;
+  }
+
   protected static final PostingsEnum EMPTY = new PostingsEnum() {
 
     @Override
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy.java
index faef106220..e77c7ca3e3 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search.uhighlight;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.index.IndexReader;
@@ -60,12 +59,12 @@ public abstract class FieldOffsetStrategy {
    * The primary method -- return offsets for highlightable words in the specified document.
    * IMPORTANT: remember to close them all.
    */
-  public abstract List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException;
+  public abstract OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException;
 
-  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {
+  protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {
     final Terms termsIndex = leafReader.terms(field);
     if (termsIndex == null) {
-      return Collections.emptyList();
+      return OffsetsEnum.EMPTY;
     }
 
     final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);
@@ -92,7 +91,7 @@ public abstract class FieldOffsetStrategy {
       createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);
     }
 
-    return offsetsEnums;
+    return new OffsetsEnum.MultiOffsetsEnum(offsetsEnums);
   }
 
   protected void createOffsetsEnumsForTerms(BytesRef[] sourceTerms, Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MemoryIndexOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MemoryIndexOffsetStrategy.java
index cf7a3c91f7..6364f3fcd5 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MemoryIndexOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MemoryIndexOffsetStrategy.java
@@ -100,7 +100,7 @@ public class MemoryIndexOffsetStrategy extends AnalysisOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
     // note: don't need LimitTokenOffsetFilter since content is already truncated to maxLength
     TokenStream tokenStream = tokenStream(content);
 
@@ -110,7 +110,7 @@ public class MemoryIndexOffsetStrategy extends AnalysisOffsetStrategy {
     memoryIndex.addField(field, tokenStream);//note: calls tokenStream.reset() & close()
     docId = 0;
 
-    return createOffsetsEnumsFromReader(leafReader, docId);
+    return createOffsetsEnumFromReader(leafReader, docId);
   }
 
 
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/NoOpOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/NoOpOffsetStrategy.java
index 7ae4de5d54..44a23f7072 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/NoOpOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/NoOpOffsetStrategy.java
@@ -17,8 +17,6 @@
 package org.apache.lucene.search.uhighlight;
 
 import java.io.IOException;
-import java.util.Collections;
-import java.util.List;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.util.BytesRef;
@@ -43,8 +41,8 @@ public class NoOpOffsetStrategy extends FieldOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
-    return Collections.emptyList();
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
+    return OffsetsEnum.EMPTY;
   }
 
 }
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/OffsetsEnum.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/OffsetsEnum.java
index f0a46a5d83..1133eb5d2c 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/OffsetsEnum.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/OffsetsEnum.java
@@ -21,21 +21,21 @@ import java.io.Closeable;
 import java.io.IOException;
 import java.util.List;
 import java.util.Objects;
+import java.util.PriorityQueue;
 
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
 
 /**
  * An enumeration/iterator of a term and its offsets for use by {@link FieldHighlighter}.
  * It is advanced and is placed in a priority queue by
- * {@link FieldHighlighter#highlightOffsetsEnums(List)} based on the start offset.
+ * {@link FieldHighlighter#highlightOffsetsEnums(OffsetsEnum)} based on the start offset.
  *
  * @lucene.internal
  */
 public abstract class OffsetsEnum implements Comparable<OffsetsEnum>, Closeable {
 
-  private float weight; // set once in highlightOffsetsEnums
-
   // note: the ordering clearly changes as the postings enum advances
   // note: would be neat to use some Comparator utilities with method
   //  references but our methods throw IOException
@@ -82,14 +82,6 @@ public abstract class OffsetsEnum implements Comparable<OffsetsEnum>, Closeable
 
   public abstract int endOffset() throws IOException;
 
-  public float getWeight() {
-    return weight;
-  }
-
-  public void setWeight(float weight) {
-    this.weight = weight;
-  }
-
   @Override
   public void close() throws IOException {
   }
@@ -133,25 +125,108 @@ public abstract class OffsetsEnum implements Comparable<OffsetsEnum>, Closeable
       }
     }
 
+    @Override
+    public BytesRef getTerm() throws IOException {
+      return term;
+    }
+
+    @Override
+    public int startOffset() throws IOException {
+      return postingsEnum.startOffset();
+    }
+
+    @Override
+    public int endOffset() throws IOException {
+      return postingsEnum.endOffset();
+    }
+
     @Override
     public int freq() throws IOException {
       return postingsEnum.freq();
     }
+  }
+
+  public static final OffsetsEnum EMPTY = new OffsetsEnum() {
+    @Override
+    public boolean nextPosition() throws IOException {
+      return false;
+    }
 
     @Override
     public BytesRef getTerm() throws IOException {
-      return term;
+      throw new UnsupportedOperationException();
     }
 
     @Override
     public int startOffset() throws IOException {
-      return postingsEnum.startOffset();
+      throw new UnsupportedOperationException();
     }
 
     @Override
     public int endOffset() throws IOException {
-      return postingsEnum.endOffset();
+      throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public int freq() throws IOException {
+      return 0;
     }
 
+  };
+
+  public static class MultiOffsetsEnum extends OffsetsEnum {
+
+    private final PriorityQueue<OffsetsEnum> queue;
+    private boolean started = false;
+
+    public MultiOffsetsEnum(List<OffsetsEnum> inner) throws IOException {
+      this.queue = new PriorityQueue<>();
+      for (OffsetsEnum oe : inner) {
+        if (oe.nextPosition())
+          this.queue.add(oe);
+      }
+    }
+
+    @Override
+    public boolean nextPosition() throws IOException {
+      if (started == false) {
+        started = true;
+        return this.queue.size() > 0;
+      }
+      if (this.queue.size() > 0) {
+        OffsetsEnum top = this.queue.poll();
+        if (top.nextPosition()) {
+          this.queue.add(top);
+          return true;
+        }
+        return this.queue.size() > 0;
+      }
+      return false;
+    }
+
+    @Override
+    public BytesRef getTerm() throws IOException {
+      return this.queue.peek().getTerm();
+    }
+
+    @Override
+    public int startOffset() throws IOException {
+      return this.queue.peek().startOffset();
+    }
+
+    @Override
+    public int endOffset() throws IOException {
+      return this.queue.peek().endOffset();
+    }
+
+    @Override
+    public int freq() throws IOException {
+      return this.queue.peek().freq();
+    }
+
+    @Override
+    public void close() throws IOException {
+      IOUtils.close(queue);
+    }
   }
 }
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/Passage.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/Passage.java
index 24b1015d10..17fc5603f5 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/Passage.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/Passage.java
@@ -17,9 +17,11 @@
 package org.apache.lucene.search.uhighlight;
 
 
+import java.util.Arrays;
+
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.InPlaceMergeSorter;
+import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.RamUsageEstimator;
 
 /**
@@ -39,9 +41,12 @@ public class Passage {
   private int[] matchEnds = new int[8];
   private BytesRef[] matchTerms = new BytesRef[8];
   private int numMatches = 0;
+  private final BytesRefHash termsHash = new BytesRefHash();
+  private int[] termFreqsInDoc = new int[8];
+  private int[] termFreqsInPassage = new int[8];
 
   /** @lucene.internal */
-  public void addMatch(int startOffset, int endOffset, BytesRef term) {
+  public void addMatch(int startOffset, int endOffset, BytesRef term, int termFreqInDoc) {
     assert startOffset >= this.startOffset && startOffset <= this.endOffset;
     if (numMatches == matchStarts.length) {
       int newLength = ArrayUtil.oversize(numMatches + 1, RamUsageEstimator.NUM_BYTES_OBJECT_REF);
@@ -60,35 +65,25 @@ public class Passage {
     matchEnds[numMatches] = endOffset;
     matchTerms[numMatches] = term;
     numMatches++;
-  }
-
-  /** @lucene.internal */
-  public void sort() {
-    final int starts[] = matchStarts;
-    final int ends[] = matchEnds;
-    final BytesRef terms[] = matchTerms;
-    new InPlaceMergeSorter() {
-      @Override
-      protected void swap(int i, int j) {
-        int temp = starts[i];
-        starts[i] = starts[j];
-        starts[j] = temp;
-
-        temp = ends[i];
-        ends[i] = ends[j];
-        ends[j] = temp;
-
-        BytesRef tempTerm = terms[i];
-        terms[i] = terms[j];
-        terms[j] = tempTerm;
-      }
-
-      @Override
-      protected int compare(int i, int j) {
-        return Integer.compare(starts[i], starts[j]);
-      }
-
-    }.sort(0, numMatches);
+    int termIndex = termsHash.add(term);
+    if (termIndex >= termFreqsInDoc.length) {
+      int newLength = ArrayUtil.oversize(termFreqsInDoc.length + 1, Integer.BYTES);
+      int newTermFreqsInDoc[] = new int[newLength];
+      int newTermFreqsInPassage[] = new int[newLength];
+      System.arraycopy(termFreqsInDoc, 0, newTermFreqsInDoc, 0, termFreqsInDoc.length);
+      System.arraycopy(termFreqsInPassage, 0, newTermFreqsInPassage, 0, termFreqsInDoc.length);
+      Arrays.fill(newTermFreqsInDoc, termFreqsInDoc.length, newTermFreqsInDoc.length - 1, 0);
+      Arrays.fill(newTermFreqsInPassage, termFreqsInPassage.length, newTermFreqsInPassage.length - 1, 0);
+      termFreqsInDoc = newTermFreqsInDoc;
+      termFreqsInPassage = newTermFreqsInPassage;
+    }
+    if (termIndex < 0) {
+      termIndex = -(termIndex + 1);
+    }
+    else {
+      termFreqsInDoc[termIndex] = termFreqInDoc;
+    }
+    termFreqsInPassage[termIndex]++;
   }
 
   /** @lucene.internal */
@@ -96,6 +91,9 @@ public class Passage {
     startOffset = endOffset = -1;
     score = 0.0f;
     numMatches = 0;
+    Arrays.fill(termFreqsInPassage, 0);
+    termsHash.clear();
+    termsHash.reinit();
   }
 
   /** For debugging.  ex: Passage[0-22]{yin[0-3],yang[4-8],yin[10-13]}score=2.4964213 */
@@ -136,6 +134,10 @@ public class Passage {
     return endOffset;
   }
 
+  public int getLength() {
+    return endOffset - startOffset;
+  }
+
   /**
    * Passage's score.
    */
@@ -143,6 +145,14 @@ public class Passage {
     return score;
   }
 
+  public void setScore(PassageScorer scorer, int contentLength) {
+    score = 0;
+    for (int termIndex = 0; termIndex < termsHash.size(); termIndex++) {
+      score += scorer.tf(termFreqsInPassage[termIndex], getLength()) * scorer.weight(contentLength, termFreqsInDoc[termIndex]);
+    }
+    score *= scorer.norm(startOffset);
+  }
+
   /**
    * Number of term matches available in
    * {@link #getMatchStarts}, {@link #getMatchEnds},
@@ -193,8 +203,4 @@ public class Passage {
     this.endOffset = endOffset;
   }
 
-  /** @lucene.internal */
-  public void setScore(float score) {
-    this.score = score;
-  }
 }
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsOffsetStrategy.java
index 975d3a1dcc..b7df77a8f2 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsOffsetStrategy.java
@@ -40,7 +40,7 @@ public class PostingsOffsetStrategy extends FieldOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
     final LeafReader leafReader;
     if (reader instanceof LeafReader) {
       leafReader = (LeafReader) reader;
@@ -51,7 +51,7 @@ public class PostingsOffsetStrategy extends FieldOffsetStrategy {
       docId -= leafReaderContext.docBase; // adjust 'doc' to be within this leaf reader
     }
 
-    return createOffsetsEnumsFromReader(leafReader, docId);
+    return createOffsetsEnumFromReader(leafReader, docId);
   }
 
 
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsWithTermVectorsOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsWithTermVectorsOffsetStrategy.java
index b9086a7400..9097e4d68b 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsWithTermVectorsOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/PostingsWithTermVectorsOffsetStrategy.java
@@ -17,7 +17,6 @@
 package org.apache.lucene.search.uhighlight;
 
 import java.io.IOException;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.index.IndexReader;
@@ -40,7 +39,7 @@ public class PostingsWithTermVectorsOffsetStrategy extends FieldOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
     LeafReader leafReader;
     if (reader instanceof LeafReader) {
       leafReader = (LeafReader) reader;
@@ -53,11 +52,11 @@ public class PostingsWithTermVectorsOffsetStrategy extends FieldOffsetStrategy {
 
     Terms docTerms = leafReader.getTermVector(docId, field);
     if (docTerms == null) {
-      return Collections.emptyList();
+      return OffsetsEnum.EMPTY;
     }
     leafReader = new TermVectorFilteredLeafReader(leafReader, docTerms);
 
-    return createOffsetsEnumsFromReader(leafReader, docId);
+    return createOffsetsEnumFromReader(leafReader, docId);
   }
 
   @Override
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TermVectorOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TermVectorOffsetStrategy.java
index f6eedc4176..cd19bb9d0d 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TermVectorOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TermVectorOffsetStrategy.java
@@ -17,8 +17,6 @@
 package org.apache.lucene.search.uhighlight;
 
 import java.io.IOException;
-import java.util.Collections;
-import java.util.List;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReader;
@@ -44,16 +42,16 @@ public class TermVectorOffsetStrategy extends FieldOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
     Terms tvTerms = reader.getTermVector(docId, field);
     if (tvTerms == null) {
-      return Collections.emptyList();
+      return OffsetsEnum.EMPTY;
     }
 
     LeafReader leafReader = new TermVectorLeafReader(field, tvTerms);
     docId = 0;
 
-    return createOffsetsEnumsFromReader(leafReader, docId);
+    return createOffsetsEnumFromReader(leafReader, docId);
   }
 
 }
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy.java
index 5f47a5daac..b81e63e282 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy.java
@@ -17,8 +17,6 @@
 package org.apache.lucene.search.uhighlight;
 
 import java.io.IOException;
-import java.util.Collections;
-import java.util.List;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
@@ -60,8 +58,8 @@ public class TokenStreamOffsetStrategy extends AnalysisOffsetStrategy {
   }
 
   @Override
-  public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
-    return Collections.singletonList(new TokenStreamOffsetsEnum(tokenStream(content), automata));
+  public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
+    return new TokenStreamOffsetsEnum(tokenStream(content), automata);
   }
 
   private static class TokenStreamOffsetsEnum extends OffsetsEnum {
@@ -106,6 +104,7 @@ public class TokenStreamOffsetStrategy extends AnalysisOffsetStrategy {
       return Integer.MAX_VALUE; // lie
     }
 
+
     @Override
     public int startOffset() throws IOException {
       return offsetAtt.startOffset();
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.java b/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.java
index e5392632f0..a235edd72b 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.java
@@ -16,6 +16,10 @@
  */
 package org.apache.lucene.search.uhighlight;
 
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Random;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -39,10 +43,6 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Random;
-
 public class TestUnifiedHighlighterRanking extends LuceneTestCase {
 
   Analyzer indexAnalyzer;
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java b/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java
index e60b17be76..c7349e28b2 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java
@@ -19,7 +19,6 @@ package org.apache.lucene.search.uhighlight.visibility;
 
 import java.io.IOException;
 import java.text.BreakIterator;
-import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -69,13 +68,13 @@ public class TestUnifiedHighlighterExtensibility extends LuceneTestCase {
       }
 
       @Override
-      public List<OffsetsEnum> getOffsetsEnums(IndexReader reader, int docId, String content) throws IOException {
-        return Collections.emptyList();
+      public OffsetsEnum getOffsetsEnum(IndexReader reader, int docId, String content) throws IOException {
+        return OffsetsEnum.EMPTY;
       }
 
       @Override
-      protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {
-        return super.createOffsetsEnumsFromReader(leafReader, doc);
+      protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {
+        return super.createOffsetsEnumFromReader(leafReader, doc);
       }
 
     };
@@ -193,7 +192,7 @@ public class TestUnifiedHighlighterExtensibility extends LuceneTestCase {
     final String fieldName = "fieldName";
     FieldHighlighter fieldHighlighter = new FieldHighlighter(fieldName, null, null, null, 1, 1, null) {
       @Override
-      protected Passage[] highlightOffsetsEnums(List<OffsetsEnum> offsetsEnums) throws IOException {
+      protected Passage[] highlightOffsetsEnums(OffsetsEnum offsetsEnums) throws IOException {
         return super.highlightOffsetsEnums(offsetsEnums);
       }
     };
@@ -213,28 +212,24 @@ public class TestUnifiedHighlighterExtensibility extends LuceneTestCase {
     }
 
     @Override
-    protected Passage[] highlightOffsetsEnums(List<OffsetsEnum> offsetsEnums) throws IOException {
+    protected Passage[] highlightOffsetsEnums(OffsetsEnum offsetsEnums) throws IOException {
       // TEST OffsetsEnums & Passage visibility
 
       // this code never runs; just for compilation
       Passage p;
       try (OffsetsEnum oe = new OffsetsEnum.OfPostings(null, EMPTY)) {
         oe.getTerm();
-        oe.freq();
         oe.nextPosition();
         oe.startOffset();
         oe.endOffset();
-        oe.getWeight();
-        oe.setWeight(2f);
+        oe.freq();
       }
 
       p = new Passage();
       p.setStartOffset(0);
       p.setEndOffset(9);
-      p.setScore(1f);
-      p.addMatch(1, 2, new BytesRef());
+      p.addMatch(1, 2, new BytesRef(), 1);
       p.reset();
-      p.sort();
       //... getters are all exposed; custom PassageFormatter impls uses them
 
       return super.highlightOffsetsEnums(offsetsEnums);
