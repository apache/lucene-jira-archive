diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
index f19cd2c..461bae1 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.java
@@ -362,7 +362,7 @@ public class BlockTermsWriter extends FieldsConsumer implements Closeable {
         final BlockTermState state = pendingTerms[termCount].state;
         postingsWriter.encodeTerm(longs, bufferWriter, fieldInfo, state, absolute);
         for (int i = 0; i < longsSize; i++) {
-          bytesWriter.writeVLong(longs[i]);
+          bytesWriter.writeZLong(longs[i]);
         }
         bufferWriter.writeTo(bytesWriter);
         bufferWriter.reset();
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
index 1fb83b9..3e647c1 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
@@ -18,11 +18,14 @@ package org.apache.lucene.codecs;
 
 
 import java.io.IOException;
+import java.util.LinkedHashMap;
+import java.util.Map;
 
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.TermsEnum.OriginalTermsSupplier;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 
@@ -63,6 +66,9 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
   /** True if the current field writes offsets. */
   protected boolean writeOffsets;
 
+  /** keps earlier written term states */
+  private Map<String, BlockTermState> twinTermsStore = new LinkedHashMap<>();
+
   /** Sole constructor. (For invocation by subclass 
    *  constructors, typically implicit.) */
   protected PushPostingsWriterBase() {
@@ -119,6 +125,9 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
   @Override
   public final BlockTermState writeTerm(BytesRef term, TermsEnum termsEnum, FixedBitSet docsSeen) throws IOException {
     startTerm();
+    
+    String original = (termsEnum instanceof OriginalTermsSupplier) ?  ((OriginalTermsSupplier) termsEnum).getTwinTerm() : null;
+    if (original==null || !twinTermsStore.containsKey(original)) {
       postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
       assert postingsEnum != null;
   
@@ -167,8 +176,17 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
         state.docFreq = docFreq;
         state.totalTermFreq = writeFreqs ? totalTermFreq : -1;
         finishTerm(state);
+        if (original!=null) {
+          twinTermsStore.put(term.utf8ToString(), state);
+          System.out.println("remember " + term.utf8ToString() +" -> " + state);
+        }
         return state;
       }
+    } else {
+      BlockTermState synonymState = twinTermsStore.get(original);
+      System.out.println("referring " + term.utf8ToString() +" to "+ original +" -> " + synonymState);
+      return synonymState;
+    }
   }
 
   /** Adds a new doc in this term. 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
index a4a150b..89c5519 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
@@ -725,8 +725,8 @@ public final class BlockTreeTermsWriter extends FieldsConsumer {
           // Write term meta data
           postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);
           for (int pos = 0; pos < longsSize; pos++) {
-            assert longs[pos] >= 0;
-            metaWriter.writeVLong(longs[pos]);
+            //assert longs[pos] >= 0;
+            metaWriter.writeZLong(longs[pos]);
           }
           bytesWriter.writeTo(metaWriter);
           bytesWriter.reset();
@@ -776,8 +776,8 @@ public final class BlockTreeTermsWriter extends FieldsConsumer {
             // Write term meta data
             postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);
             for (int pos = 0; pos < longsSize; pos++) {
-              assert longs[pos] >= 0;
-              metaWriter.writeVLong(longs[pos]);
+              //assert longs[pos] >= 0;
+              metaWriter.writeZLong(longs[pos]);
             }
             bytesWriter.writeTo(metaWriter);
             bytesWriter.reset();
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnumFrame.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnumFrame.java
index 3241075..f9e0e09 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnumFrame.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnumFrame.java
@@ -343,7 +343,7 @@ final class IntersectTermsEnumFrame {
       }
       // metadata 
       for (int i = 0; i < ite.fr.longsSize; i++) {
-        longs[i] = bytesReader.readVLong();
+        longs[i] = bytesReader.readZLong();
       }
       ite.fr.parent.postingsReader.decodeTerm(longs, bytesReader, ite.fr.fieldInfo, termState, absolute);
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnumFrame.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnumFrame.java
index a2abbaf..9b86363 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnumFrame.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnumFrame.java
@@ -458,7 +458,7 @@ final class SegmentTermsEnumFrame {
       }
       // metadata 
       for (int i = 0; i < ste.fr.longsSize; i++) {
-        longs[i] = bytesReader.readVLong();
+        longs[i] = bytesReader.readZLong();
       }
       ste.fr.parent.postingsReader.decodeTerm(longs, bytesReader, ste.fr.fieldInfo, state, absolute);
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
index 0dde774..519236d 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
@@ -163,8 +163,9 @@ public final class Lucene50PostingsReader extends PostingsReaderBase {
       termState.posStartFP = 0;
       termState.payStartFP = 0;
     }
-
+    System.out.print(termState.docStartFP+"+"+longs[0]+"=");
     termState.docStartFP += longs[0];
+    System.out.println("="+termState.docStartFP+" "+termState);
     if (fieldHasPositions) {
       termState.posStartFP += longs[1];
       if (fieldHasOffsets || fieldHasPayloads) {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsWriter.java
index 6d24a4c..57dd0c5 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsWriter.java
@@ -440,6 +440,7 @@ public final class Lucene50PostingsWriter extends PushPostingsWriterBase {
       lastState = emptyState;
     }
     longs[0] = state.docStartFP - lastState.docStartFP;
+    System.out.println(state.docStartFP + "-" + lastState.docStartFP+"="+longs[0]+" " + state);
     if (writePositions) {
       longs[1] = state.posStartFP - lastState.posStartFP;
       if (writePayloads || writeOffsets) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
index fb78a92..06f1679 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
@@ -27,6 +27,7 @@ import org.apache.lucene.index.FreqProxTermsWriterPerField.FreqProxPostingsArray
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.index.TermsEnum.OriginalTermsSupplier;
 
 /** Implements limited (iterators only, no stats) {@link
  *  Fields} interface over the in-RAM buffered
@@ -124,7 +125,7 @@ class FreqProxFields extends Fields {
     }
   }
 
-  private static class FreqProxTermsEnum extends TermsEnum {
+  private static class FreqProxTermsEnum extends TermsEnum implements OriginalTermsSupplier{
     final FreqProxTermsWriterPerField terms;
     final int[] sortedTermIDs;
     final FreqProxPostingsArray postingsArray;
@@ -199,6 +200,11 @@ class FreqProxFields extends Fields {
     }
     
     @Override
+    public String getTwinTerm() {
+      return this.terms.twins.get(term().utf8ToString());
+    }
+    
+    @Override
     public BytesRef term() {
       return scratch;
     }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
index 28fe872..3b10130 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
@@ -17,6 +17,10 @@
 package org.apache.lucene.index;
 
 import java.io.IOException;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
@@ -44,6 +48,8 @@ final class FreqProxTermsWriterPerField extends TermsHashPerField {
    *  segment. */
   boolean sawPayloads;
 
+  public Map<String, String> twins = new HashMap<>();
+
   public FreqProxTermsWriterPerField(FieldInvertState invertState, TermsHash termsHash, FieldInfo fieldInfo, TermsHashPerField nextPerField) {
     super(fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0 ? 2 : 1, invertState, termsHash, nextPerField, fieldInfo);
     IndexOptions indexOptions = fieldInfo.getIndexOptions();
@@ -200,6 +206,22 @@ final class FreqProxTermsWriterPerField extends TermsHashPerField {
     return new FreqProxPostingsArray(size, hasFreq, hasProx, hasOffsets);
   }
   
+  private static final List<String> trickedFields = Arrays.asList("one", "body_txt_en");
+
+  @Override
+  protected void seeTwins(String reverse, String orig) {
+    List<String> dedupingFields = trickedFields;
+    if (dedupingFields.contains(fieldInfo.name)) {
+      System.out.println(reverse + "<=>"+orig + "\n|");
+      String pre = twins.put(reverse, orig);
+      //assert pre==null : pre + " " + reverse + " "+orig + ": "+ twins;
+      pre = twins.put(orig, reverse);
+      //assert pre==null : pre + " " + reverse + " "+orig + ": "+ twins;
+    } else {
+      System.out.println("ignoring "+ fieldInfo.name+ " "+reverse + "<=>"+orig+ "\n|"); 
+    }
+  }
+
   static final class FreqProxPostingsArray extends ParallelPostingsArray {
     public FreqProxPostingsArray(int size, boolean writeFreqs, boolean writeProx, boolean writeOffsets) {
       super(size);
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
index c4b1017..2b620f4 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
@@ -251,4 +251,8 @@ public abstract class TermsEnum implements BytesRefIterator {
     }
 
   };
+  
+  public interface OriginalTermsSupplier{
+    String getTwinTerm();
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
index d360adb..6e87cc6 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
@@ -98,6 +98,8 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
 
   private boolean doNextCall;
 
+  private String lastNewTerm;
+
   // Secondary entry point (for 2nd & subsequent TermsHash),
   // because token text has already been "interned" into
   // textStart, so we hash by textStart.  term vectors use
@@ -151,7 +153,7 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
     //System.out.println("add term=" + termBytesRef.utf8ToString() + " doc=" + docState.docID + " termID=" + termID);
 
     if (termID >= 0) {// New posting
-      bytesHash.byteStart(termID);
+     // bytesHash.byteStart(termID);
       // Init stream slices
       if (numPostingInt + intPool.intUpto > IntBlockPool.INT_BLOCK_SIZE) {
         intPool.nextBuffer();
@@ -175,7 +177,14 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
 
       newTerm(termID);
       
+      if (fieldState.posIncrAttribute.getPositionIncrement()==0) {
+        assert lastNewTerm!=null : lastNewTerm;
+        seeTwins(termAtt.getBytesRef().utf8ToString(), lastNewTerm);
+      }
+      lastNewTerm = termAtt.getBytesRef().utf8ToString();
     } else {
+      lastNewTerm =  null;
+      
       termID = (-termID)-1;
       int intStart = postingsArray.intStarts[termID];
       intUptos = intPool.buffers[intStart >> IntBlockPool.INT_BLOCK_SHIFT];
@@ -188,6 +197,10 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
     }
   }
 
+  protected void seeTwins(String utf8ToString, String lastNewTerm2) {
+    
+  }
+
   int[] intUptos;
   int intUptoStart;
 
diff --git a/solr/core/src/java/org/apache/solr/analysis/ReversedWildcardFilter.java b/solr/core/src/java/org/apache/solr/analysis/ReversedWildcardFilter.java
index 37fd95b..01913de 100644
--- a/solr/core/src/java/org/apache/solr/analysis/ReversedWildcardFilter.java
+++ b/solr/core/src/java/org/apache/solr/analysis/ReversedWildcardFilter.java
@@ -55,6 +55,10 @@ public final class ReversedWildcardFilter extends TokenFilter {
     if( save != null ) {
       // clearAttributes();  // not currently necessary
       restoreState(save);
+      reverseTerm();
+
+      posAtt.setPositionIncrement(0);
+//      posAtt.setPositionIncrement(origOffset);
       save = null;
       return true;
     }
@@ -62,20 +66,23 @@ public final class ReversedWildcardFilter extends TokenFilter {
     if (!input.incrementToken()) return false;
 
     // pass through zero-length terms
-    int oldLen = termAtt.length();
-    if (oldLen ==0) return true;
-    int origOffset = posAtt.getPositionIncrement();
+    int oldLength = termAtt.length();
+    if (oldLength ==0) return true;
+    //int origOffset = posAtt.getPositionIncrement();
     if (withOriginal == true){
-      posAtt.setPositionIncrement(0);
       save = captureState();
+    } else {
+      reverseTerm();
     }
+    return true;
+  }
+
+  protected void reverseTerm() {
+    int oldLen = termAtt.length();
     char [] buffer = termAtt.resizeBuffer(oldLen + 1);
     buffer[oldLen] = markerChar;
     reverse(buffer, 0, oldLen + 1);
-
-    posAtt.setPositionIncrement(origOffset);
     termAtt.copyBuffer(buffer, 0, oldLen +1);
-    return true;
   }
   
 
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestReversedWildcardFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestReversedWildcardFilterFactory.java
index f7a49ac..d491f30 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestReversedWildcardFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestReversedWildcardFilterFactory.java
@@ -53,7 +53,8 @@ public class TestReversedWildcardFilterFactory extends SolrTestCaseJ4 {
 
   @BeforeClass
   public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml","schema-reversed.xml");
+    //System.setProperty("enable.update.log", "false");
+    initCore("solrconfig.xml","schema-reversed.xml");//-light
   }
   
   @Override
@@ -72,7 +73,7 @@ public class TestReversedWildcardFilterFactory extends SolrTestCaseJ4 {
     ReversedWildcardFilterFactory factory = new ReversedWildcardFilterFactory(args);
     TokenStream input = factory.create(whitespaceMockTokenizer(text));
     assertTokenStreamContents(input, 
-        new String[] { "\u0001elpmis", "simple", "\u0001txet", "text" },
+        new String[] {  "simple","\u0001elpmis", "text" ,  "\u0001txet"},
         new int[] { 1, 0, 1, 0 });
 
     // now without original tokens
@@ -92,8 +93,8 @@ public class TestReversedWildcardFilterFactory extends SolrTestCaseJ4 {
     // field one
     TokenStream input = a.tokenStream("one", text);
     assertTokenStreamContents(input,
-        new String[] { "\u0001eno", "one", "\u0001owt", "two", 
-          "\u0001eerht", "three", "\u0001x\uD834\uDD1Eis", "si\uD834\uDD1Ex" },
+        new String[] {  "one", "\u0001eno", "two",  "\u0001owt",
+            "three","\u0001eerht", "si\uD834\uDD1Ex" ,  "\u0001x\uD834\uDD1Eis" },
         new int[] { 0, 0, 4, 4, 8, 8, 14, 14 },
         new int[] { 3, 3, 7, 7, 13, 13, 19, 19 },
         new int[] { 1, 0, 1, 0, 1, 0, 1, 0 }
@@ -119,26 +120,42 @@ public class TestReversedWildcardFilterFactory extends SolrTestCaseJ4 {
   @Test
   public void testQueryParsing() throws Exception {
 
+    int loops = atLeast(1000);
+    for(int i=0;i<loops ;i++){
       // add some docs
-    assertU(adoc("id", "1", "one", "one"));
-    assertU(adoc("id", "2", "two", "two"));
-    assertU(adoc("id", "3", "three", "three"));
-    assertU(adoc("id", "4", "one", "four"));
-    assertU(adoc("id", "5", "two", "five"));
-    assertU(adoc("id", "6", "three", "si\uD834\uDD1Ex"));
+      assertU(adoc("id", ""+(i*10+1), "one", "one" , "one", "one"));
+      assertU(adoc("id", ""+(i*10+2), "two", "two"));
+      assertU(adoc("id", ""+(i*10+3), "three", "three"));
+      assertU(adoc("id", ""+(i*10+4), "one", "four", "one", "one"));
+      assertU(adoc("id", ""+(i*10+5), "two", "five"));
+      assertU(adoc("id", ""+(i*10+6), "three", "si\uD834\uDD1Ex"));
+    }
     assertU(commit());
     
     assertQ("should have matched",
+        req("one:f*ur"),
+        "//result[@numFound="+loops+"]");
+    
+    assertQ("should have matched",
         req("+id:1 +one:one"),
-        "//result[@numFound=1]");
+        "//result[@numFound="+1+"]");
     
     assertQ("should have matched",
         req("+id:4 +one:f*ur"),
-        "//result[@numFound=1]");
+        "//result[@numFound="+1+"]");
         
     assertQ("should have matched",
         req("+id:6 +three:*si\uD834\uDD1Ex"),
-        "//result[@numFound=1]");
+        "//result[@numFound="+1+"]");
+    
+    assertQ("should have matched",
+        req("one:one"),
+        "//result[@numFound="+loops*2+"]");
+    
+        
+    assertQ("should have matched",
+        req("three:*si\uD834\uDD1Ex"),
+        "//result[@numFound="+loops+"]");
 
     SolrQueryRequest req = req();
     QParser qparser = QParser.getParser("id:1", req);
