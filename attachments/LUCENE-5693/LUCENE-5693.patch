Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java	(revision 1596627)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java	(working copy)
@@ -17,15 +17,13 @@
  * limitations under the License.
  */
 
-import static org.apache.lucene.index.SortedSetDocValues.NO_MORE_ORDS;
-
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.lucene42.Lucene42DocValuesFormat;
 import org.apache.lucene.document.BinaryDocValuesField;
 import org.apache.lucene.document.Document;
@@ -47,14 +45,17 @@
 import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
+import static org.apache.lucene.index.SortedSetDocValues.NO_MORE_ORDS;
+
 public class TestFieldCacheVsDocValues extends LuceneTestCase {
   
   public void testByteMissingVsFieldCache() throws Exception {
@@ -328,7 +329,7 @@
       AtomicReader r = context.reader();
       SortedDocValues expected = FieldCache.DEFAULT.getTermsIndex(r, "indexed");
       SortedDocValues actual = r.getSortedDocValues("dv");
-      assertEquals(r.maxDoc(), expected, actual);
+      assertEquals(r.maxDoc(), r.getLiveDocs(), expected, actual);
     }
     ir.close();
     dir.close();
@@ -391,7 +392,7 @@
       AtomicReader r = context.reader();
       SortedSetDocValues expected = FieldCache.DEFAULT.getDocTermOrds(r, "indexed", null);
       SortedSetDocValues actual = r.getSortedSetDocValues("dv");
-      assertEquals(r.maxDoc(), expected, actual);
+      assertEquals(r.maxDoc(), r.getLiveDocs(), expected, actual);
     }
     ir.close();
     
@@ -402,7 +403,7 @@
     AtomicReader ar = getOnlySegmentReader(ir);
     SortedSetDocValues expected = FieldCache.DEFAULT.getDocTermOrds(ar, "indexed", null);
     SortedSetDocValues actual = ar.getSortedSetDocValues("dv");
-    assertEquals(ir.maxDoc(), expected, actual);
+    assertEquals(ir.maxDoc(), ar.getLiveDocs(), expected, actual);
     ir.close();
     
     writer.shutdown();
@@ -487,102 +488,149 @@
     }
   }
   
-  private void assertEquals(int maxDoc, SortedDocValues expected, SortedDocValues actual) throws Exception {
-    assertEquals(maxDoc, DocValues.singleton(expected), DocValues.singleton(actual));
+  private void assertEquals(int maxDoc, Bits liveDocs, SortedDocValues expected, SortedDocValues actual) throws Exception {
+    assertEquals(maxDoc, liveDocs, DocValues.singleton(expected), DocValues.singleton(actual));
   }
   
-  private void assertEquals(int maxDoc, SortedSetDocValues expected, SortedSetDocValues actual) throws Exception {
+  private void assertEquals(int maxDoc, Bits liveDocs, SortedSetDocValues expected, SortedSetDocValues actual) throws Exception {
     // can be null for the segment if no docs actually had any SortedDocValues
     // in this case FC.getDocTermsOrds returns EMPTY
     if (actual == null) {
       assertEquals(DocValues.EMPTY_SORTED_SET, expected);
       return;
     }
-    assertEquals(expected.getValueCount(), actual.getValueCount());
-    // compare ord lists
+
+    FixedBitSet liveOrdsExpected = new FixedBitSet((int) expected.getValueCount());
+    FixedBitSet liveOrdsActual = new FixedBitSet((int) actual.getValueCount());
+
+    BytesRef expectedBytes = new BytesRef();
+    BytesRef actualBytes = new BytesRef();
+
+    // compare values for all live docs:
     for (int i = 0; i < maxDoc; i++) {
+      if (liveDocs != null && liveDocs.get(i) == false) {
+        // Don't check deleted docs
+        continue;
+      }
       expected.setDocument(i);
       actual.setDocument(i);
       long expectedOrd;
       while ((expectedOrd = expected.nextOrd()) != NO_MORE_ORDS) {
-        assertEquals(expectedOrd, actual.nextOrd());
+        expected.lookupOrd(expectedOrd, expectedBytes);
+        long actualOrd = actual.nextOrd();
+        assertTrue(actualOrd != NO_MORE_ORDS);
+        actual.lookupOrd(actualOrd, actualBytes);
+        assertEquals(expectedBytes, actualBytes);
+        liveOrdsExpected.set((int) expectedOrd);
+        liveOrdsActual.set((int) actualOrd);
       }
+
       assertEquals(NO_MORE_ORDS, actual.nextOrd());
     }
+
+    // Make sure both have same number of non-deleted values:
+    assertEquals(liveOrdsExpected.cardinality(), liveOrdsActual.cardinality());
     
     // compare ord dictionary
-    BytesRef expectedBytes = new BytesRef();
-    BytesRef actualBytes = new BytesRef();
-    for (long i = 0; i < expected.getValueCount(); i++) {
-      expected.lookupTerm(expectedBytes);
-      actual.lookupTerm(actualBytes);
+    int expectedOrd = 0;
+    int actualOrd = 0;
+    while (expectedOrd < expected.getValueCount()) {
+      expectedOrd = liveOrdsExpected.nextSetBit(expectedOrd);
+      if (expectedOrd == -1) {
+        break;
+      }
+      actualOrd = liveOrdsActual.nextSetBit(actualOrd);
+      expected.lookupOrd(expectedOrd, expectedBytes);
+      actual.lookupOrd(actualOrd, actualBytes);
       assertEquals(expectedBytes, actualBytes);
+      expectedOrd++;
+      actualOrd++;
     }
+    assertTrue(actualOrd == actual.getValueCount() || liveOrdsActual.nextSetBit(actualOrd) == -1);
     
     // compare termsenum
-    assertEquals(expected.getValueCount(), expected.termsEnum(), actual.termsEnum());
+    assertEquals(expected.getValueCount(), expected.termsEnum(), liveOrdsExpected, actual.termsEnum(), liveOrdsActual);
   }
-  
-  private void assertEquals(long numOrds, TermsEnum expected, TermsEnum actual) throws Exception {
+
+  /** Does termsEnum.next() but then skips over deleted ords. */
+  private static BytesRef next(TermsEnum termsEnum, Bits liveOrds) throws IOException {
+    while (termsEnum.next() != null) {
+      if (liveOrds.get((int) termsEnum.ord())) {
+        return termsEnum.term();
+      }
+    }
+    return null;
+  }
+
+  /** Does termsEnum.seekCeil() but then skips over deleted ords. */
+  private static SeekStatus seekCeil(TermsEnum termsEnum, BytesRef term, Bits liveOrds) throws IOException {
+    SeekStatus status = termsEnum.seekCeil(term);
+    if (status == SeekStatus.END) {
+      return status;
+    } else {
+      if (liveOrds.get((int) termsEnum.ord()) == false) {
+        while (termsEnum.next() != null) {
+          if (liveOrds.get((int) termsEnum.ord())) {
+            return SeekStatus.NOT_FOUND;
+          }
+        }
+        return SeekStatus.END;
+      } else {
+        return status;
+      }
+    }
+  }
+
+  private void assertEquals(long numOrds, TermsEnum expected, Bits liveOrdsExpected, TermsEnum actual, Bits liveOrdsActual) throws Exception {
     BytesRef ref;
     
     // sequential next() through all terms
-    while ((ref = expected.next()) != null) {
-      assertEquals(ref, actual.next());
-      assertEquals(expected.ord(), actual.ord());
+    while ((ref = next(expected, liveOrdsExpected)) != null) {
+      assertEquals(ref, next(actual, liveOrdsActual));
       assertEquals(expected.term(), actual.term());
     }
-    assertNull(actual.next());
+    assertNull(next(actual, liveOrdsActual));
     
-    // sequential seekExact(ord) through all terms
-    for (long i = 0; i < numOrds; i++) {
-      expected.seekExact(i);
-      actual.seekExact(i);
-      assertEquals(expected.ord(), actual.ord());
-      assertEquals(expected.term(), actual.term());
-    }
-    
     // sequential seekExact(BytesRef) through all terms
     for (long i = 0; i < numOrds; i++) {
+      if (liveOrdsExpected.get((int) i) == false) {
+        continue;
+      }
       expected.seekExact(i);
       assertTrue(actual.seekExact(expected.term()));
-      assertEquals(expected.ord(), actual.ord());
       assertEquals(expected.term(), actual.term());
     }
     
     // sequential seekCeil(BytesRef) through all terms
     for (long i = 0; i < numOrds; i++) {
+      if (liveOrdsExpected.get((int) i) == false) {
+        continue;
+      }
       expected.seekExact(i);
       assertEquals(SeekStatus.FOUND, actual.seekCeil(expected.term()));
-      assertEquals(expected.ord(), actual.ord());
       assertEquals(expected.term(), actual.term());
     }
     
-    // random seekExact(ord)
-    for (long i = 0; i < numOrds; i++) {
-      long randomOrd = TestUtil.nextLong(random(), 0, numOrds - 1);
-      expected.seekExact(randomOrd);
-      actual.seekExact(randomOrd);
-      assertEquals(expected.ord(), actual.ord());
-      assertEquals(expected.term(), actual.term());
-    }
-    
     // random seekExact(BytesRef)
     for (long i = 0; i < numOrds; i++) {
       long randomOrd = TestUtil.nextLong(random(), 0, numOrds - 1);
+      if (liveOrdsExpected.get((int) randomOrd) == false) {
+        continue;
+      }
       expected.seekExact(randomOrd);
       actual.seekExact(expected.term());
-      assertEquals(expected.ord(), actual.ord());
       assertEquals(expected.term(), actual.term());
     }
     
     // random seekCeil(BytesRef)
     for (long i = 0; i < numOrds; i++) {
+      if (liveOrdsExpected.get((int) i) == false) {
+        continue;
+      }
       BytesRef target = new BytesRef(TestUtil.randomUnicodeString(random()));
-      SeekStatus expectedStatus = expected.seekCeil(target);
-      assertEquals(expectedStatus, actual.seekCeil(target));
+      SeekStatus expectedStatus = seekCeil(expected, target, liveOrdsExpected);
+      assertEquals(expectedStatus, seekCeil(actual, target, liveOrdsActual));
       if (expectedStatus != SeekStatus.END) {
-        assertEquals(expected.ord(), actual.ord());
         assertEquals(expected.term(), actual.term());
       }
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1596627)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -508,7 +508,7 @@
     writer.shutdown();
     IndexReader reader = DirectoryReader.open(dir);
     final Term t = new Term("content", "aa");
-    assertEquals(3, reader.docFreq(t));
+    assertEquals(2, reader.docFreq(t));
 
     // Make sure the doc that hit the exception was marked
     // as deleted:
@@ -648,7 +648,7 @@
       IndexReader reader = DirectoryReader.open(dir);
       if (i == 0) { 
         int expected = 5;
-        assertEquals(expected, reader.docFreq(new Term("contents", "here")));
+        assertEquals(expected-1, reader.docFreq(new Term("contents", "here")));
         assertEquals(expected, reader.maxDoc());
         int numDel = 0;
         final Bits liveDocs = MultiFields.getLiveDocs(reader);
@@ -760,8 +760,8 @@
 
       IndexReader reader = DirectoryReader.open(dir);
       int expected = (3+(1-i)*2)*NUM_THREAD*NUM_ITER;
-      assertEquals("i=" + i, expected, reader.docFreq(new Term("contents", "here")));
-      assertEquals(expected, reader.maxDoc());
+      assertEquals("i=" + i, expected - NUM_THREAD*NUM_ITER, reader.docFreq(new Term("contents", "here")));
+      assertEquals("i=" + i, expected, reader.maxDoc());
       int numDel = 0;
       final Bits liveDocs = MultiFields.getLiveDocs(reader);
       assertNotNull(liveDocs);
Index: lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(revision 1596627)
+++ lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(working copy)
@@ -123,14 +123,18 @@
         }
         
         DocsEnum docsEnum = TestUtil.docs(random(), reader, "field", term, liveDocs, null, DocsEnum.FLAG_NONE);
-        assertNotNull(docsEnum);
-
-        for(int docID : docs.get(term)) {
-          if (!deleted.contains(docID)) {
-            assertEquals(docID, docsEnum.nextDoc());
+        if (docsEnum == null) {
+          for(int docID : docs.get(term)) {
+            assert deleted.contains(docID);
           }
+        } else {
+          for(int docID : docs.get(term)) {
+            if (!deleted.contains(docID)) {
+              assertEquals(docID, docsEnum.nextDoc());
+            }
+          }
+          assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
         }
-        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
       }
 
       reader.close();
Index: lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(revision 1596627)
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(working copy)
@@ -1637,16 +1637,15 @@
           // Again, with the one doc deleted:
           checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, false, true, infoStream, verbose);
 
-          // Only agg stats if the doc is live:
-          final boolean doStats = liveDocs == null || liveDocs.get(j);
-          if (doStats) {
-            status.docCount++;
+          if (liveDocs != null && liveDocs.get(j) == false) {
+            // Only check live docs
+            continue;
           }
 
+          status.docCount++;
+
           for(String field : tfv) {
-            if (doStats) {
-              status.totVectors++;
-            }
+            status.totVectors++;
 
             // Make sure FieldInfo thinks this field is vector'd:
             final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
Index: lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java	(revision 1596627)
+++ lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java	(working copy)
@@ -37,6 +37,8 @@
 class FreqProxFields extends Fields {
   final Map<String,FreqProxTermsWriterPerField> fields = new LinkedHashMap<>();
 
+  private Bits liveDocs;
+
   public FreqProxFields(List<FreqProxTermsWriterPerField> fieldList) {
     // NOTE: fields are already sorted by field name
     for(FreqProxTermsWriterPerField field : fieldList) {
@@ -44,6 +46,10 @@
     }
   }
 
+  public void setLiveDocs(Bits liveDocs) {
+    this.liveDocs = liveDocs;
+  }
+
   public Iterator<String> iterator() {
     return fields.keySet().iterator();
   }
@@ -51,7 +57,7 @@
   @Override
   public Terms terms(String field) throws IOException {
     FreqProxTermsWriterPerField perField = fields.get(field);
-    return perField == null ? null : new FreqProxTerms(perField);
+    return perField == null ? null : new FreqProxTerms(perField, liveDocs);
   }
 
   @Override
@@ -62,9 +68,11 @@
 
   private static class FreqProxTerms extends Terms {
     final FreqProxTermsWriterPerField terms;
+    final Bits liveDocs;
 
-    public FreqProxTerms(FreqProxTermsWriterPerField terms) {
+    public FreqProxTerms(FreqProxTermsWriterPerField terms, Bits liveDocs) {
       this.terms = terms;
+      this.liveDocs = liveDocs;
     }
 
     @Override
@@ -72,8 +80,9 @@
       FreqProxTermsEnum termsEnum;
       if (reuse instanceof FreqProxTermsEnum && ((FreqProxTermsEnum) reuse).terms == this.terms) {
         termsEnum = (FreqProxTermsEnum) reuse;
+        assert termsEnum.liveDocs == this.liveDocs;
       } else {
-        termsEnum = new FreqProxTermsEnum(terms);
+        termsEnum = new FreqProxTermsEnum(terms, liveDocs);
       }
       termsEnum.reset();
       return termsEnum;
@@ -136,11 +145,13 @@
     final FreqProxPostingsArray postingsArray;
     final BytesRef scratch = new BytesRef();
     final int numTerms;
+    final Bits liveDocs;
     int ord;
 
-    public FreqProxTermsEnum(FreqProxTermsWriterPerField terms) {
+    public FreqProxTermsEnum(FreqProxTermsWriterPerField terms, Bits liveDocs) {
       this.terms = terms;
       this.numTerms = terms.bytesHash.size();
+      this.liveDocs = liveDocs;
       sortedTermIDs = terms.sortedTermIDs;
       assert sortedTermIDs != null;
       postingsArray = (FreqProxPostingsArray) terms.postingsArray;
@@ -228,8 +239,8 @@
     }
 
     @Override
-    public DocsEnum docs(Bits liveDocs, DocsEnum reuse, int flags) {
-      if (liveDocs != null) {
+    public DocsEnum docs(Bits liveDocsIn, DocsEnum reuse, int flags) {
+      if (liveDocsIn != null) {
         throw new IllegalArgumentException("liveDocs must be null");
       }
 
@@ -244,18 +255,20 @@
       if (reuse instanceof FreqProxDocsEnum) {
         docsEnum = (FreqProxDocsEnum) reuse;
         if (docsEnum.postingsArray != postingsArray) {
-          docsEnum = new FreqProxDocsEnum(terms, postingsArray);
+          docsEnum = new FreqProxDocsEnum(terms, postingsArray, liveDocs);
+        } else {
+          assert docsEnum.liveDocs == liveDocs;
         }
       } else {
-        docsEnum = new FreqProxDocsEnum(terms, postingsArray);
+        docsEnum = new FreqProxDocsEnum(terms, postingsArray, liveDocs);
       }
       docsEnum.reset(sortedTermIDs[ord]);
       return docsEnum;
     }
 
     @Override
-    public DocsAndPositionsEnum docsAndPositions(Bits liveDocs, DocsAndPositionsEnum reuse, int flags) {
-      if (liveDocs != null) {
+    public DocsAndPositionsEnum docsAndPositions(Bits liveDocsIn, DocsAndPositionsEnum reuse, int flags) {
+      if (liveDocsIn != null) {
         throw new IllegalArgumentException("liveDocs must be null");
       }
       FreqProxDocsAndPositionsEnum posEnum;
@@ -275,10 +288,12 @@
       if (reuse instanceof FreqProxDocsAndPositionsEnum) {
         posEnum = (FreqProxDocsAndPositionsEnum) reuse;
         if (posEnum.postingsArray != postingsArray) {
-          posEnum = new FreqProxDocsAndPositionsEnum(terms, postingsArray);
+          posEnum = new FreqProxDocsAndPositionsEnum(terms, postingsArray, liveDocs);
+        } else {
+          assert posEnum.liveDocs == liveDocs;
         }
       } else {
-        posEnum = new FreqProxDocsAndPositionsEnum(terms, postingsArray);
+        posEnum = new FreqProxDocsAndPositionsEnum(terms, postingsArray, liveDocs);
       }
       posEnum.reset(sortedTermIDs[ord]);
       return posEnum;
@@ -311,15 +326,17 @@
     final FreqProxPostingsArray postingsArray;
     final ByteSliceReader reader = new ByteSliceReader();
     final boolean readTermFreq;
+    final Bits liveDocs;
     int docID;
     int freq;
     boolean ended;
     int termID;
 
-    public FreqProxDocsEnum(FreqProxTermsWriterPerField terms, FreqProxPostingsArray postingsArray) {
+    public FreqProxDocsEnum(FreqProxTermsWriterPerField terms, FreqProxPostingsArray postingsArray, Bits liveDocs) {
       this.terms = terms;
       this.postingsArray = postingsArray;
       this.readTermFreq = terms.hasFreq;
+      this.liveDocs = liveDocs;
     }
 
     public void reset(int termID) {
@@ -347,33 +364,39 @@
 
     @Override
     public int nextDoc() throws IOException {
-      if (reader.eof()) {
-        if (ended) {
-          return NO_MORE_DOCS;
-        } else {
-          ended = true;
-          docID = postingsArray.lastDocIDs[termID];
-          if (readTermFreq) {
-            freq = postingsArray.termFreqs[termID];
+      while (true) {
+        if (reader.eof()) {
+          if (ended) {
+            return NO_MORE_DOCS;
+          } else {
+            ended = true;
+            docID = postingsArray.lastDocIDs[termID];
+            if (readTermFreq) {
+              freq = postingsArray.termFreqs[termID];
+            }
           }
-        }
-      } else {
-        int code = reader.readVInt();
-        if (!readTermFreq) {
-          docID += code;
         } else {
-          docID += code >>> 1;
-          if ((code & 1) != 0) {
-            freq = 1;
+          int code = reader.readVInt();
+          if (!readTermFreq) {
+            docID += code;
           } else {
-            freq = reader.readVInt();
+            docID += code >>> 1;
+            if ((code & 1) != 0) {
+              freq = 1;
+            } else {
+              freq = reader.readVInt();
+            }
           }
+
+          assert docID != postingsArray.lastDocIDs[termID];
         }
 
-        assert docID != postingsArray.lastDocIDs[termID];
+        if (liveDocs != null && liveDocs.get(docID) == false) {
+          continue;
+        }
+
+        return docID;
       }
-
-      return docID;
     }
 
     @Override
@@ -394,6 +417,7 @@
     final ByteSliceReader reader = new ByteSliceReader();
     final ByteSliceReader posReader = new ByteSliceReader();
     final boolean readOffsets;
+    final Bits liveDocs;
     int docID;
     int freq;
     int pos;
@@ -405,10 +429,11 @@
     boolean hasPayload;
     BytesRef payload = new BytesRef();
 
-    public FreqProxDocsAndPositionsEnum(FreqProxTermsWriterPerField terms, FreqProxPostingsArray postingsArray) {
+    public FreqProxDocsAndPositionsEnum(FreqProxTermsWriterPerField terms, FreqProxPostingsArray postingsArray, Bits liveDocs) {
       this.terms = terms;
       this.postingsArray = postingsArray;
       this.readOffsets = terms.hasOffsets;
+      this.liveDocs = liveDocs;
       assert terms.hasProx;
       assert terms.hasFreq;
     }
@@ -434,34 +459,40 @@
 
     @Override
     public int nextDoc() throws IOException {
-      while (posLeft != 0) {
-        nextPosition();
-      }
+      while (true) {
+        while (posLeft != 0) {
+          nextPosition();
+        }
 
-      if (reader.eof()) {
-        if (ended) {
-          return NO_MORE_DOCS;
+        if (reader.eof()) {
+          if (ended) {
+            return NO_MORE_DOCS;
+          } else {
+            ended = true;
+            docID = postingsArray.lastDocIDs[termID];
+            freq = postingsArray.termFreqs[termID];
+          }
         } else {
-          ended = true;
-          docID = postingsArray.lastDocIDs[termID];
-          freq = postingsArray.termFreqs[termID];
+          int code = reader.readVInt();
+          docID += code >>> 1;
+          if ((code & 1) != 0) {
+            freq = 1;
+          } else {
+            freq = reader.readVInt();
+          }
+
+          assert docID != postingsArray.lastDocIDs[termID];
         }
-      } else {
-        int code = reader.readVInt();
-        docID += code >>> 1;
-        if ((code & 1) != 0) {
-          freq = 1;
-        } else {
-          freq = reader.readVInt();
+
+        posLeft = freq;
+        pos = 0;
+        startOffset = 0;
+        if (liveDocs != null && liveDocs.get(docID) == false) {
+          continue;
         }
 
-        assert docID != postingsArray.lastDocIDs[termID];
+        return docID;
       }
-
-      posLeft = freq;
-      pos = 0;
-      startOffset = 0;
-      return docID;
     }
 
     @Override
Index: lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(revision 1596627)
+++ lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(working copy)
@@ -34,6 +34,7 @@
   }
 
   private void applyDeletes(SegmentWriteState state, Fields fields) throws IOException {
+
     // Process any pending Term deletes for this newly
     // flushed segment:
     if (state.segUpdates != null && state.segUpdates.terms.size() > 0) {
@@ -98,10 +99,14 @@
     // Sort by field name
     CollectionUtil.introSort(allFields);
 
-    Fields fields = new FreqProxFields(allFields);
+    FreqProxFields fields = new FreqProxFields(allFields);
 
     applyDeletes(state, fields);
 
+    if (state.liveDocs != null) {
+      fields.setLiveDocs(state.liveDocs);
+    }
+
     FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);
     boolean success = false;
     try {
Index: lucene/core/src/java/org/apache/lucene/index/SegmentWriteState.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SegmentWriteState.java	(revision 1596627)
+++ lucene/core/src/java/org/apache/lucene/index/SegmentWriteState.java	(working copy)
@@ -105,5 +105,6 @@
     this.segmentSuffix = segmentSuffix;
     segUpdates = state.segUpdates;
     delCountOnFlush = state.delCountOnFlush;
+    liveDocs = state.liveDocs;
   }
 }
Index: lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(revision 1596627)
+++ lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(working copy)
@@ -94,6 +94,8 @@
     // aborting on any exception from this method
 
     int numDocs = state.segmentInfo.getDocCount();
+
+    // TODO: we could set liveDocs earlier and then fix DVs to also not write deleted docs:
     writeNorms(state);
     writeDocValues(state);
     
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(revision 1596627)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(working copy)
@@ -623,9 +623,15 @@
       System.out.println("TEST: reader=" + r);
       System.out.println("TEST: joinReader=" + joinR);
 
+      Bits liveDocs = MultiFields.getLiveDocs(joinR);
       for(int docIDX=0;docIDX<joinR.maxDoc();docIDX++) {
-        System.out.println("  docID=" + docIDX + " doc=" + joinR.document(docIDX));
+        System.out.println("  docID=" + docIDX + " doc=" + joinR.document(docIDX) + " deleted?=" + (liveDocs != null && liveDocs.get(docIDX) == false));
       }
+      DocsEnum parents = MultiFields.getTermDocsEnum(joinR, null, "isParent", new BytesRef("x"));
+      System.out.println("parent docIDs:");
+      while (parents.nextDoc() != parents.NO_MORE_DOCS) {
+        System.out.println("  " + parents.docID());
+      }
     }
 
     final IndexSearcher s = newSearcher(r);
@@ -823,6 +829,7 @@
           Explanation explanation = joinS.explain(childJoinQuery, hit.doc);
           StoredDocument document = joinS.doc(hit.doc - 1);
           int childId = Integer.parseInt(document.get("childID"));
+          //System.out.println("  hit docID=" + hit.doc + " childId=" + childId + " parentId=" + document.get("parentID"));
           assertTrue(explanation.isMatch());
           assertEquals(hit.score, explanation.getValue(), 0.0f);
           assertEquals(String.format(Locale.ROOT, "Score based on child doc range from %d to %d", hit.doc - 1 - childId, hit.doc - 1), explanation.getDescription());
Index: lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java	(revision 1596627)
+++ lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java	(working copy)
@@ -381,7 +381,7 @@
     @Override
     public int advance(int parentTarget) throws IOException {
 
-      //System.out.println("Q.advance parentTarget=" + parentTarget);
+      // System.out.println("Q.advance parentTarget=" + parentTarget);
       if (parentTarget == NO_MORE_DOCS) {
         return parentDoc = NO_MORE_DOCS;
       }
@@ -398,13 +398,13 @@
 
       prevParentDoc = parentBits.prevSetBit(parentTarget-1);
 
-      //System.out.println("  rolled back to prevParentDoc=" + prevParentDoc + " vs parentDoc=" + parentDoc);
+      // System.out.println("  rolled back to prevParentDoc=" + prevParentDoc + " vs parentDoc=" + parentDoc);
       assert prevParentDoc >= parentDoc;
       if (prevParentDoc > nextChildDoc) {
         nextChildDoc = childScorer.advance(prevParentDoc);
         // System.out.println("  childScorer advanced to child docID=" + nextChildDoc);
-      //} else {
-        //System.out.println("  skip childScorer advance");
+      } else {
+        // System.out.println("  skip childScorer advance");
       }
 
       // Parent & child docs are supposed to be orthogonal:
@@ -413,15 +413,21 @@
       }
 
       final int nd = nextDoc();
-      //System.out.println("  return nextParentDoc=" + nd);
+      // System.out.println("  return nextParentDoc=" + nd);
       return nd;
     }
 
     public Explanation explain(int docBase) throws IOException {
-      int start = docBase + prevParentDoc + 1; // +1 b/c prevParentDoc is previous parent doc
-      int end = docBase + parentDoc - 1; // -1 b/c parentDoc is parent doc
+      int start = prevParentDoc + 1; // +1 b/c prevParentDoc is previous parent doc
+      if (acceptDocs != null) {
+        // Skip deleted docs:
+        while (acceptDocs.get(start) == false) {
+          start++;
+        }
+      }
+      int end = parentDoc - 1; // -1 b/c parentDoc is parent doc
       return new ComplexExplanation(
-          true, score(), String.format(Locale.ROOT, "Score based on child doc range from %d to %d", start, end)
+          true, score(), String.format(Locale.ROOT, "Score based on child doc range from %d to %d", docBase+start, docBase+end)
       );
     }
 
