Index: src/java/org/apache/lucene/analysis/CharReader.java
===================================================================
--- src/java/org/apache/lucene/analysis/CharReader.java	(revision 897474)
+++ src/java/org/apache/lucene/analysis/CharReader.java	(working copy)
@@ -28,7 +28,7 @@
  */
 public final class CharReader extends CharStream {
 
-  protected Reader input;
+  private final Reader input;
   
   public static CharStream get(Reader input) {
     return input instanceof CharStream ?
Index: src/java/org/apache/lucene/index/FieldsReader.java
===================================================================
--- src/java/org/apache/lucene/index/FieldsReader.java	(revision 897474)
+++ src/java/org/apache/lucene/index/FieldsReader.java	(working copy)
@@ -164,7 +164,7 @@
   /**
    * @throws AlreadyClosedException if this FieldsReader is closed
    */
-  protected final void ensureOpen() throws AlreadyClosedException {
+  private void ensureOpen() throws AlreadyClosedException {
     if (closed) {
       throw new AlreadyClosedException("this FieldsReader is closed");
     }
Index: contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java
===================================================================
--- contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java	(revision 897474)
+++ contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java	(working copy)
@@ -34,7 +34,9 @@
 
   public void testPayloads() throws Exception {
     String test = "The quick|JJ red|JJ fox|NN jumped|VB over the lazy|JJ brown|JJ dogs|NN";
-    DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)));
+    DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter
+      (new WhitespaceTokenizer(new StringReader(test)), 
+       DelimitedPayloadTokenFilter.DEFAULT_DELIMITER, new IdentityEncoder());
     TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
     PayloadAttribute payAtt = filter.getAttribute(PayloadAttribute.class);
     assertTermEquals("The", filter, termAtt, payAtt, null);
@@ -53,7 +55,9 @@
   public void testNext() throws Exception {
 
     String test = "The quick|JJ red|JJ fox|NN jumped|VB over the lazy|JJ brown|JJ dogs|NN";
-    DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)));
+    DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter
+      (new WhitespaceTokenizer(new StringReader(test)), 
+       DelimitedPayloadTokenFilter.DEFAULT_DELIMITER, new IdentityEncoder());
     assertTermEquals("The", filter, null);
     assertTermEquals("quick", filter, "JJ".getBytes("UTF-8"));
     assertTermEquals("red", filter, "JJ".getBytes("UTF-8"));
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapper.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapper.java	(revision 897474)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapper.java	(working copy)
@@ -33,9 +33,9 @@
  */
 public final class ShingleAnalyzerWrapper extends Analyzer {
 
-  protected Analyzer defaultAnalyzer;
-  protected int maxShingleSize = 2;
-  protected boolean outputUnigrams = true;
+  private final Analyzer defaultAnalyzer;
+  private int maxShingleSize = 2;
+  private boolean outputUnigrams = true;
 
   public ShingleAnalyzerWrapper(Analyzer defaultAnalyzer) {
     super();
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java	(revision 897474)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java	(working copy)
@@ -30,8 +30,8 @@
 
 public final class ArabicNormalizationFilter extends TokenFilter {
 
-  protected ArabicNormalizer normalizer = null;
-  private TermAttribute termAtt;
+  private final ArabicNormalizer normalizer;
+  private final TermAttribute termAtt;
   
   public ArabicNormalizationFilter(TokenStream input) {
     super(input);
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java	(revision 897474)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java	(working copy)
@@ -64,23 +64,16 @@
     }
   }
 
-  private int minGram;
-  private int maxGram;
+  private final int minGram;
+  private final int maxGram;
   private Side side;
   private char[] curTermBuffer;
   private int curTermLength;
   private int curGramSize;
   
-  private TermAttribute termAtt;
-  private OffsetAttribute offsetAtt;
+  private final TermAttribute termAtt;
+  private final OffsetAttribute offsetAtt;
 
-
-  protected EdgeNGramTokenFilter(TokenStream input) {
-    super(input);
-    this.termAtt = addAttribute(TermAttribute.class);
-    this.offsetAtt = addAttribute(OffsetAttribute.class);
-  }
-
   /**
    * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range
    *
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java	(revision 897474)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java	(working copy)
@@ -38,19 +38,12 @@
  */
 public final class DelimitedPayloadTokenFilter extends TokenFilter {
   public static final char DEFAULT_DELIMITER = '|';
-  protected char delimiter = DEFAULT_DELIMITER;
-  protected TermAttribute termAtt;
-  protected PayloadAttribute payAtt;
-  protected PayloadEncoder encoder;
+  private final char delimiter;
+  private final TermAttribute termAtt;
+  private final PayloadAttribute payAtt;
+  private final PayloadEncoder encoder;
 
-  /**
-   * Construct a token stream filtering the given input.
-   */
-  protected DelimitedPayloadTokenFilter(TokenStream input) {
-    this(input, DEFAULT_DELIMITER, new IdentityEncoder());
-  }
 
-
   public DelimitedPayloadTokenFilter(TokenStream input, char delimiter, PayloadEncoder encoder) {
     super(input);
     termAtt = addAttribute(TermAttribute.class);
