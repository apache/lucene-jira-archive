From 1065aa529be18e9eea7d439e3cc8c09d1ef0a34d Mon Sep 17 00:00:00 2001
From: Varun Thacker <varunthacker1989@gmail.com>
Date: Fri, 6 Jun 2014 18:28:47 +0530
Subject: [PATCH] LUCENE-5688


diff --git lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesConsumer.java lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesConsumer.java
new file mode 100644
index 0000000..e915d66
--- /dev/null
+++ lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesConsumer.java
@@ -0,0 +1,162 @@
+package org.apache.lucene.codecs.sparsedv;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.lucene45.Lucene45DocValuesFormat;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.packed.BlockPackedWriter;
+import org.apache.lucene.util.packed.MonotonicBlockPackedWriter;
+import org.apache.lucene.util.packed.PackedInts;
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.Iterator;
+
+class SparseDocValuesConsumer extends DocValuesConsumer implements Closeable{
+
+  private static final int BLOCK_SIZE = 16384;
+  IndexOutput posData, valueData, meta;
+  final int maxDoc;
+
+
+  public SparseDocValuesConsumer(SegmentWriteState state, String dataCodec, String posDataExtension, String valueDataExtension,
+                                 String metaCodec, String metaExtension) throws IOException {
+    boolean success = false;
+    try {
+      String posDataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, posDataExtension);
+      posData = state.directory.createOutput(posDataName, state.context);
+      CodecUtil.writeHeader(posData, dataCodec, SparseDocValuesFormat.VERSION_CURRENT);
+
+      String valueDataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, valueDataExtension);
+      valueData = state.directory.createOutput(valueDataName, state.context);
+      CodecUtil.writeHeader(valueData, dataCodec, SparseDocValuesFormat.VERSION_CURRENT);
+
+      String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+      meta = state.directory.createOutput(metaName, state.context);
+      CodecUtil.writeHeader(meta, metaCodec, SparseDocValuesFormat.VERSION_CURRENT);
+      maxDoc = state.segmentInfo.getDocCount();
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this);
+      }
+    }
+  }
+
+  @Override
+  public void addNumericField(FieldInfo field, Iterable<Number> values) throws IOException {
+    meta.writeVInt(field.number);
+    meta.writeByte(SparseDocValuesFormat.NUMERIC);
+    //meta.writeVInt(format);
+    meta.writeLong(valueData.getFilePointer());
+    meta.writeLong(posData.getFilePointer());
+    writeMissingBitset(values);
+    meta.writeVInt(PackedInts.VERSION_CURRENT);
+    meta.writeLong(valueData.getFilePointer());
+
+    long count =0;
+    for (Number nv : values) {
+      if(nv != null) {
+        count++;
+      }
+    }
+    meta.writeVLong(count);
+    meta.writeVInt(BLOCK_SIZE);
+
+    final MonotonicBlockPackedWriter positionWriter = new MonotonicBlockPackedWriter(posData, BLOCK_SIZE);
+    final BlockPackedWriter valueWriter = new BlockPackedWriter(valueData, BLOCK_SIZE);
+    int pos=0;
+    for (Number nv : values) {
+      if(nv != null) {
+        positionWriter.add(pos);
+        valueWriter.add(nv.longValue());
+      }
+      pos++;
+    }
+    positionWriter.finish();
+    valueWriter.finish();
+  }
+
+  // TODO: in some cases representing missing with minValue-1 wouldn't take up additional space and so on,
+  // but this is very simple, and algorithms only check this for values of 0 anyway (doesnt slow down normal decode)
+  void writeMissingBitset(Iterable<?> values) throws IOException {
+    byte bits = 0;
+    int count = 0;
+    for (Object v : values) {
+      if (count == 8) {
+        valueData.writeByte(bits);
+        count = 0;
+        bits = 0;
+      }
+      if (v != null) {
+        bits |= 1 << (count & 7);
+      }
+      count++;
+    }
+    if (count > 0) {
+      valueData.writeByte(bits);
+    }
+  }
+
+  @Override
+  public void addBinaryField(FieldInfo field, Iterable<BytesRef> values) throws IOException {
+
+  }
+
+  @Override
+  public void addSortedField(FieldInfo field, Iterable<BytesRef> values, Iterable<Number> docToOrd) throws IOException {
+
+  }
+
+  @Override
+  public void addSortedSetField(FieldInfo field, Iterable<BytesRef> values, Iterable<Number> docToOrdCount, Iterable<Number> ords) throws IOException {
+
+  }
+
+  @Override
+  public void close() throws IOException {
+    boolean success = false;
+    try {
+      if (meta != null) {
+        meta.writeVInt(-1); // write EOF marker
+        CodecUtil.writeFooter(meta); // write checksum
+      }
+      if (posData != null) {
+        CodecUtil.writeFooter(posData); // write checksum
+      }
+      if (valueData != null) {
+        CodecUtil.writeFooter(valueData); // write checksum
+      }
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(posData,valueData, meta);
+      } else {
+        IOUtils.closeWhileHandlingException(posData, valueData, meta);
+      }
+      meta = posData = valueData = null;
+    }
+  }
+}
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesFormat.java lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesFormat.java
new file mode 100644
index 0000000..44034a2
--- /dev/null
+++ lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesFormat.java
@@ -0,0 +1,59 @@
+package org.apache.lucene.codecs.sparsedv;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+
+import java.io.IOException;
+
+public final class SparseDocValuesFormat  extends DocValuesFormat {
+
+  public SparseDocValuesFormat() {
+    super("Sparse");
+  }
+
+  @Override
+  public DocValuesConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
+    return new SparseDocValuesConsumer(state, DATA_CODEC, POS_DATA_EXTENSION, VALUE_DATA_EXTENSION, META_CODEC, META_EXTENSION);
+  }
+
+  @Override
+  public DocValuesProducer fieldsProducer(SegmentReadState state) throws IOException {
+    return new SparseDocValuesProducer(state, DATA_CODEC, POS_DATA_EXTENSION, VALUE_DATA_EXTENSION, META_CODEC, META_EXTENSION);
+  }
+
+  //nocommit better extension names.
+  public static final String DATA_CODEC = "SparseDocValuesData";
+  public static final String POS_DATA_EXTENSION = "dvdp";
+  public static final String VALUE_DATA_EXTENSION = "dvdv";
+  public static final String META_CODEC = "SparseDocValuesMetadata";
+  public static final String META_EXTENSION = "dvm";
+
+  static final int VERSION_START = 0;
+  static final int VERSION_CHECKSUM = 1;
+  static final int VERSION_CURRENT = VERSION_CHECKSUM;
+  static final byte NUMERIC = 0;
+  static final byte BINARY = 1;
+  static final byte SORTED = 2;
+  static final byte SORTED_SET = 3;
+
+}
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesProducer.java lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesProducer.java
new file mode 100644
index 0000000..8a4b72a
--- /dev/null
+++ lucene/codecs/src/java/org/apache/lucene/codecs/sparsedv/SparseDocValuesProducer.java
@@ -0,0 +1,360 @@
+package org.apache.lucene.codecs.sparsedv;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.store.ChecksumIndexInput;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LongValues;
+import org.apache.lucene.util.RamUsageEstimator;
+import org.apache.lucene.util.packed.BlockPackedReader;
+import org.apache.lucene.util.packed.MonotonicBlockPackedReader;
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicLong;
+
+class SparseDocValuesProducer extends DocValuesProducer implements Closeable {
+
+  // metadata maps (just file pointers and minimal stuff)
+  private final Map<Integer,NumericEntry> numerics = new HashMap<>();
+  private final Map<Integer,BinaryEntry> binaries = new HashMap<>();
+  private final Map<Integer,SortedEntry> sorteds = new HashMap<>();
+  private final Map<Integer,SortedSetEntry> sortedSets = new HashMap<>();
+
+  private final int version;
+  private final int maxDoc;
+  private final IndexInput posData;
+  private final AtomicLong ramBytesUsed;
+  private final IndexInput valData;
+
+
+  public SparseDocValuesProducer(SegmentReadState state, String dataCodec, String posDataExtension,
+                                 String valueDataExtension, String metaCodec, String metaExtension) throws IOException {
+    maxDoc = state.segmentInfo.getDocCount();
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+    // read in the entries from the metadata file.
+    ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);
+    boolean success = false;
+    try {
+      version = CodecUtil.checkHeader(in, metaCodec,
+          SparseDocValuesFormat.VERSION_START,
+          SparseDocValuesFormat.VERSION_CURRENT);
+      readFields(in);
+
+      if (version >= SparseDocValuesFormat.VERSION_CHECKSUM) {
+        CodecUtil.checkFooter(in);
+      } else {
+        CodecUtil.checkEOF(in);
+      }
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(in);
+      } else {
+        IOUtils.closeWhileHandlingException(in);
+      }
+    }
+
+    success = false;
+
+    String posDataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, posDataExtension);
+    posData = state.directory.openInput(posDataName, state.context);
+    try {
+      final int version2 = CodecUtil.checkHeader(posData, dataCodec,
+          SparseDocValuesFormat.VERSION_START,
+          SparseDocValuesFormat.VERSION_CURRENT);
+      if (version != version2) {
+        throw new CorruptIndexException("Format versions mismatch");
+      }
+
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this.posData);
+      }
+    }
+
+    success = false;
+
+    String valueDataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, valueDataExtension);
+    valData = state.directory.openInput(valueDataName, state.context);
+    try {
+      final int version2 = CodecUtil.checkHeader(valData, dataCodec,
+          SparseDocValuesFormat.VERSION_START,
+          SparseDocValuesFormat.VERSION_CURRENT);
+      if (version != version2) {
+        throw new CorruptIndexException("Format versions mismatch");
+      }
+
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this.posData);
+      }
+    }
+
+
+    ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));
+  }
+
+  @Override
+  public NumericDocValues getNumeric(FieldInfo field) throws IOException {
+    NumericEntry entry = numerics.get(field.number);
+    return getNumericUsingHashMap(entry);
+  }
+
+  private LongValues getNumericUsingBinarySearch(NumericEntry entry) throws IOException {
+    final IndexInput valData = this.valData.clone();
+    valData.seek(entry.valDataoffset);
+    final BlockPackedReader valReader = new BlockPackedReader(valData, entry.packedIntsVersion, entry.blockSize, entry.count, true);
+
+    final IndexInput posData = this.posData.clone();
+    valData.seek(entry.posDataoffset); //nocommit - It's always 28 (Only headers have been written). Use a constant instead?
+    final MonotonicBlockPackedReader posReader = MonotonicBlockPackedReader.of(posData, entry.packedIntsVersion, entry.blockSize, entry.count, true);
+
+    final Bits bits = getMissingBits(entry.missingOffset);
+
+    return new LongValues() {
+      @Override
+      public long get(long id) {
+        boolean bit = bits.get((int) id);
+        if(!bit) { //This doc does does not have a value. Return default value
+          return 0;
+        } else {
+          //binary search on the position reader and use that index id to retrieve the actual value from the value reader.
+          long position = binarySearch(posReader, id);
+          long value = valReader.get((int) position);
+          return value;
+        }
+      }
+    };
+
+  }
+
+  private LongValues getNumericUsingHashMap(NumericEntry entry) throws IOException {
+    final IndexInput valData = this.valData.clone();
+    valData.seek(entry.valDataoffset);
+    final BlockPackedReader valReader = new BlockPackedReader(valData, entry.packedIntsVersion, entry.blockSize, entry.count, true);
+
+    final IndexInput posData = this.posData.clone();
+    valData.seek(entry.posDataoffset); //nocommit - It's always 28 (Only headers have been written). Use a constant instead?
+    final MonotonicBlockPackedReader posReader = MonotonicBlockPackedReader.of(posData, entry.packedIntsVersion, entry.blockSize, entry.count, true);
+
+    final Map<Integer, Long> values = new HashMap<>();
+    for(int i=0; i<entry.count; i++) {
+      int pos = (int) posReader.get(i);
+      long value = valReader.get(i);
+      values.put(pos, value);
+    }
+    return new LongValues() {
+      @Override
+      public long get(long idx) {
+        return values.containsKey((int)idx) == false ? 0 : values.get((int)idx).longValue();
+      }
+    };
+
+  }
+
+  private long binarySearch(MonotonicBlockPackedReader posReader, long id) {
+    int low = 0;
+    int high = (int) posReader.size();
+    while (low <= high) {
+      int middle = (low+high) /2;
+      long value = posReader.get(middle);
+      if(id > value) {
+        low = middle +1;
+      } else if (id < value) {
+        high = middle - 1;
+      } else {
+        return middle;
+      }
+    }
+    return -1;
+  }
+
+  @Override
+  public BinaryDocValues getBinary(FieldInfo field) throws IOException {
+    return null;
+  }
+
+  @Override
+  public SortedDocValues getSorted(FieldInfo field) throws IOException {
+    return null;
+  }
+
+  @Override
+  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
+    return null;
+  }
+
+  @Override
+  public Bits getDocsWithField(FieldInfo field) throws IOException {
+    switch(field.getDocValuesType()) {
+      case SORTED_SET:
+        return DocValues.docsWithValue(getSortedSet(field), maxDoc);
+      case SORTED:
+        return DocValues.docsWithValue(getSorted(field), maxDoc);
+      case BINARY:
+        BinaryEntry be = binaries.get(field.number);
+        return getMissingBits(be.missingOffset);
+      case NUMERIC:
+        NumericEntry ne = numerics.get(field.number);
+        return getMissingBits(ne.missingOffset);
+      default:
+        throw new AssertionError();
+    }
+  }
+
+  private Bits getMissingBits(final long offset) throws IOException {
+    if (offset == -1) {
+      return new Bits.MatchAllBits(maxDoc);
+    } else {
+      final IndexInput in = valData.clone();
+      return new Bits() {
+
+        @Override
+        public boolean get(int index) {
+          try {
+            in.seek(offset + (index >> 3));
+            return (in.readByte() & (1 << (index & 7))) != 0;
+          } catch (IOException e) {
+            throw new RuntimeException(e);
+          }
+        }
+
+        @Override
+        public int length() {
+          return maxDoc;
+        }
+      };
+    }
+  }
+
+  @Override
+  public long ramBytesUsed() {
+    return ramBytesUsed.get();
+  }
+
+  @Override
+  public void checkIntegrity() throws IOException {
+    if (version >= SparseDocValuesFormat.VERSION_CHECKSUM) {
+      CodecUtil.checksumEntireFile(posData);
+    }
+  }
+
+  @Override
+  public void close() throws IOException {
+    valData.close();
+    posData.close();
+  }
+
+  private void readFields(IndexInput meta) throws IOException {
+    int fieldNumber = meta.readVInt();
+    while (fieldNumber != -1) {
+
+      byte type = meta.readByte();
+      if(type == SparseDocValuesFormat.NUMERIC) {
+        numerics.put(fieldNumber, readNumericEntry(meta));
+      }
+      fieldNumber = meta.readVInt();
+    }
+
+  }
+
+  static NumericEntry readNumericEntry(IndexInput meta) throws IOException {
+    NumericEntry entry = new NumericEntry();
+    entry.missingOffset = meta.readLong();
+    entry.posDataoffset = meta.readLong();
+    entry.packedIntsVersion = meta.readVInt();
+    entry.valDataoffset = meta.readLong();
+    entry.count = meta.readVLong();
+    entry.blockSize = meta.readVInt();
+    return entry;
+  }
+
+  /** metadata entry for a numeric docvalues field */
+  protected static class NumericEntry {
+    private NumericEntry() {}
+    /** offset to the bitset representing docsWithField, or -1 if no documents have missing values */
+    long missingOffset;
+    /** offset to the actual numeric values */
+    public long valDataoffset;
+    public long posDataoffset;
+
+    /** packed ints version used to encode these numerics */
+    public int packedIntsVersion;
+    /** count of values written */
+    public long count;
+    /** packed ints blocksize */
+    public int blockSize;
+  }
+
+  /** metadata entry for a binary docvalues field */
+  protected static class BinaryEntry {
+    private BinaryEntry() {}
+    /** offset to the bitset representing docsWithField, or -1 if no documents have missing values */
+    long missingOffset;
+    /** offset to the actual binary values */
+    long offset;
+
+    int format;
+    /** count of values written */
+    public long count;
+    int minLength;
+    int maxLength;
+    /** offset to the addressing data that maps a value to its slice of the byte[] */
+    public long addressesOffset;
+    /** interval of shared prefix chunks (when using prefix-compressed binary) */
+    public long addressInterval;
+    /** packed ints version used to encode addressing information */
+    public int packedIntsVersion;
+    /** packed ints blocksize */
+    public int blockSize;
+  }
+
+  protected static class SortedEntry {
+    NumericEntry docToOrd;
+    BinaryEntry values;
+  }
+
+  protected static class SortedSetEntry {
+    NumericEntry docToOrdAddress;
+    NumericEntry ords;
+    BinaryEntry values;
+  }
+
+
+
+
+}
diff --git lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
index 4171acf..67523ed 100644
--- lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
+++ lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
@@ -17,3 +17,4 @@ org.apache.lucene.codecs.diskdv.DiskDocValuesFormat
 org.apache.lucene.codecs.memory.MemoryDocValuesFormat
 org.apache.lucene.codecs.memory.DirectDocValuesFormat
 org.apache.lucene.codecs.simpletext.SimpleTextDocValuesFormat
+org.apache.lucene.codecs.sparsedv.SparseDocValuesFormat
diff --git lucene/core/src/test/org/apache/lucene/index/TestSparseDV.java lucene/core/src/test/org/apache/lucene/index/TestSparseDV.java
new file mode 100644
index 0000000..a85fe31
--- /dev/null
+++ lucene/core/src/test/org/apache/lucene/index/TestSparseDV.java
@@ -0,0 +1,99 @@
+package org.apache.lucene.index;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.lucene46.Lucene46Codec;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.store.BaseDirectoryWrapper;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.io.IOException;
+
+public class TestSparseDV extends LuceneTestCase {
+
+  BaseDirectoryWrapper dir;
+  DirectoryReader r;
+
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+  }
+
+  @Test
+  public void testSparseDVCodec() throws IOException {
+    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
+        .setUseCompoundFile(false)
+        .setMergePolicy(NoMergePolicy.INSTANCE)
+        .setCodec(new Lucene46Codec() {
+          public DocValuesFormat getDocValuesFormatForField(String field) {
+              return DocValuesFormat.forName("Sparse");
+          }
+        })
+    );
+
+    int numDocs = random().nextInt(100000);
+    long[] actualValues = new long[numDocs];
+    for (int i = 0; i < numDocs; i++) {
+      Document doc = new Document();
+      doc.add(new StringField("id", Integer.toString(i), Field.Store.NO));
+
+      if( TestUtil.nextInt(random(), 1, 10) == 1 ) {
+        actualValues[i] = random().nextLong();
+        NumericDocValuesField dvField = new NumericDocValuesField("dv", actualValues[i]);
+        doc.add(dvField);
+      }
+
+      w.addDocument(doc);
+    }
+    w.commit();
+    w.shutdown();
+
+    r = DirectoryReader.open(dir);
+    for (AtomicReaderContext context : r.leaves()) {
+      AtomicReader reader = context.reader();
+      NumericDocValues dv = reader.getNumericDocValues("dv");
+      for (int i = 0; i < reader.maxDoc(); i++) {
+        assertEquals(Integer.toString(i) + " When maxDoc= "  + reader.maxDoc(), actualValues[i], dv.get(i));
+      }
+    }
+
+
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    r.close();
+    dir.close();
+    super.tearDown();
+  }
+
+
+}
-- 
1.8.5.2 (Apple Git-48)

