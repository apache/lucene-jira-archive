diff --git a/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesFieldUpdates.java b/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesFieldUpdates.java
index 3faad496eb..db9aa091f3 100644
--- a/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesFieldUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/BinaryDocValuesFieldUpdates.java
@@ -33,7 +33,7 @@ import org.apache.lucene.util.packed.PagedMutable;
  * 
  * @lucene.experimental
  */
-class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
+final class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
   
   final static class Iterator extends DocValuesFieldUpdates.Iterator {
     private final int size;
@@ -55,14 +55,14 @@ class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
       value = values.clone();
       this.delGen = delGen;
     }
-    
+
     @Override
-    BytesRef value() {
+    BytesRef binaryValue() {
       value.offset = offset;
       value.length = length;
       return value;
     }
-    
+
     @Override
     public int nextDoc() {
       if (idx >= size) {
@@ -94,6 +94,11 @@ class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
     long delGen() {
       return delGen;
     }
+
+    @Override
+    long longValue() {
+      throw new UnsupportedOperationException();
+    }
   }
 
   private PagedMutable docs;
@@ -116,9 +121,18 @@ class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
     return size;
   }
 
-  // NOTE: we fully consume the incoming BytesRef so caller is free to reuse it after we return:
   @Override
-  synchronized public void add(int doc, Object value) {
+  public void add(int doc, long value) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public void add(int docId, DocValuesFieldUpdates.Iterator iterator) {
+    add(docId, iterator.binaryValue());
+  }
+
+  @Override
+  synchronized public void add(int doc, BytesRef value) {
     if (finished) {
       throw new IllegalStateException("already finished");
     }
@@ -130,8 +144,6 @@ class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
       throw new IllegalStateException("cannot support more than Integer.MAX_VALUE doc/value entries");
     }
 
-    BytesRef val = (BytesRef) value;
-    
     // grow the structures to have room for more elements
     if (docs.size() == size) {
       docs = docs.grow(size + 1);
@@ -141,8 +153,8 @@ class BinaryDocValuesFieldUpdates extends DocValuesFieldUpdates {
     
     docs.set(size, doc);
     offsets.set(size, values.length());
-    lengths.set(size, val.length);
-    values.append(val);
+    lengths.set(size, value.length);
+    values.append(value);
     ++size;
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdates.java b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdates.java
index a5a86e6774..4b98a9c58e 100644
--- a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdates.java
@@ -24,6 +24,8 @@ import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
+import java.util.function.Function;
+import java.util.function.IntFunction;
 
 import org.apache.lucene.index.DocValuesUpdate.BinaryDocValuesUpdate;
 import org.apache.lucene.index.DocValuesUpdate.NumericDocValuesUpdate;
@@ -233,62 +235,49 @@ class BufferedUpdates {
     }
   }
  
-  public void addNumericUpdate(NumericDocValuesUpdate update, int docIDUpto) {
-    LinkedHashMap<Term,NumericDocValuesUpdate> fieldUpdates = numericUpdates.get(update.field);
-    if (fieldUpdates == null) {
-      fieldUpdates = new LinkedHashMap<>();
-      numericUpdates.put(update.field, fieldUpdates);
-      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);
-    }
-    final NumericDocValuesUpdate current = fieldUpdates.get(update.term);
-    if (current != null && docIDUpto < current.docIDUpto) {
-      // Only record the new number if it's greater than or equal to the current
-      // one. This is important because if multiple threads are replacing the
-      // same doc at nearly the same time, it's possible that one thread that
-      // got a higher docID is scheduled before the other threads.
-      return;
-    }
-
-    update.docIDUpto = docIDUpto;
-    // since it's a LinkedHashMap, we must first remove the Term entry so that
-    // it's added last (we're interested in insertion-order).
-    if (current != null) {
-      fieldUpdates.remove(update.term);
-    }
-    fieldUpdates.put(update.term, update);
-    numNumericUpdates.incrementAndGet();
-    if (current == null) {
-      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());
+  void addNumericUpdate(NumericDocValuesUpdate update, int docIDUpto) {
+    if (addDocValuesUpdate(numericUpdates, update, docIDUpto, update::prepareForApply, BYTES_PER_NUMERIC_UPDATE_ENTRY,
+        BYTES_PER_NUMERIC_FIELD_ENTRY)) {
+      numNumericUpdates.incrementAndGet();
     }
   }
   
-  public void addBinaryUpdate(BinaryDocValuesUpdate update, int docIDUpto) {
-    LinkedHashMap<Term,BinaryDocValuesUpdate> fieldUpdates = binaryUpdates.get(update.field);
+  void addBinaryUpdate(BinaryDocValuesUpdate update, int docIDUpto) {
+    if (addDocValuesUpdate(binaryUpdates, update, docIDUpto, update::prepareForApply, BYTES_PER_BINARY_UPDATE_ENTRY,
+        BYTES_PER_BINARY_FIELD_ENTRY)) {
+      numBinaryUpdates.incrementAndGet();
+    }
+  }
+
+  private <T extends DocValuesUpdate> boolean addDocValuesUpdate(Map<String,LinkedHashMap<Term,T>> updates, T update,
+                                                                 int docIDUpto, IntFunction<T> prepareForApply,
+                                                                 long bytesPerUpdateEntry, long bytesPerFieldEntry) {
+    LinkedHashMap<Term,T> fieldUpdates = updates.get(update.field);
     if (fieldUpdates == null) {
       fieldUpdates = new LinkedHashMap<>();
-      binaryUpdates.put(update.field, fieldUpdates);
-      bytesUsed.addAndGet(BYTES_PER_BINARY_FIELD_ENTRY);
+      updates.put(update.field, fieldUpdates);
+      bytesUsed.addAndGet(bytesPerFieldEntry);
     }
-    final BinaryDocValuesUpdate current = fieldUpdates.get(update.term);
+    final T current = fieldUpdates.get(update.term);
     if (current != null && docIDUpto < current.docIDUpto) {
       // Only record the new number if it's greater than or equal to the current
       // one. This is important because if multiple threads are replacing the
       // same doc at nearly the same time, it's possible that one thread that
       // got a higher docID is scheduled before the other threads.
-      return;
+      return false;
     }
-    
-    update.docIDUpto = docIDUpto;
+
     // since it's a LinkedHashMap, we must first remove the Term entry so that
     // it's added last (we're interested in insertion-order).
     if (current != null) {
       fieldUpdates.remove(update.term);
     }
-    fieldUpdates.put(update.term, update);
-    numBinaryUpdates.incrementAndGet();
+
+    fieldUpdates.put(update.term, prepareForApply.apply(docIDUpto)); // only make a copy if necessary
     if (current == null) {
-      bytesUsed.addAndGet(BYTES_PER_BINARY_UPDATE_ENTRY + update.sizeInBytes());
+      bytesUsed.addAndGet(bytesPerUpdateEntry + update.sizeInBytes());
     }
+    return true;
   }
 
   void clearDeleteTerms() {
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocValuesFieldUpdates.java b/lucene/core/src/java/org/apache/lucene/index/DocValuesFieldUpdates.java
index a711f79f4d..8142047822 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocValuesFieldUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocValuesFieldUpdates.java
@@ -51,13 +51,18 @@ abstract class DocValuesFieldUpdates {
       throw new UnsupportedOperationException();
     }
 
+    @Override
     public abstract int nextDoc(); // no IOException
 
     /**
-     * Returns the value of the document returned from {@link #nextDoc()}. A
-     * {@code null} value means that it was unset for this document.
+     * Returns a long value for the current document if this iterator is a long iterator.
+     */
+    abstract long longValue();
+
+    /**
+     * Returns a binary value for the current document if this iterator is a binary value iterator.
      */
-    abstract Object value();
+    abstract BytesRef binaryValue();
 
     /** Returns delGen for this packet. */
     abstract long delGen();
@@ -73,7 +78,7 @@ abstract class DocValuesFieldUpdates {
         }
         @Override
         public BytesRef binaryValue() {
-          return (BytesRef) iterator.value();
+          return iterator.binaryValue();
         }
         @Override
         public boolean advanceExact(int target) {
@@ -100,7 +105,7 @@ abstract class DocValuesFieldUpdates {
       return new NumericDocValues() {
         @Override
         public long longValue() {
-          return ((Long)iterator.value()).longValue();
+          return iterator.longValue();
         }
         @Override
         public boolean advanceExact(int target) {
@@ -195,15 +200,20 @@ abstract class DocValuesFieldUpdates {
         }
         return doc;
       }
-        
+
       @Override
       public int docID() {
         return doc;
       }
 
       @Override
-      public Object value() {
-        return queue.top().value();
+      long longValue() {
+        return queue.top().longValue();
+      }
+
+      @Override
+      BytesRef binaryValue() {
+        return queue.top().binaryValue();
       }
 
       @Override
@@ -233,12 +243,17 @@ abstract class DocValuesFieldUpdates {
     return finished;
   }
   
+  public abstract void add(int doc, long value);
+
+  public abstract void add(int doc, BytesRef value);
+
   /**
-   * Add an update to a document. For unsetting a value you should pass
-   * {@code null}.
+   * Adds the value for the given docID.
+   * This method prevents conditional calls to {@link Iterator#longValue()} or {@link Iterator#binaryValue()}
+   * since the implementation knows if it's a long value iterator or binary value
    */
-  public abstract void add(int doc, Object value);
-  
+  public abstract void add(int docId, Iterator iterator);
+
   /**
    * Returns an {@link Iterator} over the updated documents and their
    * values.
@@ -256,4 +271,5 @@ abstract class DocValuesFieldUpdates {
   public abstract long ramBytesUsed();
 
   public abstract int size();
+
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocValuesUpdate.java b/lucene/core/src/java/org/apache/lucene/index/DocValuesUpdate.java
index a66f930085..495a17487c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocValuesUpdate.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocValuesUpdate.java
@@ -38,21 +38,30 @@ abstract class DocValuesUpdate {
   final DocValuesType type;
   final Term term;
   final String field;
-  final Object value;
-  int docIDUpto = -1; // unassigned until applied, and confusing that it's here, when it's just used in BufferedDeletes...
+  // used in BufferedDeletes to apply this update only to a slice of docs. It's initialized to BufferedUpdates.MAX_INT
+  // since it's safe and most often used this way we safe object creations.
+  final int docIDUpto;
 
   /**
    * Constructor.
    * 
    * @param term the {@link Term} which determines the documents that will be updated
    * @param field the {@link NumericDocValuesField} to update
-   * @param value the updated value
    */
-  protected DocValuesUpdate(DocValuesType type, Term term, String field, Object value) {
+  protected DocValuesUpdate(DocValuesType type, Term term, String field, int docIDUpto) {
+    assert docIDUpto >= 0 : docIDUpto + "must be >= 0";
     this.type = type;
     this.term = term;
     this.field = field;
-    this.value = value;
+    this.docIDUpto = docIDUpto;
+  }
+
+  long longValue() {
+    throw new UnsupportedOperationException();
+  }
+
+  BytesRef binaryValue() {
+    throw new UnsupportedOperationException();
   }
 
   abstract long valueSizeInBytes();
@@ -65,38 +74,86 @@ abstract class DocValuesUpdate {
     sizeInBytes += valueSizeInBytes();
     return sizeInBytes;
   }
+
+  protected abstract String valueToString();
   
   @Override
   public String toString() {
-    return "term=" + term + ",field=" + field + ",value=" + value + ",docIDUpto=" + docIDUpto;
+    return "term=" + term + ",field=" + field + ",value=" + valueToString() + ",docIDUpto=" + docIDUpto;
   }
   
   /** An in-place update to a binary DocValues field */
   static final class BinaryDocValuesUpdate extends DocValuesUpdate {
+    private final BytesRef value;
     
     /* Size of BytesRef: 2*INT + ARRAY_HEADER + PTR */
     private static final long RAW_VALUE_SIZE_IN_BYTES = NUM_BYTES_ARRAY_HEADER + 2*Integer.BYTES + NUM_BYTES_OBJECT_REF;
-    
+
     BinaryDocValuesUpdate(Term term, String field, BytesRef value) {
-      super(DocValuesType.BINARY, term, field, value);
+      this(term, field, value, BufferedUpdates.MAX_INT);
+    }
+    
+    private BinaryDocValuesUpdate(Term term, String field, BytesRef value, int docIDUpTo) {
+      super(DocValuesType.BINARY, term, field, docIDUpTo);
+      this.value = value;
+    }
+
+    BinaryDocValuesUpdate prepareForApply(int docIDUpto) {
+      if (docIDUpto == this.docIDUpto) {
+        return this; // it's a final value so we can safely reuse this instance
+      }
+      return new BinaryDocValuesUpdate(term, field, value, docIDUpto);
+    }
+
+    @Override
+    BytesRef binaryValue() {
+      return value;
     }
 
     @Override
     long valueSizeInBytes() {
-      return RAW_VALUE_SIZE_IN_BYTES + ((BytesRef) value).bytes.length;
+      return RAW_VALUE_SIZE_IN_BYTES + value.bytes.length;
+    }
+
+    @Override
+    protected String valueToString() {
+      return value.toString();
     }
   }
 
   /** An in-place update to a numeric DocValues field */
   static final class NumericDocValuesUpdate extends DocValuesUpdate {
+    private final long value;
+
+    NumericDocValuesUpdate(Term term, String field, long value) {
+      this(term, field, value, BufferedUpdates.MAX_INT);
+    }
+
+    private NumericDocValuesUpdate(Term term, String field, long value, int docIDUpTo) {
+      super(DocValuesType.NUMERIC, term, field, docIDUpTo);
+      this.value = value;
+    }
 
-    NumericDocValuesUpdate(Term term, String field, Long value) {
-      super(DocValuesType.NUMERIC, term, field, value);
+    NumericDocValuesUpdate prepareForApply(int docIDUpto) {
+      if (docIDUpto == this.docIDUpto) {
+        return this;
+      }
+      return new NumericDocValuesUpdate(term, field, value, docIDUpto);
+    }
+
+    @Override
+    long longValue() {
+      return value;
     }
 
     @Override
     long valueSizeInBytes() {
       return Long.BYTES;
     }
+
+    @Override
+    protected String valueToString() {
+      return Long.toString(value);
+    }
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
index ad9c0d1627..62338499b3 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
@@ -412,10 +412,10 @@ final class DocumentsWriterDeleteQueue implements Accountable {
       for (DocValuesUpdate update : item) {
         switch (update.type) {
           case NUMERIC:
-            bufferedUpdates.addNumericUpdate(new NumericDocValuesUpdate(update.term, update.field, (Long) update.value), docIDUpto);
+            bufferedUpdates.addNumericUpdate((NumericDocValuesUpdate) update, docIDUpto);
             break;
           case BINARY:
-            bufferedUpdates.addBinaryUpdate(new BinaryDocValuesUpdate(update.term, update.field, (BytesRef) update.value), docIDUpto);
+            bufferedUpdates.addBinaryUpdate((BinaryDocValuesUpdate) update, docIDUpto);
             break;
           default:
             throw new IllegalArgumentException(update.type + " DocValues updates not supported yet!");
@@ -436,7 +436,7 @@ final class DocumentsWriterDeleteQueue implements Accountable {
       if (item.length > 0) {
         sb.append("term=").append(item[0].term).append("; updates: [");
         for (DocValuesUpdate update : item) {
-          sb.append(update.field).append(':').append(update.value).append(',');
+          sb.append(update.field).append(':').append(update.valueToString()).append(',');
         }
         sb.setCharAt(sb.length()-1, ']');
       }
diff --git a/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java b/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
index bebc05941a..04f94a2502 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
@@ -30,6 +30,9 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.function.BiConsumer;
+import java.util.function.IntConsumer;
+import java.util.function.IntPredicate;
 
 import org.apache.lucene.index.DocValuesUpdate.BinaryDocValuesUpdate;
 import org.apache.lucene.index.DocValuesUpdate.NumericDocValuesUpdate;
@@ -174,7 +177,7 @@ final class FrozenBufferedUpdates {
           }
 
           out.writeBytes(update.term.bytes().bytes, update.term.bytes().offset, update.term.bytes().length);
-          out.writeZLong(((Long) update.value).longValue());
+          out.writeZLong(update.longValue());
         }
       }
       byte[] bytes = new byte[(int) out.getFilePointer()];
@@ -217,7 +220,7 @@ final class FrozenBufferedUpdates {
           }
           out.writeBytes(update.term.bytes().bytes, update.term.bytes().offset, update.term.bytes().length);
 
-          BytesRef value = (BytesRef) update.value;
+          BytesRef value = update.binaryValue();
           out.writeVInt(value.length);
           out.writeBytes(value.bytes, value.offset, value.length);
         }
@@ -521,13 +524,13 @@ final class FrozenBufferedUpdates {
         // because we will run on the newly merged segment next:
         continue;
       }
-
+      final boolean isSegmentPrivateDeletes = privateSegment != null;
       if (numericDVUpdates.length > 0) {
-        updateCount += applyDocValuesUpdates(segState, numericDVUpdates, true);
+        updateCount += applyDocValuesUpdates(segState, numericDVUpdates, true, delGen, isSegmentPrivateDeletes);
       }
 
       if (binaryDVUpdates.length > 0) {
-        updateCount += applyDocValuesUpdates(segState, binaryDVUpdates, false);
+        updateCount += applyDocValuesUpdates(segState, binaryDVUpdates, false, delGen, isSegmentPrivateDeletes);
       }
     }
 
@@ -544,8 +547,9 @@ final class FrozenBufferedUpdates {
     return updateCount;
   }
 
-  private long applyDocValuesUpdates(BufferedUpdatesStream.SegmentState segState,
-                                     byte[] updates, boolean isNumeric) throws IOException {
+  private static long applyDocValuesUpdates(BufferedUpdatesStream.SegmentState segState, byte[] updates,
+                                            boolean isNumeric, long delGen,
+                                            boolean segmentPrivateDeletes) throws IOException {
 
     TermsEnum termsEnum = null;
     PostingsEnum postingsEnum = null;
@@ -592,9 +596,9 @@ final class FrozenBufferedUpdates {
       }
       in.readBytes(term.bytes, 0, term.length);
 
-      int limit;
+      final int limit;
       if (delGen == segState.delGen) {
-        assert privateSegment != null;
+        assert segmentPrivateDeletes;
         limit = docIDUpto;
       } else {
         limit = Integer.MAX_VALUE;
@@ -622,12 +626,14 @@ final class FrozenBufferedUpdates {
         }
       }
 
-      // TODO: can we avoid boxing here w/o fully forking this method?
-      Object value;
+      final BytesRef binaryValue;
+      final long longValue;
       if (isNumeric) {
-        value = Long.valueOf(in.readZLong());
+        longValue = in.readZLong();
+        binaryValue = null;
       } else {
-        value = scratch;
+        longValue = -1;
+        binaryValue = scratch;
         scratch.length = in.readVInt();
         if (scratch.bytes.length < scratch.length) {
           scratch.bytes = ArrayUtil.grow(scratch.bytes, scratch.length);
@@ -641,10 +647,8 @@ final class FrozenBufferedUpdates {
       }
 
       if (termsEnum.seekExact(term)) {
-
         // we don't need term frequencies for this
         postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
-
         DocValuesFieldUpdates dvUpdates = holder.get(updateField);
         if (dvUpdates == null) {
           if (isNumeric) {
@@ -652,37 +656,30 @@ final class FrozenBufferedUpdates {
           } else {
             dvUpdates = new BinaryDocValuesFieldUpdates(delGen, updateField, segState.reader.maxDoc());
           }
-
           holder.put(updateField, dvUpdates);
         }
-
-        if (segState.rld.sortMap != null && privateSegment != null) {
+        final IntConsumer docIdConsumer;
+        final DocValuesFieldUpdates update = dvUpdates;
+        if (isNumeric) {
+          docIdConsumer = doc -> update.add(doc, longValue);
+        } else {
+          docIdConsumer = doc -> update.add(doc, binaryValue);
+        }
+        final Bits acceptDocs = segState.rld.getLiveDocs();
+        final IntPredicate isLivePredicate = acceptDocs == null ? null : acceptDocs::get;
+        final IntPredicate addPredicate;
+        if (segState.rld.sortMap != null && segmentPrivateDeletes) {
           // This segment was sorted on flush; we must apply seg-private deletes carefully in this case:
-          int doc;
-          final Bits acceptDocs = segState.rld.getLiveDocs();
-          while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-
-            if (acceptDocs != null && acceptDocs.get(doc) == false) {
-              continue;
-            }
-            
-            // The limit is in the pre-sorted doc space:
-            if (segState.rld.sortMap.newToOld(doc) < limit) {
-              dvUpdates.add(doc, value);
-              updateCount++;
-            }
-          }
+          IntPredicate limitPredicate = doc -> segState.rld.sortMap.newToOld(doc) < limit;
+          addPredicate = isLivePredicate == null ? limitPredicate : isLivePredicate.and(limitPredicate);
         } else {
-          int doc;
-          final Bits acceptDocs = segState.rld.getLiveDocs();
-          while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-            if (doc >= limit) {
-              break; // no more docs that can be updated for this term
-            }
-            if (acceptDocs != null && acceptDocs.get(doc) == false) {
-              continue;
-            }
-            dvUpdates.add(doc, value);
+          IntPredicate limitPredicate = (doc -> doc < limit);
+          addPredicate = isLivePredicate == null ? limitPredicate : limitPredicate.and(isLivePredicate);
+        }
+        int doc;
+        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+          if (addPredicate.test(doc)) {
+            docIdConsumer.accept(doc);
             updateCount++;
           }
         }
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index ccbfe5c388..b209146225 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -3699,7 +3699,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
             int mappedDoc = segDocMap.get(segLeafDocMap.get(doc));
             if (mappedDoc != -1) {
               // not deleted
-              mappedUpdates.add(mappedDoc, it.value());
+              mappedUpdates.add(mappedDoc, it);
               anyDVUpdates = true;
             }
           }
diff --git a/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesFieldUpdates.java b/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesFieldUpdates.java
index 94a964354a..b0d56d1275 100644
--- a/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesFieldUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/NumericDocValuesFieldUpdates.java
@@ -18,6 +18,7 @@ package org.apache.lucene.index;
 
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InPlaceMergeSorter;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.packed.PackedInts;
@@ -31,7 +32,7 @@ import org.apache.lucene.util.packed.PagedMutable;
  * 
  * @lucene.experimental
  */
-class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
+final class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
 
   // TODO: can't this just be NumericDocValues now?  avoid boxing the long value...
   final static class Iterator extends DocValuesFieldUpdates.Iterator {
@@ -40,7 +41,7 @@ class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
     private final PagedMutable docs;
     private long idx = 0; // long so we don't overflow if size == Integer.MAX_VALUE
     private int doc = -1;
-    private Long value = null;
+    private long value;
     private final long delGen;
     
     Iterator(int size, PagedGrowableWriter values, PagedMutable docs, long delGen) {
@@ -50,15 +51,20 @@ class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
       this.delGen = delGen;
     }
     
+
     @Override
-    Long value() {
+    long longValue() {
       return value;
     }
-    
+
+    @Override
+    BytesRef binaryValue() {
+      throw new UnsupportedOperationException();
+    }
+
     @Override
     public int nextDoc() {
       if (idx >= size) {
-        value = null;
         return doc = DocIdSetIterator.NO_MORE_DOCS;
       }
       doc = (int) docs.get(idx);
@@ -68,7 +74,7 @@ class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
         ++idx;
       }
       // idx points to the "next" element
-      value = Long.valueOf(values.get(idx - 1));
+      value = values.get(idx - 1);
       return doc;
     }
     
@@ -101,28 +107,36 @@ class NumericDocValuesFieldUpdates extends DocValuesFieldUpdates {
   }
 
   @Override
-  public synchronized void add(int doc, Object value) {
+  public void add(int doc, BytesRef value) {
+    throw new UnsupportedOperationException();
+  }
+
+  @Override
+  public void add(int docId, DocValuesFieldUpdates.Iterator iterator) {
+    add(docId, iterator.longValue());
+  }
+
+  public synchronized void add(int doc, long value) {
     if (finished) {
       throw new IllegalStateException("already finished");
     }
 
     assert doc < maxDoc;
-    
+
     // TODO: if the Sorter interface changes to take long indexes, we can remove that limitation
     if (size == Integer.MAX_VALUE) {
       throw new IllegalStateException("cannot support more than Integer.MAX_VALUE doc/value entries");
     }
 
-    Long val = (Long) value;
-    
+
     // grow the structures to have room for more elements
     if (docs.size() == size) {
       docs = docs.grow(size + 1);
       values = values.grow(size + 1);
     }
-    
+
     docs.set(size, doc);
-    values.set(size, val.longValue());
+    values.set(size, value);
     ++size;
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java b/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
index d61e8edf47..b31bc49798 100644
--- a/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
@@ -146,12 +146,7 @@ final class ReadersAndUpdates {
     if (update.getFinished() == false) {
       throw new IllegalArgumentException("call finish first");
     }
-    List<DocValuesFieldUpdates> fieldUpdates = pendingDVUpdates.get(update.field);
-    if (fieldUpdates == null) {
-      fieldUpdates = new ArrayList<>();
-      pendingDVUpdates.put(update.field, fieldUpdates);
-    }
-
+    List<DocValuesFieldUpdates> fieldUpdates = pendingDVUpdates.computeIfAbsent(update.field, key -> new ArrayList<>());
     assert assertNoDupGen(fieldUpdates, update);
 
     ramBytesUsed.addAndGet(update.ramBytesUsed());
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestPendingSoftDeletes.java b/lucene/core/src/test/org/apache/lucene/index/TestPendingSoftDeletes.java
index 4df6d16e48..9119993ee8 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestPendingSoftDeletes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestPendingSoftDeletes.java
@@ -32,6 +32,7 @@ import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.StringHelper;
 import org.apache.lucene.util.Version;
@@ -201,7 +202,18 @@ public class TestPendingSoftDeletes extends TestPendingDeletes {
   private DocValuesFieldUpdates singleUpdate(List<Integer> docsDeleted, int maxDoc) {
     return new DocValuesFieldUpdates(maxDoc, 0, "_soft_deletes", DocValuesType.NUMERIC) {
       @Override
-      public void add(int doc, Object value) {
+      public void add(int doc, long value) {
+        throw new UnsupportedOperationException();
+      }
+
+      @Override
+      public void add(int doc, BytesRef value) {
+        throw new UnsupportedOperationException();
+      }
+
+      @Override
+      public void add(int docId, Iterator iterator) {
+        throw new UnsupportedOperationException();
       }
 
       @Override
@@ -216,13 +228,18 @@ public class TestPendingSoftDeletes extends TestPendingDeletes {
           }
 
           @Override
-          public int docID() {
-            return doc;
+          long longValue() {
+            return 1;
           }
 
           @Override
-          Object value() {
-            return 1;
+          BytesRef binaryValue() {
+            throw new UnsupportedOperationException();
+          }
+
+          @Override
+          public int docID() {
+            return doc;
           }
 
           @Override
