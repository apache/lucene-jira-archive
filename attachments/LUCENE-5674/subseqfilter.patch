diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilter.java
new file mode 100644
index 0000000..36bdf65
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilter.java
@@ -0,0 +1,167 @@
+package org.apache.lucene.analysis.core;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Queue;
+import java.util.LinkedList;
+import java.io.IOException;
+
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+/**
+ * Splits tokens into sub-parts and outputs consecutive sub-sequences of those.
+ */
+public final class SubSeqFilter extends TokenFilter {
+
+  public enum Anchor {
+    NONE, START, END
+  };
+
+  private CharTermAttribute charTermAttr;
+  private PositionIncrementAttribute posIncAttr;
+  private AttributeSource.State attrState;
+  private Queue<String> output;
+
+  private String sepRegexp;
+  private String glue;
+  private int minLen;
+  private int maxLen;
+  private Anchor anchor;
+  private boolean reverse;
+  private boolean withOriginal;
+
+  /**
+   * Constructs a filter which breaks tokens into sub-parts and outputs consecutive sub-sequences of those.
+   *
+   * @param ts
+   *          Input Token Stream
+   * @param sepRegexp
+   *          A regular expression used split incoming tokens into sub-parts.
+   * @param glue
+   *          A string used to concatenate sub-parts together when creating sub-sequences.
+   * @param minLen
+   *          Minimum length (in sub-parts) of output sub-sequences
+   * @param maxLen
+   *          Maximum length (in sub-parts) of output sub-sequences (0 for unlimited; negative numbers for
+   *          token length in sub-parts minus specified length)
+   * @param anchor
+   *          Anchor.START to output only prefixes, or Anchor.END to output only suffixes,
+   *          or Anchor.NONE to output any sub-sequence
+   * @param reverse
+   *          whether to reverse the order of sub-tokens in the output token
+   * @param withOriginal
+   *          whether to output also the original token
+   */
+  public SubSeqFilter(TokenStream ts, String sepRegexp, String glue, int minLen, int maxLen, Anchor anchor, boolean reverse, boolean withOriginal) {
+  
+    super(ts);
+ 
+    this.charTermAttr = addAttribute(CharTermAttribute.class);
+    this.posIncAttr = addAttribute(PositionIncrementAttribute.class);
+    this.output = new LinkedList<String>();
+  
+    this.sepRegexp = sepRegexp;
+    this.glue = glue;
+    this.minLen = minLen;
+    this.maxLen = maxLen;
+    this.anchor = anchor;
+    this.reverse = reverse;
+    this.withOriginal = withOriginal;
+  }
+
+  private String join(String[] arr, int start, int end) {
+    if (end < start)
+      return "";
+    StringBuilder sb = new StringBuilder();
+    if (!reverse) {
+      sb.append(arr[start]);
+      for (int i = start+1; i <= end; ++i) {
+        sb.append(this.glue);
+        sb.append(arr[i]);
+      }
+    } else {
+      sb.append(arr[end]);
+      for (int i = end-1; i >= start; --i) {
+        sb.append(this.glue);
+        sb.append(arr[i]);
+      }
+    }
+    return sb.toString();
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+
+    // first -- output and ready tokens
+    if (!output.isEmpty()) {
+      restoreState(attrState);
+      charTermAttr.setEmpty();
+      charTermAttr.append(output.poll());
+      posIncAttr.setPositionIncrement(0);
+      return true;
+    }
+
+    // no tokens ready in output buffer? get next token from input stream
+    if (!input.incrementToken())
+      return false;
+    attrState = captureState();
+
+    // get the text for the current token
+    String s = charTermAttr.toString();
+
+    // split into parts
+    String[] subParts = s.split(this.sepRegexp);
+
+    // if only one part -- nothing to do
+    if (subParts.length == 1)
+      return true;
+
+    // create all sub-sequences
+    int actualMaxLen = 
+      this.maxLen <= 0 ? Math.max(subParts.length + this.maxLen, 0) : Math.min(this.maxLen, subParts.length);
+
+    for (int len = this.minLen; len <= actualMaxLen; ++len) {
+
+      int i0 = 0;
+      int i1 = subParts.length - len;;
+      if (anchor == Anchor.START) {
+        i1 = i0;
+      } else if (anchor == Anchor.END) {
+        i0 = i1;
+      }
+
+      for (int i = i0; i <= i1; ++i)
+        output.add(join(subParts, i, i + len - 1));
+    }
+
+    // preserve original if so asked
+    if (withOriginal && (actualMaxLen < subParts.length || reverse))
+      output.add(s);
+
+    // output first of the generated tokens
+    charTermAttr.setEmpty();
+    charTermAttr.append(output.poll());
+    posIncAttr.setPositionIncrement(1);
+    return true;
+  }
+
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilterFactory.java
new file mode 100644
index 0000000..d05aa3c
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/SubSeqFilterFactory.java
@@ -0,0 +1,103 @@
+package org.apache.lucene.analysis.core;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+import org.apache.lucene.analysis.core.SubSeqFilter;
+
+import java.util.Locale;
+import java.util.Map;
+
+/**
+ * Factory for {@link SubSeqFilter}.
+ *
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_subseq" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer type="index"&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.SubSeqFilterFactory" sepRegexp="[.]" glue="." minLen="1" maxLen="0" withOriginal="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ * <p>
+ * All attributes are optional:
+ * </p>
+ * <ul>
+ *  <li><code>sepRegexp</code> regular expression used to break incoming tokens into sub-parts (defaults to <code>"[.]"</code>)</li>
+ *  <li><code>glue</code> string used when concatenating sub-parts (defaults to <code>"."</code>)</li>
+ *  <li><code>minLen</code> minimum length (in sub-parts) of generated token (defaults to 2)</li>
+ *  <li><code>maxLen</code> maximum length (in sub-parts) of generated token (0 means "unlimited";
+ *    negative numbers mean token length in sub-parts minus specified number; defaults to 0)
+ *  </li>
+ *  <li><code>anchor</code> can be <code>"start"</code> to output only prefixes of input token;
+ *    <code>"end"</code> to output only suffixes; or <code>"none"</code> to output any sub-sequence
+ *  </li>
+ *  <li><code>reverse</code> whether to reverse the order of sub-tokens in each output token
+ *  <li><code>withOriginal</code> whether to include the original token in the output
+ * </ul>
+ * <p>
+ */
+public class SubSeqFilterFactory extends TokenFilterFactory {
+
+  private String sepRegexp;
+  private String glue;
+  private int minLen;
+  private int maxLen;
+  private SubSeqFilter.Anchor anchor;
+  private boolean reverse;
+  private boolean withOriginal;
+
+  /** Creates a new SubSeqFilterFactory */
+  public SubSeqFilterFactory(Map<String,String> args) {
+
+    super(args);
+
+    // get args
+    sepRegexp = get(args, "sepRegexp", "[.]");
+    glue = get(args, "glue", ".");
+    minLen = getInt(args, "minLen", 2);
+    maxLen = getInt(args, "maxLen", 0);
+    String anchorStr = get(args, "anchor", "none");
+    reverse = getBoolean(args, "reverse", false);
+    withOriginal = getBoolean(args, "withOriginal", true);
+
+    // parse and validate args
+    if (minLen < 1)
+      throw new IllegalArgumentException("Invalid minLen: " + minLen);
+
+    if (maxLen > 0 && minLen > maxLen)
+      throw new IllegalArgumentException("Invalid minLen: minLen > maxLen");
+
+    String anchorStrToLookup = anchorStr.toUpperCase(Locale.ROOT);
+    try {
+      anchor = SubSeqFilter.Anchor.valueOf(anchorStrToLookup);
+    } catch (IllegalArgumentException exc) {
+      throw new IllegalArgumentException("Invalid anchor: " + anchorStr);
+    }
+
+    if (!args.isEmpty())
+      throw new IllegalArgumentException("Unknown parameters: " + args);
+  }
+
+  @Override
+  public TokenStream create(TokenStream ts) {
+    return new SubSeqFilter(ts, sepRegexp, glue, minLen, maxLen, anchor, reverse, withOriginal);
+  }
+
+}
diff --git a/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
index c0a4719..a1426db 100644
--- a/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
+++ b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
@@ -30,6 +30,7 @@ org.apache.lucene.analysis.core.LowerCaseFilterFactory
 org.apache.lucene.analysis.core.StopFilterFactory
 org.apache.lucene.analysis.core.TypeTokenFilterFactory
 org.apache.lucene.analysis.core.UpperCaseFilterFactory
+org.apache.lucene.analysis.core.SubSeqFilterFactory
 org.apache.lucene.analysis.cz.CzechStemFilterFactory
 org.apache.lucene.analysis.de.GermanLightStemFilterFactory
 org.apache.lucene.analysis.de.GermanMinimalStemFilterFactory
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
index f3972e8..df5bd4a 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
@@ -63,6 +63,7 @@ import org.apache.lucene.analysis.commongrams.CommonGramsQueryFilter;
 import org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter;
 import org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter;
 import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree;
+import org.apache.lucene.analysis.core.SubSeqFilter;
 import org.apache.lucene.analysis.hunspell.Dictionary;
 import org.apache.lucene.analysis.hunspell.TestHunspellStemFilter;
 import org.apache.lucene.analysis.miscellaneous.HyphenatedWordsFilter;
@@ -555,6 +556,12 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         }
       }    
     });
+    put(SubSeqFilter.Anchor.class, new ArgProducer() {
+      @Override public Object create(Random random) {
+        SubSeqFilter.Anchor[] values = SubSeqFilter.Anchor.values();
+        return values[random.nextInt(values.length)];
+      }
+    });
   }};
   
   static final Set<Class<?>> allowedTokenizerArgs, allowedTokenFilterArgs, allowedCharFilterArgs;
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilter.java
new file mode 100644
index 0000000..651a120
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilter.java
@@ -0,0 +1,118 @@
+package org.apache.lucene.analysis.core;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.ArrayList;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+public class TestSubSeqFilter extends BaseTokenStreamTestCase {
+  
+  public void testNeutral() throws IOException {
+    StringReader reader = new StringReader("Now is The Time");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 0, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Now", "is", "The", "Time" });
+  }
+
+  public void testSanity() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 0, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "b", "c", "d", "a.b", "b.c", "c.d", "a.b.c", "b.c.d", "a.b.c.d", "Text" });
+  }
+
+  public void testMinLen() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 2, 0, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a.b", "b.c", "c.d", "a.b.c", "b.c.d", "a.b.c.d", "Text" });
+  }
+
+  public void testMaxLenPositive() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 2, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "b", "c", "d", "a.b", "b.c", "c.d", "Text" });
+  }
+
+  public void testMaxLenZero() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 3, 0, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a.b.c", "b.c.d", "a.b.c.d", "Text" });
+  }
+
+  public void testMaxLenNegative() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 2, -1, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a.b", "b.c", "c.d", "a.b.c", "b.c.d", "Text" });
+  }
+
+  public void testWithOriginalTrue() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 1, SubSeqFilter.Anchor.NONE, false, true);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "b", "c", "d", "a.b.c.d", "Text" });
+  }
+
+  public void testWithOriginalFalse() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 1, SubSeqFilter.Anchor.NONE, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "b", "c", "d", "Text" });
+  }
+
+  public void testAnchorStart() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 2, SubSeqFilter.Anchor.START, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "a.b", "Text" });
+  }
+
+  public void testAnchorEnd() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c.d Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 2, SubSeqFilter.Anchor.END, false, false);
+    assertTokenStreamContents(stream, new String[] { "Some", "d", "c.d", "Text" });
+  }
+
+  public void testReverse() throws IOException {
+    StringReader reader = new StringReader("Some a.b.c Text");
+    final StandardTokenizer input = new StandardTokenizer(TEST_VERSION_CURRENT, newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new SubSeqFilter(input, "[.]", ".", 1, 3, SubSeqFilter.Anchor.NONE, true, true);
+    assertTokenStreamContents(stream, new String[] { "Some", "a", "b", "c", "b.a", "c.b", "c.b.a", "a.b.c", "Text" });
+  }
+
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilterFactory.java
new file mode 100644
index 0000000..b0c51bb
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestSubSeqFilterFactory.java
@@ -0,0 +1,81 @@
+package org.apache.lucene.analysis.core;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.util.BaseTokenStreamFactoryTestCase;
+import org.apache.lucene.analysis.core.SubSeqFilterFactory;
+
+public class TestSubSeqFilterFactory extends BaseTokenStreamFactoryTestCase {
+
+  public void testArgs() throws Exception {
+
+    SubSeqFilterFactory factory;
+
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "sepRegexp", "");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "sepRegexp", "[.]");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "glue", "");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "glue", ".");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "minLen", "1");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "minLen", "3");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "maxLen", "0");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "maxLen", "-2");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "maxLen", "3");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "anchor", "none");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "anchor", "start");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "anchor", "end");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "reverse", "true");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "reverse", "false");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "withOriginal", "true");
+    factory = (SubSeqFilterFactory) tokenFilterFactory("subseq", "withOriginal", "false");
+  }
+  
+  /** Test that bogus arguments result in exception */
+  public void testBogusArguments() throws Exception {
+
+    try {
+      tokenFilterFactory("subseq", "bogusArg", "bogusValue");
+      fail();
+    } catch (IllegalArgumentException expected) {
+      assertTrue(expected.getMessage().contains("Unknown parameters"));
+    }
+
+    try {
+      tokenFilterFactory("subseq", "minLen", "0");
+      fail();
+    } catch (IllegalArgumentException expected) {
+      assertTrue(expected.getMessage().contains("Invalid minLen"));
+    }
+
+    try {
+      tokenFilterFactory("subseq", "minLen", "3", "maxLen", "1");
+      fail();
+    } catch (IllegalArgumentException expected) {
+      assertTrue(expected.getMessage().contains("minLen > maxLen"));
+    }
+
+    try {
+      tokenFilterFactory("subseq", "anchor", "bogusAnchor");
+      fail();
+    } catch (IllegalArgumentException expected) {
+      assertTrue(expected.getMessage().contains("Invalid anchor"));
+    }
+
+  }
+
+}
