Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java	(revision 1649521)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java	(working copy)
@@ -21,6 +21,7 @@
 
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.GramSizeAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
@@ -75,6 +76,7 @@
   private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
   private final PositionLengthAttribute posLenAtt = addAttribute(PositionLengthAttribute.class);
   private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+  private final GramSizeAttribute gsizeAtt = addAttribute(GramSizeAttribute.class);
 
   NGramTokenizer(int minGram, int maxGram, boolean edgesOnly) {
     init(minGram, maxGram, edgesOnly);
@@ -175,6 +177,7 @@
       posIncAtt.setPositionIncrement(1);
       posLenAtt.setPositionLength(1);
       offsetAtt.setOffset(correctOffset(offset), correctOffset(offset + length));
+      gsizeAtt.setGramSize(gramSize);
       ++gramSize;
       return true;
     }
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java	(revision 1649521)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/NGramTokenizerTest.java	(working copy)
@@ -26,6 +26,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.GramSizeAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
@@ -173,6 +174,7 @@
     final PositionIncrementAttribute posIncAtt = grams.addAttribute(PositionIncrementAttribute.class);
     final PositionLengthAttribute posLenAtt = grams.addAttribute(PositionLengthAttribute.class);
     final OffsetAttribute offsetAtt = grams.addAttribute(OffsetAttribute.class);
+    final GramSizeAttribute gsizeAtt = grams.addAttribute(GramSizeAttribute.class);
     grams.reset();
     for (int start = 0; start < codePoints.length; ++start) {
       nextGram:
@@ -192,6 +194,7 @@
         assertEquals(1, posLenAtt.getPositionLength());
         assertEquals(offsets[start], offsetAtt.startOffset());
         assertEquals(offsets[end], offsetAtt.endOffset());
+        assertEquals(end - start, gsizeAtt.getGramSize());
       }
     }
     assertFalse(grams.incrementToken());
Index: lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttribute.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttribute.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttribute.java	(working copy)
@@ -0,0 +1,52 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.search.NGramPhraseQuery;
+import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.QueryBuilder;
+
+/**
+ * This attribute can be used to store a token's gram size
+ * when this token stream is processed by N-gram based {@link Tokenizer}s or {@link TokenFilter}s.
+ * <p>
+ * If this attribute is set, {@link QueryBuilder} will generate
+ * {@link NGramPhraseQuery} (optimized {@link PhraseQuery}) when parse phrase queries.
+ * </p>
+ */
+public interface GramSizeAttribute extends Attribute{
+
+  /**
+   * Returns the gram size of this token.
+   * @see #setGramSize(int)
+   */
+  public int getGramSize();
+
+  /**
+   * Set the gram size of this token.
+   * <p>
+   * The default value is zero.
+   * </p>
+   * @throws IllegalArgumentException if <code>size</code> is negative.
+   * @see #getGramSize()
+   */
+  public void setGramSize(int size) throws IllegalArgumentException;
+}
Index: lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttributeImpl.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttributeImpl.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/GramSizeAttributeImpl.java	(working copy)
@@ -0,0 +1,65 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.AttributeImpl;
+
+/** Default implementation of {@link GramSizeAttribute} */
+public class GramSizeAttributeImpl extends AttributeImpl implements GramSizeAttribute {
+  private int size;
+
+  @Override
+  public void clear() {
+    size = 0;
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    GramSizeAttribute attr = (GramSizeAttribute) target;
+    attr.setGramSize(size);
+  }
+
+  @Override
+  public int getGramSize() {
+    return size;
+  }
+
+  @Override
+  public void setGramSize(int size) throws IllegalArgumentException {
+    if (size < 0) {
+      throw new IllegalArgumentException
+          ("Size must be zero or greater: got " + size);
+    }
+    this.size = size;
+  }
+
+  @Override
+  public int hashCode() {
+    return size;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (this == obj)
+      return true;
+    if (getClass() != obj.getClass())
+      return false;
+    final GramSizeAttributeImpl other = (GramSizeAttributeImpl) obj;
+    return size == other.size;
+  }
+}
Index: lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java	(revision 1649521)
+++ lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java	(working copy)
@@ -24,6 +24,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.GramSizeAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.index.Term;
@@ -30,6 +31,7 @@
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MultiPhraseQuery;
+import org.apache.lucene.search.NGramPhraseQuery;
 import org.apache.lucene.search.PhraseQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
@@ -197,6 +199,7 @@
     CachingTokenFilter buffer = null;
     TermToBytesRefAttribute termAtt = null;
     PositionIncrementAttribute posIncrAtt = null;
+    GramSizeAttribute gsizeAtt = null;
     int numTokens = 0;
     int positionCount = 0;
     boolean severalTokensAtSamePosition = false;
@@ -208,7 +211,7 @@
 
       termAtt = buffer.getAttribute(TermToBytesRefAttribute.class);
       posIncrAtt = buffer.getAttribute(PositionIncrementAttribute.class);
-
+      gsizeAtt = buffer.getAttribute(GramSizeAttribute.class);
       if (termAtt != null) {
         try {
           hasMoreTokens = buffer.incrementToken();
@@ -340,7 +343,7 @@
           return mpq;
         }
       } else {
-        PhraseQuery pq = newPhraseQuery();
+        PhraseQuery pq = gsizeAtt == null ? newPhraseQuery() : newNGramPhraseQuery(gsizeAtt.getGramSize());
         pq.setSlop(phraseSlop);
         int position = -1;
 
@@ -411,4 +414,8 @@
   protected MultiPhraseQuery newMultiPhraseQuery() {
     return new MultiPhraseQuery();
   }
+
+  protected NGramPhraseQuery newNGramPhraseQuery(int n) {
+    return new NGramPhraseQuery(n);
+  }
 }
Index: lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java	(revision 1649521)
+++ lucene/core/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpl.java	(working copy)
@@ -43,6 +43,8 @@
       put(OffsetAttribute.class.getName() + "#startOffset", 0);
       put(OffsetAttribute.class.getName() + "#endOffset", 0);
     }});
+    TestUtil.assertAttributeReflection(new GramSizeAttributeImpl(),
+        Collections.singletonMap(GramSizeAttribute.class.getName() + "#size", 0));
   }
 
 }
Index: lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java	(revision 1649521)
+++ lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java	(working copy)
@@ -18,8 +18,6 @@
  */
 
 import java.io.IOException;
-import java.io.Reader;
-import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -28,12 +26,17 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.GramSizeAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MultiPhraseQuery;
+import org.apache.lucene.search.NGramPhraseQuery;
 import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
 import org.apache.lucene.util.automaton.RegExp;
@@ -357,6 +360,123 @@
     assertEquals(expected, builder.createPhraseQuery("field", "中国", 3));
   }
 
+  protected static class MockNGramAnalyzer extends Analyzer {
+    private Tokenizer tokenizer;
+    public MockNGramAnalyzer(int minGram, int maxGram) {
+      this.tokenizer = new MockNGramTokenizer(minGram, maxGram);
+    }
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      return new TokenStreamComponents(tokenizer);
+    }
+  }
+
+  /**
+   * Pseudo NGramTokenizer.
+   * This mock class simulates gram-based Tokenizer.
+   * Note: the reason for this redundant mock implementation is that the basic NGramTokenizer is included in Analysis module,
+   * so it cannot be instantiated here... (same to other mock tokenizer/filters.)
+   */
+  protected static class MockNGramTokenizer extends Tokenizer {
+
+    private int minGram, maxGram, gramSize;
+    int ch;
+    private char[] buffer;
+    private int startOffset, endOffset;
+
+    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+    private final PositionLengthAttribute posLenAtt = addAttribute(PositionLengthAttribute.class);
+    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+    private final GramSizeAttribute gsizeAtt = addAttribute(GramSizeAttribute.class);
+
+    public MockNGramTokenizer(int minGram, int maxGram) {
+      this.minGram = minGram;
+      this.maxGram = maxGram;
+      this.gramSize = minGram;
+      this.buffer = new char[1024];
+    }
+
+    @Override
+    public final boolean incrementToken() throws IOException {
+      while (true) {
+        if (gramSize > maxGram) {
+          gramSize = minGram;
+          startOffset++;
+        }
+
+        if ((endOffset - startOffset) < gramSize) {
+          ch = input.read(buffer, endOffset++, 1);
+          if (ch < 0) {
+            if ((endOffset - startOffset) >= minGram) {
+              startOffset++;
+              endOffset--;
+              gramSize = minGram;
+            } else {
+              return false;
+            }
+          }
+        }
+
+        clearAttributes();
+        if ((endOffset - startOffset) >= minGram) {
+          termAtt.copyBuffer(buffer, startOffset, gramSize);
+          posIncAtt.setPositionIncrement(1);
+          posLenAtt.setPositionLength(1);
+          offsetAtt.setOffset(startOffset, startOffset + gramSize);
+          gsizeAtt.setGramSize(gramSize);  // set gram size
+          gramSize++;
+          return true;
+        }
+      }
+    }
+  }
+
+  /** generate normal phrase query */
+  public void testNormalPhraseQuery() throws IOException {
+    PhraseQuery expected = new PhraseQuery();
+    expected.add(new Term("field", "abc"));
+    expected.add(new Term("field", "def"));
+    QueryBuilder builder = new QueryBuilder(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));
+    Query q = builder.createPhraseQuery("field", "abc def");
+    assertTrue(q instanceof PhraseQuery);  // an instance of PhraseQuery
+    assertFalse(q instanceof NGramPhraseQuery);  // not an instance of NGramPhraseQuery
+    assertEquals(expected, q);
+  }
+
+  /** generate optimized phrase query by the gram size. */
+  public void testNGramPhraseQueryGram2() throws IOException {
+    // test case for minGramSize == maxGramSize.
+    NGramPhraseQuery expected = new NGramPhraseQuery(2);
+    expected.add(new Term("field", "ab"));
+    expected.add(new Term("field", "bc"));
+    expected.add(new Term("field", "c "));
+    expected.add(new Term("field", " d"));
+    expected.add(new Term("field", "de"));
+    expected.add(new Term("field", "ef"));
+    QueryBuilder builder = new QueryBuilder(new MockNGramAnalyzer(2, 2));
+    Query q = builder.createPhraseQuery("field", "abc def");
+    assertTrue(q instanceof NGramPhraseQuery);
+    assertEquals(expected, q);
+  }
+
+  /** generate optimized phrase query by the gram size of the last token. */
+  public void testNGramPhraseQueryMinGram2MaxGram3() throws IOException {
+    // test case for minGramSize != maxGramSize.
+    // the gram size of the last token is used to generate NGramPhraseQuery.
+    // TODO: maxGramSize should be used for more optimization?
+    NGramPhraseQuery expected = new NGramPhraseQuery(2);
+    expected.add(new Term("field", "ab"));  expected.add(new Term("field", "abc"));
+    expected.add(new Term("field", "bc"));  expected.add(new Term("field", "bcd"));
+    expected.add(new Term("field", "cd"));  expected.add(new Term("field", "cde"));
+    expected.add(new Term("field", "de"));  expected.add(new Term("field", "def"));
+    expected.add(new Term("field", "ef"));
+    QueryBuilder builder = new QueryBuilder(new MockNGramAnalyzer(2, 3));
+    Query q = builder.createPhraseQuery("field", "abcdef");
+    assertTrue(q instanceof NGramPhraseQuery);
+    assertEquals(expected, q);
+  }
+
   public void testNoTermAttribute() {
     //Can't use MockTokenizer because it adds TermAttribute and we don't want that
     Analyzer analyzer = new Analyzer() {
