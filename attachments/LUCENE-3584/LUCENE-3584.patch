Index: solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java	(revision 1204145)
+++ solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java	(working copy)
@@ -322,35 +322,21 @@
             outer: for (int subindex = 0; subindex<numSubs; subindex++) {
               MultiDocsEnum.EnumWithSlice sub = subs[subindex];
               if (sub.docsEnum == null) continue;
-              DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();
               int base = sub.slice.start;
-              for (;;) {
-                int nDocs = sub.docsEnum.read();
-                if (nDocs == 0) break;
-                int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-                int end = bulk.docs.offset + nDocs;
-                for (int i=bulk.docs.offset; i<end; i++) {
-                  if (fastForRandomSet.exists(docArr[i]+base)) {
-                    intersects = true;
-                    break outer;
-                  }
+              int docid;
+              while ((docid = sub.docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+                if (fastForRandomSet.exists(docid+base)) {
+                  intersects = true;
+                  break outer;
                 }
               }
             }
           } else {
-            // this should be the same bulk result object if sharing of the docsEnum succeeded
-            DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();
-
-            outer: for (;;) {
-              int nDocs = docsEnum.read();
-              if (nDocs == 0) break;
-              int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-              int end = bulk.docs.offset + nDocs;
-              for (int i=bulk.docs.offset; i<end; i++) {
-                if (fastForRandomSet.exists(docArr[i])) {
-                  intersects = true;
-                  break outer;
-                }
+            int docid;
+            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+              if (fastForRandomSet.exists(docid)) {
+                intersects = true;
+                break;
               }
             }
           }
@@ -401,32 +387,18 @@
                 for (int subindex = 0; subindex<numSubs; subindex++) {
                   MultiDocsEnum.EnumWithSlice sub = subs[subindex];
                   if (sub.docsEnum == null) continue;
-                  DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();
                   int base = sub.slice.start;
-                  for (;;) {
-                    int nDocs = sub.docsEnum.read();
-                    if (nDocs == 0) break;
-                    resultListDocs += nDocs;
-                    int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-                    int end = bulk.docs.offset + nDocs;
-                    for (int i=bulk.docs.offset; i<end; i++) {
-                      resultBits.fastSet(docArr[i]+base);
-                    }
+                  int docid;
+                  while ((docid = sub.docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+                    resultListDocs++;
+                    resultBits.fastSet(docid + base);
                   }
                 }
               } else {
-                // this should be the same bulk result object if sharing of the docsEnum succeeded
-                DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();
-
-                for (;;) {
-                  int nDocs = docsEnum.read();
-                  if (nDocs == 0) break;
-                  resultListDocs += nDocs;
-                  int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-                  int end = bulk.docs.offset + nDocs;
-                  for (int i=bulk.docs.offset; i<end; i++) {
-                    resultBits.fastSet(docArr[i]);
-                  }
+                int docid;
+                while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+                  resultListDocs++;
+                  resultBits.fastSet(docid);
                 }
               }
             }
Index: solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(revision 1204145)
+++ solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(working copy)
@@ -872,47 +872,34 @@
       for (int subindex = 0; subindex<numSubs; subindex++) {
         MultiDocsEnum.EnumWithSlice sub = subs[subindex];
         if (sub.docsEnum == null) continue;
-        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();
         int base = sub.slice.start;
-
-        for (;;) {
-          int nDocs = sub.docsEnum.read();
-          if (nDocs == 0) break;
-          int[] docArr = bulk.docs.ints;
-          int end = bulk.docs.offset + nDocs;
-          if (upto + nDocs > docs.length) {
-            if (obs == null) obs = new OpenBitSet(maxDoc());
-            for (int i=bulk.docs.offset; i<end; i++) {
-              obs.fastSet(docArr[i]+base);
-            }
-            bitsSet += nDocs;
-          } else {
-            for (int i=bulk.docs.offset; i<end; i++) {
-              docs[upto++] = docArr[i]+base;
-            }
-          }
-        }
-      }
-    } else {
-      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();
-      for (;;) {
-        int nDocs = docsEnum.read();
-        if (nDocs == 0) break;
-        int[] docArr = bulk.docs.ints;
-        int end = bulk.docs.offset + nDocs;
-
-        if (upto + nDocs > docs.length) {
+        int docid;
+        
+        if (largestPossible > docs.length) {
           if (obs == null) obs = new OpenBitSet(maxDoc());
-          for (int i=bulk.docs.offset; i<end; i++) {
-            obs.fastSet(docArr[i]);
+          while ((docid = sub.docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+            obs.fastSet(docid + base);
+            bitsSet++;
           }
-          bitsSet += nDocs;
         } else {
-          for (int i=bulk.docs.offset; i<end; i++) {
-            docs[upto++] = docArr[i];
+          while ((docid = sub.docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+            docs[upto++] = docid + base;
           }
         }
       }
+    } else {
+      int docid;
+      if (largestPossible > docs.length) {
+        if (obs == null) obs = new OpenBitSet(maxDoc());
+        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+          obs.fastSet(docid);
+          bitsSet++;
+        }
+      } else {
+        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+          docs[upto++] = docid;
+        }
+      }
     }
 
     DocSet result;
@@ -960,15 +947,9 @@
           }
 
           if (docsEnum != null) {
-            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();
-            for (;;) {
-              int n = docsEnum.read();
-              if (n==0) break;
-              int[] arr = readResult.docs.ints;
-              int end = readResult.docs.offset + n;
-              for (int j=readResult.docs.offset; j<end; j++) {
-                collector.collect(arr[j]);
-              }
+            int docid;
+            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+              collector.collect(docid);
             }
           }
         }
Index: solr/core/src/java/org/apache/solr/request/SimpleFacets.java
===================================================================
--- solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(revision 1204145)
+++ solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(working copy)
@@ -696,31 +696,16 @@
               for (int subindex = 0; subindex<numSubs; subindex++) {
                 MultiDocsEnum.EnumWithSlice sub = subs[subindex];
                 if (sub.docsEnum == null) continue;
-                DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();
                 int base = sub.slice.start;
-                for (;;) {
-                  int nDocs = sub.docsEnum.read();
-                  if (nDocs == 0) break;
-                  int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-                  int end = bulk.docs.offset + nDocs;
-                  for (int i=bulk.docs.offset; i<end; i++) {
-                    if (fastForRandomSet.exists(docArr[i]+base)) c++;
-                  }
+                int docid;
+                while ((docid = sub.docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+                  if (fastForRandomSet.exists(docid+base)) c++;
                 }
               }
             } else {
-
-              // this should be the same bulk result object if sharing of the docsEnum succeeded
-              DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();
-
-              for (;;) {
-                int nDocs = docsEnum.read();
-                if (nDocs == 0) break;
-                int[] docArr = bulk.docs.ints;  // this might be movable outside the loop, but perhaps not worth the risk.
-                int end = bulk.docs.offset + nDocs;
-                for (int i=bulk.docs.offset; i<end; i++) {
-                  if (fastForRandomSet.exists(docArr[i])) c++;
-                }
+              int docid;
+              while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+                if (fastForRandomSet.exists(docid)) c++;
               }
             }
             
Index: lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java
===================================================================
--- lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java	(revision 1204145)
+++ lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java	(working copy)
@@ -25,11 +25,15 @@
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.FieldReaderException;
 import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ReaderUtil;
+
 import java.io.File;
+import java.io.IOException;
 import java.util.Arrays;
 import java.util.Comparator;
 
@@ -178,45 +182,34 @@
     return ts;
   }
   
-  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {
-
-    long totalTF = 0;
+  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   
+    final long totalTF[] = new long[1];
     
-    Terms terms = MultiFields.getTerms(reader, field);
-    if (terms == null) {
-      return 0;
-    }
+    new ReaderUtil.Gather(reader) {
 
-    TermsEnum termsEnum = terms.iterator(null);
-    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {
-      return 0;
-    }
-
-    Bits liveDocs = MultiFields.getLiveDocs(reader);
-    if (liveDocs == null) {
-      // TODO: we could do this up front, during the scan
-      // (next()), instead of after-the-fact here w/ seek,
-      // if the codec supports it and there are no del
-      // docs...
-      final long totTF = termsEnum.totalTermFreq();
-      if (totTF != -1) {
-        return totTF;
+      @Override
+      protected void add(int base, IndexReader r) throws IOException {
+        Bits liveDocs = r.getLiveDocs();
+        if (liveDocs == null) {
+          // TODO: we could do this up front, during the scan
+          // (next()), instead of after-the-fact here w/ seek,
+          // if the codec supports it and there are no del
+          // docs...
+          final long totTF = r.totalTermFreq(field, termText);
+          if (totTF != -1) {
+            totalTF[0] += totTF;
+            return;
+          }
+        }
+        DocsEnum de = r.termDocsEnum(liveDocs, field, termText);
+        if (de != null) {
+          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)
+            totalTF[0] += de.freq();
+        }
       }
-    }
+    }.run();
     
-    DocsEnum de = termsEnum.docs(liveDocs, null);
-
-    // use DocsEnum.read() and BulkResult api
-    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();
-    int count;
-    while ((count = de.read()) != 0) {
-      final int[] freqs = bulkresult.freqs.ints;
-      final int limit = bulkresult.freqs.offset + count;
-      for(int i=bulkresult.freqs.offset;i<limit;i++) {
-        totalTF += freqs[i];
-      }
-    }
-    return totalTF;
+    return totalTF[0];
   }
   
   public static void fillQueue(TermsEnum termsEnum, TermStatsQueue tiq, String field) throws Exception {
Index: lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java
===================================================================
--- lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java	(working copy)
@@ -101,24 +101,14 @@
     if (termsEnum.next() != null) {
       // fill into a FixedBitSet
       final FixedBitSet bitSet = new FixedBitSet(context.reader.maxDoc());
-      int termCount = 0;
       DocsEnum docsEnum = null;
       do {
-        termCount++;
         // System.out.println("  iter termCount=" + termCount + " term=" +
         // enumerator.term().toBytesString());
         docsEnum = termsEnum.docs(acceptDocs, docsEnum);
-        final DocsEnum.BulkReadResult result = docsEnum.getBulkResult();
-        while (true) {
-          final int count = docsEnum.read();
-          if (count != 0) {
-            final int[] docs = result.docs.ints;
-            for (int i = 0; i < count; i++) {
-              bitSet.set(docs[i]);
-            }
-          } else {
-            break;
-          }
+        int docid;
+        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+          bitSet.set(docid);
         }
       } while (termsEnum.next() != null);
       // System.out.println("  done termCount=" + termCount);
Index: lucene/src/java/org/apache/lucene/search/TermScorer.java
===================================================================
--- lucene/src/java/org/apache/lucene/search/TermScorer.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/search/TermScorer.java	(working copy)
@@ -26,15 +26,6 @@
  */
 final class TermScorer extends Scorer {
   private final DocsEnum docsEnum;
-  private int doc = -1;
-  private int freq;
-
-  private int pointer;
-  private int pointerMax;
-
-  private final int[] docs;
-  private final int[] freqs;
-  private final DocsEnum.BulkReadResult bulkResult;
   private final Similarity.ExactDocScorer docScorer;
   
   /**
@@ -52,76 +43,32 @@
     super(weight);
     this.docScorer = docScorer;
     this.docsEnum = td;
-    bulkResult = td.getBulkResult();
-    docs = bulkResult.docs.ints;
-    freqs = bulkResult.freqs.ints;
   }
 
   @Override
-  public void score(Collector c) throws IOException {
-    score(c, Integer.MAX_VALUE, nextDoc());
-  }
-
-  // firstDocID is ignored since nextDoc() sets 'doc'
-  @Override
-  public boolean score(Collector c, int end, int firstDocID) throws IOException {
-    c.setScorer(this);
-    while (doc < end) {                           // for docs in window
-      //System.out.println("TS: collect doc=" + doc);
-      c.collect(doc);                      // collect score
-      if (++pointer >= pointerMax) {
-        pointerMax = docsEnum.read();  // refill
-        if (pointerMax != 0) {
-          pointer = 0;
-        } else {
-          doc = NO_MORE_DOCS;                // set to sentinel value
-          return false;
-        }
-      } 
-      doc = docs[pointer];
-      freq = freqs[pointer];
-    }
-    return true;
-  }
-
-  @Override
   public int docID() {
-    return doc;
+    return docsEnum.docID();
   }
 
   @Override
   public float freq() {
-    return freq;
+    return docsEnum.freq();
   }
 
   /**
    * Advances to the next document matching the query. <br>
-   * The iterator over the matching documents is buffered using
-   * {@link TermDocs#read(int[],int[])}.
    * 
    * @return the document matching the query or NO_MORE_DOCS if there are no more documents.
    */
   @Override
   public int nextDoc() throws IOException {
-    pointer++;
-    if (pointer >= pointerMax) {
-      pointerMax = docsEnum.read();  // refill
-      if (pointerMax != 0) {
-        pointer = 0;
-      } else {
-        return doc = NO_MORE_DOCS;
-      }
-    } 
-    doc = docs[pointer];
-    freq = freqs[pointer];
-    assert doc != NO_MORE_DOCS;
-    return doc;
+    return docsEnum.nextDoc();
   }
   
   @Override
   public float score() {
-    assert doc != NO_MORE_DOCS;
-    return docScorer.score(doc, freq);  
+    assert docID() != NO_MORE_DOCS;
+    return docScorer.score(docsEnum.docID(), docsEnum.freq());  
   }
 
   /**
@@ -135,24 +82,7 @@
    */
   @Override
   public int advance(int target) throws IOException {
-    // first scan in cache
-    for (pointer++; pointer < pointerMax; pointer++) {
-      if (docs[pointer] >= target) {
-        freq = freqs[pointer];
-        return doc = docs[pointer];
-      }
-    }
-
-    // not found in readahead cache, seek underlying stream
-    int newDoc = docsEnum.advance(target);
-    //System.out.println("ts.advance docsEnum=" + docsEnum);
-    if (newDoc != NO_MORE_DOCS) {
-      doc = newDoc;
-      freq = docsEnum.freq();
-    } else {
-      doc = NO_MORE_DOCS;
-    }
-    return doc;
+    return docsEnum.advance(target);
   }
 
   /** Returns a string representation of this <code>TermScorer</code>. */
Index: lucene/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java	(working copy)
@@ -35,14 +35,4 @@
   public abstract BytesRef getPayload() throws IOException;
 
   public abstract boolean hasPayload();
-
-  @Override
-  public final int read() {
-    throw new UnsupportedOperationException();
-  }
-
-  @Override
-  public BulkReadResult getBulkResult() {
-    throw new UnsupportedOperationException();
-  }
 }
Index: lucene/src/java/org/apache/lucene/index/DocsEnum.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/DocsEnum.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/DocsEnum.java	(working copy)
@@ -17,11 +17,8 @@
  * limitations under the License.
  */
 
-import java.io.IOException;
-
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.IntsRef;
 
 /** Iterates through the documents, term freq and positions.
  *  NOTE: you must first call {@link #nextDoc} before using
@@ -43,60 +40,4 @@
     if (atts == null) atts = new AttributeSource();
     return atts;
   }
-
-  // TODO: maybe add bulk read only docIDs (for eventual
-  // match-only scoring)
-
-  public static class BulkReadResult {
-    public final IntsRef docs = new IntsRef();
-    public final IntsRef freqs = new IntsRef();
-  }
-
-  protected BulkReadResult bulkResult;
-
-  protected final void initBulkResult() {
-    if (bulkResult == null) {
-      bulkResult = new BulkReadResult();
-      bulkResult.docs.ints = new int[64];
-      bulkResult.freqs.ints = new int[64];
-    }
-  }
-
-  /** Call this once, up front, and hold a reference to the
-   *  returned bulk result.  When you call {@link #read}, it
-   *  fills the docs and freqs of this pre-shared bulk
-   *  result. */
-  public BulkReadResult getBulkResult() {
-    initBulkResult();
-    return bulkResult;
-  }
-  
-  /** Bulk read (docs and freqs).  After this is called,
-   *  {@link #docID()} and {@link #freq} are undefined.
-   *  This returns the count read, or 0 if the end is
-   *  reached.  The resulting docs and freqs are placed into
-   *  the pre-shard {@link BulkReadResult} instance returned
-   *  by {@link #getBulkResult}.  Note that the {@link
-   *  IntsRef} for docs and freqs will not have their length
-   *  set.
-   * 
-   *  <p>NOTE: the default impl simply delegates to {@link
-   *  #nextDoc}, but subclasses may do this more
-   *  efficiently. */
-  public int read() throws IOException {
-    int count = 0;
-    final int[] docs = bulkResult.docs.ints;
-    final int[] freqs = bulkResult.freqs.ints;
-    while(count < docs.length) {
-      final int doc = nextDoc();
-      if (doc != NO_MORE_DOCS) {
-        docs[count] = doc;
-        freqs[count] = freq();
-        count++;
-      } else {
-        break;
-      }
-    }
-    return count;
-  }
 }
Index: lucene/src/java/org/apache/lucene/index/DocTermOrds.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/DocTermOrds.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/DocTermOrds.java	(working copy)
@@ -17,6 +17,7 @@
 
 package org.apache.lucene.index;
 
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Bits;
@@ -314,90 +315,85 @@
 
         docsEnum = te.docs(liveDocs, docsEnum);
 
-        final DocsEnum.BulkReadResult bulkResult = docsEnum.getBulkResult();
-
         // dF, but takes deletions into account
         int actualDF = 0;
 
         for (;;) {
-          int chunk = docsEnum.read();
-          if (chunk <= 0) {
+          int doc = docsEnum.nextDoc();
+          if (doc == DocIdSetIterator.NO_MORE_DOCS) {
             break;
           }
           //System.out.println("  chunk=" + chunk + " docs");
 
-          actualDF += chunk;
+          actualDF ++;
+          termInstances++;
+          
+          //System.out.println("    docID=" + doc);
+          // add TNUM_OFFSET to the term number to make room for special reserved values:
+          // 0 (end term) and 1 (index into byte array follows)
+          int delta = termNum - lastTerm[doc] + TNUM_OFFSET;
+          lastTerm[doc] = termNum;
+          int val = index[doc];
 
-          for (int i=0; i<chunk; i++) {
-            termInstances++;
-            int doc = bulkResult.docs.ints[i];
-            //System.out.println("    docID=" + doc);
-            // add TNUM_OFFSET to the term number to make room for special reserved values:
-            // 0 (end term) and 1 (index into byte array follows)
-            int delta = termNum - lastTerm[doc] + TNUM_OFFSET;
-            lastTerm[doc] = termNum;
-            int val = index[doc];
-
-            if ((val & 0xff)==1) {
-              // index into byte array (actually the end of
-              // the doc-specific byte[] when building)
-              int pos = val >>> 8;
-              int ilen = vIntSize(delta);
-              byte[] arr = bytes[doc];
-              int newend = pos+ilen;
-              if (newend > arr.length) {
-                // We avoid a doubling strategy to lower memory usage.
-                // this faceting method isn't for docs with many terms.
-                // In hotspot, objects have 2 words of overhead, then fields, rounded up to a 64-bit boundary.
-                // TODO: figure out what array lengths we can round up to w/o actually using more memory
-                // (how much space does a byte[] take up?  Is data preceded by a 32 bit length only?
-                // It should be safe to round up to the nearest 32 bits in any case.
-                int newLen = (newend + 3) & 0xfffffffc;  // 4 byte alignment
-                byte[] newarr = new byte[newLen];
-                System.arraycopy(arr, 0, newarr, 0, pos);
-                arr = newarr;
-                bytes[doc] = newarr;
-              }
-              pos = writeInt(delta, arr, pos);
-              index[doc] = (pos<<8) | 1;  // update pointer to end index in byte[]
+          if ((val & 0xff)==1) {
+            // index into byte array (actually the end of
+            // the doc-specific byte[] when building)
+            int pos = val >>> 8;
+            int ilen = vIntSize(delta);
+            byte[] arr = bytes[doc];
+            int newend = pos+ilen;
+            if (newend > arr.length) {
+              // We avoid a doubling strategy to lower memory usage.
+              // this faceting method isn't for docs with many terms.
+              // In hotspot, objects have 2 words of overhead, then fields, rounded up to a 64-bit boundary.
+              // TODO: figure out what array lengths we can round up to w/o actually using more memory
+              // (how much space does a byte[] take up?  Is data preceded by a 32 bit length only?
+              // It should be safe to round up to the nearest 32 bits in any case.
+              int newLen = (newend + 3) & 0xfffffffc;  // 4 byte alignment
+              byte[] newarr = new byte[newLen];
+              System.arraycopy(arr, 0, newarr, 0, pos);
+              arr = newarr;
+              bytes[doc] = newarr;
+            }
+            pos = writeInt(delta, arr, pos);
+            index[doc] = (pos<<8) | 1;  // update pointer to end index in byte[]
+          } else {
+            // OK, this int has data in it... find the end (a zero starting byte - not
+            // part of another number, hence not following a byte with the high bit set).
+            int ipos;
+            if (val==0) {
+              ipos=0;
+            } else if ((val & 0x0000ff80)==0) {
+              ipos=1;
+            } else if ((val & 0x00ff8000)==0) {
+              ipos=2;
+            } else if ((val & 0xff800000)==0) {
+              ipos=3;
             } else {
-              // OK, this int has data in it... find the end (a zero starting byte - not
-              // part of another number, hence not following a byte with the high bit set).
-              int ipos;
-              if (val==0) {
-                ipos=0;
-              } else if ((val & 0x0000ff80)==0) {
-                ipos=1;
-              } else if ((val & 0x00ff8000)==0) {
-                ipos=2;
-              } else if ((val & 0xff800000)==0) {
-                ipos=3;
-              } else {
-                ipos=4;
-              }
+              ipos=4;
+            }
 
-              //System.out.println("      ipos=" + ipos);
+            //System.out.println("      ipos=" + ipos);
 
-              int endPos = writeInt(delta, tempArr, ipos);
-              //System.out.println("      endpos=" + endPos);
-              if (endPos <= 4) {
-                //System.out.println("      fits!");
-                // value will fit in the integer... move bytes back
-                for (int j=ipos; j<endPos; j++) {
-                  val |= (tempArr[j] & 0xff) << (j<<3);
-                }
-                index[doc] = val;
-              } else {
-                // value won't fit... move integer into byte[]
-                for (int j=0; j<ipos; j++) {
-                  tempArr[j] = (byte)val;
-                  val >>>=8;
-                }
-                // point at the end index in the byte[]
-                index[doc] = (endPos<<8) | 1;
-                bytes[doc] = tempArr;
-                tempArr = new byte[12];
+            int endPos = writeInt(delta, tempArr, ipos);
+            //System.out.println("      endpos=" + endPos);
+            if (endPos <= 4) {
+              //System.out.println("      fits!");
+              // value will fit in the integer... move bytes back
+              for (int j=ipos; j<endPos; j++) {
+                val |= (tempArr[j] & 0xff) << (j<<3);
               }
+              index[doc] = val;
+            } else {
+              // value won't fit... move integer into byte[]
+              for (int j=0; j<ipos; j++) {
+                tempArr[j] = (byte)val;
+                val >>>=8;
+              }
+              // point at the end index in the byte[]
+              index[doc] = (endPos<<8) | 1;
+              bytes[doc] = tempArr;
+              tempArr = new byte[12];
             }
           }
         }
Index: lucene/src/java/org/apache/lucene/index/FilterIndexReader.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/FilterIndexReader.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/FilterIndexReader.java	(working copy)
@@ -222,16 +222,6 @@
     public int advance(int target) throws IOException {
       return in.advance(target);
     }
-
-    @Override
-    public BulkReadResult getBulkResult() {
-      return in.getBulkResult();
-    }
-
-    @Override
-    public int read() throws IOException {
-      return in.read();
-    }
   }
 
   /** Base class for filtering {@link DocsAndPositionsEnum} implementations. */
Index: lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40PostingsReader.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40PostingsReader.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40PostingsReader.java	(working copy)
@@ -18,6 +18,7 @@
  */
 
 import java.io.IOException;
+import java.util.Arrays;
 import java.util.Collection;
 
 import org.apache.lucene.index.DocsAndPositionsEnum;
@@ -263,8 +264,16 @@
     }
   }
 
+  static final int BUFFERSIZE = 64;
+
   // Decodes only docs
   private class SegmentDocsEnum extends DocsEnum {
+    final int[] docs = new int[BUFFERSIZE];
+    final int[] freqs = new int[BUFFERSIZE];
+    
+    int start = -1;
+    int count = 0;
+    
     final IndexInput freqIn;
     final IndexInput startFreqIn;
 
@@ -294,7 +303,9 @@
       omitTF = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY;
       if (omitTF) {
         freq = 1;
+        Arrays.fill(freqs, 1);
       }
+      
       storePayloads = fieldInfo.storePayloads;
       this.liveDocs = liveDocs;
       freqOffset = termState.freqOffset;
@@ -313,90 +324,127 @@
 
       skipped = false;
 
+      start = -1;
+      count = 0;
       return this;
     }
+    
+    @Override
+    public int freq() {
+      return freq;
+    }
 
     @Override
+    public int docID() {
+      return doc;
+    }
+    
+    @Override
     public int nextDoc() throws IOException {
-      //if (DEBUG) System.out.println("    stpr.nextDoc seg=" + segment + " fp=" + freqIn.getFilePointer());
-      while(true) {
-        if (ord == limit) {
-          //if (DEBUG) System.out.println("      return doc=" + NO_MORE_DOCS);
-          return doc = NO_MORE_DOCS;
+      while (++start < count) {
+        int d = docs[start];
+        if (liveDocs == null || liveDocs.get(d)) {
+          freq = freqs[start];
+          return doc = d;
         }
-
-        ord++;
-
-        // Decode next doc/freq pair
-        final int code = freqIn.readVInt();
-        // if (DEBUG) System.out.println("      code=" + code);
-        if (omitTF) {
-          accum += code;
+      }
+      return doc = refill();
+    }
+    
+    @Override
+    public int advance(int target) throws IOException {
+      // last doc in our buffer is >= target, binary search + next()
+      if (++start < count && docs[count-1] >= target) {
+        binarySearch(target);
+        return nextDoc();
+      }
+      
+      start = count; // buffer is consumed
+      
+      return doc = skipTo(target);
+    }
+    
+    private void binarySearch(int target) {
+      int hi = count - 1;
+      while (start <= hi) {
+        int mid = (hi + start) >>> 1;
+        int doc = docs[mid];
+        if (doc < target) {
+          start = mid + 1;
+        } else if (doc > target) {
+          hi = mid - 1;
         } else {
-          accum += code >>> 1;              // shift off low bit
-          if ((code & 1) != 0) {          // if low bit is set
-            freq = 1;                     // freq is one
-          } else {
-            freq = freqIn.readVInt();     // else read freq
-          }
-        }
-
-        if (liveDocs == null || liveDocs.get(accum)) {
+          start = mid;
           break;
         }
       }
+      start--;
+    }
 
-      //if (DEBUG) System.out.println("    stpr.nextDoc return doc=" + doc);
-      return (doc = accum);
+    private int refill() throws IOException {
+      int doc = scanTo(0);
+      
+      int bufferSize = Math.min(docs.length, limit - ord);
+      start = -1;
+      count = bufferSize;
+      ord += bufferSize;
+      
+      if (omitTF)
+        fillDocs(bufferSize);
+      else
+        fillDocsAndFreqs(bufferSize);
+      
+      return doc;
     }
-
-    @Override
-    public int read() throws IOException {
-
-      final int[] docs = bulkResult.docs.ints;
-      final int[] freqs = bulkResult.freqs.ints;
-      int i = 0;
-      final int length = docs.length;
-      while (i < length && ord < limit) {
-        ord++;
-        // manually inlined call to next() for speed
-        final int code = freqIn.readVInt();
+    
+    private int scanTo(int target) throws IOException {
+      while (ord++ < limit) {
+        int code = freqIn.readVInt();
         if (omitTF) {
           accum += code;
         } else {
-          accum += code >>> 1;              // shift off low bit
+          accum += code >>> 1;            // shift off low bit
           if ((code & 1) != 0) {          // if low bit is set
             freq = 1;                     // freq is one
           } else {
             freq = freqIn.readVInt();     // else read freq
           }
         }
-
-        if (liveDocs == null || liveDocs.get(accum)) {
-          docs[i] = doc = accum;
-          freqs[i] = freq;
-          ++i;
+        
+        if (accum >= target && (liveDocs == null || liveDocs.get(accum))) {
+          return accum;
         }
       }
       
-      return i;
+      return NO_MORE_DOCS;
     }
-
-    @Override
-    public int docID() {
-      return doc;
+    
+    private void fillDocs(int size) throws IOException {
+      int docs[] = this.docs;
+      for (int i = 0; i < size; i++) {
+        accum += freqIn.readVInt();
+        docs[i] = accum;
+      }
     }
-
-    @Override
-    public int freq() {
-      return freq;
+    
+    private void fillDocsAndFreqs(int size) throws IOException {
+      int docs[] = this.docs;
+      int freqs[] = this.freqs;
+      for (int i = 0; i < size; i++) {
+        int code = freqIn.readVInt();
+        accum += code >>> 1;                   // shift off low bit
+        docs[i] = accum;
+        if ((code & 1) != 0) {                 // if low bit is set
+          freqs[i] = 1;                        // freq is one
+        } else {
+          freqs[i] = freqIn.readVInt();        // else read freq
+        }
+      }
     }
 
-    @Override
-    public int advance(int target) throws IOException {
+    private int skipTo(int target) throws IOException {
+      if ((target - skipInterval) >= accum && limit >= skipMinimum) {
 
-      if ((target - skipInterval) >= doc && limit >= skipMinimum) {
-
         // There are enough docs in the posting to have
         // skip data, and it isn't too close.
 
@@ -424,17 +472,11 @@
           // Skipper moved
 
           ord = newOrd;
-          doc = accum = skipper.getDoc();
+          accum = skipper.getDoc();
           freqIn.seek(skipper.getFreqPointer());
         }
       }
-        
-      // scan for the rest:
-      do {
-        nextDoc();
-      } while (target > doc);
-
-      return doc;
+      return scanTo(target);
     }
   }
 
Index: lucene/src/java/org/apache/lucene/index/codecs/lucene3x/Lucene3xFields.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/codecs/lucene3x/Lucene3xFields.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/codecs/lucene3x/Lucene3xFields.java	(working copy)
@@ -1025,16 +1025,6 @@
     public int docID() {
       return docID;
     }
-
-    @Override
-    public int read() throws IOException {
-      if (bulkResult == null) {
-        initBulkResult();
-        bulkResult.docs.ints = new int[32];
-        bulkResult.freqs.ints = new int[32];
-      }
-      return this.docs.read(bulkResult.docs.ints, bulkResult.freqs.ints);
-    }
   }
 
   private final class PreDocsAndPositionsEnum extends DocsAndPositionsEnum {
Index: lucene/src/java/org/apache/lucene/index/codecs/sep/SepPostingsReader.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/codecs/sep/SepPostingsReader.java	(revision 1204145)
+++ lucene/src/java/org/apache/lucene/index/codecs/sep/SepPostingsReader.java	(working copy)
@@ -411,34 +411,6 @@
     }
 
     @Override
-    public int read() throws IOException {
-      // TODO: -- switch to bulk read api in IntIndexInput
-      //System.out.println("sepdocs read");
-      final int[] docs = bulkResult.docs.ints;
-      final int[] freqs = bulkResult.freqs.ints;
-      int i = 0;
-      final int length = docs.length;
-      while (i < length && count < docFreq) {
-        count++;
-        // manually inlined call to next() for speed
-        //System.out.println("decode doc");
-        accum += docReader.next();
-        if (!omitTF) {
-          //System.out.println("decode freq");
-          freq = freqReader.next();
-        }
-
-        if (liveDocs == null || liveDocs.get(accum)) {
-          docs[i] = doc = accum;
-          freqs[i] = freq;
-          //System.out.println("  docs[" + i + "]=" + doc + " count=" + count + " dF=" + docFreq);
-          i++;
-        }
-      }
-      return i;
-    }
-
-    @Override
     public int freq() {
       return freq;
     }
