diff --git a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
index 6060622..44b8512 100644
--- a/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
+++ b/lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
@@ -22,8 +22,10 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
-import java.util.List;
+import java.util.HashSet;
 import java.util.Locale;
+import java.util.List;
+import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -230,14 +232,16 @@ class BufferedUpdatesStream implements Accountable {
           final DocValuesFieldUpdates.Container dvUpdates = new DocValuesFieldUpdates.Container();
 
           // first apply segment-private deletes/updates
-          delCount += applyQueryDeletes(packet.queriesIterable(), segState);
+          delCount += applyQueryDeletes(packet.queriesIterable(),
+                                        updatedDvFieldNames(packet), segState);
           applyDocValuesUpdates(Arrays.asList(packet.numericDVUpdates), segState, dvUpdates);
           applyDocValuesUpdates(Arrays.asList(packet.binaryDVUpdates), segState, dvUpdates);
 
           // ... then coalesced deletes/updates, so that if there is an update that appears in both, the coalesced updates (carried from
           // updates ahead of the segment-privates ones) win:
           if (coalescedUpdates != null) {
-            delCount += applyQueryDeletes(coalescedUpdates.queriesIterable(), segState);
+            delCount += applyQueryDeletes(coalescedUpdates.queriesIterable(),
+                                          updatedDvFieldNames(coalescedUpdates), segState);
             applyDocValuesUpdatesList(coalescedUpdates.numericDVUpdates, segState, dvUpdates);
             applyDocValuesUpdatesList(coalescedUpdates.binaryDVUpdates, segState, dvUpdates);
           }
@@ -264,7 +268,8 @@ class BufferedUpdatesStream implements Accountable {
             // Lock order: IW -> BD -> RP
             assert pool.infoIsLive(info);
             int delCount = 0;
-            delCount += applyQueryDeletes(coalescedUpdates.queriesIterable(), segState);
+            delCount += applyQueryDeletes(coalescedUpdates.queriesIterable(),
+                                          updatedDvFieldNames(coalescedUpdates), segState);
             DocValuesFieldUpdates.Container dvUpdates = new DocValuesFieldUpdates.Container();
             applyDocValuesUpdatesList(coalescedUpdates.numericDVUpdates, segState, dvUpdates);
             applyDocValuesUpdatesList(coalescedUpdates.binaryDVUpdates, segState, dvUpdates);
@@ -696,9 +701,17 @@ class BufferedUpdatesStream implements Accountable {
   }
 
   // Delete by query
-  private static long applyQueryDeletes(Iterable<QueryAndLimit> queriesIter, SegmentState segState) throws IOException {
+  private static long applyQueryDeletes(Iterable<QueryAndLimit> queriesIter, Set<String> updatedDvFieldNames, SegmentState segState) throws IOException {
     long delCount = 0;
-    final LeafReaderContext readerContext = segState.reader.getContext();
+    
+    LeafReaderContext readerContext = segState.reader.getContext();
+    if (! updatedDvFieldNames.isEmpty()) {
+      readerContext = new LeafReaderContext(readerContext.parent,
+                                            new FailUpdatedDVsLeafReader(readerContext.reader(),
+                                                                         updatedDvFieldNames),
+                                            readerContext.ordInParent, readerContext.docBaseInParent,
+                                            readerContext.ord, readerContext.docBase);
+    }
     for (QueryAndLimit ent : queriesIter) {
       Query query = ent.query;
       int limit = ent.limit;
@@ -754,4 +767,71 @@ class BufferedUpdatesStream implements Accountable {
     assert bytesUsed2 == bytesUsed.get(): "bytesUsed2=" + bytesUsed2 + " vs " + bytesUsed;
     return true;
   }
+
+  // nocommit: jdocs
+  private static Set<String> updatedDvFieldNames(CoalescedUpdates coalescedUpdates) {
+    if (coalescedUpdates.numericDVUpdates.isEmpty() && coalescedUpdates.binaryDVUpdates.isEmpty()) {
+      return Collections.<String>emptySet();
+    }
+    Set<String> names = new HashSet<>(coalescedUpdates.numericDVUpdates.size()
+                                      + coalescedUpdates.binaryDVUpdates.size());
+    for (List<List<DocValuesUpdate>> lstlst : Arrays.asList(coalescedUpdates.numericDVUpdates,
+                                                            coalescedUpdates.binaryDVUpdates)) {
+      for (List<DocValuesUpdate> lst : lstlst) {
+        for (DocValuesUpdate upd : lst) {
+          names.add(upd.field);
+        }
+      }
+    }
+    return names;
+  }
+  // nocommit: jdocs
+  private static Set<String> updatedDvFieldNames(FrozenBufferedUpdates packet) {
+    if (0 == packet.numericDVUpdates.length && 0 == packet.binaryDVUpdates.length) {
+      return Collections.<String>emptySet();
+    }
+    Set<String> names = new HashSet<>(packet.numericDVUpdates.length + packet.binaryDVUpdates.length);
+    for (DocValuesUpdate[] arr : Arrays.asList(packet.numericDVUpdates, packet.binaryDVUpdates)) {
+      for (DocValuesUpdate upd : arr) {
+        names.add(upd.field);
+      }
+    }
+    return names;
+  }
+
+  // nocommit: jdocs that cross ref update(Bin|Num)DocValues and refactor to it's own javafile
+  public static final class CanNotDeleteByQueryOnUpdatedDocValues extends IllegalStateException {
+    public final String fieldName;
+    public CanNotDeleteByQueryOnUpdatedDocValues(String fieldName) {
+      super("DocValues field '" + fieldName + "' can not be used in a delete query because it has a pending update");
+      this.fieldName = fieldName;
+    }
+  }
+  
+  // nocommit: jdocs and refactor to it's own java file
+  private static final class FailUpdatedDVsLeafReader extends FilterLeafReader {
+
+    public final Set<String> updatedDvFieldNames;
+    public FailUpdatedDVsLeafReader(LeafReader wrapped, Set<String> updatedDvFieldNames) {
+      super(wrapped);
+      this.updatedDvFieldNames = updatedDvFieldNames;
+    }
+
+    // nocommit: jdocs
+    @Override
+    public NumericDocValues getNumericDocValues(String field) throws IOException {
+      if (updatedDvFieldNames.contains(field)) {
+        throw new CanNotDeleteByQueryOnUpdatedDocValues(field);
+      }
+      return super.getNumericDocValues(field);
+    }
+    // nocommit: jdocs
+    @Override
+    public BinaryDocValues getBinaryDocValues(String field) throws IOException {
+      if (updatedDvFieldNames.contains(field)) {
+        throw new CanNotDeleteByQueryOnUpdatedDocValues(field);
+      }
+      return super.getBinaryDocValues(field);
+    }
+  }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java b/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
index ea6f61a..8b6c334 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
@@ -64,7 +64,7 @@ public class TestNumericDocValuesUpdates extends LuceneTestCase {
   // nocommit: either these variables & every conditional line using them should be removed, OR...
   // the "HACK" should be officially documented, the vars removed, and conditional code should alway run
   private static final boolean FORCE_NEW_READER_HACK_PRE = true; // nocommit
-  private static final boolean FORCE_NEW_READER_HACK_POST = false; // nocommit
+  private static final boolean FORCE_NEW_READER_HACK_POST = true; // nocommit: why is this needed to prevent CanNotDeleteByQueryOnUpdatedDocValues ???
     
   private Document doc(int id) {
     // make sure we don't set the doc's value to 0, to not confuse with a document that's missing values
