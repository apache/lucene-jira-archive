Index: lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java	(revision 1724443)
+++ lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+import java.text.Collator;
+import java.util.Locale;
+
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
@@ -24,7 +27,6 @@
 import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Sort;
@@ -35,9 +37,6 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
-import java.text.Collator;
-import java.util.Locale;
-
 /**
  * trivial test of CollationDocValuesField
  */
@@ -118,7 +117,7 @@
   private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, BytesRef startBR, BytesRef endBR, Collator collator) throws Exception { 
     SortedDocValues dvs = MultiDocValues.getSortedValues(is.getIndexReader(), "collated");
     for(int docID=0;docID<is.getIndexReader().maxDoc();docID++) {
-      StoredDocument doc = is.doc(docID);
+      Document doc = is.doc(docID);
       String s = doc.getField("field").stringValue();
       boolean collatorAccepts = collate(collator, s, startPoint) >= 0 && collate(collator, s, endPoint) <= 0;
       BytesRef br = dvs.get(docID);
Index: lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
===================================================================
--- lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java	(revision 1724443)
+++ lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Sort;
@@ -115,7 +114,7 @@
   private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, BytesRef startBR, BytesRef endBR, Collator collator) throws Exception { 
     SortedDocValues dvs = MultiDocValues.getSortedValues(is.getIndexReader(), "collated");
     for(int docID=0;docID<is.getIndexReader().maxDoc();docID++) {
-      StoredDocument doc = is.doc(docID);
+      Document doc = is.doc(docID);
       String s = doc.getField("field").stringValue();
       boolean collatorAccepts = collator.compare(s, startPoint) >= 0 && collator.compare(s, endPoint) <= 0;
       BytesRef br = dvs.get(docID);
Index: lucene/analysis/uima/src/test/org/apache/lucene/analysis/uima/UIMABaseAnalyzerTest.java
===================================================================
--- lucene/analysis/uima/src/test/org/apache/lucene/analysis/uima/UIMABaseAnalyzerTest.java	(revision 1724443)
+++ lucene/analysis/uima/src/test/org/apache/lucene/analysis/uima/UIMABaseAnalyzerTest.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.TopDocs;
@@ -84,7 +83,7 @@
     IndexSearcher indexSearcher = newSearcher(directoryReader);
     TopDocs result = indexSearcher.search(new MatchAllDocsQuery(), 1);
     assertTrue(result.totalHits > 0);
-    StoredDocument d = indexSearcher.doc(result.scoreDocs[0].doc);
+    Document d = indexSearcher.doc(result.scoreDocs[0].doc);
     assertNotNull(d);
     assertNotNull(d.getField("title"));
     assertEquals(dummyTitle, d.getField("title").stringValue());
@@ -104,7 +103,7 @@
     directoryReader = DirectoryReader.open(dir);
     indexSearcher = newSearcher(directoryReader);
     result = indexSearcher.search(new MatchAllDocsQuery(), 2);
-    StoredDocument d1 = indexSearcher.doc(result.scoreDocs[1].doc);
+    Document d1 = indexSearcher.doc(result.scoreDocs[1].doc);
     assertNotNull(d1);
     assertNotNull(d1.getField("title"));
     assertEquals(dogmasTitle, d1.getField("title").stringValue());
Index: lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1724443)
+++ lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -686,13 +686,13 @@
 
     for(int i=0;i<35;i++) {
       if (liveDocs.get(i)) {
-        StoredDocument d = reader.document(i);
-        List<StorableField> fields = d.getFields();
+        Document d = reader.document(i);
+        List<IndexableField> fields = d.getFields();
         boolean isProxDoc = d.getField("content3") == null;
         if (isProxDoc) {
           final int numFields = is40Index ? 7 : 5;
           assertEquals(numFields, fields.size());
-          StorableField f =  d.getField("id");
+          IndexableField f = d.getField("id");
           assertEquals(""+i, f.stringValue());
 
           f = d.getField("utf8");
@@ -788,7 +788,7 @@
     ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String("content"), "aaa")), 1000).scoreDocs;
 
     // First document should be #0
-    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);
+    Document d = searcher.getIndexReader().document(hits[0].doc);
     assertEquals("didn't get the right document first", "0", d.get("id"));
 
     doTestHits(hits, 34, searcher.getIndexReader());
@@ -838,7 +838,7 @@
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
     ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
-    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);
+    Document d = searcher.getIndexReader().document(hits[0].doc);
     assertEquals("wrong first document", "0", d.get("id"));
     doTestHits(hits, 44, searcher.getIndexReader());
     reader.close();
@@ -866,7 +866,7 @@
     IndexSearcher searcher = newSearcher(reader);
     ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
     assertEquals("wrong number of hits", 34, hits.length);
-    StoredDocument d = searcher.doc(hits[0].doc);
+    Document d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "0", d.get("id"));
     reader.close();
 
@@ -1107,7 +1107,7 @@
       for (int id=10; id<15; id++) {
         ScoreDoc[] hits = searcher.search(LegacyNumericRangeQuery.newIntRange("trieInt", LegacyNumericUtils.PRECISION_STEP_DEFAULT_32, Integer.valueOf(id), Integer.valueOf(id), true, true), 100).scoreDocs;
         assertEquals("wrong number of hits", 1, hits.length);
-        StoredDocument d = searcher.doc(hits[0].doc);
+        Document d = searcher.doc(hits[0].doc);
         assertEquals(String.valueOf(id), d.get("id"));
         
         hits = searcher.search(LegacyNumericRangeQuery.newLongRange("trieLong", LegacyNumericUtils.PRECISION_STEP_DEFAULT, Long.valueOf(id), Long.valueOf(id), true, true), 100).scoreDocs;
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/BenchmarkHighlighter.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/BenchmarkHighlighter.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/BenchmarkHighlighter.java	(working copy)
@@ -20,7 +20,6 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 
 /**
  * Abstract class for benchmarking highlighting performance
@@ -27,5 +26,5 @@
  */
 public abstract class BenchmarkHighlighter {
   public abstract int doHighlight( IndexReader reader, int doc, String field,
-      StoredDocument document, Analyzer analyzer, String text ) throws Exception ;
+      Document document, Analyzer analyzer, String text ) throws Exception ;
 }
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(working copy)
@@ -32,8 +32,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.search.MultiTermQuery;
@@ -97,7 +95,7 @@
 
     // optionally warm and add num docs traversed to count
     if (withWarm()) {
-      StoredDocument doc = null;
+      Document doc = null;
       Bits liveDocs = MultiFields.getLiveDocs(reader);
       for (int m = 0; m < reader.maxDoc(); m++) {
         if (null == liveDocs || liveDocs.get(m)) {
@@ -142,7 +140,7 @@
           System.out.println("numDocs() = " + reader.numDocs());
           for(int i=0;i<hits.scoreDocs.length;i++) {
             final int docID = hits.scoreDocs[i].doc;
-            final StoredDocument doc = reader.document(docID);
+            final Document doc = reader.document(docID);
             System.out.println("  " + i + ": doc=" + docID + " score=" + hits.scoreDocs[i].score + " " + printHitsField + " =" + doc.get(printHitsField));
           }
         }
@@ -163,7 +161,7 @@
               int id = scoreDocs[m].doc;
               res++;
               if (retrieve) {
-                StoredDocument document = retrieveDoc(reader, id);
+                Document document = retrieveDoc(reader, id);
                 res += document != null ? 1 : 0;
                 if (numHighlight > 0 && m < numHighlight) {
                   Collection<String> fieldsToHighlight = getFieldsToHighlight(document);
@@ -193,7 +191,7 @@
   }
 
 
-  protected StoredDocument retrieveDoc(IndexReader ir, int id) throws IOException {
+  protected Document retrieveDoc(IndexReader ir, int id) throws IOException {
     return ir.document(id);
   }
 
@@ -296,10 +294,10 @@
    * @param document The Document
    * @return A Collection of Field names (Strings)
    */
-  protected Collection<String> getFieldsToHighlight(StoredDocument document) {
-    List<StorableField> fields = document.getFields();
+  protected Collection<String> getFieldsToHighlight(Document document) {
+    List<IndexableField> fields = document.getFields();
     Set<String> result = new HashSet<>(fields.size());
-    for (final StorableField f : fields) {
+    for (final IndexableField f : fields) {
       result.add(f.name());
     }
     return result;
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTokensTask.java	(working copy)
@@ -27,10 +27,11 @@
 import org.apache.lucene.benchmark.byTask.feeds.DocMaker;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.LegacyFloatField;
 import org.apache.lucene.document.LegacyIntField;
-import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.LegacyLongField;
+import org.apache.lucene.index.IndexableField;
 
 /**
  * Simple task to test performance of tokenizers.  It just
@@ -68,10 +69,10 @@
 
   @Override
   public int doLogic() throws Exception {
-    List<Field> fields = doc.getFields();
+    List<IndexableField> fields = doc.getFields();
     Analyzer analyzer = getRunData().getAnalyzer();
     int tokenCount = 0;
-    for(final Field field : fields) {
+    for(final IndexableField field : fields) {
       if (!field.fieldType().tokenized() ||
           field instanceof LegacyIntField ||
           field instanceof LegacyLongField ||
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java	(working copy)
@@ -25,8 +25,8 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.benchmark.byTask.PerfRunData;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.highlight.Highlighter;
 import org.apache.lucene.search.highlight.QueryScorer;
@@ -101,7 +101,7 @@
     return new BenchmarkHighlighter(){
       @Override
       public int doHighlight(IndexReader reader, int doc, String field,
-          StoredDocument document, Analyzer analyzer, String text) throws Exception {
+          Document document, Analyzer analyzer, String text) throws Exception {
         final int maxStartOffset = highlighter.getMaxDocCharsToAnalyze() - 1;
         TokenStream ts = TokenSources.getTokenStream(field, reader.getTermVectors(doc), text, analyzer, maxStartOffset);
         TextFragment[] frag = highlighter.getBestTextFragments(ts, text, mergeContiguous, maxFrags);
@@ -111,7 +111,7 @@
   }
 
   @Override
-  protected Collection<String> getFieldsToHighlight(StoredDocument document) {
+  protected Collection<String> getFieldsToHighlight(Document document) {
     Collection<String> result = super.getFieldsToHighlight(document);
     //if stored is false, then result will be empty, in which case just get all the param fields
     if (paramFields.isEmpty() == false && result.isEmpty() == false) {
@@ -150,4 +150,4 @@
   }
 
 
-}
\ No newline at end of file
+}
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetLoadFieldSelectorTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetLoadFieldSelectorTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetLoadFieldSelectorTask.java	(working copy)
@@ -25,7 +25,6 @@
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DocumentStoredFieldVisitor;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 
 /**
  * Search and Traverse and Retrieve docs task using a
@@ -55,7 +54,7 @@
 
 
   @Override
-  protected StoredDocument retrieveDoc(IndexReader ir, int id) throws IOException {
+  protected Document retrieveDoc(IndexReader ir, int id) throws IOException {
     if (fieldsToLoad == null) {
       return ir.document(id);
     } else {
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java	(working copy)
@@ -21,7 +21,6 @@
 import org.apache.lucene.benchmark.byTask.PerfRunData;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.vectorhighlight.FastVectorHighlighter;
 import org.apache.lucene.search.vectorhighlight.FieldQuery;
@@ -100,7 +99,7 @@
     return new BenchmarkHighlighter(){
       @Override
       public int doHighlight(IndexReader reader, int doc, String field,
-          StoredDocument document, Analyzer analyzer, String text) throws Exception {
+          Document document, Analyzer analyzer, String text) throws Exception {
         final FieldQuery fq = highlighter.getFieldQuery( myq, reader);
         String[] fragments = highlighter.getBestFragments(fq, reader, doc, field, fragSize, maxFrags);
         return fragments != null ? fragments.length : 0;
@@ -109,7 +108,7 @@
   }
 
   @Override
-  protected Collection<String> getFieldsToHighlight(StoredDocument document) {
+  protected Collection<String> getFieldsToHighlight(Document document) {
     Collection<String> result = super.getFieldsToHighlight(document);
     //if stored is false, then result will be empty, in which case just get all the param fields
     if (paramFields.isEmpty() == false && result.isEmpty() == false) {
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteEnwikiLineDocTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteEnwikiLineDocTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteEnwikiLineDocTask.java	(working copy)
@@ -13,7 +13,7 @@
 import org.apache.lucene.benchmark.byTask.feeds.DocMaker;
 import org.apache.lucene.benchmark.byTask.utils.StreamUtils;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -63,7 +63,7 @@
   
   @Override
   protected PrintWriter lineFileOut(Document doc) {
-    StorableField titleField = doc.getField(DocMaker.TITLE_FIELD);
+    IndexableField titleField = doc.getField(DocMaker.TITLE_FIELD);
     if (titleField!=null && titleField.stringValue().startsWith("Category:")) {
       return categoryLineFileOut;
     }
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java	(revision 1724443)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java	(working copy)
@@ -33,7 +33,7 @@
 import org.apache.lucene.benchmark.byTask.utils.Config;
 import org.apache.lucene.benchmark.byTask.utils.StreamUtils;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 
 /**
  * A task which writes documents, one line per document. Each line is in the
@@ -175,7 +175,7 @@
 
     boolean sufficient = !checkSufficientFields;
     for (int i=0; i<fieldsToWrite.length; i++) {
-      StorableField f = doc.getField(fieldsToWrite[i]);
+      IndexableField f = doc.getField(fieldsToWrite[i]);
       String text = f == null ? "" : matcher.reset(f.stringValue()).replaceAll(" ").trim();
       sb.append(text).append(SEP);
       sufficient |= text.length()>0 && sufficientFields[i];
Index: lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CountingHighlighterTestTask.java
===================================================================
--- lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CountingHighlighterTestTask.java	(revision 1724443)
+++ lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CountingHighlighterTestTask.java	(working copy)
@@ -22,8 +22,8 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.benchmark.byTask.PerfRunData;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.highlight.Highlighter;
 import org.apache.lucene.search.highlight.QueryScorer;
@@ -44,8 +44,8 @@
   }
 
   @Override
-  protected StoredDocument retrieveDoc(IndexReader ir, int id) throws IOException {
-    StoredDocument document = ir.document(id);
+  protected Document retrieveDoc(IndexReader ir, int id) throws IOException {
+    Document document = ir.document(id);
     if (document != null) {
       numDocsRetrieved++;
     }
@@ -57,7 +57,7 @@
     highlighter = new Highlighter(new SimpleHTMLFormatter(), new QueryScorer(q));
     return new BenchmarkHighlighter() {
       @Override
-      public int doHighlight(IndexReader reader, int doc, String field, StoredDocument document, Analyzer analyzer, String text) throws Exception {
+      public int doHighlight(IndexReader reader, int doc, String field, Document document, Analyzer analyzer, String text) throws Exception {
         final int maxStartOffset = highlighter.getMaxDocCharsToAnalyze() - 1;
         TokenStream ts = TokenSources.getTokenStream(field, reader.getTermVectors(doc), text, analyzer, maxStartOffset);
         TextFragment[] frag = highlighter.getBestTextFragments(ts, text, mergeContiguous, maxFrags);
Index: lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier.java	(revision 1724443)
+++ lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier.java	(working copy)
@@ -25,10 +25,10 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
@@ -125,12 +125,12 @@
     // run the search and use stored field values
     for (ScoreDoc scoreDoc : indexSearcher.search(q.build(),
             Integer.MAX_VALUE).scoreDocs) {
-      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);
+      Document doc = indexSearcher.doc(scoreDoc.doc);
 
-      StorableField textField = doc.getField(textFieldName);
+      IndexableField textField = doc.getField(textFieldName);
 
       // get the expected result
-      StorableField classField = doc.getField(classFieldName);
+      IndexableField classField = doc.getField(classFieldName);
 
       if (textField != null && classField != null) {
         // assign class to the doc
Index: lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java	(revision 1724443)
+++ lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java	(working copy)
@@ -27,7 +27,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
 import org.apache.lucene.search.BooleanClause;
@@ -194,7 +194,7 @@
     Map<BytesRef, Double> classBoosts = new HashMap<>(); // this is a boost based on class ranking positions in topDocs
     float maxScore = topDocs.getMaxScore();
     for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
-      StorableField storableField = indexSearcher.doc(scoreDoc.doc).getField(classFieldName);
+      IndexableField storableField = indexSearcher.doc(scoreDoc.doc).getField(classFieldName);
       if (storableField != null) {
         BytesRef cl = new BytesRef(storableField.stringValue());
         //update count
@@ -245,4 +245,4 @@
         ", similarity=" + indexSearcher.getSimilarity(true) +
         '}';
   }
-}
\ No newline at end of file
+}
Index: lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java	(revision 1724443)
+++ lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java	(working copy)
@@ -33,6 +33,7 @@
 import org.apache.lucene.classification.SimpleNaiveBayesClassifier;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.Term;
@@ -155,8 +156,8 @@
         fieldName = field2boost[0];
         boost = Float.parseFloat(field2boost[1]);
       }
-      Field[] fieldValues = inputDocument.getFields(fieldName);
-      for (Field fieldValue : fieldValues) {
+      IndexableField[] fieldValues = inputDocument.getFields(fieldName);
+      for (IndexableField fieldValue : fieldValues) {
         TokenStream fieldTokens = fieldValue.tokenStream(field2analyzer.get(fieldName), null);
         String[] fieldTokensArray = getTokenArray(fieldTokens);
         tokenizedValues.add(fieldTokensArray);
@@ -286,4 +287,4 @@
   private int docCount(Term term) throws IOException {
     return leafReader.docFreq(term);
   }
-}
\ No newline at end of file
+}
Index: lucene/classification/src/java/org/apache/lucene/classification/utils/ConfusionMatrixGenerator.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/utils/ConfusionMatrixGenerator.java	(revision 1724443)
+++ lucene/classification/src/java/org/apache/lucene/classification/utils/ConfusionMatrixGenerator.java	(working copy)
@@ -30,8 +30,8 @@
 
 import org.apache.lucene.classification.ClassificationResult;
 import org.apache.lucene.classification.Classifier;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermRangeQuery;
@@ -73,7 +73,7 @@
       double time = 0d;
 
       for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
-        StoredDocument doc = reader.document(scoreDoc.doc);
+        Document doc = reader.document(scoreDoc.doc);
         String[] correctAnswers = doc.getValues(classFieldName);
 
         if (correctAnswers != null && correctAnswers.length > 0) {
Index: lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java	(revision 1724443)
+++ lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java	(working copy)
@@ -26,9 +26,8 @@
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.ScoreDoc;
@@ -92,24 +91,24 @@
 
         // create a new document for indexing
         Document doc = new Document();
-        StoredDocument document = originalIndex.document(scoreDoc.doc);
+        Document document = originalIndex.document(scoreDoc.doc);
         if (fieldNames != null && fieldNames.length > 0) {
           for (String fieldName : fieldNames) {
-            StorableField field = document.getField(fieldName);
+            IndexableField field = document.getField(fieldName);
             if (field != null) {
               doc.add(new Field(fieldName, field.stringValue(), ft));
             }
           }
         } else {
-          for (StorableField storableField : document.getFields()) {
-            if (storableField.readerValue() != null) {
-              doc.add(new Field(storableField.name(), storableField.readerValue(), ft));
-            } else if (storableField.binaryValue() != null) {
-              doc.add(new Field(storableField.name(), storableField.binaryValue(), ft));
-            } else if (storableField.stringValue() != null) {
-              doc.add(new Field(storableField.name(), storableField.stringValue(), ft));
-            } else if (storableField.numericValue() != null) {
-              doc.add(new Field(storableField.name(), storableField.numericValue().toString(), ft));
+          for (IndexableField field : document.getFields()) {
+            if (field.readerValue() != null) {
+              doc.add(new Field(field.name(), field.readerValue(), ft));
+            } else if (field.binaryValue() != null) {
+              doc.add(new Field(field.name(), field.binaryValue(), ft));
+            } else if (field.stringValue() != null) {
+              doc.add(new Field(field.name(), field.stringValue(), ft));
+            } else if (field.numericValue() != null) {
+              doc.add(new Field(field.name(), field.numericValue().toString(), ft));
             }
           }
         }
Index: lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java	(revision 1724443)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexOutput;
@@ -85,7 +85,7 @@
   }
 
   @Override
-  public void writeField(FieldInfo info, StorableField field) throws IOException {
+  public void writeField(FieldInfo info, IndexableField field) throws IOException {
     write(FIELD);
     write(Integer.toString(info.number));
     newLine();
Index: lucene/core/src/java/org/apache/lucene/analysis/package-info.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/package-info.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/analysis/package-info.java	(working copy)
@@ -190,7 +190,7 @@
  * <ul>
  *   <li>
  *     At indexing, as a consequence of 
- *     {@link org.apache.lucene.index.IndexWriter#addDocument(org.apache.lucene.index.IndexDocument) addDocument(doc)},
+ *     {@link org.apache.lucene.index.IndexWriter#addDocument(Iterable) addDocument(doc)},
  *     the <code>Analyzer</code> in effect for indexing is invoked for each indexed field of the added document.
  *   </li>
  *   <li>
@@ -264,7 +264,7 @@
  * </p>
  * <h3>Field Section Boundaries</h3>
  * <p>
- *   When {@link org.apache.lucene.document.Document#add(org.apache.lucene.document.Field) document.add(field)}
+ *   When {@link org.apache.lucene.document.Document#add(org.apache.lucene.index.IndexableField) document.add(field)}
  *   is called multiple times for the same field name, we could say that each such call creates a new 
  *   section for that field in that document. 
  *   In fact, a separate call to 
Index: lucene/core/src/java/org/apache/lucene/codecs/StoredFieldsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/StoredFieldsWriter.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/codecs/StoredFieldsWriter.java	(working copy)
@@ -21,12 +21,14 @@
 import java.io.Reader;
 import java.nio.charset.StandardCharsets;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.document.StoredField;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.IndexableFieldType;
 import org.apache.lucene.index.MergeState;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -36,7 +38,7 @@
  * <ol>
  *   <li>For every document, {@link #startDocument()} is called,
  *       informing the Codec that a new document has started.
- *   <li>{@link #writeField(FieldInfo, StorableField)} is called for 
+ *   <li>{@link #writeField(FieldInfo, IndexableField)} is called for 
  *       each field in the document.
  *   <li>After all documents have been written, {@link #finish(FieldInfos, int)} 
  *       is called for verification/sanity-checks.
@@ -53,7 +55,7 @@
   }
 
   /** Called before writing the stored fields of the document.
-   *  {@link #writeField(FieldInfo, StorableField)} will be called
+   *  {@link #writeField(FieldInfo, IndexableField)} will be called
    *  for each stored field. Note that this is
    *  called even if the document has no stored fields. */
   public abstract void startDocument() throws IOException;
@@ -62,7 +64,7 @@
   public void finishDocument() throws IOException {}
 
   /** Writes a single stored field. */
-  public abstract void writeField(FieldInfo info, StorableField field) throws IOException;
+  public abstract void writeField(FieldInfo info, IndexableField field) throws IOException;
   
   /** Called before {@link #close()}, passing in the number
    *  of documents that were written. Note that this is 
@@ -75,7 +77,7 @@
   /** Merges in the stored fields from the readers in 
    *  <code>mergeState</code>. The default implementation skips
    *  over deleted documents, and uses {@link #startDocument()},
-   *  {@link #writeField(FieldInfo, StorableField)}, and {@link #finish(FieldInfos, int)},
+   *  {@link #writeField(FieldInfo, IndexableField)}, and {@link #finish(FieldInfos, int)},
    *  returning the number of documents that were written.
    *  Implementations can override this method for more sophisticated
    *  merging (bulk-byte copying, etc). */
@@ -115,7 +117,7 @@
    * }
    * </pre>
    */
-  protected class MergeVisitor extends StoredFieldVisitor implements StorableField {
+  protected class MergeVisitor extends StoredFieldVisitor implements IndexableField {
     BytesRef binaryValue;
     String stringValue;
     Number numericValue;
@@ -217,6 +219,16 @@
       return null;
     }
     
+    @Override
+    public float boost() {
+      return 1F;
+    }
+
+    @Override
+    public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {
+      return null;
+    }
+
     void reset(FieldInfo field) {
       if (remapper != null) {
         // field numbers are not aligned, we need to remap to the new field number
Index: lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java	(working copy)
@@ -28,9 +28,9 @@
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MergeState;
 import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
@@ -244,7 +244,7 @@
   }
   
   @Override
-  public void writeField(FieldInfo info, StorableField field)
+  public void writeField(FieldInfo info, IndexableField field)
       throws IOException {
 
     ++numStoredFieldsInDoc;
Index: lucene/core/src/java/org/apache/lucene/document/Document.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/document/Document.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/document/Document.java	(working copy)
@@ -19,17 +19,11 @@
 
 import java.util.*;
 
-import org.apache.lucene.index.DocValuesType;
-import org.apache.lucene.index.IndexDocument;
-import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexReader;  // for javadoc
 import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;  // for javadoc
 import org.apache.lucene.search.ScoreDoc; // for javadoc
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FilterIterator;
 
 /** Documents are the unit of indexing and search.
  *
@@ -44,39 +38,18 @@
  * ScoreDoc#doc} or {@link IndexReader#document(int)}.
  */
 
-public final class Document implements IndexDocument {
+public final class Document implements Iterable<IndexableField> {
 
-  private final List<Field> fields = new ArrayList<>();
+  private final List<IndexableField> fields = new ArrayList<>();
 
   /** Constructs a new document with no fields. */
   public Document() {}
   
-
-  /**
-  * Creates a Document from StoredDocument so it that can be used e.g. for another
-  * round of indexing.
-  *
-  */
-  public Document(StoredDocument storedDoc) {
-    for (StorableField field : storedDoc.getFields()) {
-      Field newField = new Field(field.name(), (FieldType) field.fieldType());
-     
-      newField.fieldsData = field.stringValue();
-      if (newField.fieldsData == null) {
-        newField.fieldsData = field.numericValue();
-      }
-      if (newField.fieldsData == null) {
-        newField.fieldsData = field.binaryValue();
-      }
-      if (newField.fieldsData == null) {
-        newField.fieldsData = field.readerValue();
-      }
-     
-      add(newField);
-    }
+  @Override
+  public Iterator<IndexableField> iterator() {
+    return fields.iterator();
   }
 
-  
   /**
    * <p>Adds a field to a document.  Several fields may be added with
    * the same name.  In this case, if the fields are indexed, their text is
@@ -87,7 +60,7 @@
    * a document has to be deleted from an index and a new changed version of that
    * document has to be added.</p>
    */
-  public final void add(Field field) {
+  public final void add(IndexableField field) {
     fields.add(field);
   }
   
@@ -102,9 +75,9 @@
    * document has to be added.</p>
    */
   public final void removeField(String name) {
-    Iterator<Field> it = fields.iterator();
+    Iterator<IndexableField> it = fields.iterator();
     while (it.hasNext()) {
-      Field field = it.next();
+      IndexableField field = it.next();
       if (field.name().equals(name)) {
         it.remove();
         return;
@@ -122,9 +95,9 @@
    * document has to be added.</p>
    */
   public final void removeFields(String name) {
-    Iterator<Field> it = fields.iterator();
+    Iterator<IndexableField> it = fields.iterator();
     while (it.hasNext()) {
-      Field field = it.next();
+      IndexableField field = it.next();
       if (field.name().equals(name)) {
         it.remove();
       }
@@ -143,9 +116,7 @@
   */
   public final BytesRef[] getBinaryValues(String name) {
     final List<BytesRef> result = new ArrayList<>();
-
-    for (Iterator<StorableField> it = storedFieldsIterator(); it.hasNext(); ) {
-      StorableField field = it.next();
+    for (IndexableField field : fields) {
       if (field.name().equals(name)) {
         final BytesRef bytes = field.binaryValue();
         if (bytes != null) {
@@ -167,8 +138,7 @@
   * @return a <code>BytesRef</code> containing the binary field value or <code>null</code>
   */
   public final BytesRef getBinaryValue(String name) {
-    for (Iterator<StorableField> it = storedFieldsIterator(); it.hasNext(); ) {
-      StorableField field = it.next();
+    for (IndexableField field : fields) {
       if (field.name().equals(name)) {
         final BytesRef bytes = field.binaryValue();
         if (bytes != null) {
@@ -183,8 +153,8 @@
    * null.  If multiple fields exists with this name, this method returns the
    * first value added.
    */
-  public final Field getField(String name) {
-    for (Field field : fields) {
+  public final IndexableField getField(String name) {
+    for (IndexableField field : fields) {
       if (field.name().equals(name)) {
         return field;
       }
@@ -200,15 +170,15 @@
    * @param name the name of the field
    * @return a <code>Field[]</code> array
    */
-  public Field[] getFields(String name) {
-    List<Field> result = new ArrayList<>();
-    for (Field field : fields) {
+  public IndexableField[] getFields(String name) {
+    List<IndexableField> result = new ArrayList<>();
+    for (IndexableField field : fields) {
       if (field.name().equals(name)) {
         result.add(field);
       }
     }
 
-    return result.toArray(new Field[result.size()]);
+    return result.toArray(new IndexableField[result.size()]);
   }
   
   /** Returns a List of all the fields in a document.
@@ -219,11 +189,11 @@
    * 
    * @return an immutable <code>List&lt;Field&gt;</code> 
    */
-  public final List<Field> getFields() {
+  public final List<IndexableField> getFields() {
     return Collections.unmodifiableList(fields);
   }
   
-   private final static String[] NO_STRINGS = new String[0];
+  private final static String[] NO_STRINGS = new String[0];
 
   /**
    * Returns an array of values of the field specified as the method parameter.
@@ -237,9 +207,7 @@
    */
   public final String[] getValues(String name) {
     List<String> result = new ArrayList<>();
-
-    for (Iterator<StorableField> it = storedFieldsIterator(); it.hasNext(); ) {
-      StorableField field = it.next();
+    for (IndexableField field : fields) {
       if (field.name().equals(name) && field.stringValue() != null) {
         result.add(field.stringValue());
       }
@@ -261,8 +229,7 @@
    * the actual numeric field instance back, use {@link #getField}.
    */
   public final String get(String name) {
-    for (Iterator<StorableField> it = storedFieldsIterator(); it.hasNext(); ) {
-      StorableField field = it.next();
+    for (IndexableField field : fields) {
       if (field.name().equals(name) && field.stringValue() != null) {
         return field.stringValue();
       }
@@ -286,46 +253,6 @@
     return buffer.toString();
   }
 
-  /** Obtains all indexed fields in document */
-  @Override
-  public Iterable<IndexableField> indexableFields() {
-    return new Iterable<IndexableField>() {
-      @Override
-      public Iterator<IndexableField> iterator() {
-        return Document.this.indexedFieldsIterator();
-      }
-    };
-  }
-
-  /** Obtains all stored fields in document. */
-  @Override
-  public Iterable<StorableField> storableFields() {
-    return new Iterable<StorableField>() {
-      @Override
-      public Iterator<StorableField> iterator() {
-        return Document.this.storedFieldsIterator();
-      }
-    };
-  }
-
-  private Iterator<StorableField> storedFieldsIterator() {
-    return new FilterIterator<StorableField, Field>(fields.iterator()) {
-      @Override
-      protected boolean predicateFunction(Field field) {
-        return field.type.stored() || field.type.docValuesType() != DocValuesType.NONE || field.type.dimensionCount() != 0;
-      }
-    };
-  }
-  
-  private Iterator<IndexableField> indexedFieldsIterator() {
-    return new FilterIterator<IndexableField, Field>(fields.iterator()) {
-      @Override
-      protected boolean predicateFunction(Field field) {
-        return field.type.indexOptions() != IndexOptions.NONE;
-      }
-    };
-  }
-
   /** Removes all the fields from document. */
   public void clear() {
     fields.clear();
Index: lucene/core/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java	(working copy)
@@ -24,7 +24,6 @@
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.StoredFieldVisitor;
 
 /** A {@link StoredFieldVisitor} that creates a {@link
@@ -37,7 +36,7 @@
  * @lucene.experimental */
 
 public class DocumentStoredFieldVisitor extends StoredFieldVisitor {
-  private final StoredDocument doc = new StoredDocument();
+  private final Document doc = new Document();
   private final Set<String> fieldsToAdd;
 
   /** 
@@ -102,12 +101,12 @@
 
   /**
    * Retrieve the visited document.
-   * @return {@link StoredDocument} populated with stored fields. Note that only
+   * @return {@link Document} populated with stored fields. Note that only
    *         the stored information in the field instances is valid,
    *         data such as indexing options, term vector options,
    *         etc is not set.
    */
-  public StoredDocument getDocument() {
+  public Document getDocument() {
     return doc;
   }
 }
Index: lucene/core/src/java/org/apache/lucene/document/Field.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/document/Field.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/document/Field.java	(working copy)
@@ -28,8 +28,8 @@
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.IndexableFieldType;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.util.BytesRef;
 
 /**
@@ -52,7 +52,7 @@
  * Field it is used in.  It is strongly recommended that no
  * changes be made after Field instantiation.
  */
-public class Field implements IndexableField, StorableField {
+public class Field implements IndexableField {
 
   /**
    * Field's type
Index: lucene/core/src/java/org/apache/lucene/document/FieldType.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/document/FieldType.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/document/FieldType.java	(working copy)
@@ -452,8 +452,6 @@
     return result.toString();
   }
   
-  /* from StorableFieldType */
-  
   /**
    * {@inheritDoc}
    * <p>
Index: lucene/core/src/java/org/apache/lucene/document/StoredField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/document/StoredField.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/document/StoredField.java	(working copy)
@@ -1,10 +1,5 @@
 package org.apache.lucene.document;
 
-import org.apache.lucene.index.IndexReader; // javadocs
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.search.IndexSearcher; // javadocs
-import org.apache.lucene.util.BytesRef;
-
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -22,6 +17,11 @@
  * limitations under the License.
  */
 
+import org.apache.lucene.index.IndexReader; // javadocs
+import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.search.IndexSearcher; // javadocs
+import org.apache.lucene.util.BytesRef;
+
 /** A field whose value is stored so that {@link
  *  IndexSearcher#doc} and {@link IndexReader#document} will
  *  return the field and its value. */
Index: lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(working copy)
@@ -39,6 +39,7 @@
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.codecs.StoredFieldsReader;
 import org.apache.lucene.codecs.TermVectorsReader;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DocumentStoredFieldVisitor;
 import org.apache.lucene.index.CheckIndex.Status.DocValuesStatus;
 import org.apache.lucene.search.DocIdSetIterator;
@@ -1795,7 +1796,7 @@
         // make sure they too are not corrupt:
         DocumentStoredFieldVisitor visitor = new DocumentStoredFieldVisitor();
         storedFields.visitDocument(j, visitor);
-        StoredDocument doc = visitor.getDocument();
+        Document doc = visitor.getDocument();
         if (liveDocs == null || liveDocs.get(j)) {
           status.docCount++;
           status.totFields += doc.getFields().size();
Index: lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(working copy)
@@ -335,29 +335,24 @@
 
     termsHash.startDocument();
 
-    // Invert indexed fields:
+    fillStoredFields(docState.docID);
+    startStoredFields();
+
+    boolean aborting = false;
     try {
-      for (IndexableField field : docState.doc.indexableFields()) {
-        IndexableFieldType fieldType = field.fieldType();
-        
-        // if the field omits norms, the boost cannot be indexed.
-        if (fieldType.omitNorms() && field.boost() != 1.0f) {
-          throw new UnsupportedOperationException("You cannot set an index-time boost: norms are omitted for field '" + field.name() + "'");
-        }
-        
-        PerField fp = getOrAddField(field.name(), fieldType, true);
-        boolean first = fp.fieldGen != fieldGen;
-        fp.invert(field, first);
-
-        if (first) {
-          fields[fieldCount++] = fp;
-          fp.fieldGen = fieldGen;
-        }
+      for (IndexableField field : docState.doc) {
+        fieldCount = processField(field, fieldGen, fieldCount);
       }
+    } catch (AbortingException ae) {
+      aborting = true;
+      throw ae;
     } finally {
-      // Finish each field name seen in the document:
-      for (int i=0;i<fieldCount;i++) {
-        fields[i].finish();
+      if (aborting == false) {
+        // Finish each indexed field name seen in the document:
+        for (int i=0;i<fieldCount;i++) {
+          fields[i].finish();
+        }
+        finishStoredFields();
       }
     }
 
@@ -368,74 +363,93 @@
       // vectors are now corrupt:
       throw AbortingException.wrap(th);
     }
+  }
 
-    // Add stored fields:
-    fillStoredFields(docState.docID);
-    startStoredFields();
+  private int processField(IndexableField field, long fieldGen, int fieldCount) throws IOException, AbortingException {
+    String fieldName = field.name();
+    IndexableFieldType fieldType = field.fieldType();
 
-    // TODO: clean up this loop, it's bogus that docvalues are treated as stored fields...
-    boolean abort = false;
-    try {
-      for (StorableField field : docState.doc.storableFields()) {
-        String fieldName = field.name();
-        IndexableFieldType fieldType = field.fieldType();
+    PerField fp = null;
+
+    if (fieldType.indexOptions() == null) {
+      throw new NullPointerException("IndexOptions must not be null (field: \"" + field.name() + "\")");
+    }
+
+    // Invert indexed fields:
+    if (fieldType.indexOptions() != IndexOptions.NONE) {
       
-        verifyFieldType(fieldName, fieldType);
+      // if the field omits norms, the boost cannot be indexed.
+      if (fieldType.omitNorms() && field.boost() != 1.0f) {
+        throw new UnsupportedOperationException("You cannot set an index-time boost: norms are omitted for field '" + field.name() + "'");
+      }
+      
+      fp = getOrAddField(fieldName, fieldType, true);
+      boolean first = fp.fieldGen != fieldGen;
+      fp.invert(field, first);
 
-        PerField fp = getOrAddField(fieldName, fieldType, false);
-        if (fieldType.stored()) {
-          try {
-            storedFieldsWriter.writeField(fp.fieldInfo, field);
-          } catch (Throwable th) {
-            abort = true;
-            throw AbortingException.wrap(th);
-          }
-        }
+      if (first) {
+        fields[fieldCount++] = fp;
+        fp.fieldGen = fieldGen;
+      }
+    } else {
+      verifyUnIndexedFieldType(fieldName, fieldType);
+    }
 
-        DocValuesType dvType = fieldType.docValuesType();
-        if (dvType == null) {
-          throw new NullPointerException("docValuesType cannot be null (field: \"" + fieldName + "\")");
+    // Add stored fields:
+    if (fieldType.stored()) {
+      if (fp == null) {
+        fp = getOrAddField(fieldName, fieldType, false);
+      }
+      if (fieldType.stored()) {
+        try {
+          storedFieldsWriter.writeField(fp.fieldInfo, field);
+        } catch (Throwable th) {
+          throw AbortingException.wrap(th);
         }
-        if (dvType != DocValuesType.NONE) {
-          indexDocValue(fp, dvType, field);
-        }
-        if (fieldType.dimensionCount() != 0) {
-          indexDimensionalValue(fp, field);
-        }
       }
-    } finally {
-      if (abort == false) {
-        finishStoredFields();
-      }
     }
-  }
 
-  private static void verifyFieldType(String name, IndexableFieldType ft) {
-    if (ft.indexOptions() == null) {
-      throw new NullPointerException("IndexOptions must not be null (field: \"" + name + "\")");
+    DocValuesType dvType = fieldType.docValuesType();
+    if (dvType == null) {
+      throw new NullPointerException("docValuesType cannot be null (field: \"" + fieldName + "\")");
     }
-    if (ft.indexOptions() == IndexOptions.NONE) {
-      if (ft.storeTermVectors()) {
-        throw new IllegalArgumentException("cannot store term vectors "
-                                           + "for a field that is not indexed (field=\"" + name + "\")");
+    if (dvType != DocValuesType.NONE) {
+      if (fp == null) {
+        fp = getOrAddField(fieldName, fieldType, false);
       }
-      if (ft.storeTermVectorPositions()) {
-        throw new IllegalArgumentException("cannot store term vector positions "
-                                           + "for a field that is not indexed (field=\"" + name + "\")");
+      indexDocValue(fp, dvType, field);
+    }
+    if (fieldType.dimensionCount() != 0) {
+      if (fp == null) {
+        fp = getOrAddField(fieldName, fieldType, false);
       }
-      if (ft.storeTermVectorOffsets()) {
-        throw new IllegalArgumentException("cannot store term vector offsets "
-                                           + "for a field that is not indexed (field=\"" + name + "\")");
-      }
-      if (ft.storeTermVectorPayloads()) {
-        throw new IllegalArgumentException("cannot store term vector payloads "
-                                           + "for a field that is not indexed (field=\"" + name + "\")");
-      }
+      indexDimensionalValue(fp, field);
     }
+    
+    return fieldCount;
   }
 
+  private static void verifyUnIndexedFieldType(String name, IndexableFieldType ft) {
+    if (ft.storeTermVectors()) {
+      throw new IllegalArgumentException("cannot store term vectors "
+                                         + "for a field that is not indexed (field=\"" + name + "\")");
+    }
+    if (ft.storeTermVectorPositions()) {
+      throw new IllegalArgumentException("cannot store term vector positions "
+                                         + "for a field that is not indexed (field=\"" + name + "\")");
+    }
+    if (ft.storeTermVectorOffsets()) {
+      throw new IllegalArgumentException("cannot store term vector offsets "
+                                         + "for a field that is not indexed (field=\"" + name + "\")");
+    }
+    if (ft.storeTermVectorPayloads()) {
+      throw new IllegalArgumentException("cannot store term vector payloads "
+                                         + "for a field that is not indexed (field=\"" + name + "\")");
+    }
+  }
+
   /** Called from processDocument to index one field's dimensional value */
-  private void indexDimensionalValue(PerField fp, StorableField field) throws IOException {
+  private void indexDimensionalValue(PerField fp, IndexableField field) throws IOException {
     int dimensionCount = field.fieldType().dimensionCount();
 
     int dimensionNumBytes = field.fieldType().dimensionNumBytes();
@@ -455,7 +469,7 @@
   }
 
   /** Called from processDocument to index one field's doc value */
-  private void indexDocValue(PerField fp, DocValuesType dvType, StorableField field) throws IOException {
+  private void indexDocValue(PerField fp, DocValuesType dvType, IndexableField field) throws IOException {
 
     if (fp.fieldInfo.getDocValuesType() == DocValuesType.NONE) {
       // This is the first time we are seeing this field indexed with doc values, so we
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java	(working copy)
@@ -393,7 +393,7 @@
     }
   }
 
-  boolean updateDocuments(final Iterable<? extends IndexDocument> docs, final Analyzer analyzer,
+  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,
                           final Term delTerm) throws IOException, AbortingException {
     boolean hasEvents = preUpdate();
 
@@ -429,7 +429,7 @@
     return postUpdate(flushingDWPT, hasEvents);
   }
 
-  boolean updateDocument(final IndexDocument doc, final Analyzer analyzer,
+  boolean updateDocument(final Iterable<? extends IndexableField> doc, final Analyzer analyzer,
       final Term delTerm) throws IOException, AbortingException {
 
     boolean hasEvents = preUpdate();
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(working copy)
@@ -73,7 +73,7 @@
     InfoStream infoStream;
     Similarity similarity;
     int docID;
-    IndexDocument doc;
+    Iterable<? extends IndexableField> doc;
 
     DocState(DocumentsWriterPerThread docWriter, InfoStream infoStream) {
       this.docWriter = docWriter;
@@ -212,7 +212,7 @@
     }
   }
 
-  public void updateDocument(IndexDocument doc, Analyzer analyzer, Term delTerm) throws IOException, AbortingException {
+  public void updateDocument(Iterable<? extends IndexableField> doc, Analyzer analyzer, Term delTerm) throws IOException, AbortingException {
     testPoint("DocumentsWriterPerThread addDocument start");
     assert deleteQueue != null;
     reserveOneDoc();
@@ -246,7 +246,7 @@
     finishDocument(delTerm);
   }
 
-  public int updateDocuments(Iterable<? extends IndexDocument> docs, Analyzer analyzer, Term delTerm) throws IOException, AbortingException {
+  public int updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, Term delTerm) throws IOException, AbortingException {
     testPoint("DocumentsWriterPerThread addDocuments start");
     assert deleteQueue != null;
     docState.analyzer = analyzer;
@@ -257,7 +257,7 @@
     boolean allDocsIndexed = false;
     try {
       
-      for(IndexDocument doc : docs) {
+      for(Iterable<? extends IndexableField> doc : docs) {
         // Even on exception, the document is still added (but marked
         // deleted), so we don't need to un-reserve at that point.
         // Aborting exceptions will actually "lose" more than one
Index: lucene/core/src/java/org/apache/lucene/index/GeneralField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/GeneralField.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/GeneralField.java	(working copy)
@@ -1,33 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Represents a single field in lucene document. Further generalizations
- * are {@link IndexableField} and {@link StorableField} interfaces.  
- *
- *  @lucene.experimental */
-
-public interface GeneralField {
-
-  /** Field name */
-  public String name();
-
-  /** {@link IndexableFieldType} describing the properties
-   * of this field. */
-  public IndexableFieldType fieldType();
-}
Index: lucene/core/src/java/org/apache/lucene/index/IndexDocument.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexDocument.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/IndexDocument.java	(working copy)
@@ -1,31 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Elementary interface used for indexing an document.
- * @lucene.internal
- */
-public interface IndexDocument {
-
-  /** Obtains all indexable fields in document */
-  public Iterable<? extends IndexableField> indexableFields();
-  
-  /** Obtains all storable fields in document */
-  public Iterable<? extends StorableField> storableFields();
-}
Index: lucene/core/src/java/org/apache/lucene/index/IndexReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexReader.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/IndexReader.java	(working copy)
@@ -17,11 +17,6 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.document.DocumentStoredFieldVisitor;
-import org.apache.lucene.store.AlreadyClosedException;
-import org.apache.lucene.util.Bits;  // javadocs
-import org.apache.lucene.util.IOUtils;
-
 import java.io.Closeable;
 import java.io.IOException;
 import java.util.Collections;
@@ -31,6 +26,12 @@
 import java.util.WeakHashMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.DocumentStoredFieldVisitor;
+import org.apache.lucene.store.AlreadyClosedException;
+import org.apache.lucene.util.Bits;  // javadocs
+import org.apache.lucene.util.IOUtils;
+
 /**
  IndexReader is an abstract class, providing an interface for accessing a
  point-in-time view of an index.  Any changes made to the index
@@ -364,7 +365,7 @@
   // TODO: we need a separate StoredField, so that the
   // Document returned here contains that class not
   // IndexableField
-  public final StoredDocument document(int docID) throws IOException {
+  public final Document document(int docID) throws IOException {
     final DocumentStoredFieldVisitor visitor = new DocumentStoredFieldVisitor();
     document(docID, visitor);
     return visitor.getDocument();
@@ -375,7 +376,7 @@
    * fields.  Note that this is simply sugar for {@link
    * DocumentStoredFieldVisitor#DocumentStoredFieldVisitor(Set)}.
    */
-  public final StoredDocument document(int docID, Set<String> fieldsToLoad)
+  public final Document document(int docID, Set<String> fieldsToLoad)
       throws IOException {
     final DocumentStoredFieldVisitor visitor = new DocumentStoredFieldVisitor(
         fieldsToLoad);
Index: lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(working copy)
@@ -87,10 +87,10 @@
   new index if there is not already an index at the provided path
   and otherwise open the existing index.</p>
 
-  <p>In either case, documents are added with {@link #addDocument(IndexDocument)
+  <p>In either case, documents are added with {@link #addDocument(Iterable)
   addDocument} and removed with {@link #deleteDocuments(Term...)} or {@link
   #deleteDocuments(Query...)}. A document can be updated with {@link
-  #updateDocument(Term, IndexDocument) updateDocument} (which just deletes
+  #updateDocument(Term, Iterable) updateDocument} (which just deletes
   and then adds the entire document). When finished adding, deleting 
   and updating documents, {@link #close() close} should be called.</p>
 
@@ -1238,7 +1238,7 @@
    * @throws CorruptIndexException if the index is corrupt
    * @throws IOException if there is a low-level IO error
    */
-  public void addDocument(IndexDocument doc) throws IOException {
+  public void addDocument(Iterable<? extends IndexableField> doc) throws IOException {
     updateDocument(null, doc);
   }
 
@@ -1263,7 +1263,7 @@
    * perhaps to obtain better index compression), in which case
    * you may need to fully re-index your documents at that time.
    *
-   * <p>See {@link #addDocument(IndexDocument)} for details on
+   * <p>See {@link #addDocument(Iterable)} for details on
    * index and IndexWriter state after an Exception, and
    * flushing/merging temporary free space requirements.</p>
    *
@@ -1279,7 +1279,7 @@
    *
    * @lucene.experimental
    */
-  public void addDocuments(Iterable<? extends IndexDocument> docs) throws IOException {
+  public void addDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     updateDocuments(null, docs);
   }
 
@@ -1296,7 +1296,7 @@
    *
    * @lucene.experimental
    */
-  public void updateDocuments(Term delTerm, Iterable<? extends IndexDocument> docs) throws IOException {
+  public void updateDocuments(Term delTerm, Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     ensureOpen();
     try {
       boolean success = false;
@@ -1455,7 +1455,7 @@
    * @throws CorruptIndexException if the index is corrupt
    * @throws IOException if there is a low-level IO error
    */
-  public void updateDocument(Term term, IndexDocument doc) throws IOException {
+  public void updateDocument(Term term, Iterable<? extends IndexableField> doc) throws IOException {
     ensureOpen();
     try {
       boolean success = false;
Index: lucene/core/src/java/org/apache/lucene/index/IndexableField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexableField.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/IndexableField.java	(working copy)
@@ -18,11 +18,13 @@
  */
 
 import java.io.IOException;
+import java.io.Reader;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.search.similarities.ClassicSimilarity; // javadocs
 import org.apache.lucene.search.similarities.Similarity; // javadocs
+import org.apache.lucene.util.BytesRef;
 
 // TODO: how to handle versioning here...?
 
@@ -31,8 +33,15 @@
  *
  *  @lucene.experimental */
 
-public interface IndexableField extends GeneralField {
+public interface IndexableField {
 
+  /** Field name */
+  public String name();
+
+  /** {@link IndexableFieldType} describing the properties
+   * of this field. */
+  public IndexableFieldType fieldType();
+
   /**
    * Creates the TokenStream used for indexing this field.  If appropriate,
    * implementations should use the given Analyzer to create the TokenStreams.
@@ -71,4 +80,16 @@
    * @see ClassicSimilarity#encodeNormValue(float)
    */
   public float boost();
+
+  /** Non-null if this field has a binary value */
+  public BytesRef binaryValue();
+
+  /** Non-null if this field has a string value */
+  public String stringValue();
+
+  /** Non-null if this field has a Reader value */
+  public Reader readerValue();
+
+  /** Non-null if this field has a numeric value */
+  public Number numericValue();
 }
Index: lucene/core/src/java/org/apache/lucene/index/StorableField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/StorableField.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/StorableField.java	(working copy)
@@ -1,42 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-
-import org.apache.lucene.util.BytesRef;
-
-/** Represents a single stored field in lucene document. These fields
- * are contained in document retrieved from IndexReader.
- *
- *  @lucene.experimental */
-
-public interface StorableField extends GeneralField {
-
-  /** Non-null if this field has a binary value */
-  public BytesRef binaryValue();
-
-  /** Non-null if this field has a string value */
-  public String stringValue();
-
-  /** Non-null if this field has a Reader value */
-  public Reader readerValue();
-
-  /** Non-null if this field has a numeric value */
-  public Number numericValue(); 
-}
Index: lucene/core/src/java/org/apache/lucene/index/StoredDocument.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/StoredDocument.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/StoredDocument.java	(working copy)
@@ -1,202 +0,0 @@
-package org.apache.lucene.index;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.BytesRef;
-
-/** 
-* StoredDocument is retrieved from IndexReader containing only stored fields from indexed {@link IndexDocument}.
-*/
-// TODO: shouldn't this really be in the .document package?
-public class StoredDocument implements Iterable<StorableField> {
-
-  private final List<StorableField> fields = new ArrayList<>();
-
-  /** Sole constructor. */
-  public StoredDocument() {
-  }
-  
-  /**
-   * Adds a field to a document.
-   * <p> This method supports construction of a StoredDocument from a 
-   * {@link StoredFieldVisitor}. This method cannot
-   * be used to change the content of an existing index! In order to achieve this,
-   * a document has to be deleted from an index and a new changed version of that
-   * document has to be added.</p>
-   */
-  public final void add(StorableField field) {
-    fields.add(field);
-  }
-  
-  /**
-   * Returns an array of {@link StorableField}s with the given name.
-   * This method returns an empty array when there are no
-   * matching fields.  It never returns null.
-   *
-   * @param name the name of the field
-   * @return a <code>StorableField[]</code> array
-   */
-  public StorableField[] getFields(String name) {
-    List<StorableField> result = new ArrayList<>();
-    for (StorableField field : fields) {
-      if (field.name().equals(name)) {
-        result.add(field);
-      }
-    }
-  
-    return result.toArray(new StorableField[result.size()]);
-  }
-  
-  /** Returns a field with the given name if any exist in this document, or
-   * null.  If multiple fields exists with this name, this method returns the
-   * first value added.
-   */
-  public final StorableField getField(String name) {
-    for (StorableField field : fields) {
-      if (field.name().equals(name)) {
-        return field;
-      }
-    }
-    return null;
-  }
-  
-
-  /** Returns a List of all the fields in a document.
-   * <p>Note that fields which are <i>not</i> stored are
-   * <i>not</i> available in documents retrieved from the
-   * index, e.g. {@link IndexSearcher#doc(int)} or {@link
-   * IndexReader#document(int)}.
-   * 
-   * @return an immutable <code>List&lt;StorableField&gt;</code> 
-   */
-  public final List<StorableField> getFields() {
-    return fields;
-  }
-  
-  @Override
-  public Iterator<StorableField> iterator() {
-    return this.fields.iterator();
-  }
-  
-  /**
-   * Returns an array of byte arrays for of the fields that have the name specified
-   * as the method parameter.  This method returns an empty
-   * array when there are no matching fields.  It never
-   * returns null.
-   *
-   * @param name the name of the field
-   * @return a <code>BytesRef[]</code> of binary field values
-   */
-   public final BytesRef[] getBinaryValues(String name) {
-     final List<BytesRef> result = new ArrayList<>();
-     for (StorableField field : fields) {
-       if (field.name().equals(name)) {
-         final BytesRef bytes = field.binaryValue();
-         if (bytes != null) {
-           result.add(bytes);
-         }
-       }
-     }
-   
-     return result.toArray(new BytesRef[result.size()]);
-   }
-   
-   /**
-   * Returns an array of bytes for the first (or only) field that has the name
-   * specified as the method parameter. This method will return <code>null</code>
-   * if no binary fields with the specified name are available.
-   * There may be non-binary fields with the same name.
-   *
-   * @param name the name of the field.
-   * @return a <code>BytesRef</code> containing the binary field value or <code>null</code>
-   */
-   public final BytesRef getBinaryValue(String name) {
-     for (StorableField field : fields) {
-       if (field.name().equals(name)) {
-         final BytesRef bytes = field.binaryValue();
-         if (bytes != null) {
-           return bytes;
-         }
-       }
-     }
-     return null;
-   }
-   private final static String[] NO_STRINGS = new String[0];
-  
-   /**
-    * Returns an array of values of the field specified as the method parameter.
-    * This method returns an empty array when there are no
-    * matching fields.  It never returns null.
-    * For {@link org.apache.lucene.document.LegacyIntField}, {@link org.apache.lucene.document.LegacyLongField}, {@link
-    * org.apache.lucene.document.LegacyFloatField} and {@link org.apache.lucene.document.LegacyDoubleField} it returns the string value of the number. If you want
-    * the actual numeric field instances back, use {@link #getFields}.
-    * @param name the name of the field
-    * @return a <code>String[]</code> of field values
-    */
-   public final String[] getValues(String name) {
-     List<String> result = new ArrayList<>();
-     for (StorableField field : fields) {
-       if (field.name().equals(name) && field.stringValue() != null) {
-         result.add(field.stringValue());
-       }
-     }
-     
-     if (result.size() == 0) {
-       return NO_STRINGS;
-     }
-     
-     return result.toArray(new String[result.size()]);
-   }
-  
-   /** Returns the string value of the field with the given name if any exist in
-    * this document, or null.  If multiple fields exist with this name, this
-    * method returns the first value added. If only binary fields with this name
-    * exist, returns null.
-    * For {@link org.apache.lucene.document.LegacyIntField}, {@link org.apache.lucene.document.LegacyLongField}, {@link
-    * org.apache.lucene.document.LegacyFloatField} and {@link org.apache.lucene.document.LegacyDoubleField} it returns the string value of the number. If you want
-    * the actual numeric field instance back, use {@link #getField}.
-    */
-   public final String get(String name) {
-     for (StorableField field : fields) {
-       if (field.name().equals(name) && field.stringValue() != null) {
-         return field.stringValue();
-       }
-     }
-     return null;
-   }
-
-  /** Prints the fields of a document for human consumption. */
-  @Override
-  public final String toString() {
-    StringBuilder buffer = new StringBuilder();
-    buffer.append("StoredDocument<");
-    for (int i = 0; i < fields.size(); i++) {
-      StorableField field = fields.get(i);
-      buffer.append(field.toString());
-      if (i != fields.size()-1)
-        buffer.append(" ");
-    }
-    buffer.append(">");
-    return buffer.toString();
-  }
-}
Index: lucene/core/src/java/org/apache/lucene/index/TrackingIndexWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/TrackingIndexWriter.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/index/TrackingIndexWriter.java	(working copy)
@@ -48,9 +48,9 @@
   }
 
   /** Calls {@link
-   *  IndexWriter#updateDocument(Term,IndexDocument)} and
+   *  IndexWriter#updateDocument(Term,Iterable)} and
    *  returns the generation that reflects this change. */
-  public long updateDocument(Term t, IndexDocument d) throws IOException {
+  public long updateDocument(Term t, Iterable<? extends IndexableField> d) throws IOException {
     writer.updateDocument(t, d);
     // Return gen as of when indexing finished:
     return indexingGen.get();
@@ -59,7 +59,7 @@
   /** Calls {@link
    *  IndexWriter#updateDocuments(Term,Iterable)} and returns
    *  the generation that reflects this change. */
-  public long updateDocuments(Term t, Iterable<? extends IndexDocument> docs) throws IOException {
+  public long updateDocuments(Term t, Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     writer.updateDocuments(t, docs);
     // Return gen as of when indexing finished:
     return indexingGen.get();
@@ -105,9 +105,9 @@
     return indexingGen.get();
   }
 
-  /** Calls {@link IndexWriter#addDocument(IndexDocument)}
+  /** Calls {@link IndexWriter#addDocument(Iterable)}
    *  and returns the generation that reflects this change. */
-  public long addDocument(IndexDocument d) throws IOException {
+  public long addDocument(Iterable<? extends IndexableField> d) throws IOException {
     writer.addDocument(d);
     // Return gen as of when indexing finished:
     return indexingGen.get();
@@ -115,7 +115,7 @@
 
   /** Calls {@link IndexWriter#addDocuments(Iterable)} and
    *  returns the generation that reflects this change. */
-  public long addDocuments(Iterable<? extends IndexDocument> docs) throws IOException {
+  public long addDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     writer.addDocuments(docs);
     // Return gen as of when indexing finished:
     return indexingGen.get();
Index: lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(working copy)
@@ -30,6 +30,7 @@
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Future;
 
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.DirectoryReader; // javadocs
 import org.apache.lucene.index.FieldInvertState;
 import org.apache.lucene.index.IndexReader;
@@ -38,7 +39,6 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.ReaderUtil;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
@@ -312,7 +312,6 @@
     }
     return slices;
   }
-
   
   /** Return the {@link IndexReader} this searches. */
   public IndexReader getIndexReader() {
@@ -323,7 +322,7 @@
    * Sugar for <code>.getIndexReader().document(docID)</code> 
    * @see IndexReader#document(int) 
    */
-  public StoredDocument doc(int docID) throws IOException {
+  public Document doc(int docID) throws IOException {
     return reader.document(docID);
   }
 
@@ -339,7 +338,7 @@
    * Sugar for <code>.getIndexReader().document(docID, fieldsToLoad)</code>
    * @see IndexReader#document(int, Set) 
    */
-  public StoredDocument doc(int docID, Set<String> fieldsToLoad) throws IOException {
+  public Document doc(int docID, Set<String> fieldsToLoad) throws IOException {
     return reader.document(docID, fieldsToLoad);
   }
 
Index: lucene/core/src/java/org/apache/lucene/store/RAMInputStream.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/RAMInputStream.java	(revision 1724443)
+++ lucene/core/src/java/org/apache/lucene/store/RAMInputStream.java	(working copy)
@@ -97,7 +97,7 @@
       if (enforceEOF) {
         throw new EOFException("read past EOF: " + this);
       } else {
-        // Force EOF if a read takes place at this position
+        // Force EOF if a read later takes place at this position
         currentBufferIndex--;
         bufferPosition = BUFFER_SIZE;
       }
@@ -120,7 +120,10 @@
       currentBufferIndex = (int) (pos / BUFFER_SIZE);
       switchCurrentBuffer(false);
     }
-    bufferPosition = (int) (pos % BUFFER_SIZE);
+    if (pos < BUFFER_SIZE * (long) file.numBuffers()) {
+      // do not overwrite bufferPosition if EOF should be thrown on the next read
+      bufferPosition = (int) (pos % BUFFER_SIZE);
+    }
   }
 
   @Override
Index: lucene/core/src/java/overview.html
===================================================================
--- lucene/core/src/java/overview.html	(revision 1724443)
+++ lucene/core/src/java/overview.html	(working copy)
@@ -54,7 +54,7 @@
     assertEquals(1, hits.length);
     // Iterate through the results:
     for (int i = 0; i < hits.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits[i].doc);
+      Document hitDoc = isearcher.doc(hits[i].doc);
       assertEquals("This is the text to be indexed.", hitDoc.get("fieldname"));
     }
     ireader.close();
@@ -130,7 +130,7 @@
 
 <li>
 Create an {@link org.apache.lucene.index.IndexWriter IndexWriter}
-and add documents to it with {@link org.apache.lucene.index.IndexWriter#addDocument(org.apache.lucene.index.IndexDocument) addDocument()};</li>
+and add documents to it with {@link org.apache.lucene.index.IndexWriter#addDocument(Iterable) addDocument()};</li>
 
 <li>
 Call <a href="../queryparser/org/apache/lucene/queryparser/classic/QueryParserBase.html#parse(java.lang.String)">QueryParser.parse()</a>
Index: lucene/core/src/test/org/apache/lucene/TestDemo.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestDemo.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/TestDemo.java	(working copy)
@@ -25,9 +25,8 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
@@ -65,7 +64,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
     }
 
Index: lucene/core/src/test/org/apache/lucene/TestSearch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestSearch.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/TestSearch.java	(working copy)
@@ -148,7 +148,7 @@
 
         out.println(hits.length + " total results");
         for (int i = 0 ; i < hits.length && i < 10; i++) {
-          StoredDocument d = searcher.doc(hits[i].doc);
+          Document d = searcher.doc(hits[i].doc);
           out.println(i + " " + hits[i].score + " " + d.get("contents"));
         }
       }
Index: lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java	(working copy)
@@ -33,7 +33,6 @@
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.MergePolicy;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
@@ -143,7 +142,7 @@
     out.println(hits.length + " total results\n");
     for (int i = 0 ; i < hits.length; i++) {
       if ( i < 10 || (i > 94 && i < 105) ) {
-        StoredDocument d = searcher.doc(hits[i].doc);
+        Document d = searcher.doc(hits[i].doc);
         out.println(i + " " + d.get(ID_FIELD));
       }
     }
@@ -153,7 +152,7 @@
     assertEquals("total results", expectedCount, hits.length);
     for (int i = 0 ; i < hits.length; i++) {
       if (i < 10 || (i > 94 && i < 105) ) {
-        StoredDocument d = searcher.doc(hits[i].doc);
+        Document d = searcher.doc(hits[i].doc);
         assertEquals("check " + i, String.valueOf(i), d.get(ID_FIELD));
       }
     }
Index: lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat2.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat2.java	(working copy)
@@ -26,6 +26,7 @@
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
@@ -85,8 +86,8 @@
   public void testDFBlockSize() throws Exception {
     Document doc = newDocument();
     for (int i = 0; i < Lucene50PostingsFormat.BLOCK_SIZE; i++) {
-      for (Field f : doc.getFields()) {
-        f.setStringValue(f.name() + " " + f.name() + "_2");
+      for (IndexableField f : doc.getFields()) {
+        ((Field) f).setStringValue(f.name() + " " + f.name() + "_2");
       }
       iw.addDocument(doc);
     }
@@ -96,8 +97,8 @@
   public void testDFBlockSizeMultiple() throws Exception {
     Document doc = newDocument();
     for (int i = 0; i < Lucene50PostingsFormat.BLOCK_SIZE * 16; i++) {
-      for (Field f : doc.getFields()) {
-        f.setStringValue(f.name() + " " + f.name() + "_2");
+      for (IndexableField f : doc.getFields()) {
+        ((Field) f).setStringValue(f.name() + " " + f.name() + "_2");
       }
       iw.addDocument(doc);
     }
@@ -107,8 +108,8 @@
   public void testTTFBlockSize() throws Exception {
     Document doc = newDocument();
     for (int i = 0; i < Lucene50PostingsFormat.BLOCK_SIZE/2; i++) {
-      for (Field f : doc.getFields()) {
-        f.setStringValue(f.name() + " " + f.name() + " " + f.name() + "_2 " + f.name() + "_2");
+      for (IndexableField f : doc.getFields()) {
+        ((Field) f).setStringValue(f.name() + " " + f.name() + " " + f.name() + "_2 " + f.name() + "_2");
       }
       iw.addDocument(doc);
     }
@@ -118,7 +119,7 @@
   public void testTTFBlockSizeMultiple() throws Exception {
     Document doc = newDocument();
     for (int i = 0; i < Lucene50PostingsFormat.BLOCK_SIZE/2; i++) {
-      for (Field f : doc.getFields()) {
+      for (IndexableField f : doc.getFields()) {
         String proto = (f.name() + " " + f.name() + " " + f.name() + " " + f.name() + " " 
                        + f.name() + "_2 " + f.name() + "_2 " + f.name() + "_2 " + f.name() + "_2");
         StringBuilder val = new StringBuilder();
@@ -126,7 +127,7 @@
           val.append(proto);
           val.append(" ");
         }
-        f.setStringValue(val.toString());
+        ((Field) f).setStringValue(val.toString());
       }
       iw.addDocument(doc);
     }
Index: lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestLucene50StoredFieldsFormatHighCompression.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestLucene50StoredFieldsFormatHighCompression.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestLucene50StoredFieldsFormatHighCompression.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.store.Directory;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
@@ -61,7 +60,7 @@
     DirectoryReader ir = DirectoryReader.open(dir);
     assertEquals(10, ir.numDocs());
     for (int i = 0; i < 10; i++) {
-      StoredDocument doc = ir.document(i);
+      Document doc = ir.document(i);
       assertEquals("value1", doc.get("field1"));
       assertEquals("value2", doc.get("field2"));
     }
Index: lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat.java	(working copy)
@@ -50,6 +50,7 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.NumericDocValues;
@@ -59,12 +60,10 @@
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMFile;
 import org.apache.lucene.store.RAMInputStream;
@@ -224,8 +223,8 @@
       final Bits sortedSetBits = DocValues.getDocsWithField(reader, "sorted_set");
 
       for (int i = 0; i < reader.maxDoc(); ++i) {
-        final StoredDocument doc = reader.document(i);
-        final StorableField valueField = doc.getField("value");
+        final Document doc = reader.document(i);
+        final IndexableField valueField = doc.getField("value");
         final Long value = valueField == null ? null : valueField.numericValue().longValue();
 
         if (value == null) {
@@ -247,9 +246,9 @@
           assertTrue(binaryBits.get(i));
         }
 
-        final StorableField[] valuesFields = doc.getFields("values");
+        final IndexableField[] valuesFields = doc.getFields("values");
         final Set<Long> valueSet = new HashSet<>();
-        for (StorableField sf : valuesFields) {
+        for (IndexableField sf : valuesFields) {
           valueSet.add(sf.numericValue().longValue());
         }
 
Index: lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java	(working copy)
@@ -38,7 +38,6 @@
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.RandomCodec;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
@@ -111,7 +110,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv1");
Index: lucene/core/src/test/org/apache/lucene/document/TestBinaryDocument.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/document/TestBinaryDocument.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/document/TestBinaryDocument.java	(working copy)
@@ -1,14 +1,5 @@
 package org.apache.lucene.document;
 
-import java.nio.charset.StandardCharsets;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -26,6 +17,14 @@
  * limitations under the License.
  */
 
+import java.nio.charset.StandardCharsets;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+
 /**
  * Tests {@link Document} class.
  */
@@ -58,7 +57,7 @@
     
     /** open a reader and fetch the document */ 
     IndexReader reader = writer.getReader();
-    StoredDocument docFromReader = reader.document(0);
+    Document docFromReader = reader.document(0);
     assertTrue(docFromReader != null);
     
     /** fetch the binary stored field and compare its content with the original one */
@@ -92,7 +91,7 @@
     
     /** open a reader and fetch the document */ 
     IndexReader reader = writer.getReader();
-    StoredDocument docFromReader = reader.document(0);
+    Document docFromReader = reader.document(0);
     assertTrue(docFromReader != null);
     
     /** fetch the binary compressed field and compare its content with the original one */
Index: lucene/core/src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -26,9 +26,8 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.PhraseQuery;
@@ -171,7 +170,7 @@
   public void testGetFieldsImmutable() {
     Document doc = makeDocumentWithFields();
     assertEquals(10, doc.getFields().size());
-    List<Field> fields = doc.getFields();
+    List<IndexableField> fields = doc.getFields();
     try {
       fields.add( new StringField("name", "value", Field.Store.NO) );
       fail("Document.getFields() should return immutable List");
@@ -213,7 +212,7 @@
     
     IndexSearcher searcher = newSearcher(reader);
     
-    // search for something that does exists
+    // search for something that does exist
     Query query = new TermQuery(new Term("keyword", "test1"));
     
     // ensure that queries return expected results without DateFilter first
@@ -220,7 +219,7 @@
     ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
-    doAssert(searcher.doc(hits[0].doc));
+    doAssert(searcher.doc(hits[0].doc), true);
     writer.close();
     reader.close();
     dir.close();
@@ -250,7 +249,7 @@
     ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
-    doAssert(searcher.doc(hits[0].doc));
+    doAssert(searcher.doc(hits[0].doc), true);
     writer.close();
     reader.close();
     dir.close();    
@@ -276,14 +275,11 @@
     return doc;
   }
   
-  private void doAssert(StoredDocument doc) {
-    doAssert(new Document(doc), true);
-  }
   private void doAssert(Document doc, boolean fromIndex) {
-    StorableField[] keywordFieldValues = doc.getFields("keyword");
-    StorableField[] textFieldValues = doc.getFields("text");
-    StorableField[] unindexedFieldValues = doc.getFields("unindexed");
-    StorableField[] unstoredFieldValues = doc.getFields("unstored");
+    IndexableField[] keywordFieldValues = doc.getFields("keyword");
+    IndexableField[] textFieldValues = doc.getFields("text");
+    IndexableField[] unindexedFieldValues = doc.getFields("unindexed");
+    IndexableField[] unstoredFieldValues = doc.getFields("unstored");
     
     assertTrue(keywordFieldValues.length == 2);
     assertTrue(textFieldValues.length == 2);
@@ -333,7 +329,7 @@
     assertEquals(3, hits.length);
     int result = 0;
     for (int i = 0; i < 3; i++) {
-      StoredDocument doc2 = searcher.doc(hits[i].doc);
+      Document doc2 = searcher.doc(hits[i].doc);
       Field f = (Field) doc2.getField("id");
       if (f.stringValue().equals("id1")) result |= 1;
       else if (f.stringValue().equals("id2")) result |= 2;
@@ -370,7 +366,7 @@
     RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
     iw.addDocument(doc);
     DirectoryReader ir = iw.getReader();
-    StoredDocument sdoc = ir.document(0);
+    Document sdoc = ir.document(0);
     assertEquals("5", sdoc.get("int"));
     assertNull(sdoc.get("somethingElse"));
     assertArrayEquals(new String[] { "5", "4" }, sdoc.getValues("int"));
Index: lucene/core/src/test/org/apache/lucene/document/TestField.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/document/TestField.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/document/TestField.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.TermQuery;
@@ -431,7 +430,7 @@
     IndexSearcher s = newSearcher(r);
     TopDocs hits = s.search(new TermQuery(new Term("binary", br)), 1);
     assertEquals(1, hits.totalHits);
-    StoredDocument storedDoc = s.doc(hits.scoreDocs[0].doc);
+    Document storedDoc = s.doc(hits.scoreDocs[0].doc);
     assertEquals(br, storedDoc.getField("binary").binaryValue());
 
     r.close();
Index: lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/Test4GBStoredFields.java	(working copy)
@@ -96,7 +96,7 @@
     }
 
     DirectoryReader rd = DirectoryReader.open(dir);
-    StoredDocument sd = rd.document(numDocs - 1);
+    Document sd = rd.document(numDocs - 1);
     assertNotNull(sd);
     assertEquals(1, sd.getFields().size());
     BytesRef valueRef = sd.getBinaryValue("fld");
Index: lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -1203,7 +1203,7 @@
     w.close();
     assertEquals(2, r3.numDocs());
     for(int docID=0;docID<2;docID++) {
-      StoredDocument d = r3.document(docID);
+      Document d = r3.document(docID);
       if (d.get("id").equals("1")) {
         assertEquals("doc1 field1", d.get("f1"));
       } else {
Index: lucene/core/src/test/org/apache/lucene/index/TestCustomNorms.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestCustomNorms.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestCustomNorms.java	(working copy)
@@ -70,7 +70,7 @@
     NumericDocValues norms = open.getNormValues(floatTestField);
     assertNotNull(norms);
     for (int i = 0; i < open.maxDoc(); i++) {
-      StoredDocument document = open.document(i);
+      Document document = open.document(i);
       float expected = Float.parseFloat(document.get(floatTestField));
       assertEquals(expected, Float.intBitsToFloat((int)norms.get(i)), 0.0f);
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.java	(working copy)
@@ -677,7 +677,7 @@
         // Slowly parse the stored field into a new doc values field:
         for(int i=0;i<maxDoc;i++) {
           // TODO: is this still O(blockSize^2)?
-          StoredDocument oldDoc = reader.document(i);
+          Document oldDoc = reader.document(i);
           Document newDoc = new Document();
           long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
           newDoc.add(new NumericDocValuesField("number", value));
@@ -733,7 +733,7 @@
           // Must slowly parse the stored field into a new doc values field:
           for(int i=0;i<maxDoc;i++) {
             // TODO: is this still O(blockSize^2)?
-            StoredDocument oldDoc = reader.document(i);
+            Document oldDoc = reader.document(i);
             Document newDoc = new Document();
             long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
             newDoc.add(new NumericDocValuesField("number_" + newSchemaGen, value));
@@ -746,7 +746,7 @@
           assertNotNull("oldSchemaGen=" + oldSchemaGen, oldValues);
           for(int i=0;i<maxDoc;i++) {
             // TODO: is this still O(blockSize^2)?
-            StoredDocument oldDoc = reader.document(i);
+            Document oldDoc = reader.document(i);
             Document newDoc = new Document();
             newDoc.add(new NumericDocValuesField("number_" + newSchemaGen, oldValues.get(i)));
             w.addDocument(newDoc);
@@ -776,7 +776,7 @@
         int maxDoc = r.maxDoc();
         boolean failed = false;
         for(int i=0;i<maxDoc;i++) {
-          StoredDocument oldDoc = r.document(i);
+          Document oldDoc = r.document(i);
           long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
           if (value != numbers.get(i)) {
             if (DEBUG) System.out.println("FAIL: docID=" + i + " " + oldDoc+ " value=" + value + " number=" + numbers.get(i) + " numbers=" + numbers);
@@ -828,7 +828,7 @@
           // Must slowly parse the stored field into a new doc values field:
           for(int i=0;i<maxDoc;i++) {
             // TODO: is this still O(blockSize^2)?
-            StoredDocument oldDoc = reader.document(i);
+            Document oldDoc = reader.document(i);
             Document newDoc = new Document();
             long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
             newDoc.add(new NumericDocValuesField("number", newSchemaGen*value));
@@ -841,7 +841,7 @@
           assertNotNull("oldSchemaGen=" + oldSchemaGen, oldValues);
           for(int i=0;i<maxDoc;i++) {
             // TODO: is this still O(blockSize^2)?
-            StoredDocument oldDoc = reader.document(i);
+            Document oldDoc = reader.document(i);
             Document newDoc = new Document();
             newDoc.add(new NumericDocValuesField("number", newSchemaGen*(oldValues.get(i)/oldSchemaGen)));
             w.addDocument(newDoc);
@@ -875,7 +875,7 @@
         int maxDoc = r.maxDoc();
         boolean failed = false;
         for(int i=0;i<maxDoc;i++) {
-          StoredDocument oldDoc = r.document(i);
+          Document oldDoc = r.document(i);
           long value = Long.parseLong(oldDoc.get("text").split(" ")[1]);
           value *= schemaGen;
           if (value != numbers.get(i)) {
@@ -1135,7 +1135,7 @@
           if (numbers != null) {
             int maxDoc = leaf.maxDoc();
             for(int i=0;i<maxDoc;i++) {
-              StoredDocument doc = leaf.document(i);
+              Document doc = leaf.document(i);
               long value = Long.parseLong(doc.get("text").split(" ")[1]);
               long dvValue = numbers.get(i);
               if (value == 0) {
@@ -1302,7 +1302,7 @@
     boolean failed = false;
     long t0 = System.currentTimeMillis();
     for(int i=0;i<maxDoc;i++) {
-      StoredDocument oldDoc = r.document(i);
+      Document oldDoc = r.document(i);
       long value = multiplier * Long.parseLong(oldDoc.get("text").split(" ")[1]);
       if (value != numbers.get(i)) {
         System.out.println("FAIL: docID=" + i + " " + oldDoc+ " value=" + value + " number=" + numbers.get(i) + " numbers=" + numbers);
Index: lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java	(working copy)
@@ -62,10 +62,10 @@
     assertTrue(reader != null);
     assertTrue(reader instanceof StandardDirectoryReader);
     
-    StoredDocument newDoc1 = reader.document(0);
+    Document newDoc1 = reader.document(0);
     assertTrue(newDoc1 != null);
     assertTrue(DocHelper.numFields(newDoc1) == DocHelper.numFields(doc1) - DocHelper.unstored.size());
-    StoredDocument newDoc2 = reader.document(1);
+    Document newDoc2 = reader.document(1);
     assertTrue(newDoc2 != null);
     assertTrue(DocHelper.numFields(newDoc2) == DocHelper.numFields(doc2) - DocHelper.unstored.size());
     Terms vector = reader.getTermVectors(0).terms(DocHelper.TEXT_FIELD_2_KEY);
@@ -385,11 +385,11 @@
     writer.addDocument(doc);
     writer.close();
     DirectoryReader reader = DirectoryReader.open(dir);
-    StoredDocument doc2 = reader.document(reader.maxDoc() - 1);
-    StorableField[] fields = doc2.getFields("bin1");
+    Document doc2 = reader.document(reader.maxDoc() - 1);
+    IndexableField[] fields = doc2.getFields("bin1");
     assertNotNull(fields);
     assertEquals(1, fields.length);
-    StorableField b1 = fields[0];
+    IndexableField b1 = fields[0];
     assertTrue(b1.binaryValue() != null);
     BytesRef bytesRef = b1.binaryValue();
     assertEquals(bin.length, bytesRef.length);
@@ -595,13 +595,13 @@
     // check stored fields
     for (int i = 0; i < index1.maxDoc(); i++) {
       if (liveDocs1 == null || liveDocs1.get(i)) {
-        StoredDocument doc1 = index1.document(i);
-        StoredDocument doc2 = index2.document(i);
-        List<StorableField> field1 = doc1.getFields();
-        List<StorableField> field2 = doc2.getFields();
+        Document doc1 = index1.document(i);
+        Document doc2 = index2.document(i);
+        List<IndexableField> field1 = doc1.getFields();
+        List<IndexableField> field2 = doc2.getFields();
         assertEquals("Different numbers of fields for doc " + i + ".", field1.size(), field2.size());
-        Iterator<StorableField> itField1 = field1.iterator();
-        Iterator<StorableField> itField2 = field2.iterator();
+        Iterator<IndexableField> itField1 = field1.iterator();
+        Iterator<IndexableField> itField2 = field2.iterator();
         while (itField1.hasNext()) {
           Field curField1 = (Field) itField1.next();
           Field curField2 = (Field) itField2.next();
@@ -1044,7 +1044,7 @@
     Set<String> fieldsToLoad = new HashSet<>();
     assertEquals(0, r.document(0, fieldsToLoad).getFields().size());
     fieldsToLoad.add("field1");
-    StoredDocument doc2 = r.document(0, fieldsToLoad);
+    Document doc2 = r.document(0, fieldsToLoad);
     assertEquals(1, doc2.getFields().size());
     assertEquals("foobar", doc2.get("field1"));
     r.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java	(working copy)
@@ -129,7 +129,7 @@
           if (i>0) {
             int k = i-1;
             int n = j + k*M;
-            StoredDocument prevItereationDoc = reader.document(n);
+            Document prevItereationDoc = reader.document(n);
             assertNotNull(prevItereationDoc);
             String id = prevItereationDoc.get("id");
             assertEquals(k+"_"+j, id);
Index: lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java	(working copy)
@@ -213,7 +213,7 @@
     NumericDocValues dv = slow.getNumericDocValues("dv");
     for (int i = 0; i < 50; i++) {
       assertEquals(i, dv.get(i));
-      StoredDocument d = slow.document(i);
+      Document d = slow.document(i);
       // cannot use d.get("dv") due to another bug!
       assertNull(d.getField("dv"));
       assertEquals(Integer.toString(i), d.get("docId"));
Index: lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(working copy)
@@ -64,11 +64,11 @@
     //After adding the document, we should be able to read it back in
     SegmentReader reader = new SegmentReader(info, newIOContext(random()));
     assertTrue(reader != null);
-    StoredDocument doc = reader.document(0);
+    Document doc = reader.document(0);
     assertTrue(doc != null);
 
     //System.out.println("Document: " + doc);
-    StorableField[] fields = doc.getFields("textField2");
+    IndexableField[] fields = doc.getFields("textField2");
     assertTrue(fields != null && fields.length == 1);
     assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));
     assertTrue(fields[0].fieldType().storeTermVectors());
Index: lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestFieldReuse.java	(working copy)
@@ -18,13 +18,14 @@
  */
 
 import java.io.IOException;
+import java.io.Reader;
 import java.util.Collections;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CannedTokenStream;
+import org.apache.lucene.analysis.LegacyNumericTokenStream.LegacyNumericTermAttribute;
 import org.apache.lucene.analysis.LegacyNumericTokenStream;
-import org.apache.lucene.analysis.LegacyNumericTokenStream.LegacyNumericTermAttribute;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.document.Field;
@@ -31,6 +32,7 @@
 import org.apache.lucene.document.LegacyIntField;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LegacyNumericUtils;
 
 /** test tokenstream reuse by DefaultIndexingChain */
@@ -124,6 +126,26 @@
     public float boost() {
       return 1;
     } 
+
+    @Override
+    public BytesRef binaryValue() {
+      return null;
+    }
+
+    @Override
+    public String stringValue() {
+      return null;
+    }
+
+    @Override
+    public Reader readerValue() {
+      return null;
+    }
+
+    @Override
+    public Number numericValue() {
+      return null;
+    } 
   }
   
   public void testIndexWriterActuallyReuses() throws IOException {
@@ -131,30 +153,12 @@
     IndexWriterConfig iwc = new IndexWriterConfig(null);
     IndexWriter iw = new IndexWriter(dir, iwc);
     final MyField field1 = new MyField();
-    iw.addDocument(new IndexDocument() {
-      @Override
-      public Iterable<? extends IndexableField> indexableFields() {
-        return Collections.singletonList(field1);
-      }
-      @Override
-      public Iterable<StorableField> storableFields() {
-        return Collections.emptyList();
-      }
-    });
+    iw.addDocument(Collections.singletonList(field1));
     TokenStream previous = field1.lastReturned;
     assertNotNull(previous);
     
     final MyField field2 = new MyField();
-    iw.addDocument(new IndexDocument() {
-      @Override
-      public Iterable<? extends IndexableField> indexableFields() {
-        return Collections.singletonList(field2);
-      }
-      @Override
-      public Iterable<StorableField> storableFields() {
-        return Collections.emptyList();
-      }
-    });
+    iw.addDocument(Collections.singletonList(field2));
     assertSame(previous, field2.lastSeen);
     iw.close();
     dir.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestFieldsReader.java	(working copy)
@@ -77,7 +77,7 @@
     assertTrue(dir != null);
     assertTrue(fieldInfos != null);
     IndexReader reader = DirectoryReader.open(dir);
-    StoredDocument doc = reader.document(0);
+    Document doc = reader.document(0);
     assertTrue(doc != null);
     assertTrue(doc.getField(DocHelper.TEXT_FIELD_1_KEY) != null);
 
@@ -102,7 +102,7 @@
 
     DocumentStoredFieldVisitor visitor = new DocumentStoredFieldVisitor(DocHelper.TEXT_FIELD_3_KEY);
     reader.document(0, visitor);
-    final List<StorableField> fields = visitor.getDocument().getFields();
+    final List<IndexableField> fields = visitor.getDocument().getFields();
     assertEquals(1, fields.size());
     assertEquals(DocHelper.TEXT_FIELD_3_KEY, fields.get(0).name());
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -1236,8 +1236,8 @@
     w.close();
 
     IndexReader ir = DirectoryReader.open(dir);
-    StoredDocument doc2 = ir.document(0);
-    StorableField f3 = doc2.getField("binary");
+    Document doc2 = ir.document(0);
+    IndexableField f3 = doc2.getField("binary");
     b = f3.binaryValue().bytes;
     assertTrue(b != null);
     assertEquals(17, b.length, 17);
@@ -2063,69 +2063,6 @@
     dir.close();
   }
   
-  public void testNullIterable1() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    // add 3 good docs
-    for (int i = 0; i < 3; i++) {
-      Document doc = new Document();
-      doc.add(new StringField("id", Integer.toString(i), Field.Store.NO));
-      iw.addDocument(doc);
-    }
-    // add broken doc
-    try {
-      iw.addDocument(new IndexDocument() {
-        @Override
-        public Iterable<IndexableField> indexableFields() {
-          return null;
-        }
-        
-        @Override
-        public Iterable<StorableField> storableFields() {
-          return Collections.emptyList();
-        }
-      });
-      fail();
-    } catch (NullPointerException expected) {}
-    // ensure good docs are still ok
-    IndexReader ir = iw.getReader();
-    assertEquals(3, ir.numDocs());
-    ir.close();
-    iw.close();
-    dir.close();
-  }
-  
-  public void testNullIterable2() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    // add 3 good docs
-    for (int i = 0; i < 3; i++) {
-      Document doc = new Document();
-      doc.add(new StringField("id", Integer.toString(i), Field.Store.NO));
-      iw.addDocument(doc);
-    }
-    // add broken doc
-    try {
-      iw.addDocument(new IndexDocument() {
-        @Override
-        public Iterable<IndexableField> indexableFields() {
-          return Collections.emptyList();
-        }
-        
-        @Override
-        public Iterable<StorableField> storableFields() {
-          return null;
-        }
-      });
-    } catch (NullPointerException expected) {}
-    // ensure good docs are still ok
-    IndexReader ir = iw.getReader();
-    assertEquals(3, ir.numDocs());
-    ir.close();
-    iw.close();
-    dir.close();
-  }
-  
   public void testIterableFieldThrowsException() throws IOException {
     Directory dir = newDirectory();
     IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));
@@ -2137,27 +2074,14 @@
       int numDocs = atLeast(4);
       for (int j = 0; j < numDocs; j++) {
         String id = Integer.toString(docId++);
-        final List<StorableField> storedFields = new ArrayList<>();
-        storedFields.add(new StoredField("id", id));
-        storedFields.add(new StoredField("foo",TestUtil.randomSimpleString(random())));
-        final List<IndexableField> indexFields = new ArrayList<>();
-        indexFields.add(new StringField("id", id, Field.Store.NO));
-        indexFields.add(new StringField("foo", TestUtil.randomSimpleString(random()), Field.Store.NO));
+        final List<IndexableField> fields = new ArrayList<>();
+        fields.add(new StringField("id", id, Field.Store.YES));
+        fields.add(new StringField("foo", TestUtil.randomSimpleString(random()), Field.Store.NO));
         docId++;
         
         boolean success = false;
         try {
-          w.addDocument(new IndexDocument() {
-            @Override
-            public Iterable<IndexableField> indexableFields() {
-              return new RandomFailingIterable<IndexableField>(indexFields, random());
-            }
-
-            @Override
-            public Iterable<StorableField> storableFields() {
-              return new RandomFailingIterable<StorableField>(storedFields, random());
-            }        
-          });
+          w.addDocument(new RandomFailingIterable<IndexableField>(fields, random()));
           success = true;
         } catch (RuntimeException e) {
           assertEquals("boom", e.getMessage());
@@ -2195,28 +2119,24 @@
     int docId = 0;
     Set<String> liveIds = new HashSet<>();
     for (int i = 0; i < iters; i++) {
-      List<Document> docs = new ArrayList<>();
-      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
-      FieldType idFt = new FieldType(TextField.TYPE_STORED);
-      
       int numDocs = atLeast(4);
       for (int j = 0; j < numDocs; j++) {
-        Document doc = new Document();
-        doc.add(newField("id", ""+ (docId++), idFt));
-        doc.add(newField("foo", TestUtil.randomSimpleString(random()), ft));
-        docs.add(doc);
-      }
-      boolean success = false;
-      try {
-        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));
-        success = true;
-      } catch (RuntimeException e) {
-        assertEquals("boom", e.getMessage());
-      } finally {
-        if (success) {
-          docCount += docs.size();
-          for (Document indexDocument : docs) {
-            liveIds.add(indexDocument.get("id"));  
+        String id = Integer.toString(docId++);
+        final List<IndexableField> fields = new ArrayList<>();
+        fields.add(new StringField("id", id, Field.Store.YES));
+        fields.add(new StringField("foo", TestUtil.randomSimpleString(random()), Field.Store.NO));
+        docId++;
+
+        boolean success = false;
+        try {
+          w.addDocument(new RandomFailingIterable<IndexableField>(fields, random()));
+          success = true;
+        } catch (RuntimeException e) {
+          assertEquals("boom", e.getMessage());
+        } finally {
+          if (success) {
+            docCount++;
+            liveIds.add(id);
           }
         }
       }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
+import java.io.Reader;
 import java.io.StringReader;
 import java.nio.file.NoSuchFileException;
 import java.util.ArrayList;
@@ -56,14 +57,14 @@
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.store.MockDirectoryWrapper.FakeIOException;
 import org.apache.lucene.store.MockDirectoryWrapper;
-import org.apache.lucene.store.MockDirectoryWrapper.FakeIOException;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InfoStream;
+import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.TestUtil;
 
 @SuppressCodecs("SimpleText") // too slow here
@@ -1747,46 +1748,49 @@
     try {
       doc = new Document();
       // try to boost with norms omitted
-      IndexDocument docList = new IndexDocument() {
-        
-        List<IndexableField> list = new ArrayList<>();
-        List<StorableField> storedList = new ArrayList<>();
-        
+      List<IndexableField> list = new ArrayList<>();
+      list.add(new IndexableField() {
         @Override
-        public Iterable<IndexableField> indexableFields() {
-          if (list.size() == 0) {
-            list.add(new IndexableField() {
-              @Override
-              public String name() {
-                return "foo";
-              }
+        public String name() {
+          return "foo";
+        }
 
-              @Override
-              public IndexableFieldType fieldType() {
-                return StringField.TYPE_NOT_STORED;
-              }
+        @Override
+        public IndexableFieldType fieldType() {
+          return StringField.TYPE_NOT_STORED;
+        }
 
-              @Override
-              public float boost() {
-                return 5f;
-              }
+        @Override
+        public float boost() {
+          return 5f;
+        }
 
-              @Override
-              public TokenStream tokenStream(Analyzer analyzer, TokenStream previous) throws IOException {
-                return null;
-              }
-            });
-          }
-          return list;
+        @Override
+        public BytesRef binaryValue() {
+          return null;
         }
 
         @Override
-        public Iterable<StorableField> storableFields() {
-          return storedList;
+        public String stringValue() {
+          return "baz";
         }
-        
-      };
-      iw.addDocument(docList);
+
+        @Override
+        public Reader readerValue() {
+          return null;
+        }
+
+        @Override
+        public Number numericValue() {
+          return null;
+        }
+
+        @Override
+        public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {
+          return null;
+        }
+      });
+      iw.addDocument(list);
       fail("didn't get any exception, boost silently discarded");
     } catch (UnsupportedOperationException expected) {
       // expected
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -85,7 +85,7 @@
     int max = reader.maxDoc();
     for (int i = 0; i < max; i++)
     {
-      StoredDocument temp = reader.document(i);
+      Document temp = reader.document(i);
       //System.out.println("doc "+i+"="+temp.getField("count").stringValue());
       //compare the index doc number to the value that it should be
       if (!temp.getField("count").stringValue().equals((i + startAt) + ""))
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -152,7 +152,7 @@
 
     String id10 = r1.document(10).getField("id").stringValue();
     
-    Document newDoc = new Document(r1.document(10));
+    Document newDoc = r1.document(10);
     newDoc.removeField("id");
     newDoc.add(newStringField("id", Integer.toString(8000), Field.Store.YES));
     writer.updateDocument(new Term("id", id10), newDoc);
@@ -280,9 +280,9 @@
     assertEquals(100, index2df);
 
     // verify the docs are from different indexes
-    StoredDocument doc5 = r1.document(5);
+    Document doc5 = r1.document(5);
     assertEquals("index1", doc5.get("indexname"));
-    StoredDocument doc150 = r1.document(150);
+    Document doc150 = r1.document(150);
     assertEquals("index2", doc150.get("indexname"));
     r1.close();
     writer.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode.java	(working copy)
@@ -260,7 +260,7 @@
     w.close();
 
     IndexReader ir = DirectoryReader.open(dir);
-    StoredDocument doc2 = ir.document(0);
+    Document doc2 = ir.document(0);
     for(int i=0;i<count;i++) {
       assertEquals("field " + i + " was not indexed correctly", 1, ir.docFreq(new Term("f"+i, utf8Data[2*i+1])));
       assertEquals("field " + i + " is incorrect", utf8Data[2*i+1], doc2.getField("f"+i).stringValue());
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java	(working copy)
@@ -25,6 +25,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.document.StoredField;
@@ -41,7 +42,7 @@
 
 public class TestIndexableField extends LuceneTestCase {
 
-  private class MyField implements IndexableField, StorableField {
+  private class MyField implements IndexableField {
 
     private final int counter;
     private final IndexableFieldType fieldType = new IndexableFieldType() {
@@ -190,99 +191,35 @@
       final int finalBaseCount = baseCount;
       baseCount += fieldCount-1;
 
-      IndexDocument d = new IndexDocument() {
+      Iterable<IndexableField> d = new Iterable<IndexableField>() {
         @Override
-        public Iterable<IndexableField> indexableFields() {
-          return new Iterable<IndexableField>() {
+        public Iterator<IndexableField> iterator() {
+          return new Iterator<IndexableField>() {
+            int fieldUpto;
+
             @Override
-            public Iterator<IndexableField> iterator() {
-              return new Iterator<IndexableField>() {
-                int fieldUpto = 0;
-                private IndexableField next;
+            public boolean hasNext() {
+              return fieldUpto < fieldCount;
+            }
 
-                @Override
-                public boolean hasNext() {
-                  if (fieldUpto >= fieldCount) return false;
-
-                  next = null;
-                  if (fieldUpto == 0) {
-                    fieldUpto = 1;
-                    next = newStringField("id", ""+finalDocCount, Field.Store.YES);
-                  } else {
-                    next = new MyField(finalBaseCount + (fieldUpto++-1));
-                  }
-                  
-                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;
-                  else return this.hasNext();
-                }
-
-                @Override
-                public IndexableField next() {
-                  assert fieldUpto <= fieldCount;
-                  if (next == null && !hasNext()) {
-                    return null;
-                  }
-                  else {
-                    return next;
-                  }
-                }
-
-                @Override
-                public void remove() {
-                  throw new UnsupportedOperationException();
-                }
-              };
+            @Override
+            public IndexableField next() {
+              assert fieldUpto < fieldCount;
+              if (fieldUpto == 0) {
+                fieldUpto = 1;
+                return newStringField("id", ""+finalDocCount, Field.Store.YES);
+              } else {
+                return new MyField(finalBaseCount + (fieldUpto++-1));
+              }
             }
-          };
-        }
 
-        @Override
-        public Iterable<StorableField> storableFields() {
-          return new Iterable<StorableField>() {
             @Override
-            public Iterator<StorableField> iterator() {
-              return new Iterator<StorableField>() {
-                int fieldUpto = 0;
-                private StorableField next = null;
-
-                @Override
-                public boolean hasNext() {
-
-                  if (fieldUpto == fieldCount) return false;
-                  
-                  next = null;
-                  if (fieldUpto == 0) {
-                    fieldUpto = 1;
-                    next = newStringField("id", ""+finalDocCount, Field.Store.YES);
-                  } else {
-                    next = new MyField(finalBaseCount + (fieldUpto++-1));
-                  }
-                  
-                  if (next != null && next.fieldType().stored()) return true;
-                  else return this.hasNext();
-                }
-
-                @Override
-                public StorableField next() {
-                  assert fieldUpto <= fieldCount;
-                  if (next == null && !hasNext()) {
-                    return null;
-                  }
-                  else {
-                    return next;
-                  }
-                }
-
-                @Override
-                public void remove() {
-                  throw new UnsupportedOperationException();
-                }
-              };
+            public void remove() {
+              throw new UnsupportedOperationException();
             }
           };
         }
-      };
-      
+        };
       w.addDocument(d);
     }
 
@@ -299,7 +236,7 @@
       final TopDocs hits = s.search(new TermQuery(new Term("id", ""+id)), 1);
       assertEquals(1, hits.totalHits);
       final int docID = hits.scoreDocs[0].doc;
-      final StoredDocument doc = s.doc(docID);
+      final Document doc = s.doc(docID);
       final int endCounter = counter + fieldsPerDoc[id];
       while(counter < endCounter) {
         final String name = "f" + counter;
@@ -318,7 +255,7 @@
 
         // stored:
         if (stored) {
-          StorableField f = doc.getField(name);
+          IndexableField f = doc.getField(name);
           assertNotNull("doc " + id + " doesn't have field f" + counter, f);
           if (binary) {
             assertNotNull("doc " + id + " doesn't have field f" + counter, f);
@@ -386,7 +323,7 @@
     dir.close();
   }
 
-  private static class CustomField implements StorableField {
+  private static class CustomField implements IndexableField {
     @Override
     public BytesRef binaryValue() {
       return null;
@@ -403,6 +340,11 @@
     }
 
     @Override
+    public float boost() {
+      return 1.0f;
+    }
+
+    @Override
     public Number numericValue() {
       return null;
     }
@@ -413,6 +355,11 @@
     }
 
     @Override
+    public TokenStream tokenStream(Analyzer a, TokenStream reuse) {
+      return null;
+    }
+
+    @Override
     public IndexableFieldType fieldType() {
       FieldType ft = new FieldType(StoredField.TYPE);
       ft.setStoreTermVectors(true);
@@ -426,17 +373,7 @@
     Directory dir = newDirectory();
     RandomIndexWriter w = new RandomIndexWriter(random(), dir);
     try {
-      w.addDocument(
-                    new IndexDocument() {
-                      @Override
-                      public Iterable<IndexableField> indexableFields() {
-                        return Collections.emptyList();
-                      }
-                      @Override
-                      public Iterable<StorableField> storableFields() {
-                        return Collections.<StorableField>singletonList(new CustomField());
-                      }
-                    });
+      w.addDocument(Collections.<IndexableField>singletonList(new CustomField()));
       fail("didn't hit exception");
     } catch (IllegalArgumentException iae) {
       // expected
Index: lucene/core/src/test/org/apache/lucene/index/TestNorms.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestNorms.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestNorms.java	(working copy)
@@ -115,7 +115,7 @@
     NumericDocValues normValues = open.getNormValues(byteTestField);
     assertNotNull(normValues);
     for (int i = 0; i < open.maxDoc(); i++) {
-      StoredDocument document = open.document(i);
+      Document document = open.document(i);
       int expected = Integer.parseInt(document.get(byteTestField));
       assertEquals(expected, normValues.get(i));
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(working copy)
@@ -416,8 +416,8 @@
     assertEquals(parallelHits.length, singleHits.length);
     for(int i = 0; i < parallelHits.length; i++) {
       assertEquals(parallelHits[i].score, singleHits[i].score, 0.001f);
-      StoredDocument docParallel = parallel.doc(parallelHits[i].doc);
-      StoredDocument docSingle = single.doc(singleHits[i].doc);
+      Document docParallel = parallel.doc(parallelHits[i].doc);
+      Document docSingle = single.doc(singleHits[i].doc);
       assertEquals(docParallel.get("f1"), docSingle.get("f1"));
       assertEquals(docParallel.get("f2"), docSingle.get("f2"));
       assertEquals(docParallel.get("f3"), docSingle.get("f3"));
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java	(working copy)
@@ -249,8 +249,8 @@
     assertEquals(parallelHits.length, singleHits.length);
     for(int i = 0; i < parallelHits.length; i++) {
       assertEquals(parallelHits[i].score, singleHits[i].score, 0.001f);
-      StoredDocument docParallel = parallel.doc(parallelHits[i].doc);
-      StoredDocument docSingle = single.doc(singleHits[i].doc);
+      Document docParallel = parallel.doc(parallelHits[i].doc);
+      Document docSingle = single.doc(singleHits[i].doc);
       assertEquals(docParallel.get("f1"), docSingle.get("f1"));
       assertEquals(docParallel.get("f2"), docSingle.get("f2"));
       assertEquals(docParallel.get("f3"), docSingle.get("f3"));
Index: lucene/core/src/test/org/apache/lucene/index/TestReadOnlyIndex.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestReadOnlyIndex.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestReadOnlyIndex.java	(working copy)
@@ -89,7 +89,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
     }
 
Index: lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java	(working copy)
@@ -76,7 +76,7 @@
       if (VERBOSE) {
         System.out.println("  docIter=" + docIter + " id=" + id);
       }
-      doc.getField("docid").setStringValue(myID);
+      ((Field) doc.getField("docid")).setStringValue(myID);
 
       Term idTerm = new Term("docid", myID);
 
Index: lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java	(working copy)
@@ -99,11 +99,11 @@
                                                    newIOContext(random()));
     assertTrue(mergedReader != null);
     assertTrue(mergedReader.numDocs() == 2);
-    StoredDocument newDoc1 = mergedReader.document(0);
+    Document newDoc1 = mergedReader.document(0);
     assertTrue(newDoc1 != null);
     //There are 2 unstored fields on the document
     assertTrue(DocHelper.numFields(newDoc1) == DocHelper.numFields(doc1) - DocHelper.unstored.size());
-    StoredDocument newDoc2 = mergedReader.document(1);
+    Document newDoc2 = mergedReader.document(1);
     assertTrue(newDoc2 != null);
     assertTrue(DocHelper.numFields(newDoc2) == DocHelper.numFields(doc2) - DocHelper.unstored.size());
 
Index: lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java	(working copy)
@@ -62,13 +62,13 @@
   public void testDocument() throws IOException {
     assertTrue(reader.numDocs() == 1);
     assertTrue(reader.maxDoc() >= 1);
-    StoredDocument result = reader.document(0);
+    Document result = reader.document(0);
     assertTrue(result != null);
     //There are 2 unstored fields on the document that are not preserved across writing
     assertTrue(DocHelper.numFields(result) == DocHelper.numFields(testDoc) - DocHelper.unstored.size());
     
-    List<StorableField> fields = result.getFields();
-    for (final StorableField field : fields ) { 
+    List<IndexableField> fields = result.getFields();
+    for (final IndexableField field : fields ) { 
       assertTrue(field != null);
       assertTrue(DocHelper.nameValues.containsKey(field.name()));
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -116,9 +116,9 @@
 
   static Term idTerm = new Term("id","");
   IndexingThread[] threads;
-  static Comparator<GeneralField> fieldNameComparator = new Comparator<GeneralField>() {
+  static Comparator<IndexableField> fieldNameComparator = new Comparator<IndexableField>() {
     @Override
-    public int compare(GeneralField o1, GeneralField o2) {
+    public int compare(IndexableField o1, IndexableField o2) {
       return o1.name().compareTo(o2.name());
     }
   };
@@ -238,7 +238,7 @@
     Iterator<Document> iter = docs.values().iterator();
     while (iter.hasNext()) {
       Document d = iter.next();
-      ArrayList<Field> fields = new ArrayList<>();
+      ArrayList<IndexableField> fields = new ArrayList<>();
       fields.addAll(d.getFields());
       // put fields in same order each time
       Collections.sort(fields, fieldNameComparator);
@@ -275,7 +275,7 @@
       Bits liveDocs = sub.getLiveDocs();
       System.out.println("  " + ((SegmentReader) sub).getSegmentInfo());
       for(int docID=0;docID<sub.maxDoc();docID++) {
-        StoredDocument doc = sub.document(docID);
+        Document doc = sub.document(docID);
         if (liveDocs == null || liveDocs.get(docID)) {
           System.out.println("    docID=" + docID + " id:" + doc.get("id"));
         } else {
@@ -575,9 +575,9 @@
     }
   }
 
-  public static void verifyEquals(StoredDocument d1, StoredDocument d2) {
-    List<StorableField> ff1 = d1.getFields();
-    List<StorableField> ff2 = d2.getFields();
+  public static void verifyEquals(Document d1, Document d2) {
+    List<IndexableField> ff1 = new ArrayList<>(d1.getFields());
+    List<IndexableField> ff2 = new ArrayList<>(d2.getFields());
 
     Collections.sort(ff1, fieldNameComparator);
     Collections.sort(ff2, fieldNameComparator);
@@ -585,8 +585,8 @@
     assertEquals(ff1 + " : " + ff2, ff1.size(), ff2.size());
 
     for (int i=0; i<ff1.size(); i++) {
-      StorableField f1 = ff1.get(i);
-      StorableField f2 = ff2.get(i);
+      IndexableField f1 = ff1.get(i);
+      IndexableField f2 = ff2.get(i);
       if (f1.binaryValue() != null) {
         assert(f2.binaryValue() != null);
       } else {
Index: lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressNRT.java	(working copy)
@@ -356,12 +356,12 @@
                 if (results.totalHits != 1) {
                   System.out.println("FAIL: hits id:" + id + " val=" + val);
                   for(ScoreDoc sd : results.scoreDocs) {
-                    final StoredDocument doc = r.document(sd.doc);
+                    final Document doc = r.document(sd.doc);
                     System.out.println("  docID=" + sd.doc + " id:" + doc.get("id") + " foundVal=" + doc.get(field));
                   }
                   fail("id=" + id + " reader=" + r + " totalHits=" + results.totalHits);
                 }
-                StoredDocument doc = searcher.doc(results.scoreDocs[0].doc);
+                Document doc = searcher.doc(results.scoreDocs[0].doc);
                 long foundVal = Long.parseLong(doc.get(field));
                 if (foundVal < Math.abs(val)) {
                   fail("foundVal=" + foundVal + " val=" + val + " id=" + id + " reader=" + r);
Index: lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java	(working copy)
@@ -931,7 +931,7 @@
         int docID = postingsEnum.nextDoc();
         assertTrue(docID != PostingsEnum.NO_MORE_DOCS);
         assertEquals(docID, pkLookup.lookup(termBytesRef));
-        StoredDocument doc = r.document(docID);
+        Document doc = r.document(docID);
         assertEquals(term, doc.get("id"));
 
         if (random().nextInt(7) == 1) {
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(working copy)
@@ -17,24 +17,23 @@
  * limitations under the License.
  */
 
+import java.text.DecimalFormat;
+import java.text.DecimalFormatSymbols;
+import java.util.Locale;
+import java.util.Random;
+
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.similarities.ClassicSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
-import java.text.DecimalFormat;
-import java.text.DecimalFormatSymbols;
-import java.util.Locale;
-import java.util.Random;
-
 /** Test that BooleanQuery.setMinimumNumberShouldMatch works.
  */
 public class TestBooleanMinShouldMatch extends LuceneTestCase {
@@ -446,7 +445,7 @@
         DecimalFormat f = new DecimalFormat("0.000000", DecimalFormatSymbols.getInstance(Locale.ROOT));
 
         for (int i = 0; i < h.length; i++) {
-            StoredDocument d = searcher.doc(h[i].doc);
+            Document d = searcher.doc(h[i].doc);
             float score = h[i].score;
             System.err.println("#" + i + ": " + f.format(score) + " - " +
                                d.get("id") + " - " + d.get("data"));
Index: lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java	(working copy)
@@ -30,10 +30,10 @@
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexDocument;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;
 import org.apache.lucene.index.NoMergePolicy;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -93,7 +93,7 @@
   }
 
   @Override
-  protected void updateDocuments(Term id, List<? extends IndexDocument> docs) throws Exception {
+  protected void updateDocuments(Term id, List<? extends Iterable<? extends IndexableField>> docs) throws Exception {
     final long gen = genWriter.updateDocuments(id, docs);
 
     // Randomly verify the update "took":
@@ -118,7 +118,7 @@
   }
 
   @Override
-  protected void addDocuments(Term id, List<? extends IndexDocument> docs) throws Exception {
+  protected void addDocuments(Term id, List<? extends Iterable<? extends IndexableField>> docs) throws Exception {
     final long gen = genWriter.addDocuments(docs);
     // Randomly verify the add "took":
     if (random().nextInt(20) == 2) {
@@ -141,7 +141,7 @@
   }
 
   @Override
-  protected void addDocument(Term id, IndexDocument doc) throws Exception {
+  protected void addDocument(Term id, Iterable<? extends IndexableField> doc) throws Exception {
     final long gen = genWriter.addDocument(doc);
 
     // Randomly verify the add "took":
@@ -165,7 +165,7 @@
   }
 
   @Override
-  protected void updateDocument(Term id, IndexDocument doc) throws Exception {
+  protected void updateDocument(Term id, Iterable<? extends IndexableField> doc) throws Exception {
     final long gen = genWriter.updateDocument(id, doc);
     // Randomly verify the udpate "took":
     if (random().nextInt(20) == 2) {
@@ -394,7 +394,7 @@
 
     @Override
     public void updateDocument(Term term,
-        IndexDocument doc)
+        Iterable<? extends IndexableField> doc)
         throws IOException {
       super.updateDocument(term, doc);
       try {
Index: lucene/core/src/test/org/apache/lucene/search/TestDateSort.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDateSort.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestDateSort.java	(working copy)
@@ -19,10 +19,6 @@
 
 import java.util.Arrays;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -29,8 +25,10 @@
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
 
 /**
  * Test date sorting, i.e. auto-sorting of fields with type "long".
@@ -85,7 +83,7 @@
     String[] actualOrder = new String[5];
     ScoreDoc[] hits = searcher.search(query, 1000, sort).scoreDocs;
     for (int i = 0; i < hits.length; i++) {
-      StoredDocument document = searcher.doc(hits[i].doc);
+      Document document = searcher.doc(hits[i].doc);
       String text = document.get(TEXT_FIELD);
       actualOrder[i] = text;
     }
Index: lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(working copy)
@@ -37,7 +37,6 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.similarities.ClassicSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
@@ -529,7 +528,7 @@
     DecimalFormat f = new DecimalFormat("0.000000000", DecimalFormatSymbols.getInstance(Locale.ROOT));
     
     for (int i = 0; i < h.length; i++) {
-      StoredDocument d = searcher.doc(h[i].doc);
+      Document d = searcher.doc(h[i].doc);
       float score = h[i].score;
       System.err
           .println("#" + i + ": " + f.format(score) + " - " + d.get("id"));
Index: lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.similarities.ClassicSimilarity;
@@ -265,12 +264,12 @@
     for (String searchTerm : searchTerms) {
       FuzzyQuery query = new FuzzyQuery(new Term("field", searchTerm), 2, 1);
       ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
-      StoredDocument bestDoc = searcher.doc(hits[0].doc);
+      Document bestDoc = searcher.doc(hits[0].doc);
       assertTrue(hits.length > 0);
       String topMatch = bestDoc.get("field");
       assertEquals(searchTerm, topMatch);
       if (hits.length > 1) {
-        StoredDocument worstDoc = searcher.doc(hits[hits.length - 1].doc);
+        Document worstDoc = searcher.doc(hits[hits.length - 1].doc);
         String worstMatch = worstDoc.get("field");
         assertNotSame(searchTerm, worstMatch);
       }
@@ -312,15 +311,15 @@
 
     // Matches on the rare surname should be worth more than matches on the common forename
     assertEquals(7, hits.length);
-    StoredDocument bestDoc = searcher.doc(hits[0].doc);
+    Document bestDoc = searcher.doc(hits[0].doc);
     String topMatch = bestDoc.get("field");
     assertTrue(topMatch.contains(rareSearchTerm));
 
-    StoredDocument runnerUpDoc = searcher.doc(hits[1].doc);
+    Document runnerUpDoc = searcher.doc(hits[1].doc);
     String runnerUpMatch = runnerUpDoc.get("field");
     assertTrue(runnerUpMatch.contains("cuttin"));
 
-    StoredDocument worstDoc = searcher.doc(hits[hits.length - 1].doc);
+    Document worstDoc = searcher.doc(hits[hits.length - 1].doc);
     String worstMatch = worstDoc.get("field");
     assertTrue(worstMatch.contains("micheal")); //misspelling of common name
 
Index: lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestLiveFieldValues.java	(working copy)
@@ -34,7 +34,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
@@ -67,7 +66,7 @@
           if (hits.totalHits == 0) {
             return null;
           } else {
-            StoredDocument doc = s.doc(hits.scoreDocs[0].doc);
+            Document doc = s.doc(hits.scoreDocs[0].doc);
             return (Integer) doc.getField("field").numericValue();
           }
         }
Index: lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
@@ -168,7 +167,7 @@
       ScoreDoc[] sd = topDocs.scoreDocs;
       assertNotNull(sd);
       assertEquals("Score doc count"+type, count, sd.length );
-      StoredDocument doc=searcher.doc(sd[0].doc);
+      Document doc=searcher.doc(sd[0].doc);
       assertEquals("First doc"+type, 2*distance+startOffset, doc.getField(field).numericValue().intValue());
       doc=searcher.doc(sd[sd.length-1].doc);
       assertEquals("Last doc"+type, (1+count)*distance+startOffset, doc.getField(field).numericValue().intValue());
@@ -208,7 +207,7 @@
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
-    StoredDocument doc=searcher.doc(sd[0].doc);
+    Document doc=searcher.doc(sd[0].doc);
     assertEquals("First doc", startOffset, doc.getField(field).numericValue().intValue());
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
@@ -248,7 +247,7 @@
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
-    StoredDocument doc=searcher.doc(sd[0].doc);
+    Document doc=searcher.doc(sd[0].doc);
     assertEquals("First doc", count*distance+startOffset, doc.getField(field).numericValue().intValue());
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
Index: lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(working copy)
@@ -19,15 +19,14 @@
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.LegacyDoubleField;
 import org.apache.lucene.document.LegacyLongField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
@@ -177,7 +176,7 @@
       ScoreDoc[] sd = topDocs.scoreDocs;
       assertNotNull(sd);
       assertEquals("Score doc count"+type, count, sd.length );
-      StoredDocument doc=searcher.doc(sd[0].doc);
+      Document doc=searcher.doc(sd[0].doc);
       assertEquals("First doc"+type, 2*distance+startOffset, doc.getField(field).numericValue().longValue() );
       doc=searcher.doc(sd[sd.length-1].doc);
       assertEquals("Last doc"+type, (1+count)*distance+startOffset, doc.getField(field).numericValue().longValue() );
@@ -222,7 +221,7 @@
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
-    StoredDocument doc=searcher.doc(sd[0].doc);
+    Document doc=searcher.doc(sd[0].doc);
     assertEquals("First doc", startOffset, doc.getField(field).numericValue().longValue() );
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
@@ -267,7 +266,7 @@
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
-    StoredDocument doc=searcher.doc(sd[0].doc);
+    Document doc=searcher.doc(sd[0].doc);
     assertEquals("First doc", count*distance+startOffset, doc.getField(field).numericValue().longValue() );
     doc=searcher.doc(sd[sd.length-1].doc);
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
Index: lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java	(revision 1724443)
+++ lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java	(working copy)
@@ -17,6 +17,7 @@
  * limitations under the License.
  */
 
+import java.io.EOFException;
 import java.io.IOException;
 import java.nio.file.Files;
 import java.nio.file.Path;
@@ -23,6 +24,7 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
+import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -32,7 +34,6 @@
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.IOUtils;
@@ -108,7 +109,7 @@
     
     // search for all documents
     for (int i = 0; i < docsToAdd; i++) {
-      StoredDocument doc = searcher.doc(i);
+      Document doc = searcher.doc(i);
       assertTrue(doc.getField("content") != null);
     }
 
@@ -161,4 +162,30 @@
     
     writer.close();
   }
-}
+
+  public void testShouldThrowEOFException() throws Exception {
+    final Random random = random();
+
+    try (Directory dir = newDirectory()) {
+      final int len = 16 + random().nextInt(2048) / 16 * 16;
+      final byte[] bytes = new byte[len];
+
+      try (IndexOutput os = dir.createOutput("foo", newIOContext(random))) {
+        os.writeBytes(bytes, bytes.length);
+      }
+
+      try (IndexInput is = dir.openInput("foo", newIOContext(random))) {
+        try {
+          is.seek(0);
+          // Here, I go past EOF.
+          is.seek(len + random().nextInt(2048));
+          // since EOF is not enforced by the previous call in RAMInputStream
+          // this call to readBytes should throw the exception.
+          is.readBytes(bytes, 0, 16);
+          fail("Did not get EOFException");
+        } catch (EOFException eof) {
+          // expected!
+        }
+      }
+    }
+  }}
Index: lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(revision 1724443)
+++ lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(working copy)
@@ -27,9 +27,9 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.queryparser.classic.QueryParser;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
@@ -178,7 +178,7 @@
           continue;
         }
 
-        StoredDocument doc = searcher.doc(hits[i].doc);
+        Document doc = searcher.doc(hits[i].doc);
         String path = doc.get("path");
         if (path != null) {
           System.out.println((i+1) + ". " + path);
Index: lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(revision 1724443)
+++ lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(working copy)
@@ -43,7 +43,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.queryparser.xml.CorePlusExtensionsParser;
 import org.apache.lucene.queryparser.xml.QueryTemplateManager;
 import org.apache.lucene.search.IndexSearcher;
@@ -116,7 +115,7 @@
       //and package the results and forward to JSP
       if (topDocs != null) {
         ScoreDoc[] sd = topDocs.scoreDocs;
-        StoredDocument[] results = new StoredDocument[sd.length];
+        Document[] results = new Document[sd.length];
         for (int i = 0; i < results.length; i++) {
           results[i] = searcher.doc(sd[i].doc);
           request.setAttribute("results", results);
Index: lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java	(revision 1724443)
+++ lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java	(working copy)
@@ -40,6 +40,7 @@
 import org.apache.lucene.facet.taxonomy.IntAssociationFacetField;
 import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
 import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.index.IndexableFieldType;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
@@ -209,7 +210,7 @@
 
     Set<String> seenDims = new HashSet<>();
 
-    for (IndexableField field : doc.indexableFields()) {
+    for (IndexableField field : doc) {
       if (field.fieldType() == FacetField.TYPE) {
         FacetField facetField = (FacetField) field;
         FacetsConfig.DimConfig dimConfig = getDimConfig(facetField.dim);
@@ -289,8 +290,8 @@
 
     //System.out.println("add stored: " + addedStoredFields);
 
-    for (Field field : doc.getFields()) {
-      FieldType ft = field.fieldType();
+    for (IndexableField field : doc.getFields()) {
+      IndexableFieldType ft = field.fieldType();
       if (ft != FacetField.TYPE && ft != SortedSetDocValuesFacetField.TYPE && ft != AssociationFacetField.TYPE) {
         result.add(field);
       }
Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java	(revision 1724443)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java	(working copy)
@@ -5,6 +5,7 @@
 import java.util.logging.Level;
 import java.util.logging.Logger;
 
+import org.apache.lucene.document.Document;
 import org.apache.lucene.facet.FacetsConfig;
 import org.apache.lucene.facet.taxonomy.FacetLabel;
 import org.apache.lucene.facet.taxonomy.LRUHashMap;
@@ -12,10 +13,9 @@
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.index.CorruptIndexException; // javadocs
 import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
@@ -312,7 +312,7 @@
       }
     }
     
-    StoredDocument doc = indexReader.document(ordinal);
+    Document doc = indexReader.document(ordinal);
     FacetLabel ret = new FacetLabel(FacetsConfig.stringToPath(doc.get(Consts.FULL)));
     synchronized (categoryCache) {
       categoryCache.put(catIDInteger, ret);
Index: lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java
===================================================================
--- lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java	(revision 1724443)
+++ lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest.java	(working copy)
@@ -39,7 +39,6 @@
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
 import org.apache.lucene.search.IndexSearcher;
@@ -454,7 +453,7 @@
     DirectoryReader reader = w.getReader();
     if (VERBOSE) {
       for(int docID=0;docID<reader.maxDoc();docID++) {
-        StoredDocument doc = reader.document(docID);
+        Document doc = reader.document(docID);
         System.out.println("docID=" + docID + " id=" + doc.get("id") + " content=" + doc.get("content") + " author=" + doc.get("author") + " publisher=" + doc.get("publisher"));
       }
     }
Index: lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(revision 1724443)
+++ lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(working copy)
@@ -25,9 +25,9 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.miscellaneous.LimitTokenOffsetFilter;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 
 /**
@@ -114,7 +114,7 @@
    */
   @Deprecated // maintenance reasons LUCENE-6445
   public static TokenStream getAnyTokenStream(IndexReader reader, int docId,
-      String field, StoredDocument document, Analyzer analyzer) throws IOException {
+      String field, Document document, Analyzer analyzer) throws IOException {
     TokenStream ts = null;
 
     Fields vectors = reader.getTermVectors(docId);
@@ -228,12 +228,12 @@
   @Deprecated // maintenance reasons LUCENE-6445
   public static TokenStream getTokenStream(IndexReader reader, int docId,
       String field, Analyzer analyzer) throws IOException {
-    StoredDocument doc = reader.document(docId);
+    Document doc = reader.document(docId);
     return getTokenStream(doc, field, analyzer);
   }
 
   @Deprecated // maintenance reasons LUCENE-6445
-  public static TokenStream getTokenStream(StoredDocument doc, String field,
+  public static TokenStream getTokenStream(Document doc, String field,
       Analyzer analyzer) {
     String contents = doc.get(field);
     if (contents == null) {
Index: lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 1724443)
+++ lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -56,7 +56,6 @@
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.CommonTermsQuery;
 import org.apache.lucene.queries.CustomScoreQuery;
@@ -154,7 +153,7 @@
     Highlighter highlighter = new Highlighter(scorer);
 
     final int docId0 = hits.scoreDocs[0].doc;
-    StoredDocument doc = searcher.doc(docId0);
+    Document doc = searcher.doc(docId0);
     String storedField = doc.get(FIELD_NAME);
 
     TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);
@@ -178,7 +177,7 @@
 
     for (int i = 0; i < hits.scoreDocs.length; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      StoredDocument doc = searcher.doc(docId);
+      Document doc = searcher.doc(docId);
       String storedField = doc.get(FIELD_NAME);
 
       TokenStream stream = getAnyTokenStream(FIELD_NAME, docId);
@@ -206,7 +205,7 @@
     Highlighter highlighter = new Highlighter(scorer);
 
     final int docId0 = hits.scoreDocs[0].doc;
-    StoredDocument doc = searcher.doc(docId0);
+    Document doc = searcher.doc(docId0);
     String storedField = doc.get(FIELD_NAME);
 
     TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);
@@ -260,7 +259,7 @@
     Highlighter highlighter = new Highlighter(scorer);
 
     final int docId0 = hits.scoreDocs[0].doc;
-    StoredDocument doc = searcher.doc(docId0);
+    Document doc = searcher.doc(docId0);
     String storedField = doc.get(FIELD_NAME);
 
     TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);
@@ -425,7 +424,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -457,7 +456,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -489,7 +488,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -516,7 +515,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -542,7 +541,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -568,7 +567,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -675,7 +674,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -696,7 +695,7 @@
 
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
       QueryScorer scorer = new QueryScorer(query, FIELD_NAME);
@@ -729,7 +728,7 @@
   
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -780,7 +779,7 @@
     
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -853,7 +852,7 @@
     int maxNumFragmentsRequired = 2;
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -1049,7 +1048,7 @@
 
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
       int maxNumFragmentsRequired = 2;
@@ -1075,7 +1074,7 @@
 
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
       int maxNumFragmentsRequired = 2;
@@ -1101,7 +1100,7 @@
 
     for (int i = 0; i < hits.totalHits; i++) {
       final int docId = hits.scoreDocs[i].doc;
-      final StoredDocument doc = searcher.doc(docId);
+      final Document doc = searcher.doc(docId);
       String text = doc.get(FIELD_NAME);
       TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
       int maxNumFragmentsRequired = 2;
@@ -1275,7 +1274,7 @@
         numHighlights = 0;
         for (int i = 0; i < hits.totalHits; i++) {
           final int docId = hits.scoreDocs[i].doc;
-          final StoredDocument doc = searcher.doc(docId);
+          final Document doc = searcher.doc(docId);
           String text = doc.get(FIELD_NAME);
           TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -1291,7 +1290,7 @@
         numHighlights = 0;
         for (int i = 0; i < hits.totalHits; i++) {
           final int docId = hits.scoreDocs[i].doc;
-          final StoredDocument doc = searcher.doc(docId);
+          final Document doc = searcher.doc(docId);
           String text = doc.get(FIELD_NAME);
           TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
           Highlighter highlighter = getHighlighter(query, FIELD_NAME,
@@ -1304,7 +1303,7 @@
         numHighlights = 0;
         for (int i = 0; i < hits.totalHits; i++) {
           final int docId = hits.scoreDocs[i].doc;
-          final StoredDocument doc = searcher.doc(docId);
+          final Document doc = searcher.doc(docId);
           String text = doc.get(FIELD_NAME);
           TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -1437,7 +1436,7 @@
 
         for (int i = 0; i < hits.totalHits; i++) {
           final int docId = hits.scoreDocs[i].doc;
-          final StoredDocument doc = searcher.doc(docId);
+          final Document doc = searcher.doc(docId);
           String text = doc.get(FIELD_NAME);
           TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
 
@@ -1591,7 +1590,7 @@
 
         for (int i = 0; i < hits.totalHits; i++) {
           final int docId = hits.scoreDocs[i].doc;
-          final StoredDocument doc = searcher.doc(docId);
+          final Document doc = searcher.doc(docId);
           String text = doc.get(FIELD_NAME);
           TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);
           Highlighter highlighter = getHighlighter(query.build(), FIELD_NAME, HighlighterTest.this, false);
@@ -1954,7 +1953,7 @@
 
     TopDocs hits = searcher.search(query, 10);
     for( int i = 0; i < hits.totalHits; i++ ){
-      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );
+      Document doc = searcher.doc( hits.scoreDocs[i].doc );
       String result = h.getBestFragment( a, "t_text1", doc.get( "t_text1" ));
       if (VERBOSE) System.out.println("result:" +  result);
       assertEquals("more <B>random</B> words for second field", result);
@@ -2299,7 +2298,7 @@
 
       for (int i = 0; i < hits.totalHits; i++) {
         final int docId = hits.scoreDocs[i].doc;
-        final StoredDocument doc = searcher.doc(docId);
+        final Document doc = searcher.doc(docId);
         String text = doc.get(HighlighterTest.FIELD_NAME);
         int maxNumFragmentsRequired = 2;
         String fragmentSeparator = "...";
Index: lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java	(revision 1724443)
+++ lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java	(working copy)
@@ -31,7 +31,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.CustomScoreQuery;
 import org.apache.lucene.search.BooleanClause;
@@ -941,7 +940,7 @@
     String snippets[] = highlighter.highlight("body", query, searcher, hits);
     assertEquals(numDocs, snippets.length);
     for(int hit=0;hit<numDocs;hit++) {
-      StoredDocument doc = searcher.doc(hits.scoreDocs[hit].doc);
+      Document doc = searcher.doc(hits.scoreDocs[hit].doc);
       int id = Integer.parseInt(doc.get("id"));
       String expected = "the <b>answer</b> is " + id;
       if ((id  & 1) == 0) {
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(revision 1724443)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(working copy)
@@ -44,7 +44,6 @@
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.ReaderUtil;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanClause;
@@ -151,10 +150,10 @@
     assertEquals(1, results.totalGroupedHitCount);
     assertEquals(1, results.groups.length);
     final GroupDocs<Integer> group = results.groups[0];
-    StoredDocument childDoc = s.doc(group.scoreDocs[0].doc);
+    Document childDoc = s.doc(group.scoreDocs[0].doc);
     assertEquals("java", childDoc.get("skill"));
     assertNotNull(group.groupValue);
-    StoredDocument parentDoc = s.doc(group.groupValue);
+    Document parentDoc = s.doc(group.groupValue);
     assertEquals("Lisa", parentDoc.get("name"));
 
     r.close();
@@ -220,11 +219,11 @@
     assertEquals(1, group.totalHits);
     assertFalse(Float.isNaN(group.score));
 
-    StoredDocument childDoc = s.doc(group.scoreDocs[0].doc);
+    Document childDoc = s.doc(group.scoreDocs[0].doc);
     //System.out.println("  doc=" + group.scoreDocs[0].doc);
     assertEquals("java", childDoc.get("skill"));
     assertNotNull(group.groupValue);
-    StoredDocument parentDoc = s.doc(group.groupValue);
+    Document parentDoc = s.doc(group.groupValue);
     assertEquals("Lisa", parentDoc.get("name"));
 
 
@@ -422,7 +421,7 @@
     }
   }
   
-  private StoredDocument getParentDoc(IndexReader reader, BitSetProducer parents, int childDocID) throws IOException {
+  private Document getParentDoc(IndexReader reader, BitSetProducer parents, int childDocID) throws IOException {
     final List<LeafReaderContext> leaves = reader.leaves();
     final int subIndex = ReaderUtil.subIndex(childDocID, leaves);
     final LeafReaderContext leaf = leaves.get(subIndex);
@@ -755,7 +754,7 @@
         System.out.println("\nTEST: normal index gets " + results.totalHits + " hits; sort=" + parentAndChildSort);
         final ScoreDoc[] hits = results.scoreDocs;
         for(int hitIDX=0;hitIDX<hits.length;hitIDX++) {
-          final StoredDocument doc = s.doc(hits[hitIDX].doc);
+          final Document doc = s.doc(hits[hitIDX].doc);
           //System.out.println("  score=" + hits[hitIDX].score + " parentID=" + doc.get("parentID") + " childID=" + doc.get("childID") + " (docID=" + hits[hitIDX].doc + ")");
           System.out.println("  parentID=" + doc.get("parentID") + " childID=" + doc.get("childID") + " (docID=" + hits[hitIDX].doc + ")");
           FieldDoc fd = (FieldDoc) hits[hitIDX];
@@ -809,10 +808,10 @@
             }
 
             assertNotNull(group.groupValue);
-            final StoredDocument parentDoc = joinS.doc(group.groupValue);
+            final Document parentDoc = joinS.doc(group.groupValue);
             System.out.println("  group parentID=" + parentDoc.get("parentID") + " (docID=" + group.groupValue + ")");
             for(int hitIDX=0;hitIDX<group.scoreDocs.length;hitIDX++) {
-              final StoredDocument doc = joinS.doc(group.scoreDocs[hitIDX].doc);
+              final Document doc = joinS.doc(group.scoreDocs[hitIDX].doc);
               //System.out.println("    score=" + group.scoreDocs[hitIDX].score + " childID=" + doc.get("childID") + " (docID=" + group.scoreDocs[hitIDX].doc + ")");
               System.out.println("    childID=" + doc.get("childID") + " child0=" + doc.get("child0") + " (docID=" + group.scoreDocs[hitIDX].doc + ")");
             }
@@ -827,7 +826,7 @@
         TopDocs b = joinS.search(childJoinQuery, 10);
         for (ScoreDoc hit : b.scoreDocs) {
           Explanation explanation = joinS.explain(childJoinQuery, hit.doc);
-          StoredDocument document = joinS.doc(hit.doc - 1);
+          Document document = joinS.doc(hit.doc - 1);
           int childId = Integer.parseInt(document.get("childID"));
           //System.out.println("  hit docID=" + hit.doc + " childId=" + childId + " parentId=" + document.get("parentID"));
           assertTrue(explanation.isMatch());
@@ -949,7 +948,7 @@
       if (VERBOSE) {
         System.out.println("  " + results2.totalHits + " totalHits:");
         for(ScoreDoc sd : results2.scoreDocs) {
-          final StoredDocument doc = s.doc(sd.doc);
+          final Document doc = s.doc(sd.doc);
           System.out.println("  childID=" + doc.get("childID") + " parentID=" + doc.get("parentID") + " docID=" + sd.doc);
         }
       }
@@ -962,8 +961,8 @@
       if (VERBOSE) {
         System.out.println("  " + joinResults2.totalHits + " totalHits:");
         for(ScoreDoc sd : joinResults2.scoreDocs) {
-          final StoredDocument doc = joinS.doc(sd.doc);
-          final StoredDocument parentDoc = getParentDoc(joinR, parentsFilter, sd.doc);
+          final Document doc = joinS.doc(sd.doc);
+          final Document parentDoc = getParentDoc(joinR, parentsFilter, sd.doc);
           System.out.println("  childID=" + doc.get("childID") + " parentID=" + parentDoc.get("parentID") + " docID=" + sd.doc);
         }
       }
@@ -983,8 +982,8 @@
     for(int hitCount=0;hitCount<results.scoreDocs.length;hitCount++) {
       ScoreDoc hit = results.scoreDocs[hitCount];
       ScoreDoc joinHit = joinResults.scoreDocs[hitCount];
-      StoredDocument doc1 = r.document(hit.doc);
-      StoredDocument doc2 = joinR.document(joinHit.doc);
+      Document doc1 = r.document(hit.doc);
+      Document doc2 = joinR.document(joinHit.doc);
       assertEquals("hit " + hitCount + " differs",
                    doc1.get("childID"), doc2.get("childID"));
       // don't compare scores -- they are expected to differ
@@ -1011,14 +1010,14 @@
       final GroupDocs<Integer> group = groupDocs[joinGroupUpto++];
       final ScoreDoc[] groupHits = group.scoreDocs;
       assertNotNull(group.groupValue);
-      final StoredDocument parentDoc = joinR.document(group.groupValue);
+      final Document parentDoc = joinR.document(group.groupValue);
       final String parentID = parentDoc.get("parentID");
       //System.out.println("GROUP groupDoc=" + group.groupDoc + " parent=" + parentDoc);
       assertNotNull(parentID);
       assertTrue(groupHits.length > 0);
       for(int hitIDX=0;hitIDX<groupHits.length;hitIDX++) {
-        final StoredDocument nonJoinHit = r.document(hits[resultUpto++].doc);
-        final StoredDocument joinHit = joinR.document(groupHits[hitIDX].doc);
+        final Document nonJoinHit = r.document(hits[resultUpto++].doc);
+        final Document joinHit = joinR.document(groupHits[hitIDX].doc);
         assertEquals(parentID,
                      nonJoinHit.get("parentID"));
         assertEquals(joinHit.get("childID"),
@@ -1100,11 +1099,11 @@
     final GroupDocs<Integer> group = jobResults.groups[0];
     assertEquals(1, group.totalHits);
 
-    StoredDocument childJobDoc = s.doc(group.scoreDocs[0].doc);
+    Document childJobDoc = s.doc(group.scoreDocs[0].doc);
     //System.out.println("  doc=" + group.scoreDocs[0].doc);
     assertEquals("java", childJobDoc.get("skill"));
     assertNotNull(group.groupValue);
-    StoredDocument parentDoc = s.doc(group.groupValue);
+    Document parentDoc = s.doc(group.groupValue);
     assertEquals("Lisa", parentDoc.get("name"));
 
     // Now Examine qualification children
@@ -1116,7 +1115,7 @@
     final GroupDocs<Integer> qGroup = qualificationResults.groups[0];
     assertEquals(1, qGroup.totalHits);
 
-    StoredDocument childQualificationDoc = s.doc(qGroup.scoreDocs[0].doc);
+    Document childQualificationDoc = s.doc(qGroup.scoreDocs[0].doc);
     assertEquals("maths", childQualificationDoc.get("qualification"));
     assertNotNull(qGroup.groupValue);
     parentDoc = s.doc(qGroup.groupValue);
@@ -1236,13 +1235,13 @@
       assertEquals(2, group.totalHits);
       assertFalse(Float.isNaN(group.score));
       assertNotNull(group.groupValue);
-      StoredDocument parentDoc = s.doc(group.groupValue);
+      Document parentDoc = s.doc(group.groupValue);
       assertEquals("Frank", parentDoc.get("name"));
 
       assertEquals(2, group.scoreDocs.length); //all matched child documents collected
 
       for (ScoreDoc scoreDoc : group.scoreDocs) {
-        StoredDocument childDoc = s.doc(scoreDoc.doc);
+        Document childDoc = s.doc(scoreDoc.doc);
         assertEquals("java", childDoc.get("skill"));
         int year = Integer.parseInt(childDoc.get("year"));
         assertTrue(year >= 2006 && year <= 2011);
@@ -1259,13 +1258,13 @@
     assertEquals(2, group.totalHits);
     assertFalse(Float.isNaN(group.score));
     assertNotNull(group.groupValue);
-    StoredDocument parentDoc = s.doc(group.groupValue);
+    Document parentDoc = s.doc(group.groupValue);
     assertEquals("Frank", parentDoc.get("name"));
 
     assertEquals(1, group.scoreDocs.length); //not all matched child documents collected
 
     for (ScoreDoc scoreDoc : group.scoreDocs) {
-      StoredDocument childDoc = s.doc(scoreDoc.doc);
+      Document childDoc = s.doc(scoreDoc.doc);
       assertEquals("java", childDoc.get("skill"));
       int year = Integer.parseInt(childDoc.get("year"));
       assertTrue(year >= 2006 && year <= 2011);
@@ -1332,7 +1331,7 @@
     assertEquals(1, groups.totalGroupedHitCount);
 
     GroupDocs<Integer> group = groups.groups[0];
-    StoredDocument doc = r.document(group.groupValue.intValue());
+    Document doc = r.document(group.groupValue.intValue());
     assertEquals("0", doc.get("parentID"));
 
     group = groups.groups[1];
@@ -1403,7 +1402,7 @@
     assertEquals(0, groups.totalGroupedHitCount);
 
     GroupDocs<Integer> group = groups.groups[0];
-    StoredDocument doc = r.document(group.groupValue.intValue());
+    Document doc = r.document(group.groupValue.intValue());
     assertEquals("0", doc.get("parentID"));
 
     group = groups.groups[1];
Index: lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java
===================================================================
--- lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java	(revision 1724443)
+++ lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java	(working copy)
@@ -446,7 +446,7 @@
       IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random(), mockAnalyzer));
       Document nextDoc = lineFileDocs.nextDoc();
       Document doc = new Document();
-      for (Field field : nextDoc.getFields()) {
+      for (IndexableField field : nextDoc.getFields()) {
         if (field.fieldType().indexOptions() != IndexOptions.NONE) {
           doc.add(field);
           if (random().nextInt(3) == 0) {
@@ -457,7 +457,7 @@
       
       writer.addDocument(doc);
       writer.close();
-      for (IndexableField field : doc.indexableFields()) {
+      for (IndexableField field : doc) {
         memory.addField(field.name(), ((Field)field).stringValue(), mockAnalyzer);  
       }
       DirectoryReader competitor = DirectoryReader.open(dir);
Index: lucene/misc/src/java/org/apache/lucene/document/LazyDocument.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/document/LazyDocument.java	(revision 1724443)
+++ lucene/misc/src/java/org/apache/lucene/document/LazyDocument.java	(working copy)
@@ -17,11 +17,11 @@
  */
 import java.io.IOException;
 import java.io.Reader;
-import java.util.List;
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
 import java.util.Map;
-import java.util.HashSet;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -28,9 +28,8 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.IndexableFieldType;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.util.BytesRef;
 
 /** Defers actually loading a field's value until you ask
@@ -43,7 +42,7 @@
   private final int docID;
 
   // null until first field is loaded
-  private StoredDocument doc;
+  private Document doc;
 
   private Map<Integer,List<LazyField>> fields = new HashMap<>();
   private Set<String> fieldNames = new HashSet<>();
@@ -68,7 +67,7 @@
    * per LazyDocument instance.
    * </p>
    */
-  public StorableField getField(FieldInfo fieldInfo) {  
+  public IndexableField getField(FieldInfo fieldInfo) {  
 
     fieldNames.add(fieldInfo.name);
     List<LazyField> values = fields.get(fieldInfo.number);
@@ -94,7 +93,7 @@
    * non-private for test only access
    * @lucene.internal 
    */
-  synchronized StoredDocument getDocument() {
+  synchronized Document getDocument() {
     if (doc == null) {
       try {
         doc = reader.document(docID, fieldNames);
@@ -107,10 +106,10 @@
 
   // :TODO: synchronize to prevent redundent copying? (sync per field name?)
   private void fetchRealValues(String name, int fieldNum) {
-    StoredDocument d = getDocument();
+    Document d = getDocument();
 
     List<LazyField> lazyValues = fields.get(fieldNum);
-    StorableField[] realValues = d.getFields(name);
+    IndexableField[] realValues = d.getFields(name);
     
     assert realValues.length <= lazyValues.size() 
       : "More lazy values then real values for field: " + name;
@@ -127,10 +126,10 @@
   /** 
    * @lucene.internal 
    */
-  public class LazyField implements StorableField {
+  public class LazyField implements IndexableField {
     private String name;
     private int fieldNum;
-    volatile StorableField realValue = null;
+    volatile IndexableField realValue = null;
 
     private LazyField(String name, int fieldNum) {
       this.name = name;
@@ -145,7 +144,7 @@
       return null != realValue;
     }
 
-    private StorableField getRealValue() {
+    private IndexableField getRealValue() {
       if (null == realValue) {
         fetchRealValues(name, fieldNum);
       }
@@ -162,6 +161,11 @@
     }
 
     @Override
+    public float boost() {
+      return 1.0f;
+    }
+
+    @Override
     public BytesRef binaryValue() {
       return getRealValue().binaryValue();
     }
@@ -185,5 +189,10 @@
     public IndexableFieldType fieldType() {
       return getRealValue().fieldType();
     }
+
+    @Override
+    public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {
+      return getRealValue().tokenStream(analyzer, reuse);
+    }
   }
 }
Index: lucene/misc/src/test/org/apache/lucene/document/TestLazyDocument.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/document/TestLazyDocument.java	(revision 1724443)
+++ lucene/misc/src/test/org/apache/lucene/document/TestLazyDocument.java	(working copy)
@@ -87,13 +87,13 @@
         = new LazyTestingStoredFieldVisitor(new LazyDocument(reader, hits[0].doc),
                                             FIELDS);
       reader.document(hits[0].doc, visitor);
-      StoredDocument d = visitor.doc;
+      Document d = visitor.doc;
 
       int numFieldValues = 0;
       Map<String,Integer> fieldValueCounts = new HashMap<>();
 
       // at this point, all FIELDS should be Lazy and unrealized
-      for (StorableField f : d) {
+      for (IndexableField f : d) {
         numFieldValues++;   
         if (f.name().equals("never_load")) {
           fail("never_load was loaded");
@@ -125,7 +125,7 @@
 
       // pick a single field name to load a single value
       final String fieldName = FIELDS[random().nextInt(FIELDS.length)];
-      final StorableField[] fieldValues = d.getFields(fieldName);
+      final IndexableField[] fieldValues = d.getFields(fieldName);
       assertEquals("#vals in field: " + fieldName, 
                    NUM_VALUES, fieldValues.length);
       final int valNum = random().nextInt(fieldValues.length);
@@ -133,7 +133,7 @@
                    fieldValues[valNum].stringValue());
       
       // now every value of fieldName should be loaded
-      for (StorableField f : d) {
+      for (IndexableField f : d) {
         if (f.name().equals("never_load")) {
           fail("never_load was loaded");
         }
@@ -160,7 +160,7 @@
       // ensure we have all the values we expect now, and that
       // adding one more lazy field didn't "unload" the existing LazyField's
       // we already loaded.
-      for (StorableField f : d) {
+      for (IndexableField f : d) {
         if (f.name().equals("never_load")) {
           fail("never_load was loaded");
         }
@@ -185,7 +185,7 @@
   }
 
   private static class LazyTestingStoredFieldVisitor extends StoredFieldVisitor {
-    public final StoredDocument doc = new StoredDocument();
+    public final Document doc = new Document();
     public final LazyDocument lazyDoc;
     public final Set<String> lazyFieldNames;
 
Index: lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(revision 1724443)
+++ lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(working copy)
@@ -70,7 +70,7 @@
     IndexReader ir;
     ir = DirectoryReader.open(dirs[0]);
     assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1); // rounding error
-    StoredDocument doc = ir.document(0);
+    Document doc = ir.document(0);
     assertEquals("0", doc.get("id"));
     TermsEnum te = MultiFields.getTerms(ir, "id").iterator();
     assertEquals(TermsEnum.SeekStatus.NOT_FOUND, te.seekCeil(new BytesRef("1")));
@@ -115,7 +115,7 @@
     IndexReader ir;
     ir = DirectoryReader.open(dirs[0]);
     assertTrue(ir.numDocs() - NUM_DOCS / 3 <= 1);
-    StoredDocument doc = ir.document(0);
+    Document doc = ir.document(0);
     assertEquals("0", doc.get("id"));
     int start = ir.numDocs();
     ir.close();
Index: lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java	(revision 1724443)
+++ lucene/misc/src/test/org/apache/lucene/search/TestDiversifiedTopDocsCollector.java	(working copy)
@@ -22,8 +22,8 @@
 import java.util.Map;
 
 import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.FloatDocValuesField;
 import org.apache.lucene.document.LegacyFloatField;
 import org.apache.lucene.document.SortedDocValuesField;
@@ -37,7 +37,6 @@
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.similarities.Similarity;
@@ -389,7 +388,7 @@
     int result = 0;
     HashMap<String, Integer> artistCounts = new HashMap<String, Integer>();
     for (int i = 0; i < sd.length; i++) {
-      StoredDocument doc = reader.document(sd[i].doc);
+      Document doc = reader.document(sd[i].doc);
       Record record = parsedRecords.get(doc.get("id"));
       Integer count = artistCounts.get(record.artist);
       int newCount = 1;
Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java	(revision 1724443)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheVsDocValues.java	(working copy)
@@ -43,7 +43,6 @@
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.TermsEnum.SeekStatus;
@@ -204,7 +203,7 @@
 
     BinaryDocValues s = FieldCache.DEFAULT.getTerms(ar, "field", false);
     for(int docID=0;docID<docBytes.size();docID++) {
-      StoredDocument doc = ar.document(docID);
+      Document doc = ar.document(docID);
       BytesRef bytes = s.get(docID);
       byte[] expected = docBytes.get(Integer.parseInt(doc.get("id")));
       assertEquals(expected.length, bytes.length);
@@ -279,7 +278,7 @@
 
     BinaryDocValues s = FieldCache.DEFAULT.getTerms(ar, "field", false);
     for(int docID=0;docID<docBytes.size();docID++) {
-      StoredDocument doc = ar.document(docID);
+      Document doc = ar.document(docID);
       BytesRef bytes = s.get(docID);
       byte[] expected = docBytes.get(Integer.parseInt(doc.get("id")));
       assertEquals(expected.length, bytes.length);
Index: lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java	(revision 1724443)
+++ lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java	(working copy)
@@ -16,14 +16,23 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
@@ -38,15 +47,6 @@
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
 
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-
 /**
  * Generate "more like this" similarity queries.
  * Based on this mail:
@@ -733,9 +733,9 @@
 
       // field does not store term vector info
       if (vector == null) {
-        StoredDocument d = ir.document(docNum);
-        StorableField[] fields = d.getFields(fieldName);
-        for (StorableField field : fields) {
+        Document d = ir.document(docNum);
+        IndexableField[] fields = d.getFields(fieldName);
+        for (IndexableField field : fields) {
           final String stringValue = field.stringValue();
           if (stringValue != null) {
             addTermFrequencies(new StringReader(stringValue), termFreqMap, fieldName);
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery.java	(revision 1724443)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
@@ -116,7 +115,7 @@
     TopDocs td = searcher.search(q, 10);
     ScoreDoc[] sd = td.scoreDocs;
     for (int i = 0; i < sd.length; i++) {
-      StoredDocument doc = searcher.doc(sd[i].doc);
+      Document doc = searcher.doc(sd[i].doc);
       String id = doc.get("id");
       assertTrue(qString + "matched doc#" + id + " not expected", expecteds
           .contains(id));
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser.java	(revision 1724443)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.DisjunctionMaxQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
@@ -202,7 +201,7 @@
       System.out.println("=========" + qType + "============");
       ScoreDoc[] scoreDocs = hits.scoreDocs;
       for (int i = 0; i < Math.min(numDocs, hits.totalHits); i++) {
-        StoredDocument ldoc = searcher.doc(scoreDocs[i].doc);
+        Document ldoc = searcher.doc(scoreDocs[i].doc);
         System.out.println("[" + ldoc.get("date") + "]" + ldoc.get("contents"));
       }
       System.out.println();
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java	(revision 1724443)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java	(working copy)
@@ -23,7 +23,6 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
@@ -89,7 +88,7 @@
     TopDocs topDocs = searcher.search(flt, 1);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    StoredDocument doc = searcher.doc(sd[0].doc);
+    Document doc = searcher.doc(sd[0].doc);
     assertEquals("Should match most similar not most rare variant", "2", doc.get("id"));
   }
 
@@ -105,7 +104,7 @@
     TopDocs topDocs = searcher.search(flt, 1);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    StoredDocument doc = searcher.doc(sd[0].doc);
+    Document doc = searcher.doc(sd[0].doc);
     assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
   }
   
@@ -123,7 +122,7 @@
     TopDocs topDocs = searcher.search(flt, 1);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    StoredDocument doc = searcher.doc(sd[0].doc);
+    Document doc = searcher.doc(sd[0].doc);
     assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
   }
 
@@ -139,7 +138,7 @@
     TopDocs topDocs = searcher.search(flt, 1);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertTrue("score docs must match 1 doc", (sd != null) && (sd.length > 0));
-    StoredDocument doc = searcher.doc(sd[0].doc);
+    Document doc = searcher.doc(sd[0].doc);
     assertEquals("Should match most similar when using 2 words", "2", doc.get("id"));
   }
 
Index: lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java
===================================================================
--- lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java	(revision 1724443)
+++ lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java	(working copy)
@@ -31,7 +31,6 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
@@ -155,7 +154,7 @@
       assertDocMatchedIds(indexSearcher, docs, 2);
       //Now, lets get the distance for the 1st doc via computing from stored point value:
       // (this computation is usually not redundant)
-      StoredDocument doc1 = indexSearcher.doc(docs.scoreDocs[0].doc);
+      Document doc1 = indexSearcher.doc(docs.scoreDocs[0].doc);
       String doc1Str = doc1.getField(strategy.getFieldName()).stringValue();
       //assume doc1Str is "x y" as written in newSampleDocument()
       int spaceIdx = doc1Str.indexOf(' ');
Index: lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java
===================================================================
--- lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java	(revision 1724443)
+++ lucene/spatial/src/test/org/apache/lucene/spatial/SpatialTestCase.java	(working copy)
@@ -36,7 +36,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
@@ -262,11 +261,11 @@
   protected static class SearchResult {
 
     public float score;
-    public StoredDocument document;
+    public Document document;
 
-    public SearchResult(float score, StoredDocument storedDocument) {
+    public SearchResult(float score, Document document) {
       this.score = score;
-      this.document = storedDocument;
+      this.document = document;
     }
 
     public String getId() {
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentDictionary.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentDictionary.java	(revision 1724443)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentDictionary.java	(working copy)
@@ -22,12 +22,12 @@
 import java.util.HashSet;
 import java.util.Set;
 
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.spell.Dictionary;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -116,7 +116,7 @@
     private BytesRef currentPayload = null;
     private Set<BytesRef> currentContexts;
     private final NumericDocValues weightValues;
-    StorableField[] currentDocFields = new StorableField[0];
+    IndexableField[] currentDocFields = new IndexableField[0];
     int nextFieldsPosition = 0;
 
     /**
@@ -143,7 +143,7 @@
       while (true) {
         if (nextFieldsPosition < currentDocFields.length) {
           // Still values left from the document
-          StorableField fieldValue =  currentDocFields[nextFieldsPosition++];
+          IndexableField fieldValue = currentDocFields[nextFieldsPosition++];
           if (fieldValue.binaryValue() != null) {
             return fieldValue.binaryValue();
           } else if (fieldValue.stringValue() != null) {
@@ -163,11 +163,11 @@
           continue;
         }
 
-        StoredDocument doc = reader.document(currentDocId, relevantFields);
+        Document doc = reader.document(currentDocId, relevantFields);
 
         BytesRef tempPayload = null;
         if (hasPayloads) {
-          StorableField payload = doc.getField(payloadField);
+          IndexableField payload = doc.getField(payloadField);
           if (payload != null) {
             if (payload.binaryValue() != null) {
               tempPayload =  payload.binaryValue();
@@ -185,8 +185,8 @@
         Set<BytesRef> tempContexts;
         if (hasContexts) {
           tempContexts = new HashSet<>();
-          final StorableField[] contextFields = doc.getFields(contextsField);
-          for (StorableField contextField : contextFields) {
+          final IndexableField[] contextFields = doc.getFields(contextsField);
+          for (IndexableField contextField : contextFields) {
             if (contextField.binaryValue() != null) {
               tempContexts.add(contextField.binaryValue());
             } else if (contextField.stringValue() != null) {
@@ -204,7 +204,7 @@
         if (currentDocFields.length == 0) { // no values in this document
           continue;
         }
-        StorableField fieldValue = currentDocFields[nextFieldsPosition++];
+        IndexableField fieldValue = currentDocFields[nextFieldsPosition++];
         BytesRef tempTerm;
         if (fieldValue.binaryValue() != null) {
           tempTerm = fieldValue.binaryValue();
@@ -240,8 +240,8 @@
      * or if it's indexed as {@link NumericDocValues} (using <code>docId</code>) for the document.
      * If no value is found, then the weight is 0.
      */
-    protected long getWeight(StoredDocument doc, int docId) {
-      StorableField weight = doc.getField(weightField);
+    protected long getWeight(Document doc, int docId) {
+      IndexableField weight = doc.getField(weightField);
       if (weight != null) { // found weight as stored
         return (weight.numericValue() != null) ? weight.numericValue().longValue() : 0;
       } else if (weightValues != null) {  // found weight as NumericDocValue
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentValueSourceDictionary.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentValueSourceDictionary.java	(revision 1724443)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/DocumentValueSourceDictionary.java	(working copy)
@@ -21,10 +21,10 @@
 import java.util.HashMap;
 import java.util.List;
 
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.ReaderUtil;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 
@@ -133,7 +133,7 @@
      * by the <code>weightsValueSource</code>
      * */
     @Override
-    protected long getWeight(StoredDocument doc, int docId) {    
+    protected long getWeight(Document doc, int docId) {    
       if (currentWeightValues == null) {
         return 0;
       }
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentDictionaryTest.java
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentDictionaryTest.java	(revision 1724443)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentDictionaryTest.java	(working copy)
@@ -21,8 +21,8 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.spell.Dictionary;
 import org.apache.lucene.store.Directory;
@@ -98,9 +98,9 @@
     while((f = inputIterator.next())!=null) {
       Document doc = docs.remove(f.utf8ToString());
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
-      Field weightField = doc.getField(WEIGHT_FIELD_NAME);
+      IndexableField weightField = doc.getField(WEIGHT_FIELD_NAME);
       assertEquals(inputIterator.weight(), (weightField != null) ? weightField.numericValue().longValue() : 0);
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
     }
@@ -140,9 +140,9 @@
     InputIterator inputIterator = dictionaryOptionalPayload.getEntryIterator();
     BytesRef f = inputIterator.next();
     assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
-    Field weightField = doc.getField(WEIGHT_FIELD_NAME);
+    IndexableField weightField = doc.getField(WEIGHT_FIELD_NAME);
     assertEquals(inputIterator.weight(), weightField.numericValue().longValue());
-    Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+    IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
     assertNull(payloadField);
     assertTrue(inputIterator.payload().length == 0);
     IOUtils.close(ir, analyzer, dir);
@@ -170,7 +170,7 @@
     while((f = inputIterator.next())!=null) {
       Document doc = docs.remove(f.utf8ToString());
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
-      Field weightField = doc.getField(WEIGHT_FIELD_NAME);
+      IndexableField weightField = doc.getField(WEIGHT_FIELD_NAME);
       assertEquals(inputIterator.weight(), (weightField != null) ? weightField.numericValue().longValue() : 0);
       assertNull(inputIterator.payload());
     }
@@ -206,14 +206,14 @@
     while((f = inputIterator.next())!=null) {
       Document doc = docs.remove(f.utf8ToString());
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
-      Field weightField = doc.getField(WEIGHT_FIELD_NAME);
+      IndexableField weightField = doc.getField(WEIGHT_FIELD_NAME);
       assertEquals(inputIterator.weight(), (weightField != null) ? weightField.numericValue().longValue() : 0);
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
       Set<BytesRef> oriCtxs = new HashSet<>();
       Set<BytesRef> contextSet = inputIterator.contexts();
-      for (StorableField ctxf : doc.getFields(CONTEXT_FIELD_NAME)) {
+      for (IndexableField ctxf : doc.getFields(CONTEXT_FIELD_NAME)) {
         oriCtxs.add(ctxf.binaryValue());
       }
       assertEquals(oriCtxs.size(), contextSet.size());
@@ -240,7 +240,7 @@
     Random rand = random();
     List<String> termsToDel = new ArrayList<>();
     for(Document doc : docs.values()) {
-      StorableField f = doc.getField(FIELD_NAME);
+      IndexableField f = doc.getField(FIELD_NAME);
       if(rand.nextBoolean() && f != null && !invalidDocTerms.contains(f.stringValue())) {
         termsToDel.add(doc.get(FIELD_NAME));
       }
@@ -271,7 +271,7 @@
     while((f = inputIterator.next())!=null) {
       Document doc = docs.remove(f.utf8ToString());
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
-      Field weightField = doc.getField(WEIGHT_FIELD_NAME);
+      IndexableField weightField = doc.getField(WEIGHT_FIELD_NAME);
       assertEquals(inputIterator.weight(), (weightField != null) ? weightField.numericValue().longValue() : 0);
       assertNull(inputIterator.payload());
     }
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest.java
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest.java	(revision 1724443)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest.java	(working copy)
@@ -36,6 +36,7 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.function.ValueSource;
@@ -105,7 +106,7 @@
       long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
       assertEquals(inputIterator.weight(), (w1 + w2 + w3));
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
     }
@@ -139,11 +140,11 @@
       long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
       assertEquals(inputIterator.weight(), (w1 + w2 + w3));
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
       Set<BytesRef> originalCtxs = new HashSet<>();
-      for (Field ctxf: doc.getFields(CONTEXTS_FIELD_NAME)) {
+      for (IndexableField ctxf: doc.getFields(CONTEXTS_FIELD_NAME)) {
         originalCtxs.add(ctxf.binaryValue());
       }
       assertEquals(originalCtxs, inputIterator.contexts());
@@ -231,7 +232,7 @@
       long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
       assertEquals(inputIterator.weight(), w2+w1);
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
     }
@@ -261,7 +262,7 @@
       Document doc = docs.remove(f.utf8ToString());
       assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));
       assertEquals(inputIterator.weight(), 10);
-      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);
+      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);
       if (payloadField == null) assertTrue(inputIterator.payload().length == 0);
       else assertEquals(inputIterator.payload(), payloadField.binaryValue());
     }
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java	(revision 1724443)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField.java	(working copy)
@@ -43,7 +43,6 @@
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.DimensionalRangeQuery;
 import org.apache.lucene.search.ScoreDoc;
@@ -450,7 +449,7 @@
       assertTrue(key.startsWith("abc_"));
       String substring = key.substring(4);
       int fieldValue = Integer.parseInt(substring);
-      StoredDocument doc = reader.document(suggestScoreDoc.doc);
+      Document doc = reader.document(suggestScoreDoc.doc);
       assertEquals(doc.getField("int_field").numericValue().intValue(), fieldValue);
     }
 
Index: lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java	(working copy)
@@ -24,6 +24,7 @@
 
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
@@ -31,8 +32,7 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
@@ -161,8 +161,8 @@
     StringBuilder buff = new StringBuilder(10);
     int n = result.length;
     for (int i = 0 ; i < n ; ++i) {
-      StoredDocument doc = searcher.doc(result[i].doc);
-      StorableField[] v = doc.getFields("tracer");
+      Document doc = searcher.doc(result[i].doc);
+      IndexableField[] v = doc.getFields("tracer");
       for (int j = 0 ; j < v.length ; ++j) {
         buff.append(v[j].stringValue());
       }
Index: lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java	(working copy)
@@ -25,8 +25,8 @@
 import org.apache.lucene.codecs.StoredFieldsWriter;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
@@ -139,7 +139,7 @@
     }
 
     @Override
-    public void writeField(FieldInfo info, StorableField field) throws IOException {
+    public void writeField(FieldInfo info, IndexableField field) throws IOException {
       assert docStatus == Status.STARTED;
       in.writeField(info, field);
     }
Index: lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyStoredFieldsFormat.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyStoredFieldsFormat.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/cranky/CrankyStoredFieldsFormat.java	(working copy)
@@ -25,9 +25,9 @@
 import org.apache.lucene.codecs.StoredFieldsWriter;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MergeState;
 import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 
@@ -106,7 +106,7 @@
     }
 
     @Override
-    public void writeField(FieldInfo info, StorableField field) throws IOException {
+    public void writeField(FieldInfo info, IndexableField field) throws IOException {
       if (random.nextInt(10000) == 0) {
         throw new IOException("Fake IOException from StoredFieldsWriter.writeField()");
       }
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java	(working copy)
@@ -119,7 +119,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
@@ -151,7 +151,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
@@ -184,7 +184,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv1");
@@ -219,7 +219,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues("dv1");
@@ -256,7 +256,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv1");
@@ -293,7 +293,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       SortedDocValues dv = ireader.leaves().get(0).reader().getSortedDocValues("dv1");
@@ -335,7 +335,7 @@
     BytesRef scratch = new BytesRef();
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       SortedDocValues dv = ireader.leaves().get(0).reader().getSortedDocValues("dv2");
@@ -404,7 +404,7 @@
     assert ireader.leaves().size() == 1;
     NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
     for(int i=0;i<2;i++) {
-      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);
+      Document doc2 = ireader.leaves().get(0).reader().document(i);
       long expected;
       if (doc2.get("id").equals("0")) {
         expected = -10;
@@ -496,7 +496,7 @@
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues("dv");
@@ -533,7 +533,7 @@
     BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues("dv");
     BytesRef scratch = new BytesRef();
     for(int i=0;i<2;i++) {
-      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);
+      Document doc2 = ireader.leaves().get(0).reader().document(i);
       String expected;
       if (doc2.get("id").equals("0")) {
         expected = "hello world 1";
@@ -601,7 +601,7 @@
     BytesRef scratch = new BytesRef();
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
-      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
       assertEquals(text, hitDoc.get("fieldname"));
       assert ireader.leaves().size() == 1;
       SortedDocValues dv = ireader.leaves().get(0).reader().getSortedDocValues("dv");
@@ -708,7 +708,7 @@
     scratch = dv.lookupOrd(1);
     assertEquals(new BytesRef("hello world 2"), scratch);
     for(int i=0;i<2;i++) {
-      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);
+      Document doc2 = ireader.leaves().get(0).reader().document(i);
       String expected;
       if (doc2.get("id").equals("0")) {
         expected = "hello world 1";
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseIndexFileFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseIndexFileFormatTestCase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseIndexFileFormatTestCase.java	(working copy)
@@ -312,7 +312,7 @@
     FieldInfo proto = oneDocReader.getFieldInfos().fieldInfo("field");
     FieldInfo field = new FieldInfo(proto.name, proto.number, proto.hasVectors(), proto.omitsNorms(), proto.hasPayloads(), 
                                     proto.getIndexOptions(), proto.getDocValuesType(), proto.getDocValuesGen(), new HashMap<>(),
-                                    0, 0);
+                                    proto.getDimensionCount(), proto.getDimensionNumBytes());
 
     FieldInfos fieldInfos = new FieldInfos(new FieldInfo[] { field } );
 
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java	(working copy)
@@ -161,7 +161,7 @@
           }
           TopDocs hits = s.search(new TermQuery(new Term("id", testID)), 1);
           assertEquals(1, hits.totalHits);
-          StoredDocument doc = r.document(hits.scoreDocs[0].doc);
+          Document doc = r.document(hits.scoreDocs[0].doc);
           Document docExp = docs.get(testID);
           for(int i=0;i<fieldCount;i++) {
             assertEquals("doc " + testID + ", field f" + fieldCount + " is wrong", docExp.get("f"+i),  doc.get("f"+i));
@@ -188,8 +188,8 @@
     doc.add(newField("zzz", "1 2 3", customType));
     w.addDocument(doc);
     IndexReader r = w.getReader();
-    StoredDocument doc2 = r.document(0);
-    Iterator<StorableField> it = doc2.getFields().iterator();
+    Document doc2 = r.document(0);
+    Iterator<IndexableField> it = doc2.getFields().iterator();
     assertTrue(it.hasNext());
     Field f = (Field) it.next();
     assertEquals(f.name(), "zzz");
@@ -230,8 +230,8 @@
     w.close();
 
     IndexReader ir = DirectoryReader.open(dir);
-    StoredDocument doc2 = ir.document(0);
-    StorableField f2 = doc2.getField("binary");
+    Document doc2 = ir.document(0);
+    IndexableField f2 = doc2.getField("binary");
     b = f2.binaryValue().bytes;
     assertTrue(b != null);
     assertEquals(17, b.length, 17);
@@ -302,7 +302,7 @@
       final LeafReader sub = ctx.reader();
       final NumericDocValues ids = DocValues.getNumeric(sub, "id");
       for(int docID=0;docID<sub.numDocs();docID++) {
-        final StoredDocument doc = sub.document(docID);
+        final Document doc = sub.document(docID);
         final Field f = (Field) doc.getField("nf");
         assertTrue("got f=" + f, f instanceof StoredField);
         assertEquals(answers[(int) ids.get(docID)], f.numericValue());
@@ -368,8 +368,8 @@
     final int docID = random().nextInt(100);
     for (Field fld : fields) {
       String fldName = fld.name();
-      final StoredDocument sDoc = reader.document(docID, Collections.singleton(fldName));
-      final StorableField sField = sDoc.getField(fldName);
+      final Document sDoc = reader.document(docID, Collections.singleton(fldName));
+      final IndexableField sField = sDoc.getField(fldName);
       if (Field.class.equals(fld.getClass())) {
         assertEquals(fld.binaryValue(), sField.binaryValue());
         assertEquals(fld.stringValue(), sField.stringValue());
@@ -397,7 +397,7 @@
     iw.commit();
     final DirectoryReader rd = DirectoryReader.open(dir);
     for (int i = 0; i < numDocs; ++i) {
-      final StoredDocument doc = rd.document(i);
+      final Document doc = rd.document(i);
       assertNotNull(doc);
       assertTrue(doc.getFields().isEmpty());
     }
@@ -451,7 +451,7 @@
               if (topDocs.totalHits != 1) {
                 throw new IllegalStateException("Expected 1 hit, got " + topDocs.totalHits);
               }
-              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);
+              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);
               if (sdoc == null || sdoc.get("fld") == null) {
                 throw new IllegalStateException("Could not find document " + q);
               }
@@ -558,7 +558,7 @@
     assertTrue(ir.numDocs() > 0);
     int numDocs = 0;
     for (int i = 0; i < ir.maxDoc(); ++i) {
-      final StoredDocument doc = ir.document(i);
+      final Document doc = ir.document(i);
       if (doc == null) {
         continue;
       }
@@ -653,7 +653,7 @@
 
     reader = w.getReader();
     for (int i = 0; i < reader.maxDoc(); ++i) {
-      final StoredDocument doc = reader.document(i);
+      final Document doc = reader.document(i);
       final int id = doc.getField("id").numericValue().intValue();
       final Document expected = docs[id];
       assertEquals(expected.get("s"), doc.get("s"));
@@ -726,9 +726,9 @@
       final Query query = new TermQuery(new Term("id", "" + i));
       final TopDocs topDocs = searcher.search(query, 1);
       assertEquals("" + i, 1, topDocs.totalHits);
-      final StoredDocument doc = rd.document(topDocs.scoreDocs[0].doc);
+      final Document doc = rd.document(topDocs.scoreDocs[0].doc);
       assertNotNull(doc);
-      final StorableField[] fieldValues = doc.getFields("fld");
+      final IndexableField[] fieldValues = doc.getFields("fld");
       assertEquals(docs[i].getFields("fld").length, fieldValues.length);
       if (fieldValues.length > 0) {
         assertEquals(docs[i].getFields("fld")[0].binaryValue(), fieldValues[0].binaryValue());
@@ -801,7 +801,7 @@
     
     LeafReader ir = getOnlySegmentReader(DirectoryReader.open(iw, true));
     for (int i = 0; i < ir.maxDoc(); i++) {
-      StoredDocument doc = ir.document(i);
+      Document doc = ir.document(i);
       assertEquals(10, doc.getFields().size());
       for (int j = 0; j < 10; j++) {
         assertEquals(Integer.toString(j), doc.get(Integer.toString(j)));
Index: lucene/test-framework/src/java/org/apache/lucene/index/DocHelper.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/DocHelper.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/DocHelper.java	(working copy)
@@ -281,10 +281,6 @@
     return doc.getFields().size();
   }
 
-  public static int numFields(StoredDocument doc) {
-    return doc.getFields().size();
-  }
-  
   public static Document createDocument(int n, String indexName, int numFields) {
     StringBuilder sb = new StringBuilder();
     FieldType customType = new FieldType(TextField.TYPE_STORED);
Index: lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/RandomIndexWriter.java	(working copy)
@@ -129,9 +129,9 @@
   
   /**
    * Adds a Document.
-   * @see IndexWriter#addDocument(org.apache.lucene.index.IndexDocument)
+   * @see IndexWriter#addDocument(Iterable)
    */
-  public <T extends IndexableField> void addDocument(final IndexDocument doc) throws IOException {
+  public <T extends IndexableField> void addDocument(final Iterable<T> doc) throws IOException {
     LuceneTestCase.maybeChangeLiveIndexWriterConfig(r, w.getConfig());
     if (r.nextInt(5) == 3) {
       // TODO: maybe, we should simply buffer up added docs
@@ -138,11 +138,12 @@
       // (but we need to clone them), and only when
       // getReader, commit, etc. are called, we do an
       // addDocuments?  Would be better testing.
-      w.addDocuments(new Iterable<IndexDocument>() {
+      w.addDocuments(new Iterable<Iterable<T>>() {
 
         @Override
-        public Iterator<IndexDocument> iterator() {
-          return new Iterator<IndexDocument>() {
+        public Iterator<Iterable<T>> iterator() {
+          return new Iterator<Iterable<T>>() {
+
             boolean done;
             
             @Override
@@ -156,7 +157,7 @@
             }
 
             @Override
-            public IndexDocument next() {
+            public Iterable<T> next() {
               if (done) {
                 throw new IllegalStateException();
               }
@@ -195,13 +196,13 @@
     }
   }
   
-  public void addDocuments(Iterable<? extends IndexDocument> docs) throws IOException {
+  public void addDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     LuceneTestCase.maybeChangeLiveIndexWriterConfig(r, w.getConfig());
     w.addDocuments(docs);
     maybeFlushOrCommit();
   }
 
-  public void updateDocuments(Term delTerm, Iterable<? extends IndexDocument> docs) throws IOException {
+  public void updateDocuments(Term delTerm, Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException {
     LuceneTestCase.maybeChangeLiveIndexWriterConfig(r, w.getConfig());
     w.updateDocuments(delTerm, docs);
     maybeFlushOrCommit();
@@ -209,16 +210,16 @@
 
   /**
    * Updates a document.
-   * @see IndexWriter#updateDocument(Term, org.apache.lucene.index.IndexDocument)
+   * @see IndexWriter#updateDocument(Term, Iterable)
    */
-  public <T extends IndexableField> void updateDocument(Term t, final IndexDocument doc) throws IOException {
+  public <T extends IndexableField> void updateDocument(Term t, final Iterable<T> doc) throws IOException {
     LuceneTestCase.maybeChangeLiveIndexWriterConfig(r, w.getConfig());
     if (r.nextInt(5) == 3) {
-      w.updateDocuments(t, new Iterable<IndexDocument>() {
+      w.updateDocuments(t, new Iterable<Iterable<T>>() {
 
         @Override
-        public Iterator<IndexDocument> iterator() {
-          return new Iterator<IndexDocument>() {
+        public Iterator<Iterable<T>> iterator() {
+          return new Iterator<Iterable<T>>() {
             boolean done;
             
             @Override
@@ -232,7 +233,7 @@
             }
 
             @Override
-            public IndexDocument next() {
+            public Iterable<T> next() {
               if (done) {
                 throw new IllegalStateException();
               }
Index: lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java	(working copy)
@@ -91,19 +91,19 @@
     return in;
   }
 
-  protected void updateDocuments(Term id, List<? extends IndexDocument> docs) throws Exception {
+  protected void updateDocuments(Term id, List<? extends Iterable<? extends IndexableField>> docs) throws Exception {
     writer.updateDocuments(id, docs);
   }
 
-  protected void addDocuments(Term id, List<? extends IndexDocument> docs) throws Exception {
+  protected void addDocuments(Term id, List<? extends Iterable<? extends IndexableField>> docs) throws Exception {
     writer.addDocuments(docs);
   }
 
-  protected void addDocument(Term id, IndexDocument doc) throws Exception {
+  protected void addDocument(Term id, Iterable<? extends IndexableField> doc) throws Exception {
     writer.addDocument(doc);
   }
 
-  protected void updateDocument(Term term, IndexDocument doc) throws Exception {
+  protected void updateDocument(Term term, Iterable<? extends IndexableField> doc) throws Exception {
     writer.updateDocument(term, doc);
   }
 
@@ -476,7 +476,7 @@
         final int inc = Math.max(1, maxDoc/50);
         for(int docID=0;docID<maxDoc;docID += inc) {
           if (liveDocs == null || liveDocs.get(docID)) {
-            final StoredDocument doc = reader.document(docID);
+            final Document doc = reader.document(docID);
             sum += doc.getFields().size();
           }
         }
@@ -587,7 +587,7 @@
               startDocID = docID;
             }
             lastDocID = docID;
-            final StoredDocument doc = s.doc(docID);
+            final Document doc = s.doc(docID);
             assertEquals(subDocs.packID, doc.get("packID"));
           }
 
Index: lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(revision 1724443)
+++ lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(working copy)
@@ -66,6 +66,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
@@ -2298,8 +2299,8 @@
   public void assertStoredFieldsEquals(String info, IndexReader leftReader, IndexReader rightReader) throws IOException {
     assert leftReader.maxDoc() == rightReader.maxDoc();
     for (int i = 0; i < leftReader.maxDoc(); i++) {
-      StoredDocument leftDoc = leftReader.document(i);
-      StoredDocument rightDoc = rightReader.document(i);
+      Document leftDoc = leftReader.document(i);
+      Document rightDoc = rightReader.document(i);
       
       // TODO: I think this is bogus because we don't document what the order should be
       // from these iterators, etc. I think the codec/IndexReader should be free to order this stuff
@@ -2306,17 +2307,19 @@
       // in whatever way it wants (e.g. maybe it packs related fields together or something)
       // To fix this, we sort the fields in both documents by name, but
       // we still assume that all instances with same name are in order:
-      Comparator<StorableField> comp = new Comparator<StorableField>() {
+      Comparator<IndexableField> comp = new Comparator<IndexableField>() {
         @Override
-        public int compare(StorableField arg0, StorableField arg1) {
+        public int compare(IndexableField arg0, IndexableField arg1) {
           return arg0.name().compareTo(arg1.name());
         }        
       };
-      Collections.sort(leftDoc.getFields(), comp);
-      Collections.sort(rightDoc.getFields(), comp);
+      List<IndexableField> leftFields = new ArrayList<>(leftDoc.getFields());
+      List<IndexableField> rightFields = new ArrayList<>(rightDoc.getFields());
+      Collections.sort(leftFields, comp);
+      Collections.sort(rightFields, comp);
 
-      Iterator<StorableField> leftIterator = leftDoc.iterator();
-      Iterator<StorableField> rightIterator = rightDoc.iterator();
+      Iterator<IndexableField> leftIterator = leftFields.iterator();
+      Iterator<IndexableField> rightIterator = rightFields.iterator();
       while (leftIterator.hasNext()) {
         assertTrue(info, rightIterator.hasNext());
         assertStoredFieldEquals(info, leftIterator.next(), rightIterator.next());
@@ -2328,7 +2331,7 @@
   /** 
    * checks that two stored fields are equivalent 
    */
-  public void assertStoredFieldEquals(String info, StorableField leftField, StorableField rightField) {
+  public void assertStoredFieldEquals(String info, IndexableField leftField, IndexableField rightField) {
     assertEquals(info, leftField.name(), rightField.name());
     assertEquals(info, leftField.binaryValue(), rightField.binaryValue());
     assertEquals(info, leftField.stringValue(), rightField.stringValue());
Index: solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
===================================================================
--- solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java	(revision 1724443)
+++ solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java	(working copy)
@@ -32,7 +32,7 @@
 import org.apache.lucene.collation.ICUCollationKeyAnalyzer;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.DocValuesRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SortField;
@@ -214,7 +214,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
@@ -291,9 +291,9 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
     if (field.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
+      List<IndexableField> fields = new ArrayList<>();
       fields.add(createField(field, value, boost));
       final BytesRef bytes = getCollationKey(field.getName(), value.toString());
       if (field.multiValued()) {
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java	(revision 1724443)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java	(working copy)
@@ -26,7 +26,7 @@
 import java.util.Locale;
 import java.util.Map;
 
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
@@ -33,8 +33,8 @@
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.join.BitSetProducer;
 import org.apache.lucene.search.join.QueryBitSetProducer;
-import org.apache.lucene.search.join.BitSetProducer;
 import org.apache.lucene.search.join.ScoreMode;
 import org.apache.lucene.search.join.ToParentBlockJoinQuery;
 import org.apache.solr.common.util.StrUtils;
@@ -249,7 +249,7 @@
     assertEquals(values.length, result.totalHits);
     List<String> actualValues = new ArrayList<String>();
     for (int index = 0; index < values.length; ++index) {
-      StoredDocument doc = searcher.doc(result.scoreDocs[index].doc);
+      Document doc = searcher.doc(result.scoreDocs[index].doc);
       actualValues.add(doc.get(field));
     }
     
Index: solr/core/src/java/org/apache/solr/handler/BlobHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/BlobHandler.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/handler/BlobHandler.java	(working copy)
@@ -27,8 +27,8 @@
 import java.util.List;
 import java.util.Map;
 
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
@@ -62,8 +62,8 @@
 import org.slf4j.LoggerFactory;
 
 import static java.util.Collections.singletonMap;
+import static org.apache.solr.common.params.CommonParams.JSON;
 import static org.apache.solr.common.util.Utils.makeMap;
-import static org.apache.solr.common.params.CommonParams.JSON;
 
 public class BlobHandler extends RequestHandlerBase implements PluginInfoInitialized {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
@@ -122,7 +122,7 @@
 
         long version = 0;
         if (docs.totalHits > 0) {
-          StoredDocument doc = req.getSearcher().doc(docs.scoreDocs[0].doc);
+          Document doc = req.getSearcher().doc(docs.scoreDocs[0].doc);
           Number n = doc.getField("version").numericValue();
           version = n.longValue();
         }
@@ -168,8 +168,8 @@
 
               @Override
               public void write(OutputStream os) throws IOException {
-                StoredDocument doc = req.getSearcher().doc(docs.scoreDocs[0].doc);
-                StorableField sf = doc.getField("blob");
+                Document doc = req.getSearcher().doc(docs.scoreDocs[0].doc);
+                IndexableField sf = doc.getField("blob");
                 FieldType fieldType = req.getSchema().getField("blob").getType();
                 ByteBuffer buf = (ByteBuffer) fieldType.toObject(sf);
                 if (buf == null) {
Index: solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java	(working copy)
@@ -17,9 +17,22 @@
 
 package org.apache.solr.handler;
 
+import java.io.IOException;
+import java.io.Reader;
+import java.lang.invoke.MethodHandles;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.ExitableDirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
 import org.apache.lucene.search.BooleanClause;
@@ -31,8 +44,8 @@
 import org.apache.solr.common.StringUtils;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.FacetParams;
+import org.apache.solr.common.params.MoreLikeThisParams.TermStyle;
 import org.apache.solr.common.params.MoreLikeThisParams;
-import org.apache.solr.common.params.MoreLikeThisParams.TermStyle;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.ContentStream;
 import org.apache.solr.common.util.NamedList;
@@ -59,19 +72,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.io.IOException;
-import java.io.Reader;
-import java.lang.invoke.MethodHandles;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Comparator;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.regex.Pattern;
-
 /**
  * Solr MoreLikeThis --
  * 
@@ -394,7 +394,7 @@
     
     public DocListAndSet getMoreLikeThis( int id, int start, int rows, List<Query> filters, List<InterestingTerm> terms, int flags ) throws IOException
     {
-      StoredDocument doc = reader.document(id);
+      Document doc = reader.document(id);
       rawMLTQuery = mlt.like(id);
       boostedMLTQuery = getBoostedQuery( rawMLTQuery );
       if( terms != null ) {
Index: solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java	(working copy)
@@ -36,6 +36,7 @@
 import org.apache.lucene.analysis.util.CharFilterFactory;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.DocValuesType;
@@ -42,13 +43,12 @@
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.SegmentReader;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
@@ -60,8 +60,8 @@
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.solr.analysis.TokenizerChain;
+import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.luke.FieldFlag;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SolrParams;
@@ -158,7 +158,7 @@
       if( style != null && style != ShowStyle.DOC ) {
         throw new SolrException(ErrorCode.BAD_REQUEST, "missing doc param for doc style");
       }
-      StoredDocument doc = null;
+      Document doc = null;
       try {
         doc = reader.document( docId );
       }
@@ -195,7 +195,7 @@
   /**
    * @return a string representing a IndexableField's flags.  
    */
-  private static String getFieldFlags( StorableField f )
+  private static String getFieldFlags( IndexableField f )
   {
     IndexOptions opts = (f == null) ? null : f.fieldType().indexOptions();
 
@@ -272,7 +272,7 @@
     return key;
   }
 
-  private static SimpleOrderedMap<Object> getDocumentFieldsInfo( StoredDocument doc, int docId, IndexReader reader,
+  private static SimpleOrderedMap<Object> getDocumentFieldsInfo( Document doc, int docId, IndexReader reader,
                                                                  IndexSchema schema ) throws IOException
   {
     final CharsRefBuilder spare = new CharsRefBuilder();
@@ -375,12 +375,12 @@
 
       if(sfield != null && sfield.indexed() ) {
         if (params.getBool(INCLUDE_INDEX_FIELD_FLAGS,true)) {
-          StoredDocument doc = getFirstLiveDoc(terms, reader);
+          Document doc = getFirstLiveDoc(terms, reader);
 
           if (doc != null) {
             // Found a document with this field
             try {
-              StorableField fld = doc.getField(fieldName);
+              IndexableField fld = doc.getField(fieldName);
               if (fld != null) {
                 fieldMap.add("index", getFieldFlags(fld));
               } else {
@@ -406,7 +406,7 @@
   // Just get a document with the term in it, the first one will do!
   // Is there a better way to do this? Shouldn't actually be very costly
   // to do it this way.
-  private static StoredDocument getFirstLiveDoc(Terms terms, LeafReader reader) throws IOException {
+  private static Document getFirstLiveDoc(Terms terms, LeafReader reader) throws IOException {
     PostingsEnum postingsEnum = null;
     TermsEnum termsEnum = terms.iterator();
     BytesRef text;
Index: solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java	(working copy)
@@ -27,9 +27,8 @@
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
@@ -257,7 +256,7 @@
 
 
        if (docid < 0) continue;
-       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());
+       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());
        SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());
        if( transformer != null ) {
          transformer.transform(doc, docid, 0);
@@ -339,7 +338,7 @@
 
         int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));
         if (docid < 0) return null;
-        StoredDocument luceneDocument = searcher.doc(docid);
+        Document luceneDocument = searcher.doc(docid);
         sid = toSolrInputDocument(luceneDocument, core.getLatestSchema());
         searcher.decorateDocValueFields(sid, docid, searcher.getNonStoredDVs(false));
       }
@@ -352,9 +351,9 @@
     return sid;
   }
 
-  private static SolrInputDocument toSolrInputDocument(StoredDocument doc, IndexSchema schema) {
+  private static SolrInputDocument toSolrInputDocument(Document doc, IndexSchema schema) {
     SolrInputDocument out = new SolrInputDocument();
-    for( StorableField f : doc.getFields() ) {
+    for( IndexableField f : doc.getFields() ) {
       String fname = f.name();
       SchemaField sf = schema.getFieldOrNull(f.name());
       Object val = null;
@@ -375,9 +374,9 @@
   }
 
 
-  private static SolrDocument toSolrDoc(StoredDocument doc, IndexSchema schema) {
+  private static SolrDocument toSolrDoc(Document doc, IndexSchema schema) {
     SolrDocument out = new SolrDocument();
-    for( StorableField f : doc.getFields() ) {
+    for( IndexableField f : doc.getFields() ) {
       // Make sure multivalued fields are represented as lists
       Object existing = out.get(f.name());
       if (existing == null) {
@@ -407,10 +406,10 @@
     Document doc = DocumentBuilder.toDocument(sdoc, schema);
 
     // copy the stored fields only
-    StoredDocument out = new StoredDocument();
+    Document out = new Document();
     for (IndexableField f : doc.getFields()) {
       if (f.fieldType().stored() ) {
-        out.add((StorableField) f);
+        out.add((IndexableField) f);
       }
     }
 
Index: solr/core/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java
===================================================================
--- solr/core/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java	(working copy)
@@ -34,12 +34,12 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.FilterLeafReader;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.highlight.Encoder;
@@ -399,7 +399,7 @@
     DocIterator iterator = docs.iterator();
     for (int i = 0; i < docs.size(); i++) {
       int docId = iterator.nextDoc();
-      StoredDocument doc = searcher.doc(docId, preFetchFieldNames);
+      Document doc = searcher.doc(docId, preFetchFieldNames);
 
       @SuppressWarnings("rawtypes")
       NamedList docHighlights = new SimpleOrderedMap();
@@ -468,7 +468,7 @@
 
   /** Highlights and returns the highlight object for this field -- a String[] by default.  Null if none. */
   @SuppressWarnings("unchecked")
-  protected Object doHighlightingByFastVectorHighlighter(StoredDocument doc, int docId,
+  protected Object doHighlightingByFastVectorHighlighter(Document doc, int docId,
                                                          SchemaField schemaField, FastVectorHighlighter highlighter,
                                                          FieldQuery fieldQuery,
                                                          IndexReader reader, SolrQueryRequest req) throws IOException {
@@ -491,7 +491,7 @@
 
   /** Highlights and returns the highlight object for this field -- a String[] by default. Null if none. */
   @SuppressWarnings("unchecked")
-  protected Object doHighlightingByHighlighter(StoredDocument doc, int docId, SchemaField schemaField, Query query,
+  protected Object doHighlightingByHighlighter(Document doc, int docId, SchemaField schemaField, Query query,
                                                IndexReader reader, SolrQueryRequest req) throws IOException {
     final SolrParams params = req.getParams();
     final String fieldName = schemaField.getName();
@@ -633,11 +633,11 @@
   /** Fetches field values to highlight. If the field value should come from an atypical place (or another aliased
    * field name, then a subclass could override to implement that.
    */
-  protected List<String> getFieldValues(StoredDocument doc, String fieldName, int maxValues, int maxCharsToAnalyze,
+  protected List<String> getFieldValues(Document doc, String fieldName, int maxValues, int maxCharsToAnalyze,
                                         SolrQueryRequest req) {
     // Collect the Fields we will examine (could be more than one if multi-valued)
     List<String> result = new ArrayList<>();
-    for (StorableField thisField : doc.getFields()) {
+    for (IndexableField thisField : doc.getFields()) {
       if (! thisField.name().equals(fieldName)) {
         continue;
       }
@@ -667,19 +667,19 @@
 
   /** Returns the alternate highlight object for this field -- a String[] by default.  Null if none. */
   @SuppressWarnings("unchecked")
-  protected Object alternateField(StoredDocument doc, String fieldName, SolrQueryRequest req) {
+  protected Object alternateField(Document doc, String fieldName, SolrQueryRequest req) {
     SolrParams params = req.getParams();
     String alternateField = params.getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);
     if (alternateField == null || alternateField.length() == 0) {
       return null;
     }
-    StorableField[] docFields = doc.getFields(alternateField);
+    IndexableField[] docFields = doc.getFields(alternateField);
     if (docFields.length == 0) {
       // The alternate field did not exist, treat the original field as fallback instead
       docFields = doc.getFields(fieldName);
     }
     List<String> listFields = new ArrayList<>();
-    for (StorableField field : docFields) {
+    for (IndexableField field : docFields) {
       if (field.binaryValue() == null)
         listFields.add(field.stringValue());
     }
Index: solr/core/src/java/org/apache/solr/highlight/PostingsSolrHighlighter.java
===================================================================
--- solr/core/src/java/org/apache/solr/highlight/PostingsSolrHighlighter.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/highlight/PostingsSolrHighlighter.java	(working copy)
@@ -17,8 +17,15 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.text.BreakIterator;
+import java.util.Collections;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
+
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.postingshighlight.DefaultPassageFormatter;
 import org.apache.lucene.search.postingshighlight.Passage;
@@ -40,13 +47,6 @@
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.plugin.PluginInfoInitialized;
 
-import java.io.IOException;
-import java.text.BreakIterator;
-import java.util.Collections;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Set;
-
 /** 
  * Highlighter impl that uses {@link PostingsHighlighter}
  * <p>
@@ -195,7 +195,7 @@
       String uniqueKeys[] = new String[docIDs.length];
       for (int i = 0; i < docIDs.length; i++) {
         int docid = docIDs[i];
-        StoredDocument doc = searcher.doc(docid, selector);
+        Document doc = searcher.doc(docid, selector);
         String id = schema.printableUniqueKey(doc);
         uniqueKeys[i] = id;
       }
Index: solr/core/src/java/org/apache/solr/response/BinaryResponseWriter.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/BinaryResponseWriter.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/response/BinaryResponseWriter.java	(working copy)
@@ -27,7 +27,7 @@
 import java.util.Iterator;
 import java.util.List;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.params.CommonParams;
@@ -91,10 +91,10 @@
         writeResults(ctx, codec);
         return null; // null means we completely handled it
       }
-      if( o instanceof StorableField ) {
+      if( o instanceof IndexableField ) {
         if(schema == null) schema = solrQueryRequest.getSchema();
 
-        StorableField f = (StorableField)o;
+        IndexableField f = (IndexableField)o;
         SchemaField sf = schema.getFieldOrNull(f.name());
         try {
           o = DocsStreamer.getValue(sf, f);
Index: solr/core/src/java/org/apache/solr/response/DocsStreamer.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/DocsStreamer.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/response/DocsStreamer.java	(working copy)
@@ -24,8 +24,8 @@
 import java.util.List;
 import java.util.Set;
 
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.util.BytesRef;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrException;
@@ -129,7 +129,7 @@
       sdoc = new SolrDocument();
     } else {
       try {
-        StoredDocument doc = rctx.getSearcher().doc(id, fnames);
+        Document doc = rctx.getSearcher().doc(id, fnames);
         sdoc = getDoc(doc, rctx.getSearcher().getSchema()); // make sure to use the schema from the searcher and not the request (cross-core)
 
         // decorate the document with non-stored docValues fields
@@ -153,9 +153,9 @@
 
   }
 
-  public static SolrDocument getDoc(StoredDocument doc, final IndexSchema schema) {
+  public static SolrDocument getDoc(Document doc, final IndexSchema schema) {
     SolrDocument out = new SolrDocument();
-    for (StorableField f : doc.getFields()) {
+    for (IndexableField f : doc.getFields()) {
       // Make sure multivalued fields are represented as lists
       Object existing = out.get(f.name());
       if (existing == null) {
@@ -178,7 +178,7 @@
   public void remove() { //do nothing
   }
 
-  public static Object getValue(SchemaField sf, StorableField f) {
+  public static Object getValue(SchemaField sf, IndexableField f) {
     FieldType ft = null;
     if (sf != null) ft = sf.getType();
 
Index: solr/core/src/java/org/apache/solr/response/TextResponseWriter.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/TextResponseWriter.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/response/TextResponseWriter.java	(working copy)
@@ -26,8 +26,8 @@
 import java.util.Iterator;
 import java.util.Map;
 
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.util.BytesRef;
 import org.apache.solr.client.solrj.io.Tuple;
 import org.apache.solr.client.solrj.io.stream.TupleStream;
@@ -127,8 +127,8 @@
     } else if (val instanceof String) {
       writeStr(name, val.toString(), true);
       // micro-optimization... using toString() avoids a cast first
-    } else if (val instanceof StorableField) {
-      StorableField f = (StorableField)val;
+    } else if (val instanceof IndexableField) {
+      IndexableField f = (IndexableField)val;
       SchemaField sf = schema.getFieldOrNull( f.name() );
       if( sf != null ) {
         sf.getType().write(this, name, f);
@@ -142,8 +142,8 @@
       writeBool(name, (Boolean)val);
     } else if (val instanceof Date) {
       writeDate(name,(Date)val);
-    } else if (val instanceof StoredDocument) {
-      SolrDocument doc = DocsStreamer.getDoc((StoredDocument) val, schema);
+    } else if (val instanceof Document) {
+      SolrDocument doc = DocsStreamer.getDoc((Document) val, schema);
       writeSolrDocument(name, doc,returnFields, 0 );
     } else if (val instanceof SolrDocument) {
       writeSolrDocument(name, (SolrDocument)val,returnFields, 0);
Index: solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java	(working copy)
@@ -18,16 +18,16 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.join.BitSetProducer;
 import org.apache.lucene.search.join.QueryBitSetProducer;
-import org.apache.lucene.search.join.BitSetProducer;
 import org.apache.lucene.search.join.ToChildBlockJoinQuery;
 import org.apache.solr.common.SolrDocument;
+import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.response.DocsStreamer;
@@ -126,8 +126,8 @@
     FieldType idFt = idField.getType();
     Object parentIdField = doc.getFirstValue(idField.getName());
     
-    String parentIdExt = parentIdField instanceof StorableField
-      ? idFt.toExternal((StorableField)parentIdField)
+    String parentIdExt = parentIdField instanceof IndexableField
+      ? idFt.toExternal((IndexableField)parentIdField)
       : parentIdField.toString();
 
     try {
@@ -138,7 +138,7 @@
         DocIterator i = children.iterator();
         while(i.hasNext()) {
           Integer childDocNum = i.next();
-          StoredDocument childDoc = context.getSearcher().doc(childDocNum);
+          Document childDoc = context.getSearcher().doc(childDocNum);
           SolrDocument solrChildDoc = DocsStreamer.getDoc(childDoc, schema);
 
           // TODO: future enhancement...
Index: solr/core/src/java/org/apache/solr/response/transform/RawValueTransformerFactory.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/transform/RawValueTransformerFactory.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/response/transform/RawValueTransformerFactory.java	(working copy)
@@ -20,7 +20,7 @@
 import java.util.ArrayList;
 import java.util.Collection;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SolrParams;
@@ -141,8 +141,8 @@
     @Override
     public void write(String name, TextResponseWriter writer) throws IOException {
       String str = null;
-      if(val instanceof StorableField) { // delays holding it in memory
-        str = ((StorableField)val).stringValue();
+      if(val instanceof IndexableField) { // delays holding it in memory
+        str = ((IndexableField)val).stringValue();
       }
       else {
         str = val.toString();
Index: solr/core/src/java/org/apache/solr/schema/AbstractSpatialFieldType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/AbstractSpatialFieldType.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/AbstractSpatialFieldType.java	(working copy)
@@ -30,18 +30,9 @@
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutionException;
 
-import com.google.common.base.Throwables;
-import com.google.common.cache.Cache;
-import com.google.common.cache.CacheBuilder;
-import com.spatial4j.core.context.SpatialContext;
-import com.spatial4j.core.context.SpatialContextFactory;
-import com.spatial4j.core.distance.DistanceUtils;
-import com.spatial4j.core.shape.Point;
-import com.spatial4j.core.shape.Rectangle;
-import com.spatial4j.core.shape.Shape;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StoredField;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionQuery;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause.Occur;
@@ -64,6 +55,16 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.google.common.base.Throwables;
+import com.google.common.cache.Cache;
+import com.google.common.cache.CacheBuilder;
+import com.spatial4j.core.context.SpatialContext;
+import com.spatial4j.core.context.SpatialContextFactory;
+import com.spatial4j.core.distance.DistanceUtils;
+import com.spatial4j.core.shape.Point;
+import com.spatial4j.core.shape.Rectangle;
+import com.spatial4j.core.shape.Shape;
+
 /**
  * Abstract base class for Solr FieldTypes based on a Lucene 4 {@link SpatialStrategy}.
  *
@@ -192,7 +193,7 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object val, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object val, float boost) {
     String shapeStr = null;
     Shape shape;
     if (val instanceof Shape) {
@@ -206,7 +207,7 @@
       return Collections.emptyList();
     }
 
-    List<StorableField> result = new ArrayList<>();
+    List<IndexableField> result = new ArrayList<>();
     if (field.indexed()) {
       T strategy = getStrategy(field.getName());
       result.addAll(Arrays.asList(strategy.createIndexableFields(shape)));
@@ -384,10 +385,10 @@
         if (du != null) {
           multiplier = du.multiplierFromDegreesToThisUnit();
         } else {
-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
-              "'score' local-param must be one of " + supportedScoreModes + ", it was: " + score);
+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
+                                  "'score' local-param must be one of " + supportedScoreModes + ", it was: " + score);
+        }
     }
-  }
 
     return strategy.makeDistanceValueSource(spatialArgs.getShape().getCenter(), multiplier);
   }
@@ -412,7 +413,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/BinaryField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/BinaryField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/BinaryField.java	(working copy)
@@ -22,7 +22,7 @@
 import java.nio.ByteBuffer;
 
 import org.apache.lucene.document.Field;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
 import org.apache.lucene.util.BytesRef;
@@ -41,7 +41,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, toBase64String(toObject(f)), false);
   }
 
@@ -61,18 +61,18 @@
   }
 
   @Override
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     return toBase64String(toObject(f));
   }
 
   @Override
-  public ByteBuffer toObject(StorableField f) {
+  public ByteBuffer toObject(IndexableField f) {
     BytesRef bytes = f.binaryValue();
     return  ByteBuffer.wrap(bytes.bytes, bytes.offset, bytes.length);
   }
 
   @Override
-  public StorableField createField(SchemaField field, Object val, float boost) {
+  public IndexableField createField(SchemaField field, Object val, float boost) {
     if (val == null) return null;
     if (!field.stored()) {
       log.trace("Ignoring unstored binary field: " + field);
Index: solr/core/src/java/org/apache/solr/schema/BoolField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/BoolField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/BoolField.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.docvalues.BoolDocValues;
@@ -123,12 +123,12 @@
   }
 
   @Override
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     return indexedToReadable(f.stringValue());
   }
 
   @Override
-  public Boolean toObject(StorableField f) {
+  public Boolean toObject(IndexableField f) {
     return Boolean.valueOf( toExternal(f) );
   }
 
@@ -157,7 +157,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeBool(name, f.stringValue().charAt(0) == 'T');
   }
 
Index: solr/core/src/java/org/apache/solr/schema/CollationField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/CollationField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/CollationField.java	(working copy)
@@ -36,7 +36,7 @@
 import org.apache.lucene.collation.CollationKeyAnalyzer;
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.DocValuesRangeQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SortField;
@@ -186,7 +186,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
@@ -256,9 +256,9 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
     if (field.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
+      List<IndexableField> fields = new ArrayList<>();
       fields.add(createField(field, value, boost));
       final BytesRef bytes = getCollationKey(field.getName(), value.toString());
       if (field.multiValued()) {
Index: solr/core/src/java/org/apache/solr/schema/CurrencyField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/CurrencyField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/CurrencyField.java	(working copy)
@@ -37,7 +37,7 @@
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause.Occur;
@@ -171,10 +171,10 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object externalVal, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object externalVal, float boost) {
     CurrencyValue value = CurrencyValue.parse(externalVal.toString(), defaultCurrency);
 
-    List<StorableField> f = new ArrayList<>();
+    List<IndexableField> f = new ArrayList<>();
     SchemaField amountField = getAmountField(field);
     f.add(amountField.createField(String.valueOf(value.getAmount()), amountField.indexed() && !amountField.omitNorms() ? boost : 1F));
     SchemaField currencyField = getCurrencyField(field);
@@ -355,7 +355,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField field) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField field) throws IOException {
     writer.writeStr(name, field.stringValue(), true);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/DateRangeField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/DateRangeField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/DateRangeField.java	(working copy)
@@ -25,7 +25,7 @@
 
 import com.spatial4j.core.shape.Shape;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.spatial.prefix.NumberRangePrefixTreeStrategy;
 import org.apache.lucene.spatial.prefix.tree.DateRangePrefixTree;
@@ -63,7 +63,7 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object val, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object val, float boost) {
     if (val instanceof Date || val instanceof Calendar)//From URP?
       val = tree.toUnitShape(val);
     return super.createFields(field, val, boost);
Index: solr/core/src/java/org/apache/solr/schema/EnumField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/EnumField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/EnumField.java	(working copy)
@@ -38,7 +38,7 @@
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
 import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.EnumFieldSource;
 import org.apache.lucene.search.ConstantScoreQuery;
@@ -168,7 +168,7 @@
    * {@inheritDoc}
    */
   @Override
-  public EnumFieldValue toObject(StorableField f) {
+  public EnumFieldValue toObject(IndexableField f) {
     Integer intValue = null;
     String stringValue = null;
     final Number val = f.numericValue();
@@ -213,7 +213,7 @@
    * {@inheritDoc}
    */
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     final Number val = f.numericValue();
     if (val == null) {
       writer.writeNull(name);
@@ -314,7 +314,7 @@
    * {@inheritDoc}
    */
   @Override
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     final Number val = f.numericValue();
     if (val == null)
       return null;
@@ -361,7 +361,7 @@
    * {@inheritDoc}
    */
   @Override
-  public String storedToIndexed(StorableField f) {
+  public String storedToIndexed(IndexableField f) {
     final Number val = f.numericValue();
     if (val == null)
       return null;
@@ -374,7 +374,7 @@
    * {@inheritDoc}
    */
   @Override
-  public StorableField createField(SchemaField field, Object value, float boost) {
+  public IndexableField createField(SchemaField field, Object value, float boost) {
     final boolean indexed = field.indexed();
     final boolean stored = field.stored();
     final boolean docValues = field.hasDocValues();
@@ -413,10 +413,10 @@
    * {@inheritDoc}
    */
   @Override
-  public List<StorableField> createFields(SchemaField sf, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField sf, Object value, float boost) {
     if (sf.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
-      final StorableField field = createField(sf, value, boost);
+      List<IndexableField> fields = new ArrayList<>();
+      final IndexableField field = createField(sf, value, boost);
       fields.add(field);
 
       if (sf.multiValued()) {
Index: solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/ExternalFileField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/ExternalFileField.java	(working copy)
@@ -16,7 +16,7 @@
  */
 package org.apache.solr.schema;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
@@ -82,7 +82,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     throw new UnsupportedOperationException();
   }
 
Index: solr/core/src/java/org/apache/solr/schema/FieldType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/FieldType.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/FieldType.java	(working copy)
@@ -37,7 +37,7 @@
 import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.DocValuesRangeQuery;
@@ -58,8 +58,8 @@
 import org.apache.lucene.util.Version;
 import org.apache.solr.analysis.SolrAnalyzer;
 import org.apache.solr.analysis.TokenizerChain;
+import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.util.Base64;
 import org.apache.solr.common.util.SimpleOrderedMap;
 import org.apache.solr.common.util.StrUtils;
@@ -256,7 +256,7 @@
    *
    *
    */
-  public StorableField createField(SchemaField field, Object value, float boost) {
+  public IndexableField createField(SchemaField field, Object value, float boost) {
     if (!field.indexed() && !field.stored()) {
       if (log.isTraceEnabled())
         log.trace("Ignoring unindexed/unstored field: " + field);
@@ -293,7 +293,7 @@
    * @param boost The boost value
    * @return the {@link org.apache.lucene.index.IndexableField}.
    */
-  protected StorableField createField(String name, String val, org.apache.lucene.document.FieldType type, float boost){
+  protected IndexableField createField(String name, String val, org.apache.lucene.document.FieldType type, float boost){
     Field f = new Field(name, val, type);
     f.setBoost(boost);
     return f;
@@ -309,8 +309,8 @@
    * @see #createField(SchemaField, Object, float)
    * @see #isPolyField()
    */
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
-    StorableField f = createField( field, value, boost);
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
+    IndexableField f = createField( field, value, boost);
     if (field.hasDocValues() && f.fieldType().docValuesType() == null) {
       // field types that support doc values should either override createField
       // to return a field with doc values or extend createFields if this can't
@@ -317,7 +317,7 @@
       // be done in a single field instance (see StrField for example)
       throw new UnsupportedOperationException("This field type does not support doc values: " + this);
     }
-    return f==null ? Collections.<StorableField>emptyList() : Collections.singletonList(f);
+    return f==null ? Collections.<IndexableField>emptyList() : Collections.singletonList(f);
   }
 
   protected IndexOptions getIndexOptions(SchemaField field, String internalVal) {
@@ -350,7 +350,7 @@
    * value
    * @see #toInternal
    */
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     // currently used in writing XML of the search result (but perhaps
     // a more efficient toXML(IndexableField f, Writer w) should be used
     // in the future.
@@ -362,7 +362,7 @@
    * @see #toInternal
    * @since solr 1.3
    */
-  public Object toObject(StorableField f) {
+  public Object toObject(IndexableField f) {
     return toExternal(f); // by default use the string
   }
 
@@ -369,7 +369,7 @@
   public Object toObject(SchemaField sf, BytesRef term) {
     final CharsRefBuilder ref = new CharsRefBuilder();
     indexedToReadable(term, ref);
-    final StorableField f = createField(sf, ref.toString(), 1.0f);
+    final IndexableField f = createField(sf, ref.toString(), 1.0f);
     return toObject(f);
   }
 
@@ -385,12 +385,12 @@
   }
 
   /** Given the stored field, return the human readable representation */
-  public String storedToReadable(StorableField f) {
+  public String storedToReadable(IndexableField f) {
     return toExternal(f);
   }
 
   /** Given the stored field, return the indexed form */
-  public String storedToIndexed(StorableField f) {
+  public String storedToIndexed(IndexableField f) {
     // right now, the transformation of single valued fields like SortableInt
     // is done when the Field is created, not at analysis time... this means
     // that the indexed form is the same as the stored field form.
@@ -651,7 +651,7 @@
   /**
    * calls back to TextResponseWriter to write the field value
    */
-  public abstract void write(TextResponseWriter writer, String name, StorableField f) throws IOException;
+  public abstract void write(TextResponseWriter writer, String name, IndexableField f) throws IOException;
 
 
   /**
Index: solr/core/src/java/org/apache/solr/schema/GeoHashField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/GeoHashField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/GeoHashField.java	(working copy)
@@ -23,7 +23,7 @@
 import com.spatial4j.core.distance.DistanceUtils;
 import com.spatial4j.core.io.GeohashUtils;
 import com.spatial4j.core.shape.Point;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.LiteralValueSource;
 import org.apache.lucene.search.Query;
@@ -70,13 +70,13 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f)
+  public void write(TextResponseWriter writer, String name, IndexableField f)
           throws IOException {
     writer.writeStr(name, toExternal(f), false);
   }
 
   @Override
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     Point p = GeohashUtils.decode(f.stringValue(), SpatialContext.GEO);
     return p.getY() + "," + p.getX();
   }
Index: solr/core/src/java/org/apache/solr/schema/IndexSchema.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/IndexSchema.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/IndexSchema.java	(working copy)
@@ -17,14 +17,14 @@
 
 package org.apache.solr.schema;
 
-import javax.xml.xpath.XPath;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
 import java.io.IOException;
 import java.io.Writer;
 import java.lang.invoke.MethodHandles;
 import java.util.*;
 import java.util.regex.Pattern;
+import javax.xml.xpath.XPath;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.DelegatingAnalyzerWrapper;
@@ -33,16 +33,15 @@
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.uninverting.UninvertingReader;
 import org.apache.lucene.util.Version;
+import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.SimpleOrderedMap;
 import org.apache.solr.core.Config;
@@ -327,8 +326,8 @@
    * the specified Document
    * @return null if this schema has no unique key field
    */
-  public String printableUniqueKey(StoredDocument doc) {
-    StorableField f = doc.getField(uniqueKeyFieldName);
+  public String printableUniqueKey(org.apache.lucene.document.Document doc) {
+    IndexableField f = doc.getField(uniqueKeyFieldName);
     return f==null ? null : uniqueKeyFieldType.toExternal(f);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/LatLonType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/LatLonType.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/LatLonType.java	(working copy)
@@ -24,7 +24,7 @@
 import org.apache.lucene.document.FieldType;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.VectorValueSource;
@@ -69,10 +69,10 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
     String externalVal = value.toString();
     //we could have 3 fields (two for the lat & lon, one for storage)
-    List<StorableField> f = new ArrayList<>(3);
+    List<IndexableField> f = new ArrayList<>(3);
     if (field.indexed()) {
       Point point = SpatialUtils.parsePointSolrException(externalVal, SpatialContext.GEO);
       //latitude
@@ -232,7 +232,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
@@ -251,7 +251,7 @@
   //It never makes sense to create a single field, so make it impossible to happen
 
   @Override
-  public StorableField createField(SchemaField field, Object value, float boost) {
+  public IndexableField createField(SchemaField field, Object value, float boost) {
     throw new UnsupportedOperationException("LatLonType uses multiple fields.  field=" + field.getName());
   }
 
Index: solr/core/src/java/org/apache/solr/schema/PointType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/PointType.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/PointType.java	(working copy)
@@ -24,7 +24,7 @@
 
 import com.spatial4j.core.distance.DistanceUtils;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.VectorValueSource;
 import org.apache.lucene.search.BooleanClause;
@@ -67,12 +67,12 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
     String externalVal = value.toString();
     String[] point = parseCommaSeparatedList(externalVal, dimension);
 
     // TODO: this doesn't currently support polyFields as sub-field types
-    List<StorableField> f = new ArrayList<>(dimension+1);
+    List<IndexableField> f = new ArrayList<>(dimension+1);
 
     if (field.indexed()) {
       for (int i=0; i<dimension; i++) {
@@ -108,12 +108,12 @@
    *
    */
   @Override
-  public StorableField createField(SchemaField field, Object value, float boost) {
+  public IndexableField createField(SchemaField field, Object value, float boost) {
     throw new UnsupportedOperationException("PointType uses multiple fields.  field=" + field.getName());
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/PreAnalyzedField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/PreAnalyzedField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/PreAnalyzedField.java	(working copy)
@@ -30,7 +30,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.SortField;
@@ -110,9 +110,9 @@
   }
 
   @Override
-  public StorableField createField(SchemaField field, Object value,
+  public IndexableField createField(SchemaField field, Object value,
           float boost) {
-    StorableField f = null;
+    IndexableField f = null;
     try {
       f = fromString(field, String.valueOf(value), boost);
     } catch (Exception e) {
@@ -139,7 +139,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f)
+  public void write(TextResponseWriter writer, String name, IndexableField f)
           throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
@@ -216,7 +216,7 @@
   }
   
   
-  public StorableField fromString(SchemaField field, String val, float boost) throws Exception {
+  public IndexableField fromString(SchemaField field, String val, float boost) throws Exception {
     if (val == null || val.trim().length() == 0) {
       return null;
     }
Index: solr/core/src/java/org/apache/solr/schema/RandomSortField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/RandomSortField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/RandomSortField.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.ReaderUtil;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionValues;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.docvalues.IntDocValues;
@@ -103,7 +103,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException { }
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException { }
 
 
   private static FieldComparatorSource randomComparatorSource = new FieldComparatorSource() {
Index: solr/core/src/java/org/apache/solr/schema/SchemaField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/SchemaField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/SchemaField.java	(working copy)
@@ -23,7 +23,7 @@
 import java.util.List;
 import java.util.Map;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.SortField;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.util.SimpleOrderedMap;
@@ -111,11 +111,11 @@
   boolean isTokenized() { return (properties & TOKENIZED)!=0; }
   boolean isBinary() { return (properties & BINARY)!=0; }
 
-  public StorableField createField(Object val, float boost) {
+  public IndexableField createField(Object val, float boost) {
     return type.createField(this,val,boost);
   }
 
-  public List<StorableField> createFields(Object val, float boost) {
+  public List<IndexableField> createFields(Object val, float boost) {
     return type.createFields(this,val,boost);
   }
 
@@ -137,7 +137,7 @@
       + "}";
   }
 
-  public void write(TextResponseWriter writer, String name, StorableField val) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField val) throws IOException {
     // name is passed in because it may be null if name should not be used.
     type.write(writer,name,val);
   }
Index: solr/core/src/java/org/apache/solr/schema/StrField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/StrField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/StrField.java	(working copy)
@@ -25,7 +25,7 @@
 
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
@@ -41,10 +41,10 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value,
+  public List<IndexableField> createFields(SchemaField field, Object value,
       float boost) {
     if (field.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
+      List<IndexableField> fields = new ArrayList<>();
       fields.add(createField(field, value, boost));
       final BytesRef bytes = new BytesRef(value.toString());
       if (field.multiValued()) {
@@ -73,7 +73,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/TextField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/TextField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/TextField.java	(working copy)
@@ -21,7 +21,7 @@
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.SortedSetFieldSource;
 import org.apache.lucene.search.*;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
@@ -113,7 +113,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/TrieDateField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/TrieDateField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/TrieDateField.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.util.Date;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.update.processor.TimestampUpdateProcessorFactory; //jdoc
 import org.apache.solr.util.DateFormatUtil;
 import org.apache.solr.util.DateMathParser;
@@ -90,7 +90,7 @@
   }
   
   @Override
-  public Date toObject(StorableField f) {
+  public Date toObject(IndexableField f) {
     return (Date)super.toObject(f);
   }
 
Index: solr/core/src/java/org/apache/solr/schema/TrieField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/TrieField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/TrieField.java	(working copy)
@@ -34,7 +34,7 @@
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
 import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.DoubleFieldSource;
 import org.apache.lucene.queries.function.valuesource.FloatFieldSource;
@@ -112,7 +112,7 @@
   }
 
   @Override
-  public Object toObject(StorableField f) {
+  public Object toObject(IndexableField f) {
     final Number val = f.numericValue();
     if (val != null) {
       return (type == TrieTypes.DATE) ? new Date(val.longValue()) : val;
@@ -295,7 +295,7 @@
   }
   
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeVal(name, toObject(f));
   }
 
@@ -445,7 +445,7 @@
   }
 
   @Override
-  public String storedToReadable(StorableField f) {
+  public String storedToReadable(IndexableField f) {
     return toExternal(f);
   }
 
@@ -491,13 +491,13 @@
     return readableToIndexed(val);
   }
 
-  static String badFieldString(StorableField f) {
+  static String badFieldString(IndexableField f) {
     String s = f.stringValue();
     return "ERROR:SCHEMA-INDEX-MISMATCH,stringValue="+s;
   }
 
   @Override
-  public String toExternal(StorableField f) {
+  public String toExternal(IndexableField f) {
     return (type == TrieTypes.DATE)
       ? DateFormatUtil.formatExternal((Date) toObject(f))
       : toObject(f).toString();
@@ -569,13 +569,13 @@
   }
 
   @Override
-  public String storedToIndexed(StorableField f) {
+  public String storedToIndexed(IndexableField f) {
     final BytesRefBuilder bytes = new BytesRefBuilder();
     storedToIndexed(f, bytes);
     return bytes.get().utf8ToString();
   }
 
-  private void storedToIndexed(StorableField f, final BytesRefBuilder bytes) {
+  private void storedToIndexed(IndexableField f, final BytesRefBuilder bytes) {
     final Number val = f.numericValue();
     if (val != null) {
       switch (type) {
@@ -633,7 +633,7 @@
   }
   
   @Override
-  public StorableField createField(SchemaField field, Object value, float boost) {
+  public IndexableField createField(SchemaField field, Object value, float boost) {
     boolean indexed = field.indexed();
     boolean stored = field.stored();
     boolean docValues = field.hasDocValues();
@@ -713,10 +713,10 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField sf, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField sf, Object value, float boost) {
     if (sf.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
-      final StorableField field = createField(sf, value, boost);
+      List<IndexableField> fields = new ArrayList<>();
+      final IndexableField field = createField(sf, value, boost);
       fields.add(field);
       
       if (sf.multiValued()) {
Index: solr/core/src/java/org/apache/solr/schema/UUIDField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/UUIDField.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/schema/UUIDField.java	(working copy)
@@ -22,7 +22,7 @@
 import java.util.Map;
 import java.util.UUID;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.SortField;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.response.TextResponseWriter;
@@ -64,7 +64,7 @@
   }
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f)
+  public void write(TextResponseWriter writer, String name, IndexableField f)
       throws IOException {
     writer.writeStr(name, f.stringValue(), false);
   }
@@ -99,7 +99,7 @@
   }
 
   @Override
-  public UUID toObject(StorableField f) {
+  public UUID toObject(IndexableField f) {
     return UUID.fromString(f.stringValue());
   }
 }
Index: solr/core/src/java/org/apache/solr/search/Grouping.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/Grouping.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/search/Grouping.java	(working copy)
@@ -29,7 +29,7 @@
 
 import org.apache.commons.lang.ArrayUtils;
 import org.apache.lucene.index.ExitableDirectoryReader;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.FunctionQuery;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.QueryValueSource;
@@ -820,7 +820,7 @@
           SchemaField schemaField = searcher.getSchema().getField(groupBy);
           FieldType fieldType = schemaField.getType();
           String readableValue = fieldType.indexedToReadable(group.groupValue.utf8ToString());
-          StorableField field = schemaField.createField(readableValue, 1.0f);
+          IndexableField field = schemaField.createField(readableValue, 1.0f);
           nl.add("groupValue", fieldType.toObject(field));
         } else {
           nl.add("groupValue", null);
Index: solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(working copy)
@@ -48,6 +48,7 @@
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.MultiPostingsEnum;
@@ -56,16 +57,14 @@
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.StoredFieldVisitor.Status;
 import org.apache.lucene.index.StoredFieldVisitor;
-import org.apache.lucene.index.StoredFieldVisitor.Status;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.CollectionStatistics;
 import org.apache.lucene.search.Collector;
@@ -101,13 +100,13 @@
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.solr.common.SolrDocumentBase;
+import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.SimpleOrderedMap;
+import org.apache.solr.core.DirectoryFactory.DirContext;
 import org.apache.solr.core.DirectoryFactory;
-import org.apache.solr.core.DirectoryFactory.DirContext;
 import org.apache.solr.core.SolrConfig;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.core.SolrInfoMBean;
@@ -166,7 +165,7 @@
   private final boolean cachingEnabled;
   private final SolrCache<Query,DocSet> filterCache;
   private final SolrCache<QueryResultKey,DocList> queryResultCache;
-  private final SolrCache<Integer,StoredDocument> documentCache;
+  private final SolrCache<Integer,Document> documentCache;
   private final SolrCache<String,UnInvertedField> fieldValueCache;
 
   // map of generic caches - not synchronized since it's read-only after the constructor.
@@ -643,7 +642,7 @@
 
   /** FieldSelector which loads the specified fields, and loads all other field lazily. */
   private static class SetNonLazyFieldSelector extends DocumentStoredFieldVisitor {
-    private final StoredDocument doc;
+    private final Document doc;
     private final LazyDocument lazyDoc;
 
     SetNonLazyFieldSelector(Set<String> toLoad, IndexReader reader, int docID) {
@@ -666,7 +665,7 @@
    * Retrieve the {@link Document} instance corresponding to the document id.
    */
   @Override
-  public StoredDocument doc(int i) throws IOException {
+  public Document doc(int i) throws IOException {
     return doc(i, (Set<String>) null);
   }
 
@@ -679,7 +678,7 @@
   @Override
   public void doc(int n, StoredFieldVisitor visitor) throws IOException {
     if (documentCache != null) {
-      StoredDocument cached = documentCache.get(n);
+      Document cached = documentCache.get(n);
       if (cached != null) {
         visitFromCached(cached, visitor);
         return;
@@ -689,8 +688,8 @@
   }
 
   /** Executes a stored field visitor against a hit from the document cache */
-  private void visitFromCached(StoredDocument document, StoredFieldVisitor visitor) throws IOException {
-    for (StorableField f : document) {
+  private void visitFromCached(Document document, StoredFieldVisitor visitor) throws IOException {
+    for (IndexableField f : document) {
       final FieldInfo info = fieldInfos.fieldInfo(f.name());
       final Status needsField = visitor.needsField(info);
       if (needsField == Status.STOP) return;
@@ -726,9 +725,9 @@
    * fields will be loaded (the remainder will be available lazily).
    */
   @Override
-  public StoredDocument doc(int i, Set<String> fields) throws IOException {
+  public Document doc(int i, Set<String> fields) throws IOException {
 
-    StoredDocument d;
+    Document d;
     if (documentCache != null) {
       d = documentCache.get(i);
       if (d != null) return d;
@@ -830,7 +829,7 @@
   /**
    * Takes a list of docs (the doc ids actually), and reads them into an array of Documents.
    */
-  public void readDocs(StoredDocument[] docs, DocList ids) throws IOException {
+  public void readDocs(Document[] docs, DocList ids) throws IOException {
     readDocs(docs, ids, null);
   }
 
@@ -837,7 +836,7 @@
   /**
    * Takes a list of docs (the doc ids actually) and a set of fields to load, and reads them into an array of Documents.
    */
-  public void readDocs(StoredDocument[] docs, DocList ids, Set<String> fields) throws IOException {
+  public void readDocs(Document[] docs, DocList ids, Set<String> fields) throws IOException {
     final DocIterator iter = ids.iterator();
     for (int i = 0; i < docs.length; i++) {
       docs[i] = doc(iter.nextDoc(), fields);
@@ -2277,8 +2276,8 @@
   /**
    * Takes a list of document IDs, and returns an array of Documents containing all of the stored fields.
    */
-  public StoredDocument[] readDocs(DocList ids) throws IOException {
-    final StoredDocument[] docs = new StoredDocument[ids.size()];
+  public Document[] readDocs(DocList ids) throws IOException {
+    final Document[] docs = new Document[ids.size()];
     readDocs(docs, ids);
     return docs;
   }
Index: solr/core/src/java/org/apache/solr/search/grouping/distributed/shardresultserializer/TopGroupsResultTransformer.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/grouping/distributed/shardresultserializer/TopGroupsResultTransformer.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/search/grouping/distributed/shardresultserializer/TopGroupsResultTransformer.java	(working copy)
@@ -24,8 +24,8 @@
 import java.util.List;
 import java.util.Map;
 
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DocumentStoredFieldVisitor;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
@@ -212,7 +212,7 @@
         NamedList<Object> document = new NamedList<>();
         documents.add(document);
 
-        StoredDocument doc = retrieveDocument(uniqueField, searchGroup.scoreDocs[i].doc);
+        Document doc = retrieveDocument(uniqueField, searchGroup.scoreDocs[i].doc);
         document.add("id", uniqueField.getType().toExternal(doc.getField(uniqueField.getName())));
         if (!Float.isNaN(searchGroup.scoreDocs[i].score))  {
           document.add("score", searchGroup.scoreDocs[i].score);
@@ -262,7 +262,7 @@
       NamedList<Object> document = new NamedList<>();
       documents.add(document);
 
-      StoredDocument doc = retrieveDocument(uniqueField, scoreDoc.doc);
+      Document doc = retrieveDocument(uniqueField, scoreDoc.doc);
       document.add("id", uniqueField.getType().toExternal(doc.getField(uniqueField.getName())));
       if (!Float.isNaN(scoreDoc.score))  {
         document.add("score", scoreDoc.score);
@@ -292,7 +292,7 @@
     return queryResult;
   }
 
-  private StoredDocument retrieveDocument(final SchemaField uniqueField, int doc) throws IOException {
+  private Document retrieveDocument(final SchemaField uniqueField, int doc) throws IOException {
     DocumentStoredFieldVisitor visitor = new DocumentStoredFieldVisitor(uniqueField.getName());
     rb.req.getSearcher().doc(doc, visitor);
     return visitor.getDocument();
Index: solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.List;
 
 import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -36,7 +35,7 @@
 /**
  *
  */
-public class AddUpdateCommand extends UpdateCommand implements Iterable<IndexDocument> {
+public class AddUpdateCommand extends UpdateCommand implements Iterable<Document> {
    // optional id in "internal" indexed form... if it is needed and not supplied,
    // it will be obtained from the doc.
    private BytesRef indexedId;
@@ -163,8 +162,8 @@
   }
 
   @Override
-  public Iterator<IndexDocument> iterator() {
-    return new Iterator<IndexDocument>() {
+  public Iterator<Document> iterator() {
+    return new Iterator<Document>() {
       Iterator<SolrInputDocument> iter;
 
       {
@@ -188,7 +187,7 @@
       }
 
       @Override
-      public IndexDocument next() {
+      public Document next() {
         return DocumentBuilder.toDocument(iter.next(), req.getSchema());
       }
 
Index: solr/core/src/java/org/apache/solr/update/DocumentBuilder.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/DocumentBuilder.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/update/DocumentBuilder.java	(working copy)
@@ -22,7 +22,7 @@
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.SolrInputField;
@@ -39,13 +39,13 @@
 public class DocumentBuilder {
 
   private static void addField(Document doc, SchemaField field, Object val, float boost) {
-    if (val instanceof StorableField) {
+    if (val instanceof IndexableField) {
       // set boost to the calculated compound boost
       ((Field)val).setBoost(boost);
       doc.add((Field)val);
       return;
     }
-    for (StorableField f : field.getType().createFields(field, val, boost)) {
+    for (IndexableField f : field.getType().createFields(field, val, boost)) {
       if (f != null) doc.add((Field) f); // null fields are not added
     }
   }
Index: solr/core/src/java/org/apache/solr/update/processor/PreAnalyzedUpdateProcessorFactory.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/processor/PreAnalyzedUpdateProcessorFactory.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/update/processor/PreAnalyzedUpdateProcessorFactory.java	(working copy)
@@ -7,7 +7,7 @@
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.FieldType;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.common.SolrInputField;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrCore;
@@ -46,7 +46,7 @@
  * <p>Fields are specified using the same patterns as in {@link FieldMutatingUpdateProcessorFactory}.
  * They are then checked whether they follow a pre-analyzed format defined by <code>parser</code>.
  * Valid fields are then parsed. The original {@link SchemaField} is used for the initial
- * creation of {@link StorableField}, which is then modified to add the results from
+ * creation of {@link IndexableField}, which is then modified to add the results from
  * parsing (token stream value and/or string value) and then it will be directly added to
  * the final Lucene {@link Document} to be indexed.</p>
  * <p>Fields that are declared in the patterns list but are not present
@@ -67,7 +67,7 @@
  * uses the "simple" parser ({@link SimplePreAnalyzedParser}) and one that uses
  * the "json" parser ({@link JsonPreAnalyzedParser}). Field "nonexistent" will be
  * removed from input documents if not present in the schema. Other fields will be
- * analyzed and if valid they will be converted to {@link StorableField}-s or if
+ * analyzed and if valid they will be converted to {@link IndexableField}-s or if
  * they are not in a valid format that can be parsed with the selected parser they
  * will be passed as-is. Assuming that <code>ssto</code> field is stored but not
  * indexed, and <code>sind</code> field is indexed but not stored: if
Index: solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java
===================================================================
--- solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java	(revision 1724443)
+++ solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java	(working copy)
@@ -32,12 +32,10 @@
 import java.util.TreeMap;
 import java.util.regex.Pattern;
 
-import com.google.common.collect.ImmutableMap;
-
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.DisjunctionMaxQuery;
@@ -83,6 +81,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.google.common.collect.ImmutableMap;
+
 /**
  * <p>Utilities that may be of use to RequestHandlers.</p>
  *
@@ -437,7 +437,7 @@
     for (int i=0; i<docs.size(); i++) {
       int id = iterator.nextDoc();
 
-      StoredDocument doc = searcher.doc(id);
+      Document doc = searcher.doc(id);
       String strid = schema.printableUniqueKey(doc);
 
       explainList.add(strid, searcher.explain(query, id) );
@@ -1019,10 +1019,10 @@
     while (dit.hasNext()) {
       int docid = dit.nextDoc();
 
-      StoredDocument luceneDoc = searcher.doc(docid, fields);
+      Document luceneDoc = searcher.doc(docid, fields);
       SolrDocument doc = new SolrDocument();
       
-      for( StorableField field : luceneDoc) {
+      for( IndexableField field : luceneDoc) {
         if (null == fields || fields.contains(field.name())) {
           SchemaField sf = schema.getField( field.name() );
           doc.addField( field.name(), sf.getType().toObject( field ) );
Index: solr/core/src/test/org/apache/solr/BasicFunctionalityTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/BasicFunctionalityTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/BasicFunctionalityTest.java	(working copy)
@@ -17,8 +17,6 @@
 
 package org.apache.solr;
 
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.StringWriter;
@@ -27,11 +25,13 @@
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
 
+import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.LazyDocument;
-import org.apache.lucene.index.StorableField;
-import org.apache.lucene.index.StoredDocument;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.MapSolrParams;
@@ -504,7 +504,7 @@
     
     IndexSchema ischema = IndexSchemaFactory.buildIndexSchema(getSchemaFile(), solrConfig);
     SchemaField f; // Solr field type
-    StorableField luf; // Lucene field
+    IndexableField luf; // Lucene field
 
     f = ischema.getField("test_basictv");
     luf = f.createField("test", 0f);
@@ -711,7 +711,7 @@
     core.execute(core.getRequestHandler(req.getParams().get(CommonParams.QT)), req, rsp);
 
     DocList dl = ((ResultContext) rsp.getResponse()).getDocList();
-    StoredDocument d = req.getSearcher().doc(dl.iterator().nextDoc());
+    Document d = req.getSearcher().doc(dl.iterator().nextDoc());
     // ensure field in fl is not lazy
     assertFalse( ((Field) d.getField("test_hlt")).getClass().getSimpleName().equals("LazyField"));
     assertFalse( ((Field) d.getField("title")).getClass().getSimpleName().equals("LazyField"));
@@ -737,8 +737,8 @@
 
     DocList dl = ((ResultContext) rsp.getResponse()).getDocList();
     DocIterator di = dl.iterator();    
-    StoredDocument d1 = req.getSearcher().doc(di.nextDoc());
-    StorableField[] values1 = null;
+    Document d1 = req.getSearcher().doc(di.nextDoc());
+    IndexableField[] values1 = null;
 
     // ensure fl field is non lazy, and non-fl field is lazy
     assertFalse( d1.getField("title") instanceof LazyDocument.LazyField);
@@ -759,10 +759,10 @@
 
     dl = ((ResultContext) rsp.getResponse()).getDocList();
     di = dl.iterator();    
-    StoredDocument d2 = req.getSearcher().doc(di.nextDoc());
+    Document d2 = req.getSearcher().doc(di.nextDoc());
     // ensure same doc, same lazy field now
     assertTrue("Doc was not cached", d1 == d2);
-    StorableField[] values2 = d2.getFields("test_hlt");
+    IndexableField[] values2 = d2.getFields("test_hlt");
     assertEquals(values1.length, values2.length);
     for (int i = 0; i < values1.length; i++) {
       assertSame("LazyField wasn't reused", 
Index: solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java
===================================================================
--- solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/response/TestCustomDocTransformer.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrInputDocument;
@@ -119,8 +119,8 @@
   public static String getAsString(String field, SolrDocument doc) {
     Object v = doc.getFirstValue(field);
     if(v != null) {
-      if(v instanceof StorableField) {
-        return ((StorableField)v).stringValue();
+      if(v instanceof IndexableField) {
+        return ((IndexableField)v).stringValue();
       }
       return v.toString();
     }
Index: solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/AbstractCurrencyFieldTest.java	(working copy)
@@ -16,20 +16,20 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.index.StorableField;
+import java.util.Currency;
+import java.util.List;
+import java.util.Random;
+import java.util.Set;
+
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.util.RTimer;
+import org.junit.Assume;
 import org.junit.BeforeClass;
 import org.junit.Ignore;
 import org.junit.Test;
-import org.junit.Assume;
 
-import java.util.List;
-import java.util.Random;
-import java.util.Set;
-import java.util.Currency;
-
 /**
  * Tests currency field type.
  * @see #field
@@ -99,7 +99,7 @@
     FieldType tmp = amount.getType();
     assertTrue(tmp instanceof CurrencyField);
     String currencyValue = "1.50,EUR";
-    List<StorableField> fields = amount.createFields(currencyValue, 2);
+    List<IndexableField> fields = amount.createFields(currencyValue, 2);
     assertEquals(fields.size(), 3);
 
     // First field is currency code, second is value, third is stored.
Index: solr/core/src/test/org/apache/solr/schema/CurrencyFieldOpenExchangeTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/CurrencyFieldOpenExchangeTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/CurrencyFieldOpenExchangeTest.java	(working copy)
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.core.SolrCore;
 import org.junit.BeforeClass;
Index: solr/core/src/test/org/apache/solr/schema/CurrencyFieldXmlFileTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/CurrencyFieldXmlFileTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/CurrencyFieldXmlFileTest.java	(working copy)
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.core.SolrCore;
 import org.junit.BeforeClass;
Index: solr/core/src/test/org/apache/solr/schema/DateFieldTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/DateFieldTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/DateFieldTest.java	(working copy)
@@ -24,7 +24,7 @@
 import java.util.Date;
 import java.util.Locale;
 
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.core.SolrConfig;
 import org.apache.solr.core.SolrResourceLoader;
@@ -183,7 +183,7 @@
   public void testCreateField() {
     int props = FieldProperties.INDEXED ^ FieldProperties.STORED;
     SchemaField sf = new SchemaField( "test", f, props, null );
-    StorableField out = f.createField(sf, "1995-12-31T23:59:59Z", 1.0f );
+    IndexableField out = f.createField(sf, "1995-12-31T23:59:59Z", 1.0f );
     assertEquals(820454399000l, f.toObject( out ).getTime() );
     
     out = f.createField(sf, new Date(820454399000l), 1.0f );
Index: solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/MyCrazyCustomField.java	(working copy)
@@ -17,7 +17,9 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.index.StorableField;
+import java.io.IOException;
+
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
@@ -25,8 +27,6 @@
 import org.apache.solr.response.TextResponseWriter;
 import org.apache.solr.search.QParser;
 
-import java.io.IOException;
-
 /**
  * Custom field that overrides the PrefixQuery behaviour to map queries such that:
  * (foo* becomes bar*) and (bar* becomes foo*).
@@ -36,7 +36,7 @@
 
 
   @Override
-  public void write(TextResponseWriter writer, String name, StorableField f) throws IOException {
+  public void write(TextResponseWriter writer, String name, IndexableField f) throws IOException {
     writer.writeStr(name, f.stringValue(), true);
   }
 
Index: solr/core/src/test/org/apache/solr/schema/PolyFieldTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/PolyFieldTest.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/PolyFieldTest.java	(working copy)
@@ -18,14 +18,14 @@
 
 import java.util.List;
 
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.index.StorableField;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.common.SolrException;
 import org.apache.solr.core.SolrCore;
-import org.apache.solr.common.SolrException;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -85,7 +85,7 @@
     assertEquals(pt.getDimension(), 2);
     double[] xy = new double[]{35.0, -79.34};
     String point = xy[0] + "," + xy[1];
-    List<StorableField> fields = home.createFields(point, 2);
+    List<IndexableField> fields = home.createFields(point, 2);
     assertEquals(fields.size(), 3);//should be 3, we have a stored field
     //first two fields contain the values, third is just stored and contains the original
     for (int i = 0; i < 3; i++) {
@@ -180,4 +180,4 @@
     clearIndex();
   }
 
-}
\ No newline at end of file
+}
Index: solr/core/src/test/org/apache/solr/schema/SortableBinaryField.java
===================================================================
--- solr/core/src/test/org/apache/solr/schema/SortableBinaryField.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/schema/SortableBinaryField.java	(working copy)
@@ -17,20 +17,20 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.document.SortedSetDocValuesField;
-import org.apache.lucene.index.StorableField;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.search.FieldComparator;
 import org.apache.lucene.search.FieldComparatorSource;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.util.BytesRef;
 
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-
 /**
  * Custom field representing a {@link BinaryField} that's sortable.
  */
@@ -42,10 +42,10 @@
   }
 
   @Override
-  public List<StorableField> createFields(SchemaField field, Object value, float boost) {
+  public List<IndexableField> createFields(SchemaField field, Object value, float boost) {
     if (field.hasDocValues()) {
-      List<StorableField> fields = new ArrayList<>();
-      StorableField storedField = createField(field, value, boost);
+      List<IndexableField> fields = new ArrayList<>();
+      IndexableField storedField = createField(field, value, boost);
       fields.add(storedField);
       ByteBuffer byteBuffer = toObject(storedField);
       BytesRef bytes = new BytesRef
Index: solr/core/src/test/org/apache/solr/search/TestStressLucene.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/TestStressLucene.java	(revision 1724443)
+++ solr/core/src/test/org/apache/solr/search/TestStressLucene.java	(working copy)
@@ -17,6 +17,16 @@
 package org.apache.solr.search;
 
 
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -25,22 +35,11 @@
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.junit.Test;
 
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
-
 import static org.apache.solr.core.SolrCore.verbose;
 
 public class TestStressLucene extends TestRTGBase {
@@ -337,7 +336,7 @@
                   verbose("ERROR: Couldn't find a doc for id", id, "using reader",r);
                 }
                 assertTrue(docid >= 0);   // we should have found the document, or its tombstone
-                StoredDocument doc = r.document(docid);
+                Document doc = r.document(docid);
                 long foundVal = Long.parseLong(doc.get(field));
                 if (foundVal < Math.abs(val)) {
                   verbose("ERROR: id",id,"model_val=",val," foundVal=",foundVal,"reader=",reader);
