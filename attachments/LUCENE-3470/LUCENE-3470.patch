Index: solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
===================================================================
--- solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(revision 1176728)
+++ solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(working copy)
@@ -106,8 +106,8 @@
         new IndexWriterConfig(Version.LUCENE_40, new StandardAnalyzer(Version.LUCENE_40))
     );
     Document doc = new Document();
-    doc.add(new Field("id", TextField.TYPE_STORED, "2"));
-    doc.add(new Field("name", TextField.TYPE_STORED, "name2"));
+    doc.add(new Field("id", "2", TextField.TYPE_STORED));
+    doc.add(new Field("name", "name2", TextField.TYPE_STORED));
     iw.addDocument(doc);
     iw.commit();
     iw.close();
Index: solr/core/src/test/org/apache/solr/search/TestSort.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/TestSort.java	(revision 1176728)
+++ solr/core/src/test/org/apache/solr/search/TestSort.java	(working copy)
@@ -150,8 +150,8 @@
 
   public void testSort() throws Exception {
     Directory dir = new RAMDirectory();
-    Field f = new Field("f", StringField.TYPE_UNSTORED,"0");
-    Field f2 = new Field("f2", StringField.TYPE_UNSTORED,"0");
+    Field f = new Field("f", "0", StringField.TYPE_UNSTORED);
+    Field f2 = new Field("f2", "0", StringField.TYPE_UNSTORED);
 
     for (int iterCnt = 0; iterCnt<iter; iterCnt++) {
       IndexWriter iw = new IndexWriter(
Index: solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java	(revision 1176728)
+++ solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java	(working copy)
@@ -290,7 +290,7 @@
     );
     for (int i = 0; i < ALT_DOCS.length; i++) {
       Document doc = new Document();
-      doc.add(new Field("title", TextField.TYPE_STORED, ALT_DOCS[i]));
+      doc.add(new Field("title", ALT_DOCS[i], TextField.TYPE_STORED));
       iw.addDocument(doc);
     }
     iw.optimize();
Index: solr/core/src/java/org/apache/solr/schema/FieldType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/FieldType.java	(revision 1176728)
+++ solr/core/src/java/org/apache/solr/schema/FieldType.java	(working copy)
@@ -273,7 +273,7 @@
    * @return the {@link org.apache.lucene.index.IndexableField}.
    */
   protected IndexableField createField(String name, String val, org.apache.lucene.document.FieldType type, float boost){
-    Field f = new Field(name, type, val);
+    Field f = new Field(name, val, type);
     f.setBoost(boost);
     return f;
   }
Index: modules/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java
===================================================================
--- modules/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java	(revision 1176728)
+++ modules/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java	(working copy)
@@ -590,7 +590,7 @@
     Document doc = new Document();
     // the word field is never queried on... its indexed so it can be quickly
     // checked for rebuild (and stored for retrieval). Doesn't need norms or TF/pos
-    Field f = new Field(F_WORD, StringField.TYPE_STORED, text);
+    Field f = new Field(F_WORD, text, StringField.TYPE_STORED);
     doc.add(f); // orig term
     addGram(text, doc, ng1, ng2);
     return doc;
@@ -605,7 +605,7 @@
         String gram = text.substring(i, i + ng);
         FieldType ft = new FieldType(StringField.TYPE_UNSTORED);
         ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);
-        Field ngramField = new Field(key, ft, gram);
+        Field ngramField = new Field(key, gram, ft);
         // spellchecker does not use positional queries, but we want freqs
         // for scoring these multivalued n-gram fields.
         doc.add(ngramField);
Index: modules/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java
===================================================================
--- modules/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java	(revision 1176728)
+++ modules/facet/src/test/org/apache/lucene/facet/FacetTestUtils.java	(working copy)
@@ -128,7 +128,7 @@
     cps.add(cp);
     Document d = new Document();
     new CategoryDocumentBuilder(tw, iParams).setCategoryPaths(cps).build(d);
-    d.add(new Field("content", TextField.TYPE_STORED, "alpha"));
+    d.add(new Field("content", "alpha", TextField.TYPE_STORED));
     iw.addDocument(d);
   }
 
Index: modules/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java
===================================================================
--- modules/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java	(revision 1176728)
+++ modules/facet/src/test/org/apache/lucene/facet/search/TestTopKInEachNodeResultHandler.java	(working copy)
@@ -328,7 +328,7 @@
     cps.add(cp);
     Document d = new Document();
     new CategoryDocumentBuilder(tw, iParams).setCategoryPaths(cps).build(d);
-    d.add(new Field("content", TextField.TYPE_STORED, "alpha"));
+    d.add(new Field("content", "alpha", TextField.TYPE_STORED));
     iw.addDocument(d);
   }
 
Index: modules/facet/src/test/org/apache/lucene/facet/FacetTestBase.java
===================================================================
--- modules/facet/src/test/org/apache/lucene/facet/FacetTestBase.java	(revision 1176728)
+++ modules/facet/src/test/org/apache/lucene/facet/FacetTestBase.java	(working copy)
@@ -245,7 +245,7 @@
     CategoryDocumentBuilder builder = new CategoryDocumentBuilder(tw, iParams);
     builder.setCategoryPaths(categories);
     builder.build(d);
-    d.add(new Field("content", TextField.TYPE_STORED, content));
+    d.add(new Field("content", content, TextField.TYPE_STORED));
     iw.addDocument(d);
   }
   
Index: modules/facet/src/test/org/apache/lucene/facet/util/TestScoredDocIDsUtils.java
===================================================================
--- modules/facet/src/test/org/apache/lucene/facet/util/TestScoredDocIDsUtils.java	(revision 1176728)
+++ modules/facet/src/test/org/apache/lucene/facet/util/TestScoredDocIDsUtils.java	(working copy)
@@ -210,7 +210,7 @@
         // assert that those docs are not returned by all-scored-doc-IDs.
         FieldType ft = new FieldType();
         ft.setStored(true);
-        doc.add(new Field("del", ft, Integer.toString(docNum)));
+        doc.add(new Field("del", Integer.toString(docNum), ft));
       }
 
       if (haveAlpha(docNum)) {
Index: modules/facet/src/java/org/apache/lucene/facet/index/CategoryDocumentBuilder.java
===================================================================
--- modules/facet/src/java/org/apache/lucene/facet/index/CategoryDocumentBuilder.java	(revision 1176728)
+++ modules/facet/src/java/org/apache/lucene/facet/index/CategoryDocumentBuilder.java	(working copy)
@@ -187,7 +187,7 @@
       // super.build())
       FieldType ft = new FieldType(TextField.TYPE_UNSTORED);
       ft.setOmitNorms(true);
-      fieldList.add(new Field(e.getKey(), ft, stream));
+      fieldList.add(new Field(e.getKey(), stream, ft));
     }
 
     return this;
Index: modules/facet/src/java/org/apache/lucene/facet/taxonomy/lucene/LuceneTaxonomyWriter.java
===================================================================
--- modules/facet/src/java/org/apache/lucene/facet/taxonomy/lucene/LuceneTaxonomyWriter.java	(revision 1176728)
+++ modules/facet/src/java/org/apache/lucene/facet/taxonomy/lucene/LuceneTaxonomyWriter.java	(working copy)
@@ -181,8 +181,8 @@
 
     FieldType ft = new FieldType(TextField.TYPE_UNSTORED);
     ft.setOmitNorms(true);
-    parentStreamField = new Field(Consts.FIELD_PAYLOADS, ft, parentStream);
-    fullPathField = new Field(Consts.FULL, StringField.TYPE_STORED, "");
+    parentStreamField = new Field(Consts.FIELD_PAYLOADS, parentStream, ft);
+    fullPathField = new Field(Consts.FULL, "", StringField.TYPE_STORED);
 
     this.nextID = indexWriter.maxDoc();
 
Index: modules/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java
===================================================================
--- modules/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java	(revision 1176728)
+++ modules/facet/src/examples/org/apache/lucene/facet/example/multiCL/MultiCLIndexer.java	(working copy)
@@ -173,7 +173,7 @@
       // create a plain Lucene document and add some regular Lucene fields
       // to it
       Document doc = new Document();
-      doc.add(new Field(SimpleUtils.TITLE, TextField.TYPE_STORED, docTitles[docNum]));
+      doc.add(new Field(SimpleUtils.TITLE, docTitles[docNum], TextField.TYPE_STORED));
       doc.add(new TextField(SimpleUtils.TEXT, docTexts[docNum]));
 
       // finally add the document to the index
Index: modules/facet/src/examples/org/apache/lucene/facet/example/simple/SimpleIndexer.java
===================================================================
--- modules/facet/src/examples/org/apache/lucene/facet/example/simple/SimpleIndexer.java	(revision 1176728)
+++ modules/facet/src/examples/org/apache/lucene/facet/example/simple/SimpleIndexer.java	(working copy)
@@ -70,7 +70,7 @@
 
       // create a plain Lucene document and add some regular Lucene fields to it 
       Document doc = new Document();
-      doc.add(new Field(SimpleUtils.TITLE, TextField.TYPE_STORED, SimpleUtils.docTitles[docNum]));
+      doc.add(new Field(SimpleUtils.TITLE, SimpleUtils.docTitles[docNum], TextField.TYPE_STORED));
       doc.add(new TextField(SimpleUtils.TEXT, SimpleUtils.docTexts[docNum]));
 
       // invoke the category document builder for adding categories to the document and,
Index: modules/facet/src/examples/org/apache/lucene/facet/example/association/AssociationIndexer.java
===================================================================
--- modules/facet/src/examples/org/apache/lucene/facet/example/association/AssociationIndexer.java	(revision 1176728)
+++ modules/facet/src/examples/org/apache/lucene/facet/example/association/AssociationIndexer.java	(working copy)
@@ -93,7 +93,7 @@
       // create a plain Lucene document and add some regular Lucene fields
       // to it
       Document doc = new Document();
-      doc.add(new Field(SimpleUtils.TITLE, TextField.TYPE_STORED, SimpleUtils.docTitles[docNum]));
+      doc.add(new Field(SimpleUtils.TITLE, SimpleUtils.docTitles[docNum], TextField.TYPE_STORED));
       doc.add(new TextField(SimpleUtils.TEXT, SimpleUtils.docTexts[docNum]));
 
       // invoke the category document builder for adding categories to the
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java	(revision 1176728)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java	(working copy)
@@ -48,8 +48,8 @@
         TEST_VERSION_CURRENT, new SimpleAnalyzer(TEST_VERSION_CURRENT)));
 
     Document doc = new Document();
-    doc.add(new Field("partnum", StringField.TYPE_STORED, "Q36"));
-    doc.add(new Field("description", TextField.TYPE_STORED, "Illidium Space Modulator"));
+    doc.add(new Field("partnum", "Q36", StringField.TYPE_STORED));
+    doc.add(new Field("description", "Illidium Space Modulator", TextField.TYPE_STORED));
     writer.addDocument(doc);
 
     writer.close();
@@ -76,10 +76,10 @@
     RAMDirectory dir = new RAMDirectory();
     IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer()));
     Document doc = new Document();
-    doc.add(new Field("partnum", TextField.TYPE_STORED, "Q36"));
+    doc.add(new Field("partnum", "Q36", TextField.TYPE_STORED));
     writer.addDocument(doc);
     doc = new Document();
-    doc.add(new Field("partnum", TextField.TYPE_STORED, "Q37"));
+    doc.add(new Field("partnum", "Q37", TextField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java	(revision 1176728)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java	(working copy)
@@ -48,8 +48,8 @@
       Document doc = new Document();
       String variedFieldValue = variedFieldValues[i % variedFieldValues.length];
       String repetitiveFieldValue = repetitiveFieldValues[i % repetitiveFieldValues.length];
-      doc.add(new Field("variedField", TextField.TYPE_STORED, variedFieldValue));
-      doc.add(new Field("repetitiveField", TextField.TYPE_STORED, repetitiveFieldValue));
+      doc.add(new Field("variedField", variedFieldValue, TextField.TYPE_STORED));
+      doc.add(new Field("repetitiveField", repetitiveFieldValue, TextField.TYPE_STORED));
       writer.addDocument(doc);
     }
     writer.close();
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(revision 1176728)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(working copy)
@@ -94,8 +94,8 @@
     ft.setStoreTermVectors(true);
     ft.setStoreTermVectorOffsets(true);
     ft.setStoreTermVectorPositions(true);
-    Field f1 = new Field("field", ft, tee);
-    Field f2 = new Field("field", ft, sink);
+    Field f1 = new Field("field", tee, ft);
+    Field f2 = new Field("field", sink, ft);
     doc.add(f1);
     doc.add(f2);
     w.addDocument(doc);
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java	(revision 1176728)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java	(working copy)
@@ -56,15 +56,15 @@
 
     Document doc;
     doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "please divide this sentence into shingles"));
+    doc.add(new Field("content", "please divide this sentence into shingles", TextField.TYPE_STORED));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "just another test sentence"));
+    doc.add(new Field("content", "just another test sentence", TextField.TYPE_STORED));
     writer.addDocument(doc);
 
     doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "a sentence which contains no test"));
+    doc.add(new Field("content", "a sentence which contains no test", TextField.TYPE_STORED));
     writer.addDocument(doc);
 
     writer.close();
Index: modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java
===================================================================
--- modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java	(revision 1176728)
+++ modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker.java	(working copy)
@@ -103,11 +103,11 @@
         numericFields = new HashMap<String,NumericField>();
         
         // Initialize the map with the default fields.
-        fields.put(BODY_FIELD, new Field(BODY_FIELD, bodyFt, ""));
-        fields.put(TITLE_FIELD, new Field(TITLE_FIELD, ft, ""));
-        fields.put(DATE_FIELD, new Field(DATE_FIELD, ft, ""));
-        fields.put(ID_FIELD, new Field(ID_FIELD, StringField.TYPE_STORED, ""));
-        fields.put(NAME_FIELD, new Field(NAME_FIELD, ft, ""));
+        fields.put(BODY_FIELD, new Field(BODY_FIELD, "", bodyFt));
+        fields.put(TITLE_FIELD, new Field(TITLE_FIELD, "", ft));
+        fields.put(DATE_FIELD, new Field(DATE_FIELD, "", ft));
+        fields.put(ID_FIELD, new Field(ID_FIELD, "", StringField.TYPE_STORED));
+        fields.put(NAME_FIELD, new Field(NAME_FIELD, "", ft));
 
         numericFields.put(DATE_MSEC_FIELD, new NumericField(DATE_MSEC_FIELD));
         numericFields.put(TIME_SEC_FIELD, new NumericField(TIME_SEC_FIELD));
@@ -127,12 +127,12 @@
      */
     Field getField(String name, FieldType ft) {
       if (!reuseFields) {
-        return new Field(name, ft, "");
+        return new Field(name, "", ft);
       }
       
       Field f = fields.get(name);
       if (f == null) {
-        f = new Field(name, ft, "");
+        f = new Field(name, "", ft);
         fields.put(name, f);
       }
       return f;
Index: modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java
===================================================================
--- modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java	(revision 1176728)
+++ modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest.java	(working copy)
@@ -45,51 +45,51 @@
                                                     new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
     // 0
     Document doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "random text"));
-    doc.add(new Field("id", customType, "1"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "1", customType));
     w.addDocument(doc);
 
     // 1
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random text blob"));
-    doc.add(new Field("id", customType, "2"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text blob", TextField.TYPE_STORED));
+    doc.add(new Field("id", "2", customType));
     w.addDocument(doc);
 
     // 2
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random textual data"));
-    doc.add(new Field("id", customType, "3"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random textual data", TextField.TYPE_STORED));
+    doc.add(new Field("id", "3", customType));
     w.addDocument(doc);
     w.commit(); // To ensure a second segment
 
     // 3
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author2"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some random text"));
-    doc.add(new Field("id", customType, "4"));
+    doc.add(new Field(groupField, "author2", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "4", customType));
     w.addDocument(doc);
 
     // 4
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author3"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random text"));
-    doc.add(new Field("id", customType, "5"));
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "5", customType));
     w.addDocument(doc);
 
     // 5
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author3"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "random blob"));
-    doc.add(new Field("id", customType, "6"));
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random blob", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
     w.addDocument(doc);
 
     // 6 -- no author field
     doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "random word stuck in alot of other text"));
-    doc.add(new Field("id", customType, "6"));
+    doc.add(new Field("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
     w.addDocument(doc);
 
     IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
Index: modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
===================================================================
--- modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java	(revision 1176728)
+++ modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java	(working copy)
@@ -61,50 +61,50 @@
                                                     new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));
     // 0
     Document doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "random text"));
-    doc.add(new Field("id", customType, "1"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "1", customType));
     w.addDocument(doc);
 
     // 1
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random text"));
-    doc.add(new Field("id", customType, "2"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "2", customType));
     w.addDocument(doc);
 
     // 2
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author1"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random textual data"));
-    doc.add(new Field("id", customType, "3"));
+    doc.add(new Field(groupField, "author1", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random textual data", TextField.TYPE_STORED));
+    doc.add(new Field("id", "3", customType));
     w.addDocument(doc);
 
     // 3
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author2"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some random text"));
-    doc.add(new Field("id", customType, "4"));
+    doc.add(new Field(groupField, "author2", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "4", customType));
     w.addDocument(doc);
 
     // 4
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author3"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "some more random text"));
-    doc.add(new Field("id", customType, "5"));
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "some more random text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "5", customType));
     w.addDocument(doc);
 
     // 5
     doc = new Document();
-    doc.add(new Field(groupField, TextField.TYPE_STORED, "author3"));
-    doc.add(new Field("content", TextField.TYPE_STORED, "random"));
-    doc.add(new Field("id", customType, "6"));
+    doc.add(new Field(groupField, "author3", TextField.TYPE_STORED));
+    doc.add(new Field("content", "random", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
     w.addDocument(doc);
 
     // 6 -- no author field
     doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED,  "random word stuck in alot of other text"));
-    doc.add(new Field("id", customType, "6"));
+    doc.add(new Field("content", "random word stuck in alot of other text", TextField.TYPE_STORED));
+    doc.add(new Field("id", "6", customType));
     w.addDocument(doc);
 
     IndexSearcher indexSearcher = new IndexSearcher(w.getReader());
Index: lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles.java
===================================================================
--- lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles.java	(revision 1176728)
+++ lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles.java	(working copy)
@@ -174,7 +174,7 @@
           // field that is indexed (i.e. searchable), but don't tokenize 
           // the field into separate words and don't index term frequency
           // or positional information:
-          Field pathField = new Field("path", StringField.TYPE_STORED, file.getPath());
+          Field pathField = new Field("path", file.getPath(), StringField.TYPE_STORED);
           doc.add(pathField);
 
           // Add the last modified date of the file a field named "modified".
Index: lucene/contrib/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
===================================================================
--- lucene/contrib/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(revision 1176728)
+++ lucene/contrib/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(working copy)
@@ -134,10 +134,10 @@
         //parse row and create a document
         StringTokenizer st = new StringTokenizer(line, "\t");
         Document doc = new Document();
-        doc.add(new Field("location", textNoNorms, st.nextToken()));
-        doc.add(new Field("salary", textNoNorms, st.nextToken()));
-        doc.add(new Field("type", textNoNorms, st.nextToken()));
-        doc.add(new Field("description", textNoNorms, st.nextToken()));
+        doc.add(new Field("location", st.nextToken(), textNoNorms));
+        doc.add(new Field("salary", st.nextToken(), textNoNorms));
+        doc.add(new Field("type", st.nextToken(), textNoNorms));
+        doc.add(new Field("description", st.nextToken(), textNoNorms));
         writer.addDocument(doc);
       }
       line = br.readLine();
Index: lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java
===================================================================
--- lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java	(revision 1176728)
+++ lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java	(working copy)
@@ -211,39 +211,39 @@
     customType.setStoreTermVectorOffsets(true);
     customType.setStoreTermVectorPositions(true);
     //document.add(new Field("a", i + " Do you really want to go and live in that house all winter?", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
-    document.add(new Field("a", customType, i + " Do you really want to go and live in that house all winter?"));
+    document.add(new Field("a", i + " Do you really want to go and live in that house all winter?", customType));
     if (i > 0) {
       //document.add(new Field("b0", i + " All work and no play makes Jack a dull boy", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
-      document.add(new Field("b0", customType, i + " All work and no play makes Jack a dull boy"));
+      document.add(new Field("b0", i + " All work and no play makes Jack a dull boy", customType));
 
       //document.add(new Field("b1", i + " All work and no play makes Jack a dull boy", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, Field.TermVector.NO));
       FieldType customType2 = new FieldType(TextField.TYPE_STORED);
       customType2.setTokenized(false);
       customType2.setOmitNorms(true);
-      document.add(new Field("b1", customType2, i + " All work and no play makes Jack a dull boy"));
+      document.add(new Field("b1", i + " All work and no play makes Jack a dull boy", customType2));
       
       //document.add(new Field("b2", i + " All work and no play makes Jack a dull boy", Field.Store.NO, Field.Index.NOT_ANALYZED, Field.TermVector.NO));
       FieldType customType3 = new FieldType(TextField.TYPE_UNSTORED);
       customType3.setTokenized(false);
-      document.add(new Field("b1", customType3, i + " All work and no play makes Jack a dull boy"));
+      document.add(new Field("b1", i + " All work and no play makes Jack a dull boy", customType3));
       
       //document.add(new Field("b3", i + " All work and no play makes Jack a dull boy", Field.Store.YES, Field.Index.NO, Field.TermVector.NO));
       FieldType customType4 = new FieldType(TextField.TYPE_STORED);
       customType4.setIndexed(false);
       customType4.setTokenized(false);
-      document.add(new Field("b1", customType4, i + " All work and no play makes Jack a dull boy"));
+      document.add(new Field("b1", i + " All work and no play makes Jack a dull boy", customType4));
       if (i > 1) {
         //document.add(new Field("c", i + " Redrum redrum", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
-        document.add(new Field("c", customType, i + " Redrum redrum"));
+        document.add(new Field("c", i + " Redrum redrum", customType));
         if (i > 2) {
           //document.add(new Field("d", i + " Hello Danny, come and play with us... forever and ever. and ever.", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
-          document.add(new Field("d", customType, i + " Hello Danny, come and play with us... forever and ever. and ever."));
+          document.add(new Field("d", i + " Hello Danny, come and play with us... forever and ever. and ever.", customType));
           if (i > 3) {
             //Field f = new Field("e", i + " Heres Johnny!", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
             //f.setOmitNorms(true);
             FieldType customType5 = new FieldType(TextField.TYPE_UNSTORED);
             customType5.setOmitNorms(true);
-            Field f = new Field("e", customType5, i + " Heres Johnny!");
+            Field f = new Field("e", i + " Heres Johnny!", customType5);
             document.add(f);
             if (i > 4) {
               final List<Token> tokens = new ArrayList<Token>(2);
Index: lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java	(revision 1176728)
+++ lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter.java	(working copy)
@@ -113,10 +113,10 @@
     Directory fsDir = newFSDirectory(indexPath);
     IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);
     Document doc = new Document();
-    doc.add(new Field("content", StringField.TYPE_STORED, "doc 1"));
+    doc.add(new Field("content", "doc 1", StringField.TYPE_STORED));
     indexWriter.addDocument(doc);
     doc = new Document();
-    doc.add(new Field("content", StringField.TYPE_STORED, "doc 2"));
+    doc.add(new Field("content", "doc 2", StringField.TYPE_STORED));
     indexWriter.addDocument(doc);
     indexWriter.close();
     fsDir.close();
Index: lucene/contrib/misc/src/java/org/apache/lucene/document/FieldSelectorVisitor.java
===================================================================
--- lucene/contrib/misc/src/java/org/apache/lucene/document/FieldSelectorVisitor.java	(revision 1176728)
+++ lucene/contrib/misc/src/java/org/apache/lucene/document/FieldSelectorVisitor.java	(working copy)
@@ -90,7 +90,7 @@
       ft.setStoreTermVectors(fieldInfo.storeTermVector);
       ft.setStoreTermVectorOffsets(fieldInfo.storeOffsetWithTermVector);
       ft.setStoreTermVectorPositions(fieldInfo.storePositionWithTermVector);
-      doc.add(new Field(fieldInfo.name, ft, new String(b, "UTF-8"))); 
+      doc.add(new Field(fieldInfo.name, new String(b, "UTF-8"), ft));
       return accept != FieldSelectorResult.LOAD;
     case LAZY_LOAD:
     case LATENT:
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java	(working copy)
@@ -64,7 +64,7 @@
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectorPositions(true);
       customType.setStoreTermVectors(true);
-      document.add(new Field(FIELD, customType, new TokenStreamConcurrent()));
+      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -112,7 +112,7 @@
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectorPositions(true);
       customType.setStoreTermVectors(true);
-      document.add(new Field(FIELD, customType, new TokenStreamConcurrent()));
+      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -187,7 +187,7 @@
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectorPositions(true);
       customType.setStoreTermVectors(true);
-      document.add(new Field(FIELD, customType, new TokenStreamSparse()));
+      document.add(new Field(FIELD, new TokenStreamSparse(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -233,7 +233,7 @@
       FieldType customType = new FieldType(TextField.TYPE_STORED);
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectors(true);
-      document.add(new Field(FIELD, customType, TEXT));
+      document.add(new Field(FIELD, TEXT, customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -277,7 +277,7 @@
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectorPositions(true);
       customType.setStoreTermVectors(true);
-      document.add(new Field(FIELD, customType, new TokenStreamSparse()));
+      document.add(new Field(FIELD, new TokenStreamSparse(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/TokenSourcesTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/TokenSourcesTest.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/TokenSourcesTest.java	(working copy)
@@ -109,7 +109,7 @@
       FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
       customType.setStoreTermVectors(true);
       customType.setStoreTermVectorOffsets(true);
-      document.add(new Field(FIELD, customType, new TokenStreamOverlap()));
+      document.add(new Field(FIELD, new TokenStreamOverlap(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -158,7 +158,7 @@
       customType.setStoreTermVectors(true);
       customType.setStoreTermVectorOffsets(true);
       customType.setStoreTermVectorPositions(true);
-      document.add(new Field(FIELD, customType, new TokenStreamOverlap()));
+      document.add(new Field(FIELD, new TokenStreamOverlap(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -206,7 +206,7 @@
       FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
       customType.setStoreTermVectors(true);
       customType.setStoreTermVectorOffsets(true);
-      document.add(new Field(FIELD, customType, new TokenStreamOverlap()));
+      document.add(new Field(FIELD, new TokenStreamOverlap(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
@@ -255,7 +255,7 @@
       FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
       customType.setStoreTermVectors(true);
       customType.setStoreTermVectorOffsets(true);
-      document.add(new Field(FIELD, customType, new TokenStreamOverlap()));
+      document.add(new Field(FIELD, new TokenStreamOverlap(), customType));
       indexWriter.addDocument(document);
     } finally {
       indexWriter.close();
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -1625,7 +1625,7 @@
   
   private Document doc( String f, String v ){
     Document doc = new Document();
-    doc.add( new Field( f, TextField.TYPE_STORED, v));
+    doc.add( new Field( f, v, TextField.TYPE_STORED));
     return doc;
   }
   
@@ -1776,7 +1776,7 @@
   private void addDoc(IndexWriter writer, String text) throws IOException {
     Document d = new Document();
 
-    Field f = new Field(FIELD_NAME, TextField.TYPE_STORED, text);
+    Field f = new Field(FIELD_NAME, text, TextField.TYPE_STORED);
     d.add(f);
     writer.addDocument(d);
 
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java	(working copy)
@@ -359,7 +359,7 @@
     customType.setStoreTermVectorOffsets(true);
     customType.setStoreTermVectorPositions(true);
     for( String value: values ) {
-      doc.add( new Field( F, customType, value ) );
+      doc.add( new Field( F, value, customType) );
     }
     writer.addDocument( doc );
     writer.close();
@@ -377,7 +377,7 @@
     customType.setStoreTermVectorOffsets(true);
     customType.setStoreTermVectorPositions(true);
     for( String value: values ) {
-      doc.add( new Field( F, customType, value ));
+      doc.add( new Field( F, value, customType));
       //doc.add( new Field( F, value, Store.YES, Index.NOT_ANALYZED, TermVector.WITH_POSITIONS_OFFSETS ) );
     }
     writer.addDocument( doc );
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/SimpleFragmentsBuilderTest.java	(working copy)
@@ -142,7 +142,7 @@
     customType.setStoreTermVectors(true);
     customType.setStoreTermVectorOffsets(true);
     customType.setStoreTermVectorPositions(true);
-    doc.add( new Field( F, customType, "aaa" ) );
+    doc.add( new Field( F, "aaa", customType) );
     //doc.add( new Field( F, "aaa", Store.NO, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS ) );
     writer.addDocument( doc );
     writer.close();
Index: lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
===================================================================
--- lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java	(revision 1176728)
+++ lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java	(working copy)
@@ -133,7 +133,7 @@
             ft.setStoreTermVectors(fieldInfo.storeTermVector);
             ft.setStoreTermVectorOffsets(fieldInfo.storeOffsetWithTermVector);
             ft.setStoreTermVectorPositions(fieldInfo.storePositionWithTermVector);
-            fields.add(new Field(fieldInfo.name, ft, new String(b, "UTF-8")));
+            fields.add(new Field(fieldInfo.name, new String(b, "UTF-8"), ft));
           } else {
             in.seek(in.getFilePointer() + numUTF8Bytes);
           }
Index: lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java	(working copy)
@@ -162,7 +162,7 @@
     Document doc = new Document();
     FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
     customType.setOmitNorms(true);
-    Field f = new Field("f", customType, docText);
+    Field f = new Field("f", docText, customType);
     doc.add(f);
     return doc;
   }
@@ -237,7 +237,7 @@
     RandomIndexWriter iw = new RandomIndexWriter(random, dir);
     FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
     customType.setOmitNorms(true);
-    Field f = new Field("lyrics", customType, "");
+    Field f = new Field("lyrics", "", customType);
     Document doc = new Document();
     doc.add(f);
     f.setValue("drug drug");
Index: lucene/src/test/org/apache/lucene/search/TestSort.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSort.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/search/TestSort.java	(working copy)
@@ -132,7 +132,7 @@
     for (int i=0; i<data.length; ++i) {
       if (((i%2)==0 && even) || ((i%2)==1 && odd)) {
         Document doc = new Document();
-        doc.add (new Field ("tracer", ft1, data[i][0]));
+        doc.add (new Field ("tracer", data[i][0], ft1));
         doc.add (new TextField ("contents", data[i][1]));
         if (data[i][2] != null) {
           Field f = new StringField ("int", data[i][2]);
@@ -196,12 +196,12 @@
     for (int i=0; i<NUM_STRINGS; i++) {
         Document doc = new Document();
         String num = getRandomCharString(getRandomNumber(2, 8), 48, 52);
-        doc.add (new Field ("tracer", customType, num));
+        doc.add (new Field ("tracer", num, customType));
         //doc.add (new Field ("contents", Integer.toString(i), Field.Store.NO, Field.Index.ANALYZED));
         doc.add (new StringField ("string", num));
         String num2 = getRandomCharString(getRandomNumber(1, 4), 48, 50);
         doc.add (new StringField ("string2", num2));
-        doc.add (new Field ("tracer2", customType, num2));
+        doc.add (new Field ("tracer2", num2, customType));
         for(IndexableField f : doc.getFields()) {
           ((Field) f).setBoost(2.0f);
         }
Index: lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/search/payloads/PayloadHelper.java	(working copy)
@@ -125,9 +125,9 @@
     // writer.infoStream = System.out;
     for (int i = 0; i < numDocs; i++) {
       Document doc = new Document();
-      doc.add(new Field(FIELD, TextField.TYPE_STORED, English.intToEnglish(i)));
-      doc.add(new Field(MULTI_FIELD, TextField.TYPE_STORED, English.intToEnglish(i) + "  " + English.intToEnglish(i)));
-      doc.add(new Field(NO_PAYLOAD_FIELD, TextField.TYPE_STORED, English.intToEnglish(i)));
+      doc.add(new Field(FIELD, English.intToEnglish(i), TextField.TYPE_STORED));
+      doc.add(new Field(MULTI_FIELD, English.intToEnglish(i) + "  " + English.intToEnglish(i), TextField.TYPE_STORED));
+      doc.add(new Field(NO_PAYLOAD_FIELD, English.intToEnglish(i), TextField.TYPE_STORED));
       writer.addDocument(doc);
     }
     reader = IndexReader.open(writer, true);
Index: lucene/src/test/org/apache/lucene/search/TestTermVectors.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTermVectors.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/search/TestTermVectors.java	(working copy)
@@ -67,9 +67,9 @@
       } else {
         ft.setStoreTermVectors(true);
       }
-      doc.add(new Field("field", ft, English.intToEnglish(i)));
+      doc.add(new Field("field", English.intToEnglish(i), ft));
       //test no term vectors too
-      doc.add(new Field("noTV", TextField.TYPE_STORED, English.intToEnglish(i)));
+      doc.add(new Field("noTV", English.intToEnglish(i), TextField.TYPE_STORED));
       writer.addDocument(doc);
     }
     reader = writer.getReader();
Index: lucene/src/test/org/apache/lucene/index/Test2BPostings.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/Test2BPostings.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/Test2BPostings.java	(working copy)
@@ -66,7 +66,7 @@
     FieldType ft = new FieldType(TextField.TYPE_UNSTORED);
     ft.setOmitNorms(true);
     ft.setIndexOptions(IndexOptions.DOCS_ONLY);
-    Field field = new Field("field", ft, new MyTokenStream());
+    Field field = new Field("field", new MyTokenStream(), ft);
     doc.add(field);
     
     final int numDocs = (Integer.MAX_VALUE / 26) + 1;
Index: lucene/src/test/org/apache/lucene/index/TestGlobalFieldNumbers.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestGlobalFieldNumbers.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestGlobalFieldNumbers.java	(working copy)
@@ -50,8 +50,8 @@
             new MockAnalyzer(random));
         IndexWriter writer = new IndexWriter(dir, config);
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d1 second field"));
+        d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d1 second field", TextField.TYPE_STORED));
         writer.addDocument(d);
         for (String string : writer.getIndexFileNames()) {
           assertFalse(string.endsWith(".fnx"));
@@ -65,7 +65,7 @@
 
         assertFNXFiles(dir, "1.fnx");
         d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+        d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
         writer.addDocument(d);
         writer.commit();
@@ -83,8 +83,8 @@
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer(random)));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d3 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d3 second field"));
+        d.add(new Field("f1", "d3 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d3 second field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3, 4, 5 }));
         writer.addDocument(d);
         writer.close();
@@ -117,13 +117,13 @@
             new MockAnalyzer(random));
         IndexWriter writer = new IndexWriter(dir, config);
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d1 second field"));
+        d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d1 second field", TextField.TYPE_STORED));
         writer.addDocument(d);
         writer.commit();
         assertFNXFiles(dir, "1.fnx");
         d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+        d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
         writer.addDocument(d);
         writer.commit();
@@ -158,13 +158,13 @@
             TEST_VERSION_CURRENT, new MockAnalyzer(random)).setIndexDeletionPolicy(
             new KeepAllDeletionPolicy()));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d1 second field"));
+        d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d1 second field", TextField.TYPE_STORED));
         writer.addDocument(d);
         writer.commit();
         assertFNXFiles(dir, "1.fnx");
         d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+        d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
         writer.addDocument(d);
         writer.commit();
@@ -179,8 +179,8 @@
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer(random)));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d3 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d3 second field"));
+        d.add(new Field("f1", "d3 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d3 second field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3, 4, 5 }));
         writer.addDocument(d);
         writer.close();
@@ -204,13 +204,13 @@
           TEST_VERSION_CURRENT, new MockAnalyzer(random)).setIndexDeletionPolicy(
           new KeepAllDeletionPolicy()));
       Document d = new Document();
-      d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
-      d.add(new Field("f2", TextField.TYPE_STORED, "d1 second field"));
+      d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
+      d.add(new Field("f2", "d1 second field", TextField.TYPE_STORED));
       writer.addDocument(d);
       writer.commit();
       assertFNXFiles(dir, "1.fnx");
       d = new Document();
-      d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+      d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
       d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
       writer.addDocument(d);
       assertFNXFiles(dir, "1.fnx");
@@ -224,7 +224,7 @@
           new KeepAllDeletionPolicy()).setIndexCommit(listCommits.get(0)));
 
       d = new Document();
-      d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+      d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
       d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
       writer.addDocument(d);
       writer.commit();
@@ -475,7 +475,7 @@
       }
       
       Document d = new Document();
-      d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
+      d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
       writer.addDocument(d);
       writer.prepareCommit();
       // the fnx file should still be under control of the SIS
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -1264,7 +1264,7 @@
             
         }
         Document document = new Document();
-        document.add(new Field("field", TextField.TYPE_STORED, "a field"));
+        document.add(new Field("field", "a field", TextField.TYPE_STORED));
         w.addDocument(document);
 
         for (int i = 0; i < numDocs; i++) {
@@ -1284,7 +1284,7 @@
           }
         }
         document = new Document();
-        document.add(new Field("field", TextField.TYPE_STORED, "a field"));
+        document.add(new Field("field", "a field", TextField.TYPE_STORED));
         w.addDocument(document);
         w.close();
         IndexReader reader = IndexReader.open(dir);
Index: lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/values/TestDocValuesIndexing.java	(working copy)
@@ -536,7 +536,7 @@
         }
       }
       doc.removeFields("id");
-      doc.add(new Field("id", StringField.TYPE_STORED, idBase + i));
+      doc.add(new Field("id", idBase + i, StringField.TYPE_STORED));
       w.addDocument(doc);
 
       if (i % 7 == 0) {
Index: lucene/src/test/org/apache/lucene/index/TestOmitNorms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestOmitNorms.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestOmitNorms.java	(working copy)
@@ -227,22 +227,22 @@
   public void testOmitNormsCombos() throws IOException {
     // indexed with norms
     FieldType customType = new FieldType(TextField.TYPE_STORED);
-    Field norms = new Field("foo", customType, "a");
+    Field norms = new Field("foo", "a", customType);
     // indexed without norms
     FieldType customType1 = new FieldType(TextField.TYPE_STORED);
     customType1.setOmitNorms(true);
-    Field noNorms = new Field("foo", customType1, "a");
+    Field noNorms = new Field("foo", "a", customType1);
     // not indexed, but stored
     FieldType customType2 = new FieldType();
     customType2.setStored(true);
-    Field noIndex = new Field("foo", customType2, "a");
+    Field noIndex = new Field("foo", "a", customType2);
     // not indexed but stored, omitNorms is set
     FieldType customType3 = new FieldType();
     customType3.setStored(true);
     customType3.setOmitNorms(true);
-    Field noNormsNoIndex = new Field("foo", customType3, "a");
+    Field noNormsNoIndex = new Field("foo", "a", customType3);
     // not indexed nor stored (doesnt exist at all, we index a different field instead)
-    Field emptyNorms = new Field("bar", customType, "a");
+    Field emptyNorms = new Field("bar", "a", customType);
     
     assertNotNull(getNorms("foo", norms, norms));
     assertNull(getNorms("foo", norms, noNorms));
Index: lucene/src/test/org/apache/lucene/index/TestBinaryTerms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestBinaryTerms.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestBinaryTerms.java	(working copy)
@@ -51,7 +51,7 @@
       Document doc = new Document();
       FieldType customType = new FieldType();
       customType.setStored(true);
-      doc.add(new Field("id", customType, "" + i));
+      doc.add(new Field("id", "" + i, customType));
       doc.add(new TextField("bytes", tokenStream));
       iw.addDocument(doc);
     }
Index: lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -1059,7 +1059,7 @@
       Document d = new Document();
       FieldType customType = new FieldType(TextField.TYPE_STORED);
       customType.setStoreTermVectors(true);
-      d.add(new Field("c", customType, "v"));
+      d.add(new Field("c", "v", customType));
       w.addDocument(d);
       w.close();
     }
@@ -1097,7 +1097,7 @@
         new MockAnalyzer(random)).setMergePolicy(lmp2);
     IndexWriter w2 = new IndexWriter(src, conf2);
     Document doc = new Document();
-    doc.add(new Field("c", TextField.TYPE_STORED, "some text"));
+    doc.add(new Field("c", "some text", TextField.TYPE_STORED));
     w2.addDocument(doc);
     doc = new Document();
     doc.add(new StringField("d", "delete"));
Index: lucene/src/test/org/apache/lucene/index/TestPayloads.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestPayloads.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestPayloads.java	(working copy)
@@ -611,14 +611,14 @@
     RandomIndexWriter writer = new RandomIndexWriter(random, dir,
                                                      new MockAnalyzer(random, MockTokenizer.WHITESPACE, true));
     Document doc = new Document();
-    doc.add(new Field("hasMaybepayload", TextField.TYPE_STORED, "here we go"));
+    doc.add(new Field("hasMaybepayload", "here we go", TextField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
 
     writer = new RandomIndexWriter(random, dir,
                                    new MockAnalyzer(random, MockTokenizer.WHITESPACE, true));
     doc = new Document();
-    doc.add(new Field("hasMaybepayload2", TextField.TYPE_STORED, "here we go"));
+    doc.add(new Field("hasMaybepayload2", "here we go", TextField.TYPE_STORED));
     writer.addDocument(doc);
     writer.addDocument(doc);
     writer.optimize();
Index: lucene/src/test/org/apache/lucene/index/TestSameTokenSamePosition.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSameTokenSamePosition.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestSameTokenSamePosition.java	(working copy)
@@ -41,7 +41,7 @@
     Directory dir = newDirectory();
     RandomIndexWriter riw = new RandomIndexWriter(random, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new BugReproAnalyzer()));
     Document doc = new Document();
-    doc.add(new Field("eng", TextField.TYPE_STORED, "Six drunken" /*This shouldn't matter. */));
+    doc.add(new Field("eng", "Six drunken", TextField.TYPE_STORED  /*This shouldn't matter. */));
     riw.addDocument(doc);
     riw.close();
     dir.close();
@@ -54,7 +54,7 @@
     Directory dir = newDirectory();
     RandomIndexWriter riw = new RandomIndexWriter(random, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new BugReproAnalyzer()));
     Document doc = new Document();
-    doc.add(new Field("eng", TextField.TYPE_STORED, "Six drunken" /*This shouldn't matter. */));
+    doc.add(new Field("eng", "Six drunken", TextField.TYPE_STORED  /*This shouldn't matter. */));
     for (int i = 0; i < 100; i++) {
       riw.addDocument(doc);
     }
Index: lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -597,15 +597,15 @@
   {
     Document doc = new Document();
     doc.add(new TextField("content", "aaa"));
-    doc.add(new Field("id", StringField.TYPE_STORED, Integer.toString(id)));
+    doc.add(new Field("id", Integer.toString(id), StringField.TYPE_STORED));
     FieldType customType2 = new FieldType(TextField.TYPE_STORED);
     customType2.setStoreTermVectors(true);
     customType2.setStoreTermVectorPositions(true);
     customType2.setStoreTermVectorOffsets(true);
-    doc.add(new Field("autf8", customType2, "Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd"));
-    doc.add(new Field("utf8", customType2, "Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd"));
-    doc.add(new Field("content2", customType2, "here is more content with aaa aaa aaa"));
-    doc.add(new Field("fie\u2C77ld", customType2, "field with non-ascii name"));
+    doc.add(new Field("autf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", customType2));
+    doc.add(new Field("utf8", "Lu\uD834\uDD1Ece\uD834\uDD60ne \u0000 \u2620 ab\ud917\udc17cd", customType2));
+    doc.add(new Field("content2", "here is more content with aaa aaa aaa", customType2));
+    doc.add(new Field("fie\u2C77ld", "field with non-ascii name", customType2));
     // add numeric fields, to test if flex preserves encoding
     doc.add(new NumericField("trieInt", 4).setIntValue(id));
     doc.add(new NumericField("trieLong", 4).setLongValue(id));
@@ -616,12 +616,12 @@
     Document doc = new Document();
     FieldType customType = new FieldType(TextField.TYPE_STORED);
     customType.setIndexOptions(IndexOptions.DOCS_ONLY);
-    Field f = new Field("content3", customType, "aaa");
+    Field f = new Field("content3", "aaa", customType);
     doc.add(f);
     FieldType customType2 = new FieldType();
     customType2.setStored(true);
     customType2.setIndexOptions(IndexOptions.DOCS_ONLY);
-    f = new Field("content4", customType2, "aaa");
+    f = new Field("content4", "aaa", customType2);
     doc.add(f);
     writer.addDocument(doc);
   }
Index: lucene/src/test/org/apache/lucene/index/TestIndexReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReader.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReader.java	(working copy)
@@ -151,9 +151,9 @@
         FieldType customType3 = new FieldType();
         customType3.setStored(true);
         
-        doc.add(new Field("keyword",StringField.TYPE_STORED,"test1"));
-        doc.add(new Field("text",TextField.TYPE_STORED,"test1"));
-        doc.add(new Field("unindexed",customType3,"test1"));
+        doc.add(new Field("keyword", "test1", StringField.TYPE_STORED));
+        doc.add(new Field("text", "test1", TextField.TYPE_STORED));
+        doc.add(new Field("unindexed", "test1", customType3));
         doc.add(new TextField("unstored","test1"));
         writer.addDocument(doc);
 
@@ -177,18 +177,18 @@
         int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();
         for (int i = 0; i < 5*mergeFactor; i++) {
           doc = new Document();
-          doc.add(new Field("keyword",StringField.TYPE_STORED,"test1"));
-          doc.add(new Field("text",TextField.TYPE_STORED, "test1"));
-          doc.add(new Field("unindexed",customType3,"test1"));
+          doc.add(new Field("keyword", "test1", StringField.TYPE_STORED));
+          doc.add(new Field("text", "test1", TextField.TYPE_STORED));
+          doc.add(new Field("unindexed", "test1", customType3));
           doc.add(new TextField("unstored","test1"));
           writer.addDocument(doc);
         }
         // new fields are in some different segments (we hope)
         for (int i = 0; i < 5*mergeFactor; i++) {
           doc = new Document();
-          doc.add(new Field("keyword2",StringField.TYPE_STORED,"test1"));
-          doc.add(new Field("text2",TextField.TYPE_STORED, "test1"));
-          doc.add(new Field("unindexed2",customType3,"test1"));
+          doc.add(new Field("keyword2", "test1", StringField.TYPE_STORED));
+          doc.add(new Field("text2", "test1", TextField.TYPE_STORED));
+          doc.add(new Field("unindexed2", "test1", customType3));
           doc.add(new TextField("unstored2","test1"));
           writer.addDocument(doc);
         }
@@ -209,11 +209,11 @@
         
         for (int i = 0; i < 5*mergeFactor; i++) {
           doc = new Document();
-          doc.add(new Field("tvnot",TextField.TYPE_STORED,"tvnot"));
-          doc.add(new Field("termvector",customType5,"termvector"));
-          doc.add(new Field("tvoffset",customType6,"tvoffset"));
-          doc.add(new Field("tvposition",customType7,"tvposition"));
-          doc.add(new Field("tvpositionoffset",customType8, "tvpositionoffset"));
+          doc.add(new Field("tvnot", "tvnot", TextField.TYPE_STORED));
+          doc.add(new Field("termvector", "termvector", customType5));
+          doc.add(new Field("tvoffset", "tvoffset", customType6));
+          doc.add(new Field("tvposition", "tvposition", customType7));
+          doc.add(new Field("tvpositionoffset", "tvpositionoffset", customType8));
           writer.addDocument(doc);
         }
         
@@ -302,11 +302,11 @@
     customType8.setStoreTermVectorPositions(true);
     for (int i = 0; i < 5 * mergeFactor; i++) {
       Document doc = new Document();
-        doc.add(new Field("tvnot",TextField.TYPE_STORED,"one two two three three three"));
-        doc.add(new Field("termvector",customType5,"one two two three three three"));
-        doc.add(new Field("tvoffset",customType6,"one two two three three three"));
-        doc.add(new Field("tvposition",customType7,"one two two three three three"));
-        doc.add(new Field("tvpositionoffset",customType8, "one two two three three three"));
+        doc.add(new Field("tvnot", "one two two three three three", TextField.TYPE_STORED));
+        doc.add(new Field("termvector", "one two two three three three", customType5));
+        doc.add(new Field("tvoffset", "one two two three three three", customType6));
+        doc.add(new Field("tvposition", "one two two three three three", customType7));
+        doc.add(new Field("tvpositionoffset", "one two two three three three", customType8));
         
         writer.addDocument(doc);
     }
Index: lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(working copy)
@@ -117,7 +117,7 @@
       else {
         customType.setStoreTermVectors(true);
       }
-      doc.add(new Field(testFields[i], customType, ""));
+      doc.add(new Field(testFields[i], "", customType));
     }
 
     //Create 5 documents for testing, they all have the same
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -304,7 +304,7 @@
       int lastFlushCount = -1;
       for(int j=1;j<52;j++) {
         Document doc = new Document();
-        doc.add(new Field("field", storedTextType, "aaa" + j));
+        doc.add(new Field("field", "aaa" + j, storedTextType));
         writer.addDocument(doc);
         _TestUtil.syncConcurrentMerges(writer);
         int flushCount = writer.getFlushCount();
@@ -358,7 +358,7 @@
 
       for(int j=1;j<52;j++) {
         Document doc = new Document();
-        doc.add(new Field("field", storedTextType, "aaa" + j));
+        doc.add(new Field("field", "aaa" + j, storedTextType));
         writer.addDocument(doc);
       }
       
@@ -1236,7 +1236,7 @@
     customType.setTokenized(true);
     customType.setIndexed(true);
     
-    Field f = new Field("binary", customType, b, 10, 17);
+    Field f = new Field("binary", b, 10, 17, customType);
     f.setTokenStream(new MockTokenizer(new StringReader("doc1field1"), MockTokenizer.WHITESPACE, false));
 
     FieldType customType2 = new FieldType(TextField.TYPE_STORED);
@@ -1685,10 +1685,10 @@
     
     for (int i=0; i<2; i++) {
       Document doc = new Document();
-      doc.add(new Field("id", customType3, Integer.toString(i)+BIG));
-      doc.add(new Field("str", customType2, Integer.toString(i)+BIG));
-      doc.add(new Field("str2", storedTextType, Integer.toString(i)+BIG));
-      doc.add(new Field("str3", customType, Integer.toString(i)+BIG));
+      doc.add(new Field("id", Integer.toString(i)+BIG, customType3));
+      doc.add(new Field("str", Integer.toString(i)+BIG, customType2));
+      doc.add(new Field("str2", Integer.toString(i)+BIG, storedTextType));
+      doc.add(new Field("str3", Integer.toString(i)+BIG, customType));
       indexWriter.addDocument(doc);
     }
 
@@ -1805,7 +1805,7 @@
     doc = new Document();
     FieldType customType = new FieldType(TextField.TYPE_UNSTORED);
     customType.setTokenized(false);
-    Field contentField = new Field("content", customType, "");
+    Field contentField = new Field("content", "", customType);
     doc.add(contentField);
 
     w = new RandomIndexWriter(random, dir);
Index: lucene/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(working copy)
@@ -143,7 +143,7 @@
     customType.setStoreTermVectors(true);
     customType.setStoreTermVectorPositions(true);
     customType.setStoreTermVectorOffsets(true);
-    Field f = new Field("field", customType, stream);
+    Field f = new Field("field", stream, customType);
     doc.add(f);
     doc.add(f);
     w.addDocument(doc);
Index: lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java	(working copy)
@@ -95,7 +95,7 @@
       // Update all 100 docs...
       for(int i=0; i<100; i++) {
         Document d = new Document();
-        d.add(new Field("id", StringField.TYPE_STORED, Integer.toString(i)));
+        d.add(new Field("id", Integer.toString(i), StringField.TYPE_STORED));
         d.add(new TextField("contents", English.intToEnglish(i+10*count)));
         writer.updateDocument(new Term("id", Integer.toString(i)), d);
       }
Index: lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestFieldsReader.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestFieldsReader.java	(working copy)
@@ -304,8 +304,8 @@
     Document doc = new Document();
     FieldType onlyStored = new FieldType();
     onlyStored.setStored(true);
-    doc.add(new Field("field", onlyStored, "value"));
-    doc.add(new Field("field2", StringField.TYPE_STORED, "value"));
+    doc.add(new Field("field", "value", onlyStored));
+    doc.add(new Field("field2", "value", StringField.TYPE_STORED));
     w.addDocument(doc);
     IndexReader r = w.getReader();
     w.close();
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(working copy)
@@ -40,8 +40,6 @@
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
-import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.search.similarities.SimilarityProvider;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BitVector;
@@ -969,13 +967,13 @@
     customType2.setOmitNorms(true);
     FieldType customType3 = new FieldType();
     customType3.setStored(true);
-    doc.add(new Field("field1", TextField.TYPE_STORED, sb.toString()));
-    doc.add(new Field("fielda", customType2, sb.toString()));
-    doc.add(new Field("fieldb", customType3, sb.toString()));
+    doc.add(new Field("field1", sb.toString(), TextField.TYPE_STORED));
+    doc.add(new Field("fielda", sb.toString(), customType2));
+    doc.add(new Field("fieldb", sb.toString(), customType3));
     sb.append(" b");
     sb.append(n);
     for (int i = 1; i < numFields; i++) {
-      doc.add(new Field("field" + (i+1), TextField.TYPE_STORED, sb.toString()));
+      doc.add(new Field("field" + (i+1), sb.toString(), TextField.TYPE_STORED));
     }
     return doc;
   }
Index: lucene/src/test/org/apache/lucene/index/TestSegmentInfo.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSegmentInfo.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestSegmentInfo.java	(working copy)
@@ -32,7 +32,7 @@
     IndexWriter writer = new IndexWriter(dir, conf);
     writer.setInfoStream(VERBOSE ? System.out : null);
     Document doc = new Document();
-    doc.add(new Field("a", TextField.TYPE_STORED, "value"));
+    doc.add(new Field("a", "value", TextField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
     
Index: lucene/src/test/org/apache/lucene/index/Test2BTerms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/Test2BTerms.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/Test2BTerms.java	(working copy)
@@ -180,7 +180,7 @@
       FieldType customType = new FieldType(TextField.TYPE_STORED);
       customType.setIndexOptions(IndexOptions.DOCS_ONLY);
       customType.setOmitNorms(true);
-      Field field = new Field("field", customType, ts);
+      Field field = new Field("field", ts, customType);
       doc.add(field);
       //w.setInfoStream(System.out);
       final int numDocs = (int) (TERM_COUNT/TERMS_PER_DOC);
Index: lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java	(working copy)
@@ -39,8 +39,8 @@
       IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
 
       Document d1 = new Document();
-      d1.add(new Field("f1", StringField.TYPE_STORED, "first field"));
-      d1.add(new Field("f2", StringField.TYPE_STORED, "second field"));
+      d1.add(new Field("f1", "first field", StringField.TYPE_STORED));
+      d1.add(new Field("f2", "second field", StringField.TYPE_STORED));
       writer.addDocument(d1);
 
       if (i == 1) {
@@ -54,7 +54,7 @@
       FieldType customType2 = new FieldType(TextField.TYPE_STORED);
       customType2.setStoreTermVectors(true);
       d2.add(new TextField("f2", "second field"));
-      d2.add(new Field("f1", customType2, "first field"));
+      d2.add(new Field("f1", "first field", customType2));
       d2.add(new TextField("f3", "third field"));
       d2.add(new TextField("f4", "fourth field"));
       writer.addDocument(d2);
@@ -102,8 +102,8 @@
     IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
 
     Document d1 = new Document();
-    d1.add(new Field("f1", TextField.TYPE_STORED, "first field"));
-    d1.add(new Field("f2", TextField.TYPE_STORED, "second field"));
+    d1.add(new Field("f1", "first field", TextField.TYPE_STORED));
+    d1.add(new Field("f2", "second field", TextField.TYPE_STORED));
     writer.addDocument(d1);
 
     writer.close();
@@ -112,10 +112,10 @@
     Document d2 = new Document();
     FieldType customType2 = new FieldType(TextField.TYPE_STORED);
     customType2.setStoreTermVectors(true);
-    d2.add(new Field("f2", TextField.TYPE_STORED, "second field"));
-    d2.add(new Field("f1", customType2, "first field"));
-    d2.add(new Field("f3", TextField.TYPE_STORED, "third field"));
-    d2.add(new Field("f4", TextField.TYPE_STORED, "fourth field"));
+    d2.add(new Field("f2", "second field", TextField.TYPE_STORED));
+    d2.add(new Field("f1", "first field", customType2));
+    d2.add(new Field("f3", "third field", TextField.TYPE_STORED));
+    d2.add(new Field("f4", "fourth field", TextField.TYPE_STORED));
     writer.addDocument(d2);
 
     writer.close();
@@ -168,8 +168,8 @@
             TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(
             NoMergePolicy.NO_COMPOUND_FILES));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d1 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d1 second field"));
+        d.add(new Field("f1", "d1 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d1 second field", TextField.TYPE_STORED));
         writer.addDocument(d);
         writer.close();
         SegmentInfos sis = new SegmentInfos();
@@ -188,7 +188,7 @@
             random.nextBoolean() ? NoMergePolicy.NO_COMPOUND_FILES
                 : NoMergePolicy.COMPOUND_FILES));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d2 first field"));
+        d.add(new Field("f1", "d2 first field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3 }));
         writer.addDocument(d);
         writer.close();
@@ -212,8 +212,8 @@
             random.nextBoolean() ? NoMergePolicy.NO_COMPOUND_FILES
                 : NoMergePolicy.COMPOUND_FILES));
         Document d = new Document();
-        d.add(new Field("f1", TextField.TYPE_STORED, "d3 first field"));
-        d.add(new Field("f2", TextField.TYPE_STORED, "d3 second field"));
+        d.add(new Field("f1", "d3 first field", TextField.TYPE_STORED));
+        d.add(new Field("f2", "d3 second field", TextField.TYPE_STORED));
         d.add(new BinaryField("f3", new byte[] { 1, 2, 3, 4, 5 }));
         writer.addDocument(d);
         writer.close();
@@ -385,22 +385,22 @@
     customType15.setStoreTermVectorPositions(true);
     
     switch (mode) {
-      case 0: return new Field(fieldName, customType, "some text");
+      case 0: return new Field(fieldName, "some text", customType);
       case 1: return new TextField(fieldName, "some text");
-      case 2: return new Field(fieldName, customType2, "some text");
-      case 3: return new Field(fieldName, customType3, "some text");
-      case 4: return new Field(fieldName, customType4, "some text");
-      case 5: return new Field(fieldName, customType5, "some text");
-      case 6: return new Field(fieldName, customType6, "some text");
-      case 7: return new Field(fieldName, customType7, "some text");
-      case 8: return new Field(fieldName, customType8, "some text");
-      case 9: return new Field(fieldName, customType9, "some text");
-      case 10: return new Field(fieldName, customType10, "some text");
-      case 11: return new Field(fieldName, customType11, "some text");
-      case 12: return new Field(fieldName, customType12, "some text");
-      case 13: return new Field(fieldName, customType13, "some text");
-      case 14: return new Field(fieldName, customType14, "some text");
-      case 15: return new Field(fieldName, customType15, "some text");
+      case 2: return new Field(fieldName, "some text", customType2);
+      case 3: return new Field(fieldName, "some text", customType3);
+      case 4: return new Field(fieldName, "some text", customType4);
+      case 5: return new Field(fieldName, "some text", customType5);
+      case 6: return new Field(fieldName, "some text", customType6);
+      case 7: return new Field(fieldName, "some text", customType7);
+      case 8: return new Field(fieldName, "some text", customType8);
+      case 9: return new Field(fieldName, "some text", customType9);
+      case 10: return new Field(fieldName, "some text", customType10);
+      case 11: return new Field(fieldName, "some text", customType11);
+      case 12: return new Field(fieldName, "some text", customType12);
+      case 13: return new Field(fieldName, "some text", customType13);
+      case 14: return new Field(fieldName, "some text", customType14);
+      case 15: return new Field(fieldName, "some text", customType15);
       default: return null;
     }
   }
Index: lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
===================================================================
--- lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java	(working copy)
@@ -38,7 +38,7 @@
     FieldType ft = new FieldType();
     ft.setStored(true);
     IndexableField binaryFldStored = new BinaryField("binaryStored", binaryValStored.getBytes());
-    IndexableField stringFldStored = new Field("stringStored", ft, binaryValStored);
+    IndexableField stringFldStored = new Field("stringStored", binaryValStored, ft);
 
     Document doc = new Document();
     
Index: lucene/src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- lucene/src/test/org/apache/lucene/document/TestDocument.java	(revision 1176728)
+++ lucene/src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -42,7 +42,7 @@
     
     FieldType ft = new FieldType();
     ft.setStored(true);
-    IndexableField stringFld = new Field("string", ft, binaryVal);
+    IndexableField stringFld = new Field("string", binaryVal, ft);
     IndexableField binaryFld = new BinaryField("binary", binaryVal.getBytes());
     IndexableField binaryFld2 = new BinaryField("binary", binaryVal2.getBytes());
     
@@ -121,20 +121,20 @@
   public void testConstructorExceptions() {
     FieldType ft = new FieldType();
     ft.setStored(true);
-    new Field("name", ft, "value"); // okay
+    new Field("name", "value", ft); // okay
     new StringField("name", "value"); // okay
     try {
-      new Field("name", new FieldType(), "value");
+      new Field("name", "value", new FieldType());
       fail();
     } catch (IllegalArgumentException e) {
       // expected exception
     }
-    new Field("name", ft, "value"); // okay
+    new Field("name", "value", ft); // okay
     try {
       FieldType ft2 = new FieldType();
       ft2.setStored(true);
       ft2.setStoreTermVectors(true);
-      new Field("name", ft2, "value");
+      new Field("name", "value", ft2);
       fail();
     } catch (IllegalArgumentException e) {
       // expected exception
@@ -195,12 +195,12 @@
     Document doc = new Document();
     FieldType stored = new FieldType();
     stored.setStored(true);
-    doc.add(new Field("keyword", StringField.TYPE_STORED, "test1"));
-    doc.add(new Field("keyword", StringField.TYPE_STORED, "test2"));
-    doc.add(new Field("text", TextField.TYPE_STORED, "test1"));
-    doc.add(new Field("text", TextField.TYPE_STORED, "test2"));
-    doc.add(new Field("unindexed", stored, "test1"));
-    doc.add(new Field("unindexed", stored, "test2"));
+    doc.add(new Field("keyword", "test1", StringField.TYPE_STORED));
+    doc.add(new Field("keyword", "test2", StringField.TYPE_STORED));
+    doc.add(new Field("text", "test1", TextField.TYPE_STORED));
+    doc.add(new Field("text", "test2", TextField.TYPE_STORED));
+    doc.add(new Field("unindexed", "test1", stored));
+    doc.add(new Field("unindexed", "test2", stored));
     doc
         .add(new TextField("unstored", "test1"));
     doc
@@ -239,10 +239,10 @@
   
   public void testFieldSetValue() throws Exception {
     
-    Field field = new Field("id", StringField.TYPE_STORED, "id1");
+    Field field = new Field("id", "id1", StringField.TYPE_STORED);
     Document doc = new Document();
     doc.add(field);
-    doc.add(new Field("keyword", StringField.TYPE_STORED, "test"));
+    doc.add(new Field("keyword", "test", StringField.TYPE_STORED));
     
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
@@ -278,7 +278,7 @@
   
   public void testFieldSetValueChangeBinary() {
     Field field1 = new BinaryField("field1", new byte[0]);
-    Field field2 = new Field("field2", TextField.TYPE_STORED, "");
+    Field field2 = new Field("field2", "", TextField.TYPE_STORED);
     try {
       field1.setValue("abc");
       fail("did not hit expected exception");
Index: lucene/src/java/org/apache/lucene/index/PersistentSnapshotDeletionPolicy.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/PersistentSnapshotDeletionPolicy.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/index/PersistentSnapshotDeletionPolicy.java	(working copy)
@@ -188,12 +188,12 @@
     Document d = new Document();
     FieldType ft = new FieldType();
     ft.setStored(true);
-    d.add(new Field(SNAPSHOTS_ID, ft, ""));
+    d.add(new Field(SNAPSHOTS_ID, "", ft));
     for (Entry<String, String> e : super.getSnapshots().entrySet()) {
-      d.add(new Field(e.getKey(), ft, e.getValue()));
+      d.add(new Field(e.getKey(), e.getValue(), ft));
     }
     if (id != null) {
-      d.add(new Field(id, ft, segment));
+      d.add(new Field(id, segment, ft));
     }
     writer.addDocument(d);
     writer.commit();
Index: lucene/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java
===================================================================
--- lucene/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/document/DocumentStoredFieldVisitor.java	(working copy)
@@ -82,8 +82,8 @@
       ft.setOmitNorms(fieldInfo.omitNorms);
       ft.setIndexOptions(fieldInfo.indexOptions);
       doc.add(new Field(fieldInfo.name,
-                        ft,
-                        new String(b, "UTF-8")));
+          new String(b, "UTF-8"), ft
+      ));
     } else {
       in.seek(in.getFilePointer() + numUTF8Bytes);
     }
Index: lucene/src/java/org/apache/lucene/document/Field.java
===================================================================
--- lucene/src/java/org/apache/lucene/document/Field.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/document/Field.java	(working copy)
@@ -60,7 +60,7 @@
     this.type = type;
   }
   
-  public Field(String name, IndexableFieldType type, Reader reader) {
+  public Field(String name, Reader reader, IndexableFieldType type) {
     if (name == null) {
       throw new NullPointerException("name cannot be null");
     }
@@ -76,7 +76,7 @@
     this.type = type;
   }
   
-  public Field(String name, IndexableFieldType type, TokenStream tokenStream) {
+  public Field(String name, TokenStream tokenStream, IndexableFieldType type) {
     if (name == null) {
       throw new NullPointerException("name cannot be null");
     }
@@ -93,15 +93,15 @@
     this.type = type;
   }
   
-  public Field(String name, IndexableFieldType type, byte[] value) {
-    this(name, type, value, 0, value.length);
+  public Field(String name, byte[] value, IndexableFieldType type) {
+    this(name, value, 0, value.length, type);
   }
 
-  public Field(String name, IndexableFieldType type, byte[] value, int offset, int length) {
-    this(name, type, new BytesRef(value, offset, length));
+  public Field(String name, byte[] value, int offset, int length, IndexableFieldType type) {
+    this(name, new BytesRef(value, offset, length), type);
   }
 
-  public Field(String name, IndexableFieldType type, BytesRef bytes) {
+  public Field(String name, BytesRef bytes, IndexableFieldType type) {
     if (type.indexed() && !type.tokenized()) {
       throw new IllegalArgumentException("Non-tokenized fields must use String values");
     }
@@ -111,7 +111,7 @@
     this.name = name;
   }
   
-  public Field(String name, IndexableFieldType type, String value) {
+  public Field(String name, String value, IndexableFieldType type) {
     if (name == null) {
       throw new IllegalArgumentException("name cannot be null");
     }
Index: lucene/src/java/org/apache/lucene/document/BinaryField.java
===================================================================
--- lucene/src/java/org/apache/lucene/document/BinaryField.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/document/BinaryField.java	(working copy)
@@ -31,16 +31,16 @@
 
   /** Creates a new BinaryField */
   public BinaryField(String name, byte[] value) {
-    super(name, BinaryField.TYPE_STORED, value);
+    super(name, value, BinaryField.TYPE_STORED);
   }
   
   /** Creates a new BinaryField */
   public BinaryField(String name, byte[] value, int offset, int length) {
-    super(name, BinaryField.TYPE_STORED, value, offset, length);
+    super(name, value, offset, length, BinaryField.TYPE_STORED);
   }
 
   /** Creates a new BinaryField */
   public BinaryField(String name, BytesRef bytes) {
-    super(name, BinaryField.TYPE_STORED, bytes);
+    super(name, bytes, BinaryField.TYPE_STORED);
   }
 }
Index: lucene/src/java/org/apache/lucene/document/TextField.java
===================================================================
--- lucene/src/java/org/apache/lucene/document/TextField.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/document/TextField.java	(working copy)
@@ -50,16 +50,16 @@
 
   /** Creates a new un-stored TextField */
   public TextField(String name, Reader reader) {
-    super(name, TextField.TYPE_UNSTORED, reader);
+    super(name, reader, TextField.TYPE_UNSTORED);
   }
 
   /** Creates a new un-stored TextField */
   public TextField(String name, String value) {
-    super(name, TextField.TYPE_UNSTORED, value);
+    super(name, value, TextField.TYPE_UNSTORED);
   }
   
   /** Creates a new un-stored TextField */
   public TextField(String name, TokenStream stream) {
-    super(name, TextField.TYPE_UNSTORED, stream);
+    super(name, stream, TextField.TYPE_UNSTORED);
   }
 }
Index: lucene/src/java/org/apache/lucene/document/StringField.java
===================================================================
--- lucene/src/java/org/apache/lucene/document/StringField.java	(revision 1176728)
+++ lucene/src/java/org/apache/lucene/document/StringField.java	(working copy)
@@ -54,7 +54,7 @@
   
   /** Creates a new un-stored StringField */
   public StringField(String name, String value) {
-    super(name, TYPE_UNSTORED, value);
+    super(name, value, TYPE_UNSTORED);
   }
   
   @Override
Index: lucene/src/test-framework/org/apache/lucene/analysis/CollationTestBase.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/analysis/CollationTestBase.java	(revision 1176728)
+++ lucene/src/test-framework/org/apache/lucene/analysis/CollationTestBase.java	(working copy)
@@ -81,8 +81,8 @@
     IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "\u0633\u0627\u0628"));
-    doc.add(new Field("body", StringField.TYPE_STORED, "body"));
+    doc.add(new Field("content", "\u0633\u0627\u0628", TextField.TYPE_STORED));
+    doc.add(new Field("body", "body", StringField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
     IndexSearcher searcher = new IndexSearcher(ramDir, true);
@@ -116,7 +116,7 @@
     // orders the U+0698 character before the U+0633 character, so the single
     // index Term below should NOT be returned by a TermRangeQuery with a Farsi
     // Collator (or an Arabic one for the case when Farsi is not supported).
-    doc.add(new Field("content", TextField.TYPE_STORED, "\u0633\u0627\u0628"));
+    doc.add(new Field("content", "\u0633\u0627\u0628", TextField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
     IndexSearcher searcher = new IndexSearcher(ramDir, true);
@@ -138,8 +138,8 @@
     IndexWriter writer = new IndexWriter(farsiIndex, new IndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
-    doc.add(new Field("content", TextField.TYPE_STORED, "\u0633\u0627\u0628"));
-    doc.add(new Field("body", StringField.TYPE_STORED, "body"));
+    doc.add(new Field("content", "\u0633\u0627\u0628", TextField.TYPE_STORED));
+    doc.add(new Field("body", "body", StringField.TYPE_STORED));
     writer.addDocument(doc);
     writer.close();
 
@@ -204,7 +204,7 @@
     
     for (int i = 0 ; i < sortData.length ; ++i) {
       Document doc = new Document();
-      doc.add(new Field("tracer", customType, sortData[i][0]));
+      doc.add(new Field("tracer", sortData[i][0], customType));
       doc.add(new TextField("contents", sortData[i][1]));
       if (sortData[i][2] != null) 
         doc.add(new TextField("US", usAnalyzer.tokenStream("US", new StringReader(sortData[i][2]))));
Index: lucene/src/test-framework/org/apache/lucene/index/DocHelper.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/index/DocHelper.java	(revision 1176728)
+++ lucene/src/test-framework/org/apache/lucene/index/DocHelper.java	(working copy)
@@ -46,7 +46,7 @@
   public static Field textField1;
   static {
     customType = new FieldType(TextField.TYPE_STORED);
-    textField1 = new Field(TEXT_FIELD_1_KEY, customType, FIELD_1_TEXT);
+    textField1 = new Field(TEXT_FIELD_1_KEY, FIELD_1_TEXT, customType);
   }
 
   public static final FieldType customType2;
@@ -60,7 +60,7 @@
     customType2.setStoreTermVectors(true);
     customType2.setStoreTermVectorPositions(true);
     customType2.setStoreTermVectorOffsets(true);
-    textField2 = new Field(TEXT_FIELD_2_KEY, customType2, FIELD_2_TEXT);
+    textField2 = new Field(TEXT_FIELD_2_KEY, FIELD_2_TEXT, customType2);
   }
   
   public static final FieldType customType3;
@@ -71,14 +71,14 @@
   static {
     customType3 = new FieldType(TextField.TYPE_STORED);
     customType3.setOmitNorms(true);
-    textField3 = new Field(TEXT_FIELD_3_KEY, customType3, FIELD_3_TEXT);
+    textField3 = new Field(TEXT_FIELD_3_KEY, FIELD_3_TEXT, customType3);
   }
 
   public static final String KEYWORD_TEXT = "Keyword";
   public static final String KEYWORD_FIELD_KEY = "keyField";
   public static Field keyField;
   static {
-    keyField = new Field(KEYWORD_FIELD_KEY, StringField.TYPE_STORED,  KEYWORD_TEXT);
+    keyField = new Field(KEYWORD_FIELD_KEY, KEYWORD_TEXT, StringField.TYPE_STORED);
   }
 
   public static final FieldType customType5;
@@ -89,7 +89,7 @@
     customType5 = new FieldType(TextField.TYPE_STORED);
     customType5.setOmitNorms(true);
     customType5.setTokenized(false);
-    noNormsField = new Field(NO_NORMS_KEY, customType5, NO_NORMS_TEXT);
+    noNormsField = new Field(NO_NORMS_KEY, NO_NORMS_TEXT, customType5);
   }
 
   public static final FieldType customType6;
@@ -99,7 +99,7 @@
   static {
     customType6 = new FieldType(TextField.TYPE_STORED);
     customType6.setIndexOptions(IndexOptions.DOCS_ONLY);
-    noTFField = new Field(NO_TF_KEY, customType6, NO_TF_TEXT);
+    noTFField = new Field(NO_TF_KEY, NO_TF_TEXT, customType6);
   }
 
   public static final FieldType customType7;
@@ -109,13 +109,13 @@
   static {
     customType7 = new FieldType();
     customType7.setStored(true);
-    unIndField = new Field(UNINDEXED_FIELD_KEY, customType7, UNINDEXED_FIELD_TEXT);
+    unIndField = new Field(UNINDEXED_FIELD_KEY, UNINDEXED_FIELD_TEXT, customType7);
   }
 
 
   public static final String UNSTORED_1_FIELD_TEXT = "unstored field text";
   public static final String UNSTORED_FIELD_1_KEY = "unStoredField1";
-  public static Field unStoredField1 = new Field(UNSTORED_FIELD_1_KEY, TextField.TYPE_UNSTORED, UNSTORED_1_FIELD_TEXT);
+  public static Field unStoredField1 = new Field(UNSTORED_FIELD_1_KEY, UNSTORED_1_FIELD_TEXT, TextField.TYPE_UNSTORED);
 
   public static final FieldType customType8;
   public static final String UNSTORED_2_FIELD_TEXT = "unstored field text";
@@ -124,7 +124,7 @@
   static {
     customType8 = new FieldType(TextField.TYPE_UNSTORED);
     customType8.setStoreTermVectors(true);
-    unStoredField2 = new Field(UNSTORED_FIELD_2_KEY, customType8, UNSTORED_2_FIELD_TEXT);
+    unStoredField2 = new Field(UNSTORED_FIELD_2_KEY, UNSTORED_2_FIELD_TEXT, customType8);
   }
 
   public static final String LAZY_FIELD_BINARY_KEY = "lazyFieldBinary";
@@ -133,7 +133,7 @@
 
   public static final String LAZY_FIELD_KEY = "lazyField";
   public static final String LAZY_FIELD_TEXT = "These are some field bytes";
-  public static Field lazyField = new Field(LAZY_FIELD_KEY, customType, LAZY_FIELD_TEXT);
+  public static Field lazyField = new Field(LAZY_FIELD_KEY, LAZY_FIELD_TEXT, customType);
   
   public static final String LARGE_LAZY_FIELD_KEY = "largeLazyField";
   public static String LARGE_LAZY_FIELD_TEXT;
@@ -142,13 +142,13 @@
   //From Issue 509
   public static final String FIELD_UTF1_TEXT = "field one \u4e00text";
   public static final String TEXT_FIELD_UTF1_KEY = "textField1Utf8";
-  public static Field textUtfField1 = new Field(TEXT_FIELD_UTF1_KEY, customType, FIELD_UTF1_TEXT);
+  public static Field textUtfField1 = new Field(TEXT_FIELD_UTF1_KEY, FIELD_UTF1_TEXT, customType);
 
   public static final String FIELD_UTF2_TEXT = "field field field \u4e00two text";
   //Fields will be lexicographically sorted.  So, the order is: field, text, two
   public static final int [] FIELD_UTF2_FREQS = {3, 1, 1};
   public static final String TEXT_FIELD_UTF2_KEY = "textField2Utf8";
-  public static Field textUtfField2 = new Field(TEXT_FIELD_UTF2_KEY, customType2, FIELD_UTF2_TEXT);
+  public static Field textUtfField2 = new Field(TEXT_FIELD_UTF2_KEY, FIELD_UTF2_TEXT, customType2);
  
   
   
@@ -200,7 +200,7 @@
     lazyFieldBinary = new BinaryField(LAZY_FIELD_BINARY_KEY, LAZY_FIELD_BINARY_BYTES);
     fields[fields.length - 2] = lazyFieldBinary;
     LARGE_LAZY_FIELD_TEXT = buffer.toString();
-    largeLazyField = new Field(LARGE_LAZY_FIELD_KEY, customType, LARGE_LAZY_FIELD_TEXT);
+    largeLazyField = new Field(LARGE_LAZY_FIELD_KEY, LARGE_LAZY_FIELD_TEXT, customType);
     fields[fields.length - 1] = largeLazyField;
     for (int i=0; i<fields.length; i++) {
       IndexableField f = fields[i];
@@ -304,15 +304,15 @@
     customType1.setStoreTermVectorOffsets(true);
 
     final Document doc = new Document();
-    doc.add(new Field("id", customType1, Integer.toString(n)));
-    doc.add(new Field("indexname", customType1, indexName));
+    doc.add(new Field("id", Integer.toString(n), customType1));
+    doc.add(new Field("indexname", indexName, customType1));
     sb.append("a");
     sb.append(n);
-    doc.add(new Field("field1", customType, sb.toString()));
+    doc.add(new Field("field1", sb.toString(), customType));
     sb.append(" b");
     sb.append(n);
     for (int i = 1; i < numFields; i++) {
-      doc.add(new Field("field" + (i + 1), customType, sb.toString()));
+      doc.add(new Field("field" + (i + 1), sb.toString(), customType));
     }
     return doc;
   }
Index: lucene/src/test-framework/org/apache/lucene/util/LineFileDocs.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/util/LineFileDocs.java	(revision 1176728)
+++ lucene/src/test-framework/org/apache/lucene/util/LineFileDocs.java	(working copy)
@@ -128,16 +128,16 @@
       ft.setStoreTermVectorOffsets(true);
       ft.setStoreTermVectorPositions(true);
       
-      titleTokenized = new Field("titleTokenized", ft, "");
+      titleTokenized = new Field("titleTokenized", "", ft);
       doc.add(titleTokenized);
 
-      body = new Field("body", ft, "");
+      body = new Field("body", "", ft);
       doc.add(body);
 
-      id = new Field("docid", StringField.TYPE_STORED, "");
+      id = new Field("docid", "", StringField.TYPE_STORED);
       doc.add(id);
 
-      date = new Field("date", StringField.TYPE_STORED, "");
+      date = new Field("date", "", StringField.TYPE_STORED);
       doc.add(date);
     }
   }
Index: lucene/src/test-framework/org/apache/lucene/util/LuceneTestCase.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/util/LuceneTestCase.java	(revision 1176728)
+++ lucene/src/test-framework/org/apache/lucene/util/LuceneTestCase.java	(working copy)
@@ -1159,7 +1159,7 @@
   public static Field newField(Random random, String name, String value, FieldType type) {
     if (usually(random) || !type.indexed()) {
       // most of the time, don't modify the params
-      return new Field(name, type, value);
+      return new Field(name, value, type);
     }
 
     FieldType newType = new FieldType(type);
@@ -1186,7 +1186,7 @@
     }
     */
     
-    return new Field(name, newType, value);
+    return new Field(name, value, newType);
   }
   
   /** return a random Locale from the available locales on the system */
Index: lucene/src/test-framework/org/apache/lucene/util/_TestUtil.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/util/_TestUtil.java	(revision 1176728)
+++ lucene/src/test-framework/org/apache/lucene/util/_TestUtil.java	(working copy)
@@ -513,10 +513,7 @@
     for(IndexableField f : doc1) {
       Field field1 = (Field) f;
       
-      Field field2 = new Field(field1.name(),
-                               field1.fieldType(),
-                               field1.stringValue()
-                               );
+      Field field2 = new Field(field1.name(), field1.stringValue(), field1.fieldType());
       doc2.add(field2);
     }
 
