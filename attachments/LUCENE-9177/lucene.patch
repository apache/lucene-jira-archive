diff --git a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter.java b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter.java
index c090d07bb8c..9ebba6b1b20 100644
--- a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter.java
+++ b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter.java
@@ -26,6 +26,7 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.ngram.NGramTokenizer;
@@ -72,6 +73,51 @@ public class TestICUNormalizer2CharFilter extends BaseTokenStreamTestCase {
       input.length());
   }
 
+  public void testVerySlow() throws IOException {
+    StringBuilder builder = new StringBuilder();
+    for (int i = 0; i < 100000; i++) {
+      builder.append("℃aa");
+    }
+    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(builder.toString()),
+        Normalizer2.getInstance(null, "nfkc_cf", Normalizer2.Mode.COMPOSE));
+    char[] tempBuff = new char[1024];
+    int total = 0;
+    long start = System.currentTimeMillis();
+    while (true) {
+      int length = reader.read(tempBuff);
+      if (length == -1) {
+        break;
+      }
+      total += length;
+    }
+    long elapsed = System.currentTimeMillis() - start;
+    System.out.println("normalized " + total + " chars in " + elapsed + "ms");
+
+
+    Analyzer a = new Analyzer() {
+      @Override
+      public TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+        return new TokenStreamComponents(tokenizer, new ICUNormalizer2Filter(
+            tokenizer,
+            /* specify nfc with decompose to get nfd */
+            Normalizer2.getInstance(null, "nfc", Normalizer2.Mode.DECOMPOSE)));
+      }
+    };
+    start = System.currentTimeMillis();
+    int numTokens = 0;
+    try (TokenStream tokenStream = a.tokenStream("", builder.toString())) {
+      tokenStream.reset();
+      while (tokenStream.incrementToken()) {
+        numTokens ++;
+      }
+      tokenStream.end();
+    }
+    a.close();
+    elapsed = System.currentTimeMillis() - start;
+    System.out.println("normalized " + total + " chars in " + elapsed + "ms");
+  }
+
   public void testTokenStream2() throws IOException {
     // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'
     String input = "㌰゙5℃№㈱㌘ｻﾞｿﾞ";
