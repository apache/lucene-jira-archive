Index: CHANGES.txt
===================================================================
--- CHANGES.txt	(revision 927086)
+++ CHANGES.txt	(working copy)
@@ -17,6 +17,10 @@
 
 * LUCENE-2222: FixedIntBlockIndexInput incorrectly read one block of
   0s before the actual data.  (Renaud Delbru via Mike McCandless)
+
+* LUCENE-2344: PostingsConsumer.merge was failing to call finishDoc,
+  which caused corruption for sep codec.  Also fixed several tests to
+  test all 4 core codecs.  (Renaud Delbru via Mike McCandless)
   
 New features
 
Index: src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 927086)
+++ src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -37,7 +37,7 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockRAMDirectory;
 
-public class TestStressIndexing2 extends LuceneTestCase {
+public class TestStressIndexing2 extends MultiCodecTestCase {
   static int maxFields=4;
   static int bigFieldSize=10;
   static boolean sameFieldOrder=false;
Index: src/test/org/apache/lucene/index/TestCodecs.java
===================================================================
--- src/test/org/apache/lucene/index/TestCodecs.java	(revision 927086)
+++ src/test/org/apache/lucene/index/TestCodecs.java	(working copy)
@@ -17,12 +17,34 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.util.*;
-import org.apache.lucene.index.codecs.*;
-import org.apache.lucene.index.codecs.standard.*;
-import org.apache.lucene.store.*;
-import java.util.*;
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Random;
 
+import org.apache.lucene.analysis.WhitespaceAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.index.codecs.Codec;
+import org.apache.lucene.index.codecs.CodecProvider;
+import org.apache.lucene.index.codecs.FieldsConsumer;
+import org.apache.lucene.index.codecs.FieldsProducer;
+import org.apache.lucene.index.codecs.PostingsConsumer;
+import org.apache.lucene.index.codecs.TermsConsumer;
+import org.apache.lucene.index.codecs.sep.SepCodec;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.MockRAMDirectory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.MultiCodecTestCase;
+import org.apache.lucene.util.Version;
+
 // TODO: test multiple codecs here?
 
 // TODO
@@ -41,7 +63,7 @@
 //   - skipTo(term)
 //   - skipTo(doc)
 
-public class TestCodecs extends LuceneTestCase {
+public class TestCodecs extends MultiCodecTestCase {
 
   private Random RANDOM;
   private static String[] fieldNames = new String[] {"one", "two", "three", "four"};
@@ -54,20 +76,20 @@
   private final static int TERM_DOC_FREQ_RAND = 20;
 
   // start is inclusive and end is exclusive
-  public int nextInt(int start, int end) {
+  public int nextInt(final int start, final int end) {
     return start + RANDOM.nextInt(end-start);
   }
 
-  private int nextInt(int lim) {
+  private int nextInt(final int lim) {
     return RANDOM.nextInt(lim);
   }
 
   char[] getRandomText() {
 
-    final int len = 1+nextInt(10);
-    char[] buffer = new char[len+1];
+    final int len = 1+this.nextInt(10);
+    final char[] buffer = new char[len+1];
     for(int i=0;i<len;i++) {
-      buffer[i] = (char) nextInt(97, 123);
+      buffer[i] = (char) this.nextInt(97, 123);
       /*
       final int t = nextInt(5);
       if (0 == t && i < len-1) {
@@ -96,7 +118,7 @@
     final boolean omitTF;
     final boolean storePayloads;
 
-    public FieldData(String name, FieldInfos fieldInfos, TermData[] terms, boolean omitTF, boolean storePayloads) {
+    public FieldData(final String name, final FieldInfos fieldInfos, final TermData[] terms, final boolean omitTF, final boolean storePayloads) {
       this.omitTF = omitTF;
       this.storePayloads = storePayloads;
       fieldInfos.add(name, true);
@@ -106,21 +128,21 @@
       this.terms = terms;
       for(int i=0;i<terms.length;i++)
         terms[i].field = this;
-      
+
       Arrays.sort(terms);
     }
 
-    public int compareTo(Object other) {
+    public int compareTo(final Object other) {
       return fieldInfo.name.compareTo(((FieldData) other).fieldInfo.name);
     }
 
-    public void write(FieldsConsumer consumer) throws Throwable {
+    public void write(final FieldsConsumer consumer) throws Throwable {
       if (Codec.DEBUG)
         System.out.println("WRITE field=" + fieldInfo.name);
       Arrays.sort(terms);
       final TermsConsumer termsConsumer = consumer.addField(fieldInfo);
-      for(int i=0;i<terms.length;i++)
-        terms[i].write(termsConsumer);
+      for (final TermData term : terms)
+        term.write(termsConsumer);
       termsConsumer.finish();
     }
   }
@@ -129,7 +151,7 @@
     int pos;
     BytesRef payload;
 
-    PositionData(int pos, BytesRef payload) {
+    PositionData(final int pos, final BytesRef payload) {
       this.pos = pos;
       this.payload = payload;
     }
@@ -141,19 +163,19 @@
     int[] docs;
     PositionData[][] positions;
     FieldData field;
-    
-    public TermData(String text, int[] docs, PositionData[][] positions) {
+
+    public TermData(final String text, final int[] docs, final PositionData[][] positions) {
       this.text = new BytesRef(text);
       this.text2 = text;
       this.docs = docs;
       this.positions = positions;
     }
 
-    public int compareTo(Object o) {
+    public int compareTo(final Object o) {
       return text2.compareTo(((TermData) o).text2);
-    }    
+    }
 
-    public void write(TermsConsumer termsConsumer) throws Throwable {
+    public void write(final TermsConsumer termsConsumer) throws Throwable {
       if (Codec.DEBUG)
         System.out.println("  term=" + text2);
       final PostingsConsumer postingsConsumer = termsConsumer.startTerm(text);
@@ -167,7 +189,7 @@
         postingsConsumer.startDoc(docs[i], termDocFreq);
         if (!field.omitTF) {
           for(int j=0;j<positions[i].length;j++) {
-            PositionData pos = positions[i][j];
+            final PositionData pos = positions[i][j];
             postingsConsumer.addPosition(pos.pos, pos.payload);
           }
           postingsConsumer.finishDoc();
@@ -179,10 +201,10 @@
 
   final private static String SEGMENT = "0";
 
-  TermData[] makeRandomTerms(boolean omitTF, boolean storePayloads) {
-    final int numTerms = 1+nextInt(NUM_TERMS_RAND);
+  TermData[] makeRandomTerms(final boolean omitTF, final boolean storePayloads) {
+    final int numTerms = 1+this.nextInt(NUM_TERMS_RAND);
     //final int numTerms = 2;
-    TermData[] terms = new TermData[numTerms];
+    final TermData[] terms = new TermData[numTerms];
 
     final HashSet<String> termsSeen = new HashSet<String>();
 
@@ -192,16 +214,16 @@
       char[] text;
       String text2;
       while(true) {
-        text = getRandomText();
+        text = this.getRandomText();
         text2 = new String(text, 0, text.length-1);
         if (!termsSeen.contains(text2)) {
           termsSeen.add(text2);
           break;
         }
       }
-      
-      final int docFreq = 1+nextInt(DOC_FREQ_RAND);
-      int[] docs = new int[docFreq];
+
+      final int docFreq = 1+this.nextInt(DOC_FREQ_RAND);
+      final int[] docs = new int[docFreq];
       PositionData[][] positions;
 
       if (!omitTF)
@@ -211,21 +233,21 @@
 
       int docID = 0;
       for(int j=0;j<docFreq;j++) {
-        docID += nextInt(1, 10);
+        docID += this.nextInt(1, 10);
         docs[j] = docID;
 
         if (!omitTF) {
-          final int termFreq = 1+nextInt(TERM_DOC_FREQ_RAND);
+          final int termFreq = 1+this.nextInt(TERM_DOC_FREQ_RAND);
           positions[j] = new PositionData[termFreq];
           int position = 0;
           for(int k=0;k<termFreq;k++) {
-            position += nextInt(1, 10);
+            position += this.nextInt(1, 10);
 
             final BytesRef payload;
-            if (storePayloads && nextInt(4) == 0) {
-              byte[] bytes = new byte[1+nextInt(5)];
+            if (storePayloads && this.nextInt(4) == 0) {
+              final byte[] bytes = new byte[1+this.nextInt(5)];
               for(int l=0;l<bytes.length;l++) {
-                bytes[l] = (byte) nextInt(255);
+                bytes[l] = (byte) this.nextInt(255);
               }
               payload = new BytesRef(bytes);
             } else {
@@ -245,33 +267,33 @@
 
   public void testFixedPostings() throws Throwable {
 
-    RANDOM = newRandom();
+    RANDOM = this.newRandom();
 
     final int NUM_TERMS = 100;
-    TermData[] terms = new TermData[NUM_TERMS];
+    final TermData[] terms = new TermData[NUM_TERMS];
     for(int i=0;i<NUM_TERMS;i++) {
-      int[] docs = new int[] {1};
-      String text = Integer.toString(i, Character.MAX_RADIX);
+      final int[] docs = new int[] {1};
+      final String text = Integer.toString(i, Character.MAX_RADIX);
       terms[i] = new TermData(text, docs, null);
     }
 
     final FieldInfos fieldInfos = new FieldInfos();
-    
-    FieldData field = new FieldData("field", fieldInfos, terms, true, false);
-    FieldData[] fields = new FieldData[] {field};
 
-    Directory dir = new MockRAMDirectory();
-    write(fieldInfos, dir, fields);
-    SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));
+    final FieldData field = new FieldData("field", fieldInfos, terms, true, false);
+    final FieldData[] fields = new FieldData[] {field};
+
+    final Directory dir = new MockRAMDirectory();
+    this.write(fieldInfos, dir, fields);
+    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));
     si.setHasProx(false);
 
-    FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));
-    
-    FieldsEnum fieldsEnum = reader.iterator();
+    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));
+
+    final FieldsEnum fieldsEnum = reader.iterator();
     assertNotNull(fieldsEnum.next());
-    TermsEnum termsEnum = fieldsEnum.terms();
+    final TermsEnum termsEnum = fieldsEnum.terms();
     for(int i=0;i<NUM_TERMS;i++) {
-      BytesRef term = termsEnum.next();
+      final BytesRef term = termsEnum.next();
       assertNotNull(term);
       assertEquals(terms[i].text2, term.utf8ToString());
     }
@@ -286,35 +308,35 @@
 
   public void testRandomPostings() throws Throwable {
 
-    RANDOM = newRandom();
+    RANDOM = this.newRandom();
 
     final FieldInfos fieldInfos = new FieldInfos();
-    
-    FieldData[] fields = new FieldData[NUM_FIELDS];
+
+    final FieldData[] fields = new FieldData[NUM_FIELDS];
     for(int i=0;i<NUM_FIELDS;i++) {
-      boolean omitTF = 0==(i%3);
-      boolean storePayloads = 1==(i%3);
-      fields[i] = new FieldData(fieldNames[i], fieldInfos, makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);
+      final boolean omitTF = 0==(i%3);
+      final boolean storePayloads = 1==(i%3);
+      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);
     }
 
-    Directory dir = new MockRAMDirectory();
+    final Directory dir = new MockRAMDirectory();
 
-    write(fieldInfos, dir, fields);
-    SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));
+    this.write(fieldInfos, dir, fields);
+    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));
 
     if (Codec.DEBUG) {
       System.out.println("\nTEST: now read");
     }
 
-    FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));
+    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));
 
-    Verify[] threads = new Verify[NUM_TEST_THREADS-1];
+    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];
     for(int i=0;i<NUM_TEST_THREADS-1;i++) {
       threads[i] = new Verify(fields, terms);
       threads[i].setDaemon(true);
       threads[i].start();
     }
-    
+
     new Verify(fields, terms).run();
 
     for(int i=0;i<NUM_TEST_THREADS-1;i++) {
@@ -326,57 +348,128 @@
     dir.close();
   }
 
-  private String getDesc(FieldData field, TermData term) {
+  public void testSepPositionAfterMerge() throws IOException {
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_31,
+      new WhitespaceAnalyzer(Version.LUCENE_31));
+    config.setCodecProvider(new SepCodecs());
+    final IndexWriter writer = new IndexWriter(dir, config);
+
+    try {
+      final PhraseQuery pq = new PhraseQuery();
+      pq.add(new Term("content", "bbb"));
+      pq.add(new Term("content", "ccc"));
+
+      final Document doc = new Document();
+      doc.add(new Field("content", "aaa bbb ccc ddd", Store.NO, Field.Index.ANALYZED_NO_NORMS));
+
+      // add document and force commit for creating a first segment
+      writer.addDocument(doc);
+      writer.commit();
+
+      ScoreDoc[] results = this.search(writer, pq, 5);
+      assertEquals(1, results.length);
+      assertEquals(0, results[0].doc);
+
+      // add document and force commit for creating a second segment
+      writer.addDocument(doc);
+      writer.commit();
+
+      // at this point, there should be at least two segments
+      results = this.search(writer, pq, 5);
+      assertEquals(2, results.length);
+      assertEquals(0, results[0].doc);
+
+      writer.optimize();
+
+      // optimise to merge the segments.
+      results = this.search(writer, pq, 5);
+      assertEquals(2, results.length);
+      assertEquals(0, results[0].doc);
+    }
+    finally {
+      writer.close();
+      dir.close();
+    }
+  }
+
+  private ScoreDoc[] search(final IndexWriter writer, final Query q, final int n) throws IOException {
+    final IndexReader reader = writer.getReader();
+    final IndexSearcher searcher = new IndexSearcher(reader);
+    try {
+      return searcher.search(q, null, n).scoreDocs;
+    }
+    finally {
+      searcher.close();
+      reader.close();
+    }
+  }
+
+  public static class SepCodecs extends CodecProvider {
+
+    protected SepCodecs() {
+      this.register(new SepCodec());
+    }
+
+    @Override
+    public Codec getWriter(final SegmentWriteState state) {
+      return this.lookup("Sep");
+    }
+
+  }
+
+  private String getDesc(final FieldData field, final TermData term) {
     return field.fieldInfo.name + ":" + term.text2;
   }
 
-  private String getDesc(FieldData field, TermData term, int doc) {
-    return getDesc(field, term) + ":" + doc;
+  private String getDesc(final FieldData field, final TermData term, final int doc) {
+    return this.getDesc(field, term) + ":" + doc;
   }
-  
+
   private class Verify extends Thread {
     final Fields termsDict;
     final FieldData[] fields;
     volatile boolean failed;
 
-    Verify(FieldData[] fields, Fields termsDict) {
+    Verify(final FieldData[] fields, final Fields termsDict) {
       this.fields = fields;
       this.termsDict = termsDict;
     }
-    
+
+    @Override
     public void run() {
       try {
-        _run();
-      } catch (Throwable t) {
+        this._run();
+      } catch (final Throwable t) {
         failed = true;
         throw new RuntimeException(t);
       }
     }
 
-    private void verifyDocs(int[] docs, PositionData[][] positions, DocsEnum docsEnum, boolean doPos) throws Throwable {
+    private void verifyDocs(final int[] docs, final PositionData[][] positions, final DocsEnum docsEnum, final boolean doPos) throws Throwable {
       for(int i=0;i<docs.length;i++) {
-        int doc = docsEnum.nextDoc();
-        assertTrue(doc != DocsEnum.NO_MORE_DOCS);
+        final int doc = docsEnum.nextDoc();
+        assertTrue(doc != DocIdSetIterator.NO_MORE_DOCS);
         assertEquals(docs[i], doc);
         if (doPos) {
-          verifyPositions(positions[i], ((DocsAndPositionsEnum) docsEnum));
+          this.verifyPositions(positions[i], ((DocsAndPositionsEnum) docsEnum));
         }
       }
-      assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
+      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
     }
 
     byte[] data = new byte[10];
 
-    private void verifyPositions(PositionData[] positions, DocsAndPositionsEnum posEnum) throws Throwable {
+    private void verifyPositions(final PositionData[] positions, final DocsAndPositionsEnum posEnum) throws Throwable {
       for(int i=0;i<positions.length;i++) {
-        int pos = posEnum.nextPosition();
+        final int pos = posEnum.nextPosition();
         if (Codec.DEBUG) {
           System.out.println("TEST pos " + (1+i) + " of " + positions.length + " pos=" + pos);
         }
         assertEquals(positions[i].pos, pos);
         if (positions[i].payload != null) {
           assertTrue(posEnum.hasPayload());
-          if (nextInt(3) < 2) {
+          if (TestCodecs.this.nextInt(3) < 2) {
             // Verify the payload bytes
             final BytesRef otherPayload = posEnum.getPayload();
             if (Codec.DEBUG) {
@@ -396,9 +489,9 @@
     }
 
     public void _run() throws Throwable {
-      
+
       for(int iter=0;iter<NUM_TEST_ITER;iter++) {
-        final FieldData field = fields[nextInt(fields.length)];
+        final FieldData field = fields[TestCodecs.this.nextInt(fields.length)];
         if (Codec.DEBUG) {
           System.out.println("verify field=" + field.fieldInfo.name);
         }
@@ -412,7 +505,7 @@
 
         int upto = 0;
         while(true) {
-          BytesRef term = termsEnum.next();
+          final BytesRef term = termsEnum.next();
           if (term == null) {
             break;
           }
@@ -427,40 +520,40 @@
         if (Codec.DEBUG) {
           System.out.println("\nTEST: random seek");
         }
-        TermData term = field.terms[nextInt(field.terms.length)];
+        TermData term = field.terms[TestCodecs.this.nextInt(field.terms.length)];
         TermsEnum.SeekStatus status = termsEnum.seek(new BytesRef(term.text2));
         assertEquals(status, TermsEnum.SeekStatus.FOUND);
         assertEquals(term.docs.length, termsEnum.docFreq());
         if (field.omitTF) {
-          verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
+          this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
         } else {
-          verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
+          this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
         }
 
         // Test random seek by ord:
-        int idx = nextInt(field.terms.length);
+        final int idx = TestCodecs.this.nextInt(field.terms.length);
         term = field.terms[idx];
         status = termsEnum.seek(idx);
         assertEquals(status, TermsEnum.SeekStatus.FOUND);
         assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
         assertEquals(term.docs.length, termsEnum.docFreq());
         if (field.omitTF) {
-          verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
+          this.verifyDocs(term.docs, term.positions, termsEnum.docs(null, null), false);
         } else {
-          verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
+          this.verifyDocs(term.docs, term.positions, termsEnum.docsAndPositions(null, null), true);
         }
 
         // Test seek to non-existent terms:
         if (Codec.DEBUG)
           System.out.println("\nTEST: seek to non-existent term");
         for(int i=0;i<100;i++) {
-          char[] text = getRandomText();
-          String text2 = new String(text, 0, text.length-1) + ".";
+          final char[] text = TestCodecs.this.getRandomText();
+          final String text2 = new String(text, 0, text.length-1) + ".";
           status = termsEnum.seek(new BytesRef(text2));
           assertTrue(status == TermsEnum.SeekStatus.NOT_FOUND ||
                      status == TermsEnum.SeekStatus.END);
         }
-        
+
         // Seek to each term, backwards:
         if (Codec.DEBUG) {
           System.out.println("\n" + Thread.currentThread().getName() + ": TEST: seek backwards through terms");
@@ -502,12 +595,12 @@
         upto = 0;
         do {
           term = field.terms[upto];
-          if (nextInt(3) == 1) {
+          if (TestCodecs.this.nextInt(3) == 1) {
             if (Codec.DEBUG) {
-              System.out.println("\nTEST [" + getDesc(field, term) + "]: iterate docs...");
+              System.out.println("\nTEST [" + TestCodecs.this.getDesc(field, term) + "]: iterate docs...");
             }
-            DocsEnum docs = termsEnum.docs(null, null);
-            DocsAndPositionsEnum postings = termsEnum.docsAndPositions(null, null);
+            final DocsEnum docs = termsEnum.docs(null, null);
+            final DocsAndPositionsEnum postings = termsEnum.docsAndPositions(null, null);
 
             final DocsEnum docsEnum;
             if (postings != null) {
@@ -520,19 +613,19 @@
               // Maybe skip:
               final int left = term.docs.length-upto2;
               int doc;
-              if (nextInt(3) == 1 && left >= 1) {
-                int inc = 1+nextInt(left-1);
+              if (TestCodecs.this.nextInt(3) == 1 && left >= 1) {
+                final int inc = 1+TestCodecs.this.nextInt(left-1);
                 upto2 += inc;
                 if (Codec.DEBUG) {
-                  System.out.println("TEST [" + getDesc(field, term) + "]: skip: " + left + " docs left; skip to doc=" + term.docs[upto2] + " [" + upto2 + " of " + term.docs.length + "]");
+                  System.out.println("TEST [" + TestCodecs.this.getDesc(field, term) + "]: skip: " + left + " docs left; skip to doc=" + term.docs[upto2] + " [" + upto2 + " of " + term.docs.length + "]");
                 }
 
-                if (nextInt(2) == 1) {
+                if (TestCodecs.this.nextInt(2) == 1) {
                   doc = docsEnum.advance(term.docs[upto2]);
                   assertEquals(term.docs[upto2], doc);
                 } else {
                   doc = docsEnum.advance(1+term.docs[upto2]);
-                  if (doc == DocsEnum.NO_MORE_DOCS) {
+                  if (doc == DocIdSetIterator.NO_MORE_DOCS) {
                     // skipped past last doc
                     assert upto2 == term.docs.length-1;
                     break;
@@ -548,18 +641,18 @@
                 doc = docsEnum.nextDoc();
                 assertTrue(doc != -1);
                 if (Codec.DEBUG) {
-                  System.out.println("TEST [" + getDesc(field, term) + "]: got next doc...");
+                  System.out.println("TEST [" + TestCodecs.this.getDesc(field, term) + "]: got next doc...");
                 }
                 upto2++;
               }
               assertEquals(term.docs[upto2], doc);
               if (!field.omitTF) {
                 assertEquals(term.positions[upto2].length, docsEnum.freq());
-                if (nextInt(2) == 1) {
+                if (TestCodecs.this.nextInt(2) == 1) {
                   if (Codec.DEBUG) {
-                    System.out.println("TEST [" + getDesc(field, term, term.docs[upto2]) + "]: check positions for doc " + term.docs[upto2] + "...");
+                    System.out.println("TEST [" + TestCodecs.this.getDesc(field, term, term.docs[upto2]) + "]: check positions for doc " + term.docs[upto2] + "...");
                   }
-                  verifyPositions(term.positions[upto2], postings);
+                  this.verifyPositions(term.positions[upto2], postings);
                 } else if (Codec.DEBUG) {
                   System.out.println("TEST: skip positions...");
                 }
@@ -568,10 +661,10 @@
               }
             }
 
-            assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());
+            assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());
 
           } else if (Codec.DEBUG) {
-            System.out.println("\nTEST [" + getDesc(field, term) + "]: skip docs");
+            System.out.println("\nTEST [" + TestCodecs.this.getDesc(field, term) + "]: skip docs");
           }
           upto++;
 
@@ -582,17 +675,17 @@
     }
   }
 
-  private void write(FieldInfos fieldInfos, Directory dir, FieldData[] fields) throws Throwable {
+  private void write(final FieldInfos fieldInfos, final Directory dir, final FieldData[] fields) throws Throwable {
 
-    final int termIndexInterval = nextInt(13, 27);
+    final int termIndexInterval = this.nextInt(13, 27);
 
-    SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval,
+    final SegmentWriteState state = new SegmentWriteState(null, dir, SEGMENT, fieldInfos, null, 10000, 10000, termIndexInterval,
                                                     CodecProvider.getDefault());
 
     final FieldsConsumer consumer = state.codec.fieldsConsumer(state);
     Arrays.sort(fields);
-    for(int i=0;i<fields.length;i++) {
-      fields[i].write(consumer);
+    for (final FieldData field : fields) {
+      field.write(consumer);
     }
     consumer.close();
   }
Index: src/test/org/apache/lucene/index/TestStressIndexing.java
===================================================================
--- src/test/org/apache/lucene/index/TestStressIndexing.java	(revision 927086)
+++ src/test/org/apache/lucene/index/TestStressIndexing.java	(working copy)
@@ -26,7 +26,7 @@
 import java.util.Random;
 import java.io.File;
 
-public class TestStressIndexing extends LuceneTestCase {
+public class TestStressIndexing extends MultiCodecTestCase {
   private Random RANDOM;
 
   private static abstract class TimedThread extends Thread {
Index: src/test/org/apache/lucene/index/FlexTestUtil.java
===================================================================
--- src/test/org/apache/lucene/index/FlexTestUtil.java	(revision 927086)
+++ src/test/org/apache/lucene/index/FlexTestUtil.java	(working copy)
@@ -110,6 +110,9 @@
 
   private static void testBogusFieldTerms(Random rand, IndexReader r) throws Exception {
     final Fields fields = MultiFields.getFields(r);
+    if (fields == null) {
+      return;
+    }
     for(int i=0;i<10;i++) {
       final String f = "bogus" + rand.nextInt() + "reallybogus";
       Terms terms = fields.terms(f);
Index: src/test/org/apache/lucene/util/MultiCodecTestCase.java
===================================================================
--- src/test/org/apache/lucene/util/MultiCodecTestCase.java	(revision 0)
+++ src/test/org/apache/lucene/util/MultiCodecTestCase.java	(revision 0)
@@ -0,0 +1,51 @@
+package org.apache.lucene.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Locale;
+import java.util.Set;
+
+import org.apache.lucene.index.codecs.CodecProvider;
+
+/**
+ * Base test class for Lucene test classes that to test across
+ * all core codecs.
+ */
+public abstract class MultiCodecTestCase extends LuceneTestCase {
+
+  private String savedDefaultCodec;
+
+  @Override
+  public void runBare() throws Throwable {
+    final String savedDefaultCodec = CodecProvider.getDefaultCodec();
+    try {
+      for(String codec : CodecProvider.CORE_CODECS) {
+        CodecProvider.setDefaultCodec(codec);
+        try {
+          super.runBare();
+        } catch (Throwable e) {
+          System.out.println("Test failure of '" + getName()
+                             + "' occurred with \"" + codec + "\" codec");
+          throw e;
+        }
+      }
+    } finally {
+      CodecProvider.setDefaultCodec(savedDefaultCodec);
+    }
+  }
+}

Property changes on: src/test/org/apache/lucene/util/MultiCodecTestCase.java
___________________________________________________________________
Added: svn:eol-style
   + native

Index: src/java/org/apache/lucene/index/codecs/PostingsConsumer.java
===================================================================
--- src/java/org/apache/lucene/index/codecs/PostingsConsumer.java	(revision 927086)
+++ src/java/org/apache/lucene/index/codecs/PostingsConsumer.java	(working copy)
@@ -21,6 +21,7 @@
 
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.BytesRef;
 
 /**
@@ -56,28 +57,29 @@
 
   /** Default merge impl: append documents, mapping around
    *  deletes */
-  public int merge(MergeState mergeState, DocsEnum postings) throws IOException {
+  public int merge(final MergeState mergeState, final DocsEnum postings) throws IOException {
 
     int df = 0;
 
     if (mergeState.fieldInfo.omitTermFreqAndPositions) {
       while(true) {
         final int doc = postings.nextDoc();
-        if (doc == DocsAndPositionsEnum.NO_MORE_DOCS) {
+        if (doc == DocIdSetIterator.NO_MORE_DOCS) {
           break;
         }
-        startDoc(doc, postings.freq());
+        this.startDoc(doc, postings.freq());
+        this.finishDoc();
         df++;
       }
     } else {
       final DocsAndPositionsEnum postingsEnum = (DocsAndPositionsEnum) postings;
       while(true) {
         final int doc = postingsEnum.nextDoc();
-        if (doc == DocsAndPositionsEnum.NO_MORE_DOCS) {
+        if (doc == DocIdSetIterator.NO_MORE_DOCS) {
           break;
         }
         final int freq = postingsEnum.freq();
-        startDoc(doc, freq);
+        this.startDoc(doc, freq);
         for(int i=0;i<freq;i++) {
           final int position = postingsEnum.nextPosition();
           final int payloadLength = postingsEnum.getPayloadLength();
@@ -87,8 +89,9 @@
           } else {
             payload = null;
           }
-          addPosition(position, payload);
+          this.addPosition(position, payload);
         }
+        this.finishDoc();
         df++;
       }
     }
Index: src/java/org/apache/lucene/index/codecs/CodecProvider.java
===================================================================
--- src/java/org/apache/lucene/index/codecs/CodecProvider.java	(revision 927086)
+++ src/java/org/apache/lucene/index/codecs/CodecProvider.java	(working copy)
@@ -43,6 +43,10 @@
 
   private final Set<String> knownExtensions = new HashSet<String>();
 
+  private static String defaultCodec = "Standard";
+
+  public final static String[] CORE_CODECS = new String[] {"Standard", "Sep", "Pulsing", "IntBlock"};
+
   public void register(Codec codec) {
     if (codec.name == null) {
       throw new IllegalArgumentException("code.name is null");
@@ -74,6 +78,15 @@
   public static CodecProvider getDefault() {
     return defaultCodecs;
   }
+
+  /** Used for testing. @lucene.internal */
+  public static void setDefaultCodec(String s) {
+    defaultCodec = s;
+  }
+  /** Used for testing. @lucene.internal */
+  public static String getDefaultCodec() {
+    return defaultCodec;
+  }
 }
 
 class DefaultCodecProvider extends CodecProvider {
@@ -87,7 +100,7 @@
 
   @Override
   public Codec getWriter(SegmentWriteState state) {
-    return lookup("Standard");
+    return lookup(CodecProvider.getDefaultCodec());
     //return lookup("Pulsing");
     //return lookup("Sep");
     //return lookup("IntBlock");
