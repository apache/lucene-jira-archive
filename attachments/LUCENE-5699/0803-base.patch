Index: lucene/classification/src/java/org/apache/lucene/classification/ClassificationResult.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/ClassificationResult.java	(revision 1613085)
+++ lucene/classification/src/java/org/apache/lucene/classification/ClassificationResult.java	(working copy)
@@ -20,10 +20,10 @@
  * The result of a call to {@link Classifier#assignClass(String)} holding an assigned class of type <code>T</code> and a score.
  * @lucene.experimental
  */
-public class ClassificationResult<T> {
+public class ClassificationResult<T> implements Comparable<ClassificationResult<T>>{
 
   private final T assignedClass;
-  private final double score;
+  private double score;
 
   /**
    * Constructor
@@ -50,4 +50,18 @@
   public double getScore() {
     return score;
   }
+  
+  /**
+   * set the score value
+   * @param score the score for the assignedClass as a <code>double</code>
+   */
+  public void setScore(double score) {
+    this.score = score;
+  }
+
+
+  @Override
+  public int compareTo(ClassificationResult<T> o) {
+    return this.getScore() < o.getScore() ? 1 : this.getScore() > o.getScore() ? -1 : 0;
+  }
 }
Index: lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java	(revision 1613085)
+++ lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java	(working copy)
@@ -31,7 +31,10 @@
 
 import java.io.IOException;
 import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
 
 /**
@@ -79,6 +82,33 @@
    */
   @Override
   public ClassificationResult<BytesRef> assignClass(String text) throws IOException {
+    TopDocs topDocs=knnSearcher(text);
+    List<ClassificationResult<BytesRef>> doclist=buildListFromTopDocs(topDocs);
+    ClassificationResult<BytesRef> retval=null;
+    double maxscore=-Double.MAX_VALUE;
+    for(ClassificationResult<BytesRef> element:doclist){
+      if(element.getScore()>maxscore){
+        retval=element;
+        maxscore=element.getScore();
+      }
+    }
+    return retval;
+  }
+
+  /**
+   * Assign a class (with score) to the given text String.
+   * @param text a String containing text to be classified
+   * @return the whole list of {@link ClassificationResult}, the classes and scores.
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public List<ClassificationResult<BytesRef>> assignClassNormalizedList(String text) throws IOException {
+    TopDocs topDocs=knnSearcher(text);
+    List<ClassificationResult<BytesRef>> doclist=buildListFromTopDocs(topDocs);
+    Collections.sort(doclist);
+    return doclist;
+  }
+
+  private TopDocs knnSearcher(String text) throws IOException{
     if (mlt == null) {
       throw new IOException("You must first call Classifier#train");
     }
@@ -92,32 +122,36 @@
       mltQuery.add(query, BooleanClause.Occur.MUST);
     }
     TopDocs topDocs = indexSearcher.search(mltQuery, k);
-    return selectClassFromNeighbors(topDocs);
+    return topDocs;
   }
-
-  private ClassificationResult<BytesRef> selectClassFromNeighbors(TopDocs topDocs) throws IOException {
-    // TODO : improve the nearest neighbor selection
+  
+  private List<ClassificationResult<BytesRef>> buildListFromTopDocs(TopDocs topDocs) throws IOException {
     Map<BytesRef, Integer> classCounts = new HashMap<>();
     for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
-      BytesRef cl = new BytesRef(indexSearcher.doc(scoreDoc.doc).getField(classFieldName).stringValue());
-      Integer count = classCounts.get(cl);
-      if (count != null) {
-        classCounts.put(cl, count + 1);
-      } else {
-        classCounts.put(cl, 1);
-      }
+        BytesRef cl = new BytesRef(indexSearcher.doc(scoreDoc.doc).getField(classFieldName).stringValue());
+        Integer count = classCounts.get(cl);
+        if (count != null) {
+            classCounts.put(cl, count + 1);
+        } else {
+            classCounts.put(cl, 1);
+        }
     }
-    double max = 0;
-    BytesRef assignedClass = new BytesRef();
+    List<ClassificationResult<BytesRef>> returnList = new ArrayList<ClassificationResult<BytesRef>>();
+    int sumdoc=0;
     for (Map.Entry<BytesRef, Integer> entry : classCounts.entrySet()) {
-      Integer count = entry.getValue();
-      if (count > max) {
-        max = count;
-        assignedClass = entry.getKey().clone();
+        Integer count = entry.getValue();
+        returnList.add(new ClassificationResult<>(entry.getKey().clone(), count / (double) k));
+        sumdoc+=count;
+
+    }
+    
+    //correction
+    if(sumdoc<k){
+      for(ClassificationResult<BytesRef> cr:returnList){
+        cr.setScore(cr.getScore()*(double)k/(double)sumdoc);
       }
     }
-    double score = max / (double) k;
-    return new ClassificationResult<>(assignedClass, score);
+    return returnList;
   }
 
   /**
Index: lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java	(revision 1613085)
+++ lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java	(working copy)
@@ -34,8 +34,11 @@
 import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
+import java.util.Collections;
 import java.util.LinkedList;
+import java.util.List;
 
 /**
  * A simplistic Lucene based NaiveBayes classifier, see <code>http://en.wikipedia.org/wiki/Naive_Bayes_classifier</code>
@@ -47,7 +50,6 @@
   private AtomicReader atomicReader;
   private String[] textFieldNames;
   private String classFieldName;
-  private int docsWithClassSize;
   private Analyzer analyzer;
   private IndexSearcher indexSearcher;
   private Query query;
@@ -89,7 +91,6 @@
     this.classFieldName = classFieldName;
     this.analyzer = analyzer;
     this.query = query;
-    this.docsWithClassSize = countDocsWithClass();
   }
 
   private int countDocsWithClass() throws IOException {
@@ -138,8 +139,9 @@
     TermsEnum termsEnum = terms.iterator(null);
     BytesRef next;
     String[] tokenizedDoc = tokenizeDoc(inputDocument);
+    int docsWithClassSize = countDocsWithClass();
     while ((next = termsEnum.next()) != null) {
-      double clVal = calculateLogPrior(next) + calculateLogLikelihood(tokenizedDoc, next);
+      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);
       if (clVal > max) {
         max = clVal;
         foundClass = BytesRef.deepCopyOf(next);
@@ -149,8 +151,68 @@
     return new ClassificationResult<>(foundClass, score);
   }
 
+  /**
+   * Assign a class (with score) to the given text String.
+   * @param inputDocument a String containing text to be classified
+   * @return the whole list of {@link ClassificationResult}, the classes and scores.
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {
+    if (atomicReader == null) {
+      throw new IOException("You must first call Classifier#train");
+    }
+    List<ClassificationResult<BytesRef>> dataList = new ArrayList<ClassificationResult<BytesRef>>();
+    
+    Terms terms = MultiFields.getTerms(atomicReader, classFieldName);
+    TermsEnum termsEnum = terms.iterator(null);
+    BytesRef next;
+    String[] tokenizedDoc = tokenizeDoc(inputDocument);
+    int docsWithClassSize = countDocsWithClass();
+    while ((next = termsEnum.next()) != null) {
+      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);
+      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));
+    }
+    
+    // normalization; the values transforms to a 0-1 range
+    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<ClassificationResult<BytesRef>>();
+    if (!dataList.isEmpty()) {
+      Collections.sort(dataList);
+      // this is a negative number closest to 0 = a
+      double smax = dataList.get(0).getScore();
+      
+      double sumLog = 0;
+      // log(sum(exp(x_n-a)))
+      for (ClassificationResult<BytesRef> cr : dataList) {
+        // getScore-smax <=0 (both negative, smax is the smallest abs()
+        sumLog += Math.exp(cr.getScore() - smax);
+      }
+      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))
+      double loga = smax;
+      loga += Math.log(sumLog);
+      
+      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))
+      for (ClassificationResult<BytesRef> cr : dataList) {
+        returnList.add(new ClassificationResult<BytesRef>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));
+      }
+    }
+    
+    return returnList;
+  }
+  /**
+   * Assign a class (with score) to the given text String, it will be normalized for comparable results
+   * @param inputDocument a String containing text to be classified
+   * @return a {@link ClassificationResult} holding assigned class of type <code>T</code> and score
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public ClassificationResult<BytesRef> assignClassNormalized(String inputDocument) throws IOException {
+    List<ClassificationResult<BytesRef>> classificationResultList = assignClassNormalizedList(inputDocument);
+    if (!classificationResultList.isEmpty()){
+      return classificationResultList.get(0);
+    }
+    return null;
+  }
 
-  private double calculateLogLikelihood(String[] tokenizedDoc, BytesRef c) throws IOException {
+  private double calculateLogLikelihood(String[] tokenizedDoc, BytesRef c, int docsWithClassSize) throws IOException {
     // for each word
     double result = 0d;
     for (String word : tokenizedDoc) {
@@ -199,7 +261,7 @@
     return totalHitCountCollector.getTotalHits();
   }
 
-  private double calculateLogPrior(BytesRef currentClass) throws IOException {
+  private double calculateLogPrior(BytesRef currentClass, int docsWithClassSize) throws IOException {
     return Math.log((double) docCount(currentClass)) - Math.log(docsWithClassSize);
   }
 
