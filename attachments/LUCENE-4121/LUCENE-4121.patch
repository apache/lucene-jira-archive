Index: lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java	(révision 1349848)
+++ lucene/test-framework/src/java/org/apache/lucene/index/AlcoholicMergePolicy.java	(copie de travail)
@@ -61,10 +61,10 @@
       
       Drink[] values = Drink.values();
       // pick a random drink during the day
-      return values[random.nextInt(values.length)].drunkFactor * info.sizeInBytes();
+      return values[random.nextInt(values.length)].drunkFactor * info.byteSize();
     }
 
-    return info.sizeInBytes();
+    return info.byteSize();
   }
   
   public static enum Drink {
Index: lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java	(révision 1349848)
+++ lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java	(copie de travail)
@@ -188,9 +188,12 @@
     return "MockDirWrapper(" + delegate + ")";
   }
 
-  public synchronized final long sizeInBytes() throws IOException {
+  /**
+   * Return the size of the underlying directory, in bytes.
+   */
+  public synchronized final long byteSize() throws IOException {
     if (delegate instanceof RAMDirectory)
-      return ((RAMDirectory) delegate).sizeInBytes();
+      return ((RAMDirectory) delegate).memSize();
     else {
       // hack
       long size = 0;
@@ -287,10 +290,10 @@
     openLocks.clear();
   }
 
-  public void setMaxSizeInBytes(long maxSize) {
+  public void setMaxByteSize(long maxSize) {
     this.maxSize = maxSize;
   }
-  public long getMaxSizeInBytes() {
+  public long maxByteSize() {
     return this.maxSize;
   }
 
@@ -298,11 +301,11 @@
    * Returns the peek actual storage used (bytes) in this
    * directory.
    */
-  public long getMaxUsedSizeInBytes() {
+  public long maxUsedByteSize() {
     return this.maxUsedSize;
   }
-  public void resetMaxUsedSizeInBytes() throws IOException {
-    this.maxUsedSize = getRecomputedActualSizeInBytes();
+  public void resetMaxUsedByteSize() throws IOException {
+    this.maxUsedSize = recomputedActualByteSize();
   }
 
   /**
@@ -455,7 +458,7 @@
         throw new IOException("file " + name + " already exists");
       else {
         if (existing!=null) {
-          ramdir.sizeInBytes.getAndAdd(-existing.sizeInBytes);
+          ramdir.memSize.getAndAdd(-existing.memSize);
           existing.directory = null;
         }
         ramdir.fileMap.put(name, file);
@@ -522,26 +525,26 @@
     return ii;
   }
   
-  /** Provided for testing purposes.  Use sizeInBytes() instead. */
-  public synchronized final long getRecomputedSizeInBytes() throws IOException {
+  /** Provided for testing purposes.  Use byteSize() instead. */
+  public synchronized final long recomputedByteSize() throws IOException {
     if (!(delegate instanceof RAMDirectory))
-      return sizeInBytes();
+      return byteSize();
     long size = 0;
     for(final RAMFile file: ((RAMDirectory)delegate).fileMap.values()) {
-      size += file.getSizeInBytes();
+      size += file.memSize();
     }
     return size;
   }
 
-  /** Like getRecomputedSizeInBytes(), but, uses actual file
+  /** Like recomputedByteSize(), but, uses actual file
    * lengths rather than buffer allocations (which are
    * quantized up to nearest
    * RAMOutputStream.BUFFER_SIZE (now 1024) bytes.
    */
 
-  public final synchronized long getRecomputedActualSizeInBytes() throws IOException {
+  public final synchronized long recomputedActualByteSize() throws IOException {
     if (!(delegate instanceof RAMDirectory))
-      return sizeInBytes();
+      return byteSize();
     long size = 0;
     for (final RAMFile file : ((RAMDirectory)delegate).fileMap.values())
       size += file.length;
Index: lucene/test-framework/src/java/org/apache/lucene/store/MockIndexOutputWrapper.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/store/MockIndexOutputWrapper.java	(révision 1349848)
+++ lucene/test-framework/src/java/org/apache/lucene/store/MockIndexOutputWrapper.java	(copie de travail)
@@ -52,7 +52,7 @@
       if (dir.trackDiskUsage) {
         // Now compute actual disk usage & track the maxUsedSize
         // in the MockDirectoryWrapper:
-        long size = dir.getRecomputedActualSizeInBytes();
+        long size = dir.recomputedActualByteSize();
         if (size > dir.maxUsedSize) {
           dir.maxUsedSize = size;
         }
@@ -75,7 +75,7 @@
   
   @Override
   public void writeBytes(byte[] b, int offset, int len) throws IOException {
-    long freeSpace = dir.maxSize == 0 ? 0 : dir.maxSize - dir.sizeInBytes();
+    long freeSpace = dir.maxSize == 0 ? 0 : dir.maxSize - dir.byteSize();
     long realUsage = 0;
 
     if (dir.rateLimiter != null && len >= 10) {
@@ -91,7 +91,7 @@
     if (dir.maxSize != 0 && freeSpace <= len) {
       // Compute the real disk free.  This will greatly slow
       // down our test but makes it more accurate:
-      realUsage = dir.getRecomputedActualSizeInBytes();
+      realUsage = dir.recomputedActualByteSize();
       freeSpace = dir.maxSize - realUsage;
     }
 
@@ -103,7 +103,7 @@
       if (realUsage > dir.maxUsedSize) {
         dir.maxUsedSize = realUsage;
       }
-      String message = "fake disk full at " + dir.getRecomputedActualSizeInBytes() + " bytes when writing " + name + " (file length=" + delegate.length();
+      String message = "fake disk full at " + dir.recomputedActualByteSize() + " bytes when writing " + name + " (file length=" + delegate.length();
       if (freeSpace > 0) {
         message += "; wrote " + freeSpace + " of " + len + " bytes";
       }
Index: lucene/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java
===================================================================
--- lucene/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java	(révision 1349848)
+++ lucene/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java	(copie de travail)
@@ -164,7 +164,7 @@
     
     final FST<Long> fst = fstBuilder.finish().pack(2, 100000, PackedInts.DEFAULT);
     
-    System.out.print("  " + fst.getNodeCount() + " nodes, " + fst.getArcCount() + " arcs, " + fst.sizeInBytes() + " bytes...  ");
+    System.out.print("  " + fst.getNodeCount() + " nodes, " + fst.getArcCount() + " arcs, " + fst.memSize() + " bytes...  ");
     dictionary.setFST(fst);
     System.out.println(" done");
     
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge.java	(copie de travail)
@@ -149,7 +149,7 @@
       }
     }
 
-    dir.resetMaxUsedSizeInBytes();
+    dir.resetMaxUsedByteSize();
     dir.setTrackDiskUsage(true);
 
     // Import to use same term index interval else a
@@ -158,7 +158,7 @@
     writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));
     writer.forceMerge(1);
     writer.close();
-    long maxDiskUsage = dir.getMaxUsedSizeInBytes();
+    long maxDiskUsage = dir.maxUsedByteSize();
     assertTrue("forceMerge used too much temporary space: starting usage was " + startDiskUsage + " bytes; max temp usage was " + maxDiskUsage + " but should have been " + (4*startDiskUsage) + " (= 4X starting usage)",
                maxDiskUsage <= 4*startDiskUsage);
     dir.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestFlushByRamOrCountsPolicy.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestFlushByRamOrCountsPolicy.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestFlushByRamOrCountsPolicy.java	(copie de travail)
@@ -314,7 +314,7 @@
         while (pendingDocs.decrementAndGet() > -1) {
           Document doc = docs.nextDoc();
           writer.addDocument(doc);
-          long newRamSize = writer.ramSizeInBytes();
+          long newRamSize = writer.memSize();
           if (newRamSize != ramSize) {
             ramSize = newRamSize;
           }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java	(copie de travail)
@@ -60,7 +60,7 @@
           System.out.println("TEST: cycle: diskFree=" + diskFree);
         }
         MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory());
-        dir.setMaxSizeInBytes(diskFree);
+        dir.setMaxByteSize(diskFree);
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));
         MergeScheduler ms = writer.getConfig().getMergeScheduler();
         if (ms instanceof ConcurrentMergeScheduler) {
@@ -104,7 +104,7 @@
                 System.out.println("TEST: exception on close; retry w/ no disk space limit");
                 e.printStackTrace(System.out);
               }
-              dir.setMaxSizeInBytes(0);
+              dir.setMaxByteSize(0);
               writer.close();
             }
           }
@@ -124,7 +124,7 @@
           diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random(), 400, 600) : _TestUtil.nextInt(random(), 3000, 5000);
         } else {
           //_TestUtil.syncConcurrentMerges(writer);
-          dir.setMaxSizeInBytes(0);
+          dir.setMaxByteSize(0);
           writer.close();
           dir.close();
           break;
@@ -211,7 +211,7 @@
     // added.
     
     // String[] files = startDir.listAll();
-    long diskUsage = startDir.sizeInBytes();
+    long diskUsage = startDir.byteSize();
     
     long startDiskUsage = 0;
     String[] files = startDir.listAll();
@@ -297,7 +297,7 @@
             System.out.println("\ncycle: " + testName);
           
           dir.setTrackDiskUsage(true);
-          dir.setMaxSizeInBytes(thisDiskFree);
+          dir.setMaxByteSize(thisDiskFree);
           dir.setRandomIOExceptionRate(rate);
           
           try {
@@ -414,7 +414,7 @@
         }
         
         if (VERBOSE) {
-          System.out.println("  start disk = " + startDiskUsage + "; input disk = " + inputDiskUsage + "; max used = " + dir.getMaxUsedSizeInBytes());
+          System.out.println("  start disk = " + startDiskUsage + "; input disk = " + inputDiskUsage + "; max used = " + dir.maxUsedByteSize());
         }
         
         if (done) {
@@ -422,14 +422,14 @@
           // required is at most 2X total input size of
           // indices so let's make sure:
           assertTrue("max free Directory space required exceeded 1X the total input index sizes during " + methodName +
-                     ": max temp usage = " + (dir.getMaxUsedSizeInBytes()-startDiskUsage) + " bytes vs limit=" + (2*(startDiskUsage + inputDiskUsage)) +
+                     ": max temp usage = " + (dir.maxUsedByteSize()-startDiskUsage) + " bytes vs limit=" + (2*(startDiskUsage + inputDiskUsage)) +
                      "; starting disk usage = " + startDiskUsage + " bytes; " +
                      "input index disk usage = " + inputDiskUsage + " bytes",
-                     (dir.getMaxUsedSizeInBytes()-startDiskUsage) < 2*(startDiskUsage + inputDiskUsage));
+                     (dir.maxUsedByteSize()-startDiskUsage) < 2*(startDiskUsage + inputDiskUsage));
         }
         
         // Make sure we don't hit disk full during close below:
-        dir.setMaxSizeInBytes(0);
+        dir.setMaxByteSize(0);
         dir.setRandomIOExceptionRate(0.0);
         
         writer.close();
@@ -523,7 +523,7 @@
     MockDirectoryWrapper dir = newDirectory();
     IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
         .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
-    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));
+    dir.setMaxByteSize(Math.max(1, dir.recomputedActualByteSize()));
     final Document doc = new Document();
     FieldType customType = new FieldType(TextField.TYPE_STORED);
     customType.setStoreTermVectorPositions(true);
@@ -548,7 +548,7 @@
 
     // Make sure once disk space is avail again, we can
     // cleanly close:
-    dir.setMaxSizeInBytes(0);
+    dir.setMaxByteSize(0);
     writer.close(false);
     dir.close();
   }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(copie de travail)
@@ -438,7 +438,7 @@
     }
     writer.close();
 
-    long diskUsage = startDir.sizeInBytes();
+    long diskUsage = startDir.byteSize();
     long diskFree = diskUsage + 10;
 
     IOException err = null;
@@ -501,7 +501,7 @@
           testName = "reader re-use after disk full";
         }
 
-        dir.setMaxSizeInBytes(thisDiskFree);
+        dir.setMaxByteSize(thisDiskFree);
         dir.setRandomIOExceptionRate(rate);
 
         try {
@@ -539,9 +539,9 @@
         }
         // prevent throwing a random exception here!!
         final double randomIOExceptionRate = dir.getRandomIOExceptionRate();
-        final long maxSizeInBytes = dir.getMaxSizeInBytes();
+        final long maxMemSize = dir.maxByteSize();
         dir.setRandomIOExceptionRate(0.0);
-        dir.setMaxSizeInBytes(0);
+        dir.setMaxByteSize(0);
         if (!success) {
           // Must force the close else the writer can have
           // open files which cause exc in MockRAMDir.close
@@ -558,7 +558,7 @@
           TestIndexWriter.assertNoUnreferencedFiles(dir, "after writer.close");
         }
         dir.setRandomIOExceptionRate(randomIOExceptionRate);
-        dir.setMaxSizeInBytes(maxSizeInBytes);
+        dir.setMaxByteSize(maxMemSize);
 
         // Finally, verify index is not corrupt, and, if
         // we succeeded, we see all docs changed, and if
Index: lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java	(copie de travail)
@@ -68,7 +68,7 @@
 
     SegmentInfos sis = new SegmentInfos();
     sis.read(dir);
-    double min = sis.info(0).sizeInBytes();
+    double min = sis.info(0).byteSize();
 
     conf = newWriterConfig();
     LogByteSizeMergePolicy lmp = new LogByteSizeMergePolicy();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java	(copie de travail)
@@ -212,10 +212,10 @@
       TestIndexWriter.addDocWithIndex(writer, j);
     }
     writer.close();
-    dir.resetMaxUsedSizeInBytes();
+    dir.resetMaxUsedByteSize();
 
     dir.setTrackDiskUsage(true);
-    long startDiskUsage = dir.getMaxUsedSizeInBytes();
+    long startDiskUsage = dir.maxUsedByteSize();
     writer = new IndexWriter(
         dir,
         newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer)
@@ -229,14 +229,14 @@
     for(int j=0;j<1470;j++) {
       TestIndexWriter.addDocWithIndex(writer, j);
     }
-    long midDiskUsage = dir.getMaxUsedSizeInBytes();
-    dir.resetMaxUsedSizeInBytes();
+    long midDiskUsage = dir.maxUsedByteSize();
+    dir.resetMaxUsedByteSize();
     writer.forceMerge(1);
     writer.close();
 
     DirectoryReader.open(dir).close();
 
-    long endDiskUsage = dir.getMaxUsedSizeInBytes();
+    long endDiskUsage = dir.maxUsedByteSize();
 
     // Ending index is 50X as large as starting index; due
     // to 3X disk usage normally we allow 150X max
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(copie de travail)
@@ -132,7 +132,7 @@
               setMergePolicy(newLogMergePolicy(4))
       );
       ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
-      dir.setMaxSizeInBytes(4*1024+20*iter);
+      dir.setMaxByteSize(4*1024+20*iter);
 
       IndexerThread[] threads = new IndexerThread[NUM_THREADS];
 
@@ -151,7 +151,7 @@
 
       // Make sure once disk space is avail again, we can
       // cleanly close:
-      dir.setMaxSizeInBytes(0);
+      dir.setMaxByteSize(0);
       writer.close(false);
       dir.close();
     }
Index: lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/store/TestRAMDirectory.java	(copie de travail)
@@ -74,7 +74,7 @@
     dir.close();
     
     // Check size
-    assertEquals(ramDir.sizeInBytes(), ramDir.getRecomputedSizeInBytes());
+    assertEquals(ramDir.byteSize(), ramDir.recomputedByteSize());
     
     // open reader to test document count
     IndexReader reader = DirectoryReader.open(ramDir);
@@ -106,7 +106,7 @@
         TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));
     writer.forceMerge(1);
     
-    assertEquals(ramDir.sizeInBytes(), ramDir.getRecomputedSizeInBytes());
+    assertEquals(ramDir.byteSize(), ramDir.recomputedByteSize());
     
     Thread[] threads = new Thread[numThreads];
     for (int i=0; i<numThreads; i++) {
@@ -132,7 +132,7 @@
       threads[i].join();
 
     writer.forceMerge(1);
-    assertEquals(ramDir.sizeInBytes(), ramDir.getRecomputedSizeInBytes());
+    assertEquals(ramDir.byteSize(), ramDir.recomputedByteSize());
     
     writer.close();
   }
Index: lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java	(révision 1349848)
+++ lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java	(copie de travail)
@@ -1174,7 +1174,7 @@
       }
       FST<Long> fst = builder.finish();
       if (VERBOSE) {
-        System.out.println("FST: " + docCount + " docs; " + ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs;" + " " + fst.sizeInBytes() + " bytes");
+        System.out.println("FST: " + docCount + " docs; " + ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs;" + " " + fst.memSize() + " bytes");
       }
 
       if (ord > 0) {
@@ -1315,7 +1315,7 @@
           return;
         }
 
-        System.out.println(ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs; " + fst.getArcWithOutputCount() + " arcs w/ output; tot size " + fst.sizeInBytes());
+        System.out.println(ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs; " + fst.getArcWithOutputCount() + " arcs w/ output; tot size " + fst.memSize());
         if (fst.getNodeCount() < 100) {
           Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
           Util.toDot(fst, w, false, false);
@@ -1326,7 +1326,7 @@
         if (doPack) {
           System.out.println("Pack...");
           fst = fst.pack(4, 100000000, random().nextFloat());
-          System.out.println("New size " + fst.sizeInBytes() + " bytes");
+          System.out.println("New size " + fst.memSize() + " bytes");
         }
         
         Directory dir = FSDirectory.open(new File(dirOut));
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(copie de travail)
@@ -506,7 +506,7 @@
       }
 
       if (infoStream.isEnabled("DWPT")) {
-        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;
+        final double newSegmentSize = segmentInfo.byteSize()/1024./1024.;
         infoStream.message("DWPT", "flushed: segment=" + segmentInfo.name + 
                 " ramUsed=" + nf.format(startMBUsed) + " MB" +
                 " newFlushedSize(includes docstores)=" + nf.format(newSegmentSize) + " MB" +
Index: lucene/core/src/java/org/apache/lucene/index/SegmentInfoPerCommit.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SegmentInfoPerCommit.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/SegmentInfoPerCommit.java	(copie de travail)
@@ -39,7 +39,7 @@
   // are no deletes yet):
   private long delGen;
 
-  private volatile long sizeInBytes = -1;
+  private volatile long byteSize = -1;
 
   public SegmentInfoPerCommit(SegmentInfo info, int delCount, long delGen) {
     this.info = info;
@@ -53,21 +53,21 @@
     } else {
       delGen++;
     }
-    sizeInBytes = -1;
+    byteSize = -1;
   }
 
-  public long sizeInBytes() throws IOException {
-    if (sizeInBytes == -1) {
+  public long byteSize() throws IOException {
+    if (byteSize == -1) {
       final Collection<String> files = new HashSet<String>();
       info.getCodec().liveDocsFormat().files(this, files);
-      long sum = info.sizeInBytes();
+      long sum = info.byteSize();
       for (final String fileName : files()) {
         sum += info.dir.fileLength(fileName);
       }
-      sizeInBytes = sum;
+      byteSize = sum;
     }
 
-    return sizeInBytes;
+    return byteSize;
   }
 
   public Collection<String> files() throws IOException {
@@ -89,17 +89,17 @@
 
   void setBufferedDeletesGen(long v) {
     bufferedDeletesGen = v;
-    sizeInBytes =  -1;
+    byteSize =  -1;
   }
   
   void clearDelGen() {
     delGen = -1;
-    sizeInBytes =  -1;
+    byteSize =  -1;
   }
 
   public void setDelGen(long delGen) {
     this.delGen = delGen;
-    sizeInBytes =  -1;
+    byteSize =  -1;
   }
 
   public boolean hasDeletions() {
Index: lucene/core/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java	(copie de travail)
@@ -42,7 +42,7 @@
   
   @Override
   protected long size(SegmentInfoPerCommit info) throws IOException {
-    return sizeBytes(info);
+    return byteSize(info);
   }
 
   /** <p>Determines the largest segment (measured by total
Index: lucene/core/src/java/org/apache/lucene/index/TypePromoter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/TypePromoter.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/TypePromoter.java	(copie de travail)
@@ -184,7 +184,7 @@
   
   @Override
   public String toString() {
-    return "TypePromoter [type=" + type + ", sizeInBytes=" + valueSize + "]";
+    return "TypePromoter [type=" + type + ", memSize=" + valueSize + "]";
   }
   
   @Override
Index: lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java	(copie de travail)
@@ -241,8 +241,8 @@
   private class SegmentByteSizeDescending implements Comparator<SegmentInfoPerCommit> {
     public int compare(SegmentInfoPerCommit o1, SegmentInfoPerCommit o2) {
       try {
-        final long sz1 = size(o1);
-        final long sz2 = size(o2);
+        final long sz1 = byteSize(o1);
+        final long sz2 = byteSize(o2);
         if (sz1 > sz2) {
           return -1;
         } else if (sz2 > sz1) {
@@ -281,7 +281,7 @@
     long totIndexBytes = 0;
     long minSegmentBytes = Long.MAX_VALUE;
     for(SegmentInfoPerCommit info : infosSorted) {
-      final long segBytes = size(info);
+      final long segBytes = byteSize(info);
       if (verbose()) {
         String extra = merging.contains(info) ? " [merging]" : "";
         if (segBytes >= maxMergedSegmentBytes/2.0) {
@@ -300,12 +300,12 @@
     // If we have too-large segments, grace them out
     // of the maxSegmentCount:
     int tooBigCount = 0;
-    while (tooBigCount < infosSorted.size() && size(infosSorted.get(tooBigCount)) >= maxMergedSegmentBytes/2.0) {
-      totIndexBytes -= size(infosSorted.get(tooBigCount));
+    while (tooBigCount < infosSorted.size() && byteSize(infosSorted.get(tooBigCount)) >= maxMergedSegmentBytes/2.0) {
+      totIndexBytes -= byteSize(infosSorted.get(tooBigCount));
       tooBigCount++;
     }
 
-    minSegmentBytes = floorSize(minSegmentBytes);
+    minSegmentBytes = floorByteSize(minSegmentBytes);
 
     // Compute max allowed segs in the index
     long levelSize = minSegmentBytes;
@@ -337,7 +337,7 @@
       for(int idx = tooBigCount; idx<infosSorted.size(); idx++) {
         final SegmentInfoPerCommit info = infosSorted.get(idx);
         if (merging.contains(info)) {
-          mergingBytes += info.info.sizeInBytes();
+          mergingBytes += info.info.byteSize();
         } else if (!toBeMerged.contains(info)) {
           eligible.add(info);
         }
@@ -370,7 +370,7 @@
           boolean hitTooLarge = false;
           for(int idx = startIdx;idx<eligible.size() && candidate.size() < maxMergeAtOnce;idx++) {
             final SegmentInfoPerCommit info = eligible.get(idx);
-            final long segBytes = size(info);
+            final long segBytes = byteSize(info);
 
             if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {
               hitTooLarge = true;
@@ -430,10 +430,10 @@
     long totAfterMergeBytes = 0;
     long totAfterMergeBytesFloored = 0;
     for(SegmentInfoPerCommit info : candidate) {
-      final long segBytes = size(info);
+      final long segBytes = byteSize(info);
       totAfterMergeBytes += segBytes;
-      totAfterMergeBytesFloored += floorSize(segBytes);
-      totBeforeMergeBytes += info.info.sizeInBytes();
+      totAfterMergeBytesFloored += floorByteSize(segBytes);
+      totBeforeMergeBytes += info.info.byteSize();
     }
 
     // Measure "skew" of the merge, which can range
@@ -447,7 +447,7 @@
       // over time:
       skew = 1.0/maxMergeAtOnce;
     } else {
-      skew = ((double) floorSize(size(candidate.get(0))))/totAfterMergeBytesFloored;
+      skew = ((double) floorByteSize(byteSize(candidate.get(0))))/totAfterMergeBytesFloored;
     }
 
     // Strongly favor merges with less skew (smaller
@@ -611,10 +611,10 @@
     } else {
       long totalSize = 0;
       for (SegmentInfoPerCommit info : infos) {
-        totalSize += size(info);
+        totalSize += byteSize(info);
       }
 
-      doCFS = size(mergedInfo) <= noCFSRatio * totalSize;
+      doCFS = byteSize(mergedInfo) <= noCFSRatio * totalSize;
     }
     return doCFS;
   }
@@ -634,15 +634,15 @@
   }
 
   // Segment size in bytes, pro-rated by % deleted
-  private long size(SegmentInfoPerCommit info) throws IOException {
-    final long byteSize = info.info.sizeInBytes();    
+  private long byteSize(SegmentInfoPerCommit info) throws IOException {
+    final long byteSize = info.info.byteSize();    
     final int delCount = writer.get().numDeletedDocs(info);
     final double delRatio = (info.info.getDocCount() <= 0 ? 0.0f : ((double)delCount / (double)info.info.getDocCount()));    
     assert delRatio <= 1.0;
     return (long) (byteSize * (1.0-delRatio));
   }
 
-  private long floorSize(long bytes) {
+  private long floorByteSize(long bytes) {
     return Math.max(floorSegmentBytes, bytes);
   }
 
Index: lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java	(copie de travail)
@@ -47,7 +47,7 @@
 
   private boolean isCompoundFile;
 
-  private volatile long sizeInBytes = -1;         // total byte size of all files (computed on demand)
+  private volatile long segmentSize = -1;         // total byte size of all files (computed on demand)
 
   private Codec codec;
 
@@ -92,17 +92,17 @@
    * Returns total size in bytes of all of files used by
    * this segment.  Note that this will not include any live
    * docs for the segment; to include that use {@link
-   * SegmentInfoPerCommit#sizeInBytes()} instead.
+   * SegmentInfoPerCommit#byteSize()} instead.
    */
-  public long sizeInBytes() throws IOException {
-    if (sizeInBytes == -1) {
+  public long byteSize() throws IOException {
+    if (segmentSize == -1) {
       long sum = 0;
       for (final String fileName : files()) {
         sum += dir.fileLength(fileName);
       }
-      sizeInBytes = sum;
+      segmentSize = sum;
     }
-    return sizeInBytes;
+    return segmentSize;
   }
 
   /**
@@ -243,7 +243,7 @@
 
   public void setFiles(Set<String> files) {
     setFiles = files;
-    sizeInBytes = -1;
+    segmentSize = -1;
   }
 
   public void addFiles(Collection<String> files) {
Index: lucene/core/src/java/org/apache/lucene/index/MergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/MergePolicy.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/MergePolicy.java	(copie de travail)
@@ -171,10 +171,10 @@
      * Returns the total size in bytes of this merge. Note that this does not
      * indicate the size of the merged segment, but the input total size.
      * */
-    public long totalBytesSize() throws IOException {
+    public long byteSize() throws IOException {
       long total = 0;
       for (SegmentInfoPerCommit info : segments) {
-        total += info.info.sizeInBytes();
+        total += info.info.byteSize();
       }
       return total;
     }
@@ -183,7 +183,7 @@
      * Returns the total number of documents that are included with this merge.
      * Note that this does not indicate the number of documents after the merge.
      * */
-    public int totalNumDocs() throws IOException {
+    public int docSize() throws IOException {
       int total = 0;
       for (SegmentInfoPerCommit info : segments) {
         total += info.info.getDocCount();
Index: lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java	(copie de travail)
@@ -182,7 +182,7 @@
 
   abstract protected long size(SegmentInfoPerCommit info) throws IOException;
 
-  protected long sizeDocs(SegmentInfoPerCommit info) throws IOException {
+  protected long docSize(SegmentInfoPerCommit info) throws IOException {
     if (calibrateSizeByDeletes) {
       int delCount = writer.get().numDeletedDocs(info);
       assert delCount <= info.info.getDocCount();
@@ -192,8 +192,8 @@
     }
   }
   
-  protected long sizeBytes(SegmentInfoPerCommit info) throws IOException {
-    long byteSize = info.sizeInBytes();
+  protected long byteSize(SegmentInfoPerCommit info) throws IOException {
+    long byteSize = info.byteSize();
     if (calibrateSizeByDeletes) {
       int delCount = writer.get().numDeletedDocs(info);
       double delRatio = (info.info.getDocCount() <= 0 ? 0.0f : ((float)delCount / (float)info.info.getDocCount()));
@@ -252,7 +252,7 @@
     int start = last - 1;
     while (start >= 0) {
       SegmentInfoPerCommit info = infos.info(start);
-      if (size(info) > maxMergeSizeForForcedMerge || sizeDocs(info) > maxMergeDocs) {
+      if (size(info) > maxMergeSizeForForcedMerge || docSize(info) > maxMergeDocs) {
         if (verbose()) {
           message("findForcedMergesSizeLimit: skip segment=" + info + ": size is > maxMergeSize (" + maxMergeSizeForForcedMerge + ") or sizeDocs is > maxMergeDocs (" + maxMergeDocs + ")");
         }
@@ -400,7 +400,7 @@
     boolean anyTooLarge = false;
     for (int i = 0; i < last; i++) {
       SegmentInfoPerCommit info = infos.info(i);
-      if (size(info) > maxMergeSizeForForcedMerge || sizeDocs(info) > maxMergeDocs) {
+      if (size(info) > maxMergeSizeForForcedMerge || docSize(info) > maxMergeDocs) {
         anyTooLarge = true;
         break;
       }
@@ -530,7 +530,7 @@
       levels.add(infoLevel);
 
       if (verbose()) {
-        final long segBytes = sizeBytes(info);
+        final long segBytes = byteSize(info);
         String extra = mergingSegments.contains(info) ? " [merging]" : "";
         if (size >= maxMergeSize) {
           extra += " [skip: too large]";
@@ -602,7 +602,7 @@
         boolean anyMerging = false;
         for(int i=start;i<end;i++) {
           final SegmentInfoPerCommit info = levels.get(i).info;
-          anyTooLarge |= (size(info) >= maxMergeSize || sizeDocs(info) >= maxMergeDocs);
+          anyTooLarge |= (size(info) >= maxMergeSize || docSize(info) >= maxMergeDocs);
           if (mergingSegments.contains(info)) {
             anyMerging = true;
             break;
Index: lucene/core/src/java/org/apache/lucene/index/DocValues.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocValues.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/DocValues.java	(copie de travail)
@@ -414,7 +414,7 @@
       }
 
       @Override
-      public long ramBytesUsed() {
+      public long memSize() {
         return 0;
       }
     };
Index: lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(copie de travail)
@@ -2023,7 +2023,7 @@
 
     setDiagnostics(newSegment.info, "flush");
     
-    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));
+    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.byteSize()));
 
     boolean success = false;
     try {
@@ -2227,7 +2227,7 @@
             infoStream.message("IW", "addIndexes: process segment origName=" + info.info.name + " newName=" + newSegName + " dsName=" + dsName + " info=" + info);
           }
 
-          IOContext context = new IOContext(new MergeInfo(info.info.getDocCount(), info.info.sizeInBytes(), true, -1));
+          IOContext context = new IOContext(new MergeInfo(info.info.getDocCount(), info.info.byteSize(), true, -1));
           
           infos.add(copySegmentAsIs(info, newSegName, dsNames, dsFilesCopied, context, copiedFiles));
         }
@@ -2814,7 +2814,7 @@
   /** Expert:  Return the total size of all index files currently cached in memory.
    * Useful for size management with flushRamDocs()
    */
-  public final long ramSizeInBytes() {
+  public final long memSize() {
     ensureOpen();
     return docWriter.flushControl.netBytes() + bufferedDeletesStream.bytesUsed();
   }
@@ -3313,7 +3313,7 @@
         final int delCount = numDeletedDocs(info);
         assert delCount <= info.info.getDocCount();
         final double delRatio = ((double) delCount)/info.info.getDocCount();
-        merge.estimatedMergeBytes += info.info.sizeInBytes() * (1.0 - delRatio);
+        merge.estimatedMergeBytes += info.info.byteSize() * (1.0 - delRatio);
       }
     }
   }
@@ -3582,7 +3582,7 @@
       // lost... 
 
       if (infoStream.isEnabled("IW")) {
-        infoStream.message("IW", String.format("merged segment size=%.3f MB vs estimate=%.3f MB", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));
+        infoStream.message("IW", String.format("merged segment size=%.3f MB vs estimate=%.3f MB", merge.info.info.byteSize()/1024./1024., merge.estimatedMergeBytes/1024/1024.));
       }
 
       final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();
Index: lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(copie de travail)
@@ -479,7 +479,7 @@
         segInfoStat.compound = info.info.getUseCompoundFile();
         msg("    numFiles=" + info.files().size());
         segInfoStat.numFiles = info.files().size();
-        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);
+        segInfoStat.sizeMB = info.byteSize()/(1024.*1024.);
         msg("    size (MB)=" + nf.format(segInfoStat.sizeMB));
         Map<String,String> diagnostics = info.info.getDiagnostics();
         segInfoStat.diagnostics = diagnostics;
Index: lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java	(copie de travail)
@@ -38,8 +38,8 @@
   }
   
   /** @return size in bytes */
-  public long getSizeInBytes() {
-    return buffer.getSizeInBytes();
+  public long memSize() {
+    return buffer.memSize();
   }
   
   /** @return iterator over the bytes */
Index: lucene/core/src/java/org/apache/lucene/index/LogDocMergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/LogDocMergePolicy.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/LogDocMergePolicy.java	(copie de travail)
@@ -39,7 +39,7 @@
 
   @Override
   protected long size(SegmentInfoPerCommit info) throws IOException {
-    return sizeDocs(info);
+    return docSize(info);
   }
 
   /** Sets the minimum size for the lowest level segments.
Index: lucene/core/src/java/org/apache/lucene/index/FrozenBufferedDeletes.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FrozenBufferedDeletes.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/index/FrozenBufferedDeletes.java	(copie de travail)
@@ -72,7 +72,7 @@
       upto++;
     }
 
-    bytesUsed = (int) terms.getSizeInBytes() + queries.length * BYTES_PER_DEL_QUERY;
+    bytesUsed = (int) terms.memSize() + queries.length * BYTES_PER_DEL_QUERY;
     numTermDeletes = deletes.numTermDeletes.get();
   }
   
Index: lucene/core/src/java/org/apache/lucene/store/RAMFile.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/RAMFile.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/store/RAMFile.java	(copie de travail)
@@ -24,7 +24,7 @@
   protected ArrayList<byte[]> buffers = new ArrayList<byte[]>();
   long length;
   RAMDirectory directory;
-  protected long sizeInBytes;
+  protected long memSize;
 
   // File used as buffer, in no RAMDirectory
   public RAMFile() {}
@@ -46,11 +46,11 @@
     byte[] buffer = newBuffer(size);
     synchronized(this) {
       buffers.add(buffer);
-      sizeInBytes += size;
+      memSize += size;
     }
 
     if (directory != null) {
-      directory.sizeInBytes.getAndAdd(size);
+      directory.memSize.getAndAdd(size);
     }
     return buffer;
   }
@@ -73,8 +73,8 @@
     return new byte[size];
   }
 
-  public synchronized long getSizeInBytes() {
-    return sizeInBytes;
+  public synchronized long memSize() {
+    return memSize;
   }
   
 }
Index: lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java	(copie de travail)
@@ -47,7 +47,7 @@
  */
 public class RAMDirectory extends Directory {
   protected final Map<String,RAMFile> fileMap = new ConcurrentHashMap<String,RAMFile>();
-  protected final AtomicLong sizeInBytes = new AtomicLong();
+  protected final AtomicLong memSize = new AtomicLong();
   
   // *****
   // Lock acquisition sequence:  RAMDirectory, then RAMFile
@@ -137,9 +137,9 @@
    * Return total size in bytes of all files in this directory. This is
    * currently quantized to RAMOutputStream.BUFFER_SIZE.
    */
-  public final long sizeInBytes() {
+  public final long memSize() {
     ensureOpen();
-    return sizeInBytes.get();
+    return memSize.get();
   }
   
   /** Removes an existing file in the directory.
@@ -151,7 +151,7 @@
     RAMFile file = fileMap.remove(name);
     if (file != null) {
       file.directory = null;
-      sizeInBytes.addAndGet(-file.sizeInBytes);
+      memSize.addAndGet(-file.memSize);
     } else {
       throw new FileNotFoundException(name);
     }
@@ -164,7 +164,7 @@
     RAMFile file = newRAMFile();
     RAMFile existing = fileMap.remove(name);
     if (existing != null) {
-      sizeInBytes.addAndGet(-existing.sizeInBytes);
+      memSize.addAndGet(-existing.memSize);
       existing.directory = null;
     }
     fileMap.put(name, file);
Index: lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java	(copie de travail)
@@ -143,8 +143,8 @@
 
   /** Returns how many bytes are being used by the
    *  RAMDirectory cache */
-  public long sizeInBytes()  {
-    return cache.sizeInBytes();
+  public long memSize()  {
+    return cache.memSize();
   }
 
   @Override
@@ -265,7 +265,7 @@
   protected boolean doCacheWrite(String name, IOContext context) {
     final MergeInfo merge = context.mergeInfo;
     //System.out.println(Thread.currentThread().getName() + ": CACHE check merge=" + merge + " size=" + (merge==null ? 0 : merge.estimatedMergeBytes));
-    return !name.equals(IndexFileNames.SEGMENTS_GEN) && (merge == null || merge.estimatedMergeBytes <= maxMergeSizeBytes) && cache.sizeInBytes() <= maxCachedBytes;
+    return !name.equals(IndexFileNames.SEGMENTS_GEN) && (merge == null || merge.estimatedMergeBytes <= maxMergeSizeBytes) && cache.memSize() <= maxCachedBytes;
   }
 
   private final Object uncacheLock = new Object();
Index: lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java	(copie de travail)
@@ -176,7 +176,7 @@
   }
 
   /** Returns byte usage of all buffers. */
-  public long sizeInBytes() {
+  public long memSize() {
     return (long) file.numBuffers() * (long) BUFFER_SIZE;
   }
   
Index: lucene/core/src/java/org/apache/lucene/util/packed/Direct64.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Direct64.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Direct64.java	(copie de travail)
@@ -73,7 +73,7 @@
     Arrays.fill(values, fromIndex, toIndex, val);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(values);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java	(copie de travail)
@@ -84,7 +84,7 @@
     Arrays.fill(blocks, (short) 0);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(blocks);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java	(copie de travail)
@@ -103,7 +103,7 @@
     /**
      * Return the in-memory size in bytes.
      */
-    long ramBytesUsed();
+    long memSize();
 
     /**
      * Expert: if the bit-width of this reader matches one of
Index: lucene/core/src/java/org/apache/lucene/util/packed/DirectPacked64SingleBlockReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/DirectPacked64SingleBlockReader.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/DirectPacked64SingleBlockReader.java	(copie de travail)
@@ -53,7 +53,7 @@
   }
 
   @Override
-  public long ramBytesUsed() {
+  public long memSize() {
     return 0;
   }
 }
Index: lucene/core/src/java/org/apache/lucene/util/packed/GrowableWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/GrowableWriter.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/GrowableWriter.java	(copie de travail)
@@ -116,8 +116,8 @@
   }
 
   @Override
-  public long ramBytesUsed() {
-    return current.ramBytesUsed();
+  public long memSize() {
+    return current.memSize();
   }
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java	(copie de travail)
@@ -216,7 +216,7 @@
             + ", elements.length=" + blocks.length + ")";
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(blocks);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/Direct8.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Direct8.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Direct8.java	(copie de travail)
@@ -83,7 +83,7 @@
     Arrays.fill(values, fromIndex, toIndex, (byte) val);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(values);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/DirectPackedReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/DirectPackedReader.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/DirectPackedReader.java	(copie de travail)
@@ -75,7 +75,7 @@
   }
 
   @Override
-  public long ramBytesUsed() {
+  public long memSize() {
     return 0;
   }
 }
Index: lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java	(copie de travail)
@@ -84,7 +84,7 @@
     Arrays.fill(blocks, (byte) 0);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(blocks);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java	(copie de travail)
@@ -280,7 +280,7 @@
     Arrays.fill(blocks, 0L);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(blocks);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/Direct32.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Direct32.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Direct32.java	(copie de travail)
@@ -78,7 +78,7 @@
     Arrays.fill(values, fromIndex, toIndex, (int) val);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(values);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/packed/Direct16.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/packed/Direct16.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/packed/Direct16.java	(copie de travail)
@@ -82,7 +82,7 @@
     Arrays.fill(values, fromIndex, toIndex, (short) val);
   }
 
-  public long ramBytesUsed() {
+  public long memSize() {
     return RamUsageEstimator.sizeOf(values);
   }
 
Index: lucene/core/src/java/org/apache/lucene/util/fst/FST.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/fst/FST.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/util/fst/FST.java	(copie de travail)
@@ -340,13 +340,13 @@
   }
 
   /** Returns bytes used to represent the FST */
-  public int sizeInBytes() {
+  public int memSize() {
     int size = bytes.length;
     if (packed) {
-      size += nodeRefToAddress.ramBytesUsed();
+      size += nodeRefToAddress.memSize();
     } else if (nodeAddress != null) {
-      size += nodeAddress.ramBytesUsed();
-      size += inCounts.ramBytesUsed();
+      size += nodeAddress.memSize();
+      size += inCounts.memSize();
     }
     return size;
   }
@@ -1775,7 +1775,7 @@
     fst.bytes = finalBytes;
     fst.cacheRootArcs();
 
-    //final int size = fst.sizeInBytes();
+    //final int size = fst.memSize();
     //System.out.println("nextCount=" + nextCount + " topCount=" + topCount + " deltaCount=" + deltaCount + " absCount=" + absCount);
 
     return fst;
Index: lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java	(copie de travail)
@@ -1258,7 +1258,7 @@
         if (index != null) {
           stats.indexNodeCount = index.getNodeCount();
           stats.indexArcCount = index.getArcCount();
-          stats.indexNumBytes = index.sizeInBytes();
+          stats.indexNumBytes = index.memSize();
         }
         
         currentFrame = staticFrame;
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java	(copie de travail)
@@ -229,7 +229,7 @@
       }
     }
 
-    public long ramBytesUsed() {
+    public long memSize() {
       return bytesUsed.get();
     }
 
Index: lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java	(révision 1349848)
+++ lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java	(copie de travail)
@@ -578,7 +578,7 @@
       ps.close();
       System.out.println("SAVED out.dot");
       */
-      //System.out.println("FST " + fst.sizeInBytes());
+      //System.out.println("FST " + fst.memSize());
     }
 
     @Override
Index: lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java	(révision 1349848)
+++ lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java	(copie de travail)
@@ -58,7 +58,7 @@
   
   @Override
   protected long size(SegmentInfoPerCommit info) throws IOException {
-    long byteSize = info.sizeInBytes();
+    long byteSize = info.byteSize();
     float delRatio = (info.info.getDocCount() <= 0 ? 0.0f : ((float)info.getDelCount() / (float)info.info.getDocCount()));
     return (info.info.getDocCount() <= 0 ?  byteSize : (long)((1.0f - delRatio) * byteSize));
   }
Index: lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java	(révision 1349848)
+++ lucene/misc/src/java/org/apache/lucene/index/IndexSplitter.java	(copie de travail)
@@ -106,7 +106,7 @@
     DecimalFormat formatter = new DecimalFormat("###,###.###");
     for (int x = 0; x < infos.size(); x++) {
       SegmentInfoPerCommit info = infos.info(x);
-      String sizeStr = formatter.format(info.sizeInBytes());
+      String sizeStr = formatter.format(info.byteSize());
       System.out.println(info.info.name + " " + sizeStr);
     }
   }
