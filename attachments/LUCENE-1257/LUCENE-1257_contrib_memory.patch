Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java	(revision 829570)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java	(working copy)
@@ -25,8 +25,6 @@
 import java.util.List;
 import java.util.Collections;
 import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
 import java.util.Properties;
 import java.util.StringTokenizer;
 
@@ -50,7 +48,7 @@
 
   private int roundNumber = 0;
   private Properties props;
-  private HashMap valByRound = new HashMap();
+  private HashMap<String, Object> valByRound = new HashMap<String, Object>();
   private HashMap<String,String> colForValByRound = new HashMap<String,String>();
   private String algorithmText;
 
@@ -247,8 +245,7 @@
     // log changes in values
     if (valByRound.size()>0) {
       sb.append(": ");
-      for (Iterator iter = valByRound.keySet().iterator(); iter.hasNext();) {
-        String name = (String) iter.next();
+      for (final String name : valByRound.keySet()) {
         Object a = valByRound.get(name);
         if (a instanceof int[]) {
           int ai[] = (int[]) a;
Index: contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
===================================================================
--- contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(revision 829570)
+++ contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(working copy)
@@ -174,10 +174,10 @@
 public class MemoryIndex implements Serializable {
 
   /** info for each field: Map<String fieldName, Info field> */
-  private final HashMap fields = new HashMap();
+  private final HashMap<String,Info> fields = new HashMap<String,Info>();
   
   /** fields sorted ascending by fieldName; lazily computed on demand */
-  private transient Map.Entry[] sortedFields; 
+  private transient Map.Entry<String,Info>[] sortedFields; 
   
   /** pos: positions[3*i], startOffset: positions[3*i +1], endOffset: positions[3*i +2] */
   private final int stride;
@@ -269,13 +269,13 @@
    *            the keywords to generate tokens for
    * @return the corresponding token stream
    */
-  public TokenStream keywordTokenStream(final Collection keywords) {
+  public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {
     // TODO: deprecate & move this method into AnalyzerUtil?
     if (keywords == null)
       throw new IllegalArgumentException("keywords must not be null");
     
     return new TokenStream() {
-      private Iterator iter = keywords.iterator();
+      private Iterator<T> iter = keywords.iterator();
       private int start = 0;
       private TermAttribute termAtt = addAttribute(TermAttribute.class);
       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
@@ -283,7 +283,7 @@
       public boolean incrementToken() {
         if (!iter.hasNext()) return false;
         
-        Object obj = iter.next();
+        T obj = iter.next();
         if (obj == null) 
           throw new IllegalArgumentException("keyword must not be null");
         
@@ -334,7 +334,7 @@
       if (fields.get(fieldName) != null)
         throw new IllegalArgumentException("field must not be added more than once");
       
-      HashMap terms = new HashMap();
+      HashMap<String,ArrayIntList> terms = new HashMap<String,ArrayIntList>();
       int numTokens = 0;
       int numOverlapTokens = 0;
       int pos = -1;
@@ -354,7 +354,7 @@
           numOverlapTokens++;
         pos += posIncr;
         
-        ArrayIntList positions = (ArrayIntList) terms.get(term);
+        ArrayIntList positions = terms.get(term);
         if (positions == null) { // term not seen before
           positions = new ArrayIntList(stride);
           terms.put(term, positions);
@@ -470,21 +470,19 @@
     if (sortedFields != null) size += VM.sizeOfObjectArray(sortedFields.length);
     
     size += VM.sizeOfHashMap(fields.size());
-    Iterator iter = fields.entrySet().iterator();
-    while (iter.hasNext()) { // for each Field Info
-      Map.Entry entry = (Map.Entry) iter.next();      
-      Info info = (Info) entry.getValue();
+    for (Map.Entry<String, Info> entry : fields.entrySet()) { // for each Field Info
+      Info info = entry.getValue();
       size += VM.sizeOfObject(2*INT + 3*PTR); // Info instance vars
       if (info.sortedTerms != null) size += VM.sizeOfObjectArray(info.sortedTerms.length);
       
       int len = info.terms.size();
       size += VM.sizeOfHashMap(len);
-      Iterator iter2 = info.terms.entrySet().iterator();
+      Iterator<Map.Entry<String, ArrayIntList>> iter2 = info.terms.entrySet().iterator();
       while (--len >= 0) { // for each term
-        Map.Entry e = (Map.Entry) iter2.next();
+        Map.Entry<String,ArrayIntList> e = iter2.next();
         size += VM.sizeOfObject(PTR + 3*INT); // assumes substring() memory overlay
 //        size += STR + 2 * ((String) e.getKey()).length();
-        ArrayIntList positions = (ArrayIntList) e.getValue();
+        ArrayIntList positions = e.getValue();
         size += VM.sizeOfArrayIntList(positions.size());
       }
     }
@@ -501,13 +499,13 @@
   }
   
   /** returns a view of the given map's entries, sorted ascending by key */
-  private static Map.Entry[] sort(HashMap map) {
+  private static <K,V> Map.Entry<K,V>[] sort(HashMap<K,V> map) {
     int size = map.size();
-    Map.Entry[] entries = new Map.Entry[size];
+    Map.Entry<K,V>[] entries = new Map.Entry[size];
     
-    Iterator iter = map.entrySet().iterator();
+    Iterator<Map.Entry<K,V>> iter = map.entrySet().iterator();
     for (int i=0; i < size; i++) {
-      entries[i] = (Map.Entry) iter.next();
+      entries[i] = iter.next();
     }
     
     if (size > 1) Arrays.sort(entries, termComparator);
@@ -527,18 +525,18 @@
     int sumTerms = 0;
     
     for (int i=0; i < sortedFields.length; i++) {
-      Map.Entry entry = sortedFields[i];
-      String fieldName = (String) entry.getKey();
-      Info info = (Info) entry.getValue();
+      Map.Entry<String,Info> entry = sortedFields[i];
+      String fieldName = entry.getKey();
+      Info info = entry.getValue();
       info.sortTerms();
       result.append(fieldName + ":\n");
       
       int numChars = 0;
       int numPositions = 0;
       for (int j=0; j < info.sortedTerms.length; j++) {
-        Map.Entry e = info.sortedTerms[j];
-        String term = (String) e.getKey();
-        ArrayIntList positions = (ArrayIntList) e.getValue();
+        Map.Entry<String,ArrayIntList> e = info.sortedTerms[j];
+        String term = e.getKey();
+        ArrayIntList positions = e.getValue();
         result.append("\t'" + term + "':" + numPositions(positions) + ":");
         result.append(positions.toString(stride)); // ignore offsets
         result.append("\n");
@@ -576,10 +574,10 @@
      * Term strings and their positions for this field: Map <String
      * termText, ArrayIntList positions>
      */
-    private final HashMap terms; 
+    private final HashMap<String,ArrayIntList> terms; 
     
     /** Terms sorted ascending by term text; computed on demand */
-    private transient Map.Entry[] sortedTerms;
+    private transient Map.Entry<String,ArrayIntList>[] sortedTerms;
     
     /** Number of added tokens for this field */
     private final int numTokens;
@@ -595,7 +593,7 @@
 
     private static final long serialVersionUID = 2882195016849084649L;  
 
-    public Info(HashMap terms, int numTokens, int numOverlapTokens, float boost) {
+    public Info(HashMap<String,ArrayIntList> terms, int numTokens, int numOverlapTokens, float boost) {
       this.terms = terms;
       this.numTokens = numTokens;
       this.numOverlapTokens = numOverlapTokens;
@@ -616,12 +614,12 @@
         
     /** note that the frequency can be calculated as numPosition(getPositions(x)) */
     public ArrayIntList getPositions(String term) {
-      return (ArrayIntList) terms.get(term);
+      return terms.get(term);
     }
 
     /** note that the frequency can be calculated as numPosition(getPositions(x)) */
     public ArrayIntList getPositions(int pos) {
-      return (ArrayIntList) sortedTerms[pos].getValue();
+      return sortedTerms[pos].getValue();
     }
     
     public float getBoost() {
@@ -735,11 +733,11 @@
     protected void finalize() {}
     
     private Info getInfo(String fieldName) {
-      return (Info) fields.get(fieldName);
+      return fields.get(fieldName);
     }
     
     private Info getInfo(int pos) {
-      return (Info) sortedFields[pos].getValue();
+      return sortedFields[pos].getValue();
     }
     
     public int docFreq(Term term) {
@@ -813,7 +811,7 @@
           Info info = getInfo(j);
           if (i >= info.sortedTerms.length) return null;
 //          if (DEBUG) System.err.println("TermEnum.term: " + i + ", " + info.sortedTerms[i].getKey());
-          return createTerm(info, j, (String) info.sortedTerms[i].getKey());
+          return createTerm(info, j, info.sortedTerms[i].getKey());
         }
         
         public int docFreq() {
@@ -833,7 +831,7 @@
           // Assertion: sortFields has already been called before
           Term template = info.template;
           if (template == null) { // not yet cached?
-            String fieldName = (String) sortedFields[pos].getKey();
+            String fieldName = sortedFields[pos].getKey();
             template = new Term(fieldName);
             info.template = template;
           }
@@ -948,9 +946,9 @@
       if (DEBUG) System.err.println("MemoryIndexReader.getTermFreqVectors");
       TermFreqVector[] vectors = new TermFreqVector[fields.size()];
 //      if (vectors.length == 0) return null;
-      Iterator iter = fields.keySet().iterator();
+      Iterator<String> iter = fields.keySet().iterator();
       for (int i=0; i < vectors.length; i++) {
-        String fieldName = (String) iter.next();
+        String fieldName = iter.next();
         vectors[i] = getTermFreqVector(docNumber, fieldName);
       }
       return vectors;
@@ -961,9 +959,8 @@
           if (DEBUG) System.err.println("MemoryIndexReader.getTermFreqVectors");
 
     //      if (vectors.length == 0) return null;
-          for (Iterator iterator = fields.keySet().iterator(); iterator.hasNext();)
+          for (final String fieldName : fields.keySet())
           {
-            String fieldName = (String) iterator.next();
             getTermFreqVector(docNumber, fieldName, mapper);
           }
       }
@@ -979,7 +976,7 @@
           mapper.setExpectations(field, info.sortedTerms.length, stride != 1, true);
           for (int i = info.sortedTerms.length; --i >=0;){
 
-              ArrayIntList positions = (ArrayIntList) info.sortedTerms[i].getValue();
+              ArrayIntList positions = info.sortedTerms[i].getValue();
               int size = positions.size();
               org.apache.lucene.index.TermVectorOffsetInfo[] offsets =
                 new org.apache.lucene.index.TermVectorOffsetInfo[size / stride];
@@ -989,9 +986,9 @@
                 int end = positions.get(j+1);
                 offsets[k] = new org.apache.lucene.index.TermVectorOffsetInfo(start, end);
               }
-              mapper.map((String)info.sortedTerms[i].getKey(),
-                         numPositions((ArrayIntList) info.sortedTerms[i].getValue()),
-                         offsets, ((ArrayIntList) info.sortedTerms[i].getValue()).toArray(stride));
+              mapper.map(info.sortedTerms[i].getKey(),
+                         numPositions(info.sortedTerms[i].getValue()),
+                         offsets, (info.sortedTerms[i].getValue()).toArray(stride));
           }
       }
 
@@ -1003,7 +1000,7 @@
       
       return new TermPositionVector() { 
   
-        private final Map.Entry[] sortedTerms = info.sortedTerms;
+        private final Map.Entry<String,ArrayIntList>[] sortedTerms = info.sortedTerms;
         
         public String getField() {
           return fieldName;
@@ -1016,7 +1013,7 @@
         public String[] getTerms() {
           String[] terms = new String[sortedTerms.length];
           for (int i=sortedTerms.length; --i >= 0; ) {
-            terms[i] = (String) sortedTerms[i].getKey();
+            terms[i] = sortedTerms[i].getKey();
           }
           return terms;
         }
@@ -1024,7 +1021,7 @@
         public int[] getTermFrequencies() {
           int[] freqs = new int[sortedTerms.length];
           for (int i=sortedTerms.length; --i >= 0; ) {
-            freqs[i] = numPositions((ArrayIntList) sortedTerms[i].getValue());
+            freqs[i] = numPositions(sortedTerms[i].getValue());
           }
           return freqs;
         }
@@ -1044,14 +1041,14 @@
         
         // lucene >= 1.4.3
         public int[] getTermPositions(int index) {
-          return ((ArrayIntList) sortedTerms[index].getValue()).toArray(stride);
+          return sortedTerms[index].getValue().toArray(stride);
         } 
         
         // lucene >= 1.9 (remove this method for lucene-1.4.3)
         public org.apache.lucene.index.TermVectorOffsetInfo[] getOffsets(int index) {
           if (stride == 1) return null; // no offsets stored
           
-          ArrayIntList positions = (ArrayIntList) sortedTerms[index].getValue();
+          ArrayIntList positions = sortedTerms[index].getValue();
           int size = positions.size();
           org.apache.lucene.index.TermVectorOffsetInfo[] offsets = 
             new org.apache.lucene.index.TermVectorOffsetInfo[size / stride];
@@ -1152,7 +1149,7 @@
       throw new UnsupportedOperationException();
     }
   
-    protected void doCommit(Map commitUserData) {
+    protected void doCommit(Map<String,String> commitUserData) {
       if (DEBUG) System.err.println("MemoryIndexReader.doCommit");
     }
   
@@ -1161,16 +1158,16 @@
     }
     
     // lucene >= 1.9 (remove this method for lucene-1.4.3)
-    public Collection getFieldNames(FieldOption fieldOption) {
+    public Collection<String> getFieldNames(FieldOption fieldOption) {
       if (DEBUG) System.err.println("MemoryIndexReader.getFieldNamesOption");
       if (fieldOption == FieldOption.UNINDEXED) 
-        return Collections.EMPTY_SET;
+        return Collections.emptySet();
       if (fieldOption == FieldOption.INDEXED_NO_TERMVECTOR) 
-        return Collections.EMPTY_SET;
+        return Collections.emptySet();
       if (fieldOption == FieldOption.TERMVECTOR_WITH_OFFSET && stride == 1) 
-        return Collections.EMPTY_SET;
+        return Collections.emptySet();
       if (fieldOption == FieldOption.TERMVECTOR_WITH_POSITION_OFFSET && stride == 1) 
-        return Collections.EMPTY_SET;
+        return Collections.emptySet();
       
       return Collections.unmodifiableSet(fields.keySet());
     }
Index: contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java
===================================================================
--- contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java	(revision 829570)
+++ contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java	(working copy)
@@ -238,12 +238,12 @@
 
     return new Analyzer() {
 
-      private final HashMap cache = new HashMap();
+      private final HashMap<String,ArrayList<AttributeSource.State>> cache = new HashMap<String,ArrayList<AttributeSource.State>>();
 
       public TokenStream tokenStream(String fieldName, Reader reader) {
-        final ArrayList tokens = (ArrayList) cache.get(fieldName);
+        final ArrayList<AttributeSource.State> tokens = cache.get(fieldName);
         if (tokens == null) { // not yet cached
-          final ArrayList tokens2 = new ArrayList();
+          final ArrayList<AttributeSource.State> tokens2 = new ArrayList<AttributeSource.State>();
           TokenStream tokenStream = new TokenFilter(child.tokenStream(fieldName, reader)) {
 
             public boolean incrementToken() throws IOException {
@@ -258,11 +258,11 @@
         } else { // already cached
           return new TokenStream() {
 
-            private Iterator iter = tokens.iterator();
+            private Iterator<AttributeSource.State> iter = tokens.iterator();
 
             public boolean incrementToken() {
               if (!iter.hasNext()) return false;
-              restoreState((AttributeSource.State) iter.next());
+              restoreState(iter.next());
               return true;
             }
           };
@@ -305,12 +305,12 @@
     if (limit <= 0) limit = Integer.MAX_VALUE;
     
     // compute frequencies of distinct terms
-    HashMap map = new HashMap();
+    HashMap<String,MutableInteger> map = new HashMap<String,MutableInteger>();
     TokenStream stream = analyzer.tokenStream("", new StringReader(text));
     TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
     try {
       while (stream.incrementToken()) {
-        MutableInteger freq = (MutableInteger) map.get(termAtt.term());
+        MutableInteger freq = map.get(termAtt.term());
         if (freq == null) {
           freq = new MutableInteger(1);
           map.put(termAtt.term(), freq);
@@ -329,17 +329,15 @@
     }
     
     // sort by frequency, text
-    Map.Entry[] entries = new Map.Entry[map.size()];
+    Map.Entry<String,MutableInteger>[] entries = new Map.Entry[map.size()];
     map.entrySet().toArray(entries);
-    Arrays.sort(entries, new Comparator() {
-      public int compare(Object o1, Object o2) {
-        Map.Entry e1 = (Map.Entry) o1;
-        Map.Entry e2 = (Map.Entry) o2;
-        int f1 = ((MutableInteger) e1.getValue()).intValue();
-        int f2 = ((MutableInteger) e2.getValue()).intValue();
+    Arrays.sort(entries, new Comparator<Map.Entry<String,MutableInteger>>() {
+      public int compare(Map.Entry<String,MutableInteger> e1, Map.Entry<String,MutableInteger> e2) {
+        int f1 = e1.getValue().intValue();
+        int f2 = e2.getValue().intValue();
         if (f2 - f1 != 0) return f2 - f1;
-        String s1 = (String) e1.getKey();
-        String s2 = (String) e2.getKey();
+        String s1 = e1.getKey();
+        String s2 = e2.getKey();
         return s1.compareTo(s2);
       }
     });
Index: contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
===================================================================
--- contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java	(revision 829570)
+++ contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java	(working copy)
@@ -72,9 +72,9 @@
   /** <code>"\\s+"</code>; Divides text at whitespaces (Character.isWhitespace(c)) */
   public static final Pattern WHITESPACE_PATTERN = Pattern.compile("\\s+");
   
-  private static final Set EXTENDED_ENGLISH_STOP_WORDS;
+  private static final Set<String> EXTENDED_ENGLISH_STOP_WORDS;
   static {
-    EXTENDED_ENGLISH_STOP_WORDS = new HashSet();
+    EXTENDED_ENGLISH_STOP_WORDS = new HashSet<String>();
   
     EXTENDED_ENGLISH_STOP_WORDS.addAll(Arrays.asList(new String[] {
       "a", "about", "above", "across", "adj", "after", "afterwards",
@@ -315,8 +315,8 @@
   }
     
   /** somewhat oversized to minimize hash collisions */
-  private static Set makeStopSet(Set stopWords) {
-    Set stops = new HashSet(stopWords.size() * 2, 0.3f); 
+  private static <T> Set<T> makeStopSet(Set<T> stopWords) {
+    Set<T> stops = new HashSet<T>(stopWords.size() * 2, 0.3f); 
     stops.addAll(stopWords);
     return stops;
 //    return Collections.unmodifiableSet(stops);
Index: contrib/memory/src/java/org/apache/lucene/index/memory/SynonymMap.java
===================================================================
--- contrib/memory/src/java/org/apache/lucene/index/memory/SynonymMap.java	(revision 829570)
+++ contrib/memory/src/java/org/apache/lucene/index/memory/SynonymMap.java	(working copy)
@@ -76,7 +76,7 @@
 public class SynonymMap {
 
   /** the index data; Map<String word, String[] synonyms> */
-  private final HashMap table;
+  private final HashMap<String,String[]> table;
   
   private static final String[] EMPTY = new String[0];
   
@@ -93,7 +93,7 @@
    *             if an error occured while reading the stream.
    */
   public SynonymMap(InputStream input) throws IOException {
-    this.table = input == null ? new HashMap(0) : read(toByteArray(input));
+    this.table = input == null ? new HashMap<String,String[]>(0) : read(toByteArray(input));
   }
   
   /**
@@ -123,7 +123,7 @@
    */
   public String toString() {
     StringBuilder buf = new StringBuilder();
-    Iterator iter = new TreeMap(table).keySet().iterator();
+    Iterator<String> iter = new TreeMap<String,String[]>(table).keySet().iterator();
     int count = 0;
     int f0 = 0;
     int f1 = 0;
@@ -131,7 +131,7 @@
     int f3 = 0;
     
     while (iter.hasNext()) {
-      String word = (String) iter.next();
+      String word = iter.next();
       buf.append(word + ":");
       String[] synonyms = getSynonyms(word);
       buf.append(Arrays.asList(synonyms));
@@ -168,12 +168,12 @@
     return true;
   }
 
-  private HashMap read(byte[] data) {
+  private HashMap<String,String[]> read(byte[] data) {
     int WORDS  = (int) (76401 / 0.7); // presizing
     int GROUPS = (int) (88022 / 0.7); // presizing
-    HashMap word2Groups = new HashMap(WORDS);  // Map<String word, int[] groups>
-    HashMap group2Words = new HashMap(GROUPS); // Map<int group, String[] words>
-    HashMap internedWords = new HashMap(WORDS);// Map<String word, String word>
+    HashMap<String,ArrayList<Integer>> word2Groups = new HashMap<String,ArrayList<Integer>>(WORDS);  // Map<String word, int[] groups>
+    HashMap<Integer,ArrayList<String>> group2Words = new HashMap<Integer,ArrayList<String>>(GROUPS); // Map<int group, String[] words>
+    HashMap<String,String> internedWords = new HashMap<String,String>(WORDS);// Map<String word, String word>
 
     Charset charset = Charset.forName("UTF-8");
     int lastNum = -1;
@@ -226,7 +226,7 @@
       /* Part C: Add (group,word) to tables */
       
       // ensure compact string representation, minimizing memory overhead
-      String w = (String) internedWords.get(word);
+      String w = internedWords.get(word);
       if (w == null) {
         word = new String(word); // ensure compact string
         internedWords.put(word, word);
@@ -242,17 +242,17 @@
       }
       
       // add word --> group
-      ArrayList groups = (ArrayList) word2Groups.get(word);
+      ArrayList<Integer> groups =  word2Groups.get(word);
       if (groups == null) {
-        groups = new ArrayList(1);
+        groups = new ArrayList<Integer>(1);
         word2Groups.put(word, groups);
       }
       groups.add(group);
 
       // add group --> word
-      ArrayList words = (ArrayList) group2Words.get(group);
+      ArrayList<String> words = group2Words.get(group);
       if (words == null) {
-        words = new ArrayList(1);
+        words = new ArrayList<String>(1);
         group2Words.put(group, words);
       } 
       words.add(word);
@@ -265,25 +265,26 @@
     /* Part E: minimize memory consumption by a factor 3 (or so) */
 //    if (true) return word2Syns;
     word2Groups = null; // help gc
-    group2Words = null; // help gc    
+    //TODO: word2Groups.clear(); would be more appropriate  ? 
+    group2Words = null; // help gc
+    //TODO: group2Words.clear(); would be more appropriate  ? 
+    
     return optimize(word2Syns, internedWords);
   }
   
-  private HashMap createIndex(Map word2Groups, Map group2Words) {
-    HashMap word2Syns = new HashMap();
-    Iterator iter = word2Groups.entrySet().iterator();
+  private HashMap<String,String[]> createIndex(Map<String,ArrayList<Integer>> word2Groups, Map<Integer,ArrayList<String>> group2Words) {
+    HashMap<String,String[]> word2Syns = new HashMap<String,String[]>();
     
-    while (iter.hasNext()) { // for each word
-      Map.Entry entry = (Map.Entry) iter.next();
-      ArrayList group = (ArrayList) entry.getValue();     
-      String word = (String) entry.getKey();
+    for (final Map.Entry<String,ArrayList<Integer>> entry : word2Groups.entrySet()) { // for each word
+      ArrayList<Integer> group = entry.getValue();     
+      String word = entry.getKey();
       
 //      HashSet synonyms = new HashSet();
-      TreeSet synonyms = new TreeSet();
+      TreeSet<String> synonyms = new TreeSet<String>();
       for (int i=group.size(); --i >= 0; ) { // for each groupID of word
-        ArrayList words = (ArrayList) group2Words.get(group.get(i));
+        ArrayList<String> words = group2Words.get(group.get(i));
         for (int j=words.size(); --j >= 0; ) { // add all words       
-          Object synonym = words.get(j); // note that w and word are interned
+          String synonym = words.get(j); // note that w and word are interned
           if (synonym != word) { // a word is implicitly it's own synonym
             synonyms.add(synonym);
           }
@@ -294,7 +295,7 @@
       if (size > 0) {
         String[] syns = new String[size];
         if (size == 1)  
-          syns[0] = (String) synonyms.first();
+          syns[0] = synonyms.first();
         else
           synonyms.toArray(syns);
 //        if (syns.length > 1) Arrays.sort(syns);
@@ -306,7 +307,7 @@
     return word2Syns;
   }
 
-  private HashMap optimize(HashMap word2Syns, HashMap internedWords) {
+  private HashMap<String,String[]> optimize(HashMap word2Syns, HashMap<String,String> internedWords) {
     if (DEBUG) {
       System.err.println("before gc");
       for (int i=0; i < 10; i++) System.gc();
@@ -318,11 +319,11 @@
     int size = word2Syns.size();
     String[][] allSynonyms = new String[size][];
     String[] words = new String[size];
-    Iterator iter = word2Syns.entrySet().iterator();
+    Iterator<Map.Entry<String,String[]>> iter = word2Syns.entrySet().iterator();
     for (int j=0; j < size; j++) {
-      Map.Entry entry = (Map.Entry) iter.next();
-      allSynonyms[j] = (String[]) entry.getValue(); 
-      words[j] = (String) entry.getKey();
+      Map.Entry<String,String[]> entry = iter.next();
+      allSynonyms[j] = entry.getValue(); 
+      words[j] = entry.getKey();
       len += words[j].length();
     }
     
@@ -343,7 +344,7 @@
     for (int j=0; j < size; j++) {
       String[] syns = allSynonyms[j];
       for (int k=syns.length; --k >= 0; ) {
-        syns[k] = (String) internedWords.get(syns[k]);
+        syns[k] = internedWords.get(syns[k]);
       }
       Object replacement = syns;
       if (syns.length == 1) replacement = syns[0]; // minimize memory consumption some more
