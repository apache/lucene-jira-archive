Index: contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Iterator;
 import java.util.List;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -62,7 +61,7 @@
  * 
  */
 public class ComplexPhraseQueryParser extends QueryParser {
-  private ArrayList/*<ComplexPhraseQuery>*/complexPhrases = null;
+  private ArrayList<ComplexPhraseQuery> complexPhrases = null;
 
   private boolean isPass2ResolvingPhrases;
 
@@ -102,7 +101,7 @@
 
     // First pass - parse the top-level query recording any PhraseQuerys
     // which will need to be resolved
-    complexPhrases = new ArrayList/*<ComplexPhraseQuery>*/();
+    complexPhrases = new ArrayList<ComplexPhraseQuery>();
     Query q = super.parse(query);
 
     // Perform second pass, using this QueryParser to parse any nested
@@ -110,8 +109,7 @@
     // set of syntax restrictions (i.e. all fields must be same)
     isPass2ResolvingPhrases = true;
     try {
-      for (Iterator iterator = complexPhrases.iterator(); iterator.hasNext();) {
-        currentPhraseQuery = (ComplexPhraseQuery) iterator.next();
+      for (final ComplexPhraseQuery currentPhraseQuery : complexPhrases) {
         // in each phrase, now parse the contents between quotes as a
         // separate parse operation
         currentPhraseQuery.parsePhraseElements(this);
@@ -247,10 +245,10 @@
         }
 
         if (qc instanceof BooleanQuery) {
-          ArrayList sc = new ArrayList();
+          ArrayList<SpanQuery> sc = new ArrayList<SpanQuery>();
           addComplexPhraseClause(sc, (BooleanQuery) qc);
           if (sc.size() > 0) {
-            allSpanClauses[i] = (SpanQuery) sc.get(0);
+            allSpanClauses[i] = sc.get(0);
           } else {
             // Insert fake term e.g. phrase query was for "Fred Smithe*" and
             // there were no "Smithe*" terms - need to
@@ -278,14 +276,14 @@
       // Complex case - we have mixed positives and negatives in the
       // sequence.
       // Need to return a SpanNotQuery
-      ArrayList positiveClauses = new ArrayList();
+      ArrayList<SpanQuery> positiveClauses = new ArrayList<SpanQuery>();
       for (int j = 0; j < allSpanClauses.length; j++) {
         if (!bclauses[j].getOccur().equals(BooleanClause.Occur.MUST_NOT)) {
           positiveClauses.add(allSpanClauses[j]);
         }
       }
 
-      SpanQuery[] includeClauses = (SpanQuery[]) positiveClauses
+      SpanQuery[] includeClauses = positiveClauses
           .toArray(new SpanQuery[positiveClauses.size()]);
 
       SpanQuery include = null;
@@ -304,9 +302,9 @@
       return snot;
     }
 
-    private void addComplexPhraseClause(List spanClauses, BooleanQuery qc) {
-      ArrayList ors = new ArrayList();
-      ArrayList nots = new ArrayList();
+    private void addComplexPhraseClause(List<SpanQuery> spanClauses, BooleanQuery qc) {
+      ArrayList<SpanQuery> ors = new ArrayList<SpanQuery>();
+      ArrayList<SpanQuery> nots = new ArrayList<SpanQuery>();
       BooleanClause[] bclauses = qc.getClauses();
 
       // For all clauses e.g. one* two~
@@ -314,7 +312,7 @@
         Query childQuery = bclauses[i].getQuery();
 
         // select the list to which we will add these options
-        ArrayList chosenList = ors;
+        ArrayList<SpanQuery> chosenList = ors;
         if (bclauses[i].getOccur() == BooleanClause.Occur.MUST_NOT) {
           chosenList = nots;
         }
@@ -336,12 +334,12 @@
       if (ors.size() == 0) {
         return;
       }
-      SpanOrQuery soq = new SpanOrQuery((SpanQuery[]) ors
+      SpanOrQuery soq = new SpanOrQuery(ors
           .toArray(new SpanQuery[ors.size()]));
       if (nots.size() == 0) {
         spanClauses.add(soq);
       } else {
-        SpanOrQuery snqs = new SpanOrQuery((SpanQuery[]) nots
+        SpanOrQuery snqs = new SpanOrQuery(nots
             .toArray(new SpanQuery[nots.size()]));
         SpanNotQuery snq = new SpanNotQuery(soq, snqs);
         spanClauses.add(snq);
Index: contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java	(working copy)
@@ -23,7 +23,6 @@
 import java.util.List;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 import org.apache.lucene.queryParser.ParseException;
@@ -76,8 +75,8 @@
    * @throws ParseException
    */
   protected Query getWildcardQuery(String field, String termStr) throws ParseException {
-    List tlist = new ArrayList();
-    List wlist = new ArrayList();
+    List<String> tlist = new ArrayList<String>();
+    List<String> wlist = new ArrayList<String>();
     /* somewhat a hack: find/store wildcard chars
      * in order to put them back after analyzing */
     boolean isWithinToken = (!termStr.startsWith("?") && !termStr.startsWith("*"));
@@ -145,8 +144,8 @@
         /* if wlist contains one wildcard, it must be at the end, because:
          * 1) wildcards are not allowed in 1st position of a term by QueryParser
          * 2) if wildcard was *not* in end, there would be *two* or more tokens */
-        return super.getWildcardQuery(field, (String) tlist.get(0)
-            + (((String) wlist.get(0)).toString()));
+        return super.getWildcardQuery(field, tlist.get(0)
+            + wlist.get(0).toString());
       } else {
         /* we should never get here! if so, this method was called
          * with a termStr containing no wildcard ... */
@@ -157,9 +156,9 @@
        * with wildcards put back in postion */
       StringBuilder sb = new StringBuilder();
       for (int i = 0; i < tlist.size(); i++) {
-        sb.append((String) tlist.get(i));
+        sb.append( tlist.get(i));
         if (wlist != null && wlist.size() > i) {
-          sb.append((String) wlist.get(i));
+          sb.append(wlist.get(i));
         }
       }
       return super.getWildcardQuery(field, sb.toString());
@@ -188,7 +187,7 @@
   protected Query getPrefixQuery(String field, String termStr) throws ParseException {
     // get Analyzer from superclass and tokenize the term
     TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));
-    List tlist = new ArrayList();
+    List<String> tlist = new ArrayList<String>();
     TermAttribute termAtt = source.addAttribute(TermAttribute.class);
     
     while (true) {
@@ -207,7 +206,7 @@
     }
 
     if (tlist.size() == 1) {
-      return super.getPrefixQuery(field, (String) tlist.get(0));
+      return super.getPrefixQuery(field, tlist.get(0));
     } else {
       /* this means that the analyzer used either added or consumed
        * (common for a stemmer) tokens, and we can't build a PrefixQuery */
Index: contrib/misc/src/java/org/apache/lucene/queryParser/precedence/FastCharStream.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/queryParser/precedence/FastCharStream.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/queryParser/precedence/FastCharStream.java	(working copy)
@@ -18,7 +18,6 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.queryParser.*;
 
 import java.io.*;
 
Index: contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java	(working copy)
@@ -158,7 +158,7 @@
     if (indexes.size() == 1) {
       input = indexes.get(0);
     } else {
-      input = new MultiReader((IndexReader[])indexes.toArray(new IndexReader[indexes.size()]));
+      input = new MultiReader(indexes.toArray(new IndexReader[indexes.size()]));
     }
     splitter.split(input, dirs, seq);
   }
Index: contrib/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java	(working copy)
@@ -103,7 +103,7 @@
     }
   }
   
-  private boolean isOptimized(SegmentInfos infos, IndexWriter writer, int maxNumSegments, Set segmentsToOptimize) throws IOException {
+  private boolean isOptimized(SegmentInfos infos, IndexWriter writer, int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {
     final int numSegments = infos.size();
     int numToOptimize = 0;
     SegmentInfo optimizeInfo = null;
@@ -128,7 +128,7 @@
   }
 
   @Override
-  public MergeSpecification findMergesForOptimize(SegmentInfos infos, int maxNumSegments, Set segmentsToOptimize) throws IOException {
+  public MergeSpecification findMergesForOptimize(SegmentInfos infos, int maxNumSegments, Set<SegmentInfo> segmentsToOptimize) throws IOException {
     
     assert maxNumSegments > 0;
 
Index: contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/index/TermVectorAccessor.java	(working copy)
@@ -5,8 +5,6 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Collection;
-import java.util.Iterator;
 /*
  *  Licensed under the Apache License, Version 2.0 (the "License");
  *  you may not use this file except in compliance with the License.
@@ -68,13 +66,13 @@
   }
 
   /** Instance reused to save garbage collector some time */
-  private List/*<String>*/ tokens;
+  private List<String> tokens;
 
   /** Instance reused to save garbage collector some time */
-  private List/*<int[]>*/ positions;
+  private List<int[]> positions;
 
   /** Instance reused to save garbage collector some time */
-  private List/*<Integer>*/ frequencies;
+  private List<Integer> frequencies;
 
 
   /**
@@ -90,9 +88,9 @@
   private void build(IndexReader indexReader, String field, TermVectorMapper mapper, int documentNumber) throws IOException {
 
     if (tokens == null) {
-      tokens = new ArrayList/*<String>*/(500);
-      positions = new ArrayList/*<int[]>*/(500);
-      frequencies = new ArrayList/*<Integer>*/(500);
+      tokens = new ArrayList<String>(500);
+      positions = new ArrayList<int[]>(500);
+      frequencies = new ArrayList<Integer>(500);
     } else {
       tokens.clear();
       frequencies.clear();
@@ -127,7 +125,7 @@
       mapper.setDocumentNumber(documentNumber);
       mapper.setExpectations(field, tokens.size(), false, !mapper.isIgnoringPositions());
       for (int i = 0; i < tokens.size(); i++) {
-        mapper.map((String) tokens.get(i), ((Integer) frequencies.get(i)).intValue(), (TermVectorOffsetInfo[]) null, (int[]) positions.get(i));
+        mapper.map(tokens.get(i), frequencies.get(i).intValue(), (TermVectorOffsetInfo[]) null, positions.get(i));
       }
     }
     termEnum.close();
Index: contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java	(working copy)
@@ -55,8 +55,7 @@
     Similarity s = null;
     if (!args[1].equals("-n")) {
       try {
-        Class simClass = Class.forName(args[1]);
-        s = (Similarity)simClass.newInstance();
+        s = Class.forName(args[1]).asSubclass(Similarity.class).newInstance();
       } catch (Exception e) {
         System.err.println("Couldn't instantiate similarity with empty constructor: " + args[1]);
         e.printStackTrace(System.err);
@@ -148,7 +147,7 @@
           if (sim == null)
             reader.setNorm(d, fieldName, fakeNorms[0]);
           else
-            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));
+            reader.setNorm(d, fieldName, Similarity.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));
         }
       }
       
Index: contrib/misc/src/java/org/apache/lucene/index/IndexSplitter.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/IndexSplitter.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/index/IndexSplitter.java	(working copy)
@@ -78,14 +78,14 @@
       for (int x = 2; x < args.length; x++) {
         segs.add(args[x]);
       }
-      is.remove((String[]) segs.toArray(new String[0]));
+      is.remove(segs.toArray(new String[0]));
     } else {
       File targetDir = new File(args[1]);
       List<String> segs = new ArrayList<String>();
       for (int x = 2; x < args.length; x++) {
         segs.add(args[x]);
       }
-      is.split(targetDir, (String[]) segs.toArray(new String[0]));
+      is.split(targetDir, segs.toArray(new String[0]));
     }
   }
 
@@ -137,9 +137,8 @@
       SegmentInfo info = getInfo(n);
       destInfos.add(info);
       // now copy files over
-      List files = info.files();
-      for (int x = 0; x < files.size(); x++) {
-        String srcName = (String) files.get(x);
+      List<String> files = info.files();
+      for (final String srcName : files) {
         File srcFile = new File(dir, srcName);
         File destFile = new File(destDir, srcName);
         copyFile(srcFile, destFile);
Index: contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java	(working copy)
@@ -17,7 +17,6 @@
 
 package org.apache.lucene.misc;
 
-import org.apache.lucene.search.Similarity;
 import org.apache.lucene.search.DefaultSimilarity;
 import org.apache.lucene.index.FieldInvertState;
 
@@ -51,10 +50,10 @@
   private int ln_max = 1;
   private float ln_steep = 0.5f;
 
-  private Map ln_mins = new HashMap(7);
-  private Map ln_maxs = new HashMap(7);
-  private Map ln_steeps = new HashMap(7);
-  private Map ln_overlaps = new HashMap(7);
+  private Map<String,Number> ln_maxs = new HashMap<String,Number>(7);
+  private Map<String,Number> ln_mins = new HashMap<String,Number>(7);
+  private Map<String,Float> ln_steeps = new HashMap<String,Float>(7);
+  private Map<String,Boolean> ln_overlaps = new HashMap<String,Boolean>(7);
 
   private float tf_base = 0.0f;
   private float tf_min = 0.0f;
@@ -139,7 +138,7 @@
     final int numTokens;
     boolean overlaps = discountOverlaps;
     if (ln_overlaps.containsKey(fieldName)) {
-      overlaps = ((Boolean)ln_overlaps.get(fieldName)).booleanValue();
+      overlaps = ln_overlaps.get(fieldName).booleanValue();
     }
     if (overlaps)
       numTokens = state.getLength() - state.getNumOverlap();
@@ -173,13 +172,13 @@
     float s = ln_steep;
   
     if (ln_mins.containsKey(fieldName)) {
-      l = ((Number)ln_mins.get(fieldName)).intValue();
+      l = ln_mins.get(fieldName).intValue();
     }
     if (ln_maxs.containsKey(fieldName)) {
-      h = ((Number)ln_maxs.get(fieldName)).intValue();
+      h = ln_maxs.get(fieldName).intValue();
     }
     if (ln_steeps.containsKey(fieldName)) {
-      s = ((Number)ln_steeps.get(fieldName)).floatValue();
+      s = ln_steeps.get(fieldName).floatValue();
     }
   
     return (float)
Index: contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java	(working copy)
@@ -65,7 +65,7 @@
       }
     }
     while (tiq.size() != 0) {
-      TermInfo termInfo = (TermInfo) tiq.pop();
+      TermInfo termInfo = tiq.pop();
       System.out.println(termInfo.term + " " + termInfo.docFreq);
     }
 
Index: contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java	(revision 829579)
+++ contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java	(working copy)
@@ -58,8 +58,7 @@
     
     Similarity s = null;
     try {
-      Class simClass = Class.forName(args[1]);
-      s = (Similarity)simClass.newInstance();
+      s = Class.forName(args[1]).asSubclass(Similarity.class).newInstance();
     } catch (Exception e) {
       System.err.println("Couldn't instantiate similarity with empty constructor: " + args[1]);
       e.printStackTrace(System.err);
@@ -142,7 +141,7 @@
       reader = IndexReader.open(dir, false); 
       for (int d = 0; d < termCounts.length; d++) {
         if (! reader.isDeleted(d)) {
-          byte norm = sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d]));
+          byte norm = Similarity.encodeNorm(sim.lengthNorm(fieldName, termCounts[d]));
           reader.setNorm(d, fieldName, norm);
         }
       }
