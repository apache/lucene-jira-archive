Index: src/java/org/apache/lucene/search/MultiTermQuery.java
===================================================================
--- src/java/org/apache/lucene/search/MultiTermQuery.java	(revision 826470)
+++ src/java/org/apache/lucene/search/MultiTermQuery.java	(working copy)
@@ -21,11 +21,11 @@
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.Iterator;
 
+
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.ToStringUtils;
+
 import org.apache.lucene.queryParser.QueryParser; // for javadoc
 
 /**
@@ -217,7 +217,7 @@
       // exhaust the enum before hitting either of the
       // cutoffs, we use ConstantBooleanQueryRewrite; else,
       // ConstantFilterRewrite:
-      final Collection pendingTerms = new ArrayList();
+      final Collection<Term> pendingTerms = new ArrayList<Term>();
       final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());
       final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);
       int docVisitCount = 0;
@@ -244,10 +244,9 @@
             // Enumeration is done, and we hit a small
             // enough number of terms & docs -- just make a
             // BooleanQuery, now
-            Iterator it = pendingTerms.iterator();
             BooleanQuery bq = new BooleanQuery(true);
-            while(it.hasNext()) {
-              TermQuery tq = new TermQuery((Term) it.next());
+            for (final Term term: pendingTerms) {
+              TermQuery tq = new TermQuery(term);
               bq.add(tq, BooleanClause.Occur.SHOULD);
             }
             // Strip scores
Index: src/java/org/apache/lucene/search/FilterManager.java
===================================================================
--- src/java/org/apache/lucene/search/FilterManager.java	(revision 826470)
+++ src/java/org/apache/lucene/search/FilterManager.java	(working copy)
@@ -46,7 +46,7 @@
   protected static final long DEFAULT_CACHE_SLEEP_TIME = 1000 * 60 * 10;
 
   /** The cache itself */
-  protected Map           cache;
+  protected Map<Integer,FilterItem>           cache;
   /** Maximum allowed cache size */
   protected int           cacheCleanSize;
   /** Cache cleaning frequency */
@@ -65,7 +65,7 @@
    * Sets up the FilterManager singleton.
    */
   protected FilterManager() {
-    cache            = new HashMap();
+    cache            = new HashMap<Integer,FilterItem>();
     cacheCleanSize   = DEFAULT_CACHE_CLEAN_SIZE; // Let the cache get to 100 items
     cleanSleepTime   = DEFAULT_CACHE_SLEEP_TIME; // 10 minutes between cleanings
 
@@ -103,7 +103,7 @@
   public Filter getFilter(Filter filter) {
     synchronized(cache) {
       FilterItem fi = null;
-      fi = (FilterItem)cache.get(Integer.valueOf(filter.hashCode()));
+      fi = cache.get(Integer.valueOf(filter.hashCode()));
       if (fi != null) {
         fi.timestamp = new Date().getTime();
         return fi.filter;
@@ -146,14 +146,13 @@
   protected class FilterCleaner implements Runnable  {
 
     private boolean running = true;
-    private TreeSet sortedFilterItems;
+    private TreeSet<Map.Entry<Integer,FilterItem>> sortedFilterItems;
 
     public FilterCleaner() {
-      sortedFilterItems = new TreeSet(new Comparator() {
-        public int compare(Object a, Object b) {
-          if( a instanceof Map.Entry && b instanceof Map.Entry) {
-            FilterItem fia = (FilterItem) ((Map.Entry)a).getValue();
-            FilterItem fib = (FilterItem) ((Map.Entry)b).getValue();
+      sortedFilterItems = new TreeSet<Map.Entry<Integer,FilterItem>>(new Comparator<Map.Entry<Integer,FilterItem>>() {
+        public int compare(Map.Entry<Integer,FilterItem> a, Map.Entry<Integer,FilterItem> b) {
+            FilterItem fia = a.getValue();
+            FilterItem fib = b.getValue();
             if ( fia.timestamp == fib.timestamp ) {
               return 0;
             }
@@ -163,9 +162,7 @@
             }
             // larger timestamp last
             return 1;
-          } else {
-            throw new ClassCastException("Objects are not Map.Entry");
-          }
+          
         }
       });
     }
@@ -180,12 +177,12 @@
           sortedFilterItems.clear();
           synchronized (cache) {
             sortedFilterItems.addAll(cache.entrySet());
-            Iterator it = sortedFilterItems.iterator();
+            Iterator<Map.Entry<Integer,FilterItem>> it = sortedFilterItems.iterator();
             int numToDelete = (int) ((cache.size() - cacheCleanSize) * 1.5);
             int counter = 0;
             // loop over the set and delete all of the cache entries not used in a while
             while (it.hasNext() && counter++ < numToDelete) {
-              Map.Entry entry = (Map.Entry)it.next();
+              Map.Entry<Integer,FilterItem> entry = it.next();
               cache.remove(entry.getKey());
             }
           }
Index: src/java/org/apache/lucene/search/CachingSpanFilter.java
===================================================================
--- src/java/org/apache/lucene/search/CachingSpanFilter.java	(revision 826470)
+++ src/java/org/apache/lucene/search/CachingSpanFilter.java	(working copy)
@@ -19,7 +19,7 @@
 import org.apache.lucene.index.IndexReader;
 
 import java.io.IOException;
-import java.util.BitSet;
+
 import java.util.Map;
 import java.util.WeakHashMap;
 
@@ -33,7 +33,7 @@
   /**
    * A transient Filter cache.
    */
-  protected transient Map cache;
+  protected transient Map<IndexReader,SpanFilterResult> cache;
 
   /**
    * @param filter Filter to cache results of
@@ -50,11 +50,11 @@
   private SpanFilterResult getCachedResult(IndexReader reader) throws IOException {
     SpanFilterResult result = null;
     if (cache == null) {
-      cache = new WeakHashMap();
+      cache = new WeakHashMap<IndexReader,SpanFilterResult>();
     }
 
     synchronized (cache) {  // check cache
-      result = (SpanFilterResult) cache.get(reader);
+      result = cache.get(reader);
       if (result == null) {
         result = filter.bitSpans(reader);
         cache.put(reader, result);
Index: src/java/org/apache/lucene/search/Similarity.java
===================================================================
--- src/java/org/apache/lucene/search/Similarity.java	(revision 826470)
+++ src/java/org/apache/lucene/search/Similarity.java	(working copy)
@@ -27,8 +27,8 @@
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.IdentityHashMap;
-import java.util.Iterator;
 
+
 /** 
  * Expert: Scoring API.
  *
@@ -787,11 +787,11 @@
    * @return idf score factor
    * @deprecated see {@link #idfExplain(Collection, Searcher)}
    */
-  public float idf(Collection terms, Searcher searcher) throws IOException {
+  public float idf(Collection<Term> terms, Searcher searcher) throws IOException {
     float idf = 0.0f;
-    Iterator i = terms.iterator();
-    while (i.hasNext()) {
-      idf += idf((Term)i.next(), searcher);
+
+    for(final Term term: terms) {
+      idf += idf(term, searcher);
     }
     return idf;
   }
@@ -810,7 +810,7 @@
    *         for each term.
    * @throws IOException
    */
-  public IDFExplanation idfExplain(Collection terms, Searcher searcher) throws IOException {
+  public IDFExplanation idfExplain(Collection<Term> terms, Searcher searcher) throws IOException {
     if(supportedMethods.overridesCollectionIDF) {
       final float idf = idf(terms, searcher);
       return new IDFExplanation() {
@@ -827,9 +827,7 @@
     final int max = searcher.maxDoc();
     float idf = 0.0f;
     final StringBuilder exp = new StringBuilder();
-    Iterator i = terms.iterator();
-    while (i.hasNext()) {
-      Term term = (Term)i.next();
+    for (final Term term : terms ) {
       final int df = searcher.docFreq(term);
       idf += idf(df, max);
       exp.append(" ");
@@ -955,7 +953,7 @@
   }
   
   /** @deprecated Remove this when old API is removed! */
-  private static final IdentityHashMap/*<Class<? extends Similarity>,MethodSupport>*/ knownMethodSupport = new IdentityHashMap();
+  private static final IdentityHashMap<Class<? extends Similarity>,MethodSupport> knownMethodSupport = new IdentityHashMap();
   
   /** @deprecated Remove this when old API is removed! */
   private static MethodSupport getSupportedMethods(Class clazz) {
Index: src/java/org/apache/lucene/search/SpanQueryFilter.java
===================================================================
--- src/java/org/apache/lucene/search/SpanQueryFilter.java	(revision 826470)
+++ src/java/org/apache/lucene/search/SpanQueryFilter.java	(working copy)
@@ -63,7 +63,7 @@
 
     final OpenBitSet bits = new OpenBitSet(reader.maxDoc());
     Spans spans = query.getSpans(reader);
-    List tmp = new ArrayList(20);
+    List<SpanFilterResult.PositionInfo> tmp = new ArrayList<SpanFilterResult.PositionInfo>(20);
     int currentDoc = -1;
     SpanFilterResult.PositionInfo currentInfo = null;
     while (spans.next())
Index: src/java/org/apache/lucene/search/SpanFilterResult.java
===================================================================
--- src/java/org/apache/lucene/search/SpanFilterResult.java	(revision 826470)
+++ src/java/org/apache/lucene/search/SpanFilterResult.java	(working copy)
@@ -16,7 +16,7 @@
  */
 
 import java.util.ArrayList;
-import java.util.BitSet;
+
 import java.util.List;
 
 
@@ -29,14 +29,14 @@
  **/
 public class SpanFilterResult {
   private DocIdSet docIdSet;
-  private List positions;//Spans spans;
+  private List<PositionInfo> positions;//Spans spans;
   
   /**
   *
   * @param docIdSet The DocIdSet for the Filter
   * @param positions A List of {@link org.apache.lucene.search.SpanFilterResult.PositionInfo} objects
   */
-  public SpanFilterResult(DocIdSet docIdSet, List positions) {
+  public SpanFilterResult(DocIdSet docIdSet, List<PositionInfo> positions) {
     this.docIdSet = docIdSet;
     this.positions = positions;
   }
@@ -46,7 +46,7 @@
    * Entries are increasing by document order
    * @return A List of PositionInfo objects
    */
-  public List getPositions() {
+  public List<PositionInfo> getPositions() {
     return positions;
   }
 
@@ -57,12 +57,12 @@
 
   public static class PositionInfo {
     private int doc;
-    private List positions;
+    private List<StartEnd> positions;
 
 
     public PositionInfo(int doc) {
       this.doc = doc;
-      positions = new ArrayList();
+      positions = new ArrayList<StartEnd>();
     }
 
     public void addPosition(int start, int end)
@@ -76,9 +76,9 @@
 
     /**
      *
-     * @return A List of {@link org.apache.lucene.search.SpanFilterResult.StartEnd} objects
+     * @return Positions
      */
-    public List getPositions() {
+    public List<StartEnd> getPositions() {
       return positions;
     }
   }
Index: src/java/org/apache/lucene/search/ConjunctionScorer.java
===================================================================
--- src/java/org/apache/lucene/search/ConjunctionScorer.java	(revision 826470)
+++ src/java/org/apache/lucene/search/ConjunctionScorer.java	(working copy)
@@ -29,8 +29,8 @@
   private final float coord;
   private int lastDoc = -1;
 
-  public ConjunctionScorer(Similarity similarity, Collection scorers) throws IOException {
-    this(similarity, (Scorer[]) scorers.toArray(new Scorer[scorers.size()]));
+  public ConjunctionScorer(Similarity similarity, Collection<Scorer> scorers) throws IOException {
+    this(similarity, scorers.toArray(new Scorer[scorers.size()]));
   }
 
   public ConjunctionScorer(Similarity similarity, Scorer[] scorers) throws IOException {
@@ -52,9 +52,9 @@
     // it will already start off sorted (all scorers on same doc).
     
     // note that this comparator is not consistent with equals!
-    Arrays.sort(scorers, new Comparator() {         // sort the array
-      public int compare(Object o1, Object o2) {
-        return ((Scorer) o1).docID() - ((Scorer) o2).docID();
+    Arrays.sort(scorers, new Comparator<Scorer>() {         // sort the array
+      public int compare(Scorer o1, Scorer o2) {
+        return o1.docID() - o2.docID();
       }
     });
 
Index: src/java/org/apache/lucene/search/SloppyPhraseScorer.java
===================================================================
--- src/java/org/apache/lucene/search/SloppyPhraseScorer.java	(revision 826470)
+++ src/java/org/apache/lucene/search/SloppyPhraseScorer.java	(working copy)
@@ -146,14 +146,14 @@
         if (!checkedRepeats) {
             checkedRepeats = true;
             // check for repeats
-            HashMap m = null;
+            HashMap<PhrasePositions, Object> m = null;
             for (PhrasePositions pp = first; pp != null; pp = pp.next) {
                 int tpPos = pp.position + pp.offset;
                 for (PhrasePositions pp2 = pp.next; pp2 != null; pp2 = pp2.next) {
                     int tpPos2 = pp2.position + pp2.offset;
                     if (tpPos2 == tpPos) { 
                         if (m == null)
-                            m = new HashMap();
+                            m = new HashMap<PhrasePositions, Object>();
                         pp.repeats = true;
                         pp2.repeats = true;
                         m.put(pp,null);
@@ -162,7 +162,7 @@
                 }
             }
             if (m!=null)
-                repeats = (PhrasePositions[]) m.keySet().toArray(new PhrasePositions[0]);
+                repeats = m.keySet().toArray(new PhrasePositions[0]);
         }
         
         // with repeats must advance some repeating pp's so they all start with differing tp's       
Index: src/java/org/apache/lucene/search/MultiPhraseQuery.java
===================================================================
--- src/java/org/apache/lucene/search/MultiPhraseQuery.java	(revision 826470)
+++ src/java/org/apache/lucene/search/MultiPhraseQuery.java	(working copy)
@@ -38,8 +38,8 @@
  */
 public class MultiPhraseQuery extends Query {
   private String field;
-  private ArrayList termArrays = new ArrayList();
-  private ArrayList positions = new ArrayList();
+  private ArrayList<Term[]> termArrays = new ArrayList<Term[]>();
+  private ArrayList<Integer> positions = new ArrayList<Integer>();
 
   private int slop = 0;
 
@@ -98,7 +98,7 @@
    * Returns a List<Term[]> of the terms in the multiphrase.
    * Do not modify the List or its contents.
    */
-  public List getTermArrays() {
+  public List<Term[]> getTermArrays() {
 	  return Collections.unmodifiableList(termArrays);
   }
 
@@ -114,10 +114,9 @@
 
   // inherit javadoc
   public void extractTerms(Set<Term> terms) {
-    for (Iterator iter = termArrays.iterator(); iter.hasNext();) {
-      Term[] arr = (Term[])iter.next();
-      for (int i=0; i<arr.length; i++) {
-        terms.add(arr[i]);
+    for (final Term[] arr : termArrays) {
+      for (final Term term: arr) {
+        terms.add(term);
       }
     }
   }
@@ -135,11 +134,9 @@
       this.similarity = getSimilarity(searcher);
 
       // compute idf
-      Iterator i = termArrays.iterator();
-      while (i.hasNext()) {
-        Term[] terms = (Term[])i.next();
-        for (int j=0; j<terms.length; j++) {
-          idf += getSimilarity(searcher).idf(terms[j], searcher);
+      for(final Term[] terms: termArrays) {
+        for (Term term: terms) {
+          idf += getSimilarity(searcher).idf(term, searcher);
         }
       }
     }
@@ -278,9 +275,9 @@
     }
 
     buffer.append("\"");
-    Iterator i = termArrays.iterator();
+    Iterator<Term[]> i = termArrays.iterator();
     while (i.hasNext()) {
-      Term[] terms = (Term[])i.next();
+      Term[] terms = i.next();
       if (terms.length > 1) {
         buffer.append("(");
         for (int j = 0; j < terms.length; j++) {
@@ -330,9 +327,7 @@
   // Breakout calculation of the termArrays hashcode
   private int termArraysHashCode() {
     int hashCode = 1;
-    Iterator iterator = termArrays.iterator();
-    while (iterator.hasNext()) {
-      Term[] termArray = (Term[]) iterator.next();
+    for (final Term[] termArray: termArrays) {
       hashCode = 31 * hashCode
           + (termArray == null ? 0 : arraysHashCode(termArray));
     }
@@ -354,15 +349,15 @@
   }
 
   // Breakout calculation of the termArrays equals
-  private boolean termArraysEquals(List termArrays1, List termArrays2) {
+  private boolean termArraysEquals(List<Term[]> termArrays1, List<Term[]> termArrays2) {
     if (termArrays1.size() != termArrays2.size()) {
       return false;
     }
-    ListIterator iterator1 = termArrays1.listIterator();
-    ListIterator iterator2 = termArrays2.listIterator();
+    ListIterator<Term[]> iterator1 = termArrays1.listIterator();
+    ListIterator<Term[]> iterator2 = termArrays2.listIterator();
     while (iterator1.hasNext()) {
-      Term[] termArray1 = (Term[]) iterator1.next();
-      Term[] termArray2 = (Term[]) iterator2.next();
+      Term[] termArray1 = iterator1.next();
+      Term[] termArray2 = iterator2.next();
       if (!(termArray1 == null ? termArray2 == null : Arrays.equals(termArray1,
           termArray2))) {
         return false;
Index: src/java/org/apache/lucene/search/Query.java
===================================================================
--- src/java/org/apache/lucene/search/Query.java	(revision 826470)
+++ src/java/org/apache/lucene/search/Query.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.IOException;
 
 import java.util.HashSet;
-import java.util.Iterator;
+
 import java.util.Set;
 
 import org.apache.lucene.index.IndexReader;
@@ -126,7 +126,7 @@
    * the other queries.
   */
   public Query combine(Query[] queries) {
-    HashSet uniques = new HashSet();
+    HashSet<Query> uniques = new HashSet<Query>();
     for (int i = 0; i < queries.length; i++) {
       Query query = queries[i];
       BooleanClause[] clauses = null;
@@ -152,10 +152,9 @@
     if(uniques.size() == 1){
         return (Query)uniques.iterator().next();
     }
-    Iterator it = uniques.iterator();
     BooleanQuery result = new BooleanQuery(true);
-    while (it.hasNext())
-      result.add((Query) it.next(), BooleanClause.Occur.SHOULD);
+    for (final Query query : uniques)
+      result.add(query, BooleanClause.Occur.SHOULD);
     return result;
   }
   
@@ -179,20 +178,19 @@
    *<p>A utility for use by {@link #combine(Query[])} implementations.
    */
   public static Query mergeBooleanQueries(BooleanQuery[] queries) {
-    HashSet allClauses = new HashSet();
-    for (int i = 0; i < queries.length; i++) {
-      BooleanClause[] clauses = queries[i].getClauses();
-      for (int j = 0; j < clauses.length; j++) {
-        allClauses.add(clauses[j]);
+    HashSet<BooleanClause> allClauses = new HashSet<BooleanClause>();
+    for (BooleanQuery booleanQuery : queries) {
+      BooleanClause[] clauses = booleanQuery.getClauses();
+      for (BooleanClause clause: clauses) {
+        allClauses.add(clause);
       }
     }
 
     boolean coordDisabled =
       queries.length==0? false : queries[0].isCoordDisabled();
     BooleanQuery result = new BooleanQuery(coordDisabled);
-    Iterator i = allClauses.iterator();
-    while (i.hasNext()) {
-      result.add((BooleanClause)i.next());
+    for(BooleanClause clause2 : allClauses) {
+      result.add(clause2);
     }
     return result;
   }
Index: src/java/org/apache/lucene/search/PhraseQuery.java
===================================================================
--- src/java/org/apache/lucene/search/PhraseQuery.java	(revision 826470)
+++ src/java/org/apache/lucene/search/PhraseQuery.java	(working copy)
@@ -34,8 +34,8 @@
  */
 public class PhraseQuery extends Query {
   private String field;
-  private ArrayList terms = new ArrayList(4);
-  private ArrayList positions = new ArrayList(4);
+  private ArrayList<Term> terms = new ArrayList<Term>(4);
+  private ArrayList<Integer> positions = new ArrayList<Integer>(4);
   private int maxPosition = 0;
   private int slop = 0;
 
@@ -67,7 +67,7 @@
   public void add(Term term) {
     int position = 0;
     if(positions.size() > 0)
-        position = ((Integer) positions.get(positions.size()-1)).intValue() + 1;
+        position = positions.get(positions.size()-1).intValue() + 1;
 
     add(term, position);
   }
@@ -94,7 +94,7 @@
 
   /** Returns the set of terms in this phrase. */
   public Term[] getTerms() {
-    return (Term[])terms.toArray(new Term[0]);
+    return terms.toArray(new Term[0]);
   }
 
   /**
@@ -103,7 +103,7 @@
   public int[] getPositions() {
       int[] result = new int[positions.size()];
       for(int i = 0; i < positions.size(); i++)
-          result[i] = ((Integer) positions.get(i)).intValue();
+          result[i] = positions.get(i).intValue();
       return result;
   }
 
@@ -145,7 +145,7 @@
 
       TermPositions[] tps = new TermPositions[terms.size()];
       for (int i = 0; i < terms.size(); i++) {
-        TermPositions p = reader.termPositions((Term)terms.get(i));
+        TermPositions p = reader.termPositions(terms.get(i));
         if (p == null)
           return null;
         tps[i] = p;
@@ -176,7 +176,7 @@
           query.append(" ");
         }
 
-        Term term = (Term)terms.get(i);
+        Term term = terms.get(i);
 
         query.append(term.text());
       }
@@ -242,7 +242,7 @@
 
   public Weight createWeight(Searcher searcher) throws IOException {
     if (terms.size() == 1) {			  // optimize one-term case
-      Term term = (Term)terms.get(0);
+      Term term = terms.get(0);
       Query termQuery = new TermQuery(term);
       termQuery.setBoost(getBoost());
       return termQuery.createWeight(searcher);
@@ -268,12 +268,12 @@
     buffer.append("\"");
     String[] pieces = new String[maxPosition + 1];
     for (int i = 0; i < terms.size(); i++) {
-      int pos = ((Integer)positions.get(i)).intValue();
+      int pos = positions.get(i).intValue();
       String s = pieces[pos];
       if (s == null) {
-        s = ((Term)terms.get(i)).text();
+        s = (terms.get(i)).text();
       } else {
-        s = s + "|" + ((Term)terms.get(i)).text();
+        s = s + "|" + (terms.get(i)).text();
       }
       pieces[pos] = s;
     }
Index: src/java/org/apache/lucene/search/Explanation.java
===================================================================
--- src/java/org/apache/lucene/search/Explanation.java	(revision 826470)
+++ src/java/org/apache/lucene/search/Explanation.java	(working copy)
@@ -24,7 +24,7 @@
 public class Explanation implements java.io.Serializable {
   private float value;                            // the value of this node
   private String description;                     // what it represents
-  private ArrayList details;                      // sub-explanations
+  private ArrayList<Explanation> details;                      // sub-explanations
 
   public Explanation() {}
 
@@ -71,13 +71,13 @@
   public Explanation[] getDetails() {
     if (details == null)
       return null;
-    return (Explanation[])details.toArray(new Explanation[0]);
+    return details.toArray(new Explanation[0]);
   }
 
   /** Adds a sub-node to this explanation node. */
   public void addDetail(Explanation detail) {
     if (details == null)
-      details = new ArrayList();
+      details = new ArrayList<Explanation>();
     details.add(detail);
   }
 
Index: src/java/org/apache/lucene/search/MultiSearcher.java
===================================================================
--- src/java/org/apache/lucene/search/MultiSearcher.java	(revision 826470)
+++ src/java/org/apache/lucene/search/MultiSearcher.java	(working copy)
@@ -43,10 +43,10 @@
    * initialize Weights.
    */
   private static class CachedDfSource extends Searcher {
-    private Map dfMap; // Map from Terms to corresponding doc freqs
+    private Map<Term,Integer> dfMap; // Map from Terms to corresponding doc freqs
     private int maxDoc; // document count
 
-    public CachedDfSource(Map dfMap, int maxDoc, Similarity similarity) {
+    public CachedDfSource(Map<Term,Integer> dfMap, int maxDoc, Similarity similarity) {
       this.dfMap = dfMap;
       this.maxDoc = maxDoc;
       setSimilarity(similarity);
@@ -55,7 +55,7 @@
     public int docFreq(Term term) {
       int df;
       try {
-        df = ((Integer) dfMap.get(term)).intValue();
+        df = dfMap.get(term).intValue();
       } catch (NullPointerException e) {
         throw new IllegalArgumentException("df for term " + term.text()
             + " not available");
@@ -305,7 +305,7 @@
     Query rewrittenQuery = rewrite(original);
 
     // step 2
-    Set terms = new HashSet();
+    Set<Term> terms = new HashSet<Term>();
     rewrittenQuery.extractTerms(terms);
 
     // step3
@@ -319,7 +319,7 @@
       }
     }
 
-    HashMap dfMap = new HashMap();
+    HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();
     for(int i=0; i<allTermsArray.length; i++) {
       dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDfs[i]));
     }
Index: src/java/org/apache/lucene/search/QueryTermVector.java
===================================================================
--- src/java/org/apache/lucene/search/QueryTermVector.java	(revision 826470)
+++ src/java/org/apache/lucene/search/QueryTermVector.java	(working copy)
@@ -22,7 +22,7 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
-import java.util.Iterator;
+
 import java.util.List;
 import java.util.Map;
 
@@ -56,7 +56,7 @@
       TokenStream stream = analyzer.tokenStream("", new StringReader(queryString));
       if (stream != null)
       {
-        List terms = new ArrayList();
+        List<String> terms = new ArrayList<String>();
         try {
           boolean hasMoreTokens = false;
           
@@ -78,30 +78,29 @@
   private void processTerms(String[] queryTerms) {
     if (queryTerms != null) {
       Arrays.sort(queryTerms);
-      Map tmpSet = new HashMap(queryTerms.length);
+      Map<String,Integer> tmpSet = new HashMap<String,Integer>(queryTerms.length);
       //filter out duplicates
-      List tmpList = new ArrayList(queryTerms.length);
-      List tmpFreqs = new ArrayList(queryTerms.length);
+      List<String> tmpList = new ArrayList<String>(queryTerms.length);
+      List<Integer> tmpFreqs = new ArrayList<Integer>(queryTerms.length);
       int j = 0;
       for (int i = 0; i < queryTerms.length; i++) {
         String term = queryTerms[i];
-        Integer position = (Integer)tmpSet.get(term);
+        Integer position = tmpSet.get(term);
         if (position == null) {
           tmpSet.put(term, Integer.valueOf(j++));
           tmpList.add(term);
           tmpFreqs.add(Integer.valueOf(1));
         }       
         else {
-          Integer integer = (Integer)tmpFreqs.get(position.intValue());
+          Integer integer = tmpFreqs.get(position.intValue());
           tmpFreqs.set(position.intValue(), Integer.valueOf(integer.intValue() + 1));          
         }
       }
-      terms = (String[])tmpList.toArray(terms);
+      terms = tmpList.toArray(terms);
       //termFreqs = (int[])tmpFreqs.toArray(termFreqs);
       termFreqs = new int[tmpFreqs.size()];
       int i = 0;
-      for (Iterator iter = tmpFreqs.iterator(); iter.hasNext();) {
-        Integer integer = (Integer) iter.next();
+      for (final Integer integer : tmpFreqs) {
         termFreqs[i++] = integer.intValue();
       }
     }
Index: src/java/org/apache/lucene/search/IndexSearcher.java
===================================================================
--- src/java/org/apache/lucene/search/IndexSearcher.java	(revision 826470)
+++ src/java/org/apache/lucene/search/IndexSearcher.java	(working copy)
@@ -90,9 +90,9 @@
     reader = r;
     this.closeReader = closeReader;
 
-    List subReadersList = new ArrayList();
+    List<IndexReader> subReadersList = new ArrayList<IndexReader>();
     gatherSubReaders(subReadersList, reader);
-    subReaders = (IndexReader[]) subReadersList.toArray(new IndexReader[subReadersList.size()]);
+    subReaders = subReadersList.toArray(new IndexReader[subReadersList.size()]);
     docStarts = new int[subReaders.length];
     int maxDoc = 0;
     for (int i = 0; i < subReaders.length; i++) {
@@ -101,7 +101,7 @@
     }
   }
 
-  protected void gatherSubReaders(List allSubReaders, IndexReader r) {
+  protected void gatherSubReaders(List<IndexReader> allSubReaders, IndexReader r) {
     ReaderUtil.gatherSubReaders(allSubReaders, r);
   }
 
