Index: src/java/org/apache/lucene/index/IndexFileNames.java
===================================================================
--- src/java/org/apache/lucene/index/IndexFileNames.java	(revision 489254)
+++ src/java/org/apache/lucene/index/IndexFileNames.java	(working copy)
@@ -45,7 +45,7 @@
    */
   static final String INDEX_EXTENSIONS[] = new String[] {
       "cfs", "fnm", "fdx", "fdt", "tii", "tis", "frq", "prx", "del",
-      "tvx", "tvd", "tvf", "tvp", "gen"};
+      "tvx", "tvd", "tvf", "tvp", "gen", "nrm"};
   
   /** File extensions of old-style index files */
   static final String COMPOUND_EXTENSIONS[] = new String[] {
Index: src/java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- src/java/org/apache/lucene/index/IndexWriter.java	(revision 489254)
+++ src/java/org/apache/lucene/index/IndexWriter.java	(working copy)
@@ -617,7 +617,7 @@
     String segmentName = newRAMSegmentName();
     dw.addDocument(segmentName, doc);
     synchronized (this) {
-      ramSegmentInfos.addElement(new SegmentInfo(segmentName, 1, ramDirectory, false));
+      ramSegmentInfos.addElement(new SegmentInfo(segmentName, 1, ramDirectory, false, false));
       maybeFlushRamSegments();
     }
   }
@@ -710,10 +710,10 @@
     while (segmentInfos.size() > 1 ||
            (segmentInfos.size() == 1 &&
             (SegmentReader.hasDeletions(segmentInfos.info(0)) ||
+             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||
              segmentInfos.info(0).dir != directory ||
              (useCompoundFile &&
-              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||
-                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {
+              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {
       int minSegment = segmentInfos.size() - mergeFactor;
       mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());
     }
@@ -1056,7 +1056,7 @@
       int docCount = merger.merge();                // merge 'em
 
       segmentInfos.setSize(0);                      // pop old infos & add new
-      info = new SegmentInfo(mergedName, docCount, directory, false);
+      info = new SegmentInfo(mergedName, docCount, directory, false, true);
       segmentInfos.addElement(info);
       commitPending = true;
 
@@ -1276,7 +1276,7 @@
         }
 
         newSegment = new SegmentInfo(mergedName, mergedDocCount,
-                                     directory, false);
+                                     directory, false, true);
 
 
         if (sourceSegments == ramSegmentInfos) {
Index: src/java/org/apache/lucene/index/SegmentMerger.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentMerger.java	(revision 489254)
+++ src/java/org/apache/lucene/index/SegmentMerger.java	(working copy)
@@ -116,7 +116,7 @@
             new CompoundFileWriter(directory, fileName);
 
     Vector files =
-      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    
+      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    
     
     // Basic files
     for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {
@@ -127,7 +127,8 @@
     for (int i = 0; i < fieldInfos.size(); i++) {
       FieldInfo fi = fieldInfos.fieldInfo(i);
       if (fi.isIndexed && !fi.omitNorms) {
-        files.add(segment + ".f" + i);
+        files.add(segment + ".nrm");
+        break;
       }
     }
 
@@ -408,11 +409,14 @@
 
   private void mergeNorms() throws IOException {
     byte[] normBuffer = null;
-    for (int i = 0; i < fieldInfos.size(); i++) {
-      FieldInfo fi = fieldInfos.fieldInfo(i);
-      if (fi.isIndexed && !fi.omitNorms) {
-        IndexOutput output = directory.createOutput(segment + ".f" + i);
-        try {
+    IndexOutput output = null;
+    try {
+      for (int i = 0; i < fieldInfos.size(); i++) {
+        FieldInfo fi = fieldInfos.fieldInfo(i);
+        if (fi.isIndexed && !fi.omitNorms) {
+          if (output == null) { 
+            output = directory.createOutput(segment + ".nrm");
+          }
           for (int j = 0; j < readers.size(); j++) {
             IndexReader reader = (IndexReader) readers.elementAt(j);
             int maxDoc = reader.maxDoc();
@@ -434,10 +438,12 @@
               }
             }
           }
-        } finally {
-          output.close();
         }
       }
+    } finally {
+      if (output != null) { 
+        output.close();
+      }
     }
   }
 
Index: src/java/org/apache/lucene/index/SegmentInfo.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentInfo.java	(revision 489254)
+++ src/java/org/apache/lucene/index/SegmentInfo.java	(working copy)
@@ -42,8 +42,13 @@
 
   private byte isCompoundFile;                    // -1 if it is not; 1 if it is; 0 if it's
                                                   // pre-2.1 (ie, must check file system to see
-                                                  // if <name>.cfs exists)         
+                                                  // if <name>.cfs and <name>.nrm exist)         
 
+  private byte withNrm;                           // 1 if this segment maintains norms in a single file; 
+                                                  // -1 if not; 0 if check file is required to tell.
+                                                  // would be -1 for segments populated by DocumentWriter.
+                                                  // would be 1 for (newly created) merge resulted segments (both compound and non compound).
+  
   public SegmentInfo(String name, int docCount, Directory dir) {
     this.name = name;
     this.docCount = docCount;
@@ -51,14 +56,13 @@
     delGen = -1;
     isCompoundFile = 0;
     preLockless = true;
+    withNrm = 0;
   }
-  public SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile) {
+
+  public SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile, boolean withNrm) { 
     this(name, docCount, dir);
-    if (isCompoundFile) {
-      this.isCompoundFile = 1;
-    } else {
-      this.isCompoundFile = -1;
-    }
+    this.isCompoundFile = (byte) (isCompoundFile ? 1 : -1);
+    this.withNrm = (byte) (withNrm ? 1 : -1);
     preLockless = false;
   }
 
@@ -78,6 +82,7 @@
       System.arraycopy(src.normGen, 0, normGen, 0, src.normGen.length);
     }
     isCompoundFile = src.isCompoundFile;
+    withNrm = src.withNrm;
   }
 
   /**
@@ -111,19 +116,20 @@
       isCompoundFile = 0;
       preLockless = true;
     }
+    withNrm = 0;
   }
   
-  void setNumField(int numField) {
+  void setNumFields(int numFields) {
     if (normGen == null) {
       // normGen is null if we loaded a pre-2.1 segment
       // file, or, if this segments file hasn't had any
       // norms set against it yet:
-      normGen = new long[numField];
+      normGen = new long[numFields];
 
       if (!preLockless) {
         // This is a FORMAT_LOCKLESS segment, which means
         // there are no norms:
-        for(int i=0;i<numField;i++) {
+        for(int i=0;i<numFields;i++) {
           normGen[i] = -1;
         }
       }
@@ -173,6 +179,7 @@
     si.isCompoundFile = isCompoundFile;
     si.delGen = delGen;
     si.preLockless = preLockless;
+    si.withNrm = withNrm;
     if (normGen != null) {
       si.normGen = (long[]) normGen.clone();
     }
@@ -245,7 +252,7 @@
       // pre-LOCKLESS and must be checked in directory:
       for(int i=0;i<normGen.length;i++) {
         if (normGen[i] == 0) {
-          if (dir.fileExists(getNormFileName(i))) {
+          if (hasSeparateNorms(i)) {
             return true;
           }
         }
@@ -285,12 +292,21 @@
     }
     
     if (hasSeparateNorms(number)) {
+      // case 1: separate norm
       prefix = ".s";
       return IndexFileNames.fileNameFromGeneration(name, prefix + number, gen);
-    } else {
-      prefix = ".f";
-      return IndexFileNames.fileNameFromGeneration(name, prefix + number, 0);
     }
+    
+
+    if (withNrm()) {
+      // case 2: lockless (or nrm file exists) - single file for all norms 
+      prefix = ".nrm";
+      return IndexFileNames.fileNameFromGeneration(name, prefix, 0);
+    }
+      
+    // case 3: norm file for each field
+    prefix = ".f";
+    return IndexFileNames.fileNameFromGeneration(name, prefix + number, 0);
   }
 
   /**
@@ -310,11 +326,6 @@
   /**
    * Returns true if this segment is stored as a compound
    * file; else, false.
-   *
-   * @param directory directory to check.  This parameter is
-   * only used when the segment was written before version
-   * 2.1 (at which point compound file or not became stored
-   * in the segments info file).
    */
   boolean getUseCompoundFile() throws IOException {
     if (isCompoundFile == -1) {
@@ -325,6 +336,32 @@
       return dir.fileExists(name + ".cfs");
     }
   }
+  
+  /**
+   * Returns true iff this segment stores filed norms in a single .nrm file.
+   */
+  private boolean withNrm () throws IOException {
+    if (withNrm == -1) {
+      return false;
+    } 
+    if (withNrm == 1) {
+      return true;
+    }
+    Directory d = dir;
+    try {
+      if (getUseCompoundFile()) {
+        d = new CompoundFileReader(dir, name + ".cfs");
+      }
+      boolean res = d.fileExists(name + ".nrm");
+      withNrm = (byte) (res ? 1 : -1); // avoid more file tests like this 
+      return res;
+    } finally {
+      if (d!=dir && d!=null) {
+        d.close();
+      }
+      
+    }
+  }
 
   /**
    * Save this segment's info.
Index: src/java/org/apache/lucene/index/SegmentReader.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentReader.java	(revision 489254)
+++ src/java/org/apache/lucene/index/SegmentReader.java	(working copy)
@@ -58,23 +58,25 @@
   CompoundFileReader cfsReader = null;
 
   private class Norm {
-    public Norm(IndexInput in, int number)
+    public Norm(IndexInput in, int number, long normSeek)
     {
       this.in = in;
       this.number = number;
+      this.normSeek = normSeek;
     }
 
     private IndexInput in;
     private byte[] bytes;
     private boolean dirty;
     private int number;
+    private long normSeek;
     private boolean rollbackDirty;
 
     private void reWrite(SegmentInfo si) throws IOException {
       // NOTE: norms are re-written in regular directory, not cfs
 
       String oldFileName = si.getNormFileName(this.number);
-      if (oldFileName != null) {
+      if (oldFileName != null && !oldFileName.endsWith(".nrm")) {
         // Mark this file for deletion.  Note that we don't
         // actually try to delete it until the new segments files is
         // successfully written:
@@ -215,7 +217,7 @@
       si.clearDelGen();
     }
     if (normsDirty) {               // re-write norms
-      si.setNumField(fieldInfos.size());
+      si.setNumFields(fieldInfos.size());
       Enumeration values = norms.elements();
       while (values.hasMoreElements()) {
         Norm norm = (Norm) values.nextElement();
@@ -301,10 +303,16 @@
       files.addElement(si.getDelFileName());
     }
 
+    boolean addedNrm = false;
     for (int i = 0; i < fieldInfos.size(); i++) {
       String name = si.getNormFileName(i);
-      if (name != null && directory().fileExists(name))
+      if (name != null && directory().fileExists(name)) {
+        if (name.endsWith(".nrm")) {
+          if (addedNrm) continue; // add .nrm just once
+          addedNrm = true;
+        }
             files.addElement(name);
+      }
     }
     return files;
   }
@@ -462,7 +470,7 @@
 
     IndexInput normStream = (IndexInput) norm.in.clone();
     try {                                         // read from disk
-      normStream.seek(0);
+      normStream.seek(norm.normSeek);
       normStream.readBytes(bytes, offset, maxDoc());
     } finally {
       normStream.close();
@@ -471,6 +479,8 @@
 
 
   private void openNorms(Directory cfsDir) throws IOException {
+    long nextNormSeek = 0;
+    int maxDoc = maxDoc();
     for (int i = 0; i < fieldInfos.size(); i++) {
       FieldInfo fi = fieldInfos.fieldInfo(i);
       if (fi.isIndexed && !fi.omitNorms) {
@@ -479,7 +489,9 @@
         if (!si.hasSeparateNorms(fi.number)) {
           d = cfsDir;
         }
-        norms.put(fi.name, new Norm(d.openInput(fileName), fi.number));
+        long normSeek = (fileName.endsWith(".nrm") ? nextNormSeek : 0);
+        norms.put(fi.name, new Norm(d.openInput(fileName), fi.number, normSeek));
+        nextNormSeek += maxDoc; // increment also if some norms are separate
       }
     }
   }
