diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
index 924756e..e1f0cbd 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
@@ -144,17 +144,17 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
       typeAtt = ts.getAttribute(TypeAttribute.class);
     }
     
-    PositionIncrementAttribute posIncrAtt = null;
     if (posIncrements != null || finalPosInc != null) {
       assertTrue("has no PositionIncrementAttribute", ts.hasAttribute(PositionIncrementAttribute.class));
-      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);
     }
+    PositionIncrementAttribute posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);
 
-    PositionLengthAttribute posLengthAtt = null;
+    boolean hasPosLengthAtt = ts.hasAttribute(PositionLengthAttribute.class);
     if (posLengths != null) {
       assertTrue("has no PositionLengthAttribute", ts.hasAttribute(PositionLengthAttribute.class));
-      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);
     }
+    // addAttribute not getAttribute, so we can detect dup tokens below:
+    PositionLengthAttribute posLengthAtt = ts.addAttribute(PositionLengthAttribute.class);
 
     KeywordAttribute keywordAtt = null;
     if (keywordAtts != null) {
@@ -169,6 +169,7 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
     ts.reset();
     int pos = -1;
     int lastStartOffset = 0;
+    List<Token> tokensAtPosition = new ArrayList<>();
     for (int i = 0; i < output.length; i++) {
       // extra safety to enforce, that the state is not preserved and also assign bogus values
       ts.clearAttributes();
@@ -180,9 +181,13 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
       if (keywordAtt != null) keywordAtt.setKeyword((i&1) == 0);
       
       checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before
+
+      // finally increment to next token:
       assertTrue("token "+i+" does not exist", ts.incrementToken());
       assertTrue("clearAttributes() was not called correctly in TokenStream chain", checkClearAtt.getAndResetClearCalled());
-      
+
+      //System.out.println("term: " + termAtt);
+
       assertEquals("term "+i, output[i], termAtt.toString());
       if (startOffsets != null) {
         assertEquals("startOffset " + i + " term=" + termAtt, startOffsets[i], offsetAtt.startOffset());
@@ -193,6 +198,24 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
       if (types != null) {
         assertEquals("type " + i + " term=" + termAtt, types[i], typeAtt.type());
       }
+      if (posIncrAtt != null && posLengthAtt != null) {
+        int posInc = posIncrAtt.getPositionIncrement();
+        // make sure no duplicate tokens
+        if (posInc > 0) {
+          pos += posInc;
+          tokensAtPosition.clear();
+        } else {
+          for(Token old : tokensAtPosition) {
+            if (old.toString().equals(termAtt.toString()) &&
+                old.getPositionLength() == posLengthAtt.getPositionLength()) {
+              fail("duplicate token=" + termAtt + " from pos=" + pos + " to pos=" + (pos + posLengthAtt.getPositionLength()));
+            }
+          }
+        }
+        Token token = new Token(termAtt.toString(), 0, 0);
+        token.setPositionLength(posLengthAtt.getPositionLength());
+        tokensAtPosition.add(token);
+      }
       if (posIncrements != null) {
         assertEquals("posIncrement " + i + " term=" + termAtt, posIncrements[i], posIncrAtt.getPositionIncrement());
       }
@@ -218,13 +241,11 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
           lastStartOffset = offsetAtt.startOffset();
         }
 
-        if (offsetsAreCorrect && posLengthAtt != null && posIncrAtt != null) {
+        if (offsetsAreCorrect && hasPosLengthAtt && posIncrAtt != null) {
           // Validate offset consistency in the graph, ie
           // all tokens leaving from a certain pos have the
           // same startOffset, and all tokens arriving to a
           // certain pos have the same endOffset:
-          final int posInc = posIncrAtt.getPositionIncrement();
-          pos += posInc;
 
           final int posLength = posLengthAtt.getPositionLength();
 
@@ -829,6 +850,7 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
 
       reader = new MockReaderWrapper(random, reader);
     }
+    //System.out.println("text: " + text);
 
     ts = a.tokenStream("dummy", useCharFilter ? new MockCharFilter(reader, remainder) : reader);
     if (typeAtt != null && posIncAtt != null && posLengthAtt != null && offsetAtt != null) {
