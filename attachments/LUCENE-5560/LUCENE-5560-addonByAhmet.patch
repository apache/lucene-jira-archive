Index: lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java	(revision 1583329)
+++ lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java	(working copy)
@@ -21,6 +21,7 @@
 import java.io.IOException;
 import java.io.PrintStream;
 import java.io.UnsupportedEncodingException;
+import java.nio.charset.StandardCharsets;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.Locale;
@@ -428,7 +429,7 @@
       }
 
       try {
-        return bos.toString("UTF-8");
+        return bos.toString(StandardCharsets.UTF_8.name());
       } catch (UnsupportedEncodingException bogus) {
         throw new RuntimeException(bogus);
       }
Index: lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java	(revision 1583329)
+++ lucene/test-framework/src/java/org/apache/lucene/util/fst/FSTTester.java	(working copy)
@@ -21,6 +21,7 @@
 import java.io.IOException;
 import java.io.OutputStreamWriter;
 import java.io.Writer;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -328,7 +329,7 @@
     }
 
     if (LuceneTestCase.VERBOSE && pairs.size() <= 20 && fst != null) {
-      Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
+      Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), StandardCharsets.UTF_8);
       Util.toDot(fst, w, false, false);
       w.close();
       System.out.println("SAVED out.dot");
Index: solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java
===================================================================
--- solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java	(revision 1583329)
+++ solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.FileOutputStream;
+import java.nio.charset.StandardCharsets;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.io.IOUtils;
@@ -86,7 +87,7 @@
     RuleBasedCollator tailoredCollator = new RuleBasedCollator(baseCollator.getRules() + DIN5007_2_tailorings);
     String tailoredRules = tailoredCollator.getRules();
     FileOutputStream os = new FileOutputStream(new File(confDir, "customrules.dat"));
-    IOUtils.write(tailoredRules, os, "UTF-8");
+    IOUtils.write(tailoredRules, os, StandardCharsets.UTF_8.name());
     os.close();
 
     return tmpFile.getAbsolutePath();
Index: solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationFieldDocValues.java
===================================================================
--- solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationFieldDocValues.java	(revision 1583329)
+++ solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationFieldDocValues.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.FileOutputStream;
+import java.nio.charset.StandardCharsets;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.io.IOUtils;
@@ -88,7 +89,7 @@
     RuleBasedCollator tailoredCollator = new RuleBasedCollator(baseCollator.getRules() + DIN5007_2_tailorings);
     String tailoredRules = tailoredCollator.getRules();
     FileOutputStream os = new FileOutputStream(new File(confDir, "customrules.dat"));
-    IOUtils.write(tailoredRules, os, "UTF-8");
+    IOUtils.write(tailoredRules, os, StandardCharsets.UTF_8.name());
     os.close();
 
     return tmpFile.getAbsolutePath();
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FieldReaderDataSource.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FieldReaderDataSource.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FieldReaderDataSource.java	(working copy)
@@ -22,6 +22,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.io.*;
+import java.nio.charset.StandardCharsets;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.SQLException;
@@ -106,7 +107,7 @@
   private Reader getReader(Blob blob)
           throws SQLException, UnsupportedEncodingException {
     if (encoding == null) {
-      return (new InputStreamReader(blob.getBinaryStream(), "UTF-8"));
+      return (new InputStreamReader(blob.getBinaryStream(), StandardCharsets.UTF_8));
     } else {
       return (new InputStreamReader(blob.getBinaryStream(), encoding));
     }
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FileDataSource.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FileDataSource.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/FileDataSource.java	(working copy)
@@ -17,6 +17,7 @@
 package org.apache.solr.handler.dataimport;
 
 import java.io.*;
+import java.nio.charset.StandardCharsets;
 import java.util.Properties;
 
 import org.slf4j.Logger;
@@ -138,7 +139,7 @@
   protected Reader openStream(File file) throws FileNotFoundException,
           UnsupportedEncodingException {
     if (encoding == null) {
-      return new InputStreamReader(new FileInputStream(file), "UTF-8");
+      return new InputStreamReader(new FileInputStream(file), StandardCharsets.UTF_8);
     } else {
       return new InputStreamReader(new FileInputStream(file), encoding);
     }
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrWriter.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrWriter.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrWriter.java	(working copy)
@@ -28,6 +28,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.io.*;
+import java.nio.charset.StandardCharsets;
 
 /**
  * <p> Writes documents to SOLR. </p>
@@ -147,7 +148,7 @@
 
       }
     }
-    return new String(baos.toByteArray(), "UTF-8");
+    return new String(baos.toByteArray(), StandardCharsets.UTF_8);
   }
 
   static String getDocCount() {
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/URLDataSource.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/URLDataSource.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/URLDataSource.java	(working copy)
@@ -24,6 +24,7 @@
 import java.io.Reader;
 import java.net.URL;
 import java.net.URLConnection;
+import java.nio.charset.StandardCharsets;
 import java.util.Properties;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
@@ -140,7 +141,13 @@
 
   public static final String BASE_URL = "baseUrl";
 
-  public static final String UTF_8 = "UTF-8";
+  /**
+   * UTF-8 charset string.
+   * <p>Where possible, use {@link StandardCharsets#UTF_8} instead,
+   * as using the String constant may slow things down.
+   * @see StandardCharsets#UTF_8
+   */
+  public static final String UTF_8 = StandardCharsets.UTF_8.name();
 
   public static final String CONNECTION_TIMEOUT_FIELD_NAME = "connectionTimeout";
 
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/UrlEvaluator.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/UrlEvaluator.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/UrlEvaluator.java	(working copy)
@@ -4,6 +4,7 @@
 import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
 
 import java.net.URLEncoder;
+import java.nio.charset.StandardCharsets;
 import java.util.List;
 
 /*
@@ -38,7 +39,7 @@
     String s = l.get(0).toString();
 
     try {
-      return URLEncoder.encode(s.toString(), "UTF-8");
+      return URLEncoder.encode(s.toString(), StandardCharsets.UTF_8.name());
     } catch (Exception e) {
       wrapAndThrow(SEVERE, e, "Unable to encode expression: " + expression + " with value: " + s);
       return null;
Index: solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ZKPropertiesWriter.java
===================================================================
--- solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ZKPropertiesWriter.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ZKPropertiesWriter.java	(working copy)
@@ -90,7 +90,7 @@
     try {
       byte[] data = zkClient.getData(path, null, null, false);
       if (data != null) {
-        props.load(new StringReader(new String(data, "UTF-8")));
+        props.load(new StringReader(new String(data, StandardCharsets.UTF_8)));
       }
     } catch (Exception e) {
       log.warn(
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestDocBuilder2.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestDocBuilder2.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestDocBuilder2.java	(working copy)
@@ -22,6 +22,7 @@
 
 import org.apache.solr.request.LocalSolrQueryRequest;
 
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
@@ -247,14 +248,14 @@
 
     Map<String, String> params = createMap("baseDir", tmpdir.getAbsolutePath());
 
-    createFile(tmpdir, "a.xml", "a.xml".getBytes("UTF-8"), true);
-    createFile(tmpdir, "b.xml", "b.xml".getBytes("UTF-8"), true);
-    createFile(tmpdir, "c.props", "c.props".getBytes("UTF-8"), true);
+    createFile(tmpdir, "a.xml", "a.xml".getBytes(StandardCharsets.UTF_8), true);
+    createFile(tmpdir, "b.xml", "b.xml".getBytes(StandardCharsets.UTF_8), true);
+    createFile(tmpdir, "c.props", "c.props".getBytes(StandardCharsets.UTF_8), true);
     runFullImport(dataConfigFileList, params);
     assertQ(req("*:*"), "//*[@numFound='3']");
 
     // Add a new file after a full index is done
-    createFile(tmpdir, "t.xml", "t.xml".getBytes("UTF-8"), false);
+    createFile(tmpdir, "t.xml", "t.xml".getBytes(StandardCharsets.UTF_8), false);
     runFullImport(dataConfigFileList, params);
     // we should find only 1 because by default clean=true is passed
     // and this particular import should find only one file t.xml
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListEntityProcessor.java	(working copy)
@@ -21,6 +21,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.nio.charset.StandardCharsets;
 import java.text.SimpleDateFormat;
 import java.util.*;
 
@@ -69,19 +70,19 @@
     tmpdir.deleteOnExit();
     long minLength = Long.MAX_VALUE;
     String smallestFile = "";
-    byte[] content = "abcdefgij".getBytes("UTF-8");
+    byte[] content = "abcdefgij".getBytes(StandardCharsets.UTF_8);
     createFile(tmpdir, "a.xml", content, false);
     if (minLength > content.length) {
       minLength = content.length;
       smallestFile = "a.xml";
     }
-    content = "abcdefgij".getBytes("UTF-8");
+    content = "abcdefgij".getBytes(StandardCharsets.UTF_8);
     createFile(tmpdir, "b.xml", content, false);
     if (minLength > content.length) {
       minLength = content.length;
       smallestFile = "b.xml";
     }
-    content = "abc".getBytes("UTF-8");
+    content = "abc".getBytes(StandardCharsets.UTF_8);
     createFile(tmpdir, "c.props", content, false);
     if (minLength > content.length) {
       minLength = content.length;
@@ -137,9 +138,9 @@
     tmpdir.delete();
     tmpdir.mkdir();
     tmpdir.deleteOnExit();
-    createFile(tmpdir, "a.xml", "a.xml".getBytes("UTF-8"), true);
-    createFile(tmpdir, "b.xml", "b.xml".getBytes("UTF-8"), true);
-    createFile(tmpdir, "c.props", "c.props".getBytes("UTF-8"), true);
+    createFile(tmpdir, "a.xml", "a.xml".getBytes(StandardCharsets.UTF_8), true);
+    createFile(tmpdir, "b.xml", "b.xml".getBytes(StandardCharsets.UTF_8), true);
+    createFile(tmpdir, "c.props", "c.props".getBytes(StandardCharsets.UTF_8), true);
     Map attrs = createMap(
             FileListEntityProcessor.FILE_NAME, "xml$",
             FileListEntityProcessor.BASE_DIR, tmpdir.getAbsolutePath(),
@@ -161,7 +162,7 @@
     VariableResolver resolver = new VariableResolver();
     String lastMod = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss", Locale.ROOT).format(new Date(System.currentTimeMillis() - 50000));
     resolver.addNamespace("a", createMap("x", lastMod));
-    createFile(tmpdir, "t.xml", "t.xml".getBytes("UTF-8"), false);
+    createFile(tmpdir, "t.xml", "t.xml".getBytes(StandardCharsets.UTF_8), false);
     fList = getFiles(resolver, attrs);
     assertEquals(1, fList.size());
     assertEquals("File name must be t.xml", new File(tmpdir, "t.xml").getAbsolutePath(), fList.get(0));
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListWithLineEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListWithLineEntityProcessor.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestFileListWithLineEntityProcessor.java	(working copy)
@@ -1,6 +1,7 @@
 package org.apache.solr.handler.dataimport;
 
 import java.io.File;
+import java.nio.charset.StandardCharsets;
 
 import org.apache.solr.request.LocalSolrQueryRequest;
 import org.junit.BeforeClass;
@@ -33,9 +34,9 @@
     tmpdir.delete();
     tmpdir.mkdir();
     tmpdir.deleteOnExit();
-    createFile(tmpdir, "a.txt", "a line one\na line two\na line three".getBytes("UTF-8"), false);
-    createFile(tmpdir, "b.txt", "b line one\nb line two".getBytes("UTF-8"), false);
-    createFile(tmpdir, "c.txt", "c line one\nc line two\nc line three\nc line four".getBytes("UTF-8"), false);
+    createFile(tmpdir, "a.txt", "a line one\na line two\na line three".getBytes(StandardCharsets.UTF_8), false);
+    createFile(tmpdir, "b.txt", "b line one\nb line two".getBytes(StandardCharsets.UTF_8), false);
+    createFile(tmpdir, "c.txt", "c line one\nc line two\nc line three\nc line four".getBytes(StandardCharsets.UTF_8), false);
     
     String config = generateConfig(tmpdir);
     LocalSolrQueryRequest request = lrf.makeRequest(
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java	(revision 1583329)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestXPathEntityProcessor.java	(working copy)
@@ -21,6 +21,7 @@
 import java.io.File;
 import java.io.Reader;
 import java.io.StringReader;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
@@ -337,7 +338,7 @@
     tmpdir.delete();
     tmpdir.mkdir();
     tmpdir.deleteOnExit();
-    AbstractDataImportHandlerTestCase.createFile(tmpdir, "x.xsl", xsl.getBytes("UTF-8"),
+    AbstractDataImportHandlerTestCase.createFile(tmpdir, "x.xsl", xsl.getBytes(StandardCharsets.UTF_8),
             false);
     Map entityAttrs = createMap("name", "e",
             XPathEntityProcessor.USE_SOLR_ADD_SCHEMA, "true", "xsl", ""
Index: solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java
===================================================================
--- solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java	(revision 1583329)
+++ solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader.java	(working copy)
@@ -19,6 +19,7 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.StringWriter;
+import java.nio.charset.StandardCharsets;
 import java.util.Locale;
 
 import org.apache.commons.io.IOUtils;
@@ -178,9 +179,9 @@
           if (extractFormat.equals(TEXT_FORMAT)) {
             serializer = new TextSerializer();
             serializer.setOutputCharStream(writer);
-            serializer.setOutputFormat(new OutputFormat("Text", "UTF-8", true));
+            serializer.setOutputFormat(new OutputFormat("Text",  StandardCharsets.UTF_8.name(), true));
           } else {
-            serializer = new XMLSerializer(writer, new OutputFormat("XML", "UTF-8", true));
+            serializer = new XMLSerializer(writer, new OutputFormat("XML",  StandardCharsets.UTF_8.name(), true));
           }
           if (xpathExpr != null) {
             Matcher matcher =
Index: solr/contrib/langid/src/java/org/apache/solr/update/processor/LangDetectLanguageIdentifierUpdateProcessorFactory.java
===================================================================
--- solr/contrib/langid/src/java/org/apache/solr/update/processor/LangDetectLanguageIdentifierUpdateProcessorFactory.java	(revision 1583329)
+++ solr/contrib/langid/src/java/org/apache/solr/update/processor/LangDetectLanguageIdentifierUpdateProcessorFactory.java	(working copy)
@@ -22,6 +22,7 @@
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.nio.charset.Charset;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.List;
 
@@ -126,10 +127,10 @@
     }
     loaded = true;
     List<String> profileData = new ArrayList<>();
-    Charset encoding = Charset.forName("UTF-8");
+
     for (String language : languages) {
       InputStream stream = LangDetectLanguageIdentifierUpdateProcessor.class.getResourceAsStream("langdetect-profiles/" + language);
-      BufferedReader reader = new BufferedReader(new InputStreamReader(stream, encoding));
+      BufferedReader reader = new BufferedReader(new InputStreamReader(stream, StandardCharsets.UTF_8));
       profileData.add(new String(IOUtils.toCharArray(reader)));
       reader.close();
     }
Index: solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/MapReduceIndexerTool.java
===================================================================
--- solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/MapReduceIndexerTool.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/MapReduceIndexerTool.java	(working copy)
@@ -31,6 +31,7 @@
 import java.net.URISyntaxException;
 import java.net.URL;
 import java.net.URLClassLoader;
+import java.nio.charset.StandardCharsets;
 import java.text.NumberFormat;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -924,7 +925,7 @@
     FileSystem fs = fullInputList.getFileSystem(conf);
     FSDataOutputStream out = fs.create(fullInputList);
     try {
-      Writer writer = new BufferedWriter(new OutputStreamWriter(out, "UTF-8"));
+      Writer writer = new BufferedWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8));
       
       for (Path inputFile : inputFiles) {
         FileSystem inputFileFs = inputFile.getFileSystem(conf);
@@ -949,7 +950,7 @@
           in = inputList.getFileSystem(conf).open(inputList);
         }
         try {
-          BufferedReader reader = new BufferedReader(new InputStreamReader(in, "UTF-8"));
+          BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));
           String line;
           while ((line = reader.readLine()) != null) {
             writer.write(line + "\n");
@@ -988,7 +989,7 @@
   
   private void randomizeFewInputFiles(FileSystem fs, Path outputStep2Dir, Path fullInputList) throws IOException {    
     List<String> lines = new ArrayList();
-    BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(fullInputList), "UTF-8"));
+    BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(fullInputList), StandardCharsets.UTF_8));
     try {
       String line;
       while ((line = reader.readLine()) != null) {
@@ -1001,7 +1002,7 @@
     Collections.shuffle(lines, new Random(421439783L)); // constant seed for reproducability
     
     FSDataOutputStream out = fs.create(new Path(outputStep2Dir, FULL_INPUT_LIST));
-    Writer writer = new BufferedWriter(new OutputStreamWriter(out, "UTF-8"));
+    Writer writer = new BufferedWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8));
     try {
       for (String line : lines) {
         writer.write(line + "\n");
@@ -1135,7 +1136,7 @@
    * turnaround during trial & debug sessions
    */
   private void dryRun(MorphlineMapRunner runner, FileSystem fs, Path fullInputList) throws IOException {    
-    BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(fullInputList), "UTF-8"));
+    BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(fullInputList), StandardCharsets.UTF_8));
     try {
       String line;
       while ((line = reader.readLine()) != null) {
@@ -1154,7 +1155,7 @@
     int numFiles = 0;
     FSDataOutputStream out = fs.create(fullInputList);
     try {
-      Writer writer = new BufferedWriter(new OutputStreamWriter(out, "UTF-8"));
+      Writer writer = new BufferedWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8));
       for (FileStatus stat : dirs) {
         LOG.debug("Adding path {}", stat.getPath());
         Path dir = new Path(stat.getPath(), "data/index");
Index: solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrOutputFormat.java
===================================================================
--- solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrOutputFormat.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrOutputFormat.java	(working copy)
@@ -22,6 +22,7 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URI;
+import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Locale;
@@ -242,7 +243,7 @@
     
     ZipEntry ze = new ZipEntry("solr.xml");
     zos.putNextEntry(ze);
-    zos.write("<cores><core name=\"collection1\" instanceDir=\".\"/></cores>".getBytes("UTF-8"));
+    zos.write("<cores><core name=\"collection1\" instanceDir=\".\"/></cores>".getBytes(StandardCharsets.UTF_8));
     zos.flush();
     zos.closeEntry();
     zos.close();
Index: solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ToolRunnerHelpFormatter.java
===================================================================
--- solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ToolRunnerHelpFormatter.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ToolRunnerHelpFormatter.java	(working copy)
@@ -24,6 +24,7 @@
 import java.io.StringReader;
 import java.io.StringWriter;
 import java.io.UnsupportedEncodingException;
+import java.nio.charset.StandardCharsets;
 
 import net.sourceforge.argparse4j.ArgumentParsers;
 import net.sourceforge.argparse4j.helper.ASCIITextWidthCounter;
@@ -41,8 +42,8 @@
     ByteArrayOutputStream bout = new ByteArrayOutputStream();
     String msg;
     try {
-      ToolRunner.printGenericCommandUsage(new PrintStream(bout, true, "UTF-8"));
-      msg = new String(bout.toByteArray(), "UTF-8");
+      ToolRunner.printGenericCommandUsage(new PrintStream(bout, true, StandardCharsets.UTF_8.name()));
+      msg = new String(bout.toByteArray(), StandardCharsets.UTF_8);
     } catch (UnsupportedEncodingException e) {
       throw new RuntimeException(e); // unreachable
     }
Index: solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/UnbufferedDataInputInputStream.java
===================================================================
--- solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/UnbufferedDataInputInputStream.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/UnbufferedDataInputInputStream.java	(working copy)
@@ -22,6 +22,7 @@
 import java.io.DataInputStream;
 import java.io.IOException;
 import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
 
 public class UnbufferedDataInputInputStream extends org.apache.solr.common.util.DataInputInputStream {
   private final DataInputStream in;
@@ -97,7 +98,7 @@
 
   @Override
   public String readLine() throws IOException {
-    BufferedReader reader = new BufferedReader(new InputStreamReader(in, "UTF-8"));
+    BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));
     return reader.readLine();
   }
 
Index: solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ZooKeeperInspector.java
===================================================================
--- solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ZooKeeperInspector.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/ZooKeeperInspector.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -193,7 +194,7 @@
       Files.move(dir, confDir);
       dir = confDir.getParentFile();
     }
-    FileUtils.writeStringToFile(new File(dir, "solr.xml"), "<solr><cores><core name=\"collection1\" instanceDir=\".\" /></cores></solr>", "UTF-8");
+    FileUtils.writeStringToFile(new File(dir, "solr.xml"), "<solr><cores><core name=\"collection1\" instanceDir=\".\" /></cores></solr>", StandardCharsets.UTF_8.name());
     verifyConfigDir(confDir);
     return dir;
   }
Index: solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MapReduceIndexerToolArgumentParserTest.java
===================================================================
--- solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MapReduceIndexerToolArgumentParserTest.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MapReduceIndexerToolArgumentParserTest.java	(working copy)
@@ -20,6 +20,7 @@
 import java.io.File;
 import java.io.PrintStream;
 import java.io.UnsupportedEncodingException;
+import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
 import java.util.Collections;
 
@@ -73,10 +74,10 @@
     opts = new MapReduceIndexerTool.Options();
     oldSystemOut = System.out;
     bout = new ByteArrayOutputStream();
-    System.setOut(new PrintStream(bout, true, "UTF-8"));
+    System.setOut(new PrintStream(bout, true, StandardCharsets.UTF_8.name()));
     oldSystemErr = System.err;
     berr = new ByteArrayOutputStream();
-    System.setErr(new PrintStream(berr, true, "UTF-8"));
+    System.setErr(new PrintStream(berr, true, StandardCharsets.UTF_8.name()));
   }
 
   @After
@@ -191,7 +192,7 @@
   public void testArgsParserHelp() throws UnsupportedEncodingException  {
     String[] args = new String[] { "--help" };
     assertEquals(new Integer(0), parser.parseArgs(args, conf, opts));
-    String helpText = new String(bout.toByteArray(), "UTF-8");
+    String helpText = new String(bout.toByteArray(), StandardCharsets.UTF_8);
     assertTrue(helpText.contains("MapReduce batch job driver that "));
     assertTrue(helpText.contains("bin/hadoop command"));
     assertEquals(0, berr.toByteArray().length);
@@ -458,9 +459,9 @@
   
   private void assertArgumentParserException(String[] args) throws UnsupportedEncodingException {
     assertEquals("should have returned fail code", new Integer(1), parser.parseArgs(args, conf, opts));
-    assertEquals("no sys out expected:" + new String(bout.toByteArray(), "UTF-8"), 0, bout.toByteArray().length);
+    assertEquals("no sys out expected:" + new String(bout.toByteArray(), StandardCharsets.UTF_8), 0, bout.toByteArray().length);
     String usageText;
-    usageText = new String(berr.toByteArray(), "UTF-8");
+    usageText = new String(berr.toByteArray(), StandardCharsets.UTF_8);
 
     assertTrue("should start with usage msg \"usage: hadoop \":" + usageText, usageText.startsWith("usage: hadoop "));
   }
Index: solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineBasicMiniMRTest.java
===================================================================
--- solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineBasicMiniMRTest.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineBasicMiniMRTest.java	(working copy)
@@ -22,6 +22,7 @@
 import java.io.OutputStreamWriter;
 import java.io.Writer;
 import java.lang.reflect.Array;
+import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
 
 import org.apache.commons.io.FileUtils;
@@ -307,7 +308,7 @@
     assertTrue(fs.mkdirs(inDir));
     Path INPATH = new Path(inDir, "input.txt");
     OutputStream os = fs.create(INPATH);
-    Writer wr = new OutputStreamWriter(os, "UTF-8");
+    Writer wr = new OutputStreamWriter(os, StandardCharsets.UTF_8);
     wr.write(DATADIR + "/" + inputAvroFile);
     wr.close();
 
Index: solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java
===================================================================
--- solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java	(revision 1583329)
+++ solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java	(working copy)
@@ -24,6 +24,7 @@
 import java.io.Writer;
 import java.lang.reflect.Array;
 import java.net.URI;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -677,7 +678,7 @@
       Path dataDir, String localFile) throws IOException, UnsupportedEncodingException {
     Path INPATH = new Path(inDir, "input.txt");
     OutputStream os = fs.create(INPATH);
-    Writer wr = new OutputStreamWriter(os, "UTF-8");
+    Writer wr = new OutputStreamWriter(os, StandardCharsets.UTF_8);
     wr.write(DATADIR + File.separator + localFile);
     wr.close();
     
Index: solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java
===================================================================
--- solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java	(revision 1583329)
+++ solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java	(working copy)
@@ -19,6 +19,7 @@
 import java.io.ByteArrayInputStream;
 import java.io.File;
 import java.io.IOException;
+import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Collection;
@@ -291,13 +292,13 @@
   }
   
   public static void setupMorphline(String tempDir, String file, boolean replaceSolrLocator) throws IOException {
-    String morphlineText = FileUtils.readFileToString(new File(RESOURCES_DIR + "/" + file + ".conf"), "UTF-8");
+    String morphlineText = FileUtils.readFileToString(new File(RESOURCES_DIR + "/" + file + ".conf"), StandardCharsets.UTF_8.name());
     morphlineText = morphlineText.replace("RESOURCES_DIR", new File(tempDir).getAbsolutePath());
     if (replaceSolrLocator) {
       morphlineText = morphlineText.replace("${SOLR_LOCATOR}",
           "{ collection : collection1 }");
     }
     new File(tempDir + "/" + file + ".conf").getParentFile().mkdirs();
-    FileUtils.writeStringToFile(new File(tempDir + "/" + file + ".conf"), morphlineText, "UTF-8");
+    FileUtils.writeStringToFile(new File(tempDir + "/" + file + ".conf"), morphlineText, StandardCharsets.UTF_8.name());
   }
 }
Index: solr/core/src/java/org/apache/solr/cloud/ZkController.java
===================================================================
--- solr/core/src/java/org/apache/solr/cloud/ZkController.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/cloud/ZkController.java	(working copy)
@@ -59,6 +59,7 @@
 import java.net.NetworkInterface;
 import java.net.URLEncoder;
 import java.net.UnknownHostException;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -1624,7 +1625,7 @@
                                  final String hostContext) {
     try {
       return hostName + ':' + hostPort + '_' + 
-        URLEncoder.encode(trimLeadingAndTrailingSlashes(hostContext), "UTF-8");
+        URLEncoder.encode(trimLeadingAndTrailingSlashes(hostContext), StandardCharsets.UTF_8.name());
     } catch (UnsupportedEncodingException e) {
       throw new IllegalStateException("JVM Does not seem to support UTF-8", e);
     }
Index: solr/core/src/java/org/apache/solr/core/ConfigSolr.java
===================================================================
--- solr/core/src/java/org/apache/solr/core/ConfigSolr.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/core/ConfigSolr.java	(working copy)
@@ -42,6 +42,7 @@
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Properties;
@@ -84,7 +85,7 @@
     try {
       ByteArrayOutputStream baos = new ByteArrayOutputStream();
       ByteStreams.copy(is, baos);
-      String originalXml = IOUtils.toString(new ByteArrayInputStream(baos.toByteArray()), "UTF-8");
+      String originalXml = IOUtils.toString(new ByteArrayInputStream(baos.toByteArray()), StandardCharsets.UTF_8.name());
       ByteArrayInputStream dup = new ByteArrayInputStream(baos.toByteArray());
       Config config = new Config(loader, null, new InputSource(dup), null, false);
       return fromConfig(config, originalXml);
Index: solr/core/src/java/org/apache/solr/core/HdfsDirectoryFactory.java
===================================================================
--- solr/core/src/java/org/apache/solr/core/HdfsDirectoryFactory.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/core/HdfsDirectoryFactory.java	(working copy)
@@ -20,6 +20,7 @@
 import java.io.IOException;
 import java.net.URI;
 import java.net.URLEncoder;
+import java.nio.charset.StandardCharsets;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
@@ -269,10 +270,10 @@
     String path;
     if (cd.getCloudDescriptor() != null) {
       path = URLEncoder.encode(cd.getCloudDescriptor().getCollectionName(),
-          "UTF-8")
+          StandardCharsets.UTF_8.name())
           + "/"
           + URLEncoder.encode(cd.getCloudDescriptor().getCoreNodeName(),
-              "UTF-8");
+          StandardCharsets.UTF_8.name());
     } else {
       path = cd.getName();
     }
Index: solr/core/src/java/org/apache/solr/handler/PingRequestHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/PingRequestHandler.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/handler/PingRequestHandler.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.nio.charset.StandardCharsets;
 import java.util.Date;
 import java.util.Locale;
 
@@ -274,7 +275,7 @@
       try {
         // write out when the file was created
         FileUtils.write(healthcheck, 
-                        DateField.formatExternal(new Date()), "UTF-8");
+                        DateField.formatExternal(new Date()), StandardCharsets.UTF_8.name());
       } catch (IOException e) {
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, 
                                 "Unable to write healthcheck flag file", e);
Index: solr/core/src/java/org/apache/solr/handler/admin/EditFileRequestHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/admin/EditFileRequestHandler.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/handler/admin/EditFileRequestHandler.java	(working copy)
@@ -44,6 +44,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Locale;
@@ -152,7 +153,7 @@
           return; // Error already in rsp.
         }
 
-        data = IOUtils.toByteArray(new InputStreamReader(stream.getStream(), "UTF-8"), "UTF-8");
+        data = IOUtils.toByteArray(new InputStreamReader(stream.getStream(), StandardCharsets.UTF_8), StandardCharsets.UTF_8.name());
 
         // If it's "solrconfig.xml", try parsing it as that object. Otherwise, if it ends in '.xml',
         // see if it at least parses.
@@ -276,7 +277,7 @@
     File home = null;
     try {
       home = new File(FileUtils.getTempDirectory(), "SOLR_5459"); // Unlikely to name a core or collection this!
-      FileUtils.writeStringToFile(new File(home, "solr.xml"), "<solr></solr>", "UTF-8"); // Use auto-discovery
+      FileUtils.writeStringToFile(new File(home, "solr.xml"), "<solr></solr>", StandardCharsets.UTF_8.name()); // Use auto-discovery
       File coll = new File(home, "SOLR_5459");
 
       SolrCore core = req.getCore();
@@ -300,7 +301,7 @@
             new File(coll, "conf"));
       }
 
-      FileUtils.writeStringToFile(new File(coll, "core.properties"), "name=SOLR_5459", "UTF-8");
+      FileUtils.writeStringToFile(new File(coll, "core.properties"), "name=SOLR_5459", StandardCharsets.UTF_8.name());
 
       FileUtils.writeByteArrayToFile(new File(new File(coll, "conf"), req.getParams().get("file", null)), data);
 
Index: solr/core/src/java/org/apache/solr/response/XSLTResponseWriter.java
===================================================================
--- solr/core/src/java/org/apache/solr/response/XSLTResponseWriter.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/response/XSLTResponseWriter.java	(working copy)
@@ -23,6 +23,7 @@
 import java.io.IOException;
 import java.io.Reader;
 import java.io.Writer;
+import java.nio.charset.StandardCharsets;
 import java.util.Map;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -85,7 +86,7 @@
     if (!mediaType.contains("charset")) {
       String encoding = t.getOutputProperty("encoding");
       if (encoding == null || encoding.length()==0) {
-        encoding = "UTF-8";
+        encoding = StandardCharsets.UTF_8.name();
       }
       mediaType = mediaType + "; charset=" + encoding;
     }
Index: solr/core/src/java/org/apache/solr/rest/BaseSolrResource.java
===================================================================
--- solr/core/src/java/org/apache/solr/rest/BaseSolrResource.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/rest/BaseSolrResource.java	(working copy)
@@ -162,7 +162,7 @@
           binWriter.write(outputStream, solrRequest, solrResponse);
         } else {
           String charset = ContentStreamBase.getCharsetFromContentType(contentType);
-          Writer out = (charset == null || charset.equalsIgnoreCase("UTF-8"))
+          Writer out = (charset == null || charset.equalsIgnoreCase(UTF8.name()))
               ? new OutputStreamWriter(outputStream, UTF8)
               : new OutputStreamWriter(outputStream, charset);
           out = new FastWriter(out);
@@ -213,6 +213,6 @@
 
   /** Decode URL-encoded strings as UTF-8, and avoid converting "+" to space */
   protected static String urlDecode(String str) throws UnsupportedEncodingException {
-    return URLDecoder.decode(str.replace("+", "%2B"), "UTF-8");
+    return URLDecoder.decode(str.replace("+", "%2B"), StandardCharsets.UTF_8.name());
   }
 }
Index: solr/core/src/java/org/apache/solr/schema/CollationField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/CollationField.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/schema/CollationField.java	(working copy)
@@ -19,6 +19,7 @@
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
 import java.text.Collator;
 import java.text.ParseException;
 import java.text.RuleBasedCollator;
@@ -177,7 +178,7 @@
     InputStream input = null;
     try {
      input = loader.openResource(fileName);
-     String rules = IOUtils.toString(input, "UTF-8");
+     String rules = IOUtils.toString(input, StandardCharsets.UTF_8.name());
      return new RuleBasedCollator(rules);
     } catch (IOException e) {
       // io error
Index: solr/core/src/java/org/apache/solr/servlet/LoadAdminUiServlet.java
===================================================================
--- solr/core/src/java/org/apache/solr/servlet/LoadAdminUiServlet.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/servlet/LoadAdminUiServlet.java	(working copy)
@@ -50,11 +50,11 @@
     InputStream in = getServletContext().getResourceAsStream("/admin.html");
     if(in != null && cores != null) {
       try {
-        response.setCharacterEncoding("UTF-8");
+        response.setCharacterEncoding(StandardCharsets.UTF_8.name());
         response.setContentType("text/html");
         Writer out = new OutputStreamWriter(response.getOutputStream(), StandardCharsets.UTF_8);
 
-        String html = IOUtils.toString(in, "UTF-8");
+        String html = IOUtils.toString(in, StandardCharsets.UTF_8.name());
         Package pack = SolrCore.class.getPackage();
 
         String[] search = new String[] { 
Index: solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
===================================================================
--- solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java	(working copy)
@@ -767,7 +767,7 @@
         binWriter.write(response.getOutputStream(), solrReq, solrRsp);
       } else {
         String charset = ContentStreamBase.getCharsetFromContentType(ct);
-        Writer out = (charset == null || charset.equalsIgnoreCase("UTF-8"))
+        Writer out = (charset == null || charset.equalsIgnoreCase(UTF8.name()))
           ? new OutputStreamWriter(response.getOutputStream(), UTF8)
           : new OutputStreamWriter(response.getOutputStream(), charset);
         out = new FastWriter(out);
Index: solr/core/src/java/org/apache/solr/update/processor/RegexpBoostProcessor.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/processor/RegexpBoostProcessor.java	(revision 1583329)
+++ solr/core/src/java/org/apache/solr/update/processor/RegexpBoostProcessor.java	(working copy)
@@ -21,6 +21,7 @@
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.nio.charset.Charset;
+import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
@@ -121,7 +122,7 @@
   private List<BoostEntry> initBoostEntries(InputStream is) throws IOException {
     List<BoostEntry> newBoostEntries = new ArrayList<>();
     
-    BufferedReader reader = new BufferedReader(new InputStreamReader(is, Charset.forName("UTF-8")));
+    BufferedReader reader = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8));
     try {
       String line = null;
       while ((line = reader.readLine()) != null) {
