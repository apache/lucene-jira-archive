Index: lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java	(revision 1642868)
+++ lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java	(working copy)
@@ -33,10 +33,12 @@
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.RamUsageEstimator;
 
 /**
  * Constructs a filter for docs matching any of the terms added to this class.
@@ -45,8 +47,10 @@
  * a choice of "category" labels picked by the end user. As a filter, this is much faster than the
  * equivalent query (a BooleanQuery with many "should" TermQueries)
  */
-public final class TermsFilter extends Filter {
+public final class TermsFilter extends Filter implements Accountable {
 
+  private static final long BASE_RAM_BYTES_USED = RamUsageEstimator.shallowSizeOfInstance(TermsFilter.class);
+
   /*
    * this class is often used for large number of terms in a single field.
    * to optimize for this case and to be filter-cache friendly we 
@@ -178,8 +182,15 @@
     this.hashCode = hash;
     
   }
+
+  @Override
+  public long ramBytesUsed() {
+    return BASE_RAM_BYTES_USED
+        + RamUsageEstimator.sizeOf(termsAndFields)
+        + RamUsageEstimator.sizeOf(termsBytes)
+        + RamUsageEstimator.sizeOf(offsets);
+  }
   
-  
   @Override
   public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
     final LeafReader reader = context.reader();
@@ -254,7 +265,13 @@
     return builder.toString();
   }
   
-  private static final class TermsAndField {
+  private static final class TermsAndField implements Accountable {
+
+    private static final long BASE_RAM_BYTES_USED =
+        RamUsageEstimator.shallowSizeOfInstance(TermsAndField.class)
+        + RamUsageEstimator.shallowSizeOfInstance(String.class)
+        + RamUsageEstimator.NUM_BYTES_ARRAY_HEADER; // header of the array held by the String
+
     final int start;
     final int end;
     final String field;
@@ -268,6 +285,13 @@
     }
 
     @Override
+    public long ramBytesUsed() {
+      // this is an approximation since we don't actually know how strings store
+      // their data, which can be JVM-dependent
+      return BASE_RAM_BYTES_USED + field.length() * RamUsageEstimator.NUM_BYTES_CHAR;
+    }
+
+    @Override
     public int hashCode() {
       final int prime = 31;
       int result = 1;
@@ -317,4 +341,5 @@
     Collections.sort(toSort);
     return toSort;
   }
+
 }
Index: lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java
===================================================================
--- lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java	(revision 1642868)
+++ lucene/queries/src/test/org/apache/lucene/queries/TermsFilterTest.java	(working copy)
@@ -46,12 +46,14 @@
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.RamUsageTester;
 import org.apache.lucene.util.TestUtil;
 
+import com.carrotsearch.randomizedtesting.generators.RandomStrings;
+
 public class TermsFilterTest extends LuceneTestCase {
 
   public void testCachability() throws Exception {
@@ -336,4 +338,18 @@
                                               new Term("field1", "c"));
     assertEquals("field1:a field1:b field1:c", termsFilter.toString());
   }
+
+  public void testRamBytesUsed() {
+    List<Term> terms = new ArrayList<>();
+    final int numTerms = 1000 + random().nextInt(1000);
+    for (int i = 0; i < numTerms; ++i) {
+      terms.add(new Term("f", RandomStrings.randomUnicodeOfLength(random(), 10)));
+    }
+    TermsFilter filter = new TermsFilter(terms);
+    final long actualRamBytesUsed = RamUsageTester.sizeOf(filter);
+    final long expectedRamBytesUsed = filter.ramBytesUsed();
+    // error margin within 1%
+    assertEquals(actualRamBytesUsed, expectedRamBytesUsed, actualRamBytesUsed / 100);
+  }
+
 }
