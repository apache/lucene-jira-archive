diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 143067d..f4133cf 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -37,6 +37,9 @@ New Features
   long "sequence number" indicating the effective equivalent
   single-threaded execution order (Mike McCandless)
 
+* LUCENE-7321: Character Mapping filter for morphological modificataions of the tokens 
+  (Ivan Provalov)
+
 API Changes
 
 * LUCENE-7184: Refactor LatLonPoint encoding methods to new GeoEncodingUtils
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingCollapser.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingCollapser.java
new file mode 100644
index 0000000..1f0c37a
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingCollapser.java
@@ -0,0 +1,117 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/***
+ * 
+ * This class will collapse the graph and also help debugging it: one could convert the produced file into pdf using the graphviz:
+ *         `dot -Tpdf logs/ar-map.dot -o logs/ar-map.pdf`
+ *         
+ */
+public class CharacterMappingCollapser {
+
+	private Map<String, CharacterMappingVertex> vertices = new HashMap<String, CharacterMappingVertex>();
+	private final CharacterMappingSimpleStringTransformer characterMappingStringTransformer;
+	private CharacterMappingReportWriter characterMappingReportWriter;
+
+	public CharacterMappingCollapser(String transliteratorForDebug, CharacterMappingReportWriter characterMappingReportWriter) {
+		this.characterMappingStringTransformer = new CharacterMappingSimpleStringTransformer();
+		this.characterMappingReportWriter = characterMappingReportWriter;
+	}
+
+	public void addEdge(String key, String value) {
+
+		boolean nodeSuccessfullyCreated = validateNodeAndWriteToReport(key, value);
+
+		if (nodeSuccessfullyCreated) {
+			CharacterMappingVertex nodeForKey = vertices.get(key);
+			if (nodeForKey == null)
+				nodeForKey = new CharacterMappingVertex(key);
+
+			CharacterMappingVertex nodeForValue = vertices.get(value);
+			if (nodeForValue == null)
+				nodeForValue = new CharacterMappingVertex(value);
+
+			nodeForKey.setParent(nodeForValue);
+
+			vertices.put(key, nodeForKey);
+			vertices.put(value, nodeForValue);
+		}
+	}
+
+	private boolean validateNodeAndWriteToReport(String key, String value) {
+		String transformedKey = getTransformedString(key);
+		String transformedValue = getTransformedString(value);
+		if (transformedKey.isEmpty())
+			transformedKey = key.toString();
+		if (transformedValue.isEmpty())
+			transformedValue = "NULL";
+		if (getRoot(value) != null && getRoot(value).getVertexValue().equals(key)) {
+			writeCircularDependencyNode(key, value, transformedKey, transformedValue);
+			return false;
+		} else if (vertices.containsKey(key) && vertices.get(key).getAdjacent() != null	&& vertices.get(key).getAdjacent().size() > 0) {
+			writeRepeatedKeyNode(key, value, transformedKey, transformedValue);
+			return false;
+		}
+		writeRegularNode(key, value, transformedKey, transformedValue);
+		return true;
+	}
+
+	private String getTransformedString(String string) {
+		return characterMappingStringTransformer.getTransformedString(string);
+	}
+
+	protected void writeHeader() {
+		if (characterMappingReportWriter != null) {
+			characterMappingReportWriter.writeToReportFile("digraph {");
+		}
+	}
+	
+	protected void writeClosing() {
+		if (characterMappingReportWriter != null) {
+			characterMappingReportWriter.writeToReportFile("}");
+			characterMappingReportWriter.close();
+		}
+	}
+	
+	private void writeRegularNode(String key, String value, String transformedKey, String transformedValue) {
+		if (characterMappingReportWriter != null) {
+			characterMappingReportWriter.writeToReportFile(transformedKey + " [fontsize=18,label=\"" + key + "/" + transformedKey + "\"];");
+			characterMappingReportWriter.writeToReportFile(transformedValue + " [fontsize=18,label=\"" + value + "/" + transformedValue + "\"];");
+			characterMappingReportWriter.writeToReportFile(transformedKey + "->" + transformedValue);
+		}
+	}
+
+	private void writeRepeatedKeyNode(String key, String value, String transformedKey, String transformedValue) {
+		if (characterMappingReportWriter != null) {
+			characterMappingReportWriter.writeToReportFile(transformedKey + " [label=\"" + key + "\",style=filled,color=red];");
+			characterMappingReportWriter.writeToReportFile(transformedValue + " [label=\"" + value + "\",style=filled,color=yellow];");
+			characterMappingReportWriter.writeToReportFile(transformedKey + "->" + transformedValue);
+		}
+	}
+
+	private void writeCircularDependencyNode(String key, String value, String transformedKey, String transformedValue) {
+		if (characterMappingReportWriter != null) {
+			characterMappingReportWriter.writeToReportFile(transformedKey + " [label=\"" + key + "\",style=filled,color=red];");
+			characterMappingReportWriter.writeToReportFile(transformedValue + " [label=\"" + value + "\",style=filled,color=lightgrey];");
+			characterMappingReportWriter.writeToReportFile(transformedKey + "->" + transformedValue);
+		}
+	}
+
+	public Map<String, CharacterMappingVertex> getVertices() {
+		return vertices;
+	}
+
+	public CharacterMappingVertex getRoot(String vertexValue) {
+		CharacterMappingVertex node = vertices.get(vertexValue);
+		if (node != null && node.getAdjacent() != null)
+			for (CharacterMappingVertex adjacent : node.getAdjacent()) {
+				if (adjacent.isRoot())
+					return adjacent;
+				else
+					return getRoot(adjacent.getVertexValue());
+			}
+		return node;
+	}
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilter.java
new file mode 100644
index 0000000..0ce9d56
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilter.java
@@ -0,0 +1,135 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.Set;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.AttributeSource;
+
+public final class CharacterMappingFilter extends TokenFilter {
+    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    private final PositionIncrementAttribute posIncAttr = addAttribute(PositionIncrementAttribute.class);
+    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+    
+    private int minPrefix;
+    private int minLength;
+    private CharacterMappingTrie trie;
+    private Set<String> protectedWords;
+    private Boolean keepOriginalToken;
+    private Boolean matchFromEnd;
+    private Boolean isPrefixMatch;
+    private Boolean isFirstTokenOnly;
+    private LinkedList<AttributeSource.State> states = new LinkedList<AttributeSource.State>();
+    private int tokenProcessed = 0;
+
+    /**
+     * Create a new {@link CharacterMappingFilter}.
+     * 
+     * @param input TokenStream to filter
+     * @param trie - Factory created lookup structure
+     * @param minPrefix - check starts with character (minPrefix+1)
+     * @param protectedWords protectedWords
+     * @param keepOriginalToken keepOriginalToken
+     * @param matchFromEnd matchFromEnd
+     * @param isFirstTokenOnly isFirstTokenOnly
+     * 
+     **/
+    public CharacterMappingFilter(TokenStream input, CharacterMappingTrie trie, int minPrefix, Set<String> protectedWords, boolean keepOriginalToken, boolean matchFromEnd, boolean isPrefixMatch, boolean isFirstTokenOnly, int minLength) {
+        super(input);
+        this.trie = trie;
+        this.minPrefix = minPrefix;
+        this.protectedWords = protectedWords;
+        this.keepOriginalToken = keepOriginalToken;
+        this.matchFromEnd = matchFromEnd;
+        this.isPrefixMatch = isPrefixMatch;
+        this.isFirstTokenOnly = isFirstTokenOnly;
+        this.minLength = minLength;
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException
+    {
+        while (states.size() > 0) {
+            AttributeSource.State state = states.removeFirst();
+            restoreState(state);
+            return true;
+        }
+        
+        tokenIncrementerLoop: while (input.incrementToken()) {
+            if (isFirstTokenOnly && tokenProcessed > 0){
+                tokenProcessed++;
+                return true;
+            }
+            
+            String thisTerm = new String(termAtt.buffer(), 0, termAtt.length());
+            if (protectedWords != null && protectedWords.contains(thisTerm)) {
+                tokenProcessed++;
+                return true;
+            }
+            if (thisTerm.length() < minLength) {
+                tokenProcessed++;
+                return true;
+            }
+            String generatedTerm = trie.getSubstituted(thisTerm, minPrefix, matchFromEnd, isPrefixMatch);
+            if (generatedTerm != null && !generatedTerm.equals(thisTerm)) {
+
+                if (generatedTerm.isEmpty()) {
+                    tokenProcessed++;
+                    if(isFirstTokenOnly) 
+                    {
+                        return true;
+                    }
+                    continue tokenIncrementerLoop;
+                }
+
+                if (keepOriginalToken) {
+                    int positionIncrement = 1;
+                    if (posIncAttr.getPositionIncrement() == 0 && tokenProcessed > 0)
+                        positionIncrement = 0;
+                    putAllAttributesOfReplacementStringInStateObjectToUseLater(generatedTerm);
+                    setCurrentTermToBeProducedAsNextToken(thisTerm, positionIncrement);
+                } else {
+                    overrideCurrentTerm(generatedTerm);
+                }
+            }
+            tokenProcessed++;
+            return true;
+        }
+        return false;
+    }
+
+    protected void overrideCurrentTerm(String generatedTerm)
+    {
+        termAtt.copyBuffer(generatedTerm.toCharArray(), 0, generatedTerm.length());
+        termAtt.setLength(generatedTerm.length());
+        typeAtt.setType("generated");
+    }
+
+    protected void setCurrentTermToBeProducedAsNextToken(String thisTerm, int positionIncrement)
+    {
+        posIncAttr.setPositionIncrement(positionIncrement);
+        termAtt.copyBuffer(thisTerm.toCharArray(), 0, thisTerm.length());
+        termAtt.setLength(thisTerm.length());
+    }
+
+    protected void putAllAttributesOfReplacementStringInStateObjectToUseLater(String generatedTerm)
+    {
+        overrideCurrentTerm(generatedTerm);
+        posIncAttr.setPositionIncrement(0);
+        AttributeSource.State current = captureState();
+        states.add(current);
+    }
+
+    @Override
+    public void reset() throws IOException
+    {
+        super.reset();
+        states.clear();
+        this.tokenProcessed = 0;
+    }
+}
\ No newline at end of file
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilterFactory.java
new file mode 100644
index 0000000..72adb68
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingFilterFactory.java
@@ -0,0 +1,89 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.lucene.analysis.util.ResourceLoaderAware;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/***
+Parameters
+        mappingFile - e.g. "lang/mapping-ja.txt"
+        protectedWordsFile - e.g. "lang/protected-ja.txt"
+
+Morphological Features
+
+	minPrefix - check for potential substitution character(s) starts with minPrefix+1 position (e.g. for suffix folding, one may only consider tokens starting in position two)
+	minLength - checks the min length of the token before applying the transformation
+	keepOriginalToken - e.g. in suffix folding (autocomplete case) it is useful to keep both tokens if ngram indexing is used
+	matchFromEnd - for prefix vs suffix replacement (suffix folding case)
+	isPrefixMatch - whether a match can start in any position, or only prefix match (Arabic prefix removal)
+	isFirstTokenOnly - only apply the substitutions to the first token in the field (Korean last names removal)
+
+Debugging
+        transliteratorForDebug - ICU ID for debugging the keys/values, e.g. “Hiragana-Latin”
+        dotFile - e.g. "logs/mapping-ja.dot" to produce a .dot file (one could convert the produced dot file into pdf using the graphviz: `dot -Tpdf logs/ar-map.dot -o logs/ar-map.pdf`)
+
+ *
+ */
+public class CharacterMappingFilterFactory extends TokenFilterFactory  implements ResourceLoaderAware {
+
+    private String mappingFile;
+    private CharacterMappingTrie trie;
+    private int minPrefix;
+    private int minLength;
+    private String protectedWordsFile;
+    private Set<String> protectedWords = null;
+    public static final int BUFFER_SIZE = 1 << 16;
+    private Boolean keepOriginalToken;
+    private Boolean matchFromEnd;
+    private Boolean isPrefixMatch;
+    private Boolean isFirstTokenOnly;
+    private String transliteratorForDebug;
+    private String dotFile;
+
+    public CharacterMappingFilterFactory(Map<String, String> args) {
+        super(args);
+        mappingFile = get(args, "mappingFile", "");
+        protectedWordsFile = get(args, "protectedWords", "");
+        minPrefix = getInt(args, "minPrefix", 2);
+        minLength = getInt(args, "minLength", 0);
+        keepOriginalToken = getBoolean(args, "keepOriginalToken", false);
+        matchFromEnd = getBoolean(args, "matchFromEnd", false);
+        isPrefixMatch = getBoolean(args, "isPrefixMatch", false);
+        isFirstTokenOnly = getBoolean(args, "isFirstTokenOnly", false);
+        transliteratorForDebug = get(args, "transliteratorForDebug", "Null");
+        dotFile = get(args, "dotFile", "");
+        if (!args.isEmpty()) {
+            throw new IllegalArgumentException("Unknown parameters: " + args);
+        }
+        if (matchFromEnd && isPrefixMatch) {
+            throw new IllegalArgumentException("Invalid config - both isPrefixMatch and matchFromEnd cannot be set to true: " + args);
+        }
+    }
+    
+    @Override
+    public void inform(ResourceLoader loader) throws IOException {
+      if (mappingFile != null && protectedWordsFile!=null) {
+        InputStream stream = loader.openResource(mappingFile);
+    	CharacterMappingLoader trieLoader = new CharacterMappingLoader(transliteratorForDebug, dotFile);
+        trie = new CharacterMappingTrie();
+        trieLoader.populate(trie, stream);
+        List<String> lines = getLines(loader, protectedWordsFile);
+        protectedWords = new HashSet<String>(lines);
+      } else 
+          trie = null;
+    }
+    
+    @Override
+    public TokenStream create(TokenStream input)
+    {
+        return new CharacterMappingFilter(input, trie, minPrefix, protectedWords, keepOriginalToken, matchFromEnd, isPrefixMatch, isFirstTokenOnly, minLength);
+    }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingLoader.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingLoader.java
new file mode 100644
index 0000000..b90a929
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingLoader.java
@@ -0,0 +1,59 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+
+public class CharacterMappingLoader {
+
+	private static final int BUFFER_SIZE = 1 << 16;
+	
+	private final CharacterMappingCollapser keyCollapser;
+
+	public CharacterMappingLoader(String transliteratorForDebug, String dotFileName) {
+		CharacterMappingReportWriter characterMappingReportWriter = null;
+		if (dotFileName != null && !dotFileName.equals(""))
+			characterMappingReportWriter = new CharacterMappingReportWriter(dotFileName);
+		keyCollapser = new CharacterMappingCollapser(transliteratorForDebug, characterMappingReportWriter);
+	}
+
+	public int populate(CharacterMappingTrie trie, InputStream is) throws IOException {
+		BufferedReader reader = new BufferedReader(new InputStreamReader(is, "UTF-8"), BUFFER_SIZE);
+		String lineString = null;
+		keyCollapser.writeHeader();
+		while ((lineString = reader.readLine()) != null) {
+			String[] keyValue = lineString.split("\\t+");
+			String key = keyValue[0];
+			String value = "";
+			if (keyValue.length == 2)
+				value = keyValue[1];
+			addToKeyCollapser(key, value);
+		}
+		keyCollapser.writeClosing();
+		
+		int totalCollapsed = addAllItemsToTrieTree(trie);
+		keyCollapser.getVertices().clear();
+
+		reader.close();
+		is.close();
+		return totalCollapsed;
+	}
+
+	protected int addAllItemsToTrieTree(CharacterMappingTrie trie) {
+		int counter = 0;
+		for (CharacterMappingVertex n : keyCollapser.getVertices().values()) {
+			String key = n.getVertexValue();
+			String value = keyCollapser.getRoot(n.getVertexValue()).getVertexValue();
+			if (!key.equals(value)) {
+				trie.put(key, value);
+				counter++;
+			}
+		}
+		return counter;
+	}
+
+	public void addToKeyCollapser(String key, String value) {
+		keyCollapser.addEdge(key, value);
+	}
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingReportWriter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingReportWriter.java
new file mode 100644
index 0000000..491f3f5
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingReportWriter.java
@@ -0,0 +1,44 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.BufferedOutputStream;
+import java.io.BufferedWriter;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+
+public class CharacterMappingReportWriter {
+
+	private OutputStream os;
+	private BufferedWriter writer;
+
+	public CharacterMappingReportWriter(String reportFileName) {
+		if (reportFileName != null && !reportFileName.equals(""))
+			try {
+				new File(reportFileName).delete();
+				os = new BufferedOutputStream(new FileOutputStream(reportFileName, true));
+				writer = new BufferedWriter(new OutputStreamWriter(os, "UTF-8"));
+			} catch (Throwable e) {
+				throw new RuntimeException("Could not create report file: ", e);
+			}
+	}
+
+	public synchronized void writeToReportFile(String results) {
+		try {
+			writer.append(results);
+			writer.newLine();
+			writer.flush();
+		} catch (Throwable e) {
+			throw new RuntimeException("Could not create report file: ", e);
+		}
+	}
+
+	public void close() {
+		try {
+			writer.close();
+			os.close();
+		} catch (Throwable e) {
+			throw new RuntimeException("Could not create report file: ", e);
+		}
+	}
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingSimpleStringTransformer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingSimpleStringTransformer.java
new file mode 100644
index 0000000..7f7605f
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingSimpleStringTransformer.java
@@ -0,0 +1,10 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+public class CharacterMappingSimpleStringTransformer implements CharacterMappingStringTransformer {
+
+	@Override
+	public String getTransformedString(String string) {
+		return string;
+	}
+
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingStringTransformer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingStringTransformer.java
new file mode 100644
index 0000000..63d7694
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingStringTransformer.java
@@ -0,0 +1,14 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/***
+ * 
+ * The classes implementing this interface are responsible for transforming the node 
+ * values for generating the graph.  The simple implementation will just return the String
+ * ICU implementation will return a transformed string give the ICU ID.
+ *
+ */
+public interface CharacterMappingStringTransformer {
+
+	String getTransformedString(String obj);
+	
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingTrie.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingTrie.java
new file mode 100644
index 0000000..95a916c
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingTrie.java
@@ -0,0 +1,183 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/***
+ * Trie tree implementation where the children are a Map<Character, Node>
+ * 
+ */
+import java.util.HashMap;
+import java.util.Map;
+
+public class CharacterMappingTrie {
+
+    private Node root = new Node();
+
+    private class Node {
+        Map<Character, Node> children = new HashMap<Character, Node>();
+
+        boolean leaf;
+        String value;
+
+        @Override
+        public String toString()
+        {
+            return "Node [children=" + children + ", leaf=" + leaf + ", value=" + value + "]";
+        }
+
+    }
+
+    public void put(String input, String value)
+    {
+        put(input, root, 0, value);
+    }
+
+    private Node put(String input, Node node, int depth, String value)
+    {
+        if (node == null) {
+            node = new Node();
+        }
+        if (input.length() == depth) {
+            node.leaf = true;
+            node.value = value;
+            return node;
+        }
+        char c = input.charAt(depth);
+        node.children.put(c, put(input, node.children.get(c), depth + 1, value));
+        return node;
+    }
+
+    private Node getTrieRoot()
+    {
+        return root;
+    }
+
+    public String getSubstituted(String input, int minPrefix, boolean matchFromEnd, boolean isPrefixMatch)
+    {
+        if (matchFromEnd)
+            return getSubstitutedFromEnd(input, minPrefix);
+        else
+            return getSubstituted(input, minPrefix, isPrefixMatch);
+    }
+
+    private String getSubstituted(final String input, int minPrefix, boolean isPrefixMatch)
+    {
+        if (input == null)
+            return null;
+        Replacement replacement = null;
+        firstCharMovingLoop: for (int matchStartIndex = minPrefix; matchStartIndex < input.length(); matchStartIndex++) {
+            if (replacement != null && matchStartIndex < replacement.matchEndIndex) {
+                matchStartIndex = replacement.matchEndIndex;
+            }
+            int matchEndIndex = matchStartIndex;
+            Node trieNode = getTrieRoot();
+            lastCharMovingLoop: while (trieNode != null) {
+                if (trieNode.leaf) {
+                    if (replacement == null) {
+                        replacement = new Replacement(input);
+                    }
+                    if ((!isPrefixMatch) || (isPrefixMatch && matchStartIndex==minPrefix)) {
+                        replacement.matchEndIndex = matchEndIndex;
+                        if (replacement.matchStartIndex == matchStartIndex && replacement.stringWithPreviousReplacements!=null) {
+                            replacement.matchStartIndex = matchStartIndex;
+                            replacement.stringWithReplacements = replacement.modifyStringWithCurrentReplacement(replacement.stringWithPreviousReplacements, replacement.adjustedPreviousMatchStartPostion, new String(trieNode.value));
+                            replacement.adjustedMatchStartPostion = replacement.getAdjustedMatchStartPosition(replacement.adjustedPreviousMatchStartPostion, trieNode.value.length());
+                        } else {
+                            replacement.matchStartIndex = matchStartIndex;
+                            replacement.stringWithPreviousReplacements = replacement.stringWithReplacements;
+                            replacement.adjustedPreviousMatchStartPostion = replacement.adjustedMatchStartPostion;
+                            replacement.stringWithReplacements = replacement.modifyStringWithCurrentReplacement(replacement.stringWithReplacements, replacement.adjustedMatchStartPostion, new String(trieNode.value));
+                            replacement.adjustedMatchStartPostion = replacement.getAdjustedMatchStartPosition(replacement.adjustedMatchStartPostion, trieNode.value.length());
+                        }
+                    }
+                }
+                if (matchEndIndex >= input.length())
+                    break lastCharMovingLoop;
+                trieNode = getNextTrieNodeAtNode(trieNode, input, matchEndIndex++, null);
+            }
+
+        }
+        return replacement!=null ? replacement.stringWithReplacements : null;
+    }
+    
+    private String getSubstitutedFromEnd(final String input, int minPrefix)
+    {
+        if (input == null)
+            return null;
+        Replacement replacement = null;
+        firstCharMovingLoop: for (int matchStartIndex = input.length() - 1; matchStartIndex >= minPrefix; matchStartIndex--) {
+            int matchEndIndex = matchStartIndex;
+            Node trieNode = getTrieRoot();
+            lastCharMovingLoop: while (trieNode != null) {
+                if (trieNode.leaf) {
+                    if (replacement == null) {
+                        replacement = new Replacement(input);
+                    }
+                    if (matchEndIndex == input.length()) {
+                        replacement.matchEndIndex = matchEndIndex;
+                        if (replacement.matchEndIndex == matchEndIndex && replacement.stringWithPreviousReplacements != null) {
+                            replacement.matchStartIndex = matchStartIndex;
+                            replacement.stringWithReplacements = replacement.modifyStringWithCurrentReplacement(replacement.stringWithPreviousReplacements, replacement.adjustedPreviousMatchStartPostion, new String(trieNode.value));
+                            replacement.adjustedMatchStartPostion = replacement.getAdjustedMatchStartPositionForMavingBackward(replacement.adjustedPreviousMatchStartPostion, trieNode.value.length());
+                        } else {
+                            replacement.matchStartIndex = matchStartIndex;
+                            replacement.stringWithPreviousReplacements = replacement.stringWithReplacements;
+                            replacement.adjustedPreviousMatchStartPostion = replacement.adjustedMatchStartPostion;
+                            replacement.stringWithReplacements = replacement.modifyStringWithCurrentReplacement(replacement.stringWithReplacements, replacement.adjustedMatchStartPostion, new String(trieNode.value));
+                            replacement.adjustedMatchStartPostion = replacement.getAdjustedMatchStartPositionForMavingBackward(replacement.adjustedMatchStartPostion, trieNode.value.length());
+                        }
+                    }
+                }
+                if (matchEndIndex >= input.length())
+                    break lastCharMovingLoop;
+                trieNode = getNextTrieNodeAtNode(trieNode, input, matchEndIndex++, null);
+            }
+
+        }
+        return replacement != null ? replacement.stringWithReplacements : null;
+    }
+
+    private class Replacement{
+        private final String input;
+        private final int inputLength;
+        private String stringWithReplacements;
+        private String stringWithPreviousReplacements;
+        private int adjustedMatchStartPostion;
+        private int adjustedPreviousMatchStartPostion;
+        private int matchStartIndex;
+        private int matchEndIndex;
+        
+        public Replacement(String input) {
+            super();
+            this.input = input;
+            this.inputLength = input.length();
+            this.stringWithReplacements = new String (input);
+            this.adjustedMatchStartPostion = 0;
+        }
+        
+        protected String modifyStringWithCurrentReplacement(String stringWithReplacements, int adjustedMatchStartPostion, String replacementValue)
+        {
+            int start = matchStartIndex + adjustedMatchStartPostion;
+            String stringNewValue = stringWithReplacements.substring(0, start) + replacementValue + input.substring(matchEndIndex, inputLength);
+            return stringNewValue;
+        }
+
+        protected int getAdjustedMatchStartPosition(int adjustedMatchStartPostion, int replacementValueLength)
+        {
+            return adjustedMatchStartPostion + replacementValueLength - (matchEndIndex - matchStartIndex);
+        }
+        
+        protected int getAdjustedMatchStartPositionForMavingBackward(int adjustedMatchStartPostion, int replacementValueLength)
+        {
+            return adjustedMatchStartPostion - replacementValueLength + (matchEndIndex - matchStartIndex);
+        }
+    }
+    
+    private Node getNextTrieNodeAtNode(final Node x, final String key, final int d, Node lastMatchedNode)
+    {
+        if (x == null)
+            return null;
+        if (d == key.length())
+            return x;
+        char c = key.charAt(d);
+        return x.children.get(c);
+    }
+}
\ No newline at end of file
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingVertex.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingVertex.java
new file mode 100644
index 0000000..2da2d16
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CharacterMappingVertex.java
@@ -0,0 +1,64 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.util.HashSet;
+import java.util.Set;
+
+public class CharacterMappingVertex {
+
+	private Set<CharacterMappingVertex> parents = new HashSet<CharacterMappingVertex>();
+
+	private String vertexValue;
+
+	public CharacterMappingVertex(String vertexValue) {
+		this.vertexValue = vertexValue;
+	}
+
+	public void setParent(CharacterMappingVertex parent) {
+		if (parent != null) {
+			this.parents.add(parent);
+		}
+	}
+
+	public boolean isRoot() {
+		return parents.isEmpty();
+	}
+
+	public Set<CharacterMappingVertex> getAdjacent() {
+		return parents;
+	}
+
+	public String getVertexValue() {
+		return vertexValue;
+	}
+
+	@Override
+	public String toString() {
+		return "'" + vertexValue + "':" + parents;
+	}
+
+	@Override
+	public int hashCode() {
+		final int prime = 31;
+		int result = 1;
+		result = prime * result + ((vertexValue == null) ? 0 : vertexValue.hashCode());
+		return result;
+	}
+
+	@Override
+	public boolean equals(Object obj) {
+		if (this == obj)
+			return true;
+		if (obj == null)
+			return false;
+		if (getClass() != obj.getClass())
+			return false;
+		CharacterMappingVertex other = (CharacterMappingVertex) obj;
+		if (vertexValue == null) {
+			if (other.vertexValue != null)
+				return false;
+		} else if (!vertexValue.equals(other.vertexValue))
+			return false;
+		return true;
+	}
+
+}
diff --git a/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
index 8b19cdf..ab0d09d 100644
--- a/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
+++ b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
@@ -60,6 +60,7 @@ org.apache.lucene.analysis.it.ItalianLightStemFilterFactory
 org.apache.lucene.analysis.lv.LatvianStemFilterFactory
 org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilterFactory
 org.apache.lucene.analysis.miscellaneous.CapitalizationFilterFactory
+org.apache.lucene.analysis.miscellaneous.CharacterMappingFilterFactory
 org.apache.lucene.analysis.miscellaneous.CodepointCountFilterFactory
 org.apache.lucene.analysis.miscellaneous.DateRecognizerFilterFactory
 org.apache.lucene.analysis.miscellaneous.FingerprintFilterFactory
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingCollapser.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingCollapser.java
new file mode 100644
index 0000000..21cd55c
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingCollapser.java
@@ -0,0 +1,85 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import static org.junit.Assert.assertEquals;
+
+import org.junit.Test;
+
+public class TestCharacterMappingCollapser {
+
+    @Test
+    public void test()
+    {
+        CharacterMappingCollapser g = new CharacterMappingCollapser("Null", null);
+        
+        g.addEdge("d", "a");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("a", "b");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("d", "a");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("c", "a");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("b", "e");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("f", "x");
+        System.out.println(g.getVertices());
+        
+        g.addEdge("f", "z");//repeated, not added
+        System.out.println(g.getVertices());
+        
+        g.addEdge("e", "a");//circular won't be added
+        System.out.println(g.getVertices());
+        
+        for (CharacterMappingVertex n: g.getVertices().values())
+            System.out.println(n.getVertexValue()+":"+g.getRoot(n.getVertexValue()).getVertexValue());
+        
+        assertEquals("e", g.getRoot("a").getVertexValue());
+        assertEquals("e", g.getRoot("b").getVertexValue());
+        assertEquals("e", g.getRoot("c").getVertexValue());
+        assertEquals("e", g.getRoot("d").getVertexValue());
+        assertEquals("e", g.getRoot("e").getVertexValue());
+        assertEquals("x", g.getRoot("f").getVertexValue());
+        assertEquals("x", g.getRoot("x").getVertexValue());
+        
+    }
+
+    @Test
+    public void testKeyCollapserKorean()
+    {
+    	CharacterMappingLoader loader = new CharacterMappingLoader("Hangul-Latin","");
+        CharacterMappingTrie genericTree = new CharacterMappingTrie();
+
+        loader.addToKeyCollapser("ᄋ", "ㅇ");
+        
+        loader.addAllItemsToTrieTree(genericTree);
+        
+        assertEquals("ㅇ", genericTree.getSubstituted("ᄋ", 0, false, false));
+    }
+    	
+    @Test
+    public void testKeyCollapser()
+    {
+    	CharacterMappingLoader loader = new CharacterMappingLoader("Null","");
+        CharacterMappingTrie genericTree = new CharacterMappingTrie();
+
+        loader.addToKeyCollapser("d", "a");
+        loader.addToKeyCollapser("a", "b");
+        loader.addToKeyCollapser("c", "a");
+        loader.addToKeyCollapser("b", "e");
+        loader.addToKeyCollapser("x", "");
+        
+        loader.addAllItemsToTrieTree(genericTree);
+        
+        assertEquals("e", genericTree.getSubstituted("a", 0, false, false));
+        assertEquals("e", genericTree.getSubstituted("b", 0, false, false));
+        assertEquals("e", genericTree.getSubstituted("c", 0, false, false));
+        assertEquals("e", genericTree.getSubstituted("d", 0, false, false));
+        assertEquals("", genericTree.getSubstituted("x", 0, false, false));
+    }
+
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingFilterFactory.java
new file mode 100644
index 0000000..72815c0
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingFilterFactory.java
@@ -0,0 +1,316 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.BaseTokenStreamFactoryTestCase;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.lucene.analysis.util.StringMockResourceByNameLoader;
+import org.apache.lucene.analysis.util.StringMockResourceLoader;
+import org.apache.lucene.util.Version;
+import org.junit.Before;
+
+public class TestCharacterMappingFilterFactory extends BaseTokenStreamFactoryTestCase {
+    private String minPrefix = null;
+    private String inputString = null;
+    private String mappings = null;
+
+    @Before
+    public void setup()
+    {
+        minPrefix = "2";
+        inputString = "にせんじゅうにつヴァ";
+        mappings = "つ\tっ\n" + "ヴァ\tバ";
+    }
+
+    public void testWithSynonyms() throws Exception
+    {
+        Reader reader = new StringReader("termA termB termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        stream = tokenFilterFactory("Synonym", Version.LUCENE_CURRENT, new StringMockResourceLoader("termB, term_B\ntermC, term_C"), "synonyms", "synonyms.txt").create(stream);
+        mappings = "C\tc\n";
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("keepOriginalToken", "true");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termA", 
+                "termB", "term_B", 
+                "termC", "termc", "term_C","term_c" }, 
+                new int[] { 0, 6, 6, 12, 12, 12, 12}, 
+                new int[] { 5, 11, 11, 17, 17, 17, 17}, 
+                new int[] { 1, 1, 0, 1, 0, 0, 0});
+    }
+
+    public void testRemoveFirstToken() throws Exception
+    {
+        Reader reader = new StringReader("AA termB termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "AA";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", "0");
+                put("isPrefixMatch", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termB", "termC" }, 
+                new int[] { 3, 9 }, 
+                new int[] { 8, 14 }, 
+                new int[] { 1, 1 });
+    }
+    
+    public void testRemoveSecondToken() throws Exception
+    {
+        Reader reader = new StringReader("termB AA termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "AA";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", "0");
+                put("isPrefixMatch", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termB", "termC" }, 
+                new int[] { 0, 9 }, 
+                new int[] { 5, 14 }, 
+                new int[] { 1, 1 });
+    }
+    
+    public void testModifyOnlyFirstToken() throws Exception
+    {
+        Reader reader = new StringReader("AAterm AAtermB termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "AA";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", "0");
+                put("isPrefixMatch", "true");
+                put("isFirstTokenOnly", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "term", "AAtermB", "termC" }, 
+                new int[] { 0, 7, 15 }, 
+                new int[] { 6, 14, 20 }, 
+                new int[] { 1, 1, 1 });
+    }
+    
+    public void testFirstToken() throws Exception
+    {
+        Reader reader = new StringReader("termAA termB termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "AA\taa\n";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("keepOriginalToken", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termAA", 
+                "termaa",
+                "termB", 
+                 "termC" }, 
+                new int[] { 0, 0, 7, 13 }, 
+                new int[] { 6, 6, 12, 18 }, 
+                new int[] { 1, 0, 1, 1 });
+    }
+    
+    public void testWithKeepOriginal() throws Exception
+    {
+        Reader reader = new StringReader("termA termB termC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "C\tc\n";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("keepOriginalToken", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termA", 
+                "termB", 
+                "termC", 
+                "termc", 
+                }, 
+                new int[] { 0, 6, 12, 12 }, 
+                new int[] { 5, 11, 17, 17 }, 
+                new int[] { 1, 1, 1, 0 });
+    }
+    
+    
+    public void testWithMatchFromEnd() throws Exception
+    {
+        Reader reader = new StringReader("termA termB CtermBtermC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "C\tc\nB\tb\n";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("matchFromEnd", "true");
+                put("keepOriginalToken", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termA", 
+                "termB", 
+                "termb", 
+                "CtermBtermC",  
+                "CtermBtermc"
+                }
+        , 
+                new int[] { 0, 6, 6, 12, 12 }, 
+                new int[] { 5, 11, 11, 23, 23 }, 
+                new int[] { 1, 1, 0, 1, 0 }
+                );
+    }
+    
+    
+    public void testMultiMatch() throws Exception
+    {
+        Reader reader = new StringReader("termA termB CtermBtermC");
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        mappings = "C\tc\nB\tb\n";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("matchFromEnd", "false");
+                put("keepOriginalToken", "true");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+        stream = factory.create(stream);
+
+        assertTokenStreamContents(stream, new String[] { 
+                "termA", 
+                "termB", 
+                "termb", 
+                "CtermBtermC", 
+                "Ctermbtermc",
+                }
+        , 
+                new int[] { 0, 6, 6, 12, 12 }, 
+                new int[] { 5, 11, 11, 23, 23 }, 
+                new int[] { 1, 1, 0, 1, 0 }
+                );
+    }
+    
+    
+    
+    public void testHappyPath() throws Exception
+    {
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        TokenStream stream = createStream(inputString, minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { "にせんじゅうにっバ       ".trim() }, new int[] { 0 }, new int[] { 10 }, new int[] { 1 });
+    }
+    
+    public void testMoreThanSingleToken() throws Exception
+    {
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        TokenStream stream = createStream("にせんじゅうにつヴァ"+" "+"にせんじゅうにつヴァ", minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { "にせんじゅうにっバ       ".trim(),"にせんじゅうにっバ       ".trim() }, new int[] { 0,11 }, new int[] { 10,21 }, new int[] { 1,1 });
+    }
+
+    public void testOriginalIsIntactWhenNoHit() throws Exception
+    {
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        inputString = "zzzzzzzzzz";
+        TokenStream stream = createStream(inputString, minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { inputString }, new int[] { 0 }, new int[] { 10 }, new int[] { 1 });
+    }
+
+    public void testLargePrefixReturnsLessValues() throws Exception
+    {
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        minPrefix = "8";
+        TokenStream stream = createStream(inputString, minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { "にせんじゅうにつバ      ".trim() }, new int[] { 0}, new int[] { 10 }, new int[] { 1});
+    }
+
+    public void testLargeMinPrefixReturnsNoValues() throws Exception
+    {
+        StringMockResourceLoader loader = new StringMockResourceLoader(mappings);
+        minPrefix = "10";
+        TokenStream stream = createStream(inputString, minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { inputString, }, new int[] { 0 }, new int[] { 10 }, new int[] { 1 });
+    }
+
+    public void testProtectedWord() throws Exception
+    {
+        mappings = "にせんじゅうにつヴァ";
+        ResourceLoader loader = new StringMockResourceByNameLoader("mapping.txt", mappings);
+        TokenStream stream = createStream(inputString, minPrefix, loader);
+        assertTokenStreamContents(stream, new String[] { inputString }, new int[] { 0 }, new int[] { 10 }, new int[] { 1 });
+    }
+
+    private TokenStream createStream(final String inputString, final String minPrefix, final ResourceLoader loader) throws IOException
+    {
+        Reader reader = new StringReader(inputString);
+        TokenStream stream = getInitialStreamUsingMockTokenizer(reader);
+        CharacterMappingFilterFactory factory = new CharacterMappingFilterFactory(new HashMap<String, String>() {
+            {
+                put("minPrefix", minPrefix);
+                put("keepOriginalToken", "false");
+                put("matchFromEnd", "false");
+                put("mappingFile", "mapping.txt");
+            }
+        });
+        factory.inform(loader);
+
+        stream = factory.create(stream);
+        return stream;
+    }
+    
+    private TokenStream getInitialStreamUsingMockTokenizer(Reader reader) {
+        TokenStream stream = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+        ((Tokenizer)stream).setReader(reader);
+        ((MockTokenizer) stream).setEnableChecks(false);
+        return stream;
+      }
+    
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingTrie.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingTrie.java
new file mode 100644
index 0000000..3c58791
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCharacterMappingTrie.java
@@ -0,0 +1,199 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+
+import java.util.LinkedHashSet;
+import java.util.Set;
+
+import org.junit.Before;
+import org.junit.Test;
+
+public class TestCharacterMappingTrie {
+
+    CharacterMappingTrie stEnglish = new CharacterMappingTrie();
+    CharacterMappingTrie stJapanese = new CharacterMappingTrie();
+    CharacterMappingTrie stLoadTestJapanese = new CharacterMappingTrie();
+
+    @Before
+    public void setup()
+    {
+        stEnglish.put("aaa", "fff");
+        stEnglish.put("ccc", "ggg");
+        stEnglish.put("bbb", "ii");
+        stEnglish.put("ddd", "jjjj");
+        stEnglish.put("eee", "k");
+        stEnglish.put("fff", "ccc");// no recursive matches
+        stEnglish.put("x", "y");//single char replacement
+
+        stEnglish.put("ll", "mm");//prefix of another key
+        stEnglish.put("llll", "o");
+        
+        stEnglish.put("z", "");
+        stEnglish.put("sz", "");
+
+        /**
+         * Long Vowel mapping https://en.wikibooks.org/wiki/Japanese/Pronunciation#Long_vowels
+         * **/
+        stJapanese.put("ぽう", "ポー");
+        /**
+         * Case folding, not handled by ASCII tools, 
+         * because it's really not case folding but rather a palatalization https://en.wikipedia.org/wiki/Palatalization_(phonetics)
+         * https://en.wikipedia.org/wiki/Y%C5%8Don https://en.wikipedia.org/wiki/Sokuon
+         * **/
+        stJapanese.put("ゆ", "ゅ");
+        
+        stLoadTestJapanese.put("ァ", "ア");
+        stLoadTestJapanese.put("ィ", "イ");
+        stLoadTestJapanese.put("ゥ", "ウ");
+        stLoadTestJapanese.put("ェ", "エ");
+        stLoadTestJapanese.put("ォ", "オ");
+        stLoadTestJapanese.put("ャ", "ヤ");
+        stLoadTestJapanese.put("ュ", "ユ");
+        stLoadTestJapanese.put("ョ", "ヨ");
+        stLoadTestJapanese.put("ッ", "ツ");
+    }
+
+    
+    @Test
+    public void testEnglishMiddle()
+    {
+        assertEquals("prefffpost", stEnglish.getSubstituted("preaaapost", 0, false, false));
+    }
+
+    @Test
+    public void testEnglishMiddleMoreThanOneMatch()
+    {
+        assertEquals("prefffgggpost", stEnglish.getSubstituted("preaaacccpost", 0, false, false));
+    }
+
+    @Test
+    public void testEnglishMiddleMoreThanOneMatchOfDiffLength()
+    {
+        assertEquals("preiijjjjkpost", stEnglish.getSubstituted("prebbbdddeeepost", 0, false, false));
+    }
+    
+    @Test
+    public void testPrefixOfAnotherKeyWontBeUsed()
+    {
+        assertEquals("opost", stEnglish.getSubstituted("llllpost", 0, false, false));
+    }
+    
+    @Test
+    public void testPrefixOfAnotherKeyIsUsedFromTheEnd()
+    {
+        assertEquals("preo", stEnglish.getSubstituted("prellll", 0, true, false));
+    }
+
+    @Test
+    public void testPrefixMatch()
+    {
+        assertEquals("opost", stEnglish.getSubstituted("llllpost", 0, false, true));
+        assertEquals("prex", stEnglish.getSubstituted("prex", 0, false, true));
+        assertEquals("cccpost", stEnglish.getSubstituted("fffpost", 0, false, true));
+        assertEquals(null, stEnglish.getSubstituted("fffpost", 3, false, true));
+    }
+
+    @Test
+    public void testNull()
+    {
+        assertNull(stEnglish.getSubstituted(null, 0, false, false));
+    }
+
+    
+    @Test
+    public void testEnglishMiddleWithMinPrefix()
+    {
+        assertEquals("prefffpost", stEnglish.getSubstituted("preaaapost", 3, false, false));
+    }
+
+    @Test
+    public void testEnglishMiddleWithMinPrefixNoResult()
+    {
+        assertNull(stEnglish.getSubstituted("preaaapost", 4, false, false));
+    }
+
+    @Test
+    public void testEnglishPrefix()
+    {
+        assertEquals("fffpost", stEnglish.getSubstituted("aaapost", 0, false, false));
+    }
+
+    @Test
+    public void testEnglishPrefixWithMatchFromEndReturnsSameString()
+    {
+        assertEquals("fffpost", stEnglish.getSubstituted("fffpost", 0, true, false));
+    }
+    
+    @Test
+    public void testTheLongestMatch()
+    {
+        assertEquals("AAA", stEnglish.getSubstituted("AAAsz", 0, true, false));
+    }
+    
+    @Test
+    public void testSingleCharWithMatchFromEnd()
+    {
+        assertEquals("prey", stEnglish.getSubstituted("prex", 3, true, false));
+        assertEquals(null, stEnglish.getSubstituted("prex", 4, true, false));
+    }
+    
+    @Test
+    public void testSingleCharWithMatchFromEnd2()
+    {
+        assertEquals("prexe", stEnglish.getSubstituted("prexe", 3, true, false));
+    }
+    
+    @Test
+    public void testEnglishSuffix()
+    {
+        assertEquals("prefff", stEnglish.getSubstituted("preaaa", 0, false, false));
+    }
+    
+    
+    @Test
+    public void testEnglishSuffixMoreThanSingleMatch()
+    {
+        assertEquals("prefffggg", stEnglish.getSubstituted("preaaaccc", 0, false, false));
+    }
+
+    @Test
+    public void testEnglishValueItself()
+    {
+        assertEquals("fff", stEnglish.getSubstituted("aaa", 0, false, false));
+    }
+
+    @Test
+    public void testEnglishNoMatchReturnsNull()
+    {
+        assertEquals(null, stEnglish.getSubstituted("prewwwpost", 0, false, false));
+    }
+
+    @Test
+    public void testJapaneseLongVowel()
+    {
+        assertEquals("らんポー",stJapanese.getSubstituted("らんぽう", 0, false, false));
+    }
+    
+    @Test
+    public void testJapaneseCase()
+    {
+        assertEquals("加賀伝統工芸村ゅ",stJapanese.getSubstituted("加賀伝統工芸村ゆ", 0, false, false));
+    }
+    
+    
+    @Test
+    public void testJapaneseLoad(){
+        Set<String> queries = new LinkedHashSet<String>();
+        queries.add("マトリックス+リローデッド");
+        queries.add("ターミネーター3");
+        queries.add("X-MEN：ファイナル ディシジョン");
+        for(String q: queries) {
+            String substituted = stLoadTestJapanese.getSubstituted(q, 0, false, false);
+            String isSubstituted = substituted==null?"false":String.valueOf(!substituted.equals(q));
+            System.out.println(isSubstituted + "\t"+ q + "\t" + substituted);
+        }
+
+    }
+
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/StringMockResourceByNameLoader.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/StringMockResourceByNameLoader.java
new file mode 100644
index 0000000..feaffef
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/StringMockResourceByNameLoader.java
@@ -0,0 +1,47 @@
+package org.apache.lucene.analysis.util;
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.util.ResourceLoader;
+
+public class StringMockResourceByNameLoader implements ResourceLoader {
+    Map<String, String> fileNameToStringsMap = new HashMap<String, String>();
+
+    public StringMockResourceByNameLoader(String fileName, String text) {
+        this.fileNameToStringsMap.put(fileName, text);
+    }
+
+    @Override
+    public <T> Class<? extends T> findClass(String cname, Class<T> expectedType)
+    {
+        try {
+            return Class.forName(cname).asSubclass(expectedType);
+        } catch (Exception e) {
+            throw new RuntimeException("Cannot load class: " + cname, e);
+        }
+    }
+
+    @Override
+    public <T> T newInstance(String cname, Class<T> expectedType)
+    {
+        Class<? extends T> clazz = findClass(cname, expectedType);
+        try {
+            return clazz.newInstance();
+        } catch (Exception e) {
+            throw new RuntimeException("Cannot create instance: " + cname, e);
+        }
+    }
+
+	@Override
+	public InputStream openResource(String resource) throws IOException {
+		String valuesForThisResource = this.fileNameToStringsMap.get(resource);
+		if (valuesForThisResource != null)
+			return new ByteArrayInputStream(valuesForThisResource.getBytes("UTF-8"));
+		else
+			return new ByteArrayInputStream(new byte[]{});
+	}
+}
