diff --git a/lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java b/lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java
index 1b1c41449c..2d709d8b1e 100644
--- a/lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java
+++ b/lucene/core/src/java/org/apache/lucene/util/QueryBuilder.java
@@ -385,25 +385,26 @@ public class QueryBuilder {
    * Creates simple boolean query from the cached tokenstream contents 
    */
   protected Query analyzeBoolean(String field, TokenStream stream) throws IOException {
-    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);
-    
     stream.reset();
-    List<Term> terms = new ArrayList<>();
+    List<AttributeSource> terms = new ArrayList<>();
     while (stream.incrementToken()) {
-      terms.add(new Term(field, termAtt.getBytesRef()));
+      terms.add(stream.cloneAttributes());
     }
-    
-    return newSynonymQuery(terms.toArray(new Term[terms.size()]));
+    return newSynonymQuery(field, terms);
+  }
+
+  protected Term buildTerm(String field, AttributeSource source) {
+    return new Term(field, source.addAttribute(TermToBytesRefAttribute.class).getBytesRef());
   }
 
-  protected void add(BooleanQuery.Builder q, List<Term> current, BooleanClause.Occur operator) {
+  protected void add(BooleanQuery.Builder q, String field, List<AttributeSource> current, BooleanClause.Occur operator) {
     if (current.isEmpty()) {
       return;
     }
     if (current.size() == 1) {
-      q.add(newTermQuery(current.get(0)), operator);
+      q.add(newTermQuery(buildTerm(field, current.get(0))), operator);
     } else {
-      q.add(newSynonymQuery(current.toArray(new Term[current.size()])), operator);
+      q.add(newSynonymQuery(field, current), operator);
     }
   }
 
@@ -412,20 +413,19 @@ public class QueryBuilder {
    */
   protected Query analyzeMultiBoolean(String field, TokenStream stream, BooleanClause.Occur operator) throws IOException {
     BooleanQuery.Builder q = newBooleanQuery();
-    List<Term> currentQuery = new ArrayList<>();
-    
-    TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);
+    List<AttributeSource> currentQuery = new ArrayList<>();
+
     PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);
     
     stream.reset();
     while (stream.incrementToken()) {
       if (posIncrAtt.getPositionIncrement() != 0) {
-        add(q, currentQuery, operator);
+        add(q, field, currentQuery, operator);
         currentQuery.clear();
       }
-      currentQuery.add(new Term(field, termAtt.getBytesRef()));
+      currentQuery.add(stream.cloneAttributes());
     }
-    add(q, currentQuery, operator);
+    add(q, field, currentQuery, operator);
     
     return q.build();
   }
@@ -525,12 +525,12 @@ public class QueryBuilder {
         };
         queryPos = newGraphSynonymQuery(queries);
       } else {
-        Term[] terms = graph.getTerms(field, start);
-        assert terms.length > 0;
-        if (terms.length == 1) {
-          queryPos = newTermQuery(terms[0]);
+        List<AttributeSource> terms = graph.getTokens(start);
+        assert terms.size() > 0;
+        if (terms.size() == 1) {
+          queryPos = newTermQuery(buildTerm(field, terms.get(0)));
         } else {
-          queryPos = newSynonymQuery(terms);
+          queryPos = newSynonymQuery(field, terms);
         }
       }
       if (queryPos != null) {
@@ -599,19 +599,17 @@ public class QueryBuilder {
           queryPos = null;
         }
       } else {
-        Term[] terms = graph.getTerms(field, start);
-        assert terms.length > 0;
-        if (terms.length == 1) {
-          queryPos = new SpanTermQuery(terms[0]);
+        List<AttributeSource> terms = graph.getTokens(start);
+        assert terms.size() > 0;
+        if (terms.size() == 1) {
+          queryPos = new SpanTermQuery(buildTerm(field, terms.get(0)));
         } else {
-          if (terms.length >= maxClauseCount) {
+          if (terms.size() >= maxClauseCount) {
             throw new BooleanQuery.TooManyClauses();
           }
-          SpanTermQuery[] orClauses = new SpanTermQuery[terms.length];
-          for (int idx = 0; idx < terms.length; idx++) {
-            orClauses[idx] = new SpanTermQuery(terms[idx]);
-          }
-
+          SpanTermQuery[] orClauses = terms.stream()
+              .map(a -> new SpanTermQuery(buildTerm(field, a)))
+              .toArray(SpanTermQuery[]::new);
           queryPos = new SpanOrQuery(orClauses);
         }
       }
@@ -649,8 +647,9 @@ public class QueryBuilder {
    * This is intended for subclasses that wish to customize the generated queries.
    * @return new Query instance
    */
-  protected Query newSynonymQuery(Term terms[]) {
-    return new SynonymQuery(terms);
+  protected Query newSynonymQuery(String field, List<AttributeSource> terms) {
+    return new SynonymQuery(terms.stream()
+        .map(a -> buildTerm(field, a)).toArray(Term[]::new));
   }
 
   /**
diff --git a/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java b/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
index a7005012b7..6d8f8c8268 100644
--- a/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
+++ b/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
@@ -22,18 +22,15 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.BytesTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.FiniteStringsIterator;
@@ -48,19 +45,18 @@ import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZ
  * This class also provides helpers to explore the different paths of the {@link Automaton}.
  */
 public final class GraphTokenStreamFiniteStrings {
-  private final Map<Integer, BytesRef> idToTerm = new HashMap<>();
-  private final Map<Integer, Integer> idToInc = new HashMap<>();
+
+  private AttributeSource[] tokens = new AttributeSource[4];
   private final Automaton det;
   private final Transition transition = new Transition();
 
   private class FiniteStringsTokenStream extends TokenStream {
-    private final BytesTermAttribute termAtt = addAttribute(BytesTermAttribute.class);
-    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
     private final IntsRef ids;
     private final int end;
     private int offset;
 
     FiniteStringsTokenStream(final IntsRef ids) {
+      super(tokens[0].cloneAttributes());
       assert ids != null;
       this.ids = ids;
       this.offset = ids.offset;
@@ -72,13 +68,7 @@ public final class GraphTokenStreamFiniteStrings {
       if (offset < end) {
         clearAttributes();
         int id = ids.ints[offset];
-        termAtt.setBytesRef(idToTerm.get(id));
-
-        int incr = 1;
-        if (idToInc.containsKey(id)) {
-          incr = idToInc.get(id);
-        }
-        posIncAtt.setPositionIncrement(incr);
+        tokens[id].copyTo(this);
         offset++;
         return true;
       }
@@ -112,19 +102,16 @@ public final class GraphTokenStreamFiniteStrings {
   }
 
   /**
-   * Returns the list of terms that start at the provided state
+   * Returns the set of tokens starting at the current state
    */
-  public Term[] getTerms(String field, int state) {
+  public List<AttributeSource> getTokens(int state) {
     int numT = det.initTransition(state, transition);
-    List<Term> terms = new ArrayList<> ();
+    List<AttributeSource> tokens = new ArrayList<>();
     for (int i = 0; i < numT; i++) {
       det.getNextTransition(transition);
-      for (int id = transition.min; id <= transition.max; id++) {
-        Term term = new Term(field, idToTerm.get(id));
-        terms.add(term);
-      }
+      tokens.addAll(Arrays.asList(this.tokens).subList(transition.min, transition.max + 1));
     }
-    return terms.toArray(new Term[terms.size()]);
+    return tokens;
   }
 
   /**
@@ -138,7 +125,7 @@ public final class GraphTokenStreamFiniteStrings {
   /**
    * Get all finite strings that start at {@code startState} and end at {@code endState}.
    */
-  public Iterator<TokenStream> getFiniteStrings(int startState, int endState) throws IOException {
+  public Iterator<TokenStream> getFiniteStrings(int startState, int endState) {
     final FiniteStringsIterator it = new FiniteStringsIterator(det, startState, endState);
     return new Iterator<TokenStream> () {
       IntsRef current;
@@ -202,7 +189,6 @@ public final class GraphTokenStreamFiniteStrings {
    */
   private Automaton build(final TokenStream in) throws IOException {
     Automaton.Builder builder = new Automaton.Builder();
-    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);
     final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);
     final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);
 
@@ -211,6 +197,7 @@ public final class GraphTokenStreamFiniteStrings {
     int pos = -1;
     int prevIncr = 1;
     int state = -1;
+    int id = -1;
     while (in.incrementToken()) {
       int currentIncr = posIncAtt.getPositionIncrement();
       if (pos == -1 && currentIncr < 1) {
@@ -228,10 +215,18 @@ public final class GraphTokenStreamFiniteStrings {
         state = builder.createState();
       }
 
-      BytesRef term = termBytesAtt.getBytesRef();
-      int id = getTermID(currentIncr, prevIncr, term);
+      id++;
+      if (tokens.length < id + 1) {
+        tokens = ArrayUtil.grow(tokens, id + 1);
+      }
+      tokens[id] = in.cloneAttributes();
       builder.addTransition(pos, endPos, id);
 
+      if (incr == 0) {
+        // stacked token should have the same increment as original token at this position
+        tokens[id].addAttribute(PositionIncrementAttribute.class).setPositionIncrement(prevIncr);
+      }
+
       // only save last increment on non-zero increment in case we have multiple stacked tokens
       if (currentIncr > 0) {
         prevIncr = currentIncr;
@@ -245,23 +240,6 @@ public final class GraphTokenStreamFiniteStrings {
     return builder.finish();
   }
 
-  /**
-   * Gets an integer id for a given term and saves the position increment if needed.
-   */
-  private int getTermID(int incr, int prevIncr, BytesRef term) {
-    assert term != null;
-    boolean isStackedGap = incr == 0 && prevIncr > 1;
-    int id = idToTerm.size();
-    idToTerm.put(id, BytesRef.deepCopyOf(term));
-    // stacked token should have the same increment as original token at this position
-    if (isStackedGap) {
-      idToInc.put(id, prevIncr);
-    } else if (incr > 1) {
-      idToInc.put(id, incr);
-    }
-    return id;
-  }
-
   private static void articulationPointsRecurse(Automaton a, int state, int d, int[] depth, int[] low, int[] parent,
                                                 BitSet visited, List<Integer> points) {
     visited.set(state);
diff --git a/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java b/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
index 44b7b7c4de..fe121dc599 100644
--- a/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
+++ b/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
@@ -16,14 +16,20 @@
  */
 package org.apache.lucene.util.graph;
 
+import java.util.HashSet;
 import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+import java.util.stream.Collectors;
 
 import org.apache.lucene.analysis.CannedTokenStream;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.BytesTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -38,13 +44,21 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     return t;
   }
 
+  private static Token token(String term, int posInc, int posLength, String type) {
+    final Token t = new Token(term, 0, term.length());
+    t.setPositionLength(posLength);
+    t.setPositionIncrement(posInc);
+    t.setType(type);
+    return t;
+  }
+
   private void assertTokenStream(TokenStream ts, String[] terms, int[] increments) throws Exception {
     // verify no nulls and arrays same length
     assertNotNull(ts);
     assertNotNull(terms);
     assertNotNull(increments);
     assertEquals(terms.length, increments.length);
-    BytesTermAttribute termAtt = ts.getAttribute(BytesTermAttribute.class);
+    TermToBytesRefAttribute termAtt = ts.getAttribute(TermToBytesRefAttribute.class);
     PositionIncrementAttribute incrAtt = ts.getAttribute(PositionIncrementAttribute.class);
     int offset = 0;
     while (ts.incrementToken()) {
@@ -59,6 +73,16 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertEquals(offset, terms.length);
   }
 
+  private static void assertTerms(List<AttributeSource> actual, String... expected) {
+    Set<BytesRef> actualTerms = actual.stream()
+        .map(a -> a.addAttribute(TermToBytesRefAttribute.class).getBytesRef()).collect(Collectors.toSet());
+    Set<BytesRef> expectedTerms = new HashSet<>();
+    for (String s : expected) {
+      expectedTerms.add(new BytesRef(s));
+    }
+    assertEquals(expectedTerms, actualTerms);
+  }
+
   public void testIllegalState() throws Exception {
     expectThrows(IllegalStateException.class, () -> {
       TokenStream ts = new CannedTokenStream(
@@ -105,8 +129,8 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"fast"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast")});
+    List<AttributeSource> terms = graph.getTokens(0);
+    assertTerms(graph.getTokens(0), "fast");
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 3);
@@ -121,8 +145,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 3);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(3), "network");
   }
 
   public void testSingleGraphWithGap() throws Exception {
@@ -155,16 +178,14 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"hey"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "hey")});
+    assertTerms(graph.getTokens(0), "hey");
 
     assertFalse(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 2);
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"fast"}, new int[] {2});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 1);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast")});
+    assertTerms(graph.getTokens(1), "fast");
 
     assertTrue(graph.hasSidePath(2));
     it = graph.getFiniteStrings(2, 4);
@@ -179,8 +200,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 4);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(4), "network");
   }
 
 
@@ -210,8 +230,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"fast"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast")});
+    assertTerms(graph.getTokens(0), "fast");
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 3);
@@ -226,8 +245,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 3);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(3), "network");
   }
 
   public void testGraphAndGapSameTokenTerm() throws Exception {
@@ -256,16 +274,14 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"a"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "a")});
+    assertTerms(graph.getTokens(0), "a");
 
     assertFalse(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 2);
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"b"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 1);
-    assertArrayEquals(terms, new Term[] {new Term("field", "b")});
+    assertTerms(graph.getTokens(1), "b");
 
     assertTrue(graph.hasSidePath(2));
     it = graph.getFiniteStrings(2, -1);
@@ -305,8 +321,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"fast"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast")});
+    assertTerms(graph.getTokens(0), "fast");
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 3);
@@ -323,8 +338,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 3);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(3), "network");
   }
 
   public void testStackedGraphWithGap() throws Exception {
@@ -356,8 +370,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"fast"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast")});
+    assertTerms(graph.getTokens(0), "fast");
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 3);
@@ -374,8 +387,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 3);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(3), "network");
   }
 
   public void testStackedGraphWithRepeat() throws Exception {
@@ -419,22 +431,20 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"is"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 4);
-    assertArrayEquals(terms, new Term[] {new Term("field", "is")});
+    assertTerms(graph.getTokens(4), "is");
 
     assertFalse(graph.hasSidePath(5));
     it = graph.getFiniteStrings(5, -1);
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"great"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 5);
-    assertArrayEquals(terms, new Term[] {new Term("field", "great")});
+    assertTerms(graph.getTokens(5), "great");
   }
 
   public void testGraphWithRegularSynonym() throws Exception {
     TokenStream ts = new CannedTokenStream(
         token("fast", 1, 1),
-        token("speedy", 0, 1),
+        token("speedy", 0, 1, "SYNONYM"),
         token("wi", 1, 1),
         token("wifi", 0, 2),
         token("fi", 1, 1),
@@ -464,8 +474,9 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"speedy"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "fast"), new Term("field", "speedy")});
+    assertTerms(graph.getTokens(0), "fast", "speedy");
+    List<AttributeSource> sources = graph.getTokens(0);
+    assertEquals("SYNONYM", sources.get(1).addAttribute(TypeAttribute.class).type());
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 3);
@@ -480,8 +491,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 3);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(3), "network");
   }
 
   public void testMultiGraph() throws Exception {
@@ -534,8 +544,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[] {1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 4);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(4), "network");
   }
 
   public void testMultipleSidePaths() throws Exception {
@@ -573,8 +582,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"the"}, new int[]{1});
     assertFalse(it.hasNext());
-    Term[] terms = graph.getTerms("field", 0);
-    assertArrayEquals(terms, new Term[] {new Term("field", "the")});
+    assertTerms(graph.getTokens(0), "the");
 
     assertTrue(graph.hasSidePath(1));
     it = graph.getFiniteStrings(1, 7);
@@ -593,7 +601,6 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertTrue(it.hasNext());
     assertTokenStream(it.next(), new String[]{"network"}, new int[]{1});
     assertFalse(it.hasNext());
-    terms = graph.getTerms("field", 7);
-    assertArrayEquals(terms, new Term[] {new Term("field", "network")});
+    assertTerms(graph.getTokens(7), "network");
   }
 }
diff --git a/solr/core/src/java/org/apache/solr/parser/SolrQueryParserBase.java b/solr/core/src/java/org/apache/solr/parser/SolrQueryParserBase.java
index a97bae590c..f57d60e0f9 100644
--- a/solr/core/src/java/org/apache/solr/parser/SolrQueryParserBase.java
+++ b/solr/core/src/java/org/apache/solr/parser/SolrQueryParserBase.java
@@ -43,6 +43,7 @@ import org.apache.lucene.search.PhraseQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.QueryBuilder;
 import org.apache.lucene.util.automaton.Automata;
 import org.apache.lucene.util.automaton.Automaton;
@@ -61,7 +62,7 @@ import org.apache.solr.search.QueryUtils;
 import org.apache.solr.search.SolrConstantScoreQuery;
 import org.apache.solr.search.SyntaxError;
 
-import static org.apache.solr.parser.SolrQueryParserBase.SynonymQueryStyle.*;
+import static org.apache.solr.parser.SolrQueryParserBase.SynonymQueryStyle.AS_SAME_TERM;
 
 /** This class is overridden by QueryParser in QueryParser.jj
  * and acts to separate the majority of the Java code from the .jj grammar file.
@@ -593,23 +594,23 @@ public abstract class SolrQueryParserBase extends QueryBuilder {
   }
 
   @Override
-  protected Query newSynonymQuery(Term terms[]) {
+  protected Query newSynonymQuery(String field, List<AttributeSource> terms) {
     switch (synonymQueryStyle) {
       case PICK_BEST:
-        List<Query> currPosnClauses = new ArrayList<Query>(terms.length);
-        for (Term term : terms) {
-          currPosnClauses.add(newTermQuery(term));
+        List<Query> currPosnClauses = new ArrayList<Query>(terms.size());
+        for (AttributeSource a : terms) {
+          currPosnClauses.add(newTermQuery(buildTerm(field, a)));
         }
         DisjunctionMaxQuery dm = new DisjunctionMaxQuery(currPosnClauses, 0.0f);
         return dm;
       case AS_DISTINCT_TERMS:
         BooleanQuery.Builder builder = new BooleanQuery.Builder();
-        for (Term term : terms) {
-          builder.add(newTermQuery(term), BooleanClause.Occur.SHOULD);
+        for (AttributeSource a : terms) {
+          builder.add(newTermQuery(buildTerm(field, a)), BooleanClause.Occur.SHOULD);
         }
         return builder.build();
       case AS_SAME_TERM:
-        return super.newSynonymQuery(terms);
+        return super.newSynonymQuery(field, terms);
       default:
         throw new AssertionError("unrecognized synonymQueryStyle passed when creating newSynonymQuery");
     }
