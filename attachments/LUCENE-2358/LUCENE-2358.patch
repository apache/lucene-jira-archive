Index: lucene/src/test/org/apache/lucene/analysis/TestPorterStemFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestPorterStemFilter.java	(revision 929156)
+++ lucene/src/test/org/apache/lucene/analysis/TestPorterStemFilter.java	(working copy)
@@ -60,7 +60,7 @@
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("yourselves");
     Tokenizer tokenizer = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader("yourselves yours"));
-    TokenStream filter = new PorterStemFilter(new KeywordMarkerTokenFilter(tokenizer, set));   
+    TokenStream filter = new PorterStemFilter(new KeywordMarkerFilter(tokenizer, set));   
     assertTokenStreamContents(filter, new String[] {"yourselves", "your"});
   }
 }
Index: lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerFilter.java	(revision 929156)
+++ lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerFilter.java	(working copy)
@@ -27,9 +27,9 @@
  */
 
 /**
- * Testcase for {@link KeywordMarkerTokenFilter}
+ * Testcase for {@link KeywordMarkerFilter}
  */
-public class TestKeywordMarkerTokenFilter extends BaseTokenStreamTestCase {
+public class TestKeywordMarkerFilter extends BaseTokenStreamTestCase {
 
   @Test
   public void testIncrementToken() throws IOException {
@@ -38,16 +38,16 @@
     String[] output = new String[] { "the", "quick", "brown", "LuceneFox",
         "jumps" };
     assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "The quIck browN LuceneFox Jumps")), set)), output);
     Set<String> jdkSet = new HashSet<String>();
     jdkSet.add("LuceneFox");
     assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "The quIck browN LuceneFox Jumps")), jdkSet)), output);
     Set<?> set2 = set;
     assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "The quIck browN LuceneFox Jumps")), set2)), output);
   }
 
Index: lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerTokenFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerTokenFilter.java	(revision 929156)
+++ lucene/src/test/org/apache/lucene/analysis/TestKeywordMarkerTokenFilter.java	(working copy)
@@ -1,76 +0,0 @@
-package org.apache.lucene.analysis;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
-import org.apache.lucene.analysis.tokenattributes.TermAttribute;
-import org.junit.Test;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Testcase for {@link KeywordMarkerTokenFilter}
- */
-public class TestKeywordMarkerTokenFilter extends BaseTokenStreamTestCase {
-
-  @Test
-  public void testIncrementToken() throws IOException {
-    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 5, true);
-    set.add("lucenefox");
-    String[] output = new String[] { "the", "quick", "brown", "LuceneFox",
-        "jumps" };
-    assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
-            "The quIck browN LuceneFox Jumps")), set)), output);
-    Set<String> jdkSet = new HashSet<String>();
-    jdkSet.add("LuceneFox");
-    assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
-            "The quIck browN LuceneFox Jumps")), jdkSet)), output);
-    Set<?> set2 = set;
-    assertTokenStreamContents(new LowerCaseFilterMock(
-        new KeywordMarkerTokenFilter(new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(
-            "The quIck browN LuceneFox Jumps")), set2)), output);
-  }
-
-  public static class LowerCaseFilterMock extends TokenFilter {
-
-    private TermAttribute termAtt;
-    private KeywordAttribute keywordAttr;
-
-    public LowerCaseFilterMock(TokenStream in) {
-      super(in);
-      termAtt = addAttribute(TermAttribute.class);
-      keywordAttr = addAttribute(KeywordAttribute.class);
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (input.incrementToken()) {
-        if (!keywordAttr.isKeyword())
-          termAtt.setTermBuffer(termAtt.term().toLowerCase());
-        return true;
-      }
-      return false;
-    }
-
-  }
-}
Index: lucene/src/java/org/apache/lucene/analysis/KeywordMarkerFilter.java
===================================================================
--- lucene/src/java/org/apache/lucene/analysis/KeywordMarkerFilter.java	(revision 929156)
+++ lucene/src/java/org/apache/lucene/analysis/KeywordMarkerFilter.java	(working copy)
@@ -31,14 +31,14 @@
  * 
  * @see KeywordAttribute
  */
-public final class KeywordMarkerTokenFilter extends TokenFilter {
+public final class KeywordMarkerFilter extends TokenFilter {
 
   private final KeywordAttribute keywordAttr;
   private final TermAttribute termAtt;
   private final CharArraySet keywordSet;
 
   /**
-   * Create a new KeywordMarkerTokenFilter, that marks the current token as a
+   * Create a new KeywordMarkerFilter, that marks the current token as a
    * keyword if the tokens term buffer is contained in the given set via the
    * {@link KeywordAttribute}.
    * 
@@ -47,7 +47,7 @@
    * @param keywordSet
    *          the keywords set to lookup the current termbuffer
    */
-  public KeywordMarkerTokenFilter(final TokenStream in,
+  public KeywordMarkerFilter(final TokenStream in,
       final CharArraySet keywordSet) {
     super(in);
     termAtt = addAttribute(TermAttribute.class);
@@ -56,7 +56,7 @@
   }
 
   /**
-   * Create a new KeywordMarkerTokenFilter, that marks the current token as a
+   * Create a new KeywordMarkerFilter, that marks the current token as a
    * keyword if the tokens term buffer is contained in the given set via the
    * {@link KeywordAttribute}.
    * 
@@ -65,7 +65,7 @@
    * @param keywordSet
    *          the keywords set to lookup the current termbuffer
    */
-  public KeywordMarkerTokenFilter(final TokenStream in, final Set<?> keywordSet) {
+  public KeywordMarkerFilter(final TokenStream in, final Set<?> keywordSet) {
     this(in, keywordSet instanceof CharArraySet ? (CharArraySet) keywordSet
         : CharArraySet.copy(Version.LUCENE_31, keywordSet));
   }
Index: lucene/src/java/org/apache/lucene/analysis/KeywordMarkerTokenFilter.java
===================================================================
--- lucene/src/java/org/apache/lucene/analysis/KeywordMarkerTokenFilter.java	(revision 929156)
+++ lucene/src/java/org/apache/lucene/analysis/KeywordMarkerTokenFilter.java	(working copy)
@@ -1,82 +0,0 @@
-package org.apache.lucene.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
-import org.apache.lucene.analysis.tokenattributes.TermAttribute;
-import org.apache.lucene.util.Version;
-
-/**
- * Marks terms as keywords via the {@link KeywordAttribute}. Each token
- * contained in the provided is marked as a keyword by setting
- * {@link KeywordAttribute#setKeyword(boolean)} to <code>true</code>.
- * 
- * @see KeywordAttribute
- */
-public final class KeywordMarkerTokenFilter extends TokenFilter {
-
-  private final KeywordAttribute keywordAttr;
-  private final TermAttribute termAtt;
-  private final CharArraySet keywordSet;
-
-  /**
-   * Create a new KeywordMarkerTokenFilter, that marks the current token as a
-   * keyword if the tokens term buffer is contained in the given set via the
-   * {@link KeywordAttribute}.
-   * 
-   * @param in
-   *          TokenStream to filter
-   * @param keywordSet
-   *          the keywords set to lookup the current termbuffer
-   */
-  public KeywordMarkerTokenFilter(final TokenStream in,
-      final CharArraySet keywordSet) {
-    super(in);
-    termAtt = addAttribute(TermAttribute.class);
-    keywordAttr = addAttribute(KeywordAttribute.class);
-    this.keywordSet = keywordSet;
-  }
-
-  /**
-   * Create a new KeywordMarkerTokenFilter, that marks the current token as a
-   * keyword if the tokens term buffer is contained in the given set via the
-   * {@link KeywordAttribute}.
-   * 
-   * @param in
-   *          TokenStream to filter
-   * @param keywordSet
-   *          the keywords set to lookup the current termbuffer
-   */
-  public KeywordMarkerTokenFilter(final TokenStream in, final Set<?> keywordSet) {
-    this(in, keywordSet instanceof CharArraySet ? (CharArraySet) keywordSet
-        : CharArraySet.copy(Version.LUCENE_31, keywordSet));
-  }
-
-  @Override
-  public final boolean incrementToken() throws IOException {
-    if (input.incrementToken()) {
-      keywordAttr.setKeyword(keywordSet.contains(termAtt.termBuffer(), 0,
-          termAtt.termLength()));
-      return true;
-    } else
-      return false;
-  }
-}
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemmer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemmer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemmer.java	(working copy)
@@ -22,7 +22,7 @@
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.WhitespaceTokenizer;
 import org.apache.lucene.util.Version;
 
@@ -219,7 +219,7 @@
         new StringReader("строевете строеве"));
 
     BulgarianStemFilter filter = new BulgarianStemFilter(
-        new KeywordMarkerTokenFilter(tokenStream, set));
+        new KeywordMarkerFilter(tokenStream, set));
     assertTokenStreamContents(filter, new String[] { "строй", "строеве" });
   }
 }
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseTokenizer;
 import org.apache.lucene.util.Version;
 
@@ -48,7 +48,7 @@
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("fischen");
     GermanStemFilter filter = new GermanStemFilter(
-        new KeywordMarkerTokenFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader( 
+        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader( 
             "Fischen Trinken")), set));
     assertTokenStreamContents(filter, new String[] { "fischen", "trink" });
   }
@@ -60,7 +60,7 @@
     set1.add("trinken");
     set1.add("fischen");
     GermanStemFilter filter = new GermanStemFilter(
-        new KeywordMarkerTokenFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "Fischen Trinken")), set));
     filter.setExclusionSet(set1);
     assertTokenStreamContents(filter, new String[] { "fischen", "trinken" });
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java	(working copy)
@@ -23,7 +23,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseTokenizer;
 
 /**
@@ -152,7 +152,7 @@
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("Brasília");
     BrazilianStemFilter filter = new BrazilianStemFilter(
-        new KeywordMarkerTokenFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "Brasília Brasilia")), set));
     assertTokenStreamContents(filter, new String[] { "brasília", "brasil" });
   }
@@ -163,7 +163,7 @@
     CharArraySet set1 = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set1.add("Brasilia");
     BrazilianStemFilter filter = new BrazilianStemFilter(
-        new KeywordMarkerTokenFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
+        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
             "Brasília Brasilia")), set), set1);
     assertTokenStreamContents(filter, new String[] { "brasília", "brasilia" });
   }
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ar/TestArabicStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ar/TestArabicStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ar/TestArabicStemFilter.java	(working copy)
@@ -22,7 +22,7 @@
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 
 /**
  * Test the Arabic Normalization Filter
@@ -119,7 +119,7 @@
     set.add("ساهدهات");
     ArabicLetterTokenizer tokenStream  = new ArabicLetterTokenizer(TEST_VERSION_CURRENT, new StringReader("ساهدهات"));
 
-    ArabicStemFilter filter = new ArabicStemFilter(new KeywordMarkerTokenFilter(tokenStream, set));
+    ArabicStemFilter filter = new ArabicStemFilter(new KeywordMarkerFilter(tokenStream, set));
     assertTokenStreamContents(filter, new String[]{"ساهدهات"});
   }
 
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemmer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemmer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemmer.java	(working copy)
@@ -22,7 +22,7 @@
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.WhitespaceTokenizer;
 
 /**
@@ -277,7 +277,7 @@
   public void testWithKeywordAttribute() throws IOException {
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("hole");
-    CzechStemFilter filter = new CzechStemFilter(new KeywordMarkerTokenFilter(
+    CzechStemFilter filter = new CzechStemFilter(new KeywordMarkerFilter(
         new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader("hole desek")), set));
     assertTokenStreamContents(filter, new String[] { "hole", "desk" });
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new DanishStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilter.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter; // for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -30,7 +30,7 @@
  * words.
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
  */
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java	(working copy)
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -109,7 +109,7 @@
   
   /**
    * Builds an analyzer with the given stop words and a stem exclusion set.
-   * If a stem exclusion set is provided this analyzer will add a {@link KeywordMarkerTokenFilter} 
+   * If a stem exclusion set is provided this analyzer will add a {@link KeywordMarkerFilter} 
    * before {@link BulgarianStemFilter}.
    */
   public BulgarianAnalyzer(Version matchVersion, Set<?> stopwords, Set<?> stemExclusionSet) {
@@ -126,7 +126,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link BulgarianStemFilter}.
    */
   @Override
@@ -136,7 +136,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new BulgarianStemFilter(result);
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java	(working copy)
@@ -29,7 +29,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.LowerCaseFilter;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -230,7 +230,7 @@
    * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided, and {@link SnowballFilter}
    */
   @Override
@@ -240,7 +240,7 @@
     TokenStream result = new StandardFilter(source);
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter( matchVersion, result, stopwords);
-    result = new KeywordMarkerTokenFilter(result, exclusionSet);
+    result = new KeywordMarkerFilter(result, exclusionSet);
     if (matchVersion.onOrAfter(Version.LUCENE_31))
       result = new SnowballFilter(result, new German2Stemmer());
     else
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.IOException;
 import java.util.Set;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;// for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter;// for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -35,10 +35,10 @@
  * </p>
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  */
 public final class GermanStemFilter extends TokenFilter
 {
@@ -65,7 +65,7 @@
 
     /**
      * Builds a GermanStemFilter that uses an exclusion table.
-     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
      */
     @Deprecated
     public GermanStemFilter( TokenStream in, Set<?> exclusionSet )
@@ -107,7 +107,7 @@
 
     /**
      * Set an alternative exclusion list for this filter.
-     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
      */
     @Deprecated
     public void setExclusionSet( Set<?> exclusionSet )
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new SwedishStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new FinnishStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -112,7 +112,7 @@
    * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link IndicTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link IndicNormalizationFilter},
-   *         {@link HindiNormalizationFilter}, {@link KeywordMarkerTokenFilter}
+   *         {@link HindiNormalizationFilter}, {@link KeywordMarkerFilter}
    *         if a stem exclusion set is provided, {@link HindiStemFilter}, and
    *         Hindi Stop words
    */
@@ -122,7 +122,7 @@
     final Tokenizer source = new IndicTokenizer(matchVersion, reader);
     TokenStream result = new LowerCaseFilter(matchVersion, source);
     if (!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new IndicNormalizationFilter(result);
     result = new HindiNormalizationFilter(result);
     result = new StopFilter(matchVersion, result, stopwords);
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilter.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -31,7 +31,7 @@
  * <p>
  * In some cases the normalization may cause unrelated terms to conflate, so
  * to prevent terms from being normalized use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
  * @see HindiNormalizer
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java	(working copy)
@@ -29,7 +29,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.LowerCaseFilter;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -209,7 +209,7 @@
     result = new StandardFilter(result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(excltable != null && !excltable.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, excltable);
+      result = new KeywordMarkerFilter(result, excltable);
     return new TokenStreamComponents(source, new BrazilianStemFilter(result));
   }
 }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java	(working copy)
@@ -20,7 +20,7 @@
 import java.io.IOException;
 import java.util.Set;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter; // for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -30,10 +30,10 @@
  * A {@link TokenFilter} that applies {@link BrazilianStemmer}.
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  * 
  */
 public final class BrazilianStemFilter extends TokenFilter {
@@ -63,7 +63,7 @@
    * 
    * @param in the source {@link TokenStream} 
    * @param exclusiontable a set of terms that should be prevented from being stemmed.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
    */
   @Deprecated
   public BrazilianStemFilter(TokenStream in, Set<?> exclusiontable) {
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java	(working copy)
@@ -17,7 +17,7 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;// for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter;// for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
@@ -37,10 +37,10 @@
  * </p>
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  * @deprecated Use {@link SnowballFilter} with 
  * {@link org.tartarus.snowball.ext.FrenchStemmer} instead, which has the
  * same functionality. This filter will be removed in Lucene 4.0
@@ -68,7 +68,7 @@
    * 
    * @param in the {@link TokenStream} to filter
    * @param exclusiontable a set of terms not to be stemmed
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
    */
 	@Deprecated // TODO remove in 3.2
 	public FrenchStemFilter( TokenStream in, Set<?> exclusiontable ) {
@@ -106,7 +106,7 @@
 	}
 	/**
 	 * Set an alternative exclusion list for this filter.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
 	 */
 	@Deprecated // TODO remove in 3.2
 	public void setExclusionTable( Map<?,?> exclusiontable ) {
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(working copy)
@@ -20,7 +20,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.LowerCaseFilter;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -232,7 +232,7 @@
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link ElisionFilter},
    *         {@link LowerCaseFilter}, {@link StopFilter},
-   *         {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided, and {@link SnowballFilter}
    */
   @Override
@@ -245,7 +245,7 @@
       result = new LowerCaseFilter(matchVersion, result);
       result = new StopFilter(matchVersion, result, stopwords);
       if(!excltable.isEmpty())
-        result = new KeywordMarkerTokenFilter(result, excltable);
+        result = new KeywordMarkerFilter(result, excltable);
       result = new SnowballFilter(result, new org.tartarus.snowball.ext.FrenchStemmer());
       return new TokenStreamComponents(source, result);
     } else {
@@ -253,7 +253,7 @@
       TokenStream result = new StandardFilter(source);
       result = new StopFilter(matchVersion, result, stopwords);
       if(!excltable.isEmpty())
-        result = new KeywordMarkerTokenFilter(result, excltable);
+        result = new KeywordMarkerFilter(result, excltable);
       result = new FrenchStemFilter(result);
       // Convert to lowercase after stemming!
       return new TokenStreamComponents(source, new LowerCaseFilter(matchVersion, result));
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java	(working copy)
@@ -23,7 +23,7 @@
 import java.util.Map;
 import java.util.Set;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;// for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter;// for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.snowball.SnowballFilter;
@@ -39,10 +39,10 @@
  * </p>
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  * @deprecated Use {@link SnowballFilter} with 
  * {@link org.tartarus.snowball.ext.DutchStemmer} instead, which has the
  * same functionality. This filter will be removed in Lucene 4.0
@@ -67,7 +67,7 @@
 
   /**
    * Builds a DutchStemFilter that uses an exclusion table.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
    */
   @Deprecated
   public DutchStemFilter(TokenStream _in, Set<?> exclusiontable) {
@@ -85,7 +85,7 @@
 
   /**
    * @param stemdictionary Dictionary of word stem pairs, that overrule the algorithm
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
    */
   @Deprecated
   public DutchStemFilter(TokenStream _in, Set<?> exclusiontable, Map<?,?> stemdictionary) {
@@ -125,7 +125,7 @@
 
   /**
    * Set an alternative exclusion list for this filter.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerTokenFilter} instead.
+   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
    */
   @Deprecated
   public void setExclusionTable(HashSet<?> exclusiontable) {
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(working copy)
@@ -19,7 +19,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.StopFilter;
@@ -238,7 +238,7 @@
    *
    * @return A {@link TokenStream} built from a {@link StandardTokenizer}
    *   filtered with {@link StandardFilter}, {@link LowerCaseFilter}, 
-   *   {@link StopFilter}, {@link KeywordMarkerTokenFilter} if a stem exclusion set is provided,
+   *   {@link StopFilter}, {@link KeywordMarkerFilter} if a stem exclusion set is provided,
    *   {@link StemmerOverrideFilter}, and {@link SnowballFilter}
    */
   @Override
@@ -250,7 +250,7 @@
       result = new LowerCaseFilter(matchVersion, result);
       result = new StopFilter(matchVersion, result, stoptable);
       if (!excltable.isEmpty())
-        result = new KeywordMarkerTokenFilter(result, excltable);
+        result = new KeywordMarkerFilter(result, excltable);
       if (!stemdict.isEmpty())
         result = new StemmerOverrideFilter(matchVersion, result, stemdict);
       result = new SnowballFilter(result, new org.tartarus.snowball.ext.DutchStemmer());
@@ -260,7 +260,7 @@
       TokenStream result = new StandardFilter(source);
       result = new StopFilter(matchVersion, result, stoptable);
       if (!excltable.isEmpty())
-        result = new KeywordMarkerTokenFilter(result, excltable);
+        result = new KeywordMarkerFilter(result, excltable);
       result = new DutchStemFilter(result, stemdict);
       return new TokenStreamComponents(source, result);
     }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new NorwegianStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new HungarianStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ro/RomanianAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -95,7 +95,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -117,7 +117,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -128,7 +128,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new RomanianStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new PortugueseStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/tr/TurkishAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -94,7 +94,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -116,7 +116,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link TurkishLowerCaseFilter},
-   *         {@link StopFilter}, {@link KeywordMarkerTokenFilter} if a stem
+   *         {@link StopFilter}, {@link KeywordMarkerFilter} if a stem
    *         exclusion set is provided and {@link SnowballFilter}.
    */
   @Override
@@ -127,7 +127,7 @@
     result = new TurkishLowerCaseFilter(result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new TurkishStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java	(working copy)
@@ -17,7 +17,7 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;// for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter;// for javadoc
 import org.apache.lucene.analysis.LowerCaseFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -37,10 +37,10 @@
  * </p>
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  * @deprecated Use {@link SnowballFilter} with 
  * {@link org.tartarus.snowball.ext.RussianStemmer} instead, which has the
  * same functionality. This filter will be removed in Lucene 4.0
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java	(working copy)
@@ -29,7 +29,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -167,7 +167,7 @@
    * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided, and {@link SnowballFilter}
    */
     @Override
@@ -178,7 +178,7 @@
         TokenStream result = new StandardFilter(source);
         result = new LowerCaseFilter(matchVersion, result);
         result = new StopFilter(matchVersion, result, stopwords);
-        if (!stemExclusionSet.isEmpty()) result = new KeywordMarkerTokenFilter(
+        if (!stemExclusionSet.isEmpty()) result = new KeywordMarkerFilter(
             result, stemExclusionSet);
         result = new SnowballFilter(result, new org.tartarus.snowball.ext.RussianStemmer());
         return new TokenStreamComponents(source, result);
@@ -186,7 +186,7 @@
         final Tokenizer source = new RussianLetterTokenizer(matchVersion, reader);
         TokenStream result = new LowerCaseFilter(matchVersion, source);
         result = new StopFilter(matchVersion, result, stopwords);
-        if (!stemExclusionSet.isEmpty()) result = new KeywordMarkerTokenFilter(
+        if (!stemExclusionSet.isEmpty()) result = new KeywordMarkerFilter(
           result, stemExclusionSet);
         return new TokenStreamComponents(source, new RussianStemFilter(result));
       }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java	(working copy)
@@ -19,7 +19,7 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -29,10 +29,10 @@
  * A {@link TokenFilter} that applies {@link ArabicStemmer} to stem Arabic words..
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
- * @see KeywordMarkerTokenFilter */
+ * @see KeywordMarkerFilter */
 
 public final class ArabicStemFilter extends TokenFilter {
 
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java	(working copy)
@@ -26,7 +26,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -118,7 +118,7 @@
 
   /**
    * Builds an analyzer with the given stop word. If a none-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * {@link ArabicStemFilter}.
    * 
    * @param matchVersion
@@ -169,7 +169,7 @@
    * @return {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link ArabicLetterTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link StopFilter},
-   *         {@link ArabicNormalizationFilter}, {@link KeywordMarkerTokenFilter}
+   *         {@link ArabicNormalizationFilter}, {@link KeywordMarkerFilter}
    *         if a stem exclusion set is provided and {@link ArabicStemFilter}.
    */
   @Override
@@ -182,7 +182,7 @@
     // TODO maybe we should make ArabicNormalization filter also KeywordAttribute aware?!
     result = new ArabicNormalizationFilter(result);
     if(!stemExclusionSet.isEmpty()) {
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     }
     return new TokenStreamComponents(source, new ArabicStemFilter(result));
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java	(working copy)
@@ -22,7 +22,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.PorterStemFilter;
 import org.apache.lucene.analysis.StopFilter;
@@ -75,7 +75,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -97,7 +97,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link PorterStemFilter}.
    */
   @Override
@@ -108,7 +108,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new PorterStemFilter(result);
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new SpanishStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(working copy)
@@ -23,7 +23,7 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
@@ -91,7 +91,7 @@
 
   /**
    * Builds an analyzer with the given stop words. If a non-empty stem exclusion set is
-   * provided this analyzer will add a {@link KeywordMarkerTokenFilter} before
+   * provided this analyzer will add a {@link KeywordMarkerFilter} before
    * stemming.
    * 
    * @param matchVersion lucene compatibility version
@@ -113,7 +113,7 @@
    *         {@link org.apache.lucene.analysis.ReusableAnalyzerBase.TokenStreamComponents}
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , {@link KeywordMarkerTokenFilter} if a stem exclusion set is
+   *         , {@link KeywordMarkerFilter} if a stem exclusion set is
    *         provided and {@link SnowballFilter}.
    */
   @Override
@@ -124,7 +124,7 @@
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
-      result = new KeywordMarkerTokenFilter(result, stemExclusionSet);
+      result = new KeywordMarkerFilter(result, stemExclusionSet);
     result = new SnowballFilter(result, new ItalianStemmer());
     return new TokenStreamComponents(source, result);
   }
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java	(working copy)
@@ -20,7 +20,7 @@
 import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;
+import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -227,7 +227,7 @@
    *         , and {@link CzechStemFilter} (only if version is >= LUCENE_31). If
    *         a version is >= LUCENE_31 and a stem exclusion set is provided via
    *         {@link #CzechAnalyzer(Version, Set, Set)} a
-   *         {@link KeywordMarkerTokenFilter} is added before
+   *         {@link KeywordMarkerFilter} is added before
    *         {@link CzechStemFilter}.
    */
   @Override
@@ -239,7 +239,7 @@
     result = new StopFilter( matchVersion, result, stoptable);
     if (matchVersion.onOrAfter(Version.LUCENE_31)) {
       if(!this.stemExclusionTable.isEmpty())
-        result = new KeywordMarkerTokenFilter(result, stemExclusionTable);
+        result = new KeywordMarkerFilter(result, stemExclusionTable);
       result = new CzechStemFilter(result);
     }
     return new TokenStreamComponents(source, result);
Index: lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilter.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilter.java	(revision 929156)
+++ lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilter.java	(working copy)
@@ -2,7 +2,7 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.analysis.KeywordMarkerTokenFilter;// for javadoc
+import org.apache.lucene.analysis.KeywordMarkerFilter;// for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
@@ -29,12 +29,12 @@
  * A {@link TokenFilter} that applies {@link CzechStemmer} to stem Czech words.
  * <p>
  * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerTokenFilter} or a custom {@link TokenFilter} that sets
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
  * <p><b>NOTE</b>: Input is expected to be in lowercase, 
  * but with diacritical marks</p>
- * @see KeywordMarkerTokenFilter
+ * @see KeywordMarkerFilter
  */
 public final class CzechStemFilter extends TokenFilter {
   private final CzechStemmer stemmer;
