Index: src/test/org/apache/lucene/queryParser/TestQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestQueryParser.java	(revision 790750)
+++ src/test/org/apache/lucene/queryParser/TestQueryParser.java	(working copy)
@@ -424,12 +424,13 @@
 
   public void testRange() throws Exception {
     assertQueryEquals("[ a TO z]", null, "[a TO z]");
+    /* Disabled, because QueryParser now generates a different type of RangeQuery
     assertTrue(((RangeQuery)getQuery("[ a TO z]", null)).getConstantScoreRewrite());
 
     QueryParser qp = new QueryParser("field", new SimpleAnalyzer());
 	  qp.setConstantScoreRewrite(false);
     assertFalse(((RangeQuery)qp.parse("[ a TO z]")).getConstantScoreRewrite());
-    
+    */
     assertQueryEquals("[ a TO z ]", null, "[a TO z]");
     assertQueryEquals("{ a TO z}", null, "{a TO z}");
     assertQueryEquals("{ a TO z }", null, "{a TO z}");
Index: src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(revision 790750)
+++ src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(working copy)
@@ -1,606 +0,0 @@
-package org.apache.lucene.search;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.WhitespaceAnalyzer;
-import org.apache.lucene.analysis.SimpleAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.RAMDirectory;
-
-import java.io.IOException;
-import java.text.Collator;
-import java.util.Locale;
-
-import junit.framework.Assert;
-
-public class TestMultiTermConstantScore extends BaseTestRangeFilter {
-
-  /** threshold for comparing floats */
-  public static final float SCORE_COMP_THRESH = 1e-6f;
-
-  public TestMultiTermConstantScore(String name) {
-    super(name);
-  }
-
-  public TestMultiTermConstantScore() {
-    super();
-  }
-
-  Directory small;
-
-  void assertEquals(String m, float e, float a) {
-    assertEquals(m, e, a, SCORE_COMP_THRESH);
-  }
-
-  static public void assertEquals(String m, int e, int a) {
-    Assert.assertEquals(m, e, a);
-  }
-
-  public void setUp() throws Exception {
-    super.setUp();
-
-    String[] data = new String[] { "A 1 2 3 4 5 6", "Z       4 5 6", null,
-        "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
-        "X       4 5 6" };
-
-    small = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(small, new WhitespaceAnalyzer(), true,
-        IndexWriter.MaxFieldLength.LIMITED);
-
-    for (int i = 0; i < data.length; i++) {
-      Document doc = new Document();
-      doc.add(new Field("id", String.valueOf(i), Field.Store.YES,
-          Field.Index.NOT_ANALYZED));// Field.Keyword("id",String.valueOf(i)));
-      doc
-          .add(new Field("all", "all", Field.Store.YES,
-              Field.Index.NOT_ANALYZED));// Field.Keyword("all","all"));
-      if (null != data[i]) {
-        doc.add(new Field("data", data[i], Field.Store.YES,
-            Field.Index.ANALYZED));// Field.Text("data",data[i]));
-      }
-      writer.addDocument(doc);
-    }
-
-    writer.optimize();
-    writer.close();
-  }
-
-  /** macro for readability */
-  public static Query csrq(String f, String l, String h, boolean il, boolean ih) {
-    RangeQuery query = new RangeQuery(f, l, h, il, ih);
-    query.setConstantScoreRewrite(true);
-    return query;
-  }
-
-  /** macro for readability */
-  public static Query csrq(String f, String l, String h, boolean il,
-      boolean ih, Collator c) {
-    RangeQuery query = new RangeQuery(f, l, h, il, ih, c);
-    query.setConstantScoreRewrite(true);
-    return query;
-  }
-
-  /** macro for readability */
-  public static Query cspq(Term prefix) {
-    PrefixQuery query = new PrefixQuery(prefix);
-    query.setConstantScoreRewrite(true);
-    return query;
-  }
-
-  /** macro for readability */
-  public static Query cswcq(Term wild) {
-    WildcardQuery query = new WildcardQuery(wild);
-    query.setConstantScoreRewrite(true);
-    return query;
-  }
-
-  public void testBasics() throws IOException {
-    QueryUtils.check(csrq("data", "1", "6", T, T));
-    QueryUtils.check(csrq("data", "A", "Z", T, T));
-    QueryUtils.checkUnequal(csrq("data", "1", "6", T, T), csrq("data", "A",
-        "Z", T, T));
-
-    QueryUtils.check(cspq(new Term("data", "p*u?")));
-    QueryUtils.checkUnequal(cspq(new Term("data", "pre*")), cspq(new Term(
-        "data", "pres*")));
-
-    QueryUtils.check(cswcq(new Term("data", "p")));
-    QueryUtils.checkUnequal(cswcq(new Term("data", "pre*n?t")), cswcq(new Term(
-        "data", "pr*t?j")));
-  }
-
-  public void testBasicsRngCollating() throws IOException {
-    Collator c = Collator.getInstance(Locale.ENGLISH);
-    QueryUtils.check(csrq("data", "1", "6", T, T, c));
-    QueryUtils.check(csrq("data", "A", "Z", T, T, c));
-    QueryUtils.checkUnequal(csrq("data", "1", "6", T, T, c), csrq("data", "A",
-        "Z", T, T, c));
-  }
-
-  public void testEqualScores() throws IOException {
-    // NOTE: uses index build in *this* setUp
-
-    IndexReader reader = IndexReader.open(small);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    ScoreDoc[] result;
-
-    // some hits match more terms then others, score should be the same
-
-    result = search.search(csrq("data", "1", "6", T, T), null, 1000).scoreDocs;
-    int numHits = result.length;
-    assertEquals("wrong number of results", 6, numHits);
-    float score = result[0].score;
-    for (int i = 1; i < numHits; i++) {
-      assertEquals("score for " + i + " was not the same", score,
-          result[i].score);
-    }
-
-  }
-
-  public void testBoost() throws IOException {
-    // NOTE: uses index build in *this* setUp
-
-    IndexReader reader = IndexReader.open(small);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    // test for correct application of query normalization
-    // must use a non score normalizing method for this.
-    Query q = csrq("data", "1", "6", T, T);
-    q.setBoost(100);
-    search.search(q, null, new HitCollector() {
-      public void collect(int doc, float score) {
-        assertEquals("score for doc " + doc + " was not correct", 1.0f, score);
-      }
-    });
-
-    //
-    // Ensure that boosting works to score one clause of a query higher
-    // than another.
-    //
-    Query q1 = csrq("data", "A", "A", T, T); // matches document #0
-    q1.setBoost(.1f);
-    Query q2 = csrq("data", "Z", "Z", T, T); // matches document #1
-    BooleanQuery bq = new BooleanQuery(true);
-    bq.add(q1, BooleanClause.Occur.SHOULD);
-    bq.add(q2, BooleanClause.Occur.SHOULD);
-
-    ScoreDoc[] hits = search.search(bq, null, 1000).scoreDocs;
-    assertEquals(1, hits[0].doc);
-    assertEquals(0, hits[1].doc);
-    assertTrue(hits[0].score > hits[1].score);
-
-    q1 = csrq("data", "A", "A", T, T); // matches document #0
-    q1.setBoost(10f);
-    q2 = csrq("data", "Z", "Z", T, T); // matches document #1
-    bq = new BooleanQuery(true);
-    bq.add(q1, BooleanClause.Occur.SHOULD);
-    bq.add(q2, BooleanClause.Occur.SHOULD);
-
-    hits = search.search(bq, null, 1000).scoreDocs;
-    assertEquals(0, hits[0].doc);
-    assertEquals(1, hits[1].doc);
-    assertTrue(hits[0].score > hits[1].score);
-  }
-
-  public void testBooleanOrderUnAffected() throws IOException {
-    // NOTE: uses index build in *this* setUp
-
-    IndexReader reader = IndexReader.open(small);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    // first do a regular RangeQuery which uses term expansion so
-    // docs with more terms in range get higher scores
-
-    Query rq = new RangeQuery(new Term("data", "1"), new Term("data", "4"), T);
-
-    ScoreDoc[] expected = search.search(rq, null, 1000).scoreDocs;
-    int numHits = expected.length;
-
-    // now do a boolean where which also contains a
-    // ConstantScoreRangeQuery and make sure hte order is the same
-
-    BooleanQuery q = new BooleanQuery();
-    q.add(rq, BooleanClause.Occur.MUST);// T, F);
-    q.add(csrq("data", "1", "6", T, T), BooleanClause.Occur.MUST);// T, F);
-
-    ScoreDoc[] actual = search.search(q, null, 1000).scoreDocs;
-
-    assertEquals("wrong numebr of hits", numHits, actual.length);
-    for (int i = 0; i < numHits; i++) {
-      assertEquals("mismatch in docid for hit#" + i, expected[i].doc,
-          actual[i].doc);
-    }
-
-  }
-
-  public void testRangeQueryId() throws IOException {
-    // NOTE: uses index build in *super* setUp
-
-    IndexReader reader = IndexReader.open(signedIndex.index);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    int medId = ((maxId - minId) / 2);
-
-    String minIP = pad(minId);
-    String maxIP = pad(maxId);
-    String medIP = pad(medId);
-
-    int numDocs = reader.numDocs();
-
-    assertEquals("num of docs", numDocs, 1 + maxId - minId);
-
-    ScoreDoc[] result;
-
-    // test id, bounded on both ends
-
-    result = search.search(csrq("id", minIP, maxIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("find all", numDocs, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, T, F), null, numDocs).scoreDocs;
-    assertEquals("all but last", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, F, T), null, numDocs).scoreDocs;
-    assertEquals("all but first", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, F, F), null, numDocs).scoreDocs;
-    assertEquals("all but ends", numDocs - 2, result.length);
-
-    result = search.search(csrq("id", medIP, maxIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("med and up", 1 + maxId - medId, result.length);
-
-    result = search.search(csrq("id", minIP, medIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("up to med", 1 + medId - minId, result.length);
-
-    // unbounded id
-
-    result = search.search(csrq("id", minIP, null, T, F), null, numDocs).scoreDocs;
-    assertEquals("min and up", numDocs, result.length);
-
-    result = search.search(csrq("id", null, maxIP, F, T), null, numDocs).scoreDocs;
-    assertEquals("max and down", numDocs, result.length);
-
-    result = search.search(csrq("id", minIP, null, F, F), null, numDocs).scoreDocs;
-    assertEquals("not min, but up", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", null, maxIP, F, F), null, numDocs).scoreDocs;
-    assertEquals("not max, but down", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", medIP, maxIP, T, F), null, numDocs).scoreDocs;
-    assertEquals("med and up, not max", maxId - medId, result.length);
-
-    result = search.search(csrq("id", minIP, medIP, F, T), null, numDocs).scoreDocs;
-    assertEquals("not min, up to med", medId - minId, result.length);
-
-    // very small sets
-
-    result = search.search(csrq("id", minIP, minIP, F, F), null, numDocs).scoreDocs;
-    assertEquals("min,min,F,F", 0, result.length);
-    result = search.search(csrq("id", medIP, medIP, F, F), null, numDocs).scoreDocs;
-    assertEquals("med,med,F,F", 0, result.length);
-    result = search.search(csrq("id", maxIP, maxIP, F, F), null, numDocs).scoreDocs;
-    assertEquals("max,max,F,F", 0, result.length);
-
-    result = search.search(csrq("id", minIP, minIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("min,min,T,T", 1, result.length);
-    result = search.search(csrq("id", null, minIP, F, T), null, numDocs).scoreDocs;
-    assertEquals("nul,min,F,T", 1, result.length);
-
-    result = search.search(csrq("id", maxIP, maxIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("max,max,T,T", 1, result.length);
-    result = search.search(csrq("id", maxIP, null, T, F), null, numDocs).scoreDocs;
-    assertEquals("max,nul,T,T", 1, result.length);
-
-    result = search.search(csrq("id", medIP, medIP, T, T), null, numDocs).scoreDocs;
-    assertEquals("med,med,T,T", 1, result.length);
-
-  }
-
-  public void testRangeQueryIdCollating() throws IOException {
-    // NOTE: uses index build in *super* setUp
-
-    IndexReader reader = IndexReader.open(signedIndex.index);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    int medId = ((maxId - minId) / 2);
-
-    String minIP = pad(minId);
-    String maxIP = pad(maxId);
-    String medIP = pad(medId);
-
-    int numDocs = reader.numDocs();
-
-    assertEquals("num of docs", numDocs, 1 + maxId - minId);
-
-    ScoreDoc[] result;
-
-    Collator c = Collator.getInstance(Locale.ENGLISH);
-
-    // test id, bounded on both ends
-
-    result = search.search(csrq("id", minIP, maxIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("find all", numDocs, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("all but last", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("all but first", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", minIP, maxIP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("all but ends", numDocs - 2, result.length);
-
-    result = search.search(csrq("id", medIP, maxIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("med and up", 1 + maxId - medId, result.length);
-
-    result = search.search(csrq("id", minIP, medIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("up to med", 1 + medId - minId, result.length);
-
-    // unbounded id
-
-    result = search.search(csrq("id", minIP, null, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("min and up", numDocs, result.length);
-
-    result = search.search(csrq("id", null, maxIP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("max and down", numDocs, result.length);
-
-    result = search.search(csrq("id", minIP, null, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("not min, but up", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", null, maxIP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("not max, but down", numDocs - 1, result.length);
-
-    result = search.search(csrq("id", medIP, maxIP, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("med and up, not max", maxId - medId, result.length);
-
-    result = search.search(csrq("id", minIP, medIP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("not min, up to med", medId - minId, result.length);
-
-    // very small sets
-
-    result = search.search(csrq("id", minIP, minIP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("min,min,F,F,c", 0, result.length);
-    result = search.search(csrq("id", medIP, medIP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("med,med,F,F,c", 0, result.length);
-    result = search.search(csrq("id", maxIP, maxIP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("max,max,F,F,c", 0, result.length);
-
-    result = search.search(csrq("id", minIP, minIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("min,min,T,T,c", 1, result.length);
-    result = search.search(csrq("id", null, minIP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("nul,min,F,T,c", 1, result.length);
-
-    result = search.search(csrq("id", maxIP, maxIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("max,max,T,T,c", 1, result.length);
-    result = search.search(csrq("id", maxIP, null, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("max,nul,T,T,c", 1, result.length);
-
-    result = search.search(csrq("id", medIP, medIP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("med,med,T,T,c", 1, result.length);
-  }
-
-  public void testRangeQueryRand() throws IOException {
-    // NOTE: uses index build in *super* setUp
-
-    IndexReader reader = IndexReader.open(signedIndex.index);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    String minRP = pad(signedIndex.minR);
-    String maxRP = pad(signedIndex.maxR);
-
-    int numDocs = reader.numDocs();
-
-    assertEquals("num of docs", numDocs, 1 + maxId - minId);
-
-    ScoreDoc[] result;
-
-    // test extremes, bounded on both ends
-
-    result = search.search(csrq("rand", minRP, maxRP, T, T), null, numDocs).scoreDocs;
-    assertEquals("find all", numDocs, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, T, F), null, numDocs).scoreDocs;
-    assertEquals("all but biggest", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, F, T), null, numDocs).scoreDocs;
-    assertEquals("all but smallest", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, F, F), null, numDocs).scoreDocs;
-    assertEquals("all but extremes", numDocs - 2, result.length);
-
-    // unbounded
-
-    result = search.search(csrq("rand", minRP, null, T, F), null, numDocs).scoreDocs;
-    assertEquals("smallest and up", numDocs, result.length);
-
-    result = search.search(csrq("rand", null, maxRP, F, T), null, numDocs).scoreDocs;
-    assertEquals("biggest and down", numDocs, result.length);
-
-    result = search.search(csrq("rand", minRP, null, F, F), null, numDocs).scoreDocs;
-    assertEquals("not smallest, but up", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", null, maxRP, F, F), null, numDocs).scoreDocs;
-    assertEquals("not biggest, but down", numDocs - 1, result.length);
-
-    // very small sets
-
-    result = search.search(csrq("rand", minRP, minRP, F, F), null, numDocs).scoreDocs;
-    assertEquals("min,min,F,F", 0, result.length);
-    result = search.search(csrq("rand", maxRP, maxRP, F, F), null, numDocs).scoreDocs;
-    assertEquals("max,max,F,F", 0, result.length);
-
-    result = search.search(csrq("rand", minRP, minRP, T, T), null, numDocs).scoreDocs;
-    assertEquals("min,min,T,T", 1, result.length);
-    result = search.search(csrq("rand", null, minRP, F, T), null, numDocs).scoreDocs;
-    assertEquals("nul,min,F,T", 1, result.length);
-
-    result = search.search(csrq("rand", maxRP, maxRP, T, T), null, numDocs).scoreDocs;
-    assertEquals("max,max,T,T", 1, result.length);
-    result = search.search(csrq("rand", maxRP, null, T, F), null, numDocs).scoreDocs;
-    assertEquals("max,nul,T,T", 1, result.length);
-
-  }
-
-  public void testRangeQueryRandCollating() throws IOException {
-    // NOTE: uses index build in *super* setUp
-
-    // using the unsigned index because collation seems to ignore hyphens
-    IndexReader reader = IndexReader.open(unsignedIndex.index);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    String minRP = pad(unsignedIndex.minR);
-    String maxRP = pad(unsignedIndex.maxR);
-
-    int numDocs = reader.numDocs();
-
-    assertEquals("num of docs", numDocs, 1 + maxId - minId);
-
-    ScoreDoc[] result;
-
-    Collator c = Collator.getInstance(Locale.ENGLISH);
-
-    // test extremes, bounded on both ends
-
-    result = search.search(csrq("rand", minRP, maxRP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("find all", numDocs, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("all but biggest", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("all but smallest", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", minRP, maxRP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("all but extremes", numDocs - 2, result.length);
-
-    // unbounded
-
-    result = search.search(csrq("rand", minRP, null, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("smallest and up", numDocs, result.length);
-
-    result = search.search(csrq("rand", null, maxRP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("biggest and down", numDocs, result.length);
-
-    result = search.search(csrq("rand", minRP, null, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("not smallest, but up", numDocs - 1, result.length);
-
-    result = search.search(csrq("rand", null, maxRP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("not biggest, but down", numDocs - 1, result.length);
-
-    // very small sets
-
-    result = search.search(csrq("rand", minRP, minRP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("min,min,F,F,c", 0, result.length);
-    result = search.search(csrq("rand", maxRP, maxRP, F, F, c), null, numDocs).scoreDocs;
-    assertEquals("max,max,F,F,c", 0, result.length);
-
-    result = search.search(csrq("rand", minRP, minRP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("min,min,T,T,c", 1, result.length);
-    result = search.search(csrq("rand", null, minRP, F, T, c), null, numDocs).scoreDocs;
-    assertEquals("nul,min,F,T,c", 1, result.length);
-
-    result = search.search(csrq("rand", maxRP, maxRP, T, T, c), null, numDocs).scoreDocs;
-    assertEquals("max,max,T,T,c", 1, result.length);
-    result = search.search(csrq("rand", maxRP, null, T, F, c), null, numDocs).scoreDocs;
-    assertEquals("max,nul,T,T,c", 1, result.length);
-  }
-
-  public void testFarsi() throws Exception {
-
-    /* build an index */
-    RAMDirectory farsiIndex = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(farsiIndex, new SimpleAnalyzer(), T,
-        IndexWriter.MaxFieldLength.LIMITED);
-    Document doc = new Document();
-    doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
-        Field.Index.NOT_ANALYZED));
-    doc
-        .add(new Field("body", "body", Field.Store.YES,
-            Field.Index.NOT_ANALYZED));
-    writer.addDocument(doc);
-
-    writer.optimize();
-    writer.close();
-
-    IndexReader reader = IndexReader.open(farsiIndex);
-    IndexSearcher search = new IndexSearcher(reader);
-
-    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
-    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
-    // characters properly.
-    Collator c = Collator.getInstance(new Locale("ar"));
-
-    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
-    // orders the U+0698 character before the U+0633 character, so the single
-    // index Term below should NOT be returned by a ConstantScoreRangeQuery
-    // with a Farsi Collator (or an Arabic one for the case when Farsi is
-    // not supported).
-    ScoreDoc[] result = search.search(csrq("content", "\u062F", "\u0698", T, T,
-        c), null, 1000).scoreDocs;
-    assertEquals("The index Term should not be included.", 0, result.length);
-
-    result = search.search(csrq("content", "\u0633", "\u0638", T, T, c), null,
-        1000).scoreDocs;
-    assertEquals("The index Term should be included.", 1, result.length);
-    search.close();
-  }
-
-  public void testDanish() throws Exception {
-
-    /* build an index */
-    RAMDirectory danishIndex = new RAMDirectory();
-    IndexWriter writer = new IndexWriter(danishIndex, new SimpleAnalyzer(), T,
-                                         IndexWriter.MaxFieldLength.LIMITED);
-
-    // Danish collation orders the words below in the given order
-    // (example taken from TestSort.testInternationalSort() ).
-    String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
-    for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
-      Document doc = new Document();
-      doc.add(new Field("content", words[docnum], 
-                        Field.Store.YES, Field.Index.UN_TOKENIZED));
-      doc.add(new Field("body", "body",
-                        Field.Store.YES, Field.Index.UN_TOKENIZED));
-      writer.addDocument(doc);
-    }
-    writer.optimize();
-    writer.close();
-
-    IndexReader reader = IndexReader.open(danishIndex);
-    IndexSearcher search = new IndexSearcher(reader);
-    Query q = new TermQuery(new Term("body","body"));
-
-    Collator c = Collator.getInstance(new Locale("da", "dk"));
-
-    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
-    // but Danish collation does.
-    ScoreDoc[] result = search.search
-      (csrq("content", "H\u00D8T", "MAND", F, F, c), null, 1000).scoreDocs;
-    assertEquals("The index Term should be included.", 1, result.length);
-
-    result = search.search
-      (csrq("content", "H\u00C5T", "MAND", F, F, c), null, 1000).scoreDocs;
-    assertEquals("The index Term should not be included.", 0, result.length);
-    search.close();
-  }
-}
Index: src/test/org/apache/lucene/search/TestRangeFilter.java
===================================================================
--- src/test/org/apache/lucene/search/TestRangeFilter.java	(revision 790750)
+++ src/test/org/apache/lucene/search/TestRangeFilter.java	(working copy)
@@ -376,46 +376,4 @@
         assertEquals("The index Term should be included.", 1, result.length());
         search.close();
     }
-
-    public void testDanish() throws Exception {
-            
-        /* build an index */
-        RAMDirectory danishIndex = new RAMDirectory();
-        IndexWriter writer = new IndexWriter
-            (danishIndex, new SimpleAnalyzer(), T, 
-             IndexWriter.MaxFieldLength.LIMITED);
-        // Danish collation orders the words below in the given order
-        // (example taken from TestSort.testInternationalSort() ).
-        String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
-        for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
-            Document doc = new Document();
-            doc.add(new Field("content", words[docnum], 
-                              Field.Store.YES, Field.Index.UN_TOKENIZED));
-            doc.add(new Field("body", "body",
-                              Field.Store.YES, Field.Index.UN_TOKENIZED));
-            writer.addDocument(doc);
-        }
-        writer.optimize();
-        writer.close();
-
-        IndexReader reader = IndexReader.open(danishIndex);
-        IndexSearcher search = new IndexSearcher(reader);
-        Query q = new TermQuery(new Term("body","body"));
-
-        Collator collator = Collator.getInstance(new Locale("da", "dk"));
-        Query query = new RangeQuery
-            ("content", "H\u00D8T", "MAND", false, false, collator);
-
-        // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
-        // but Danish collation does.
-        Hits result = search.search
-            (q, new RangeFilter("content", "H\u00D8T", "MAND", F, F, collator));
-        assertEquals("The index Term should be included.", 1, result.length());
-
-        result = search.search
-            (q, new RangeFilter("content", "H\u00C5T", "MAND", F, F, collator));
-        assertEquals
-            ("The index Term should not be included.", 0, result.length());
-        search.close();
-    }
 }
Index: src/test/org/apache/lucene/search/TestRangeQuery.java
===================================================================
--- src/test/org/apache/lucene/search/TestRangeQuery.java	(revision 790750)
+++ src/test/org/apache/lucene/search/TestRangeQuery.java	(working copy)
@@ -23,14 +23,9 @@
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.RAMDirectory;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 
 import org.apache.lucene.util.LuceneTestCase;
 import java.io.IOException;
-import java.io.Reader;
 import java.util.Locale;
 import java.text.Collator;
 
@@ -46,7 +41,9 @@
   }
 
   public void testExclusive() throws Exception {
-    Query query = new RangeQuery("content", "A", "C", false, false);
+    Query query = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 false);
     initializeIndex(new String[] {"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
     ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
@@ -65,26 +62,11 @@
     assertEquals("C added, still only B in range", 1, hits.length);
     searcher.close();
   }
-  
-  //TODO: remove in Lucene 3.0
-  public void testDeprecatedCstrctors() throws IOException {
-    Query query = new RangeQuery(null, new Term("content","C"), false);
-    initializeIndex(new String[] {"A", "B", "C", "D"});
-    IndexSearcher searcher = new IndexSearcher(dir);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
-    assertEquals("A,B,C,D, only B in range", 2, hits.length);
-    searcher.close();
-    
-    query = new RangeQuery(new Term("content","C"),null, false);
-    initializeIndex(new String[] {"A", "B", "C", "D"});
-    searcher = new IndexSearcher(dir);
-    hits = searcher.search(query, null, 1000).scoreDocs;
-    assertEquals("A,B,C,D, only B in range", 1, hits.length);
-    searcher.close();
-  }
 
   public void testInclusive() throws Exception {
-    Query query = new RangeQuery("content", "A", "C", true, true);
+    Query query = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 true);
 
     initializeIndex(new String[]{"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
@@ -106,10 +88,13 @@
   }
 
   public void testEqualsHashcode() {
-    Query query = new RangeQuery("content", "A", "C", true, true);
-    
+    Query query = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 true);
     query.setBoost(1.0f);
-    Query other = new RangeQuery("content", "A", "C", true, true);
+    Query other = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 true);
     other.setBoost(1.0f);
 
     assertEquals("query equals itself is true", query, query);
@@ -119,36 +104,38 @@
     other.setBoost(2.0f);
     assertFalse("Different boost queries are not equal", query.equals(other));
 
-    other = new RangeQuery("notcontent", "A", "C", true, true);
+    other = new RangeQuery(new Term("notcontent", "A"), new Term("notcontent", "C"), true);
     assertFalse("Different fields are not equal", query.equals(other));
 
-    other = new RangeQuery("content", "X", "C", true, true);
+    other = new RangeQuery(new Term("content", "X"), new Term("content", "C"), true);
     assertFalse("Different lower terms are not equal", query.equals(other));
 
-    other = new RangeQuery("content", "A", "Z", true, true);
+    other = new RangeQuery(new Term("content", "A"), new Term("content", "Z"), true);
     assertFalse("Different upper terms are not equal", query.equals(other));
 
-    query = new RangeQuery("content", null, "C", true, true);
-    other = new RangeQuery("content", null, "C", true, true);
+    query = new RangeQuery(null, new Term("content", "C"), true);
+    other = new RangeQuery(null, new Term("content", "C"), true);
     assertEquals("equivalent queries with null lowerterms are equal()", query, other);
     assertEquals("hashcode must return same value when equals is true", query.hashCode(), other.hashCode());
 
-    query = new RangeQuery("content", "C", null, true, true);
-    other = new RangeQuery("content", "C", null, true, true);
+    query = new RangeQuery(new Term("content", "C"), null, true);
+    other = new RangeQuery(new Term("content", "C"), null, true);
     assertEquals("equivalent queries with null upperterms are equal()", query, other);
     assertEquals("hashcode returns same value", query.hashCode(), other.hashCode());
 
-    query = new RangeQuery("content", null, "C", true, true);
-    other = new RangeQuery("content", "C", null, true, true);
+    query = new RangeQuery(null, new Term("content", "C"), true);
+    other = new RangeQuery(new Term("content", "C"), null, true);
     assertFalse("queries with different upper and lower terms are not equal", query.equals(other));
 
-    query = new RangeQuery("content", "A", "C", false, false);
-    other = new RangeQuery("content", "A", "C", true, true);
+    query = new RangeQuery(new Term("content", "A"), new Term("content", "C"), false);
+    other = new RangeQuery(new Term("content", "A"), new Term("content", "C"), true);
     assertFalse("queries with different inclusive are not equal", query.equals(other));
   }
 
   public void testExclusiveCollating() throws Exception {
-    Query query = new RangeQuery("content", "A", "C", false, false, Collator.getInstance(Locale.ENGLISH));
+    Query query = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 false, Collator.getInstance(Locale.ENGLISH));
     initializeIndex(new String[] {"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
     ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
@@ -169,7 +156,9 @@
   }
 
   public void testInclusiveCollating() throws Exception {
-    Query query = new RangeQuery("content", "A", "C",true, true, Collator.getInstance(Locale.ENGLISH));
+    Query query = new RangeQuery(new Term("content", "A"),
+                                 new Term("content", "C"),
+                                 true, Collator.getInstance(Locale.ENGLISH));
 
     initializeIndex(new String[]{"A", "B", "C", "D"});
     IndexSearcher searcher = new IndexSearcher(dir);
@@ -195,7 +184,9 @@
     // RuleBasedCollator.  However, the Arabic Locale seems to order the Farsi
     // characters properly.
     Collator collator = Collator.getInstance(new Locale("ar"));
-    Query query = new RangeQuery("content", "\u062F", "\u0698", true, true, collator);
+    Query query = new RangeQuery(new Term("content", "\u062F"),
+                                 new Term("content", "\u0698"),
+                                 true, collator);
     // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
     // orders the U+0698 character before the U+0633 character, so the single
     // index Term below should NOT be returned by a RangeQuery with a Farsi
@@ -205,86 +196,16 @@
     ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
     assertEquals("The index Term should not be included.", 0, hits.length);
 
-    query = new RangeQuery("content", "\u0633", "\u0638",true, true, collator);
+    query = new RangeQuery(new Term("content", "\u0633"),
+                           new Term("content", "\u0638"),
+                           true, collator);
     hits = searcher.search(query, null, 1000).scoreDocs;
     assertEquals("The index Term should be included.", 1, hits.length);
     searcher.close();
   }
-  
-  public void testDanish() throws Exception {
-    Collator collator = Collator.getInstance(new Locale("da", "dk"));
-    // Danish collation orders the words below in the given order (example taken
-    // from TestSort.testInternationalSort() ).
-    String[] words = { "H\u00D8T", "H\u00C5T", "MAND" };
-    Query query = new RangeQuery("content", "H\u00D8T", "MAND", false, false, collator);
 
-    // Unicode order would not include "H\u00C5T" in [ "H\u00D8T", "MAND" ],
-    // but Danish collation does.
-    initializeIndex(words);
-    IndexSearcher searcher = new IndexSearcher(dir);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
-    assertEquals("The index Term should be included.", 1, hits.length);
-
-    query = new RangeQuery("content", "H\u00C5T", "MAND", false, false, collator);
-    hits = searcher.search(query, null, 1000).scoreDocs;
-    assertEquals("The index Term should not be included.", 0, hits.length);
-    searcher.close();
-  }
-
-  private static class SingleCharAnalyzer extends Analyzer {
-
-    private static class SingleCharTokenizer extends Tokenizer {
-      char[] buffer = new char[1];
-      boolean done;
-      TermAttribute termAtt;
-      
-      public SingleCharTokenizer(Reader r) {
-        super(r);
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      }
-
-      public boolean incrementToken() throws IOException {
-        int count = input.read(buffer);
-        if (done)
-          return false;
-        else {
-          done = true;
-          if (count == 1) {
-            termAtt.termBuffer()[0] = buffer[0];
-            termAtt.setTermLength(1);
-          } else
-            termAtt.setTermLength(0);
-          return true;
-        }
-      }
-
-      public final void reset(Reader reader) throws IOException {
-        super.reset(reader);
-        done = false;
-      }
-    }
-
-    public TokenStream reusableTokenStream(String fieldName, Reader reader) throws IOException {
-      Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();
-      if (tokenizer == null) {
-        tokenizer = new SingleCharTokenizer(reader);
-        setPreviousTokenStream(tokenizer);
-      } else
-        tokenizer.reset(reader);
-      return tokenizer;
-    }
-
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      return new SingleCharTokenizer(reader);
-    }
-  }
-
   private void initializeIndex(String[] values) throws IOException {
-    initializeIndex(values, new WhitespaceAnalyzer());
-  }
-
-  private void initializeIndex(String[] values, Analyzer analyzer) throws IOException {
-    IndexWriter writer = new IndexWriter(dir, analyzer, true, IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter writer = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
     for (int i = 0; i < values.length; i++) {
       insertDoc(writer, values[i]);
     }
@@ -306,71 +227,4 @@
     writer.addDocument(doc);
     docCount++;
   }
-
-  // LUCENE-38
-  public void testExclusiveLowerNull() throws Exception {
-    Analyzer analyzer = new SingleCharAnalyzer();
-    //http://issues.apache.org/jira/browse/LUCENE-38
-    Query query = new RangeQuery(null,
-                                 new Term("content", "C"),
-                                 false);
-    initializeIndex(new String[] {"A", "B", "", "C", "D"}, analyzer);
-    IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("A,B,<empty string>,C,D => A, B & <empty string> are in range", 3, hits.length());
-    // until Lucene-38 is fixed, use this assert:
-    //assertEquals("A,B,<empty string>,C,D => A, B & <empty string> are in range", 2, hits.length());
-
-    searcher.close();
-    initializeIndex(new String[] {"A", "B", "", "D"}, analyzer);
-    searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("A,B,<empty string>,D => A, B & <empty string> are in range", 3, hits.length());
-    // until Lucene-38 is fixed, use this assert:
-    //assertEquals("A,B,<empty string>,D => A, B & <empty string> are in range", 2, hits.length());
-    searcher.close();
-    addDoc("C");
-    searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("C added, still A, B & <empty string> are in range", 3, hits.length());
-    // until Lucene-38 is fixed, use this assert
-    //assertEquals("C added, still A, B & <empty string> are in range", 2, hits.length());
-    searcher.close();
-  }
-
-  // LUCENE-38
-  public void testInclusiveLowerNull() throws Exception {
-    //http://issues.apache.org/jira/browse/LUCENE-38
-    Analyzer analyzer = new SingleCharAnalyzer();
-    Query query = new RangeQuery(null,
-                                 new Term("content", "C"),
-                                 true);
-    initializeIndex(new String[]{"A", "B", "","C", "D"}, analyzer);
-    IndexSearcher searcher = new IndexSearcher(dir);
-    Hits hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("A,B,<empty string>,C,D => A,B,<empty string>,C in range", 4, hits.length());
-    // until Lucene-38 is fixed, use this assert
-    //assertEquals("A,B,<empty string>,C,D => A,B,<empty string>,C in range", 3, hits.length());
-    searcher.close();
-    initializeIndex(new String[]{"A", "B", "", "D"}, analyzer);
-    searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("A,B,<empty string>,D - A, B and <empty string> in range", 3, hits.length());
-    // until Lucene-38 is fixed, use this assert
-    //assertEquals("A,B,<empty string>,D => A, B and <empty string> in range", 2, hits.length());
-    searcher.close();
-    addDoc("C");
-    searcher = new IndexSearcher(dir);
-    hits = searcher.search(query);
-    // When Lucene-38 is fixed, use the assert on the next line:
-    assertEquals("C added => A,B,<empty string>,C in range", 4, hits.length());
-    // until Lucene-38 is fixed, use this assert
-    //assertEquals("C added => A,B,<empty string>,C in range", 3, hits.length());
-     searcher.close();
-  }
 }
