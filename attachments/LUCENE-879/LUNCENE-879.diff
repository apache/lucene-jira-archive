Index: src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java	(revision 537286)
+++ src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java	(working copy)
@@ -49,7 +49,7 @@
     assertEquals("foo", qp.parse("\"foo\"").toString());
     assertEquals("foo foobar", qp.parse("foo foobar").toString());
     assertEquals("\"foo foobar\"", qp.parse("\"foo foobar\"").toString());
-    assertEquals("\"foo foobar blah\"", qp.parse("\"foo foobar blah\"").toString());
+    assertEquals("\"foo foobar mergeDocumentFields\"", qp.parse("\"foo foobar mergeDocumentFields\"").toString());
 
     // two tokens at the same position:
     assertEquals("(multi multi2) foo", qp.parse("multi foo").toString());
Index: src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(revision 537286)
+++ src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(working copy)
@@ -144,7 +144,7 @@
     q = MultiFieldQueryParser.parse(queries4, fields, new StandardAnalyzer());
     assertEquals("(b:one +b:more) (+t:two)", q.toString());
 
-    String[] queries5 = {"blah"};
+    String[] queries5 = {"mergeDocumentFields"};
     try {
       q = MultiFieldQueryParser.parse(queries5, fields, new StandardAnalyzer());
       fail();
@@ -164,7 +164,7 @@
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse("mergeDocumentFields", fields, flags2, new StandardAnalyzer());
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -185,7 +185,7 @@
 
     try {
       BooleanClause.Occur[] flags2 = {BooleanClause.Occur.MUST};
-      q = MultiFieldQueryParser.parse("blah", fields, flags2, new StandardAnalyzer());
+      q = MultiFieldQueryParser.parse("mergeDocumentFields", fields, flags2, new StandardAnalyzer());
       fail();
     } catch(IllegalArgumentException e) {
       // expected exception, array length differs
@@ -244,7 +244,7 @@
     Directory ramDir = new RAMDirectory();
     IndexWriter iw =  new IndexWriter(ramDir, analyzer, true);
     Document doc = new Document();
-    doc.add(new Field("body", "blah the footest blah", Field.Store.NO, Field.Index.TOKENIZED));
+    doc.add(new Field("body", "mergeDocumentFields the footest mergeDocumentFields", Field.Store.NO, Field.Index.TOKENIZED));
     iw.addDocument(doc);
     iw.close();
     
Index: src/test/org/apache/lucene/queryParser/TestQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestQueryParser.java	(revision 537286)
+++ src/test/org/apache/lucene/queryParser/TestQueryParser.java	(working copy)
@@ -498,23 +498,23 @@
     /*assertQueryEquals("\\[brackets", a, "\\[brackets");
     assertQueryEquals("\\[brackets", null, "brackets");
     assertQueryEquals("\\\\", a, "\\\\");
-    assertQueryEquals("\\+blah", a, "\\+blah");
-    assertQueryEquals("\\(blah", a, "\\(blah");
+    assertQueryEquals("\\+mergeDocumentFields", a, "\\+mergeDocumentFields");
+    assertQueryEquals("\\(mergeDocumentFields", a, "\\(mergeDocumentFields");
 
-    assertQueryEquals("\\-blah", a, "\\-blah");
-    assertQueryEquals("\\!blah", a, "\\!blah");
-    assertQueryEquals("\\{blah", a, "\\{blah");
-    assertQueryEquals("\\}blah", a, "\\}blah");
-    assertQueryEquals("\\:blah", a, "\\:blah");
-    assertQueryEquals("\\^blah", a, "\\^blah");
-    assertQueryEquals("\\[blah", a, "\\[blah");
-    assertQueryEquals("\\]blah", a, "\\]blah");
-    assertQueryEquals("\\\"blah", a, "\\\"blah");
-    assertQueryEquals("\\(blah", a, "\\(blah");
-    assertQueryEquals("\\)blah", a, "\\)blah");
-    assertQueryEquals("\\~blah", a, "\\~blah");
-    assertQueryEquals("\\*blah", a, "\\*blah");
-    assertQueryEquals("\\?blah", a, "\\?blah");
+    assertQueryEquals("\\-mergeDocumentFields", a, "\\-mergeDocumentFields");
+    assertQueryEquals("\\!mergeDocumentFields", a, "\\!mergeDocumentFields");
+    assertQueryEquals("\\{mergeDocumentFields", a, "\\{mergeDocumentFields");
+    assertQueryEquals("\\}mergeDocumentFields", a, "\\}mergeDocumentFields");
+    assertQueryEquals("\\:mergeDocumentFields", a, "\\:mergeDocumentFields");
+    assertQueryEquals("\\^mergeDocumentFields", a, "\\^mergeDocumentFields");
+    assertQueryEquals("\\[mergeDocumentFields", a, "\\[mergeDocumentFields");
+    assertQueryEquals("\\]mergeDocumentFields", a, "\\]mergeDocumentFields");
+    assertQueryEquals("\\\"mergeDocumentFields", a, "\\\"mergeDocumentFields");
+    assertQueryEquals("\\(mergeDocumentFields", a, "\\(mergeDocumentFields");
+    assertQueryEquals("\\)mergeDocumentFields", a, "\\)mergeDocumentFields");
+    assertQueryEquals("\\~mergeDocumentFields", a, "\\~mergeDocumentFields");
+    assertQueryEquals("\\*mergeDocumentFields", a, "\\*mergeDocumentFields");
+    assertQueryEquals("\\?mergeDocumentFields", a, "\\?mergeDocumentFields");
     //assertQueryEquals("foo \\&\\& bar", a, "foo \\&\\& bar");
     //assertQueryEquals("foo \\|| bar", a, "foo \\|| bar");
     //assertQueryEquals("foo \\AND bar", a, "foo \\AND bar");*/
Index: src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(revision 537286)
+++ src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(working copy)
@@ -136,7 +136,7 @@
   }
   
   private void addCollection1(IndexWriter iw) throws IOException {
-    add("one blah three", iw);
+    add("one mergeDocumentFields three", iw);
     add("one foo three multiOne", iw);
     add("one foobar three multiThree", iw);
     add("blueberry pie", iw);
@@ -145,7 +145,7 @@
   }
 
   private void addCollection2(IndexWriter iw) throws IOException {
-    add("two blah three", iw);
+    add("two mergeDocumentFields three", iw);
     add("two foo xxx multiTwo", iw);
     add("two foobar xxx multiThreee", iw);
     add("blueberry chewing gum", iw);
Index: src/test/org/apache/lucene/index/TestIdentifiableDocumentUpdateSegmentMerger.java
===================================================================
--- src/test/org/apache/lucene/index/TestIdentifiableDocumentUpdateSegmentMerger.java	(revision 0)
+++ src/test/org/apache/lucene/index/TestIdentifiableDocumentUpdateSegmentMerger.java	(revision 0)
@@ -0,0 +1,70 @@
+package org.apache.lucene.index;
+
+import junit.framework.TestCase;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+
+import java.io.IOException;
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-12
+ *         Time: 00:47:02
+ */
+public class TestIdentifiableDocumentUpdateSegmentMerger extends TestCase {
+
+  public void test() throws Exception {
+
+
+    RAMDirectory dir = new RAMDirectory();
+
+    IndexWriter iw = new IndexWriter(dir, null, true);
+    iw.setMaxMergeDocs(100);
+    iw.setMergeFactor(100);
+
+    Document[] documents = new Document[10];
+    for (int i = 0; i < documents.length; i++) {
+      documents[i] = new Document();
+      documents[i].add(new Field("_id", String.valueOf(i), Field.Store.YES, Field.Index.UN_TOKENIZED));
+      iw.addDocument(documents[i]);
+    }
+
+    iw.close();
+
+    IndexReader ir = IndexReader.open(dir);
+    ir.deleteDocument(5);
+    ir.close();
+        
+    iw = new IndexWriter(dir, null, false);
+    iw.setMaxMergeDocs(100);
+    iw.setMergeFactor(100);
+
+    documents[5].add(new Field("foo", "bar", Field.Store.YES, Field.Index.UN_TOKENIZED));
+    iw.addDocument(documents[5]);
+
+    iw.setSegmentMergerFactory(new SegmentMergerFactory(){
+      public AbstractSegmentMerger newInstance(IndexWriter indexWriter, String mergedName) {
+        return new IdentifiableDocumentUpdateSegmentMerger(indexWriter, mergedName) {
+          protected Query documentIdentityQueryFactory(IndexReader reader, int docNum) throws IOException {
+            return new TermQuery(new Term("_id", reader.document(docNum).get("_id")));
+          }
+        };
+      }
+    });
+
+    iw.optimize();
+    iw.close();
+
+    ir = IndexReader.open(dir);
+
+    assertTrue(ir.document(5).get("foo") != null);
+
+    ir.close();
+
+
+  }
+
+}
Index: src/test/org/apache/lucene/index/TestMultiReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestMultiReader.java	(revision 537286)
+++ src/test/org/apache/lucene/index/TestMultiReader.java	(working copy)
@@ -19,9 +19,7 @@
 
 import junit.framework.TestCase;
 
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 
@@ -111,7 +109,7 @@
     RAMDirectory ramDir1=new RAMDirectory();
     addDoc(ramDir1, "test foo", true);
     RAMDirectory ramDir2=new RAMDirectory();
-    addDoc(ramDir2, "test blah", true);
+    addDoc(ramDir2, "test mergeDocumentFields", true);
     IndexReader[] readers = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2)};
     MultiReader mr = new MultiReader(readers);
     assertTrue(mr.isCurrent());   // just opened, must be current
Index: src/java/org/apache/lucene/index/IdentifiableDocumentUpdateSegmentMerger.java
===================================================================
--- src/java/org/apache/lucene/index/IdentifiableDocumentUpdateSegmentMerger.java	(revision 0)
+++ src/java/org/apache/lucene/index/IdentifiableDocumentUpdateSegmentMerger.java	(revision 0)
@@ -0,0 +1,117 @@
+package org.apache.lucene.index;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.document.FieldSelector;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.HitCollector;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.*;
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-11
+ *         Time: 23:32:03
+ */
+public abstract class IdentifiableDocumentUpdateSegmentMerger extends StaticDocumentNumberSegmentMerger {
+
+  public IdentifiableDocumentUpdateSegmentMerger(Directory dir, String name) {
+    super(dir, name);
+  }
+
+  public IdentifiableDocumentUpdateSegmentMerger(IndexWriter writer, String name) {
+    super(writer, name);
+  }
+
+  private Map/*<Set<Integer>>*/ reassignedDocumentNumbersByReader = new HashMap/*<Set<Integer>>*/();
+
+  protected abstract Query documentIdentityQueryFactory(IndexReader reader, int docNum) throws IOException;
+
+  protected int mergeDocumentFields(IndexReader reader, int docNum, FieldsWriter fieldsWriter, FieldSelector fieldSelectorMerge) throws IOException {
+
+    Set/*<Integer>*/ reassignedDocumentNumbersForCurrentReader = (Set/*<Integer>*/)reassignedDocumentNumbersByReader.get(reader);
+    if (reassignedDocumentNumbersForCurrentReader != null && reassignedDocumentNumbersForCurrentReader.contains(docNum)) {
+      // this document has been moved to another place in the index. so skip it.
+      return 0;
+    }
+
+    if (reader.isDeleted(docNum)) {
+      Query idQuery = documentIdentityQueryFactory(reader, docNum);
+      if (idQuery != null) {
+
+        // this is a identified document. is there an update?
+
+        for (int readerIndex = getReaders().size() - 1; readerIndex >= 0; readerIndex--) {
+
+          IndexSearcher searcher = new IndexSearcher((IndexReader) getReaders().get(readerIndex));
+
+          final List/*<Integer>*/ hits = new ArrayList/*<Integer>*/();
+          searcher.search(idQuery, new HitCollector() {
+            public void collect(int doc, float score) {
+              hits.add(doc);
+            }
+          });
+
+          searcher.close();
+
+          if (hits.size() > 0) {
+
+            Collections.sort(hits);
+            int topDocNum = (Integer) hits.get(0);
+
+            if (reader == getReaders().get(readerIndex)
+                && topDocNum == docNum) {
+              // current reader and current document is top. no update available
+              break;
+            } else {
+
+              if (reassignedDocumentNumbersForCurrentReader == null) {
+                reassignedDocumentNumbersForCurrentReader = new HashSet/*<Integer>*/();
+                reassignedDocumentNumbersByReader.put(getReaders().get(readerIndex), reassignedDocumentNumbersForCurrentReader);
+              }              
+              reassignedDocumentNumbersForCurrentReader.add(docNum);
+              
+              fieldsWriter.addDocument(((IndexReader)getReaders().get(readerIndex)).document(topDocNum, fieldSelectorMerge));
+              return 1;
+
+            }
+          }
+
+          if (reader == getReaders().get(readerIndex)) {
+            // reached current segment. no update available.
+            break;
+          }
+
+        }
+      }
+    }
+    return super.mergeDocumentFields(reader, docNum, fieldsWriter, fieldSelectorMerge);
+
+  }
+
+  protected void mergeDocumentVectors(IndexReader reader, int docNum, TermVectorsWriter termVectorsWriter) throws IOException {
+
+    Set/*<Integer>*/ reassignedDocumentNumbers = (Set/*<Integer>*/)reassignedDocumentNumbersByReader.get(reader);
+    if (reassignedDocumentNumbers != null && reassignedDocumentNumbers.contains(docNum)) {
+      // this document has been moved to another place in the index. so skip it.
+      return;
+    }
+
+    super.mergeDocumentVectors(reader, docNum, termVectorsWriter);
+  }
+
+  protected void mergeDocumentNorms(IndexReader reader, int docNum, IndexOutput output, byte[] normBuffer) throws IOException {
+
+    Set/*<Integer>*/ reassignedDocumentNumbers = (Set/*<Integer>*/)reassignedDocumentNumbersByReader.get(reader);
+    if (reassignedDocumentNumbers != null && reassignedDocumentNumbers.contains(docNum)) {
+      // this document has been moved to another place in the index. so skip it.
+      return;
+    }
+
+    super.mergeDocumentNorms(reader, docNum, output, normBuffer);
+  }
+}
Index: src/java/org/apache/lucene/index/StaticDocumentNumberSegmentMerger.java
===================================================================
--- src/java/org/apache/lucene/index/StaticDocumentNumberSegmentMerger.java	(revision 0)
+++ src/java/org/apache/lucene/index/StaticDocumentNumberSegmentMerger.java	(revision 0)
@@ -0,0 +1,69 @@
+package org.apache.lucene.index;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.document.FieldSelector;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.search.Similarity;
+
+import java.io.IOException;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-11
+ *         Time: 23:12:04
+ */
+public class StaticDocumentNumberSegmentMerger extends SegmentMerger {
+
+
+  public StaticDocumentNumberSegmentMerger(Directory dir, String name) {
+    super(dir, name);
+  }
+
+  public StaticDocumentNumberSegmentMerger(IndexWriter writer, String name) {
+    super(writer, name);
+  }
+
+  protected int mergeDocumentFields(IndexReader reader, int docNum, FieldsWriter fieldsWriter, FieldSelector fieldSelectorMerge) throws IOException {
+    if (reader.isDeleted(docNum)) {
+      fieldsWriter.addDocument(new Document());
+      return 1;
+    } else {
+      return super.mergeDocumentFields(reader, docNum, fieldsWriter, fieldSelectorMerge);
+    }
+  }
+
+  protected void mergeDocumentVectors(IndexReader reader, int docNum, TermVectorsWriter termVectorsWriter) throws IOException {
+    if (reader.isDeleted(docNum)) {
+      termVectorsWriter.addAllDocVectors(null);
+    } else {
+      super.mergeDocumentVectors(reader, docNum, termVectorsWriter);
+    }
+  }
+
+  protected void mergeDocumentNorms(IndexReader reader, int docNum, IndexOutput output, byte[] normBuffer) throws IOException {
+    if (reader.isDeleted(docNum)) {
+      output.writeByte(Similarity.encodeNorm(0f));      
+    } else {
+      super.mergeDocumentNorms(reader, docNum, output, normBuffer);
+    }
+  }
+}
Index: src/java/org/apache/lucene/index/DefaultSegmentMergerFactory.java
===================================================================
--- src/java/org/apache/lucene/index/DefaultSegmentMergerFactory.java	(revision 0)
+++ src/java/org/apache/lucene/index/DefaultSegmentMergerFactory.java	(revision 0)
@@ -0,0 +1,32 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-11
+ *         Time: 23:00:23
+ */
+public class DefaultSegmentMergerFactory implements SegmentMergerFactory {
+
+
+  public SegmentMerger newInstance(IndexWriter indexWriter, String mergedName) {
+    return new SegmentMerger(indexWriter, mergedName);
+  }
+
+}
Index: src/java/org/apache/lucene/index/SegmentMerger.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentMerger.java	(revision 537286)
+++ src/java/org/apache/lucene/index/SegmentMerger.java	(working copy)
@@ -39,7 +39,7 @@
  * @see #merge
  * @see #add
  */
-final class SegmentMerger {
+class SegmentMerger extends AbstractSegmentMerger {
   
   /** norms header placeholder */
   static final byte[] NORMS_HEADER = new byte[]{'N','R','M',-1}; 
@@ -48,7 +48,7 @@
   private String segment;
   private int termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;
 
-  private Vector readers = new Vector();
+  private Vector/*<IndexReader>*/ readers = new Vector/*<IndexReader>*/();
   private FieldInfos fieldInfos;
 
   /** This ctor used only by test code.
@@ -201,11 +201,9 @@
       for (int i = 0; i < readers.size(); i++) {
         IndexReader reader = (IndexReader) readers.elementAt(i);
         int maxDoc = reader.maxDoc();
-        for (int j = 0; j < maxDoc; j++)
-          if (!reader.isDeleted(j)) {               // skip deleted docs
-            fieldsWriter.addDocument(reader.document(j, fieldSelectorMerge));
-            docCount++;
-          }
+        for (int j = 0; j < maxDoc; j++) {
+          docCount += mergeDocumentFields(reader, j, fieldsWriter, fieldSelectorMerge);
+        }
       }
     } finally {
       fieldsWriter.close();
@@ -213,7 +211,23 @@
     return docCount;
   }
 
+
   /**
+   * @param reader
+   * @param docNum
+   * @param fieldsWriter
+   * @param fieldSelectorMerge @return Number of documents merged. 0 or 1;
+   * @throws IOException
+   */
+  protected int mergeDocumentFields(IndexReader reader, int docNum, FieldsWriter fieldsWriter, FieldSelector fieldSelectorMerge) throws IOException {
+    if (!reader.isDeleted(docNum)) {               // skip deleted docs
+      fieldsWriter.addDocument(reader.document(docNum, fieldSelectorMerge));
+      return 1;
+    }
+    return 0;
+  }
+
+  /**
    * Merge the TermVectors from each of the segments into the new one.
    * @throws IOException
    */
@@ -226,10 +240,7 @@
         IndexReader reader = (IndexReader) readers.elementAt(r);
         int maxDoc = reader.maxDoc();
         for (int docNum = 0; docNum < maxDoc; docNum++) {
-          // skip deleted docs
-          if (reader.isDeleted(docNum)) 
-            continue;
-          termVectorsWriter.addAllDocVectors(reader.getTermFreqVectors(docNum));
+          mergeDocumentVectors(reader, docNum, termVectorsWriter);
         }
       }
     } finally {
@@ -237,6 +248,13 @@
     }
   }
 
+  protected void mergeDocumentVectors(IndexReader reader, int docNum, TermVectorsWriter termVectorsWriter) throws IOException {
+    // skip deleted docs
+    if (!reader.isDeleted(docNum)) {      
+      termVectorsWriter.addAllDocVectors(reader.getTermFreqVectors(docNum));
+    }
+  }
+
   private IndexOutput freqOutput = null;
   private IndexOutput proxOutput = null;
   private TermInfosWriter termInfosWriter = null;
@@ -508,9 +526,7 @@
               // this segment has deleted docs, so we have to
               // check for every doc if it is deleted or not
               for (int k = 0; k < maxDoc; k++) {
-                if (!reader.isDeleted(k)) {
-                  output.writeByte(normBuffer[k]);
-                }
+                mergeDocumentNorms(reader, k, output, normBuffer);
               }
             }
           }
@@ -523,4 +539,14 @@
     }
   }
 
+  protected void mergeDocumentNorms(IndexReader reader, int k, IndexOutput output, byte[] normBuffer) throws IOException {
+    // skip deleted documents
+    if (!reader.isDeleted(k)) {
+      output.writeByte(normBuffer[k]);
+    }
+  }
+
+  public Vector/*<IndexReader>*/ getReaders() {
+    return readers;
+  }
 }
Index: src/java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- src/java/org/apache/lucene/index/IndexWriter.java	(revision 537286)
+++ src/java/org/apache/lucene/index/IndexWriter.java	(working copy)
@@ -1556,6 +1556,17 @@
     }
   }
 
+  private SegmentMergerFactory segmentMergerFactory = new DefaultSegmentMergerFactory();
+
+
+  public SegmentMergerFactory getSegmentMergerFactory() {
+    return segmentMergerFactory;
+  }
+
+  public void setSegmentMergerFactory(SegmentMergerFactory segmentMergerFactory) {
+    this.segmentMergerFactory = segmentMergerFactory;
+  }
+
   /** Merges the provided indexes into this index.
    * <p>After this completes, the index is optimized. </p>
    * <p>The provided IndexReaders are not closed.</p>
@@ -1574,7 +1585,7 @@
     optimize();					  // start with zero or 1 seg
 
     final String mergedName = newSegmentName();
-    SegmentMerger merger = new SegmentMerger(this, mergedName);
+    AbstractSegmentMerger merger = segmentMergerFactory.newInstance(this, mergedName);
 
     SegmentInfo info;
 
@@ -1796,7 +1807,7 @@
     // pending, in which case doMerge is false:
     boolean doMerge = end > 0;
     final String mergedName = newSegmentName();
-    SegmentMerger merger = null;
+    AbstractSegmentMerger merger = null;
 
     final List ramSegmentsToDelete = new ArrayList();
 
@@ -1810,7 +1821,7 @@
 
       if (doMerge) {
         if (infoStream != null) infoStream.print("merging segments");
-        merger = new SegmentMerger(this, mergedName);
+        merger = segmentMergerFactory.newInstance(this, mergedName);
 
         for (int i = minSegment; i < end; i++) {
           SegmentInfo si = sourceSegments.info(i);
@@ -2095,4 +2106,5 @@
       reader.deleteDocuments((Term) entry.getKey());
     }
   }
+  
 }
Index: src/java/org/apache/lucene/index/SegmentReader.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentReader.java	(revision 537286)
+++ src/java/org/apache/lucene/index/SegmentReader.java	(working copy)
@@ -317,9 +317,10 @@
    */
   public synchronized Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
     ensureOpen();
-    if (isDeleted(n))
-      throw new IllegalArgumentException
-              ("attempt to access a deleted document");
+    // todo commented out for IdentifiableDocumentUpdateSegmentMerger.documentIdentityQueryFactory
+//    if (isDeleted(n))
+//      throw new IllegalArgumentException
+//              ("attempt to access a deleted document");
     return fieldsReader.doc(n, fieldSelector);
   }
 
Index: src/java/org/apache/lucene/index/AbstractSegmentMerger.java
===================================================================
--- src/java/org/apache/lucene/index/AbstractSegmentMerger.java	(revision 0)
+++ src/java/org/apache/lucene/index/AbstractSegmentMerger.java	(revision 0)
@@ -0,0 +1,56 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Vector;
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-11
+ *         Time: 23:04:56
+ */
+public abstract class AbstractSegmentMerger {
+
+  /**
+   * Add an IndexReader to the collection of readers that are to be merged
+   *
+   * @param reader
+   */
+  abstract void add(IndexReader reader);
+
+  /**
+   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor
+   *
+   * @return The number of documents that were merged
+   * @throws CorruptIndexException if the index is corrupt
+   * @throws java.io.IOException   if there is a low-level IO error
+   */
+  abstract int merge() throws CorruptIndexException, IOException;
+
+  abstract Vector createCompoundFile(String fileName) throws IOException;
+
+  /**
+   * close all IndexReaders that have been added.
+   * Should not be called before merge().
+   *
+   * @throws IOException
+   */
+  abstract void closeReaders() throws IOException;
+
+}
Index: src/java/org/apache/lucene/index/SegmentMergerFactory.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentMergerFactory.java	(revision 0)
+++ src/java/org/apache/lucene/index/SegmentMergerFactory.java	(revision 0)
@@ -0,0 +1,29 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * @author karl wettin <mailto:karl.wettin@gmail.com>
+ *         Date: 2007-maj-11
+ *         Time: 22:56:55
+ */
+public interface SegmentMergerFactory {
+
+  public abstract AbstractSegmentMerger newInstance(IndexWriter indexWriter, String mergedName);
+
+}
