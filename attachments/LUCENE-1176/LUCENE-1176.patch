Index: src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 620768)
+++ src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -38,9 +38,9 @@
 
 
   public void testRandom() throws Exception {
-    Directory dir1 = new RAMDirectory();
+    Directory dir1 = new MockRAMDirectory();
     // dir1 = FSDirectory.getDirectory("foofoofoo");
-    Directory dir2 = new RAMDirectory();
+    Directory dir2 = new MockRAMDirectory();
     // mergeFactor=2; maxBufferedDocs=2; Map docs = indexRandom(1, 3, 2, dir1);
     Map docs = indexRandom(10, 100, 100, dir1);
     indexSerial(docs, dir2);
@@ -54,7 +54,8 @@
 
   public void testMultiConfig() throws Exception {
     // test lots of smaller different params together
-    for (int i=0; i<100; i++) {  // increase iterations for better testing
+    for (int i=0; i<100; i++) {  // increase iterations for
+                                 // better testing
       sameFieldOrder=r.nextBoolean();
       autoCommit=r.nextBoolean();
       mergeFactor=r.nextInt(3)+2;
@@ -65,8 +66,8 @@
       int iter=r.nextInt(10)+1;
       int range=r.nextInt(20)+1;
 
-      Directory dir1 = new RAMDirectory();
-      Directory dir2 = new RAMDirectory();
+      Directory dir1 = new MockRAMDirectory();
+      Directory dir2 = new MockRAMDirectory();
       Map docs = indexRandom(nThreads, iter, range, dir1);
       indexSerial(docs, dir2);
       verifyEquals(dir1, dir2, "id");
@@ -87,7 +88,7 @@
   // everything.
 
   public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {
-    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);
+    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);
     w.setUseCompoundFile(false);
     /***
     w.setMaxMergeDocs(Integer.MAX_VALUE);
@@ -195,8 +196,11 @@
       r2r1[id2] = id1;
 
       // verify stored fields are equivalent
-     verifyEquals(r1.document(id1), r2.document(id2));
+      verifyEquals(r1.document(id1), r2.document(id2));
 
+      // verify term vectors are equivalent
+      verifyEquals(r1.getTermFreqVectors(id1), r2.getTermFreqVectors(id2));
+
     } while (termEnum.next());
 
     termEnum.close();
@@ -300,7 +304,55 @@
     }
   }
 
+  public static void verifyEquals(TermFreqVector[] d1, TermFreqVector[] d2) {
+    if (d1 == null) {
+      assertTrue(d2 == null);
+      return;
+    }
+    assertTrue(d2 != null);
 
+    assertEquals(d1.length, d2.length);
+    for(int i=0;i<d1.length;i++) {
+      TermFreqVector v1 = d1[i];
+      TermFreqVector v2 = d2[i];
+      assertEquals(v1.size(), v2.size());
+      int numTerms = v1.size();
+      String[] terms1 = v1.getTerms();
+      String[] terms2 = v2.getTerms();
+      int[] freq1 = v1.getTermFrequencies();
+      int[] freq2 = v2.getTermFrequencies();
+      for(int j=0;j<numTerms;j++) {
+        assertEquals(terms1[j], terms2[j]);
+        assertEquals(freq1[j], freq2[j]);
+      }
+      if (v1 instanceof TermPositionVector) {
+        assertTrue(v2 instanceof TermPositionVector);
+        TermPositionVector tpv1 = (TermPositionVector) v1;
+        TermPositionVector tpv2 = (TermPositionVector) v2;
+        for(int j=0;j<numTerms;j++) {
+          int[] pos1 = tpv1.getTermPositions(j);
+          int[] pos2 = tpv2.getTermPositions(j);
+          assertEquals(pos1.length, pos2.length);
+          TermVectorOffsetInfo[] offsets1 = tpv1.getOffsets(j);
+          TermVectorOffsetInfo[] offsets2 = tpv2.getOffsets(j);
+          if (offsets1 == null)
+            assertTrue(offsets2 == null);
+          else
+            assertTrue(offsets2 != null);
+          for(int k=0;k<pos1.length;k++) {
+            assertEquals(pos1[k], pos2[k]);
+            if (offsets1 != null) {
+              assertEquals(offsets1[k].getStartOffset(),
+                           offsets2[k].getStartOffset());
+              assertEquals(offsets1[k].getEndOffset(),
+                           offsets2[k].getEndOffset());
+            }
+          }
+        }
+      }
+    }
+  }
+
   private static class IndexingThread extends Thread {
     IndexWriter w;
     int base;
@@ -336,18 +388,35 @@
 
       int nFields = nextInt(maxFields);
       for (int i=0; i<nFields; i++) {
+
+        Field.TermVector tvVal = Field.TermVector.NO;
         switch (nextInt(4)) {
+        case 0:
+          tvVal = Field.TermVector.NO;
+          break;
+        case 1:
+          tvVal = Field.TermVector.YES;
+          break;
+        case 2:
+          tvVal = Field.TermVector.WITH_POSITIONS;
+          break;
+        case 3:
+          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;
+          break;
+        }
+        
+        switch (nextInt(4)) {
           case 0:
-            fields.add(new Field("f0", getString(1), Field.Store.YES, Field.Index.NO_NORMS));
+            fields.add(new Field("f0", getString(1), Field.Store.YES, Field.Index.NO_NORMS, tvVal));
             break;
           case 1:
-            fields.add(new Field("f1", getString(0), Field.Store.NO, Field.Index.TOKENIZED));
+            fields.add(new Field("f1", getString(0), Field.Store.NO, Field.Index.TOKENIZED, tvVal));
             break;
           case 2:
-            fields.add(new Field("f2", getString(0), Field.Store.YES, Field.Index.NO));
+            fields.add(new Field("f2", getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));
             break;
           case 3:
-            fields.add(new Field("f3", getString(bigFieldSize), Field.Store.YES, Field.Index.TOKENIZED));
+            fields.add(new Field("f3", getString(bigFieldSize), Field.Store.YES, Field.Index.TOKENIZED, tvVal));
             break;          
         }
       }
