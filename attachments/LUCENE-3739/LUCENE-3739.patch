Index: lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java
===================================================================
--- lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java	(revision 1238621)
+++ lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java	(working copy)
@@ -33,8 +33,6 @@
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.FieldsEnum;
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
@@ -43,26 +41,11 @@
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.CodecUtil;
 import org.apache.lucene.util.IOUtils;
 
 public class Lucene40TermVectorsReader extends TermVectorsReader {
 
-  // NOTE: if you make a new format, it must be larger than
-  // the current format
-
-  // Changed strings to UTF8 with length-in-bytes not length-in-chars
-  static final int FORMAT_UTF8_LENGTH_IN_BYTES = 4;
-
-  // NOTE: always change this if you switch to a new format!
-  // whenever you add a new format, make it 1 larger (positive version logic)!
-  static final int FORMAT_CURRENT = FORMAT_UTF8_LENGTH_IN_BYTES;
-  
-  // when removing support for old versions, leave the last supported version here
-  static final int FORMAT_MINIMUM = FORMAT_UTF8_LENGTH_IN_BYTES;
-
-  //The size in bytes that the FORMAT_VERSION will take up at the beginning of each file 
-  static final int FORMAT_SIZE = 4;
-
   static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x1;
 
   static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x2;
@@ -83,18 +66,15 @@
   private IndexInput tvf;
   private int size;
   private int numTotalDocs;
-  
-  private final int format;
 
   // used by clone
-  Lucene40TermVectorsReader(FieldInfos fieldInfos, IndexInput tvx, IndexInput tvd, IndexInput tvf, int size, int numTotalDocs, int format) {
+  Lucene40TermVectorsReader(FieldInfos fieldInfos, IndexInput tvx, IndexInput tvd, IndexInput tvf, int size, int numTotalDocs) {
     this.fieldInfos = fieldInfos;
     this.tvx = tvx;
     this.tvd = tvd;
     this.tvf = tvf;
     this.size = size;
     this.numTotalDocs = numTotalDocs;
-    this.format = format;
   }
     
   public Lucene40TermVectorsReader(Directory d, SegmentInfo si, FieldInfos fieldInfos, IOContext context)
@@ -107,19 +87,16 @@
     try {
       String idxName = IndexFileNames.segmentFileName(segment, "", VECTORS_INDEX_EXTENSION);
       tvx = d.openInput(idxName, context);
-      format = checkValidFormat(tvx);
+      CodecUtil.checkHeader(tvx, Lucene40TermVectorsWriter.INDEX_CODEC, Lucene40TermVectorsWriter.VERSION_START, Lucene40TermVectorsWriter.VERSION_CURRENT);
       String fn = IndexFileNames.segmentFileName(segment, "", VECTORS_DOCUMENTS_EXTENSION);
       tvd = d.openInput(fn, context);
-      final int tvdFormat = checkValidFormat(tvd);
+      CodecUtil.checkHeader(tvd, Lucene40TermVectorsWriter.DOCUMENTS_CODEC, Lucene40TermVectorsWriter.VERSION_START, Lucene40TermVectorsWriter.VERSION_CURRENT);
       fn = IndexFileNames.segmentFileName(segment, "", VECTORS_FIELDS_EXTENSION);
       tvf = d.openInput(fn, context);
-      final int tvfFormat = checkValidFormat(tvf);
+      CodecUtil.checkHeader(tvf, Lucene40TermVectorsWriter.FIELDS_CODEC, Lucene40TermVectorsWriter.VERSION_START, Lucene40TermVectorsWriter.VERSION_CURRENT);
 
-      assert format == tvdFormat;
-      assert format == tvfFormat;
+      numTotalDocs = (int) ((tvx.length()-Lucene40TermVectorsWriter.INDEX_HEADER_LENGTH) >> 4);
 
-      numTotalDocs = (int) (tvx.length() >> 4);
-
       this.size = numTotalDocs;
       assert size == 0 || numTotalDocs == size;
 
@@ -149,15 +126,9 @@
 
   // Not private to avoid synthetic access$NNN methods
   void seekTvx(final int docNum) throws IOException {
-    tvx.seek(docNum * 16L + FORMAT_SIZE);
+    tvx.seek(docNum * 16L + Lucene40TermVectorsWriter.INDEX_HEADER_LENGTH);
   }
 
-  boolean canReadRawDocs() {
-    // we can always read raw docs, unless the term vectors
-    // didn't exist
-    return format != 0;
-  }
-
   /** Retrieve the length (in bytes) of the tvd and tvf
    *  entries for the next numDocs starting with
    *  startDocID.  This is used for bulk copying when
@@ -203,16 +174,6 @@
     }
   }
 
-  private int checkValidFormat(IndexInput in) throws CorruptIndexException, IOException
-  {
-    int format = in.readInt();
-    if (format < FORMAT_MINIMUM)
-      throw new IndexFormatTooOldException(in, format, FORMAT_MINIMUM, FORMAT_CURRENT);
-    if (format > FORMAT_CURRENT)
-      throw new IndexFormatTooNewException(in, format, FORMAT_MINIMUM, FORMAT_CURRENT);
-    return format;
-  }
-
   public void close() throws IOException {
     IOUtils.close(tvx, tvd, tvf);
   }
@@ -458,8 +419,8 @@
         endOffsets = new int[freq];
         int offset = 0;
         for(int posUpto=0;posUpto<freq;posUpto++) {
-          startOffsets[posUpto] = offset + tvf.readVInt();
-          offset = endOffsets[posUpto] = startOffsets[posUpto] + tvf.readVInt();
+          offset = startOffsets[posUpto] = offset + tvf.readVInt();
+          endOffsets[posUpto] = offset + tvf.readVInt();
         }
       }
 
@@ -696,7 +657,7 @@
       cloneTvf = (IndexInput) tvf.clone();
     }
     
-    return new Lucene40TermVectorsReader(fieldInfos, cloneTvx, cloneTvd, cloneTvf, size, numTotalDocs, format);
+    return new Lucene40TermVectorsReader(fieldInfos, cloneTvx, cloneTvd, cloneTvf, size, numTotalDocs);
   }
   
   public static void files(SegmentInfo info, Set<String> files) throws IOException {
Index: lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsWriter.java
===================================================================
--- lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsWriter.java	(revision 1238621)
+++ lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsWriter.java	(working copy)
@@ -35,19 +35,25 @@
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.CodecUtil;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.StringHelper;
 
 // TODO: make a new 4.0 TV format that encodes better
-//   - use startOffset (not endOffset) as base for delta on
-//     next startOffset because today for syns or ngrams or
-//     WDF or shingles etc. we are encoding negative vints
-//     (= slow, 5 bytes per)
 //   - if doc has no term vectors, write 0 into the tvx
 //     file; saves a seek to tvd only to read a 0 vint (and
 //     saves a byte in tvd)
 
 public final class Lucene40TermVectorsWriter extends TermVectorsWriter {
+  final static String INDEX_CODEC = "Lucene40TermVectorsIndex";
+  final static String DOCUMENTS_CODEC = "Lucene40TermVectorsDocuments";
+  final static String FIELDS_CODEC = "Lucene40TermVectorsFields";
+  final static int VERSION_START = 0;
+  final static int VERSION_CURRENT = VERSION_START;
+  
+  // used for checking written size in finish()
+  final static int INDEX_HEADER_LENGTH = CodecUtil.headerLength(INDEX_CODEC);
+
   private final Directory directory;
   private final String segment;
   private IndexOutput tvx = null, tvd = null, tvf = null;
@@ -59,11 +65,11 @@
     try {
       // Open files for TermVector storage
       tvx = directory.createOutput(IndexFileNames.segmentFileName(segment, "", Lucene40TermVectorsReader.VECTORS_INDEX_EXTENSION), context);
-      tvx.writeInt(Lucene40TermVectorsReader.FORMAT_CURRENT);
+      CodecUtil.writeHeader(tvx, INDEX_CODEC, VERSION_CURRENT);
       tvd = directory.createOutput(IndexFileNames.segmentFileName(segment, "", Lucene40TermVectorsReader.VECTORS_DOCUMENTS_EXTENSION), context);
-      tvd.writeInt(Lucene40TermVectorsReader.FORMAT_CURRENT);
+      CodecUtil.writeHeader(tvd, DOCUMENTS_CODEC, VERSION_CURRENT);
       tvf = directory.createOutput(IndexFileNames.segmentFileName(segment, "", Lucene40TermVectorsReader.VECTORS_FIELDS_EXTENSION), context);
-      tvf.writeInt(Lucene40TermVectorsReader.FORMAT_CURRENT);
+      CodecUtil.writeHeader(tvf, FIELDS_CODEC, VERSION_CURRENT);
       success = true;
     } finally {
       if (!success) {
@@ -183,7 +189,7 @@
         for (int i = 0; i < offsetIndex; i++) {
           tvf.writeVInt(offsetStartBuffer[i] - lastOffset);
           tvf.writeVInt(offsetEndBuffer[i] - offsetStartBuffer[i]);
-          lastOffset = offsetEndBuffer[i];
+          lastOffset = offsetStartBuffer[i];
         }
       }
     } else if (positions) {
@@ -194,7 +200,7 @@
       // write offset deltas
       tvf.writeVInt(startOffset - lastOffset);
       tvf.writeVInt(endOffset - startOffset);
-      lastOffset = endOffset;
+      lastOffset = startOffset;
     }
   }
 
@@ -245,10 +251,9 @@
         TermVectorsReader vectorsReader = matchingSegmentReader.getTermVectorsReader();
 
         if (vectorsReader != null && vectorsReader instanceof Lucene40TermVectorsReader) {
-          // If the TV* files are an older format then they cannot read raw docs:
-          if (((Lucene40TermVectorsReader)vectorsReader).canReadRawDocs()) {
-            matchingVectorsReader = (Lucene40TermVectorsReader) vectorsReader;
-          }
+          // note: if we add minor versions to 4.0's term vectors, we should check
+          // the format is the same... but its unlikely, simpler to just make a new impl.
+          matchingVectorsReader = (Lucene40TermVectorsReader) vectorsReader;
         }
       }
       if (reader.liveDocs != null) {
@@ -349,7 +354,7 @@
   
   @Override
   public void finish(int numDocs) throws IOException {
-    if (4+((long) numDocs)*16 != tvx.getFilePointer())
+    if (INDEX_HEADER_LENGTH+((long) numDocs)*16 != tvx.getFilePointer())
       // This is most likely a bug in Sun JRE 1.6.0_04/_05;
       // we detect that the bug has struck, here, and
       // throw an exception to prevent the corruption from
Index: lucene/src/java/org/apache/lucene/codecs/TermVectorsWriter.java
===================================================================
--- lucene/src/java/org/apache/lucene/codecs/TermVectorsWriter.java	(revision 1238603)
+++ lucene/src/java/org/apache/lucene/codecs/TermVectorsWriter.java	(working copy)
@@ -126,7 +126,7 @@
       } else {
         startOffset = lastOffset + offsets.readVInt();
         endOffset = startOffset + offsets.readVInt();
-        lastOffset = endOffset;
+        lastOffset = startOffset;
       }
       addPosition(position, startOffset, endOffset);
     }
Index: lucene/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java	(revision 1238603)
+++ lucene/src/java/org/apache/lucene/index/TermVectorsConsumerPerField.java	(working copy)
@@ -179,7 +179,7 @@
 
       termsHashPerField.writeVInt(1, startOffset);
       termsHashPerField.writeVInt(1, endOffset - startOffset);
-      postings.lastOffsets[termID] = endOffset;
+      postings.lastOffsets[termID] = startOffset;
     }
 
     if (doVectorPositions) {
@@ -203,7 +203,7 @@
 
       termsHashPerField.writeVInt(1, startOffset - postings.lastOffsets[termID]);
       termsHashPerField.writeVInt(1, endOffset - startOffset);
-      postings.lastOffsets[termID] = endOffset;
+      postings.lastOffsets[termID] = startOffset;
     }
 
     if (doVectorPositions) {
Index: lucene/src/test-framework/java/org/apache/lucene/codecs/preflexrw/PreFlexRWTermVectorsWriter.java
===================================================================
--- lucene/src/test-framework/java/org/apache/lucene/codecs/preflexrw/PreFlexRWTermVectorsWriter.java	(revision 1238603)
+++ lucene/src/test-framework/java/org/apache/lucene/codecs/preflexrw/PreFlexRWTermVectorsWriter.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.codecs.lucene3x.Lucene3xTermVectorsReader;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexOutput;
@@ -136,23 +135,6 @@
   int lastOffset = 0;
 
   @Override
-  public void addProx(int numProx, DataInput positions, DataInput offsets) throws IOException {
-    // TODO: technically we could just copy bytes and not re-encode if we knew the length...
-    if (positions != null) {
-      for (int i = 0; i < numProx; i++) {
-        tvf.writeVInt(positions.readVInt());
-      }
-    }
-    
-    if (offsets != null) {
-      for (int i = 0; i < numProx; i++) {
-        tvf.writeVInt(offsets.readVInt());
-        tvf.writeVInt(offsets.readVInt());
-      }
-    }
-  }
-
-  @Override
   public void addPosition(int position, int startOffset, int endOffset) throws IOException {
     if (positions && offsets) {
       // write position delta
