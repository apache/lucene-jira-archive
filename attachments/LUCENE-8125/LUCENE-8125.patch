diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/BreakIteratorWrapper.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/BreakIteratorWrapper.java
index d8ecb77..9e5050d 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/BreakIteratorWrapper.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/BreakIteratorWrapper.java
@@ -16,152 +16,84 @@
  */
 package org.apache.lucene.analysis.icu.segmentation;
 
-
-import java.text.CharacterIterator;
-
 import com.ibm.icu.lang.UCharacter;
+import com.ibm.icu.lang.UProperty;
 import com.ibm.icu.text.BreakIterator;
 import com.ibm.icu.text.RuleBasedBreakIterator;
 import com.ibm.icu.text.UTF16;
+import com.ibm.icu.text.UnicodeSet;
 
 /**
- * Contain all the issues surrounding BreakIterators in ICU in one place.
- * Basically this boils down to the fact that they aren't very friendly to any
- * sort of OO design.
- * <p>
- * http://bugs.icu-project.org/trac/ticket/5901: RBBI.getRuleStatus(), hoist to
- * BreakIterator from RuleBasedBreakIterator
- * <p>
- * DictionaryBasedBreakIterator is a subclass of RuleBasedBreakIterator, but
- * doesn't actually behave as a subclass: it always returns 0 for
- * getRuleStatus(): 
- * http://bugs.icu-project.org/trac/ticket/4730: Thai RBBI, no boundary type
- * tags
+ * Wraps RuleBasedBreakIterator, making object reuse convenient and 
+ * emitting a rule status for emoji sequences.
  * @lucene.experimental
  */
-abstract class BreakIteratorWrapper {
-  protected final CharArrayIterator textIterator = new CharArrayIterator();
-  protected char text[];
-  protected int start;
-  protected int length;
-
-  abstract int next();
-  abstract int current();
-  abstract int getRuleStatus();
-  abstract void setText(CharacterIterator text);
-
-  void setText(char text[], int start, int length) {
-    this.text = text;
-    this.start = start;
-    this.length = length;
-    textIterator.setText(text, start, length);
-    setText(textIterator);
+final class BreakIteratorWrapper {
+  private final CharArrayIterator textIterator = new CharArrayIterator();
+  private final RuleBasedBreakIterator rbbi;
+  private char text[];
+  private int start;
+  private int status;
+  
+  BreakIteratorWrapper(RuleBasedBreakIterator rbbi) {
+    this.rbbi = rbbi;
   }
-
-  /**
-   * If it's a RuleBasedBreakIterator, the rule status can be used for token type. If it's
-   * any other BreakIterator, the rulestatus method is not available, so treat
-   * it like a generic BreakIterator.
-   */
-  static BreakIteratorWrapper wrap(BreakIterator breakIterator) {
-    if (breakIterator instanceof RuleBasedBreakIterator)
-      return new RBBIWrapper((RuleBasedBreakIterator) breakIterator);
-    else
-      return new BIWrapper(breakIterator);
+  
+  int current() {
+    return rbbi.current();
   }
 
-  /**
-   * RuleBasedBreakIterator wrapper: RuleBasedBreakIterator (as long as it's not
-   * a DictionaryBasedBreakIterator) behaves correctly.
-   */
-  static final class RBBIWrapper extends BreakIteratorWrapper {
-    private final RuleBasedBreakIterator rbbi;
-
-    RBBIWrapper(RuleBasedBreakIterator rbbi) {
-      this.rbbi = rbbi;
-    }
-
-    @Override
-    int current() {
-      return rbbi.current();
-    }
+  int getRuleStatus() {
+    return status;
+  }
 
-    @Override
-    int getRuleStatus() {
+  int next() {
+    int current = rbbi.current();
+    int next = rbbi.next();
+    status = calcStatus(current, next);
+    return next;
+  }
+  
+  /** Returns current rule status for the text between breaks. (determines token type) */
+  private int calcStatus(int current, int next) {
+    // to support presentation selectors, we need to handle alphanum, num, and none at least, so currently not worth optimizing.
+    // https://unicode.org/cldr/utility/list-unicodeset.jsp?a=%5B%3AEmoji%3A%5D-%5B%3AEmoji_Presentation%3A%5D&g=Word_Break&i=
+    if (next != BreakIterator.DONE && isEmoji(current, next)) {
+      return ICUTokenizerConfig.EMOJI_SEQUENCE_STATUS;
+    } else {
       return rbbi.getRuleStatus();
     }
-
-    @Override
-    int next() {
-      return rbbi.next();
-    }
-
-    @Override
-    void setText(CharacterIterator text) {
-      rbbi.setText(text);
-    }
   }
-
-  /**
-   * Generic BreakIterator wrapper: Either the rulestatus method is not
-   * available or always returns 0. Calculate a rulestatus here so it behaves
-   * like RuleBasedBreakIterator.
-   * 
-   * Note: This is slower than RuleBasedBreakIterator.
-   */
-  static final class BIWrapper extends BreakIteratorWrapper {
-    private final BreakIterator bi;
-    private int status;
-
-    BIWrapper(BreakIterator bi) {
-      this.bi = bi;
-    }
-
-    @Override
-    int current() {
-      return bi.current();
-    }
-
-    @Override
-    int getRuleStatus() {
-      return status;
-    }
-
-    @Override
-    int next() {
-      int current = bi.current();
-      int next = bi.next();
-      status = calcStatus(current, next);
-      return next;
-    }
-
-    private int calcStatus(int current, int next) {
-      if (current == BreakIterator.DONE || next == BreakIterator.DONE)
-        return RuleBasedBreakIterator.WORD_NONE;
-
-      int begin = start + current;
-      int end = start + next;
-
-      int codepoint;
-      for (int i = begin; i < end; i += UTF16.getCharCount(codepoint)) {
-        codepoint = UTF16.charAt(text, 0, end, begin);
-
-        if (UCharacter.isDigit(codepoint))
-          return RuleBasedBreakIterator.WORD_NUMBER;
-        else if (UCharacter.isLetter(codepoint)) {
-          // TODO: try to separately specify ideographic, kana? 
-          // [currently all bundled as letter for this case]
-          return RuleBasedBreakIterator.WORD_LETTER;
-        }
+  
+  // See unicode doc L2/16-315 and also the RBBI rules for rationale.
+  // we don't include regional indicators here, because they aren't ambiguous for tagging,
+  // they need only be treated special for segmentation.
+  static final UnicodeSet EMOJI_RK = new UnicodeSet("[\u002a\u00230-9Â©Â®â„¢ã€°ã€½]").freeze();
+
+  /** Returns true if the current text represents emoji character or sequence */
+  private boolean isEmoji(int current, int next) {
+    int begin = start + current;
+    int end = start + next;
+    int codepoint = UTF16.charAt(text, 0, end, begin);
+    // TODO: this can be made more aggressive and future-proof if it uses [:Extended_Pictographic:]
+    if (UCharacter.hasBinaryProperty(codepoint, UProperty.EMOJI)) {
+      if (EMOJI_RK.contains(codepoint)) {
+        // if its in EmojiRK, we don't treat it as emoji unless there is evidence it forms emoji sequence,
+        // an emoji presentation selector or keycap follows.
+        int trailer = begin + Character.charCount(codepoint);
+        return trailer < end && (text[trailer] == 0xFE0F || text[trailer] == 0x20E3);
+      } else {
+        return true;
       }
-
-      return RuleBasedBreakIterator.WORD_NONE;
     }
+    return false;
+  }
 
-    @Override
-    void setText(CharacterIterator text) {
-      bi.setText(text);
-      status = RuleBasedBreakIterator.WORD_NONE;
-    }
+  void setText(char text[], int start, int length) {
+    this.text = text;
+    this.start = start;
+    textIterator.setText(text, start, length);
+    rbbi.setText(textIterator);
+    status = RuleBasedBreakIterator.WORD_NONE;
   }
 }
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/CompositeBreakIterator.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/CompositeBreakIterator.java
index 096eada..3cb39ed 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/CompositeBreakIterator.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/CompositeBreakIterator.java
@@ -123,7 +123,7 @@ final class CompositeBreakIterator {
   
   private BreakIteratorWrapper getBreakIterator(int scriptCode) {
     if (wordBreakers[scriptCode] == null)
-      wordBreakers[scriptCode] = BreakIteratorWrapper.wrap(config.getBreakIterator(scriptCode));
+      wordBreakers[scriptCode] = new BreakIteratorWrapper(config.getBreakIterator(scriptCode));
     return wordBreakers[scriptCode];
   }
 }
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/DefaultICUTokenizerConfig.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/DefaultICUTokenizerConfig.java
index 50a6b4c..10e6c67 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/DefaultICUTokenizerConfig.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/DefaultICUTokenizerConfig.java
@@ -52,6 +52,8 @@ public class DefaultICUTokenizerConfig extends ICUTokenizerConfig {
   public static final String WORD_LETTER = StandardTokenizer.TOKEN_TYPES[StandardTokenizer.ALPHANUM];
   /** Token type for words that appear to be numbers */
   public static final String WORD_NUMBER = StandardTokenizer.TOKEN_TYPES[StandardTokenizer.NUM];
+  /** Token type for words that appear to be emoji sequences */
+  public static final String WORD_EMOJI = StandardTokenizer.TOKEN_TYPES[StandardTokenizer.EMOJI];
   
   /*
    * the default breakiterators in use. these can be expensive to
@@ -65,9 +67,9 @@ public class DefaultICUTokenizerConfig extends ICUTokenizerConfig {
   // maybe add an explicit check? http://icu-project.org/apiref/icu4j/com/ibm/icu/util/VersionInfo.html
 
   // the same as ROOT, except no dictionary segmentation for cjk
-  private static final BreakIterator defaultBreakIterator = 
+  private static final RuleBasedBreakIterator defaultBreakIterator = 
     readBreakIterator("Default.brk");
-  private static final BreakIterator myanmarSyllableIterator = 
+  private static final RuleBasedBreakIterator myanmarSyllableIterator = 
     readBreakIterator("MyanmarSyllable.brk");
   
   // TODO: deprecate this boolean? you only care if you are doing super-expert stuff...
@@ -95,16 +97,16 @@ public class DefaultICUTokenizerConfig extends ICUTokenizerConfig {
   }
 
   @Override
-  public BreakIterator getBreakIterator(int script) {
+  public RuleBasedBreakIterator getBreakIterator(int script) {
     switch(script) {
-      case UScript.JAPANESE: return (BreakIterator)cjkBreakIterator.clone();
+      case UScript.JAPANESE: return (RuleBasedBreakIterator)cjkBreakIterator.clone();
       case UScript.MYANMAR: 
         if (myanmarAsWords) {
-          return (BreakIterator)defaultBreakIterator.clone();
+          return (RuleBasedBreakIterator)defaultBreakIterator.clone();
         } else {
-          return (BreakIterator)myanmarSyllableIterator.clone();
+          return (RuleBasedBreakIterator)myanmarSyllableIterator.clone();
         }
-      default: return (BreakIterator)defaultBreakIterator.clone();
+      default: return (RuleBasedBreakIterator)defaultBreakIterator.clone();
     }
   }
 
@@ -119,6 +121,8 @@ public class DefaultICUTokenizerConfig extends ICUTokenizerConfig {
         return script == UScript.HANGUL ? WORD_HANGUL : WORD_LETTER;
       case RuleBasedBreakIterator.WORD_NUMBER:
         return WORD_NUMBER;
+      case EMOJI_SEQUENCE_STATUS:
+        return WORD_EMOJI;
       default: /* some other custom code */
         return "<OTHER>";
     }
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerConfig.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerConfig.java
index 69694fc..e2d3dae 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerConfig.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerConfig.java
@@ -16,8 +16,7 @@
  */
 package org.apache.lucene.analysis.icu.segmentation;
 
-
-import com.ibm.icu.text.BreakIterator;
+import com.ibm.icu.text.RuleBasedBreakIterator;
 
 /**
  * Class that allows for tailored Unicode Text Segmentation on
@@ -25,14 +24,16 @@ import com.ibm.icu.text.BreakIterator;
  * @lucene.experimental
  */
 public abstract class ICUTokenizerConfig {
-  
+  /** Rule status for emoji sequences */
+  public static final int EMOJI_SEQUENCE_STATUS = 299;
+
   /**
    * Sole constructor. (For invocation by subclass 
    * constructors, typically implicit.)
    */
   public ICUTokenizerConfig() {}
   /** Return a breakiterator capable of processing a given script. */
-  public abstract BreakIterator getBreakIterator(int script);
+  public abstract RuleBasedBreakIterator getBreakIterator(int script);
   /** Return a token type value for a given script and BreakIterator
    *  rule status. */
   public abstract String getType(int script, int ruleStatus);
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
index 4d29b0c..0cd4cf2 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizerFactory.java
@@ -116,9 +116,9 @@ public class ICUTokenizerFactory extends TokenizerFactory implements ResourceLoa
       config = new DefaultICUTokenizerConfig(cjkAsWords, myanmarAsWords) {
         
         @Override
-        public BreakIterator getBreakIterator(int script) {
+        public RuleBasedBreakIterator getBreakIterator(int script) {
           if (breakers[script] != null) {
-            return (BreakIterator) breakers[script].clone();
+            return (RuleBasedBreakIterator) breakers[script].clone();
           } else {
             return super.getBreakIterator(script);
           }
diff --git a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java
index 027baa3..9893975 100644
--- a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java
+++ b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer.java
@@ -16,13 +16,10 @@
  */
 package org.apache.lucene.analysis.icu.segmentation;
 
-
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.icu.ICUNormalizer2Filter;
 import org.apache.lucene.analysis.icu.tokenattributes.ScriptAttribute;
 
 import com.ibm.icu.lang.UScript;
@@ -76,8 +73,7 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
       @Override
       protected TokenStreamComponents createComponents(String fieldName) {
         Tokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false, true));
-        TokenFilter filter = new ICUNormalizer2Filter(tokenizer);
-        return new TokenStreamComponents(tokenizer, filter);
+        return new TokenStreamComponents(tokenizer);
       }
     };
   }
@@ -90,8 +86,8 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
 
   public void testArmenian() throws Exception {
     assertAnalyzesTo(a, "ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ« 13 Õ´Õ«Õ¬Õ«Õ¸Õ¶ Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨ (4,600` Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶ Õ¾Õ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ¸Ö‚Õ´) Õ£Ö€Õ¾Õ¥Õ¬ Õ¥Õ¶ Õ¯Õ¡Õ´Õ¡Õ¾Õ¸Ö€Õ¶Õ¥Ö€Õ« Õ¯Õ¸Õ²Õ´Õ«Ö Õ¸Ö‚ Õ°Õ¡Õ´Õ¡Ö€ÕµÕ¡ Õ¢Õ¸Õ¬Õ¸Ö€ Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨ Õ¯Õ¡Ö€Õ¸Õ² Õ§ Õ­Õ´Õ¢Õ¡Õ£Ö€Õ¥Õ¬ ÖÕ¡Õ¶Õ¯Õ¡Ö Õ´Õ¡Ö€Õ¤ Õ¸Õ¾ Õ¯Õ¡Ö€Õ¸Õ² Õ§ Õ¢Õ¡ÖÕ¥Õ¬ ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ« Õ¯Õ¡ÕµÖ„Õ¨Ö‰",
-        new String[] { "Õ¾Õ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ«", "13", "Õ´Õ«Õ¬Õ«Õ¸Õ¶", "Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨", "4,600", "Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶", "Õ¾Õ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ¸Ö‚Õ´", "Õ£Ö€Õ¾Õ¥Õ¬", "Õ¥Õ¶", "Õ¯Õ¡Õ´Õ¡Õ¾Õ¸Ö€Õ¶Õ¥Ö€Õ«", "Õ¯Õ¸Õ²Õ´Õ«Ö", 
-        "Õ¸Ö‚", "Õ°Õ¡Õ´Õ¡Ö€ÕµÕ¡", "Õ¢Õ¸Õ¬Õ¸Ö€", "Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨", "Õ¯Õ¡Ö€Õ¸Õ²", "Õ§", "Õ­Õ´Õ¢Õ¡Õ£Ö€Õ¥Õ¬", "ÖÕ¡Õ¶Õ¯Õ¡Ö", "Õ´Õ¡Ö€Õ¤", "Õ¸Õ¾", "Õ¯Õ¡Ö€Õ¸Õ²", "Õ§", "Õ¢Õ¡ÖÕ¥Õ¬", "Õ¾Õ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ«", "Õ¯Õ¡ÕµÖ„Õ¨" } );
+        new String[] { "ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ«", "13", "Õ´Õ«Õ¬Õ«Õ¸Õ¶", "Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨", "4,600", "Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶", "Õ¾Õ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ¸Ö‚Õ´", "Õ£Ö€Õ¾Õ¥Õ¬", "Õ¥Õ¶", "Õ¯Õ¡Õ´Õ¡Õ¾Õ¸Ö€Õ¶Õ¥Ö€Õ«", "Õ¯Õ¸Õ²Õ´Õ«Ö", 
+        "Õ¸Ö‚", "Õ°Õ¡Õ´Õ¡Ö€ÕµÕ¡", "Õ¢Õ¸Õ¬Õ¸Ö€", "Õ°Õ¸Õ¤Õ¾Õ¡Õ®Õ¶Õ¥Ö€Õ¨", "Õ¯Õ¡Ö€Õ¸Õ²", "Õ§", "Õ­Õ´Õ¢Õ¡Õ£Ö€Õ¥Õ¬", "ÖÕ¡Õ¶Õ¯Õ¡Ö", "Õ´Õ¡Ö€Õ¤", "Õ¸Õ¾", "Õ¯Õ¡Ö€Õ¸Õ²", "Õ§", "Õ¢Õ¡ÖÕ¥Õ¬", "ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ÕµÕ«", "Õ¯Õ¡ÕµÖ„Õ¨" } );
   }
   
   public void testAmharic() throws Exception {
@@ -102,12 +98,12 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
   public void testArabic() throws Exception {
     assertAnalyzesTo(a, "Ø§Ù„ÙÙŠÙ„Ù… Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ÙŠ Ø§Ù„Ø£ÙˆÙ„ Ø¹Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ ÙŠØ³Ù…Ù‰ \"Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù…: Ù‚ØµØ© ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§\" (Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©: Truth in Numbers: The Wikipedia Story)ØŒ Ø³ÙŠØªÙ… Ø¥Ø·Ù„Ø§Ù‚Ù‡ ÙÙŠ 2008.",
         new String[] { "Ø§Ù„ÙÙŠÙ„Ù…", "Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ÙŠ", "Ø§Ù„Ø£ÙˆÙ„", "Ø¹Ù†", "ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§", "ÙŠØ³Ù…Ù‰", "Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©", "Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù…", "Ù‚ØµØ©", "ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§",
-        "Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", "truth", "in", "numbers", "the", "wikipedia", "story", "Ø³ÙŠØªÙ…", "Ø¥Ø·Ù„Ø§Ù‚Ù‡", "ÙÙŠ", "2008" } ); 
+        "Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "Ø³ÙŠØªÙ…", "Ø¥Ø·Ù„Ø§Ù‚Ù‡", "ÙÙŠ", "2008" } ); 
   }
   
   public void testAramaic() throws Exception {
     assertAnalyzesTo(a, "Ü˜ÜÜ©ÜÜ¦Ü•ÜÜ (ÜÜ¢Ü“Ü ÜÜ: Wikipedia) Ü—Ü˜ ÜÜÜ¢Ü£Ü©Ü Ü˜Ü¦Ü•ÜÜ ÜšÜÜªÜ¬Ü Ü•ÜÜ¢Ü›ÜªÜ¢Ü› Ü’Ü Ü«Ü¢ÌˆÜ Ü£Ü“ÜÜÌˆÜÜ‚ Ü«Ü¡Ü— ÜÜ¬Ü Ü¡Ü¢ Ü¡ÌˆÜ Ü¬Ü Ü•\"Ü˜ÜÜ©Ü\" Ü˜\"ÜÜÜ¢Ü£Ü©Ü Ü˜Ü¦Ü•ÜÜ\"Ü€",
-        new String[] { "Ü˜ÜÜ©ÜÜ¦Ü•ÜÜ", "ÜÜ¢Ü“Ü ÜÜ", "wikipedia", "Ü—Ü˜", "ÜÜÜ¢Ü£Ü©Ü Ü˜Ü¦Ü•ÜÜ", "ÜšÜÜªÜ¬Ü", "Ü•ÜÜ¢Ü›ÜªÜ¢Ü›", "Ü’Ü Ü«Ü¢ÌˆÜ", "Ü£Ü“ÜÜÌˆÜ", "Ü«Ü¡Ü—",
+        new String[] { "Ü˜ÜÜ©ÜÜ¦Ü•ÜÜ", "ÜÜ¢Ü“Ü ÜÜ", "Wikipedia", "Ü—Ü˜", "ÜÜÜ¢Ü£Ü©Ü Ü˜Ü¦Ü•ÜÜ", "ÜšÜÜªÜ¬Ü", "Ü•ÜÜ¢Ü›ÜªÜ¢Ü›", "Ü’Ü Ü«Ü¢ÌˆÜ", "Ü£Ü“ÜÜÌˆÜ", "Ü«Ü¡Ü—",
         "ÜÜ¬Ü", "Ü¡Ü¢", "Ü¡ÌˆÜ Ü¬Ü", "Ü•", "Ü˜ÜÜ©Ü", "Ü˜", "ÜÜÜ¢Ü£Ü©Ü Ü˜Ü¦Ü•ÜÜ"});
   }
   
@@ -125,7 +121,7 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
   
   public void testGreek() throws Exception {
     assertAnalyzesTo(a, "Î“ÏÎ¬Ï†ÎµÏ„Î±Î¹ ÏƒÎµ ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î± Î±Ï€ÏŒ ÎµÎ¸ÎµÎ»Î¿Î½Ï„Î­Ï‚ Î¼Îµ Ï„Î¿ Î»Î¿Î³Î¹ÏƒÎ¼Î¹ÎºÏŒ wiki, ÎºÎ¬Ï„Î¹ Ï€Î¿Ï… ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Î¬ÏÎ¸ÏÎ± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€ÏÎ¿ÏƒÏ„ÎµÎ¸Î¿ÏÎ½ Î® Î½Î± Î±Î»Î»Î¬Î¾Î¿Ï…Î½ Î±Ï€ÏŒ Ï„Î¿Î½ ÎºÎ±Î¸Î­Î½Î±.",
-        new String[] { "Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹", "ÏƒÎµ", "ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î±", "Î±Ï€ÏŒ", "ÎµÎ¸ÎµÎ»Î¿Î½Ï„Î­Ïƒ", "Î¼Îµ", "Ï„Î¿", "Î»Î¿Î³Î¹ÏƒÎ¼Î¹ÎºÏŒ", "wiki", "ÎºÎ¬Ï„Î¹", "Ï€Î¿Ï…",
+        new String[] { "Î“ÏÎ¬Ï†ÎµÏ„Î±Î¹", "ÏƒÎµ", "ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î±", "Î±Ï€ÏŒ", "ÎµÎ¸ÎµÎ»Î¿Î½Ï„Î­Ï‚", "Î¼Îµ", "Ï„Î¿", "Î»Î¿Î³Î¹ÏƒÎ¼Î¹ÎºÏŒ", "wiki", "ÎºÎ¬Ï„Î¹", "Ï€Î¿Ï…",
         "ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹", "ÏŒÏ„Î¹", "Î¬ÏÎ¸ÏÎ±", "Î¼Ï€Î¿ÏÎµÎ¯", "Î½Î±", "Ï€ÏÎ¿ÏƒÏ„ÎµÎ¸Î¿ÏÎ½", "Î®", "Î½Î±", "Î±Î»Î»Î¬Î¾Î¿Ï…Î½", "Î±Ï€ÏŒ", "Ï„Î¿Î½", "ÎºÎ±Î¸Î­Î½Î±" });
   }
   
@@ -156,7 +152,7 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
    */
   public void testChinese() throws Exception {
     assertAnalyzesTo(a, "æˆ‘æ˜¯ä¸­å›½äººã€‚ ï¼‘ï¼’ï¼“ï¼” ï¼´ï½…ï½“ï½”ï½“ ",
-        new String[] { "æˆ‘", "æ˜¯", "ä¸­", "å›½", "äºº", "1234", "tests"});
+        new String[] { "æˆ‘", "æ˜¯", "ä¸­", "å›½", "äºº", "ï¼‘ï¼’ï¼“ï¼”", "ï¼´ï½…ï½“ï½”ï½“"});
   }
   
   public void testHebrew() throws Exception {
@@ -186,8 +182,8 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
   /* Tests from StandardAnalyzer, just to show behavior is similar */
   public void testAlphanumericSA() throws Exception {
     // alphanumeric tokens
-    assertAnalyzesTo(a, "B2B", new String[]{"b2b"});
-    assertAnalyzesTo(a, "2B", new String[]{"2b"});
+    assertAnalyzesTo(a, "B2B", new String[]{"B2B"});
+    assertAnalyzesTo(a, "2B", new String[]{"2B"});
   }
 
   public void testDelimitersSA() throws Exception {
@@ -199,34 +195,34 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
 
   public void testApostrophesSA() throws Exception {
     // internal apostrophes: O'Reilly, you're, O'Reilly's
-    assertAnalyzesTo(a, "O'Reilly", new String[]{"o'reilly"});
+    assertAnalyzesTo(a, "O'Reilly", new String[]{"O'Reilly"});
     assertAnalyzesTo(a, "you're", new String[]{"you're"});
     assertAnalyzesTo(a, "she's", new String[]{"she's"});
-    assertAnalyzesTo(a, "Jim's", new String[]{"jim's"});
+    assertAnalyzesTo(a, "Jim's", new String[]{"Jim's"});
     assertAnalyzesTo(a, "don't", new String[]{"don't"});
-    assertAnalyzesTo(a, "O'Reilly's", new String[]{"o'reilly's"});
+    assertAnalyzesTo(a, "O'Reilly's", new String[]{"O'Reilly's"});
   }
 
   public void testNumericSA() throws Exception {
     // floating point, serial, model numbers, ip addresses, etc.
     // every other segment must have at least one digit
     assertAnalyzesTo(a, "21.35", new String[]{"21.35"});
-    assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"r2d2", "c3po"});
+    assertAnalyzesTo(a, "R2D2 C3PO", new String[]{"R2D2", "C3PO"});
     assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
     assertAnalyzesTo(a, "216.239.63.104", new String[]{"216.239.63.104"});
   }
 
   public void testTextWithNumbersSA() throws Exception {
     // numbers
-    assertAnalyzesTo(a, "David has 5000 bones", new String[]{"david", "has", "5000", "bones"});
+    assertAnalyzesTo(a, "David has 5000 bones", new String[]{"David", "has", "5000", "bones"});
   }
 
   public void testVariousTextSA() throws Exception {
     // various
-    assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"c", "embedded", "developers", "wanted"});
-    assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "foo", "bar"});
-    assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "foo", "bar"});
-    assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"quoted", "word"});
+    assertAnalyzesTo(a, "C embedded developers wanted", new String[]{"C", "embedded", "developers", "wanted"});
+    assertAnalyzesTo(a, "foo bar FOO BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    assertAnalyzesTo(a, "foo      bar .  FOO <> BAR", new String[]{"foo", "bar", "FOO", "BAR"});
+    assertAnalyzesTo(a, "\"QUOTED\" word", new String[]{"QUOTED", "word"});
   }
 
   public void testKoreanSA() throws Exception {
@@ -242,14 +238,14 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
   
   public void testOffsets() throws Exception {
     assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"david", "has", "5000", "bones"},
+        new String[] {"David", "has", "5000", "bones"},
         new int[] {0, 6, 10, 15},
         new int[] {5, 9, 14, 20});
   }
   
   public void testTypes() throws Exception {
     assertAnalyzesTo(a, "David has 5000 bones", 
-        new String[] {"david", "has", "5000", "bones"},
+        new String[] {"David", "has", "5000", "bones"},
         new String[] { "<ALPHANUM>", "<ALPHANUM>", "<NUM>", "<ALPHANUM>" });
   }
   
@@ -265,6 +261,61 @@ public class TestICUTokenizer extends BaseTokenStreamTestCase {
         new String[] { "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<HIRAGANA>", "<KATAKANA>" });
   }
   
+  /** simple emoji */
+  public void testEmoji() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ’© ğŸ’©ğŸ’©",
+        new String[] { "ğŸ’©", "ğŸ’©", "ğŸ’©" },
+        new String[] { "<EMOJI>", "<EMOJI>", "<EMOJI>" });
+  }
+ 
+  /** emoji zwj sequence */
+  public void testEmojiSequence() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ‘©â€â¤ï¸â€ğŸ‘©",
+        new String[] { "ğŸ‘©â€â¤ï¸â€ğŸ‘©" },
+        new String[] { "<EMOJI>" });
+  }
+  
+  /** emoji zwj sequence with fitzpatrick modifier */
+  public void testEmojiSequenceWithModifier() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ‘¨ğŸ¼â€âš•ï¸",
+        new String[] { "ğŸ‘¨ğŸ¼â€âš•ï¸" },
+        new String[] { "<EMOJI>" });
+  }
+  
+  /** regional indicator */
+  public void testEmojiRegionalIndicator() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ‡ºğŸ‡¸ğŸ‡ºğŸ‡¸",
+        new String[] { "ğŸ‡ºğŸ‡¸", "ğŸ‡ºğŸ‡¸" },
+        new String[] { "<EMOJI>", "<EMOJI>" });
+  }
+  
+  /** variation sequence */
+  public void testEmojiVariationSequence() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "#ï¸âƒ£",
+        new String[] { "#ï¸âƒ£" },
+        new String[] { "<EMOJI>" });
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "3ï¸âƒ£",
+        new String[] { "3ï¸âƒ£",},
+        new String[] { "<EMOJI>" });
+  }
+
+  public void testEmojiTagSequence() throws Exception {
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿",
+        new String[] { "ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿" },
+        new String[] { "<EMOJI>" });
+  }
+  
+  public void testEmojiTokenization() throws Exception {
+    // simple emoji around latin
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "pooğŸ’©poo",
+        new String[] { "poo", "ğŸ’©", "poo" },
+        new String[] { "<ALPHANUM>", "<EMOJI>", "<ALPHANUM>" });
+    // simple emoji around non-latin
+    BaseTokenStreamTestCase.assertAnalyzesTo(a, "ğŸ’©ä¸­åœ‹ğŸ’©",
+        new String[] { "ğŸ’©", "ä¸­", "åœ‹", "ğŸ’©" },
+        new String[] { "<EMOJI>", "<IDEOGRAPHIC>", "<IDEOGRAPHIC>", "<EMOJI>" });
+  }
+  
   /** blast some random strings through the analyzer */
   public void testRandomStrings() throws Exception {
     checkRandomData(random(), a, 1000*RANDOM_MULTIPLIER);
diff --git a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizerCJK.java b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizerCJK.java
index 75481f1..d93a810 100644
--- a/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizerCJK.java
+++ b/lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizerCJK.java
@@ -78,6 +78,15 @@ public class TestICUTokenizerCJK extends BaseTokenStreamTestCase {
     );
   }
   
+  /**
+   * dictionary segmentation with emoji
+   */
+  public void testSimpleJapaneseWithEmoji() throws Exception {
+    assertAnalyzesTo(a, "ãã‚Œã¯ã¾ã å®Ÿé¨“æ®µéšã«ã‚ã‚Šã¾ã™ğŸ’©",
+        new String[] { "ãã‚Œ", "ã¯", "ã¾ã ", "å®Ÿé¨“", "æ®µéš", "ã«", "ã‚ã‚Š", "ã¾ã™", "ğŸ’©"  }
+    );
+  }
+  
   public void testJapaneseTypes() throws Exception {
     assertAnalyzesTo(a, "ä»®åé£ã„ ã‚«ã‚¿ã‚«ãƒŠ",
         new String[] { "ä»®åé£ã„", "ã‚«ã‚¿ã‚«ãƒŠ" },
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index 0410124..50d1f9f 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -54,6 +54,8 @@ public final class StandardTokenizer extends Tokenizer {
   public static final int KATAKANA = 5;
   /** Hangul token type */
   public static final int HANGUL = 6;
+  /** Emoji token type. */
+  public static final int EMOJI = 7;
   
   /** String token types that correspond to token type int constants */
   public static final String [] TOKEN_TYPES = new String [] {
@@ -63,7 +65,8 @@ public final class StandardTokenizer extends Tokenizer {
     "<IDEOGRAPHIC>",
     "<HIRAGANA>",
     "<KATAKANA>",
-    "<HANGUL>"
+    "<HANGUL>",
+    "<EMOJI>"
   };
   
   /** Absolute maximum sized token */
