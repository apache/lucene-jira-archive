Index: modules/analysis/CHANGES.txt
===================================================================
--- modules/analysis/CHANGES.txt	(revision 1141671)
+++ modules/analysis/CHANGES.txt	(revision )
@@ -31,7 +31,9 @@
  * LUCENE-2514, LUCENE-2551: JDK and ICU CollationKeyAnalyzers were changed to
    use pure byte keys when Version >= 4.0. This cuts sort key size approximately
    in half. (Robert Muir)
-   
+
+ * LUCENE-3400: Removed DutchAnalyzer.setStemDictionary (Chris Male)
+   
 New Features
 
  * LUCENE-2341: A new analyzer/ filter: Morfologik - a dictionary-driven lemmatizer 
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java	(revision 1096178)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java	(revision )
@@ -150,18 +150,6 @@
 
   }
   
-  /* 
-   * Test that changes to the dictionary stemming table are applied immediately
-   * when using reusable token streams.
-   */
-  public void testStemDictionaryReuse() throws Exception {
-    DutchAnalyzer a = new DutchAnalyzer(TEST_VERSION_CURRENT);
-    checkOneTermReuse(a, "lichamelijk", "licham");
-    File customDictFile = getDataFile("customStemDict.txt");
-    a.setStemDictionary(customDictFile);
-    checkOneTermReuse(a, "lichamelijk", "somethingentirelydifferent");
-  }
-  
   /**
    * Prior to 3.1, this analyzer had no lowercase filter.
    * stopwords were case sensitive. Preserve this for back compat.
Index: modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
===================================================================
--- modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(revision 1160117)
+++ modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java	(revision )
@@ -105,7 +105,7 @@
    */
   private Set<?> excltable = Collections.emptySet();
 
-  private Map<String, String> stemdict = new HashMap<String, String>();
+  private final Map<String, String> stemdict = new HashMap<String, String>();
   private final Version matchVersion;
 
   /**
@@ -130,24 +130,8 @@
     excltable = CharArraySet.unmodifiableSet(CharArraySet.copy(matchVersion, stemExclusionTable));
     this.matchVersion = matchVersion;
   }
-
+  
   /**
-   * Reads a stemdictionary file , that overrules the stemming algorithm
-   * This is a textfile that contains per line
-   * <tt>word<b>\t</b>stem</tt>, i.e: two tab seperated words
-   */
-  public void setStemDictionary(File stemdictFile) {
-    try {
-      stemdict = WordlistLoader.getStemDict(stemdictFile);
-      setPreviousTokenStream(null); // force a new stemmer to be created
-    } catch (IOException e) {
-      // TODO: throw IOException
-      throw new RuntimeException(e);
-    }
-  }
-
-
-  /**
    * Returns a (possibly reused) {@link TokenStream} which tokenizes all the 
    * text in the provided {@link Reader}.
    *
