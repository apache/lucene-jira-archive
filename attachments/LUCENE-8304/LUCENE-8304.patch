diff --git a/lucene/queries/src/java/org/apache/lucene/queries/TermFrequencyQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/TermFrequencyQuery.java
new file mode 100644
index 0000000000..572cf35c34
--- /dev/null
+++ b/lucene/queries/src/java/org/apache/lucene/queries/TermFrequencyQuery.java
@@ -0,0 +1,228 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.queries;
+
+import java.io.IOException;
+import java.util.Objects;
+import java.util.Set;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermStates;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.CollectionStatistics;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.LeafSimScorer;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreMode;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.TermStatistics;
+import org.apache.lucene.search.TwoPhaseIterator;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.similarities.Similarity;
+
+/**
+ * Matches documents where a term appears with a frequency in a given range
+ */
+public class TermFrequencyQuery extends Query {
+
+  private final Term term;
+  private final int minFreq;
+  private final int maxFreq;
+
+  /**
+   * Create a query that matches documents containing the given term at the given frequency
+   */
+  public TermFrequencyQuery(Term term, int freq) {
+    this(term, freq, freq);
+  }
+
+  /**
+   * Create a query that matches documents containing the given term with a frequency between
+   * {@code minFreq} and {@code maxFreq} inclusive.
+   */
+  public TermFrequencyQuery(Term term, int minFreq, int maxFreq) {
+    this.term = term;
+    this.minFreq = minFreq;
+    this.maxFreq = maxFreq;
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
+    TermStates termStates = TermStates.build(searcher.getTopReaderContext(), term, scoreMode.needsScores());
+    return new TermFrequencyWeight(this, termStates, searcher, scoreMode, boost);
+  }
+
+  @Override
+  public String toString(String field) {
+    return "TermFrequencyQuery(" + term + ", minFreq=" + minFreq + "maxFreq=" + maxFreq + ")";
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (sameClassAs(obj) == false) {
+      return false;
+    }
+    TermFrequencyQuery o = (TermFrequencyQuery) obj;
+    return Objects.equals(this.term, o.term) && this.maxFreq == o.maxFreq && this.minFreq == o.minFreq;
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(term, minFreq, maxFreq);
+  }
+
+  private class TermFrequencyWeight extends Weight {
+
+    final ScoreMode scoreMode;
+    final Similarity.SimScorer simScorer;
+    final Similarity similarity;
+
+    TermFrequencyWeight(Query query, TermStates termStates, IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
+      super(query);
+      this.scoreMode = scoreMode;
+      this.similarity = searcher.getSimilarity();
+      final CollectionStatistics collectionStats;
+      final TermStatistics termStats;
+      if (scoreMode.needsScores()) {
+        collectionStats = searcher.collectionStatistics(term.field());
+        termStats = searcher.termStatistics(term, termStates);
+      } else {
+        // we do not need the actual stats, use fake stats with docFreq=maxDoc=ttf=1
+        collectionStats = new CollectionStatistics(term.field(), 1, 1, 1, 1);
+        termStats = new TermStatistics(term.bytes(), 1, 1);
+      }
+
+      if (termStats == null) {
+        this.simScorer = null; // term doesn't exist in any segment, we won't use similarity at all
+      } else {
+        this.simScorer = similarity.scorer(boost, collectionStats, termStats);
+      }
+    }
+
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      terms.add(term);
+    }
+
+    @Override
+    public Explanation explain(LeafReaderContext context, int doc) throws IOException {
+      PostingsEnum pe = getPostings(context);
+      if (pe == null) {
+        return Explanation.noMatch("No matching term");
+      }
+      if (pe.advance(doc) != doc) {
+        return Explanation.noMatch("No matching term in document");
+      }
+      int freq = pe.freq();
+      if (freq < minFreq || freq > maxFreq) {
+        return Explanation.noMatch("Term frequency " + freq + " falls out of range [" + minFreq + ":" + maxFreq + "]");
+      }
+      LeafSimScorer leafSimScorer = new LeafSimScorer(simScorer, context.reader(), scoreMode.needsScores(), Float.MAX_VALUE);
+      Explanation freqExplanation = Explanation.match(freq, "freq, occurrences of term within document");
+      Explanation scoreExplanation = leafSimScorer.explain(doc, freqExplanation);
+      return Explanation.match(
+          scoreExplanation.getValue(),
+          "weight(" + getQuery() + " in " + doc + ") ["
+              + similarity.getClass().getSimpleName() + "], result of:",
+          scoreExplanation);
+    }
+
+    @Override
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      PostingsEnum pe = getPostings(context);
+      if (pe == null) {
+        return null;
+      }
+      LeafSimScorer leafSimScorer = new LeafSimScorer(simScorer, context.reader(), scoreMode.needsScores(), Float.MAX_VALUE);
+      return new TermFrequencyScorer(this, pe, leafSimScorer);
+    }
+
+    private PostingsEnum getPostings(LeafReaderContext context) throws IOException {
+      Terms terms = context.reader().terms(term.field());
+      if (terms == null) {
+        return null;
+      }
+      if (terms.hasFreqs() == false) {
+        throw new IllegalArgumentException("Field " + term.field() + " was indexed without freqs");
+      }
+      TermsEnum te = terms.iterator();
+      if (te.seekExact(term.bytes()) == false) {
+        return null;
+      }
+      return te.postings(null, PostingsEnum.FREQS);
+    }
+
+    @Override
+    public boolean isCacheable(LeafReaderContext ctx) {
+      return true;
+    }
+
+  }
+
+  private class TermFrequencyScorer extends Scorer {
+
+    final PostingsEnum pe;
+    final LeafSimScorer docScorer;
+
+    TermFrequencyScorer(Weight weight, PostingsEnum pe, LeafSimScorer docScorer) {
+      super(weight);
+      this.pe = pe;
+      this.docScorer = docScorer;
+    }
+
+    @Override
+    public int docID() {
+      return pe.docID();
+    }
+
+    @Override
+    public float score() throws IOException {
+      return docScorer.score(docID(), pe.freq());
+    }
+
+    @Override
+    public DocIdSetIterator iterator() {
+      return TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator());
+    }
+
+    @Override
+    public TwoPhaseIterator twoPhaseIterator() {
+      return new TwoPhaseIterator(pe) {
+        @Override
+        public boolean matches() throws IOException {
+          return pe.freq() <= maxFreq && pe.freq() >= minFreq;
+        }
+
+        @Override
+        public float matchCost() {
+          return 1;
+        }
+      };
+    }
+
+    @Override
+    public float getMaxScore(int upTo) {
+      return Float.MAX_VALUE; // TODO
+    }
+  }
+}
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/TermFrequencyQueryTest.java b/lucene/queries/src/test/org/apache/lucene/queries/TermFrequencyQueryTest.java
new file mode 100644
index 0000000000..88d1e3dad8
--- /dev/null
+++ b/lucene/queries/src/test/org/apache/lucene/queries/TermFrequencyQueryTest.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.queries;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.QueryUtils;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TermFrequencyQueryTest extends LuceneTestCase {
+
+  public void testTermFrequencyQuery() throws IOException {
+
+    Directory dir = newDirectory();
+    MockAnalyzer analyzer = new MockAnalyzer(random());
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, analyzer);
+
+    StringBuilder contents = new StringBuilder();
+    for (int i = 1; i < 20; i++) {
+      Document doc = new Document();
+      contents.append(" term");
+      doc.add(newTextField("field", contents.toString(), Field.Store.NO));
+      doc.add(newStringField("id", "" + i, Field.Store.YES));
+      writer.addDocument(doc);
+    }
+
+    IndexReader reader = writer.getReader();
+    writer.close();
+
+    IndexSearcher searcher = new IndexSearcher(reader);
+
+    TermFrequencyQuery q = new TermFrequencyQuery(new Term("field", "term"), 3, 11);
+    TopDocs t = searcher.search(q, 10);
+    assertEquals(9, t.totalHits);
+    assertEquals("11", reader.document(t.scoreDocs[0].doc).get("id"));
+
+    QueryUtils.check(random(), q, searcher);
+
+    reader.close();
+    dir.close();
+  }
+
+  public void testEquals() throws IOException {
+    QueryUtils.checkEqual(new TermFrequencyQuery(new Term("field", "term"), 5),
+                          new TermFrequencyQuery(new Term("field", "term"), 5, 5));
+    QueryUtils.checkUnequal(new TermFrequencyQuery(new Term("field", "term"), 1),
+                            new TermFrequencyQuery(new Term("field", "yerm"), 1));
+  }
+
+}
