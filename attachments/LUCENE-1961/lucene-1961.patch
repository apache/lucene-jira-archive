Index: src/test/org/apache/lucene/queryParser/TestQueryParser.java
===================================================================
--- src/test/org/apache/lucene/queryParser/TestQueryParser.java	(revision 823012)
+++ src/test/org/apache/lucene/queryParser/TestQueryParser.java	(working copy)
@@ -467,7 +467,7 @@
                                      IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     doc.add(new Field("content","\u0633\u0627\u0628", 
-                      Field.Store.YES, Field.Index.UN_TOKENIZED));
+                      Field.Store.YES, Field.Index.NOT_ANALYZED));
     iw.addDocument(doc);
     iw.close();
     IndexSearcher is = new IndexSearcher(ramDir, true);
Index: src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
===================================================================
--- src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(revision 823012)
+++ src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(working copy)
@@ -660,9 +660,9 @@
     for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
       Document doc = new Document();
       doc.add(new Field("content", words[docnum], 
-                        Field.Store.YES, Field.Index.UN_TOKENIZED));
+                        Field.Store.YES, Field.Index.NOT_ANALYZED));
       doc.add(new Field("body", "body",
-                        Field.Store.YES, Field.Index.UN_TOKENIZED));
+                        Field.Store.YES, Field.Index.NOT_ANALYZED));
       writer.addDocument(doc);
     }
     writer.optimize();
Index: src/test/org/apache/lucene/search/spans/TestSpans.java
===================================================================
--- src/test/org/apache/lucene/search/spans/TestSpans.java	(revision 823012)
+++ src/test/org/apache/lucene/search/spans/TestSpans.java	(working copy)
@@ -421,8 +421,8 @@
   // LUCENE-1404
   private void addDoc(IndexWriter writer, String id, String text) throws IOException {
     final Document doc = new Document();
-    doc.add( new Field("id", id, Field.Store.YES, Field.Index.UN_TOKENIZED) );
-    doc.add( new Field("text", text, Field.Store.YES, Field.Index.TOKENIZED) );
+    doc.add( new Field("id", id, Field.Store.YES, Field.Index.NOT_ANALYZED) );
+    doc.add( new Field("text", text, Field.Store.YES, Field.Index.ANALYZED) );
     writer.addDocument(doc);
   }
 
Index: src/test/org/apache/lucene/search/TestTermRangeFilter.java
===================================================================
--- src/test/org/apache/lucene/search/TestTermRangeFilter.java	(revision 823012)
+++ src/test/org/apache/lucene/search/TestTermRangeFilter.java	(working copy)
@@ -343,9 +343,9 @@
                                              IndexWriter.MaxFieldLength.LIMITED);
         Document doc = new Document();
         doc.add(new Field("content","\u0633\u0627\u0628", 
-                          Field.Store.YES, Field.Index.UN_TOKENIZED));
+                          Field.Store.YES, Field.Index.NOT_ANALYZED));
         doc.add(new Field("body", "body",
-                          Field.Store.YES, Field.Index.UN_TOKENIZED));
+                          Field.Store.YES, Field.Index.NOT_ANALYZED));
         writer.addDocument(doc);
             
         writer.optimize();
@@ -387,9 +387,9 @@
         for (int docnum = 0 ; docnum < words.length ; ++docnum) {   
             Document doc = new Document();
             doc.add(new Field("content", words[docnum], 
-                              Field.Store.YES, Field.Index.UN_TOKENIZED));
+                              Field.Store.YES, Field.Index.NOT_ANALYZED));
             doc.add(new Field("body", "body",
-                              Field.Store.YES, Field.Index.UN_TOKENIZED));
+                              Field.Store.YES, Field.Index.NOT_ANALYZED));
             writer.addDocument(doc);
         }
         writer.optimize();
Index: src/test/org/apache/lucene/index/DocHelper.java
===================================================================
--- src/test/org/apache/lucene/index/DocHelper.java	(revision 823012)
+++ src/test/org/apache/lucene/index/DocHelper.java	(working copy)
@@ -169,7 +169,7 @@
       if (f.isStored()) add(stored,f);
       else add(unstored,f);
       if (f.getOmitNorms()) add(noNorms,f);
-      if (f.getOmitTf()) add(noTf,f);
+      if (f.getOmitTermFreqAndPositions()) add(noTf,f);
       if (f.isLazy()) add(lazy, f);
     }
   }
Index: src/test/org/apache/lucene/index/TestFieldsReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestFieldsReader.java	(revision 823012)
+++ src/test/org/apache/lucene/index/TestFieldsReader.java	(working copy)
@@ -72,7 +72,7 @@
     assertTrue(field.isStoreOffsetWithTermVector() == true);
     assertTrue(field.isStorePositionWithTermVector() == true);
     assertTrue(field.getOmitNorms() == false);
-    assertTrue(field.getOmitTf() == false);
+    assertTrue(field.getOmitTermFreqAndPositions() == false);
 
     field = doc.getField(DocHelper.TEXT_FIELD_3_KEY);
     assertTrue(field != null);
@@ -80,7 +80,7 @@
     assertTrue(field.isStoreOffsetWithTermVector() == false);
     assertTrue(field.isStorePositionWithTermVector() == false);
     assertTrue(field.getOmitNorms() == true);
-    assertTrue(field.getOmitTf() == false);
+    assertTrue(field.getOmitTermFreqAndPositions() == false);
 
     field = doc.getField(DocHelper.NO_TF_KEY);
     assertTrue(field != null);
@@ -88,7 +88,7 @@
     assertTrue(field.isStoreOffsetWithTermVector() == false);
     assertTrue(field.isStorePositionWithTermVector() == false);
     assertTrue(field.getOmitNorms() == false);
-    assertTrue(field.getOmitTf() == true);
+    assertTrue(field.getOmitTermFreqAndPositions() == true);
     reader.close();
   }
 
@@ -134,7 +134,7 @@
     assertTrue("field is null and it shouldn't be", field != null);
     assertTrue("stringValue isn't null for lazy binary field", field.stringValue() == null);
 
-    byte [] bytes = field.binaryValue();
+    byte [] bytes = field.getBinaryValue();
     assertTrue("bytes is null and it shouldn't be", bytes != null);
     assertTrue("", DocHelper.LAZY_FIELD_BINARY_BYTES.length == bytes.length);
     for (int i = 0; i < bytes.length; i++) {
@@ -286,9 +286,9 @@
     assertTrue(f1.isBinary());
     assertTrue(!f3.isBinary());
     assertTrue(fb.isBinary());
-    assertSizeEquals(2*DocHelper.FIELD_1_TEXT.length(), f1.binaryValue());
+    assertSizeEquals(2*DocHelper.FIELD_1_TEXT.length(), f1.getBinaryValue());
     assertEquals(DocHelper.FIELD_3_TEXT, f3.stringValue());
-    assertSizeEquals(DocHelper.LAZY_FIELD_BINARY_BYTES.length, fb.binaryValue());
+    assertSizeEquals(DocHelper.LAZY_FIELD_BINARY_BYTES.length, fb.getBinaryValue());
     
     reader.close();
   }
Index: src/java/org/apache/lucene/index/FieldInfos.java
===================================================================
--- src/java/org/apache/lucene/index/FieldInfos.java	(revision 823012)
+++ src/java/org/apache/lucene/index/FieldInfos.java	(working copy)
@@ -116,7 +116,7 @@
     while (fieldIterator.hasNext()) {
       Fieldable field = (Fieldable) fieldIterator.next();
       add(field.name(), field.isIndexed(), field.isTermVectorStored(), field.isStorePositionWithTermVector(),
-              field.isStoreOffsetWithTermVector(), field.getOmitNorms(), false, field.getOmitTf());
+              field.isStoreOffsetWithTermVector(), field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
     }
   }
 
Index: src/java/org/apache/lucene/index/FieldsReader.java
===================================================================
--- src/java/org/apache/lucene/index/FieldsReader.java	(revision 823012)
+++ src/java/org/apache/lucene/index/FieldsReader.java	(working copy)
@@ -425,16 +425,9 @@
       return localFieldsStream;
     }
 
-    /** The value of the field in Binary, or null.  If null, the Reader value,
-     * String value, or TokenStream value is used. Exactly one of stringValue(), 
-     * readerValue(), binaryValue(), and tokenStreamValue() must be set. */
-    public byte[] binaryValue() {
-      return getBinaryValue(null);
-    }
-
     /** The value of the field as a Reader, or null.  If null, the String value,
      * binary value, or TokenStream value is used.  Exactly one of stringValue(), 
-     * readerValue(), binaryValue(), and tokenStreamValue() must be set. */
+     * readerValue(), getBinaryValue(), and tokenStreamValue() must be set. */
     public Reader readerValue() {
       ensureOpen();
       return null;
@@ -442,7 +435,7 @@
 
     /** The value of the field as a TokenStream, or null.  If null, the Reader value,
      * String value, or binary value is used. Exactly one of stringValue(), 
-     * readerValue(), binaryValue(), and tokenStreamValue() must be set. */
+     * readerValue(), getBinaryValue(), and tokenStreamValue() must be set. */
     public TokenStream tokenStreamValue() {
       ensureOpen();
       return null;
@@ -450,7 +443,7 @@
 
     /** The value of the field as a String, or null.  If null, the Reader value,
      * binary value, or TokenStream value is used.  Exactly one of stringValue(), 
-     * readerValue(), binaryValue(), and tokenStreamValue() must be set. */
+     * readerValue(), getBinaryValue(), and tokenStreamValue() must be set. */
     public String stringValue() {
       ensureOpen();
       if (isBinary)
Index: src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
===================================================================
--- src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java	(revision 823012)
+++ src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java	(working copy)
@@ -190,7 +190,7 @@
         // easily add it
         FieldInfo fi = fieldInfos.add(fieldName, field.isIndexed(), field.isTermVectorStored(),
                                       field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
-                                      field.getOmitNorms(), false, field.getOmitTf());
+                                      field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
 
         fp = new DocFieldProcessorPerField(this, fi);
         fp.next = fieldHash[hashPos];
@@ -202,7 +202,7 @@
       } else
         fp.fieldInfo.update(field.isIndexed(), field.isTermVectorStored(),
                             field.isStorePositionWithTermVector(), field.isStoreOffsetWithTermVector(),
-                            field.getOmitNorms(), false, field.getOmitTf());
+                            field.getOmitNorms(), false, field.getOmitTermFreqAndPositions());
 
       if (thisFieldGen != fp.lastGen) {
 
Index: src/java/org/apache/lucene/document/NumericField.java
===================================================================
--- src/java/org/apache/lucene/document/NumericField.java	(revision 823012)
+++ src/java/org/apache/lucene/document/NumericField.java	(working copy)
@@ -207,11 +207,6 @@
   }
   
   /** Returns always <code>null</code> for numeric fields */
-  public byte[] binaryValue() {
-    return null;
-  }
-  
-  /** Returns always <code>null</code> for numeric fields */
   @Override
   public byte[] getBinaryValue(byte[] result){
     return null;
Index: src/java/org/apache/lucene/document/Fieldable.java
===================================================================
--- src/java/org/apache/lucene/document/Fieldable.java	(revision 823012)
+++ src/java/org/apache/lucene/document/Fieldable.java	(working copy)
@@ -18,6 +18,8 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.FieldInvertState; // for javadocs
+import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 
 import java.io.Reader;
 import java.io.Serializable;
@@ -77,7 +79,7 @@
   /** The value of the field as a String, or null.
    * <p>
    * For indexing, if isStored()==true, the stringValue() will be used as the stored field value
-   * unless isBinary()==true, in which case binaryValue() will be used.
+   * unless isBinary()==true, in which case getBinaryValue() will be used.
    *
    * If isIndexed()==true and isTokenized()==false, this String value will be indexed as a single token.
    * If isIndexed()==true and isTokenized()==true, then tokenStreamValue() will be used to generate indexed tokens if not null,
@@ -90,11 +92,6 @@
    */
   public Reader readerValue();
   
-  /** The value of the field in Binary, or null.
-   * @see #stringValue()
-   */
-  public byte[] binaryValue();
-  
   /** The TokenStream for this field to be used when indexing, or null.
    * @see #stringValue()
    */
@@ -147,15 +144,9 @@
    */
   void setOmitNorms(boolean omitNorms);
 
-  /** @deprecated Renamed to {@link AbstractField#setOmitTermFreqAndPositions} */
-  void setOmitTf(boolean omitTf);
-
-  /** @deprecated Renamed to {@link AbstractField#getOmitTermFreqAndPositions} */
-  boolean getOmitTf();
-
   /**
    * Indicates whether a Field is Lazy or not.  The semantics of Lazy loading are such that if a Field is lazily loaded, retrieving
-   * it's values via {@link #stringValue()} or {@link #binaryValue()} is only valid as long as the {@link org.apache.lucene.index.IndexReader} that
+   * it's values via {@link #stringValue()} or {@link #getBinaryValue()} is only valid as long as the {@link org.apache.lucene.index.IndexReader} that
    * retrieved the {@link Document} is still open.
    *  
    * @return true if this field can be loaded lazily
@@ -193,7 +184,7 @@
    * About reuse: if you pass in the result byte[] and it is
    * used, likely the underlying implementation will hold
    * onto this byte[] and return it in future calls to
-   * {@link #binaryValue()} or {@link #getBinaryValue()}.
+   * {@link #getBinaryValue()}.
    * So if you subsequently re-use the same byte[] elsewhere
    * it will alter this Fieldable's value.
    * @param result  User defined buffer that will be used if
@@ -202,4 +193,20 @@
    * @return reference to the Field value as byte[].
    */
   abstract byte[] getBinaryValue(byte[] result);
+  
+  /** @see #setOmitTermFreqAndPositions */
+  boolean getOmitTermFreqAndPositions();
+  
+  /** Expert:
+  *
+  * If set, omit term freq, positions and payloads from
+  * postings for this field.
+  *
+  * <p><b>NOTE</b>: While this option reduces storage space
+  * required in the index, it also means any query
+  * requiring positional information, such as {@link
+  * PhraseQuery} or {@link SpanQuery} subclasses will
+  * silently fail to find results.
+  */
+  void setOmitTermFreqAndPositions(boolean omitTermFreqAndPositions);
 }
Index: src/java/org/apache/lucene/document/AbstractField.java
===================================================================
--- src/java/org/apache/lucene/document/AbstractField.java	(revision 823012)
+++ src/java/org/apache/lucene/document/AbstractField.java	(working copy)
@@ -257,9 +257,6 @@
   /** True if norms are omitted for this indexed field */
   public boolean getOmitNorms() { return omitNorms; }
 
-  /** @deprecated Renamed to {@link #getOmitTermFreqAndPositions} */
-  public boolean getOmitTf() { return omitTermFreqAndPositions; }
-
   /** @see #setOmitTermFreqAndPositions */
   public boolean getOmitTermFreqAndPositions() { return omitTermFreqAndPositions; }
   
@@ -270,9 +267,6 @@
    */
   public void setOmitNorms(boolean omitNorms) { this.omitNorms=omitNorms; }
 
-  /** @deprecated Renamed to {@link #setOmitTermFreqAndPositions} */
-  public void setOmitTf(boolean omitTermFreqAndPositions) { this.omitTermFreqAndPositions=omitTermFreqAndPositions; }
-
   /** Expert:
    *
    * If set, omit term freq, positions and payloads from
Index: src/java/org/apache/lucene/document/Document.java
===================================================================
--- src/java/org/apache/lucene/document/Document.java	(revision 823012)
+++ src/java/org/apache/lucene/document/Document.java	(working copy)
@@ -164,21 +164,6 @@
     return null;
   }
 
-  /** Returns an Enumeration of all the fields in a document.
-   * @deprecated use {@link #getFields()} instead
-   */
-  public final Enumeration<Fieldable> fields() {
-    return new Enumeration<Fieldable>() {
-      final Iterator<Fieldable> iter = fields.iterator();
-      public boolean hasMoreElements() {
-        return iter.hasNext();
-      }
-      public Fieldable nextElement() {
-        return iter.next();
-      }
-    };
-  }
-
   /** Returns a List of all the fields in a document.
    * <p>Note that fields which are <i>not</i> {@link Fieldable#isStored() stored} are
    * <i>not</i> available in documents retrieved from the
@@ -277,7 +262,7 @@
     List<byte[]> result = new ArrayList<byte[]>();
     for (Fieldable field : fields) {
       if (field.name().equals(name) && (field.isBinary()))
-        result.add(field.binaryValue());
+        result.add(field.getBinaryValue());
     }
   
     if (result.size() == 0)
@@ -298,7 +283,7 @@
   public final byte[] getBinaryValue(String name) {
     for (Fieldable field : fields) {
       if (field.name().equals(name) && (field.isBinary()))
-        return field.binaryValue();
+        return field.getBinaryValue();
     }
     return null;
   }
Index: src/java/org/apache/lucene/document/Field.java
===================================================================
--- src/java/org/apache/lucene/document/Field.java	(revision 823012)
+++ src/java/org/apache/lucene/document/Field.java	(working copy)
@@ -70,18 +70,12 @@
      * common text. */
     public static final Index ANALYZED = new Index("ANALYZED");
 
-    /** @deprecated this has been renamed to {@link #ANALYZED} */
-    public static final Index TOKENIZED = ANALYZED;
-
     /** Index the field's value without using an Analyzer, so it can be searched.
      * As no analyzer is used the value will be stored as a single term. This is
      * useful for unique Ids like product numbers.
      */
     public static final Index NOT_ANALYZED = new Index("NOT_ANALYZED");
 
-    /** @deprecated This has been renamed to {@link #NOT_ANALYZED} */
-    public static final Index UN_TOKENIZED = NOT_ANALYZED;
-
     /** Expert: Index the field's value without an Analyzer,
      * and also disable the storing of norms.  Note that you
      * can also separately enable/disable norms by calling
@@ -98,10 +92,6 @@
      * from the beginning. */
     public static final Index NOT_ANALYZED_NO_NORMS = new Index("NOT_ANALYZED_NO_NORMS");
 
-    /** @deprecated This has been renamed to
-     *  {@link #NOT_ANALYZED_NO_NORMS} */
-    public static final Index NO_NORMS = NOT_ANALYZED_NO_NORMS;
-
     /** Expert: Index the tokens produced by running the
      *  field's value through an Analyzer, and also
      *  separately disable the storing of norms.  See
@@ -159,29 +149,7 @@
    * binary value is used.  Exactly one of stringValue(),
    * readerValue(), and getBinaryValue() must be set. */
   public Reader readerValue()   { return fieldsData instanceof Reader ? (Reader)fieldsData : null; }
-  
-  /** The value of the field in Binary, or null.  If null, the Reader value,
-   * or String value is used. Exactly one of stringValue(),
-   * readerValue(), and getBinaryValue() must be set.
-   * @deprecated This method must allocate a new byte[] if
-   * the {@link AbstractField#getBinaryOffset()} is non-zero
-   * or {@link AbstractField#getBinaryLength()} is not the
-   * full length of the byte[]. Please use {@link
-   * AbstractField#getBinaryValue()} instead, which simply
-   * returns the byte[].
-   */ 
-  public byte[] binaryValue() {
-    if (!isBinary)
-      return null;
-    final byte[] data = (byte[]) fieldsData;
-    if (binaryOffset == 0 && data.length == binaryLength)
-      return data; //Optimization
     
-    final byte[] ret = new byte[binaryLength];
-    System.arraycopy(data, binaryOffset, ret, 0, binaryLength);
-    return ret;    
-  }
-  
   /** The TokesStream for this field to be used when indexing, or null.  If null, the Reader value
    * or String value is analyzed to produce the indexed tokens. */
   public TokenStream tokenStreamValue()   { return tokenStream; }
@@ -236,22 +204,8 @@
     binaryOffset = offset;
   }
   
-  
-  /** Expert: change the value of this field.  See <a href="#setValue(java.lang.String)">setValue(String)</a>.
-   * @deprecated use {@link #setTokenStream} */
-  public void setValue(TokenStream value) {
-    if (isBinary) {
-      throw new IllegalArgumentException("cannot set a TokenStream value on a binary field");
-    }
-    if (isStored) {
-      throw new IllegalArgumentException("cannot set a TokenStream value on a stored field");
-    }
-    fieldsData = null;
-    tokenStream = value;
-  }
-
   /** Expert: sets the token stream to be used for indexing and causes isIndexed() and isTokenized() to return true.
-   *  May be combined with stored values from stringValue() or binaryValue() */
+   *  May be combined with stored values from stringValue() or getBinaryValue() */
   public void setTokenStream(TokenStream tokenStream) {
     this.isIndexed = true;
     this.isTokenized = true;
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(revision 823012)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(working copy)
@@ -595,7 +595,7 @@
         IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
-        Field.Index.UN_TOKENIZED));
+        Field.Index.NOT_ANALYZED));
     iw.addDocument(doc);
     iw.close();
     IndexSearcher is = new IndexSearcher(ramDir, true);
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(revision 823012)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(working copy)
@@ -591,7 +591,7 @@
         IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
     doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
-        Field.Index.UN_TOKENIZED));
+        Field.Index.NOT_ANALYZED));
     iw.addDocument(doc);
     iw.close();
     IndexSearcher is = new IndexSearcher(ramDir, true);
Index: contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java
===================================================================
--- contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java	(revision 823012)
+++ contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java	(working copy)
@@ -96,14 +96,14 @@
     
     Document doc = new Document();
     
-    doc.add(new Field("name", name,Field.Store.YES, Field.Index.TOKENIZED));
+    doc.add(new Field("name", name,Field.Store.YES, Field.Index.ANALYZED));
     
     // convert the lat / long to lucene fields
-    doc.add(new Field(latField, NumericUtils.doubleToPrefixCoded(lat),Field.Store.YES, Field.Index.UN_TOKENIZED));
-    doc.add(new Field(lngField, NumericUtils.doubleToPrefixCoded(lng),Field.Store.YES, Field.Index.UN_TOKENIZED));
+    doc.add(new Field(latField, NumericUtils.doubleToPrefixCoded(lat),Field.Store.YES, Field.Index.NOT_ANALYZED));
+    doc.add(new Field(lngField, NumericUtils.doubleToPrefixCoded(lng),Field.Store.YES, Field.Index.NOT_ANALYZED));
     
     // add a default meta field to make searching all documents easy 
-    doc.add(new Field("metafile", "doc",Field.Store.YES, Field.Index.TOKENIZED));
+    doc.add(new Field("metafile", "doc",Field.Store.YES, Field.Index.ANALYZED));
     
     int ctpsize = ctps.size();
     for (int i =0; i < ctpsize; i++){
@@ -111,11 +111,11 @@
       doc.add(new Field(ctp.getTierFieldName(), 
           NumericUtils.doubleToPrefixCoded(ctp.getTierBoxId(lat,lng)),
           Field.Store.YES, 
-          Field.Index.NO_NORMS));
+          Field.Index.NOT_ANALYZED_NO_NORMS));
       
       doc.add(new Field(geoHashPrefix, GeoHashUtils.encode(lat,lng), 
     		  Field.Store.YES, 
-    		  Field.Index.NO_NORMS));
+    		  Field.Index.NOT_ANALYZED_NO_NORMS));
     }
     writer.addDocument(doc);
     
Index: contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java
===================================================================
--- contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java	(revision 823012)
+++ contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java	(working copy)
@@ -63,14 +63,14 @@
     
     Document doc = new Document();
     
-    doc.add(new Field("name", name,Field.Store.YES, Field.Index.TOKENIZED));
+    doc.add(new Field("name", name,Field.Store.YES, Field.Index.ANALYZED));
     
     // convert the lat / long to lucene fields
-    doc.add(new Field(latField, NumericUtils.doubleToPrefixCoded(lat),Field.Store.YES, Field.Index.UN_TOKENIZED));
-    doc.add(new Field(lngField, NumericUtils.doubleToPrefixCoded(lng),Field.Store.YES, Field.Index.UN_TOKENIZED));
+    doc.add(new Field(latField, NumericUtils.doubleToPrefixCoded(lat),Field.Store.YES, Field.Index.NOT_ANALYZED));
+    doc.add(new Field(lngField, NumericUtils.doubleToPrefixCoded(lng),Field.Store.YES, Field.Index.NOT_ANALYZED));
     
     // add a default meta field to make searching all documents easy 
-    doc.add(new Field("metafile", "doc",Field.Store.YES, Field.Index.TOKENIZED));
+    doc.add(new Field("metafile", "doc",Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
     
   }
