diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesConsumer.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesConsumer.java
new file mode 100644
index 00000000000..65db1b8488c
--- /dev/null
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesConsumer.java
@@ -0,0 +1,136 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.codecs.bool;/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * Writer for {@link BooleanDocValuesFormat}
+ */
+
+class BooleanDocValuesConsumer extends DocValuesConsumer {
+    private IndexOutput data, meta;
+    private final int maxDoc;
+
+    BooleanDocValuesConsumer(SegmentWriteState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
+        maxDoc = state.segmentInfo.maxDoc();
+        boolean success = false;
+        try {
+            String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+            data = state.directory.createOutput(dataName, state.context);
+            CodecUtil.writeIndexHeader(data, dataCodec, BooleanDocValuesProducer.VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+            String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+            meta = state.directory.createOutput(metaName, state.context);
+            CodecUtil.writeIndexHeader(meta, metaCodec, BooleanDocValuesProducer.VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+            success = true;
+        } finally {
+            if (!success) {
+                IOUtils.closeWhileHandlingException(this);
+            }
+        }
+    }
+
+    @Override
+    public void addNumericField(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {
+        meta.writeVInt(field.number);
+        meta.writeByte(BooleanDocValuesProducer.NUMBER);
+        meta.writeLong(data.getFilePointer());
+
+        final NumericDocValues values = valuesProducer.getNumeric(field);
+        final FixedBitSet bits = new FixedBitSet(maxDoc);
+        while (values.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+            if (values.longValue() == 1) {
+                bits.set(values.docID());
+            }
+        }
+        long[] backingStore = bits.getBits();
+        meta.writeInt(backingStore.length);
+        for (long v : backingStore) {
+            data.writeLong(v);
+        }
+    }
+
+    @Override
+    public void close() throws IOException {
+        boolean success = false;
+        try {
+            if (meta != null) {
+                meta.writeVInt(-1); // write EOF marker
+                CodecUtil.writeFooter(meta); // write checksum
+            }
+            if (data != null) {
+                CodecUtil.writeFooter(data);
+            }
+            success = true;
+        } finally {
+            if (success) {
+                IOUtils.close(data, meta);
+            } else {
+                IOUtils.closeWhileHandlingException(data, meta);
+            }
+            data = meta = null;
+        }
+    }
+
+    @Override
+    public void addBinaryField(FieldInfo field, DocValuesProducer valuesProducer) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void addSortedField(FieldInfo field, DocValuesProducer valuesProducer) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void addSortedNumericField(FieldInfo field, DocValuesProducer valuesProducer) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void addSortedSetField(FieldInfo field, DocValuesProducer valuesProducer) {
+        throw new UnsupportedOperationException();
+    }
+}
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesFormat.java
new file mode 100644
index 00000000000..e31e40b82cd
--- /dev/null
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesFormat.java
@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.codecs.bool;
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+
+/**
+ * Bitwise doc values format that uses internal representation of {@link org.apache.lucene.util.FixedBitSet}
+ * in order to store indexed values and load them at search time as a simple {code long[]} array without additional
+ * decoding. There are several reasons for this:
+ * <ul>
+ * <li>At index time encoding is super fast without superfluous iterations over all values to choose ths best
+ * compression algorithm suitable for given data.</li>
+ * <li>At query time decoding is also simple and fast, no GC pressure and extra steps</li>
+ * <li>Internal representation allows to perform random access in constant time</li>
+ * </ul>
+ *
+ * <p>Limitations:
+ * <ul>
+ * <li>Does not support non boolean fields</li>
+ * <li>Boolean fields must be represented as long values {@code 1} for {@code true} and {@code 0} for {@code false}</li>
+ * </ul>
+ * <p>
+ * Current implementation does not support advanced bit set implementations like
+ * {@link org.apache.lucene.util.SparseFixedBitSet} or {@code org.apache.lucene.util.RoaringDocIdSet}.
+ */
+public class BooleanDocValuesFormat extends DocValuesFormat {
+
+    private static final String DATA_CODEC = "BooleanDocValuesData";
+    private static final String DATA_EXTENSION = "dvdb";
+    private static final String METADATA_CODEC = "BooleanDocValuesMetadata";
+    private static final String METADATA_EXTENSION = "dvmb";
+
+    public BooleanDocValuesFormat() {
+        super("Boolean");
+    }
+
+    @Override
+    public DocValuesConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
+        return new BooleanDocValuesConsumer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+    }
+
+    @Override
+    public DocValuesProducer fieldsProducer(SegmentReadState state) throws IOException {
+        return new BooleanDocValuesProducer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+    }
+
+}
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesProducer.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesProducer.java
new file mode 100644
index 00000000000..92bc8b86e52
--- /dev/null
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/BooleanDocValuesProducer.java
@@ -0,0 +1,292 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.codecs.bool;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.index.BinaryDocValues;
+import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.SortedNumericDocValues;
+import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.store.ChecksumIndexInput;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Accountables;
+import org.apache.lucene.util.BitSet;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/**
+ * Reader for {@link BooleanDocValuesFormat}
+ */
+class BooleanDocValuesProducer extends DocValuesProducer {
+    // metadata maps (just file pointers and minimal stuff)
+    private final Map<String, BooleanEntry> booleans = new HashMap<>();
+
+    // ram instances we have already loaded
+    private final Map<String, BitSet> booleanInstances = new HashMap<>();
+
+    private final IndexInput data;
+    private final int numEntries;
+
+    private final int maxDoc;
+    private long ramBytesUsed;
+    private final int version;
+
+    private final boolean merging;
+
+    static final byte NUMBER = 0;
+
+    private static final int VERSION_START = 0;
+    static final int VERSION_CURRENT = VERSION_START;
+
+    // clone for merge: when merging we don't do any instances.put()s
+    private BooleanDocValuesProducer(BooleanDocValuesProducer original) {
+        assert Thread.holdsLock(original);
+        booleans.putAll(original.booleans);
+        data = original.data.clone();
+
+        booleanInstances.putAll(original.booleanInstances);
+
+        numEntries = original.numEntries;
+        maxDoc = original.maxDoc;
+        ramBytesUsed = original.ramBytesUsed;
+        version = original.version;
+        merging = true;
+    }
+
+    BooleanDocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec,
+                             String metaExtension) throws IOException {
+        maxDoc = state.segmentInfo.maxDoc();
+        merging = false;
+        String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+        // read in the entries from the metadata file.
+        ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context);
+        ramBytesUsed = RamUsageEstimator.shallowSizeOfInstance(getClass());
+        boolean success = false;
+        try {
+            version = CodecUtil.checkIndexHeader(in, metaCodec, VERSION_START, VERSION_CURRENT,
+                    state.segmentInfo.getId(), state.segmentSuffix);
+            numEntries = readFields(in, state.fieldInfos);
+
+            CodecUtil.checkFooter(in);
+            success = true;
+        } finally {
+            if (success) {
+                IOUtils.close(in);
+            } else {
+                IOUtils.closeWhileHandlingException(in);
+            }
+        }
+
+        String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+        this.data = state.directory.openInput(dataName, state.context);
+        success = false;
+        try {
+            final int version2 = CodecUtil.checkIndexHeader(data, dataCodec, VERSION_START, VERSION_CURRENT,
+                    state.segmentInfo.getId(), state.segmentSuffix);
+            if (version != version2) {
+                throw new CorruptIndexException("Format versions mismatch: meta=" + version + ", data=" + version2, data);
+            }
+
+            // NOTE: data file is too costly to verify checksum against all the bytes on open,
+            // but for now we at least verify proper structure of the checksum footer: which looks
+            // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption
+            // such as file truncation.
+            CodecUtil.retrieveChecksum(data);
+
+            success = true;
+        } finally {
+            if (!success) {
+                IOUtils.closeWhileHandlingException(this.data);
+            }
+        }
+    }
+
+    private BooleanEntry readBooleanEntry(IndexInput meta) throws IOException {
+        BooleanEntry entry = new BooleanEntry();
+        entry.offset = meta.readLong();
+        entry.count = meta.readInt();
+        return entry;
+    }
+
+    private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
+        int numEntries = 0;
+        int fieldNumber = meta.readVInt();
+        while (fieldNumber != -1) {
+            numEntries++;
+            FieldInfo info = infos.fieldInfo(fieldNumber);
+            int fieldType = meta.readByte();
+            if (fieldType == NUMBER) {
+                booleans.put(info.name, readBooleanEntry(meta));
+            } else {
+                throw new CorruptIndexException("invalid entry type: " + fieldType + ", field= " + info.name, meta);
+            }
+            fieldNumber = meta.readVInt();
+        }
+        return numEntries;
+    }
+
+    @Override
+    public long ramBytesUsed() {
+        return ramBytesUsed;
+    }
+
+    @Override
+    public synchronized Collection<Accountable> getChildResources() {
+        Collection<Accountable> childResources = Accountables.namedAccountables("numeric field", booleanInstances);
+        return Collections.unmodifiableList(new ArrayList<>(childResources));
+    }
+
+    @Override
+    public String toString() {
+        return getClass().getSimpleName() + "(entries=" + numEntries + ")";
+    }
+
+    @Override
+    public void checkIntegrity() throws IOException {
+        CodecUtil.checksumEntireFile(data.clone());
+    }
+
+    @Override
+    public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
+        BitSet instance = booleanInstances.get(field.name);
+        BooleanEntry ne = booleans.get(field.name);
+        if (instance == null) {
+            // Lazy load
+            instance = loadBoolean(ne);
+            if (!merging) {
+                booleanInstances.put(field.name, instance);
+                ramBytesUsed += instance.ramBytesUsed();
+            }
+        }
+        return new BooleanDocValues(instance, ne.count << 6);
+    }
+
+    private BitSet loadBoolean(BooleanEntry entry) throws IOException {
+        IndexInput data = this.data.clone();
+        data.seek(entry.offset);
+
+        int length = entry.count;
+        final long[] bits = new long[length];
+        for (int i = 0; i < length; i++) {
+            //better to read bytes at a time org.apache.lucene.store.DataInput.readBytes(byte[], int, int)
+            bits[i] = data.readLong();
+        }
+        //we can choose better implementation here based on data density
+        return new FixedBitSet(bits, length << 6);
+    }
+
+    @Override
+    public BinaryDocValues getBinary(FieldInfo field) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public SortedDocValues getSorted(FieldInfo field) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public SortedNumericDocValues getSortedNumeric(FieldInfo field) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public SortedSetDocValues getSortedSet(FieldInfo field) {
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public synchronized DocValuesProducer getMergeInstance() {
+        return new BooleanDocValuesProducer(this);
+    }
+
+    @Override
+    public void close() throws IOException {
+        data.close();
+    }
+
+    static class BooleanEntry {
+        long offset;
+        int count;
+    }
+
+    static class BooleanDocValues extends NumericDocValues {
+        private final BitSet bitSet;
+        private final int maxDoc;
+        private final int cost;
+        private int docId = -1;
+
+        BooleanDocValues(BitSet bitSet, int maxDoc) {
+            this.bitSet = bitSet;
+            this.maxDoc = maxDoc;//performance hint use prevSetBit here
+            //is very expensive we can store an information in meta at index time and use as a constant
+            this.cost = bitSet.approximateCardinality();
+        }
+
+        @Override
+        public long longValue() {
+            return bitSet.get(docId) ? 1 : 0;
+        }
+
+        @Override
+        public boolean advanceExact(int target) {
+            docId = target;
+            return bitSet.get(docId);
+        }
+
+        @Override
+        public int docID() {
+            return docId;
+        }
+
+        @Override
+        public int nextDoc() {
+            return advance(docId + 1);
+        }
+
+        @Override
+        public int advance(int target) {
+            if (target >= maxDoc) {
+                docId = NO_MORE_DOCS;
+            } else {
+                docId = bitSet.nextSetBit(target);
+            }
+            return docId;
+        }
+
+        @Override
+        public long cost() {
+            return cost;
+        }
+    }
+}
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/bool/package-info.java b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/package-info.java
new file mode 100644
index 00000000000..c09ed70f5f3
--- /dev/null
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/bool/package-info.java
@@ -0,0 +1,22 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Codec PostingsFormat for fast access to low-frequency terms 
+ * such as primary key fields.
+ */
+package org.apache.lucene.codecs.bool;
diff --git a/lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat b/lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
index 33c8fadb8cc..e7435589e44 100644
--- a/lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
+++ b/lucene/codecs/src/resources/META-INF/services/org.apache.lucene.codecs.DocValuesFormat
@@ -14,3 +14,4 @@
 #  limitations under the License.
 
 org.apache.lucene.codecs.memory.DirectDocValuesFormat
+org.apache.lucene.codecs.bool.BooleanDocValuesFormat
diff --git a/lucene/codecs/src/test/org/apache/lucene/index/TestBooleanDocValuesFormat.java b/lucene/codecs/src/test/org/apache/lucene/index/TestBooleanDocValuesFormat.java
new file mode 100644
index 00000000000..7906c99a005
--- /dev/null
+++ b/lucene/codecs/src/test/org/apache/lucene/index/TestBooleanDocValuesFormat.java
@@ -0,0 +1,570 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.index;
+
+import java.io.IOException;
+import java.util.concurrent.CountDownLatch;
+import java.util.function.LongSupplier;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.codecs.bool.BooleanDocValuesFormat;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.StoredField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.TestUtil;
+
+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;
+
+/**
+ * Tests BooleanDocValuesFormat. Inspired by {@link BaseDocValuesFormatTestCase}.
+ */
+public class TestBooleanDocValuesFormat extends BaseIndexFileFormatTestCase {
+    private final Codec codec = TestUtil.alwaysDocValuesFormat(new BooleanDocValuesFormat());
+
+    @Override
+    protected Codec getCodec() {
+        return codec;
+    }
+
+    @Override
+    protected void addRandomFields(Document doc) {
+        if (usually()) {
+            doc.add(new NumericDocValuesField("ndv", random().nextInt(2)));
+        }
+    }
+
+    public void testOneBoolean() throws IOException {
+        Directory directory = newDirectory();
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory);
+        Document doc = new Document();
+        String longTerm = "longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm";
+        String text = "This is the text to be indexed. " + longTerm;
+        doc.add(newTextField("fieldname", text, Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv", 1));
+        iwriter.addDocument(doc);
+        iwriter.close();
+
+        // Now search the index:
+        IndexReader ireader = DirectoryReader.open(directory); // read-only=true
+        IndexSearcher isearcher = new IndexSearcher(ireader);
+
+        assertEquals(1, isearcher.count(new TermQuery(new Term("fieldname", longTerm))));
+        Query query = new TermQuery(new Term("fieldname", "text"));
+        TopDocs hits = isearcher.search(query, 1);
+        assertEquals(1, hits.totalHits.value);
+        // Iterate through the results:
+        for (int i = 0; i < hits.scoreDocs.length; i++) {
+            Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);
+            assertEquals(text, hitDoc.get("fieldname"));
+            assert ireader.leaves().size() == 1;
+            NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
+            int docID = hits.scoreDocs[i].doc;
+            assertEquals(docID, dv.advance(docID));
+            assertEquals(1, dv.longValue());
+        }
+
+        ireader.close();
+        directory.close();
+    }
+
+    public void testTwoBooleans() throws IOException {
+        Directory directory = newDirectory();
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory);
+        Document doc = new Document();
+        String longTerm = "longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm";
+        String text = "This is the text to be indexed. " + longTerm;
+        doc.add(newTextField("fieldname", text, Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv1", 1));
+        doc.add(new NumericDocValuesField("dv2", 0));
+        iwriter.addDocument(doc);
+        iwriter.close();
+
+        // Now search the index:
+        IndexReader ireader = DirectoryReader.open(directory); // read-only=true
+        IndexSearcher isearcher = new IndexSearcher(ireader);
+
+        assertEquals(1, isearcher.count(new TermQuery(new Term("fieldname", longTerm))));
+        Query query = new TermQuery(new Term("fieldname", "text"));
+        TopDocs hits = isearcher.search(query, 1);
+        assertEquals(1, hits.totalHits.value);
+        // Iterate through the results:
+        for (int i = 0; i < hits.scoreDocs.length; i++) {
+            int docID = hits.scoreDocs[i].doc;
+            Document hitDoc = isearcher.doc(docID);
+            assertEquals(text, hitDoc.get("fieldname"));
+            assert ireader.leaves().size() == 1;
+            NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv1");
+            assertEquals(docID, dv.advance(docID));
+            assertEquals(1, dv.longValue());
+            dv = ireader.leaves().get(0).reader().getNumericDocValues("dv2");
+            assertEquals(NO_MORE_DOCS, dv.advance(docID));
+        }
+
+        ireader.close();
+        directory.close();
+    }
+
+    public void testTwoDocumentsBoolean() throws IOException {
+        Analyzer analyzer = new MockAnalyzer(random());
+
+        Directory directory = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(analyzer);
+        conf.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, conf);
+        Document doc = new Document();
+        doc.add(new NumericDocValuesField("dv", 1));
+        iwriter.addDocument(doc);
+        doc = new Document();
+        doc.add(new NumericDocValuesField("dv", 0));
+        iwriter.addDocument(doc);
+        iwriter.forceMerge(1);
+        iwriter.close();
+
+        // Now search the index:
+        IndexReader ireader = DirectoryReader.open(directory); // read-only=true
+        assert ireader.leaves().size() == 1;
+        NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
+        assertEquals(0, dv.nextDoc());
+        assertEquals(1, dv.longValue());
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+
+        ireader.close();
+        directory.close();
+    }
+
+    public void testTwoDocumentsMerged() throws IOException {
+        Analyzer analyzer = new MockAnalyzer(random());
+
+        Directory directory = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(analyzer);
+        conf.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, conf);
+        Document doc = new Document();
+        doc.add(newField("id", "0", StringField.TYPE_STORED));
+        doc.add(new NumericDocValuesField("dv", 0));
+        iwriter.addDocument(doc);
+        iwriter.commit();
+        doc = new Document();
+        doc.add(newField("id", "1", StringField.TYPE_STORED));
+        doc.add(new NumericDocValuesField("dv", 1));
+        iwriter.addDocument(doc);
+        iwriter.forceMerge(1);
+        iwriter.close();
+
+        // Now search the index:
+        IndexReader ireader = DirectoryReader.open(directory); // read-only=true
+        assert ireader.leaves().size() == 1;
+        NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues("dv");
+        assertEquals(1, dv.nextDoc());
+        assertEquals(1, dv.longValue());
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+
+        ireader.close();
+        directory.close();
+    }
+
+    public void doTestBooleansVsStoredFields(LongSupplier longs) throws Exception {
+        Directory dir = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));
+        RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);
+        Document doc = new Document();
+        Field idField = new StringField("id", "", Field.Store.NO);
+        Field storedField = newStringField("stored", "", Field.Store.YES);
+        Field dvField = new NumericDocValuesField("dv", 0);
+        doc.add(idField);
+        doc.add(storedField);
+        doc.add(dvField);
+
+        // index some docs
+        int numDocs = atLeast(300);
+        // numDocs should be always > 256 so that in case of a codec that optimizes
+        // for numbers of values <= 256, all storage layouts are tested
+        assert numDocs > 256;
+        for (int i = 0; i < numDocs; i++) {
+            idField.setStringValue(Integer.toString(i));
+            long value = longs.getAsLong();
+            storedField.setStringValue(Long.toString(value));
+            dvField.setLongValue(value);
+            writer.addDocument(doc);
+            if (random().nextInt(31) == 0) {
+                writer.commit();
+            }
+        }
+
+        // delete some docs
+        int numDeletions = random().nextInt(numDocs / 10);
+        for (int i = 0; i < numDeletions; i++) {
+            int id = random().nextInt(numDocs);
+            writer.deleteDocuments(new Term("id", Integer.toString(id)));
+        }
+
+        // merge some segments and ensure that at least one of them has more than
+        // 256 values
+        writer.forceMerge(numDocs / 256);
+
+        writer.close();
+
+        // compare
+        DirectoryReader ir = DirectoryReader.open(dir);
+        TestUtil.checkReader(ir);
+        for (LeafReaderContext context : ir.leaves()) {
+            LeafReader r = context.reader();
+            NumericDocValues docValues = DocValues.getNumeric(r, "dv");
+            docValues.nextDoc();
+            for (int i = 0; i < r.maxDoc(); i++) {
+                String storedValue = r.document(i).get("stored");
+                if (storedValue == null) {
+                    assertTrue(docValues.docID() > i);
+                } else {
+                    long value = Long.parseLong(storedValue);
+                    if (value == 0) {
+                        continue;
+                    }
+                    int docID = docValues.docID();
+                    assertEquals(i, docID);
+                    assertEquals(Long.parseLong(storedValue), docValues.longValue());
+                    docValues.nextDoc();
+                }
+            }
+            assertEquals(NO_MORE_DOCS, docValues.docID());
+        }
+        ir.close();
+        dir.close();
+    }
+
+    public void testBooleansVsStoredFields() throws Exception {
+        int numIterations = atLeast(1);
+        for (int i = 0; i < numIterations; i++) {
+            doTestBooleansVsStoredFields(() -> random().nextInt(2));
+        }
+    }
+
+    public void testTwoBooleansOneMissing() throws IOException {
+        Directory directory = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(null);
+        conf.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iw = new RandomIndexWriter(random(), directory, conf);
+        Document doc = new Document();
+        doc.add(new StringField("id", "0", Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv1", 0));
+        iw.addDocument(doc);
+        doc = new Document();
+        doc.add(new StringField("id", "1", Field.Store.YES));
+        iw.addDocument(doc);
+        iw.forceMerge(1);
+        iw.close();
+
+        IndexReader ir = DirectoryReader.open(directory);
+        assertEquals(1, ir.leaves().size());
+        LeafReader ar = ir.leaves().get(0).reader();
+        NumericDocValues dv = ar.getNumericDocValues("dv1");
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+        ir.close();
+        directory.close();
+    }
+
+    public void testTwoBooleansOneMissingWithMerging() throws IOException {
+        Directory directory = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(null);
+        conf.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iw = new RandomIndexWriter(random(), directory, conf);
+        Document doc = new Document();
+        doc.add(new StringField("id", "0", Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv1", 0));
+        iw.addDocument(doc);
+        iw.commit();
+        doc = new Document();
+        doc.add(new StringField("id", "1", Field.Store.YES));
+        iw.addDocument(doc);
+        iw.forceMerge(1);
+        iw.close();
+
+        IndexReader ir = DirectoryReader.open(directory);
+        assertEquals(1, ir.leaves().size());
+        LeafReader ar = ir.leaves().get(0).reader();
+        NumericDocValues dv = ar.getNumericDocValues("dv1");
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+        ir.close();
+        directory.close();
+    }
+
+    public void testThreeBooleansOneMissingWithMerging() throws IOException {
+        Directory directory = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(null);
+        conf.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iw = new RandomIndexWriter(random(), directory, conf);
+        Document doc = new Document();
+        doc.add(new StringField("id", "0", Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv1", 0));
+        iw.addDocument(doc);
+        doc = new Document();
+        doc.add(new StringField("id", "1", Field.Store.YES));
+        iw.addDocument(doc);
+        iw.commit();
+        doc = new Document();
+        doc.add(new StringField("id", "2", Field.Store.YES));
+        doc.add(new NumericDocValuesField("dv1", 1));
+        iw.addDocument(doc);
+        iw.forceMerge(1);
+        iw.close();
+
+        IndexReader ir = DirectoryReader.open(directory);
+        assertEquals(1, ir.leaves().size());
+        LeafReader ar = ir.leaves().get(0).reader();
+        NumericDocValues dv = ar.getNumericDocValues("dv1");
+        assertEquals(2, dv.nextDoc());
+        assertEquals(1, dv.longValue());
+        ir.close();
+        directory.close();
+    }
+
+    /**
+     * Tests dv against stored fields with threads (binary/numeric/sorted, no missing)
+     */
+    public void testThreads() throws Exception {
+        Directory dir = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));
+        RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);
+        Document doc = new Document();
+        Field idField = new StringField("id", "", Field.Store.NO);
+        Field storedNumericField = new StoredField("storedNum", "");
+        Field dvNumericField = new NumericDocValuesField("dvNum", 0);
+        doc.add(idField);
+        doc.add(storedNumericField);
+        doc.add(dvNumericField);
+
+        // index some docs
+        int numDocs = atLeast(300);
+        for (int i = 0; i < numDocs; i++) {
+            idField.setStringValue(Integer.toString(i));
+            Integer numericValue = random().nextInt(2);
+            storedNumericField.setStringValue(numericValue.toString());
+            dvNumericField.setLongValue(numericValue);
+            writer.addDocument(doc);
+            if (random().nextInt(31) == 0) {
+                writer.commit();
+            }
+        }
+
+        // delete some docs
+        int numDeletions = random().nextInt(numDocs / 10);
+        for (int i = 0; i < numDeletions; i++) {
+            int id = random().nextInt(numDocs);
+            writer.deleteDocuments(new Term("id", Integer.toString(id)));
+        }
+        writer.close();
+
+        // compare
+        final DirectoryReader ir = DirectoryReader.open(dir);
+        int numThreads = TestUtil.nextInt(random(), 2, 7);
+        Thread threads[] = new Thread[numThreads];
+        final CountDownLatch startingGun = new CountDownLatch(1);
+
+        for (int i = 0; i < threads.length; i++) {
+            threads[i] = new Thread() {
+                @Override
+                public void run() {
+                    try {
+                        startingGun.await();
+                        for (LeafReaderContext context : ir.leaves()) {
+                            LeafReader r = context.reader();
+                            NumericDocValues numerics = r.getNumericDocValues("dvNum");
+                            for (int j = 0; j < r.maxDoc(); j++) {
+                                String expected = r.document(j).get("storedNum");
+                                long value = Long.parseLong(expected);
+                                if (value == 0) {
+                                    continue;
+                                }
+                                assertEquals(j, numerics.nextDoc());
+                                assertEquals(1, numerics.longValue());
+                            }
+                        }
+                        TestUtil.checkReader(ir);
+                    } catch (Exception e) {
+                        throw new RuntimeException(e);
+                    }
+                }
+            };
+            threads[i].start();
+        }
+        startingGun.countDown();
+        for (Thread t : threads) {
+            t.join();
+        }
+        ir.close();
+        dir.close();
+    }
+
+    /**
+     * Tests dv against stored fields with threads (all types + missing)
+     */
+    @Slow
+    public void testThreads2() throws Exception {
+        Directory dir = newDirectory();
+        IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));
+        RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);
+        Field idField = new StringField("id", "", Field.Store.NO);
+        Field storedNumericField = new StoredField("storedNum", "");
+        Field dvNumericField = new NumericDocValuesField("dvNum", 0);
+
+        // index some docs
+        int numDocs = TestUtil.nextInt(random(), 1025, 2047);
+        for (int i = 0; i < numDocs; i++) {
+            idField.setStringValue(Integer.toString(i));
+            int numericValue = random().nextInt(2);
+            storedNumericField.setStringValue(Integer.toString(numericValue));
+            dvNumericField.setLongValue(numericValue);
+            Document doc = new Document();
+            doc.add(idField);
+            if (random().nextInt(4) > 0) {
+                doc.add(storedNumericField);
+                doc.add(dvNumericField);
+            }
+            writer.addDocument(doc);
+            if (random().nextInt(31) == 0) {
+                writer.commit();
+            }
+        }
+
+        // delete some docs
+        int numDeletions = random().nextInt(numDocs / 10);
+        for (int i = 0; i < numDeletions; i++) {
+            int id = random().nextInt(numDocs);
+            writer.deleteDocuments(new Term("id", Integer.toString(id)));
+        }
+        writer.close();
+
+        // compare
+        final DirectoryReader ir = DirectoryReader.open(dir);
+        int numThreads = TestUtil.nextInt(random(), 2, 7);
+        Thread threads[] = new Thread[numThreads];
+        final CountDownLatch startingGun = new CountDownLatch(1);
+
+        for (int i = 0; i < threads.length; i++) {
+            threads[i] = new Thread() {
+                @Override
+                public void run() {
+                    try {
+                        startingGun.await();
+                        for (LeafReaderContext context : ir.leaves()) {
+                            LeafReader r = context.reader();
+                            NumericDocValues numerics = r.getNumericDocValues("dvNum");
+                            for (int j = 0; j < r.maxDoc(); j++) {
+                                String number = r.document(j).get("storedNum");
+                                if (number != null) {
+                                    long value = Long.parseLong(number);
+                                    if (value == 0) {
+                                        continue;
+                                    }
+                                    if (numerics != null) {
+                                        assertEquals(j, numerics.advance(j));
+                                        assertEquals(1, numerics.longValue());
+                                    }
+                                }
+                            }
+                        }
+                        TestUtil.checkReader(ir);
+                    } catch (Exception e) {
+                        throw new RuntimeException(e);
+                    }
+                }
+            };
+            threads[i].start();
+        }
+        startingGun.countDown();
+        for (Thread t : threads) {
+            t.join();
+        }
+        ir.close();
+        dir.close();
+    }
+
+    public void testBooleanMergeAwayAllValues() throws IOException {
+        Directory directory = newDirectory();
+        Analyzer analyzer = new MockAnalyzer(random());
+        IndexWriterConfig iwconfig = newIndexWriterConfig(analyzer);
+        iwconfig.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);
+
+        Document doc = new Document();
+        doc.add(new StringField("id", "0", Field.Store.NO));
+        iwriter.addDocument(doc);
+        doc = new Document();
+        doc.add(new StringField("id", "1", Field.Store.NO));
+        doc.add(new NumericDocValuesField("field", 1));
+        iwriter.addDocument(doc);
+        iwriter.commit();
+        iwriter.deleteDocuments(new Term("id", "1"));
+        iwriter.forceMerge(1);
+
+        DirectoryReader ireader = iwriter.getReader();
+        iwriter.close();
+
+        NumericDocValues dv = getOnlyLeafReader(ireader).getNumericDocValues("field");
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+
+        ireader.close();
+        directory.close();
+    }
+
+    // same as testBooleanMergeAwayAllValues but on more than 1024 docs to have sparse encoding on
+    public void testNumericMergeAwayAllValuesLargeSegment() throws IOException {
+        Directory directory = newDirectory();
+        Analyzer analyzer = new MockAnalyzer(random());
+        IndexWriterConfig iwconfig = newIndexWriterConfig(analyzer);
+        iwconfig.setMergePolicy(newLogMergePolicy());
+        RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);
+
+        Document doc = new Document();
+        doc.add(new StringField("id", "1", Field.Store.NO));
+        doc.add(new NumericDocValuesField("field", 1));
+        iwriter.addDocument(doc);
+        final int numEmptyDocs = atLeast(1024);
+        for (int i = 0; i < numEmptyDocs; ++i) {
+            iwriter.addDocument(new Document());
+        }
+        iwriter.commit();
+        iwriter.deleteDocuments(new Term("id", "1"));
+        iwriter.forceMerge(1);
+
+        DirectoryReader ireader = iwriter.getReader();
+        iwriter.close();
+
+        NumericDocValues dv = getOnlyLeafReader(ireader).getNumericDocValues("field");
+        assertEquals(NO_MORE_DOCS, dv.nextDoc());
+
+        ireader.close();
+        directory.close();
+    }
+}
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesBooleanQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesBooleanQuery.java
new file mode 100644
index 00000000000..3954a996978
--- /dev/null
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesBooleanQuery.java
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.search;
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.NumericDocValues;
+
+/**
+ * Like {@code DocValuesNumbersQuery}, but this query only
+ * runs on a long {@link NumericDocValuesField}, matching
+ * all documents whose value is {@code 1}. All documents with
+ * {@code 0} and {@code null} values are considered as absent.
+ * <p>
+ *
+ * @lucene.experimental
+ */
+public class DocValuesBooleanQuery extends Query {
+
+    private final String field;
+  
+    public DocValuesBooleanQuery(String field) {
+        this.field = Objects.requireNonNull(field);
+    }
+  
+    @Override
+    public boolean equals(Object other) {
+        return sameClassAs(other) && equalsTo(getClass().cast(other));
+    }
+  
+    private boolean equalsTo(DocValuesBooleanQuery other) {
+        return field.equals(other.field);
+    }
+  
+    @Override
+    public int hashCode() {
+        return 31 * classHash() + Objects.hash(field);
+    }
+  
+    @Override
+    public void visit(QueryVisitor visitor) {
+        if (visitor.acceptField(field)) {
+            visitor.visitLeaf(this);
+        }
+    }
+  
+    @Override
+    public String toString(String defaultField) {
+      return "DocValuesBooleanQuery:" + field;
+    }
+
+    @Override
+    public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) {
+        return new ConstantScoreWeight(this, boost) {
+            @Override
+            public boolean isCacheable(LeafReaderContext ctx) {
+                return true;
+            }
+
+            @Override
+            public Scorer scorer(LeafReaderContext context) throws IOException {
+                final NumericDocValues values = DocValues.getNumeric(context.reader(), field);
+                final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(values) {
+                    @Override
+                    public boolean matches() throws IOException {
+                        return values.longValue() != 0; // treats any non-zero value as true
+                    }
+
+                    @Override
+                    public float matchCost() {
+                        return 1; // 1 comparison
+                    }
+                };
+
+                final DocIdSetIterator iterator = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);
+                return new Scorer(this) {
+                    @Override
+                    public int docID() {
+                        return iterator.docID();
+                    }
+
+                    @Override
+                    public float score() {
+                        return boost;
+                    }
+
+                    @Override
+                    public DocIdSetIterator iterator() {
+                        return iterator;
+                    }
+
+                    @Override
+                    public float getMaxScore(int upTo) throws IOException {
+                        return Float.POSITIVE_INFINITY;
+                    }
+                };
+            }
+        };
+    }
+}
+
