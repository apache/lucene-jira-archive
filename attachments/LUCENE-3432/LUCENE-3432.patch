Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1170109)
+++ lucene/CHANGES.txt	(working copy)
@@ -585,6 +585,10 @@
 * LUCENE-3421: PayloadTermQuery's explain was wrong when includeSpanScore=false.
   (Edward Drapkin via Robert Muir)
 
+* LUCENE-3432: IndexWriter.expungeDeletes with TieredMergePolicy
+  should ignore the maxMergedSegmentMB setting (v.sevel via Mike
+  McCandless)
+
 ======================= Lucene 3.4.0 =======================
 
 Bug fixes
Index: lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy.java	(revision 1170109)
+++ lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy.java	(working copy)
@@ -19,6 +19,7 @@
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
+import org.apache.lucene.document.StringField;
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
@@ -107,4 +108,48 @@
       dir.close();
     }
   }
+
+  public void testExpungeMaxSegSize() throws Exception {
+    final Directory dir = newDirectory();
+    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));
+    final TieredMergePolicy tmp = new TieredMergePolicy();
+    tmp.setMaxMergedSegmentMB(0.01);
+    tmp.setExpungeDeletesPctAllowed(0.0);
+    conf.setMergePolicy(tmp);
+
+    final RandomIndexWriter w = new RandomIndexWriter(random, dir, conf);
+    w.setDoRandomOptimize(false);
+
+    final int numDocs = atLeast(200);
+    for(int i=0;i<numDocs;i++) {
+      Document doc = new Document();
+      doc.add(newField("id", "" + i, StringField.TYPE_UNSTORED));
+      doc.add(newField("content", "aaa " + i, TextField.TYPE_UNSTORED));
+      w.addDocument(doc);
+    }
+
+    w.optimize();
+    IndexReader r = w.getReader();
+    assertEquals(numDocs, r.maxDoc());
+    assertEquals(numDocs, r.numDocs());
+    r.close();
+
+    w.deleteDocuments(new Term("id", ""+(42+17)));
+
+    r = w.getReader();
+    assertEquals(numDocs, r.maxDoc());
+    assertEquals(numDocs-1, r.numDocs());
+    r.close();
+
+    w.expungeDeletes();
+
+    r = w.getReader();
+    assertEquals(numDocs-1, r.maxDoc());
+    assertEquals(numDocs-1, r.numDocs());
+    r.close();
+
+    w.close();
+
+    dir.close();
+  }
 }
Index: lucene/src/java/org/apache/lucene/index/TieredMergePolicy.java
===================================================================
--- lucene/src/java/org/apache/lucene/index/TieredMergePolicy.java	(revision 1170109)
+++ lucene/src/java/org/apache/lucene/index/TieredMergePolicy.java	(working copy)
@@ -576,45 +576,20 @@
     MergeSpecification spec = null;
 
     while(start < eligible.size()) {
-      long totAfterMergeBytes = 0;
-      int upto = start;
-      boolean done = false;
-      while(upto < start + maxMergeAtOnceExplicit) {
-        if (upto == eligible.size()) {
-          done = true;
-          break;
-        }
-        final SegmentInfo info = eligible.get(upto);
-        final long segBytes = size(info);
-        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {
-          // TODO: we could be smarter here, eg cherry
-          // picking smaller merges that'd sum up to just
-          // around the max size
-          break;
-        }
-        totAfterMergeBytes += segBytes;
-        upto++;
-      }
-
-      if (upto == start) {
-        // Single segment is too big; grace it
-        start++;
-        continue;
-      }
-      
+      // Don't enforce max merged size here: app is explicitly
+      // calling expungeDeletes, and knows this may take a
+      // long time / produce big segments (like optimize):
+      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());
       if (spec == null) {
         spec = new MergeSpecification();
       }
 
-      final OneMerge merge = new OneMerge(eligible.subList(start, upto));
+      final OneMerge merge = new OneMerge(eligible.subList(start, end));
       if (verbose()) {
         message("add merge=" + writer.get().segString(merge.segments));
       }
       spec.add(merge);
-      start = upto;
-      if (done) {
-        break;
-      }
+      start = end;
     }
 
     return spec;
Index: lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java
===================================================================
--- lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java	(revision 1170109)
+++ lucene/src/test-framework/org/apache/lucene/index/RandomIndexWriter.java	(working copy)
@@ -326,6 +326,14 @@
   private boolean doRandomOptimize = true;
   private boolean doRandomOptimizeAssert = true;
 
+  public void expungeDeletes(boolean doWait) throws IOException {
+    w.expungeDeletes(doWait);
+  }
+
+  public void expungeDeletes() throws IOException {
+    w.expungeDeletes();
+  }
+
   public void setDoRandomOptimize(boolean v) {
     doRandomOptimize = v;
   }
