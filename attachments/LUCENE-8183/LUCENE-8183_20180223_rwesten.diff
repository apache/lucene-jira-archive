diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
index 41f92c9..21fa8b8 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
@@ -133,6 +133,12 @@ public class HyphenationCompoundWordTokenFilter extends
 
   @Override
   protected void decompose() {
+    //avoid to emit a token if the token is in the dictionary
+    if(this.onlyLongestMatch && dictionary != null && 
+        (dictionary.contains(termAtt.buffer(), 0, termAtt.length()) ||
+            termAtt.length() > 1 && dictionary.contains(termAtt.buffer(), 0, termAtt.length() - 1))){
+      return; //the whole token is in the dictionary - do not decompose
+    }
     // get the hyphenation points
     Hyphenation hyphens = hyphenator.hyphenate(termAtt.buffer(), 0, termAtt.length(), 1, 1);
     // No hyphen points found -> exit
@@ -145,7 +151,9 @@ public class HyphenationCompoundWordTokenFilter extends
     for (int i = 0; i < hyp.length; ++i) {
       int remaining = hyp.length - i;
       int start = hyp[i];
+      
       CompoundToken longestMatchToken = null;
+      int consumedHyp = i;
       for (int j = 1; j < remaining; j++) {
         int partLength = hyp[i + j] - start;
 
@@ -160,7 +168,7 @@ public class HyphenationCompoundWordTokenFilter extends
         if (partLength < this.minSubwordSize) {
           // BOGUS/BROKEN/FUNKY/WACKO: somehow we have negative 'parts' according to the 
           // calculation above, and we rely upon minSubwordSize being >=0 to filter them out...
-          continue;
+          continue; 
         }
 
         // check the dictionary
@@ -169,9 +177,11 @@ public class HyphenationCompoundWordTokenFilter extends
             if (longestMatchToken != null) {
               if (longestMatchToken.txt.length() < partLength) {
                 longestMatchToken = new CompoundToken(start, partLength);
+                consumedHyp = i + j - 1; //consume matched hyp as we do not want overlapping tokens
               }
             } else {
               longestMatchToken = new CompoundToken(start, partLength);
+              consumedHyp = i + j - 1; //consume matched hyp as we do not want overlapping tokens
             }
           } else {
             tokens.add(new CompoundToken(start, partLength));
@@ -185,9 +195,11 @@ public class HyphenationCompoundWordTokenFilter extends
             if (longestMatchToken != null) {
               if (longestMatchToken.txt.length() < partLength - 1) {
                 longestMatchToken = new CompoundToken(start, partLength - 1);
+                consumedHyp = i + j - 1; //consume matched hyp as we do not want overlapping tokens
               }
             } else {
               longestMatchToken = new CompoundToken(start, partLength - 1);
+              consumedHyp = i + j - 1; //consume matched hyp as we do not want overlapping tokens
             }
           } else {
             tokens.add(new CompoundToken(start, partLength - 1));
@@ -195,6 +207,7 @@ public class HyphenationCompoundWordTokenFilter extends
         }
       }
       if (this.onlyLongestMatch && longestMatchToken!=null) {
+        i = consumedHyp;
         tokens.add(longestMatchToken);
       }
     }
