Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex	(working copy)
@@ -73,7 +73,7 @@
     upperCaseVariantsAccepted.put("amp", "AMP");
   }
   private static final CharArrayMap<Character> entityValues
-      = new CharArrayMap<Character>(Version.LUCENE_40, 253, false);
+      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, 253, false);
   static {
     String[] entities = {
       "AElig", "\u00C6", "Aacute", "\u00C1", "Acirc", "\u00C2",
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java	(working copy)
@@ -30673,7 +30673,7 @@
     upperCaseVariantsAccepted.put("amp", "AMP");
   }
   private static final CharArrayMap<Character> entityValues
-      = new CharArrayMap<Character>(Version.LUCENE_40, 253, false);
+      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, 253, false);
   static {
     String[] entities = {
       "AElig", "\u00C6", "Aacute", "\u00C1", "Acirc", "\u00C2",
@@ -30812,7 +30812,7 @@
           escapeSTYLE = true;
         } else {
           if (null == this.escapedTags) {
-            this.escapedTags = new CharArraySet(Version.LUCENE_40, 16, true);
+            this.escapedTags = new CharArraySet(Version.LUCENE_CURRENT, 16, true);
           }
           this.escapedTags.add(tag);
         }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex	(working copy)
@@ -197,7 +197,7 @@
           escapeSTYLE = true;
         } else {
           if (null == this.escapedTags) {
-            this.escapedTags = new CharArraySet(Version.LUCENE_40, 16, true);
+            this.escapedTags = new CharArraySet(Version.LUCENE_CURRENT, 16, true);
           }
           this.escapedTags.add(tag);
         }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/htmlentity.py	(working copy)
@@ -61,7 +61,7 @@
   print '    upperCaseVariantsAccepted.put("amp", "AMP");'
   print '  }'
   print '  private static final CharArrayMap<Character> entityValues'
-  print '      = new CharArrayMap<Character>(Version.LUCENE_40, %i, false);' % len(keys)
+  print '      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, %i, false);' % len(keys)
   print '  static {'
   print '    String[] entities = {'
   output_line = '     '
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java	(working copy)
@@ -196,7 +196,7 @@
     return len;
   }
   
-  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("θ", "δ", "ελ", "γαλ", "ν", "π", "ιδ", "παρ"),
       false);
   
@@ -222,7 +222,7 @@
     return len;
   }
 
-  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "αδ", "ενδ", "αμαν", "αμμοχαλ", "ηθ", "ανηθ",
           "αντιδ", "φυσ", "βρωμ", "γερ", "εξωδ", "καλπ", "καλλιν", "καταδ",
           "μουλ", "μπαν", "μπαγιατ", "μπολ", "μποσ", "νιτ", "ξικ", "συνομηλ",
@@ -247,7 +247,7 @@
     return len;
   }
   
-  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αναπ", "αποθ", "αποκ", "αποστ", "βουβ", "ξεθ", "ουλ",
           "πεθ", "πικρ", "ποτ", "σιχ", "χ"), 
       false);
@@ -274,11 +274,11 @@
     return len;
   }
 
-  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("τρ", "τσ"),
       false);
 
-  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("βετερ", "βουλκ", "βραχμ", "γ", "δραδουμ", "θ", "καλπουζ",
           "καστελ", "κορμορ", "λαοπλ", "μωαμεθ", "μ", "μουσουλμ", "ν", "ουλ",
           "π", "πελεκ", "πλ", "πολισ", "πορτολ", "σαρακατσ", "σουλτ",
@@ -337,7 +337,7 @@
     return len;
   }
   
-  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβαρ", "βεν", "εναρ", "αβρ", "αδ", "αθ", "αν", "απλ",
           "βαρον", "ντρ", "σκ", "κοπ", "μπορ", "νιφ", "παγ", "παρακαλ", "σερπ",
           "σκελ", "συρφ", "τοκ", "υ", "δ", "εμ", "θαρρ", "θ"), 
@@ -425,11 +425,11 @@
     return len;
   }
 
-  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("π", "απ", "συμπ", "ασυμπ", "ακαταπ", "αμεταμφ"),
       false);
 
-  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "αρ", "εκτελ", "ζ", "μ", "ξ", "παρακαλ", "αρ", "προ", "νισ"),
       false);
   
@@ -449,7 +449,7 @@
     return len;
   }
   
-  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("διαθ", "θ", "παρακαταθ", "προσθ", "συνθ"),
       false);
   
@@ -483,7 +483,7 @@
     return len;
   }
   
-  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("φαρμακ", "χαδ", "αγκ", "αναρρ", "βρομ", "εκλιπ", "λαμπιδ",
           "λεχ", "μ", "πατ", "ρ", "λ", "μεδ", "μεσαζ", "υποτειν", "αμ", "αιθ",
           "ανηκ", "δεσποζ", "ενδιαφερ", "δε", "δευτερευ", "καθαρευ", "πλε",
@@ -521,7 +521,7 @@
    return len;
   }
   
-  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβαστ", "πολυφ", "αδηφ", "παμφ", "ρ", "ασπ", "αφ", "αμαλ",
           "αμαλλι", "ανυστ", "απερ", "ασπαρ", "αχαρ", "δερβεν", "δροσοπ",
           "ξεφ", "νεοπ", "νομοτ", "ολοπ", "ομοτ", "προστ", "προσωποπ", "συμπ",
@@ -530,7 +530,7 @@
           "ουλαμ", "ουρ", "π", "τρ", "μ"), 
       false);
   
-  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ψοφ", "ναυλοχ"),
       false);
   
@@ -567,7 +567,7 @@
     return len;
   }
   
-  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "χερσον", "δωδεκαν", "ερημον", "μεγαλον", "επταν"),
       false);
   
@@ -587,7 +587,7 @@
     return len;
   }
   
-  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ασβ", "σβ", "αχρ", "χρ", "απλ", "αειμν", "δυσχρ", "ευχρ", "κοινοχρ", "παλιμψ"),
       false);
   
@@ -601,7 +601,7 @@
     return len;
   }
   
-  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "ρ", "σπι", "στραβομουτσ", "κακομουτσ", "εξων"),
       false);
   
@@ -625,7 +625,7 @@
     return len;
   }
   
-  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("παρασουσ", "φ", "χ", "ωριοπλ", "αζ", "αλλοσουσ", "ασουσ"),
       false);
   
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java	(working copy)
@@ -280,10 +280,7 @@
     DictEntry defaultEntry;
     DictEntry entry;
 
-    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(
-        Version.LUCENE_50, 1000, false);
-    
-    d = new CharArrayMap<DictEntry>(Version.LUCENE_50, 1000, false);
+    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(Version.LUCENE_CURRENT, 1000, false);
     for (int i = 0; i < exceptionWords.length; i++) {
       if (!d.containsKey(exceptionWords[i])) {
         entry = new DictEntry(exceptionWords[i], true);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java	(working copy)
@@ -34,7 +34,7 @@
   private final int recursionCap;
   private final HunspellDictionary dictionary;
   private final StringBuilder segment = new StringBuilder();
-  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_40);
+  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_CURRENT);
 
   /**
    * Constructs a new HunspellStemmer which will use the provided HunspellDictionary to create its stems. Uses the 
@@ -324,7 +324,8 @@
     InputStream affixInputStream = new FileInputStream(args[offset++]);
     InputStream dicInputStream = new FileInputStream(args[offset++]);
 
-    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_40, ignoreCase);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_50, ignoreCase);
 
     affixInputStream.close();
     dicInputStream.close();
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java	(working copy)
@@ -35,7 +35,7 @@
   private final PositionIncrementAttribute posIncAttribute =  addAttribute(PositionIncrementAttribute.class);
   
   // use a fixed version, as we don't care about case sensitivity.
-  private final CharArraySet previous = new CharArraySet(Version.LUCENE_50, 8, false);
+  private final CharArraySet previous = new CharArraySet(Version.LUCENE_CURRENT, 8, false);
 
   /**
    * Creates a new RemoveDuplicatesTokenFilter
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java	(working copy)
@@ -134,7 +134,7 @@
         if (!exceptions[i].endsWith(suffix))
           throw new RuntimeException("useless exception '" + exceptions[i] + "' does not end with '" + suffix + "'");
       }
-      this.exceptions = new CharArraySet(Version.LUCENE_50,
+      this.exceptions = new CharArraySet(Version.LUCENE_CURRENT,
            Arrays.asList(exceptions), false);
     }
 
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java	(revision 1548952)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java	(working copy)
@@ -133,8 +133,8 @@
       analyzer = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_50, reader) : factory.create(reader);
-          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_50, tokenizer) : tokenizer;
+          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_CURRENT, reader) : factory.create(reader);
+          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_CURRENT, tokenizer) : tokenizer;
           return new TokenStreamComponents(tokenizer, stream);
         }
       };
@@ -201,7 +201,7 @@
   private Analyzer loadAnalyzer(ResourceLoader loader, String cname) throws IOException {
     Class<? extends Analyzer> clazz = loader.findClass(cname, Analyzer.class);
     try {
-      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_50);
+      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_CURRENT);
       if (analyzer instanceof ResourceLoaderAware) {
         ((ResourceLoaderAware) analyzer).inform(loader);
       }
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java	(revision 1548952)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java	(working copy)
@@ -60,7 +60,7 @@
 
   public void testStopList() throws IOException {
     CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet("good", "test", "analyzer"), false);
-    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);
+    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);
     try (TokenStream stream = newStop.tokenStream("test", "This is a good test of the english stop analyzer")) {
       assertNotNull(stream);
       CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java	(revision 1548952)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java	(working copy)
@@ -94,7 +94,7 @@
   // LUCENE-3849: make sure after .end() we see the "ending" posInc
   public void testEndStopword() throws Exception {
     CharArraySet stopSet = StopFilter.makeStopSet(TEST_VERSION_CURRENT, "of");
-    StopFilter stpf = new StopFilter(Version.LUCENE_40, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
+    StopFilter stpf = new StopFilter(TEST_VERSION_CURRENT, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
     assertTokenStreamContents(stpf, new String[] { "test" },
                               new int[] {0},
                               new int[] {4},
Index: lucene/analysis/icu/src/java/overview.html
===================================================================
--- lucene/analysis/icu/src/java/overview.html	(revision 1548952)
+++ lucene/analysis/icu/src/java/overview.html	(working copy)
@@ -114,9 +114,9 @@
 <h3>Farsi Range Queries</h3>
 <pre class="prettyprint">
   Collator collator = Collator.getInstance(new ULocale("ar"));
-  ICUCollationKeyAnalyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+  ICUCollationKeyAnalyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_50, collator);
   RAMDirectory ramDir = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   Document doc = new Document();
   doc.add(new Field("content", "\u0633\u0627\u0628", 
                     Field.Store.YES, Field.Index.ANALYZED));
@@ -124,7 +124,7 @@
   writer.close();
   IndexSearcher is = new IndexSearcher(ramDir, true);
 
-  QueryParser aqp = new QueryParser(Version.LUCENE_40, "content", analyzer);
+  QueryParser aqp = new QueryParser(Version.LUCENE_50, "content", analyzer);
   aqp.setAnalyzeRangeTerms(true);
     
   // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
@@ -140,9 +140,9 @@
 <h3>Danish Sorting</h3>
 <pre class="prettyprint">
   Analyzer analyzer 
-    = new ICUCollationKeyAnalyzer(Version.LUCENE_40, Collator.getInstance(new ULocale("da", "dk")));
+    = new ICUCollationKeyAnalyzer(Version.LUCENE_50, Collator.getInstance(new ULocale("da", "dk")));
   RAMDirectory indexStore = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   String[] tracer = new String[] { "A", "B", "C", "D", "E" };
   String[] data = new String[] { "HAT", "HUT", "H\u00C5T", "H\u00D8T", "HOT" };
   String[] sortedTracerOrder = new String[] { "A", "E", "B", "D", "C" };
@@ -168,15 +168,15 @@
 <pre class="prettyprint">
   Collator collator = Collator.getInstance(new ULocale("tr", "TR"));
   collator.setStrength(Collator.PRIMARY);
-  Analyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+  Analyzer analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_50, collator);
   RAMDirectory ramDir = new RAMDirectory();
-  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_40, analyzer));
+  IndexWriter writer = new IndexWriter(ramDir, new IndexWriterConfig(Version.LUCENE_50, analyzer));
   Document doc = new Document();
   doc.add(new Field("contents", "DIGY", Field.Store.NO, Field.Index.ANALYZED));
   writer.addDocument(doc);
   writer.close();
   IndexSearcher is = new IndexSearcher(ramDir, true);
-  QueryParser parser = new QueryParser(Version.LUCENE_40, "contents", analyzer);
+  QueryParser parser = new QueryParser(Version.LUCENE_50, "contents", analyzer);
   Query query = parser.parse("d\u0131gy");   // U+0131: dotless i
   ScoreDoc[] result = is.search(query, null, 1000).scoreDocs;
   assertEquals("The index Term should be included.", 1, result.length);
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java	(revision 1548952)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java	(working copy)
@@ -97,7 +97,8 @@
   }
   
   public static IndexWriterConfig createWriterConfig(Config config, PerfRunData runData, OpenMode mode, IndexCommit commit) {
-    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_40.toString()));
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_50.toString()));
     IndexWriterConfig iwConf = new IndexWriterConfig(version, runData.getAnalyzer());
     iwConf.setOpenMode(mode);
     IndexDeletionPolicy indexDeletionPolicy = getIndexDeletionPolicy(config);
Index: lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
===================================================================
--- lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java	(revision 1548952)
+++ lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java	(working copy)
@@ -37,7 +37,8 @@
 
   private PerfRunData createPerfRunData(String infoStreamValue) throws Exception {
     Properties props = new Properties();
-    props.setProperty("writer.version", Version.LUCENE_40.toString());
+    // :Post-Release-Update-Version.LUCENE_XY:
+    props.setProperty("writer.version", Version.LUCENE_50.toString());
     props.setProperty("print.props", "false"); // don't print anything
     props.setProperty("directory", "RAMDirectory");
     if (infoStreamValue != null) {
Index: lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
===================================================================
--- lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java	(revision 1548952)
+++ lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java	(working copy)
@@ -69,6 +69,7 @@
                     Analyzer analyzer, String... fieldNames) throws IOException {
 
     // create IWs for train / test / cv IDXs
+    // :Post-Release-Update-Version.LUCENE_XY:
     IndexWriter testWriter = new IndexWriter(testIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter cvWriter = new IndexWriter(crossValidationIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter trainingWriter = new IndexWriter(trainingIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
Index: lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java	(revision 1548952)
+++ lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java	(working copy)
@@ -50,7 +50,7 @@
  * <pre class="prettyprint">
  *   Directory fsDir = FSDirectory.open(new File("/path/to/index"));
  *   NRTCachingDirectory cachedFSDir = new NRTCachingDirectory(fsDir, 5.0, 60.0);
- *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_32, analyzer);
+ *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_50, analyzer);
  *   IndexWriter writer = new IndexWriter(cachedFSDir, conf);
  * </pre>
  *
Index: lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java	(revision 1548952)
+++ lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java	(working copy)
@@ -217,7 +217,7 @@
     Directory directory = newDirectory();
     Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory, 
-        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));
     Document doc = new Document();
     doc.add(newTextField("field", "the stop words are here", Field.Store.YES));
     writer.addDocument(doc);
Index: lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java	(revision 1548952)
+++ lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java	(working copy)
@@ -86,8 +86,9 @@
       System.out.println("Indexing to directory '" + indexPath + "'...");
 
       Directory dir = FSDirectory.open(new File(indexPath));
-      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
-      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+      // :Post-Release-Update-Version.LUCENE_XY:
+      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
+      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_50, analyzer);
 
       if (create) {
         // Create a new index in the directory, removing any
Index: lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(revision 1548952)
+++ lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(working copy)
@@ -90,7 +90,8 @@
     
     IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));
     IndexSearcher searcher = new IndexSearcher(reader);
-    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
 
     BufferedReader in = null;
     if (queries != null) {
@@ -98,7 +99,8 @@
     } else {
       in = new BufferedReader(new InputStreamReader(System.in, "UTF-8"));
     }
-    QueryParser parser = new QueryParser(Version.LUCENE_40, field, analyzer);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    QueryParser parser = new QueryParser(Version.LUCENE_50, field, analyzer);
     while (true) {
       if (queries == null && queryString == null) {                        // prompt the user
         System.out.println("Enter query: ");
Index: lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java	(revision 1548952)
+++ lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java	(working copy)
@@ -25,7 +25,8 @@
  * @lucene.experimental
  */
 public interface FacetExamples {
-  
+
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** The Lucene {@link Version} used by the example code. */
   public static final Version EXAMPLES_VER = Version.LUCENE_50;
 
Index: lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(revision 1548952)
+++ lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java	(working copy)
@@ -133,7 +133,7 @@
   private void openExampleIndex() throws IOException {
     //Create a RAM-based index from our test data file
     RAMDirectory rd = new RAMDirectory();
-    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
     IndexWriter writer = new IndexWriter(rd, iwConfig);
     InputStream dataIn = getServletContext().getResourceAsStream("/WEB-INF/data.tsv");
     BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));
Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(revision 1548952)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(working copy)
@@ -299,7 +299,8 @@
   protected IndexWriterConfig createIndexWriterConfig(OpenMode openMode) {
     // TODO: should we use a more optimized Codec, e.g. Pulsing (or write custom)?
     // The taxonomy has a unique structure, where each term is associated with one document
- 
+
+    // :Post-Release-Update-Version.LUCENE_XY:
     // Make sure we use a MergePolicy which always merges adjacent segments and thus
     // keeps the doc IDs ordered as well (this is crucial for the taxonomy index).
     return new IndexWriterConfig(Version.LUCENE_50, null).setOpenMode(openMode).setMergePolicy(
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java	(revision 1548952)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java	(working copy)
@@ -65,7 +65,7 @@
     BufferedReader d = new BufferedReader(new InputStreamReader(
         TestParser.class.getResourceAsStream("reuters21578.txt"), "US-ASCII"));
     dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_40, analyzer));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     String line = d.readLine();
     while (line != null) {
       int endOfDate = line.indexOf('\t');
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java	(revision 1548952)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java	(working copy)
@@ -301,7 +301,7 @@
 
     Directory dir = FSDirectory.open(tempIndexPath);
 
-    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_46, indexAnalyzer);
+    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT, indexAnalyzer);
     iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);
     iwc.setRAMBufferSizeMB(ramBufferSizeMB);
     IndexWriter writer = new IndexWriter(dir, iwc);
Index: lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(revision 1548952)
+++ lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(working copy)
@@ -228,6 +228,7 @@
   // for all suites ever since.
   // -----------------------------------------------------------------
 
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** 
    * Use this constant when creating Analyzers and any other version-dependent stuff.
    * <p><b>NOTE:</b> Change this when development starts for new Lucene version:
Index: solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
===================================================================
--- solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java	(revision 1548952)
+++ solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java	(working copy)
@@ -187,8 +187,7 @@
       rbc.setVariableTop(variableTop);
     }
 
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
Index: solr/core/src/java/org/apache/solr/schema/CollationField.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/CollationField.java	(revision 1548952)
+++ solr/core/src/java/org/apache/solr/schema/CollationField.java	(working copy)
@@ -147,8 +147,7 @@
       else
         throw new SolrException(ErrorCode.SERVER_ERROR, "Invalid decomposition: " + decomposition);
     }
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new CollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new CollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
Index: solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
===================================================================
--- solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java	(revision 1548952)
+++ solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java	(working copy)
@@ -43,7 +43,7 @@
     //explicitly creates the temp dataDir so we know where the index will be located
     createTempDir();
 
-    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LUCENE_40, null);
+    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, null);
     Directory directory = newFSDirectory(new File(dataDir, "index"));
     //creates a new index on the known location
     new IndexWriter(
@@ -58,7 +58,7 @@
 
     Directory directory = newFSDirectory(new File(dataDir, "index"), new SimpleFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
@@ -84,7 +84,7 @@
     log.info("Acquiring lock on {}", indexDir.getAbsolutePath());
     Directory directory = newFSDirectory(indexDir, new NativeFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
Index: solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
===================================================================
--- solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(revision 1548952)
+++ solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java	(working copy)
@@ -118,7 +118,7 @@
     Directory dir = newFSDirectory(newDir);
     IndexWriter iw = new IndexWriter(
         dir,
-        new IndexWriterConfig(Version.LUCENE_40, new StandardAnalyzer(Version.LUCENE_40))
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))
     );
     Document doc = new Document();
     doc.add(new TextField("id", "2", Field.Store.YES));
Index: solr/core/src/test/org/apache/solr/search/TestStressLucene.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/TestStressLucene.java	(revision 1548952)
+++ solr/core/src/test/org/apache/solr/search/TestStressLucene.java	(working copy)
@@ -101,7 +101,7 @@
 
 
     // RAMDirectory dir = new RAMDirectory();
-    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(Version.LUCENE_40, new WhitespaceAnalyzer(Version.LUCENE_40)));
+    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));
 
     Directory dir = newDirectory();
 
Index: solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
===================================================================
--- solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java	(revision 1548952)
+++ solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java	(working copy)
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.Version;
+import org.apache.lucene.util.LuceneTestCase;
 
 import java.util.Collection;
 import java.util.HashSet;
@@ -41,7 +41,7 @@
   @Override
   public Collection<Token> convert(String origQuery) {
     Collection<Token> result = new HashSet<Token>();
-    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);
+    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);
     
     try (TokenStream ts = analyzer.tokenStream("", origQuery)) {
       // TODO: support custom attributes
