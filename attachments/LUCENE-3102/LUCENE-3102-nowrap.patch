Index: lucene/contrib/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
===================================================================
--- lucene/contrib/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java	(revision 1124269)
+++ lucene/contrib/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java	(working copy)
@@ -451,11 +451,20 @@
             System.out.println("TEST: maxCacheMB=" + maxCacheMB);
           }
 
+          boolean useWrappingCollector = random.nextBoolean();
           if (doAllGroups) {
-            cCache = CachingCollector.create(c1, true, maxCacheMB);
+            if (useWrappingCollector) {
+              cCache = CachingCollector.create(c1, true, maxCacheMB);              
+            } else {
+              cCache = CachingCollector.create(false, true, maxCacheMB);
+            }
             c = MultiCollector.wrap(cCache, groupCountCollector);
           } else {
-            c = cCache = CachingCollector.create(c1, true, maxCacheMB);
+            if (useWrappingCollector) {
+              c = cCache = CachingCollector.create(c1, true, maxCacheMB);              
+            } else {
+              c = cCache = CachingCollector.create(false, true, maxCacheMB);
+            }
           }
         } else if (doAllGroups) {
           c = MultiCollector.wrap(c1, groupCountCollector);
Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1124269)
+++ lucene/CHANGES.txt	(working copy)
@@ -50,7 +50,7 @@
   PathHierarchyTokenizer (Olivier Favre via ryan)
 
 * LUCENE-1421, LUCENE-3102: added CachingCollector which allow you to cache 
-  document IDs and scores encountered during the search, and "reply" them to 
+  document IDs and scores encountered during the search, and "replay" them to 
   another Collector. (Mike McCandless, Shai Erera)
   
 API Changes
Index: lucene/src/test/org/apache/lucene/search/TestCachingCollector.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestCachingCollector.java	(revision 1124269)
+++ lucene/src/test/org/apache/lucene/search/TestCachingCollector.java	(working copy)
@@ -171,5 +171,18 @@
       assertFalse(cc.isCached());
     }
   }
+
+  public void testNoWrappedCollector() throws Exception {
+    for (boolean cacheScores : new boolean[] { false, true }) {
+      // create w/ null wrapped collector, and test that the methods work
+      CachingCollector cc = CachingCollector.create(true, cacheScores, 50 * ONE_BYTE);
+      cc.setNextReader(null, 0);
+      cc.setScorer(new MockScorer());
+      cc.collect(0);
+      
+      assertTrue(cc.isCached());
+      cc.replay(new NoOpCollector(true));
+    }
+  }
   
 }
Index: lucene/src/java/org/apache/lucene/search/CachingCollector.java
===================================================================
--- lucene/src/java/org/apache/lucene/search/CachingCollector.java	(revision 1124269)
+++ lucene/src/java/org/apache/lucene/search/CachingCollector.java	(working copy)
@@ -310,6 +310,48 @@
   protected int base;
   protected int lastDocBase;
 
+  /**
+   * Creates a {@link CachingCollector} which does not wrap another collector.
+   * The cached documents and scores can later be {@link #replay(Collector)
+   * replayed}.
+   * 
+   * @param acceptDocsOutOfOrder
+   *          whether documents are allowed to be collected out-of-order
+   */
+  public static CachingCollector create(final boolean acceptDocsOutOfOrder, boolean cacheScores, double maxRAMMB) {
+    Collector other = new Collector() {
+      @Override
+      public boolean acceptsDocsOutOfOrder() {
+        return acceptDocsOutOfOrder;
+      }
+      
+      @Override
+      public void setScorer(Scorer scorer) throws IOException {}
+
+      @Override
+      public void collect(int doc) throws IOException {}
+
+      @Override
+      public void setNextReader(IndexReader reader, int docBase) throws IOException {}
+
+    };
+    return create(other, cacheScores, maxRAMMB);
+  }
+
+  /**
+   * Create a new {@link CachingCollector} that wraps the given collector and
+   * caches documents and scores up to the specified RAM threshold.
+   * 
+   * @param other
+   *          the Collector to wrap and delegate calls to.
+   * @param cacheScores
+   *          whether to cache scores in addition to document IDs. Note that
+   *          this increases the RAM consumed per doc
+   * @param maxRAMMB
+   *          the maximum RAM in MB to consume for caching the documents and
+   *          scores. If the collector exceeds the threshold, no documents and
+   *          scores are cached.
+   */
   public static CachingCollector create(Collector other, boolean cacheScores, double maxRAMMB) {
     return cacheScores ? new ScoreCachingCollector(other, maxRAMMB) : new NoScoreCachingCollector(other, maxRAMMB);
   }
