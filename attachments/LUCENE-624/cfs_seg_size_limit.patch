Index: java/org/apache/lucene/index/IndexModifier.java
===================================================================
--- java/org/apache/lucene/index/IndexModifier.java	(revision 425796)
+++ java/org/apache/lucene/index/IndexModifier.java	(working copy)
@@ -95,6 +95,7 @@
   // Lucene defaults:
   protected PrintStream infoStream = null;
   protected boolean useCompoundFile = true;
+  protected int compoundFileSegmentSizeLimit = IndexWriter.DEFAULT_COMPOUND_FILE_SEGMENT_SIZE_LIMIT;
   protected int maxBufferedDocs = IndexWriter.DEFAULT_MAX_BUFFERED_DOCS;
   protected int maxFieldLength = IndexWriter.DEFAULT_MAX_FIELD_LENGTH;
   protected int mergeFactor = IndexWriter.DEFAULT_MERGE_FACTOR;
@@ -173,6 +174,7 @@
       indexWriter = new IndexWriter(directory, analyzer, false);
       indexWriter.setInfoStream(infoStream);
       indexWriter.setUseCompoundFile(useCompoundFile);
+      indexWriter.setCompoundFileSegmentSizeLimit(compoundFileSegmentSizeLimit);
       indexWriter.setMaxBufferedDocs(maxBufferedDocs);
       indexWriter.setMaxFieldLength(maxFieldLength);
       indexWriter.setMergeFactor(mergeFactor);
@@ -363,7 +365,37 @@
     }
   }
 
+  /** Sets the limit of documents a segment can have, so that
+   *  compound format is being used for that segment. A high
+   *  limit will decrease the number of files per index, whereas
+   *  a lower limit will improve search performance but 
+   *  increase the number of files.
+   *  @see IndexWriter#setCompoundFileSegmentSizeLimit(int)
+   *  @throws IllegalStateException if the index is closed
+   */
+  public void setCompoundFileSegmentSizeLimit(int compoundFileSegmentSizeLimit) {
+    synchronized(directory) {
+      assureOpen();
+      if (indexWriter != null) {
+        indexWriter.setCompoundFileSegmentSizeLimit(compoundFileSegmentSizeLimit);
+      }
+      this.compoundFileSegmentSizeLimit = compoundFileSegmentSizeLimit;    
+    }
+  }
+    
   /**
+   * @throws IOException
+   * @see IndexModifier#setCompoundFileSegmentSizeLimit(int)
+   */
+  public int getCompoundFileSegmentSizeLimit() throws IOException {
+    synchronized(directory) {
+        assureOpen();
+        createIndexWriter();
+        return indexWriter.getCompoundFileSegmentSizeLimit();
+    }
+  }
+  
+  /**
    * The maximum number of terms that will be indexed for a single field in a
    * document.  This limits the amount of memory required for indexing, so that
    * collections with very large files will not crash the indexing process by
Index: java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- java/org/apache/lucene/index/IndexWriter.java	(revision 425796)
+++ java/org/apache/lucene/index/IndexWriter.java	(working copy)
@@ -102,6 +102,11 @@
    */
   public final static int DEFAULT_TERM_INDEX_INTERVAL = 128;
   
+  /**
+   * Default value is {@link Integer#MAX_VALUE}. Change using {@link #setCompoundFileSegmentSizeLimit(int)}.
+   */
+  public final static int DEFAULT_COMPOUND_FILE_SEGMENT_SIZE_LIMIT = Integer.MAX_VALUE;
+  
   private Directory directory;  // where this index resides
   private Analyzer analyzer;    // how to analyze text
 
@@ -120,6 +125,11 @@
    */
   private boolean useCompoundFile = true;
   
+  /** A high value results in a small number of segment files, whereas a small
+   *  value results in more files but better performance.
+   */ 
+  private int compoundFileSegmentSizeLimit = DEFAULT_COMPOUND_FILE_SEGMENT_SIZE_LIMIT;
+  
   private boolean closeDir;
 
   /** Get the current setting of whether to use the compound file format.
@@ -138,6 +148,25 @@
   public void setUseCompoundFile(boolean value) {
     useCompoundFile = value;
   }
+  
+  /** Get the current value of the compound file segment size limit.
+   *  Note that this just returns the value you set with setCompoundFileSegmentSizeLimit(int)
+   *  or the default. You cannot use this to query the status of an existing index.
+   *  @see #setCompoundFileSegmentSizeLimit(int)
+   */
+  public int getCompoundFileSegmentSizeLimit() {
+    return compoundFileSegmentSizeLimit;
+  }
+    
+  /** Sets the limit of documents a segment can have, so that
+   *  compound format is being used for that segment. A high
+   *  limit will decrease the number of files per index, whereas
+   *  a lower limit will improve search performance but 
+   *  increase the number of files.
+   */
+  public void setCompoundFileSegmentSizeLimit(int value) {
+    this.compoundFileSegmentSizeLimit = value;
+  }
 
   /** Expert: Set the Similarity implementation used by this IndexWriter.
    *
@@ -570,6 +599,7 @@
             (SegmentReader.hasDeletions(segmentInfos.info(0)) ||
              segmentInfos.info(0).dir != directory ||
              (useCompoundFile &&
+              segmentInfos.info(0).docCount <= compoundFileSegmentSizeLimit &&       
               (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||
                 SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {
       int minSegment = segmentInfos.size() - mergeFactor;
@@ -654,7 +684,7 @@
     
     deleteSegments(segmentsToDelete);  // delete now-unused segments
 
-    if (useCompoundFile) {
+    if (useCompoundFile && docCount <= compoundFileSegmentSizeLimit) {
       final Vector filesToDelete = merger.createCompoundFile(mergedName + ".tmp");
       synchronized (directory) { // in- & inter-process sync
         new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
@@ -764,7 +794,7 @@
     
     deleteSegments(segmentsToDelete);  // delete now-unused segments
 
-    if (useCompoundFile) {
+    if (useCompoundFile && mergedDocCount <= compoundFileSegmentSizeLimit) {
       final Vector filesToDelete = merger.createCompoundFile(mergedName + ".tmp");
       synchronized (directory) { // in- & inter-process sync
         new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
