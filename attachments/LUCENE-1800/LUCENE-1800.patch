Index: src/java/org/apache/lucene/queryParser/QueryParser.java
===================================================================
--- src/java/org/apache/lucene/queryParser/QueryParser.java	(revision 803082)
+++ src/java/org/apache/lucene/queryParser/QueryParser.java	(working copy)
@@ -537,7 +537,13 @@
     // Use the analyzer to get all the tokens, and then build a TermQuery,
     // PhraseQuery, or nothing based on the term count
 
-    TokenStream source = analyzer.tokenStream(field, new StringReader(queryText));
+    TokenStream source;
+    try {
+      source = analyzer.reusableTokenStream(field, new StringReader(queryText));
+      source.reset();
+    } catch (IOException e) {
+      source = analyzer.tokenStream(field, new StringReader(queryText));
+    }
     CachingTokenFilter buffer = new CachingTokenFilter(source);
     TermAttribute termAtt = null;
     PositionIncrementAttribute posIncrAtt = null;
Index: src/java/org/apache/lucene/queryParser/QueryParser.jj
===================================================================
--- src/java/org/apache/lucene/queryParser/QueryParser.jj	(revision 803082)
+++ src/java/org/apache/lucene/queryParser/QueryParser.jj	(working copy)
@@ -562,7 +562,13 @@
     // Use the analyzer to get all the tokens, and then build a TermQuery,
     // PhraseQuery, or nothing based on the term count
 
-    TokenStream source = analyzer.tokenStream(field, new StringReader(queryText));
+    TokenStream source;
+    try {
+      source = analyzer.reusableTokenStream(field, new StringReader(queryText));
+      source.reset();
+    } catch (IOException e) {
+      source = analyzer.tokenStream(field, new StringReader(queryText));
+    }
     CachingTokenFilter buffer = new CachingTokenFilter(source);
     TermAttribute termAtt = null;
     PositionIncrementAttribute posIncrAtt = null;
