Index: lucene/core/src/java/org/apache/lucene/index/DocInverterPerField.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocInverterPerField.java	(revision 1579114)
+++ lucene/core/src/java/org/apache/lucene/index/DocInverterPerField.java	(working copy)
@@ -83,8 +83,8 @@
         }
         
         // only bother checking offsets if something will consume them.
-        // TODO: after we fix analyzers, also check if termVectorOffsets will be indexed.
-        final boolean checkOffsets = fieldType.indexOptions() == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;
+        final boolean checkOffsets = fieldType.indexOptions() == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS ||
+                                     fieldType.storeTermVectorOffsets();
         int lastStartOffset = 0;
 
         if (i > 0) {
Index: lucene/core/src/test/org/apache/lucene/index/TestCheckIndex.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestCheckIndex.java	(revision 1579114)
+++ lucene/core/src/test/org/apache/lucene/index/TestCheckIndex.java	(working copy)
@@ -95,22 +95,4 @@
     assertTrue(checker.checkIndex(onlySegments).clean == true);
     dir.close();
   }
-  
-  // LUCENE-4221: we have to let these thru, for now
-  public void testBogusTermVectors() throws IOException {
-    Directory dir = newDirectory();
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));
-    Document doc = new Document();
-    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
-    ft.setStoreTermVectors(true);
-    ft.setStoreTermVectorOffsets(true);
-    Field field = new Field("foo", "", ft);
-    field.setTokenStream(new CannedTokenStream(
-        new Token("bar", 5, 10), new Token("bar", 1, 4)
-    ));
-    doc.add(field);
-    iw.addDocument(doc);
-    iw.close();
-    dir.close(); // checkindex
-  }
 }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1579114)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -1930,5 +1930,29 @@
 
     dir.close();
   }
+  
+  public void testBogusTermVectors() throws IOException {
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));
+    Document doc = new Document();
+    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorOffsets(true);
+    Field field = new Field("foo", "", ft);
+    field.setTokenStream(new CannedTokenStream(
+        new Token("bar", 5, 10), new Token("bar", 1, 4)
+    ));
+    doc.add(field);
+    iw.addDocument(new Document()); // an ok empty doc
+    try {
+      iw.addDocument(doc);
+      fail();
+    } catch (IllegalArgumentException expected) {}
+    iw.close();
+    DirectoryReader ir = DirectoryReader.open(dir);
+    assertEquals(1, ir.numDocs());
+    ir.close();
+    dir.close();
+  }
 
 }
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java	(revision 1579114)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java	(working copy)
@@ -201,10 +201,6 @@
     int i = 0;
 
     protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes) {
-      this(len, sampleTerms, sampleTermBytes, rarely());
-    }
-
-    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {
       terms = new String[len];
       termBytes = new BytesRef[len];
       positionsIncrements = new int[len];
@@ -217,17 +213,12 @@
         terms[i] = sampleTerms[o];
         termBytes[i] = sampleTermBytes[o];
         positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);
-        if (offsetsGoBackwards) {
-          startOffsets[i] = random().nextInt();
-          endOffsets[i] = random().nextInt();
+        if (i == 0) {
+          startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);
         } else {
-          if (i == 0) {
-            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);
-          } else {
-            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);
-          }
-          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);
+          startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);
         }
+        endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);
       }
 
       for (int i = 0; i < len; ++i) {
