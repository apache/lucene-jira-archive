diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter.java
index 730d00ac0a..8b6ecb754b 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter.java
@@ -21,6 +21,8 @@ import java.io.IOException;
 import java.io.StringReader;
 import java.text.ParseException;
 import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Locale;
@@ -28,12 +30,15 @@ import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockGraphTokenFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.TokenStreamToAutomaton;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.FlattenGraphFilter;
+import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.tokenattributes.*;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -1929,6 +1934,32 @@ public class TestSynonymGraphFilter extends BaseTokenStreamTestCase {
     assertMapping("word".toUpperCase(Locale.ROOT), "synonym");
   }
 
+  public void testLeadingStopwordSynonymGraph() throws Exception {
+    SynonymMap.Builder builder = new SynonymMap.Builder(true);
+    builder.add(new CharsRef("twd"), new CharsRef("the\u0000walking\u0000dead"), true);
+    builder.add(new CharsRef("twd"), new CharsRef("the\u0000zombie\u0000show"), false);
+    final SynonymMap synonymMap = builder.build();
+
+    Analyzer analyzer = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        MockTokenizer tokenizer = new MockTokenizer();
+        TokenStream stream = new SynonymGraphFilter(tokenizer, synonymMap, true);
+        stream = new StopFilter(stream, CharArraySet.copy(Collections.singleton("the")));
+        return new TokenStreamComponents(tokenizer, stream);
+      }
+    };
+    TokenStream tokenStream = analyzer.tokenStream("field", "twd");
+      assertTokenStreamContents(tokenStream,
+        new String[] { "twd", "walking", "dead", "zombie", "show" },
+        null, null,
+        new int[]    { 1,     1,         1,         1,      1},  // posinc
+        new int[]    { 5,     1,         3,         1,      1},  // poslen
+        null);
+    TokenStreamToAutomaton aut = new TokenStreamToAutomaton();
+    System.out.println(aut.toAutomaton(analyzer.tokenStream("field", "twd")).toDot());
+  }
+
   private void assertMapping(String inputString, String outputString) throws IOException {
     SynonymMap.Builder builder = new SynonymMap.Builder(false);
     // the rules must be lowercased up front, but the incoming tokens will be case insensitive:
