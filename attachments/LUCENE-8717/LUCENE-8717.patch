diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/FlattenGraphFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/FlattenGraphFilter.java
index 01e1f6f7df..916ef3d9ca 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/FlattenGraphFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/FlattenGraphFilter.java
@@ -27,6 +27,7 @@ import org.apache.lucene.analysis.synonym.SynonymGraphFilter;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermDeletedAttribute;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.RollingBuffer;
 
@@ -129,6 +130,7 @@ public final class FlattenGraphFilter extends TokenFilter {
   private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
   private final PositionLengthAttribute posLenAtt = addAttribute(PositionLengthAttribute.class);
   private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+  private final TermDeletedAttribute deletedAtt = addAttribute(TermDeletedAttribute.class);
 
   /** Which input node the last seen token leaves from */
   private int inputFrom;
@@ -259,6 +261,12 @@ public final class FlattenGraphFilter extends TokenFilter {
         //retOutputFrom += posIncAtt.getPositionIncrement();
         //System.out.println("    return buffered: " + termAtt + " " + retOutputFrom + "-" + (retOutputFrom + posLenAtt.getPositionLength()));
         //printStates();
+        if (deletedAtt.isDeleted()) {
+          // This token remains in the TokenStream because it's required to preserve the graph structure,
+          // but it shouldn't be indexed; seeing as we're flattening out the graph here it's unnecessary,
+          // so we just skip over it
+          continue;
+        }
         return true;
       } else if (done) {
         //System.out.println("    done, return false");
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFlattenGraphFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFlattenGraphFilter.java
index c69bcca9cf..9726088516 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFlattenGraphFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFlattenGraphFilter.java
@@ -34,6 +34,12 @@ public class TestFlattenGraphFilter extends BaseTokenStreamTestCase {
     return t;
   }
 
+  private static Token token(String term, int posInc, int posLength, boolean deleted) {
+    final Token t = new Token(term, posInc, 0, 1, posLength);
+    t.setDeleted(deleted);
+    return t;
+  }
+
   public void testSimpleMock() throws Exception {
     Analyzer a = new Analyzer() {
         @Override
@@ -228,6 +234,27 @@ public class TestFlattenGraphFilter extends BaseTokenStreamTestCase {
                               12);
   }
 
+  public void testHoleAtArticulationPoint() throws Exception {
+    // Tests a StopFilter after SynFilter where the first word in a multi-term synonym
+    // is removed
+    //
+    // the walking dead -> twd, but then 'the' becomes a hole
+
+    TokenStream in = new CannedTokenStream(
+        token("twd", 1, 3, false),
+        token("the", 0, 1, true),
+        token("walking", 1, 1, false),
+        token("dead", 1, 1, false)
+    );
+
+    TokenStream out = new FlattenGraphFilter(in);
+    assertTokenStreamContents(out,
+        new String[] {"twd", "walking", "dead"},
+        new int[]{ 0, 0, 0 },
+        new int[]{ 1, 1, 1 },
+        new int[]{ 1, 1, 1 });
+  }
+
   public void testStrangelyNumberedNodes() throws Exception {
 
     // Uses only nodes 0, 2, 3, i.e. 1 is just never used (it is not a hole!!)
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/FixedShingleFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/FixedShingleFilterTest.java
index 85c7dc6d14..8ca4f9daf3 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/FixedShingleFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/FixedShingleFilterTest.java
@@ -199,6 +199,29 @@ public class FixedShingleFilterTest extends BaseTokenStreamTestCase {
           new int[] {    1,        0,      0,       0,       1,        0,     });
   }
 
+  private static Token delete(Token token) {
+    token.setDeleted(true);
+    return token;
+  }
+
+  public void testShinglesOverStopWordsAtArticulationPoints() throws IOException {
+
+    // watch tyd:3/[] walking dead right now
+    TokenStream ts = new CannedTokenStream(
+        new Token("watch", 0, 1),
+        new Token("tyd", 1, 2, 3, 3),
+        delete(new Token("the", 0, 2, 3)),
+        new Token("walking", 2, 3),
+        new Token("dead", 2, 3),
+        new Token("right", 4, 5),
+        new Token("now", 6, 7)
+    );
+
+    assertTokenStreamContents(new FixedShingleFilter(ts, 3),
+        new String[] { "watch tyd right", "watch _ walking", "tyd right now", "walking dead right", "dead right now"});
+
+  }
+
   public void testParameterLimits() {
     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> {
       new FixedShingleFilter(new CannedTokenStream(), 1);
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/FilteringTokenFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/FilteringTokenFilter.java
index e942224056..d538128a3b 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/FilteringTokenFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/FilteringTokenFilter.java
@@ -20,6 +20,7 @@ package org.apache.lucene.analysis;
 import java.io.IOException;
 
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermDeletedAttribute;
 
 /**
  * Abstract base class for TokenFilters that may remove tokens.
@@ -27,9 +28,10 @@ import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
  * token should be preserved. {@link #incrementToken} uses this method
  * to decide if a token should be passed to the caller.
  */
-public abstract class FilteringTokenFilter extends TokenFilter {
+public abstract class FilteringTokenFilter extends GraphTokenFilter {
 
   private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+  private final TermDeletedAttribute deletedAtt = addAttribute(TermDeletedAttribute.class);
   private int skippedPositions;
 
   /**
@@ -45,14 +47,25 @@ public abstract class FilteringTokenFilter extends TokenFilter {
 
   @Override
   public final boolean incrementToken() throws IOException {
+
     skippedPositions = 0;
-    while (input.incrementToken()) {
+    while (incrementBaseToken()) {
       if (accept()) {
         if (skippedPositions != 0) {
           posIncrAtt.setPositionIncrement(posIncrAtt.getPositionIncrement() + skippedPositions);
         }
         return true;
       }
+      if (atArticulationPoint()) {
+        // deleted tokens at points where the token graph diverges cannot just be removed from
+        // the token stream, as this breaks the graph.  Instead, we mark them as deleted with
+        // a special attribute
+        if (skippedPositions != 0) {
+          posIncrAtt.setPositionIncrement(posIncrAtt.getPositionIncrement() + skippedPositions);
+        }
+        deletedAtt.setDeleted(true);
+        return true;
+      }
       skippedPositions += posIncrAtt.getPositionIncrement();
     }
 
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/GraphTokenFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/GraphTokenFilter.java
index 9c1e02e8c4..3c2188a5d2 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/GraphTokenFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/GraphTokenFilter.java
@@ -26,6 +26,7 @@ import java.util.List;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermDeletedAttribute;
 import org.apache.lucene.util.AttributeSource;
 
 /**
@@ -90,9 +91,15 @@ public abstract class GraphTokenFilter extends TokenFilter {
     if (baseToken == null) {
       return false;
     }
+    if (baseToken.deleted()) {
+      baseToken = nextTokenInGraph(baseToken);
+    }
+    if (baseToken == null) {
+      return false;
+    }
     currentGraph.clear();
     currentGraph.add(baseToken);
-    baseToken.attSource.copyTo(this);
+    baseToken.copyTo(this);
     recycleToken(oldBase);
     return true;
   }
@@ -105,7 +112,7 @@ public abstract class GraphTokenFilter extends TokenFilter {
   protected final boolean incrementGraphToken() throws IOException {
     if (graphPos < graphDepth) {
       graphPos++;
-      currentGraph.get(graphPos).attSource.copyTo(this);
+      currentGraph.get(graphPos).copyTo(this);
       return true;
     }
     Token token = nextTokenInGraph(currentGraph.get(graphDepth));
@@ -115,7 +122,7 @@ public abstract class GraphTokenFilter extends TokenFilter {
     graphDepth++;
     graphPos++;
     currentGraph.add(graphDepth, token);
-    token.attSource.copyTo(this);
+    token.copyTo(this);
     return true;
   }
 
@@ -131,14 +138,19 @@ public abstract class GraphTokenFilter extends TokenFilter {
     graphPos = 0;
     for (int i = graphDepth; i >= 1; i--) {
       if (lastInStack(currentGraph.get(i)) == false) {
-        currentGraph.set(i, nextTokenInStream(currentGraph.get(i)));
-        for (int j = i + 1; j < graphDepth; j++) {
-          currentGraph.set(j, nextTokenInGraph(currentGraph.get(j)));
+        Token nextToken = nextTokenInStream(currentGraph.get(i));
+        assert nextToken != null;
+        while (nextToken.deleted()) {
+          nextToken = nextTokenInGraph(nextToken);
+          if (nextToken == null) {
+            return false;
+          }
         }
+        currentGraph.set(i, nextToken);
         if (stackSize++ > MAX_GRAPH_STACK_SIZE) {
           throw new IllegalStateException("Too many graph paths (> " + MAX_GRAPH_STACK_SIZE + ")");
         }
-        currentGraph.get(0).attSource.copyTo(this);
+        currentGraph.get(0).copyTo(this);
         graphDepth = i;
         return true;
       }
@@ -146,6 +158,17 @@ public abstract class GraphTokenFilter extends TokenFilter {
     return false;
   }
 
+  /**
+   * {@code true} if the current point in the token stream has paths of different
+   * lengths leaving it.
+   *
+   * Note that simple stacked tokens (eg one-word synonyms) are not considered an
+   * articulation point
+   */
+  protected final boolean atArticulationPoint() throws IOException {
+    return isArticulationPoint(currentGraph.get(graphPos));
+  }
+
   /**
    * Return the number of trailing positions at the end of the graph
    *
@@ -208,16 +231,46 @@ public abstract class GraphTokenFilter extends TokenFilter {
 
   private Token nextTokenInGraph(Token token) throws IOException {
     int remaining = token.length();
+    int deletedPosCount = 0;
+    if (token.deleted()) {
+      deletedPosCount = remaining;
+    }
     do {
-      token = nextTokenInStream(token);
-      if (token == null) {
-        return null;
+      do {
+        token = nextTokenInStream(token);
+        if (token == null) {
+          return null;
+        }
+        remaining -= token.posInc();
+      }
+      while (remaining > 0);
+      if (token.deleted()) {
+        deletedPosCount += token.length();
       }
-      remaining -= token.posInc();
-    } while (remaining > 0);
+    }
+    while (token.deleted());
+    if (deletedPosCount > 0) {
+      token.deletedPositions = deletedPosCount;
+    }
     return token;
   }
 
+  private boolean isArticulationPoint(Token token) throws IOException {
+    // we are at an articulation point if any token at the current position has
+    // a position increment > 1
+    State state = captureState();
+    do {
+      if (token.length() > 1) {
+        restoreState(state);
+        return true;
+      }
+      token = nextTokenInStream(token);
+    }
+    while (token != null && token.posInc() == 0);
+    restoreState(state);
+    return false;
+  }
+
   // check if the next token in the tokenstream is at the same position as this one
   private boolean lastInStack(Token token) throws IOException {
     Token next = nextTokenInStream(token);
@@ -250,13 +303,16 @@ public abstract class GraphTokenFilter extends TokenFilter {
     final AttributeSource attSource;
     final PositionIncrementAttribute posIncAtt;
     final PositionLengthAttribute lengthAtt;
+    final TermDeletedAttribute deletedAtt;
     Token nextToken;
+    int deletedPositions;
 
     Token(AttributeSource attSource) {
       this.attSource = attSource;
       this.posIncAtt = attSource.addAttribute(PositionIncrementAttribute.class);
       boolean hasLengthAtt = attSource.hasAttribute(PositionLengthAttribute.class);
       this.lengthAtt = hasLengthAtt ? attSource.addAttribute(PositionLengthAttribute.class) : null;
+      this.deletedAtt = attSource.addAttribute(TermDeletedAttribute.class);
     }
 
     int posInc() {
@@ -270,9 +326,22 @@ public abstract class GraphTokenFilter extends TokenFilter {
       return this.lengthAtt.getPositionLength();
     }
 
+    boolean deleted() {
+      return this.deletedAtt.isDeleted();
+    }
+
     void reset(AttributeSource attSource) {
       attSource.copyTo(this.attSource);
       this.nextToken = null;
+      this.deletedPositions = 0;
+    }
+
+    void copyTo(AttributeSource target) {
+      this.attSource.copyTo(target);
+      if (this.deletedPositions > 0) {
+        PositionIncrementAttribute p = target.getAttribute(PositionIncrementAttribute.class);
+        p.setPositionIncrement(p.getPositionIncrement() + this.deletedPositions);
+      }
     }
 
     @Override
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PackedTokenAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PackedTokenAttributeImpl.java
index 449ab3e20b..fdc62ed9f3 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PackedTokenAttributeImpl.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/PackedTokenAttributeImpl.java
@@ -17,6 +17,8 @@
 package org.apache.lucene.analysis.tokenattributes;
 
 
+import java.util.Objects;
+
 import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.AttributeReflector;
 
@@ -31,13 +33,14 @@ import org.apache.lucene.util.AttributeReflector;
 public class PackedTokenAttributeImpl extends CharTermAttributeImpl 
                    implements TypeAttribute, PositionIncrementAttribute,
                               PositionLengthAttribute, OffsetAttribute,
-                              TermFrequencyAttribute {
+                              TermFrequencyAttribute, TermDeletedAttribute {
 
   private int startOffset,endOffset;
   private String type = DEFAULT_TYPE;
   private int positionIncrement = 1;
   private int positionLength = 1;
   private int termFrequency = 1;
+  private boolean deleted = false;
 
   /** Constructs the attribute implementation. */
   public PackedTokenAttributeImpl() {
@@ -148,6 +151,16 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
     return termFrequency;
   }
 
+  @Override
+  public boolean isDeleted() {
+    return deleted;
+  }
+
+  @Override
+  public void setDeleted(boolean isDeleted) {
+    this.deleted = isDeleted;
+  }
+
   /** Resets the attributes
    */
   @Override
@@ -157,6 +170,7 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
     termFrequency = 1;
     startOffset = endOffset = 0;
     type = DEFAULT_TYPE;
+    deleted = false;
   }
   
   /** Resets the attributes at end
@@ -186,6 +200,7 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
           positionLength == other.positionLength &&
           (type == null ? other.type == null : type.equals(other.type)) &&
           termFrequency == other.termFrequency &&
+          deleted == other.deleted &&
           super.equals(obj)
       );
     } else
@@ -201,7 +216,8 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
     code = code * 31 + positionLength;
     if (type != null)
       code = code * 31 + type.hashCode();
-    code = code * 31 + termFrequency;;
+    code = code * 31 + termFrequency;
+    code = code * Objects.hashCode(deleted);
     return code;
   }
 
@@ -216,6 +232,7 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
       to.endOffset = endOffset;
       to.type = type;
       to.termFrequency = termFrequency;
+      to.deleted = deleted;
     } else {
       super.copyTo(target);
       ((OffsetAttribute) target).setOffset(startOffset, endOffset);
@@ -223,6 +240,7 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
       ((PositionLengthAttribute) target).setPositionLength(positionLength);
       ((TypeAttribute) target).setType(type);
       ((TermFrequencyAttribute) target).setTermFrequency(termFrequency);
+      ((TermDeletedAttribute) target).setDeleted(deleted);
     }
   }
 
@@ -235,5 +253,7 @@ public class PackedTokenAttributeImpl extends CharTermAttributeImpl
     reflector.reflect(PositionLengthAttribute.class, "positionLength", positionLength);
     reflector.reflect(TypeAttribute.class, "type", type);
     reflector.reflect(TermFrequencyAttribute.class, "termFrequency", termFrequency);
+    reflector.reflect(TermDeletedAttribute.class, "isDeleted", deleted);
   }
+
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttribute.java
new file mode 100644
index 0000000000..f41dcc6e6c
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttribute.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.tokenattributes;
+
+import org.apache.lucene.util.Attribute;
+
+/**
+ * Marks whether or not a token should be removed from the TokenStream
+ *
+ * Used in token graphs when a token cannot be completely removed from
+ * the underlying TokenStream because it is at an articulation point
+ */
+public interface TermDeletedAttribute extends Attribute {
+
+  /** Whether or not this token has been deleted */
+  public boolean isDeleted();
+
+  /** Set whether or not the token should be deleted */
+  public void setDeleted(boolean isDeleted);
+
+}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttributeImpl.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttributeImpl.java
new file mode 100644
index 0000000000..15c82e279f
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/TermDeletedAttributeImpl.java
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.tokenattributes;
+
+import java.util.Objects;
+
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+
+/** Default implementation of {@link org.apache.lucene.analysis.tokenattributes.TermDeletedAttribute} */
+public class TermDeletedAttributeImpl extends AttributeImpl implements TermDeletedAttribute {
+
+  private boolean deleted;
+
+  @Override
+  public boolean isDeleted() {
+    return deleted;
+  }
+
+  @Override
+  public void setDeleted(boolean isDeleted) {
+    deleted = isDeleted;
+  }
+
+  @Override
+  public void clear() {
+    deleted = false;
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o) return true;
+    if (o == null || getClass() != o.getClass()) return false;
+    TermDeletedAttributeImpl that = (TermDeletedAttributeImpl) o;
+    return deleted == that.deleted;
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(deleted);
+  }
+
+  @Override
+  public void reflectWith(AttributeReflector reflector) {
+    reflector.reflect(TermDeletedAttribute.class, "isDeleted", deleted);
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    TermDeletedAttribute t = (TermDeletedAttribute) target;
+    t.setDeleted(isDeleted());
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java b/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
index b6a99958e6..1048243aec 100644
--- a/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
+++ b/lucene/core/src/java/org/apache/lucene/util/graph/GraphTokenStreamFiniteStrings.java
@@ -28,11 +28,12 @@ import java.util.List;
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.BytesTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermDeletedAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.automaton.Automaton;
@@ -48,19 +49,21 @@ import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZ
  * This class also provides helpers to explore the different paths of the {@link Automaton}.
  */
 public final class GraphTokenStreamFiniteStrings {
-  private final Map<Integer, BytesRef> idToTerm = new HashMap<>();
-  private final Map<Integer, Integer> idToInc = new HashMap<>();
+  private final Map<Integer, AttributeSource.State> idToState = new HashMap<>();
+  private final AttributeSource extractor;
   private final Automaton det;
   private final Transition transition = new Transition();
 
   private class FiniteStringsTokenStream extends TokenStream {
-    private final BytesTermAttribute termAtt = addAttribute(BytesTermAttribute.class);
-    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
     private final IntsRef ids;
     private final int end;
+    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+    private final TermDeletedAttribute deletedAtt = addAttribute(TermDeletedAttribute.class);
     private int offset;
+    private int gap;
 
     FiniteStringsTokenStream(final IntsRef ids) {
+      super(extractor.cloneAttributes());
       assert ids != null;
       this.ids = ids;
       this.offset = ids.offset;
@@ -69,17 +72,17 @@ public final class GraphTokenStreamFiniteStrings {
 
     @Override
     public boolean incrementToken() throws IOException {
-      if (offset < end) {
+      while (offset < end) {
         clearAttributes();
         int id = ids.ints[offset];
-        termAtt.setBytesRef(idToTerm.get(id));
-
-        int incr = 1;
-        if (idToInc.containsKey(id)) {
-          incr = idToInc.get(id);
-        }
-        posIncAtt.setPositionIncrement(incr);
+        restoreState(idToState.get(id));
         offset++;
+        if (deletedAtt.isDeleted()) {
+          gap += posIncAtt.getPositionIncrement();
+          continue;
+        }
+        posIncAtt.setPositionIncrement(posIncAtt.getPositionIncrement() + gap);
+        gap = 0;
         return true;
       }
 
@@ -90,6 +93,7 @@ public final class GraphTokenStreamFiniteStrings {
   public GraphTokenStreamFiniteStrings(TokenStream in) throws IOException {
     Automaton aut = build(in);
     this.det = Operations.removeDeadStates(Operations.determinize(aut, DEFAULT_MAX_DETERMINIZED_STATES));
+    this.extractor = in.cloneAttributes();
   }
 
   /**
@@ -115,12 +119,14 @@ public final class GraphTokenStreamFiniteStrings {
    * Returns the list of terms that start at the provided state
    */
   public Term[] getTerms(String field, int state) {
+    TermToBytesRefAttribute att = extractor.getAttribute(TermToBytesRefAttribute.class);
     int numT = det.initTransition(state, transition);
     List<Term> terms = new ArrayList<> ();
     for (int i = 0; i < numT; i++) {
       det.getNextTransition(transition);
       for (int id = transition.min; id <= transition.max; id++) {
-        Term term = new Term(field, idToTerm.get(id));
+        extractor.restoreState(idToState.get(id));
+        Term term = new Term(field, BytesRef.deepCopyOf(att.getBytesRef()));
         terms.add(term);
       }
     }
@@ -209,7 +215,6 @@ public final class GraphTokenStreamFiniteStrings {
     in.reset();
 
     int pos = -1;
-    int prevIncr = 1;
     int state = -1;
     int gap = 0;
     while (in.incrementToken()) {
@@ -233,16 +238,29 @@ public final class GraphTokenStreamFiniteStrings {
         state = builder.createState();
       }
 
-      BytesRef term = termBytesAtt.getBytesRef();
-      int id = getTermID(currentIncr, prevIncr, term);
-      //System.out.println("Adding transition: " + term.utf8ToString() + "@" + pos + "->" + endPos);
+      int id = idToState.size();
+      // Before we capture state, set posInc to the previous increment if we're starting
+      // a new path, and set posLen to 1 - the states will be returned as part of a single
+      // token path, so there are no stacks or jumps
+      if (currentIncr == 0) {
+        posIncAtt.setPositionIncrement(gap + 1);
+      }
+      posLengthAtt.setPositionLength(1);
+      idToState.put(id, in.captureState());
+      //System.out.println("Creating transition from " + pos + " to " + endPos);
       builder.addTransition(pos, endPos, id);
-      pos += gap;
-
-      // only save last increment on non-zero increment in case we have multiple stacked tokens
-      if (currentIncr > 0) {
-        prevIncr = currentIncr;
+      if (gap != 0) {
+        // there's a gap behind us in the token stream; we've already pushed our starting
+        // position back to take this into account, but we now need to add an extra state
+        // at the real position so that any incoming paths hit the correct node
+        pos += gap;
+        //System.out.println("Creating transition from " + pos + " to " + endPos);
+        id = idToState.size();
+        posIncAtt.setPositionIncrement(1);
+        idToState.put(id, in.captureState());
+        builder.addTransition(pos, endPos, id);
       }
+
     }
 
     in.end();
@@ -252,23 +270,6 @@ public final class GraphTokenStreamFiniteStrings {
     return builder.finish();
   }
 
-  /**
-   * Gets an integer id for a given term and saves the position increment if needed.
-   */
-  private int getTermID(int incr, int prevIncr, BytesRef term) {
-    assert term != null;
-    boolean isStackedGap = incr == 0 && prevIncr > 1;
-    int id = idToTerm.size();
-    idToTerm.put(id, BytesRef.deepCopyOf(term));
-    // stacked token should have the same increment as original token at this position
-    if (isStackedGap) {
-      idToInc.put(id, prevIncr);
-    } else if (incr > 1) {
-      idToInc.put(id, incr);
-    }
-    return id;
-  }
-
   private static void articulationPointsRecurse(Automaton a, int state, int d, int[] depth, int[] low, int[] parent,
                                                 BitSet visited, List<Integer> points) {
     visited.set(state);
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter.java
index d3a476f585..cdb844bf27 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter.java
@@ -54,8 +54,10 @@ public class TestGraphTokenFilter extends BaseTokenStreamTestCase {
     assertTrue(graph.incrementBaseToken());
     assertEquals("a", termAtt.toString());
     assertEquals(1, posIncAtt.getPositionIncrement());
+    assertFalse(graph.atArticulationPoint());
     assertTrue(graph.incrementGraphToken());
     assertEquals("b", termAtt.toString());
+    assertFalse(graph.atArticulationPoint());
     assertTrue(graph.incrementGraphToken());
     assertEquals("d", termAtt.toString());
     assertTrue(graph.incrementGraph());
@@ -70,8 +72,10 @@ public class TestGraphTokenFilter extends BaseTokenStreamTestCase {
     assertTrue(graph.incrementBaseToken());
     assertEquals("b", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
+    assertFalse(graph.atArticulationPoint());
     assertEquals("d", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
+    assertTrue(graph.atArticulationPoint());
     assertEquals("e", termAtt.toString());
     assertTrue(graph.incrementGraph());
     assertEquals("b", termAtt.toString());
@@ -91,8 +95,10 @@ public class TestGraphTokenFilter extends BaseTokenStreamTestCase {
     assertEquals(6, graph.cachedTokenCount());
 
     assertTrue(graph.incrementBaseToken());
+    assertFalse(graph.atArticulationPoint());
     assertEquals("d", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
+    assertTrue(graph.atArticulationPoint());
     assertEquals("e", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
     assertEquals("g", termAtt.toString());
@@ -114,16 +120,20 @@ public class TestGraphTokenFilter extends BaseTokenStreamTestCase {
     //tok.setReader(new StringReader("a b/c d e/f:3 g/h i j k"));
 
     assertTrue(graph.incrementBaseToken());
+    assertTrue(graph.atArticulationPoint());
     assertEquals("e", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
+    assertFalse(graph.atArticulationPoint());
     assertEquals("g", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
     assertEquals("i", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
     assertEquals("j", termAtt.toString());
     assertTrue(graph.incrementGraph());
+    assertTrue(graph.atArticulationPoint());
     assertEquals("e", termAtt.toString());
     assertTrue(graph.incrementGraphToken());
+    assertFalse(graph.atArticulationPoint());
     assertEquals("h", termAtt.toString());
     assertFalse(graph.incrementGraph());
     assertEquals(8, graph.cachedTokenCount());
@@ -184,6 +194,119 @@ public class TestGraphTokenFilter extends BaseTokenStreamTestCase {
     assertFalse(gts.incrementGraph());
   }
 
+  private static Token delete(Token token) {
+    token.setDeleted(true);
+    return token;
+  }
+
+  public void testGapsAtArticulationPoints() throws IOException {
+
+    // watch tyd:3/[] walking dead now
+    CannedTokenStream cts = new CannedTokenStream(
+        new Token("watch", 0, 1),
+        new Token("tyd", 1, 2, 3, 3),
+        delete(new Token("the", 0, 2, 3)),
+        new Token("walking", 2, 3),
+        new Token("dead", 2, 3),
+        new Token("now", 2, 3)
+    );
+
+    GraphTokenFilter graph = new TestGraphTokenFilter.TestFilter(cts);
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "watch", 1);
+    assertNextInGraph(graph, true, "tyd", 1);
+    assertNextInGraph(graph, true, "now", 1);
+    assertFalse(graph.incrementGraphToken());
+
+    assertTrue(graph.incrementGraph());
+    assertNextInGraph(graph, false, "watch", 1);
+    assertNextInGraph(graph, true, "walking", 2);
+    assertNextInGraph(graph, true, "dead", 1);
+    assertNextInGraph(graph, true, "now", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "tyd", 1);
+    assertNextInGraph(graph, true, "now", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "walking", 2);
+    assertNextInGraph(graph, true, "dead", 1);
+    assertNextInGraph(graph, true, "now", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "dead", 1);
+    assertNextInGraph(graph, true, "now", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+  }
+
+  private void assertNextInGraph(GraphTokenFilter graph, boolean advance, String term, int posInc) throws IOException {
+    CharTermAttribute termAtt = graph.addAttribute(CharTermAttribute.class);
+    PositionIncrementAttribute posAtt = graph.addAttribute(PositionIncrementAttribute.class);
+
+    if (advance) {
+      assertTrue(graph.incrementGraphToken());
+    }
+    assertEquals(term, termAtt.toString());
+    assertEquals(posInc, posAtt.getPositionIncrement());
+  }
+
+  public void testMultipleGaps() throws IOException {
+
+    // king kong:3/[] [] hill movie
+    CannedTokenStream cts = new CannedTokenStream(
+        new Token("king", 0, 1),
+        new Token("kong", 1, 2, 3, 3),
+        delete(new Token("of", 0, 2, 3)),
+        delete(new Token("the", 2, 3)),
+        new Token("hill", 2, 3),
+        new Token("movie", 4, 5)
+    );
+
+    GraphTokenFilter graph = new TestFilter(cts);
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "king", 1);
+    assertNextInGraph(graph, true, "kong", 1);
+    assertNextInGraph(graph, true, "movie", 1);
+    assertFalse(graph.incrementGraphToken());
+
+    assertTrue(graph.incrementGraph());
+    assertNextInGraph(graph, false, "king", 1);
+    assertNextInGraph(graph, true, "hill", 3);
+    assertNextInGraph(graph, true, "movie", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "kong", 1);
+    assertNextInGraph(graph, true, "movie", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "hill", 3);
+    assertNextInGraph(graph, true, "movie", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertTrue(graph.incrementToken());
+    assertNextInGraph(graph, false, "movie", 1);
+    assertFalse(graph.incrementGraphToken());
+    assertFalse(graph.incrementGraph());
+
+    assertFalse(graph.incrementToken());
+
+  }
+
   public void testMaximumGraphCacheSize() throws IOException {
 
     Token[] tokens = new Token[GraphTokenFilter.MAX_TOKEN_CACHE_SIZE + 5];
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java b/lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java
index dc5468321f..ea4b9a732d 100644
--- a/lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java
+++ b/lucene/core/src/test/org/apache/lucene/util/TestQueryBuilder.java
@@ -21,9 +21,11 @@ import java.io.IOException;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CannedBinaryTokenStream;
+import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockSynonymFilter;
 import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -173,6 +175,34 @@ public class TestQueryBuilder extends LuceneTestCase {
         queryBuilder.createPhraseQuery("field", "guinea pig"));
   }
 
+  static class MockSynonymStopwordAnalyzer extends Analyzer {
+
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      MockTokenizer tokenizer = new MockTokenizer();
+      CharArraySet stopwords = new CharArraySet(2, false);
+      stopwords.add("guinea");
+      return new TokenStreamComponents(tokenizer, new StopFilter(new MockSynonymFilter(tokenizer), stopwords));
+    }
+  }
+
+  public void testMultiWordSynonymsAndStopwords() {
+
+    SpanNearQuery expected = SpanNearQuery.newOrderedNearQuery("field")
+        .addClause(new SpanTermQuery(new Term("field", "my")))
+        .addClause(new SpanOrQuery(
+            // TODO - this is actually incorrect, we need to have a gap before 'pig'
+            // LUCENE-7848
+            new SpanTermQuery(new Term("field", "pig")),
+            new SpanTermQuery(new Term("field", "cavy"))))
+        .addClause(new SpanTermQuery(new Term("field", "farm")))
+        .build();
+
+    QueryBuilder builder = new QueryBuilder(new MockSynonymStopwordAnalyzer());
+    assertEquals(expected, builder.createPhraseQuery("field", "my guinea pig farm"));
+
+  }
+
   public void testMultiWordSynonymsPhraseWithSlop() throws Exception {
     BooleanQuery expected = new BooleanQuery.Builder()
         .add(new PhraseQuery.Builder().setSlop(4)
diff --git a/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java b/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
index 1739fa0c7d..ffdaa28a00 100644
--- a/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
+++ b/lucene/core/src/test/org/apache/lucene/util/graph/TestGraphTokenStreamFiniteStrings.java
@@ -21,8 +21,8 @@ import java.util.Iterator;
 import org.apache.lucene.analysis.CannedTokenStream;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.BytesTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -32,9 +32,14 @@ import org.apache.lucene.util.LuceneTestCase;
 public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
 
   private static Token token(String term, int posInc, int posLength) {
+    return token(term, posInc, posLength, false);
+  }
+
+  private static Token token(String term, int posInc, int posLength, boolean deleted) {
     final Token t = new Token(term, 0, term.length());
     t.setPositionIncrement(posInc);
     t.setPositionLength(posLength);
+    t.setDeleted(deleted);
     return t;
   }
 
@@ -44,7 +49,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertNotNull(terms);
     assertNotNull(increments);
     assertEquals(terms.length, increments.length);
-    BytesTermAttribute termAtt = ts.getAttribute(BytesTermAttribute.class);
+    TermToBytesRefAttribute termAtt = ts.getAttribute(TermToBytesRefAttribute.class);
     PositionIncrementAttribute incrAtt = ts.getAttribute(PositionIncrementAttribute.class);
     int offset = 0;
     while (ts.incrementToken()) {
@@ -601,7 +606,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
 
   public void testSidePathWithGap() throws Exception {
     // 0    1               2  3  4             5
-    // king alfred:3/alfred [] [] great/awesome ruled
+    // king alfred:4/alfred [] [] great/awesome ruled
     CannedTokenStream cts = new CannedTokenStream(
         token("king", 1, 1),
         token("alfred", 1, 4),
@@ -622,6 +627,7 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
   }
 
   public void testMultipleSidePathsWithGaps() throws Exception {
+    // 0    1                2  3  4       5  6      7
     // king alfred:4/alfred [] [] saxons:3 [] wessex ruled
     CannedTokenStream cts = new CannedTokenStream(
         token("king", 1, 1),
@@ -640,4 +646,54 @@ public class TestGraphTokenStreamFiniteStrings extends LuceneTestCase {
     assertFalse(it.hasNext());
   }
 
+  public void testSidePathsWithDeletedArticulationNode() throws Exception {
+    // watch tyd:3/[] walking dead series 2
+    CannedTokenStream cts = new CannedTokenStream(
+        token("watch", 1, 1),
+        token("tyd", 1, 3),
+        token("the", 0, 1, true),
+        token("walking", 1, 1),
+        token("dead", 1, 1),
+        token("series", 1, 1),
+        token("2", 1, 1)
+    );
+    GraphTokenStreamFiniteStrings graph = new GraphTokenStreamFiniteStrings(cts);
+    Iterator<TokenStream> it = graph.getFiniteStrings();
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "watch", "tyd", "series", "2" }, new int[]{ 1, 1, 1, 1 });
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "watch", "walking", "dead", "series", "2" }, new int[]{ 1, 2, 1, 1, 1 });
+  }
+
+  public void testFullyRemovedSidePathWithInitialNode() throws Exception {
+    // 0                  1  2  3
+    // tobeornottobe:3/to [] [] that
+    CannedTokenStream cts = new CannedTokenStream(
+        token("tobeornottobe", 1, 3),
+        token("to", 0, 1),
+        token("that", 3, 1)
+    );
+    GraphTokenStreamFiniteStrings graph = new GraphTokenStreamFiniteStrings(cts);
+    Iterator<TokenStream> it = graph.getFiniteStrings();
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "tobeornottobe", "that" }, new int[]{ 1, 1 });
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "to", "that" }, new int[]{ 1, 3 });
+  }
+
+  public void testFullyRemovedSidePathWithoutInitialNode() throws Exception {
+    // tobeornottobe:3/[] [] [] that
+    CannedTokenStream cts = new CannedTokenStream(
+        token("tobeornottobe", 1, 3),
+        token("to", 0, 1, true),
+        token("that", 3, 1)
+    );
+    GraphTokenStreamFiniteStrings graph = new GraphTokenStreamFiniteStrings(cts);
+    Iterator<TokenStream> it = graph.getFiniteStrings();
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "tobeornottobe", "that" }, new int[]{ 1, 1 });
+    assertTrue(it.hasNext());
+    assertTokenStream(it.next(), new String[]{ "that" }, new int[]{ 4 });
+  }
+
 }
