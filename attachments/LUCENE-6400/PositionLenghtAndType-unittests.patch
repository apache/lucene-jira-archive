Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java	(revision 1671534)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSolrSynonymParser.java	(working copy)
@@ -72,7 +72,7 @@
         new int[] { 1, 0, 1, 0 });
     analyzer.close();
   }
-  
+
   /** parse a syn file with bad syntax */
   public void testInvalidDoubleMap() throws Exception {
     String testFile = "a => b => c";
@@ -174,4 +174,73 @@
         new int[] { 1 });
     analyzer.close();
   }
+
+  /** verify type of token and positionLengths on synonyms of different word counts. */
+  public void testPositionLengthAndType() throws Exception {
+    String testFile =
+        "spider man, spiderman\n"+
+        "usa,united states,u s a,united states of america";
+
+    Analyzer analyzer = new MockAnalyzer(random());
+    SolrSynonymParser parser = new SolrSynonymParser(true, true, analyzer);
+    parser.parse(new StringReader(testFile));
+    final SynonymMap map = parser.build();
+    analyzer.close();
+
+    analyzer = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);
+        return new TokenStreamComponents(tokenizer, new SynonymFilter(tokenizer, map, true));
+      }
+    };
+
+    assertAnalyzesToPositions(analyzer, "spider man",
+        new String[] { "spider", "spiderman", "man" },
+        new String[] { "word", "SYNONYM", "word" },
+        new int[] { 1, 0, 1 },
+        new int[] { 1, 2, 1 });
+
+    assertAnalyzesToPositions(analyzer, "amazing spider man",
+        new String[] { "amazing", "spider", "spiderman", "man" },
+        new String[] { "word", "word", "SYNONYM", "word" },
+        new int[] { 1, 1, 0, 1 },
+        new int[] { 1, 1, 2, 1 });
+
+    assertAnalyzesToPositions(analyzer, "spiderman",
+        new String[] { "spiderman", "spider", "man" },
+        new String[] { "word", "SYNONYM", "SYNONYM" },
+        new int[] { 1, 0, 1 },
+        new int[] { 1, 1, 1 });
+        // should be: new int[] { 2, 1, 1 });
+
+    assertAnalyzesToPositions(analyzer, "spiderman enemies",
+        new String[] { "spiderman", "spider", "enemies", "man" },
+        // should be: new String[] { "spiderman", "spider", "man", "enemies" },
+        new String[] { "word", "SYNONYM", "word", "SYNONYM" },
+        // should be: new String[] { "word", "SYNONYM", "SYNONYM", "word" },
+        new int[] { 1, 0, 1, 0 },
+        // should be: new int[] { 1, 0, 0, 1 },
+        new int[] { 1, 1, 1, 1 });
+        // should be: new int[] { 2, 1, 1, 1 });
+
+    assertAnalyzesToPositions(analyzer, "the united states of america is wealthy",
+        new String[] { "the", "united", "usa", "united", "u", "states", "states", "s", "of", "a", "america", "is", "wealthy"},
+        new String[] { "word", "word", "SYNONYM", "SYNONYM", "SYNONYM", "word", "SYNONYM", "SYNONYM", "word", "SYNONYM", "word", "word", "word" },
+        new int[] { 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1 },
+        new int[] { 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 });
+        // should be: new int[] {  1, 1, 4, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1 });
+
+    assertAnalyzesToPositions(analyzer, "the united states is wealthy",
+        new String[] { "the", "united", "usa", "u", "united", "states", "s", "states", "is", "a", "of", "wealthy", "america"},
+        // should be: new String[] { "the", "united", "usa", "u", "united", "states", "s", "states", "a", "of", "america", "is", "wealthy"},
+        new String[] { "word", "word", "SYNONYM", "SYNONYM", "SYNONYM", "word", "SYNONYM", "SYNONYM", "word", "SYNONYM", "SYNONYM", "word", "SYNONYM" },
+        // should be: new String[] { "word", "word", "SYNONYM", "SYNONYM", "SYNONYM", "word", "SYNONYM", "SYNONYM", "SYNONYM", "SYNONYM", "SYNONYM", "word", "word" },
+        new int[] { 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
+        // should be: new int[] { 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1 },
+        new int[] { 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 }); // has to be 1, 1, 4, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1
+        // should be: new int[] { 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 }); // has to be 1, 1, 4, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1
+
+    analyzer.close();
+  }
 }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java	(revision 1671534)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java	(working copy)
@@ -104,6 +104,12 @@
         for (int i = 0; i < outputs.length; i++) {
           outputs[i] = analyze(unescape(outputStrings[i]).trim(), new CharsRefBuilder());
         }
+        // these mappings are explicit and never preserve original
+        for (int i = 0; i < inputs.length; i++) {
+          for (int j = 0; j < outputs.length; j++) {
+            add(inputs[i], outputs[j], false);
+          }
+        }
       } else {
         String inputStrings[] = split(line, ",");
         inputs = new CharsRef[inputStrings.length];
@@ -116,15 +122,13 @@
           outputs = new CharsRef[1];
           outputs[0] = inputs[0];
         }
-      }
-      
-      // currently we include the term itself in the map,
-      // and use includeOrig = false always.
-      // this is how the existing filter does it, but it's actually a bug,
-      // especially if combined with ignoreCase = true
-      for (int i = 0; i < inputs.length; i++) {
-        for (int j = 0; j < outputs.length; j++) {
-          add(inputs[i], outputs[j], false);
+        
+        for (int i = 0; i < inputs.length; i++) {
+          for (int j = 0; j < outputs.length; j++) {
+            if (expand == false || i != j) {
+              add(inputs[i], outputs[j], expand);
+            }
+          }
         }
       }
     }
Index: lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java	(revision 1671534)
+++ lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java	(working copy)
@@ -374,6 +374,10 @@
     assertAnalyzesTo(a, input, output, null, null, null, posIncrements, posLengths);
   }
   
+  public static void assertAnalyzesToPositions(Analyzer a, String input, String[] output, String[] types, int[] posIncrements, int[] posLengths) throws IOException {
+    assertAnalyzesTo(a, input, output, null, null, types, posIncrements, posLengths);
+  }
+
   public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[]) throws IOException {
     assertAnalyzesTo(a, input, output, startOffsets, endOffsets, null, null, null);
   }
