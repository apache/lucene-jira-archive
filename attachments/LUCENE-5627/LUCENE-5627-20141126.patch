diff --git a/lucene/join/build.xml b/lucene/join/build.xml
index b5360c4..43bf8a9 100644
--- a/lucene/join/build.xml
+++ b/lucene/join/build.xml
@@ -19,7 +19,7 @@
 -->
 <project name="join" default="default">
   <description>
-    Index-time and Query-time joins for normalized content
+    Index-time and Query-time document joins for normalized content
   </description>
 
   <import file="../module-build.xml"/>
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/package.html b/lucene/join/src/java/org/apache/lucene/search/join/package.html
index 036ef63..e479236 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/package.html
+++ b/lucene/join/src/java/org/apache/lucene/search/join/package.html
@@ -17,11 +17,11 @@
 <html>
 <body>
 
-<p>This modules support index-time and query-time joins.</p>
+<p>This modules support index-time and query-time document joins.</p>
 
-<h2>Index-time joins</h2>
+<h2>Index-time document joins</h2>
 
-<p>The index-time joining support joins while searching, where joined
+<p>The index-time joining support document joins while searching, where joined
   documents are indexed as a single document block using
   {@link org.apache.lucene.index.IndexWriter#addDocuments IndexWriter.addDocuments()}.  
   This is useful for any normalized content (XML documents or database tables).  In database terms, all rows for all
@@ -56,10 +56,10 @@
   any query matching parent documents, creating the joined query
   matching only child documents.
 
-<h2>Query-time joins</h2>
+<h2>Query-time document joins</h2>
 
 <p>
-  The query time joining is index term based and implemented as two pass search. The first pass collects all the terms from a fromField
+  The query time document joining is index term based and implemented as two pass search. The first pass collects all the terms from a fromField
   that match the fromQuery. The second pass returns all documents that have matching terms in a toField to the terms
   collected in the first pass.
 </p>
@@ -74,7 +74,7 @@
   <li><code>toField</code>: The to field to join to
 </ul>
 <p>
-  Basically the query-time joining is accessible from one static method. The user of this method supplies the method
+  Basically the query-time document joining is accessible from one static method. The user of this method supplies the method
   with the described input and a <code>IndexSearcher</code> where the from terms need to be collected from. The returned
   query can be executed with the same <code>IndexSearcher</code>, but also with another <code>IndexSearcher</code>.
   Example usage of the {@link org.apache.lucene.search.join.JoinUtil#createJoinQuery(String, boolean, String, org.apache.lucene.search.Query, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.join.ScoreMode)
diff --git a/lucene/label/build.xml b/lucene/label/build.xml
new file mode 100644
index 0000000..890da25
--- /dev/null
+++ b/lucene/label/build.xml
@@ -0,0 +1,34 @@
+<?xml version="1.0"?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one
+   or more contributor license agreements.  See the NOTICE file
+   distributed with this work for additional information
+   regarding copyright ownership.  The ASF licenses this file
+   to you under the Apache License, Version 2.0 (the
+   "License"); you may not use this file except in compliance
+   with the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing,
+   software distributed under the License is distributed on an
+   "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+   KIND, either express or implied.  See the License for the
+   specific language governing permissions and limitations
+   under the License.
+-->
+<project name="label" default="default">
+  <description>
+    Index-time and Query-time positional joins
+  </description>
+
+  <import file="../module-build.xml"/>
+
+  <path id="classpath">
+    <pathelement path="${analyzers-common.jar}"/>
+    <path refid="base.classpath"/>
+  </path>
+
+  <target name="init" depends="module-build.init,jar-analyzers-common"/>
+
+</project>
diff --git a/lucene/label/ivy.xml b/lucene/label/ivy.xml
new file mode 100644
index 0000000..a008e3d
--- /dev/null
+++ b/lucene/label/ivy.xml
@@ -0,0 +1,21 @@
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one
+   or more contributor license agreements.  See the NOTICE file
+   distributed with this work for additional information
+   regarding copyright ownership.  The ASF licenses this file
+   to you under the Apache License, Version 2.0 (the
+   "License"); you may not use this file except in compliance
+   with the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing,
+   software distributed under the License is distributed on an
+   "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+   KIND, either express or implied.  See the License for the
+   specific language governing permissions and limitations
+   under the License.
+-->
+<ivy-module version="2.0">
+    <info organisation="org.apache.lucene" module="label"/>
+</ivy-module>
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java b/lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java
new file mode 100644
index 0000000..57f35f0
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java
@@ -0,0 +1,128 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+
+import org.apache.lucene.analysis.TokenStream;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoEncoder;
+
+class FragmentPositionsStreamBuilder {
+  private ArrayList<Integer> fragmentPositions;
+  private AttributeSource attributeSource;
+  private PrefillTokenStream fragmentStream;
+  private int fragmentsSize;
+
+  FragmentPositionsStreamBuilder(AttributeSource attributeSource) {
+    this.attributeSource = attributeSource;
+    this.fragmentStream = new PrefillTokenStream(attributeSource);
+    this.fragmentPositions = new ArrayList<>();
+    this.fragmentsSize = 0;
+  }
+
+  void addTokenState(AttributeSource attributeSource) {
+    fragmentStream.addState(attributeSource.captureState());
+  }
+
+  void incrementFragmentsSize() {
+    fragmentsSize++;
+  }
+
+  void incrementFragmentsSize(int incr) {
+    fragmentsSize += incr;
+  }
+
+  void addSizeAsPosition() {
+    fragmentPositions.add(fragmentsSize);
+  }
+
+  TokenStream fragmentsTokenStream() {
+    return fragmentStream;
+  }
+
+  BytesRef fragmentPositionsBytesRef() {
+    int numValues = fragmentPositions.size();
+    if (numValues <= 1) { // no labels: do not index.
+      return null; // avoid creating an EliasFanoBytes
+    } else {
+      int upperBound = fragmentPositions.get(numValues - 1); // non empty
+      if (upperBound == 0) { // only empty fragments
+        return null;
+      } else {
+        /* Corner case not checked here: all labels after first and only non empty fragment.
+         * In this case the first labeled fragment start position is non zero, and
+         * equal to the last fragment end position.
+         * A query for a first non labeled non empty fragment is not unthinkable, so index this.
+         */
+        EliasFanoBytes efBytes = new EliasFanoBytes(numValues, upperBound);
+        EliasFanoEncoder<?> efEncoder = efBytes.getEncoder();
+        for (int fragmentPos: fragmentPositions) {
+          // The Elias-Fano sequence position is the label position,
+          // the sequence value is the fragment start position:
+          efEncoder.encodeNext(fragmentPos);
+        }
+        return efBytes.getBytesRef();
+      }
+    }
+  }
+
+  public TokenStream fragmentPositionsTokenStream(final String termText) {
+    final BytesRef payload = fragmentPositionsBytesRef();
+
+    return new TokenStream() { // single term at position 0 with payload, if any.
+      CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+      PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
+      boolean atFirstTerm;
+
+      @Override
+      public void reset() {
+        atFirstTerm = true;
+      }
+
+      @Override
+      public boolean incrementToken() {
+        if (! atFirstTerm) {
+          return false;
+        }
+        atFirstTerm = false;
+        if (payload == null) {
+          return false;
+        }
+        termAtt.setEmpty();
+        termAtt.append(termText);
+        payloadAtt.setPayload(payload);
+        return true;
+      }
+    };
+  }
+
+  public void clear() {
+    fragmentStream = new PrefillTokenStream(attributeSource); // replace, do not close, may still be indexed.
+    fragmentPositions.clear();
+    fragmentsSize = 0;
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java b/lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java
new file mode 100644
index 0000000..5f732a3
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java
@@ -0,0 +1,106 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import java.util.ArrayList;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.packed.label.LongsInBytes;
+
+
+/*
+  Number of bits needed for label tree info: 2*n*ceil(2log(n-1)), for example:
+   100  labels: 2*100*7     =    1.4 Kbits =   0.175 KB
+   500  labels: 2*500*9     =    9   Kbits =   1.125 KB
+     1k labels: 2*1000*10   =   20   Kbits =   2.5   KB
+     5k labels: 2*5000*13   =  130   Kbits =  16.25  KB
+    10k labels: 2*10000*14  =  280   Kbits =  35     KB
+    50k labels: 2*50000*16  = 1600   Kbits = 200     KB
+   100k labels: 2*100000*17 = 3400   Kbits = 425     KB
+  that is about 1-3 times what is needed for the positions of the labels.
+
+  The number of bits might be reduced to about 2.4*n bits,
+  see also Arroyuelo et al., 2010, Succinct Trees in Practice.
+  That requires more complex code (balanced parentheses), and it will probably be slower.
+*/
+
+class LabelTreeInfoBuilder {
+  private ArrayList<Integer> labelParentPositions;
+  private ArrayList<Integer> labelSubTreeSizes;
+  private ArrayList<Integer> labelPositionsStack;
+
+  LabelTreeInfoBuilder() {
+    labelParentPositions = new ArrayList<>(0);
+    labelSubTreeSizes = new ArrayList<>(0);
+    labelPositionsStack = new ArrayList<>(0);
+  }
+
+  void reInit() {
+    labelParentPositions.clear();
+    labelSubTreeSizes.clear();
+    labelPositionsStack.clear();
+  }
+
+  void pushLabel() {
+    int currentLabelPosition = labelParentPositions.size();
+    int parentPosition = (currentLabelPosition == 0)
+                          ? 0 // root is its own parent
+                          : labelPositionsStack.get(labelPositionsStack.size()-1); // top of labelPositionsStack
+    labelParentPositions.add(parentPosition);
+    labelPositionsStack.add(currentLabelPosition);
+    labelSubTreeSizes.add(0); // sub tree size to be filled in by popLabel
+  }
+
+  void popLabel() {
+    int currentLabelPosition = labelParentPositions.size() - 1;
+    int stackTop = labelPositionsStack.size()-1;
+    int parentPosition = labelPositionsStack.get(stackTop);
+    labelSubTreeSizes.set(parentPosition, currentLabelPosition - parentPosition);
+    labelPositionsStack.remove(stackTop);
+  }
+
+  boolean isEmptyStack() {
+    return labelPositionsStack.isEmpty();
+  }
+
+  BytesRef treeInfoBytesRef() {
+    // This takes 2 * ceil(2log(numLabels-1)) bits per label,
+    // An alternative implementation takes 2.3 bits per label ("fully functional") but takes more time to decode.
+    assert labelParentPositions.size() == labelSubTreeSizes.size();
+    assert labelParentPositions.size() > 0;
+    int numBits = Integer.SIZE - Integer.numberOfLeadingZeros(labelParentPositions.size() - 1);
+    if (numBits == 0) {
+      assert labelParentPositions.size() == 1;
+      return null; // no payload needed, only a root
+    }
+    int numBytes = (2 * numBits * labelParentPositions.size() + (Byte.SIZE-1)) >>> LongsInBytes.LOG2_BYTE_SIZE;
+    BytesRef bytesRef = new BytesRef(numBytes);
+    byte[] bytes = bytesRef.bytes;
+    for (int nodeNum = 0; nodeNum < labelParentPositions.size(); nodeNum++) {
+      LongsInBytes.packValue(labelParentPositions.get(nodeNum), numBits, 2 * nodeNum,     bytes); // parent position
+      LongsInBytes.packValue(labelSubTreeSizes.get(nodeNum),    numBits, 2 * nodeNum + 1, bytes); // subtree size
+    }
+    bytesRef.offset = 0;
+    bytesRef.length = bytesRef.bytes.length;
+    return bytesRef;
+  }
+
+  public void close() {
+    reInit();
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java b/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java
new file mode 100644
index 0000000..fa4a98f
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java
@@ -0,0 +1,378 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * Split a {@link TokenStream} with labeled fragments into Tokenstreams
+ * for labels, fragments and fragment positions,
+ * to be searched by subclasses of {@link org.apache.lucene.search.spans.label.LabeledFragmentsQuery} after indexing.
+ * Labels and fragments are indicated by methods from {@link LabeledFragmentsAnalyzer.InputSplitter}.
+ * <br>
+ * Each input stream is split into token streams for:
+ * <ul>
+ * <li>a label stream, and
+ * <li>one or more pairs of a fragment stream and a stream with a fragment start/end positions payload.
+ * </ul>
+ * A document can be indexed with these output streams and a field for the label tokens, field(s) for the fragment tokens
+ * and field(s) for the fragment start/end positions.
+ * Subclasses of {@link org.apache.lucene.search.spans.label.LabeledFragmentsQuery}
+ * can use these associations between labels and fragments.
+ * <p>
+ * In a labeled fragment stream each label preceeds its associated fragments.
+ * The label tokens in this stream are distinguished from the fragment tokens by
+ * {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+ * <p>
+ * Each label is associated with the start/end positions of one fragment in each fragment stream.
+ * A fragment is a possibly empty series of tokens in a fragment stream.
+ * In each fragment stream the fragments are contiguous and in the same order as the labels in the label stream.
+ * <p>
+ * For one document, the fragment start/end positions for one fragment stream
+ * are compressed into a single payload that is provided with a dedicated term in another stream at position zero.
+ * <p>
+ * The example below associates the label <code>A:</code> with the fragment <code>a1 a2</code>,
+ * the label <code>B:</code> with the fragment <code>b1 b2 b3</code>, and
+ * the label <code>C:</code> with the fragment <code>c1</code>.
+ * <br>In the output streams, the label stream and the fragment streams are provided
+ * with tokens at the shown positions. In this example an ending colon indicates the labels:
+ * <p>
+ * Input stream with labels for a single fragments stream:
+ * <pre>
+ *
+ *                                A: a1 a2  B: b1 b2 b3  C: c1
+ *
+ * Labels output stream:
+ *
+ *                  label terms:  A:        B:           C:
+ *              label positions:  0         1            2
+ *
+ * Fragments output stream:
+ *
+ *              fragments/terms:     a1 a2     b1 b2 b3     c1
+ *           fragment positions:     0  1      2  3  4      5
+ *
+ * Payload term output stream:
+ *
+ * fragment start/end positions:     0         2            5  6
+ *
+ * </pre>
+ * <p>
+ * Fragments in two streams for a single labels stream can for example be separated by a double colon || .
+ * <p>
+ * Input stream with labels for two fragments streams, in one line per label:
+ * <pre>
+ *
+ *                                A:    a1   ||  a2
+ *                                B:    b1
+ *                                C:    c1   ||  c2 c3
+ * </pre>
+ * In this way the columns show the output streams, one for the labels, and two for the fragments.
+ * In this example the labels output stream is the same as above.
+ * <br>The same input stream on a single line:
+ * <pre>
+ *
+ *                                A: a1 || a2  B: b1  C: c1 || c2 c3
+ *
+ * First fragments output stream:
+ *
+ *              fragments/terms:     a1           b1     c1
+ *           fragment positions:     0            1      2
+ *
+ * First payload term output stream:
+ *
+ * fragment start/end positions:     0            1      2  3
+ *
+ *
+ * Second fragments output stream:
+ *
+ *              fragments/terms:           a2                  c2 c3
+ *           fragment positions:           0                   1  2
+ *
+ * Second payload term output stream:
+ *
+ * fragment start/end positions:           0      1            1     3
+ *
+ * </pre>
+ * <p>
+ * The fragment streams and fragment start/end position streams are separate
+ * to allow various associations between fragment streams and label streams.
+ * <p>
+ * For a <code>1 : 1</code> relationship between tokens in the same positions in different fields there is no need
+ * to index the start/end positions. For example:
+ * <pre>
+ *                                A: a1   B: b1   C: c1
+ * </pre>
+ * See {@link org.apache.lucene.search.spans.FieldMaskingSpanQuery} for searching this case.
+ * <p>
+ * This implementation uses {@link org.apache.lucene.util.packed.EliasFanoBytes} to compress a payload with start/end positions.
+ * These have a value index, which allows for fast fragment to label associations.
+ * Currently these have no position index, so label to fragment associations will be somewhat slower.
+ * Since payloads need to be loaded completely during searches, this is not expected to have a big impact.
+ *
+ * @lucene.experimental
+ */
+public class LabeledFragmentsAnalyzer {
+  PrefillTokenStream labelStream;
+  TokenStream labeledFragments;
+
+  private final int numFragmentStreams;
+  private final ArrayList<FragmentPositionsStreamBuilder> fpsBuilders;
+
+  private int currentFragmentStream;
+  private FragmentPositionsStreamBuilder currentFPSB;
+
+  private InputSplitter inputSplitter;
+
+  /** Token types for splitting an input stream */
+  public static enum TokenType {
+     /** The token is a label, a later label will be its child when labels can be nested. */
+    LABEL,
+
+    /** The token is part of a text fragment associated with the last label. */
+    FRAGMENT,
+
+    /** Indicates that the next fragment token will be part of another fragment associated with the last label. */
+    NEXT_FRAGMENT,
+
+    /** Ends the last label, a later label will be a child of the last label that was not ended. */
+    END_LABEL
+  }
+
+
+  /** Indicates how tokens should be used to split the stream into (a tree of) labels and fragments. */
+  public interface InputSplitter {
+    /** Returns the {@link TokenType} for an input token. */
+    public TokenType tokenType(String term);
+  }
+
+  /** A splitter to split labeled fragment streams into labels and fragments for fragment fields.
+   * @param labeledFragments The labeled fragments input stream. This is used by {@link #consumeInputStream}.
+   * @param inputSplitter   The split will be based on {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+   * @param numFragmentStreams     The number of fragment streams. When no tokens occur for a fragment stream
+   *                               no fragment positions will be provided for that stream.
+   */
+  public LabeledFragmentsAnalyzer(TokenStream labeledFragments, InputSplitter inputSplitter, int numFragmentStreams) {
+    if (labeledFragments == null) {
+      throw new IllegalArgumentException("labeledFragments should not be null");
+    }
+    if (numFragmentStreams < 1) {
+      throw new IllegalArgumentException("numFragmentStreams should be at least one");
+    }
+    if (inputSplitter == null) {
+      throw new IllegalArgumentException("inputSplitter should not be null");
+    }
+    this.labeledFragments = labeledFragments; // for subclass
+    this.numFragmentStreams = numFragmentStreams;
+    this.inputSplitter = inputSplitter;
+
+    this.labelStream = new PrefillTokenStream(labeledFragments);
+    this.fpsBuilders = new ArrayList<>();
+    for (int i = 0; i < numFragmentStreams; i++) {
+      FragmentPositionsStreamBuilder fpsb = new FragmentPositionsStreamBuilder(labeledFragments);
+      this.fpsBuilders.add(fpsb);
+    }
+  }
+
+
+  /**
+   * Consume the labeled fragments input stream once.
+   * <br>This performs <code> {@link TokenStream#reset}; while ({@link TokenStream#incrementToken}) ... ; {@link TokenStream#end}; </code>
+   * on the input stream.
+   * <br>When the input stream has a {@link PositionIncrementAttribute} it is used as expected for fragments.
+   * <br>Fragment tokens ({@link TokenType#FRAGMENT}) that immediately follow a label token or a next fragment stream token
+   * must have a positive position increment.
+   * <br>A label token ({@link TokenType#LABEL}) must have a position increment 1.
+   * <br>The position increments of next fragment stream tokens ({@link TokenType#NEXT_FRAGMENT}) are ignored.
+   * @throws IllegalArgumentException when:
+   *    <ul>
+   *    <li>the input stream does not have a {@link CharTermAttribute}, or
+   *    <li>there is a fragment token ({@link TokenType#FRAGMENT}) without an associated label ({@link TokenType#LABEL}), or
+   *    <li>there are more than {@link #numFragmentStreams}-1 next fragment tokens ({@link TokenType#NEXT_FRAGMENT}) for any label, or
+   *    <li>there is any label end token ({@link TokenType#END_LABEL} (for this use a {@link LabeledTreeFragmentsAnalyzer}.)
+   *    </ul>
+   */
+  public void consumeInputStream() throws IOException {
+    clear(); // any pending output
+
+    // split the stream into labels and fragment streams and build the fragment start/end positions in the fragment streams
+    labeledFragments.reset(); // start TokenStream consumption
+
+    boolean someLabelsEnded = false;
+    int numOpenLabels = 0;
+
+    // for checking input syntax:
+    boolean allLabelsEnded = false;
+    boolean lastTokenEndLabel = true;
+
+    CharTermAttribute labeledFragmentsTermAttr = null;
+    if (! labeledFragments.hasAttribute(CharTermAttribute.class)) {
+      throw new IllegalArgumentException("labeledFragments must have CharTermAttribute");
+    }
+    labeledFragmentsTermAttr = labeledFragments.getAttribute(CharTermAttribute.class);
+
+    PositionIncrementAttribute labeledFragmentsPosIncrAttr = null;
+    if (labeledFragments.hasAttribute(PositionIncrementAttribute.class)) {
+      labeledFragmentsPosIncrAttr = labeledFragments.getAttribute(PositionIncrementAttribute.class);
+    }
+
+    currentFragmentStream = 0;
+    currentFPSB = fpsBuilders.get(currentFragmentStream);
+
+    while (labeledFragments.incrementToken()) { // do the split.
+      // CHECKME: the implementation for a position increment attribute on labeledFragments could be separated.
+      String termText = labeledFragmentsTermAttr.toString();
+
+      switch (inputSplitter.tokenType(termText)) {
+
+      case LABEL:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("label token after all labels ended: " + termText);
+        }
+        numOpenLabels++;
+        lastTokenEndLabel = false;
+        buildLabel(termText);
+        labelStream.addState(labeledFragments.captureState());
+        break;
+
+      case FRAGMENT:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("fragment token after all labels ended: " + termText);
+        }
+        if (lastTokenEndLabel) { // this might be allowed, but it would require a special query to retrieve
+          throw new IllegalArgumentException("fragment token without open label: " + termText);
+        }
+        if (labeledFragmentsPosIncrAttr == null) {
+          currentFPSB.incrementFragmentsSize(); // default position increment
+        } else {
+          int posIncr = labeledFragmentsPosIncrAttr.getPositionIncrement();
+          currentFPSB.incrementFragmentsSize(posIncr);
+        }
+        currentFPSB.addTokenState(labeledFragments);
+        break;
+
+      case NEXT_FRAGMENT:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("next fragment token after all labels ended: " + termText);
+        }
+        if (lastTokenEndLabel) { // this might be allowed, but it would require a special query to retrieve
+          throw new IllegalArgumentException("next fragment token without open label: " + termText);
+        }
+        currentFragmentStream++; // continue for next stream
+        if (currentFragmentStream >= fpsBuilders.size()) {
+          throw new IllegalArgumentException("too many next fragment stream tokens for a single label");
+        }
+        currentFPSB = fpsBuilders.get(currentFragmentStream);
+        break;
+
+      case END_LABEL:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("end label token after all labels ended: " + termText);
+        }
+        numOpenLabels--;
+        if (numOpenLabels == 0) {
+          allLabelsEnded = true;
+        }
+        lastTokenEndLabel = true;
+        someLabelsEnded = true;
+        buildEndLabel();
+        break;
+
+      default:
+        throw new IllegalStateException("unknown token type: " + termText);
+      }
+    }
+
+    if (someLabelsEnded && (numOpenLabels > 0)) {
+      throw new IllegalArgumentException("labels not ended: " + numOpenLabels);
+    }
+    for (FragmentPositionsStreamBuilder fpsb: fpsBuilders) {
+      fpsb.addSizeAsPosition(); // final end positions
+    }
+
+    labeledFragments.end();
+    labeledFragments.close();
+  }
+
+
+  void buildLabel(String termText) {
+    for (FragmentPositionsStreamBuilder fpsb: fpsBuilders) {
+      fpsb.addSizeAsPosition(); // start positions of all fragments for new label
+    }
+    currentFragmentStream = 0; // first fragment stream
+    currentFPSB = fpsBuilders.get(currentFragmentStream);
+  }
+
+  void buildEndLabel() {
+    throw new IllegalArgumentException(getClass().getName() + " input should not contain end label token");
+  }
+
+  private void clear() {
+    labelStream = new PrefillTokenStream(labeledFragments); // replace, do not close, may still be indexed.
+    for (int i = 0; i < numFragmentStreams; i++) {
+      fpsBuilders.get(i).clear();
+    }
+  }
+
+  /** Provide the label stream from the last input stream */
+  public TokenStream labelTokenStream() {
+    if (labelStream == null) {
+      throw new IllegalStateException("no input stream given");
+    }
+    return labelStream;
+  }
+
+  /** The number of fragment streams that can be provided. */
+  public int numFragmentStreams() {
+    return numFragmentStreams;
+  }
+
+  /** Provide the fragment stream from the last input stream as indicated by the given number.
+   * Fragment streams are numbered from 0.
+   */
+  public TokenStream fragmentsTokenStream(int streamNum) {
+    return checkFpsbAvailable(streamNum).fragmentsTokenStream();
+  }
+
+  /** Provide the fragment positions stream from the last input stream as indicated by the given output stream number.
+   * Fragment streams are numbered from 0.
+   * The returned stream will have a single term with a payload for the fragment positions
+   * when the corresponding fragment stream contains at least one non empty fragment.
+   */
+  public TokenStream fragmentPositionsTokenStream(int streamNum, String termText) {
+    return checkFpsbAvailable(streamNum).fragmentPositionsTokenStream(termText);
+  }
+
+  private FragmentPositionsStreamBuilder checkFpsbAvailable(int streamNum) {
+    FragmentPositionsStreamBuilder res = fpsBuilders.get(streamNum);
+    if (res == null) {
+      throw new IllegalStateException("no input stream given or streamNum not available: " + streamNum);
+    }
+    return res;
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java b/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java
new file mode 100644
index 0000000..d6ffd09
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java
@@ -0,0 +1,146 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.AttributeSource;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType; // for javadocs
+
+
+/** A subclass of {@link LabeledFragmentsAnalyzer} that also provides fragment stream with labels in a tree,
+ * to be searched by subclasses of {@link org.apache.lucene.search.spans.label.LabeledTreeFragmentsQuery} after indexing.
+ * For example, using an ending colon to denote a label token, and a double semicolon ;; to denote an end label token,
+ * this input stream:
+ * <pre>
+ *
+ * A:  B: ;;  C: ;;  ;;
+ * </pre>
+ * will produce this label tree in the label stream:
+ * <pre>
+ *
+ *      A:
+ *      | \
+ *      B: C:
+ * </pre>
+ * with root A: at position 0, children B: and C: at positions 1 and 2,
+ * and with a token with a payload containing information about the tree structure.
+ * Subclasses of {@link org.apache.lucene.search.spans.label.LabeledTreeQuery} can use this label tree.
+ * <p>
+ * Fragment streams can be embedded directly after each label. For example, using a double bar || as the next fragment
+ * stream token and showing the label end tokens ;; below their corresponding labels:
+ * <pre>
+ * A:     a1 || a2
+ *    B:  b1 ||
+ *    ;;
+ *    C:     || c1
+ *    ;;
+ * ;;
+ * </pre>
+ * See {@link LabeledFragmentsAnalyzer} such fragments.
+ * <p>
+ * In the current implementation the payload with the label tree information
+ * consists of an array that is indexed by the (preorder) label positions.
+ * Each array element consist of a pair <code>(parentPosition, numberOfDescendants)</code>
+ * that is encoded in <code>2*(ceil(2log(#labels-1))</code> bits.
+ * <br>For each document, the number of labels is the position of the tree information payload term in the label field.
+ * When there is only one label, no payload is stored.
+ *
+ * @lucene.experimental
+ */
+public class LabeledTreeFragmentsAnalyzer extends LabeledFragmentsAnalyzer {
+
+  private final String treeInfoPayloadTerm;
+  private LabelTreeInfoBuilder labelTreeInfoBuilder;
+
+  /** A splitter to split labeled fragment streams into nested labels and into fragments for fragment fields.
+   * @param inputSplitter   The split will be based on {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+   * @param numFragmentStreams     The number of fragment streams. When no tokens occur for a fragment stream
+   *                               no fragment positions will be provided for that stream.
+   * @param treeInfoPayloadTerm    The term added in the {@link #labelTokenStream()} after the last label wich will contain
+   *                               the payload with the label tree info.
+   */
+  public LabeledTreeFragmentsAnalyzer(TokenStream labeledFragments, InputSplitter inputSplitter, int numFragmentStreams, String treeInfoPayloadTerm) {
+    super(labeledFragments, inputSplitter, numFragmentStreams);
+    if (treeInfoPayloadTerm == null) {
+      throw new IllegalArgumentException("treeInfoPayloadTerm should not be null");
+    }
+    this.treeInfoPayloadTerm = treeInfoPayloadTerm;
+    this.labelTreeInfoBuilder = new LabelTreeInfoBuilder();
+  }
+
+  /** Start an input stream.
+   * In addition to {@link LabeledFragmentsAnalyzer#consumeInputStream} this builds the label tree info and adds it to the
+   * {@link LabeledFragmentsAnalyzer#labelStream}.
+   * <br>The position increments of end label tokens ({@link TokenType#END_LABEL}) are ignored.
+   * @throws IllegalArgumentException when:
+   * <ul>
+   * <li>the input stream does not have a {@link CharTermAttribute}, or
+   * <li>there is a fragment token ({@link TokenType#FRAGMENT}) without an associated label ({@link TokenType#LABEL}), or
+   * <li>there are more than <code>numFragmentStreams-1</code> next fragment tokens ({@link TokenType#NEXT_FRAGMENT}) for any label, or
+   * <li>any label equals the <code>treeInfoPayloadTerm</code>, or
+   * <li>not all label tokens have a corresponding end label token ({@link TokenType#END_LABEL}), or
+   * <li>there is any token after the end label token of the first label.
+   * </ul>
+   */
+  @Override
+  public void consumeInputStream() throws IOException {
+    labelTreeInfoBuilder.reInit();
+    super.consumeInputStream();
+  }
+
+  @Override
+  void buildLabel(String termText) {
+    if (termText.equals(treeInfoPayloadTerm)) {
+      throw new IllegalArgumentException("label term is tree info payload term: " + termText);
+    }
+    super.buildLabel(termText);
+    labelTreeInfoBuilder.pushLabel();
+  }
+
+
+  @Override
+  void buildEndLabel() {
+    labelTreeInfoBuilder.popLabel();
+    if (! labelTreeInfoBuilder.isEmptyStack()) {
+      return; // not all labels seen, no output token
+    }
+
+    CharTermAttribute termAtt = labeledFragments.getAttribute(CharTermAttribute.class); // IAE when not there, must be there.
+    termAtt.setEmpty();
+    termAtt.append(treeInfoPayloadTerm); // change char attribute to treeInfoPayloadTerm
+
+    BytesRef payload = labelTreeInfoBuilder.treeInfoBytesRef();
+    labelTreeInfoBuilder.close();
+    if (payload != null) {
+      PayloadAttribute payloadAtt = labeledFragments.addAttribute(PayloadAttribute.class); // might not be there on input
+      payloadAtt.setPayload(payload);
+    } // else only a root, put the treeInfoPayloadTerm in the label stream without payload.
+    labelStream.addState(labeledFragments.captureState());
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/PrefillTokenStream.java b/lucene/label/src/java/org/apache/lucene/analysis/label/PrefillTokenStream.java
new file mode 100644
index 0000000..b77c642
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/PrefillTokenStream.java
@@ -0,0 +1,104 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.AttributeImpl;
+
+/**
+ * A TokenStream that is prefilled by adding token attribute states.
+ * <br>Note (May 2014): This is much like CachingTokenFilter and TeeSinkTokenFilter.SinkTokenStream from the core module.
+ */
+public final class PrefillTokenStream extends TokenStream {
+// CHECKME: move to core module as super class of TeeSinkTokenFilter.SinkTokenStream ?
+
+  private final List<AttributeSource.State> cachedStates = new LinkedList<>();
+  private AttributeSource.State finalState;
+  private Iterator<AttributeSource.State> it = null;
+
+  /** A prefilled TokenStream.
+   * This stream can filled by {@link #addState} and {@link #setFinalState}.
+   * This stream can be (re)started by {@link #reset} and reused after {@link #close}.
+   * @param source See {@link TokenStream#TokenStream(AttributeSource)}.
+   */
+  public PrefillTokenStream(AttributeSource source) {
+    super(source);
+  }
+
+  /** Add token state to be used later at a single invocation of {@link #incrementToken}. */
+  public void addState(AttributeSource.State state) {
+    if (it != null) {
+      throw new IllegalStateException("State can only be added before the stream is consumed.");
+    }
+    cachedStates.add(state);
+  }
+
+  /** Add token state to be used later at invocation of {@link #end}. */
+  public void setFinalState(AttributeSource.State finalState) {
+    this.finalState = finalState;
+  }
+
+  /** Prepare the token stream so a next {@link #incrementToken} will use the earliest added state. */
+  @Override
+  public final void reset() {
+    it = cachedStates.iterator();
+  }
+
+  /** Restore the earliest token state added by {@link #addState} that was not restored yet.
+   * {@link #addState} should not be used after this.
+   * @return true iff such a token state was available.
+   */
+  @Override
+  public final boolean incrementToken() {
+    // lazy init the iterator
+    if (it == null) {
+      it = cachedStates.iterator();
+    }
+
+    if (!it.hasNext()) {
+      return false;
+    }
+
+    AttributeSource.State state = it.next();
+    restoreState(state);
+    return true;
+  }
+
+  /** When a {@link #setFinalState} was done, restore that token state. */
+  @Override
+  public final void end() {
+    if (finalState != null) {
+      restoreState(finalState);
+    }
+  }
+
+  /** Release resources and prepare reuse by clearing all token state. */
+  @Override
+  public void close() throws IOException {
+    super.close();
+    cachedStates.clear();
+    finalState = null;
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/XmlAnalyzer.java b/lucene/label/src/java/org/apache/lucene/analysis/label/XmlAnalyzer.java
new file mode 100644
index 0000000..3cb0072
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/XmlAnalyzer.java
@@ -0,0 +1,649 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.TreeMap;
+import java.util.HashMap;
+
+import javax.xml.namespace.QName;
+import javax.xml.stream.XMLInputFactory;
+import javax.xml.stream.XMLEventReader;
+import javax.xml.stream.XMLStreamException;
+import javax.xml.stream.XMLStreamConstants;
+import javax.xml.stream.Location;
+import javax.xml.stream.events.XMLEvent;
+import javax.xml.stream.events.StartElement;
+import javax.xml.stream.events.Characters;
+
+//use complete name of javax.xml.stream.events.Attribute
+//use complete name of org.apache.lucene.util.Attribute
+
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+
+
+/** Transform an {@link XMLEventReader} into a token stream for tags with element structure,
+ * into token streams for attribute names and values, and into token streams for text.
+ * <p>
+ * This does the following:
+ * <br>- the XML element tags are used either as labels or as text stream redirectors,
+ * <br>- the text stream redirecting tags are provided by the user, the first one is used by default.
+ * <p>
+ * For each XML element with a label tag:
+ * <br>- the tag name is used as a label in a label token stream,
+ * <br>- the specified attributes are sorted by their qualified names,
+ * <br>- attribute names are put into a dedicated fragment stream as single tokens,
+ * <br>- attribute values are put into another dedicated fragment stream as single tokens, and
+ * <br>- attribute fragment positions are provided in a dedicated fragment positions stream.
+ * <br>The tree structure of the elements with labels tags is provided in a label tree info payload.
+ * <p>
+ * The attributes of XML elements with text redirecting tags are ignored.
+ * <p>
+ * When text redirecting tags are provided, XML element texts are tokenized and put into
+ * a fragment stream associated with the latest enclosing redirecting tag,
+ * or into a default text fragment stream.
+ * <p>
+ * All element texts occurring after a nested element are given a special label.
+ * <br>The tokenizers for the element texts need to be provided.
+ * <p>
+ * The output token streams can be used for indexing in the same way as the output streams of
+ * a {@link LabeledTreeFragmentsAnalyzer}.
+ * <br>After indexing the XML tags that are used as labels, their attributes and text tokens can be searched by
+ * subclasses of {@link org.apache.lucene.search.spans.label.LabeledTreeQuery} by providing the indexed field names.
+ * <br>The fragment positions of the attribute values are not provided separately because they are the same as
+ * the fragment positions of the attribute names. The attributes names and their values can be searched by
+ * {@link org.apache.lucene.search.spans.FieldMaskingSpanQuery}.
+ * <p>
+ * Some limitations to be considered before using this class:
+ * <br>- The first XML element must have not a have a text redirecting tag.
+ * <br>- Tokenizing XML attribute values is not supported.
+ *       XML attribute values consisting of multiple tokens may be transformed into element texts
+ *       with the element tag as the original attribute name.
+ * <br>- For the underlying XML parser, the attributes of an XML element are fundamentally unordered.
+ * Therefore in the parsed XML the specified attributes may not be in the same order as in the input XML.
+ * To improve consistency the specified attributes are sorted at each XML element before generating the output streams.
+ * <br>- Repetitive XML elements with text that consist of a single token may be transformed into attributes.
+ * <br>- When an attribute name without an attribute value is needed at a label,
+ *       a token stream with a single token per label can be used.
+ * <br>- XML markup inside a single Lucene token is not supported.
+ * <p>
+ * This example illustrates text redirection for the <code>editor</code> and <code>title</code> tags,
+ * and <code>some more text</code> is added to illustrate the default text token stream
+ * and the label inserted for text after a nested XML element:
+ * <p>
+ * <pre>
+ * &lt;kiosk&gt;
+ *   some
+ *   &lt;newspaper counter="42"&gt;
+ *     &lt;editor&gt;J. More&lt;/editor&gt;
+ *     &lt;title&gt;Greatest&lt;/title&gt;
+ *   &lt;/newspaper&gt;
+ *   more text
+ *   &lt;newspaper counter="43"&gt;
+ *     &lt;editor&gt;C. Less&lt;/editor&gt;
+ *     &lt;title&gt;Early Morning&lt;/title&gt;
+ *   &lt;/newspaper&gt;
+ * &lt;/kiosk&gt;
+ * </pre>
+ * When the parser is provided with:
+ * <br>- text stream tags <code>["txt", "editor", "title"]</code>, <code>"txt"</code> is the default as the first one,
+ * <br>- white space text tokenizers for the text stream tags,
+ * <br>- <code>"after"</code> as the label to be used for text after a nested XML element
+ *       (just before "more text" above),
+ * <br>- <code>"treeInfo"</code> as the token string for the tree info payload, and
+ * <br>- <code>"fragPos"</code> as the token string for each fragment positions payload,
+ * <br>the following example token streams will be made after parsing:
+ * <p>
+ * <table border="1">
+ * <tr>
+ *   <td>made by</td>
+ *   <td>token strings (payload)</td>
+ * </tr>
+ * <tr>
+ *     <td> <code>labelTokenStream()<code></td>
+ *     <td> <code>"kiosk" "newspaper" "after" "newspaper" "treeInfo"(0,3, 0,0, 0,0, 0,0)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrNameFragmentsTokenStream()</code>
+ *     <td> <code>"counter" "counter"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrValueFragmentsTokenStream()</code>
+ *     <td> <code>"42" "43"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrFragmentPositionsTokenStream("fragPos")</code>
+ *     <td> <code>"fragPos"(0, 0, 1, 1, 2)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("txt")</code>
+ *     <td> <code>"some" "more" "text"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("txt", "fragPos")<code>
+ *     <td> <code>"fragPos"(0, 1, 1, 3, 3)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("editor")</code>
+ *     <td> <code>"J." "More" "C." "Less"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("editor", "fragPos")<code>
+ *     <td> <code>"fragPos"(0, 0, 2, 2, 4)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("title")</code>
+ *     <td> <code>"Greatest" "Early" "Morning"</code></td>
+ * </td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("title", "fragPos")<code>
+ *     <td> <code>"fragPos"(0, 0, 1, 1, 3)</code></td>
+ * </tr>
+ * </table>
+ * The tree info payload is documented at {@link LabeledTreeFragmentsAnalyzer} and
+ * the fragment positions payload is documented at {@link LabeledFragmentsAnalyzer}.
+ *
+ * @lucene.experimental
+ */
+public class XmlAnalyzer {
+
+  /** Provides tokens and label names not provided by the XML parser.
+   *  These methods are called in the order in which the XML elements texts are parsed.
+   */
+  public interface LabeledTreeTokens {
+
+    /** The label to be used for text occurring after a nested XML element.
+     */
+    public String fragmentLabelAfterNestedElement();
+
+    /** Tokenizer to provide fragment tokens from an XML element text.
+     *  @param tag The tag of the XML element or <code>null</code> for element texts directly after a nested element.
+     */
+    public Tokenizer textTokenizer(String tag);
+  }
+
+  private LabeledTreeTokens labeledTreeTokens;
+
+  private LabelTreeInfoBuilder labelTreeInfoBuilder;
+  private PrefillTokenStream labelStream;
+  private AttributeSource labelAttributes;
+  private CharTermAttribute labelCharTermAttribute;
+  private PayloadAttribute labelPayloadAttribute;
+  private OffsetAttribute labelOffsetAttribute;
+  private final String labelTreeInfoPayloadTerm;
+
+  private FragmentPositionsStreamBuilder attrNameFPSB;
+  private PrefillTokenStream attrValueStream;
+
+  // for xml attribute name and value streams:
+  private AttributeSource xmlAttributeStreamsTokenAttributes;
+  private CharTermAttribute xmlAttributeStreamsCharTermAttribute;
+  private OffsetAttribute xmlAttributeStreamsOffsetAttribute;
+  // for text streams:
+  private List<String> textStreamTags;
+  private HashMap<String,TextFragmentsBuilder> textFragmentsBuilderByTag;
+  private TextFragmentsBuilder defaultTextFragmentsBuilder;
+  /** Construct an XmlAnalyzer.
+   * @param textStreamTags The tags of XML elements to be used for redirecting text to fragment streams.
+   *                       These tags should all be different. The first one is used as the default.
+   *                       The top level XML element should have a different tag.
+   *                       <br>When this is empty or null, no XML text elements will be tokenized.
+   * @param labeledTreeTokens Provides the labels for text after nested XML elements and provides the text tokenizers.
+   * @param labelTreeInfoPayloadTerm The term to contain the label tree info as payload.
+   */
+  public XmlAnalyzer (
+        List<String> textStreamTags,
+        LabeledTreeTokens labeledTreeTokens,
+        String labelTreeInfoPayloadTerm) {
+    this.textStreamTags = textStreamTags;
+    this.labeledTreeTokens = labeledTreeTokens;
+    this.labelTreeInfoPayloadTerm = labelTreeInfoPayloadTerm;
+
+    this.labelAttributes = new AttributeSource(Token.TOKEN_ATTRIBUTE_FACTORY);
+    this.labelCharTermAttribute = labelAttributes.addAttribute(CharTermAttribute.class);
+    this.labelOffsetAttribute = labelAttributes.addAttribute(OffsetAttribute.class);
+    this.labelPayloadAttribute = labelAttributes.addAttribute(PayloadAttribute.class);
+    this.labelStream = new PrefillTokenStream(labelAttributes);
+
+    this.labelTreeInfoBuilder = new LabelTreeInfoBuilder();
+
+    this.xmlAttributeStreamsTokenAttributes = new AttributeSource(Token.TOKEN_ATTRIBUTE_FACTORY);
+    this.xmlAttributeStreamsCharTermAttribute = xmlAttributeStreamsTokenAttributes.addAttribute(CharTermAttribute.class);
+    this.xmlAttributeStreamsOffsetAttribute = xmlAttributeStreamsTokenAttributes.addAttribute(OffsetAttribute.class);
+
+    this.attrNameFPSB = new FragmentPositionsStreamBuilder(xmlAttributeStreamsTokenAttributes);
+    this.attrValueStream = new PrefillTokenStream(xmlAttributeStreamsTokenAttributes); // same positions as attribute names
+
+    this.textFragmentsBuilderByTag = new HashMap<>();
+    this.defaultTextFragmentsBuilder = null;
+    if (this.textStreamTags != null) {
+      for (String tag: this.textStreamTags) {
+        if (this.textFragmentsBuilderByTag.get(tag) != null) {
+          throw new IllegalArgumentException("text stream redirecting tag occurs more than once: " + tag);
+        }
+        this.textFragmentsBuilderByTag.put(tag, new TextFragmentsBuilder(labeledTreeTokens.textTokenizer(tag)));
+      }
+      if (! textStreamTags.isEmpty()) {
+        this.defaultTextFragmentsBuilder = textFragmentsBuilderByTag.get(textStreamTags.get(0));
+      }
+    }
+  }
+
+  /** Provide an XMLEventReader for creating labeled fragments token streams.
+   * After this, when no exception is thrown,
+   * {@link #labelTokenStream},
+   * {@link #attrNameFragmentsTokenStream},
+   * {@link #attrValueFragmentsTokenStream},
+   * {@link #attrFragmentPositionsTokenStream},
+   * {@link #textFragmentsStream} and
+   * {@link #textFragmentPositionsStream}
+   * will provide token streams for the parsed XML.
+   * @param xmlEventReader    Provides XML as parsing events. All available events are read.
+   *                          <br>The {@link XMLStreamConstants#START_ELEMENT}
+   *                          and {@link XMLStreamConstants#END_ELEMENT} events are used to provide the labels
+   *                          from the tag names, except for tags present in <code>textStreamTags</code>
+   *                          passed to the constructor.
+   *                          <br>The attributes specified at the element are taken from the XML start element events,
+   *                          {@link XMLStreamConstants#ATTRIBUTE} events should not occur.
+   *                          <br>{@link XMLStreamConstants#CHARACTERS} events should be coalesced.
+   *                          When some of these characters are non white space they are tokenized into text fragments.
+   *                          <br>The following events the are ignored:
+   *                           {@link XMLStreamConstants#COMMENT},
+   *                           {@link XMLStreamConstants#PROCESSING_INSTRUCTION},
+   *                           {@link XMLStreamConstants#START_DOCUMENT},
+   *                           {@link XMLStreamConstants#END_DOCUMENT},
+   *                           {@link XMLStreamConstants#NAMESPACE},
+   *                           {@link XMLStreamConstants#DTD}.
+   * @param initialOffset     The initial character offset. This is added to the XML location and set in the
+   *                          provided token streams where possible, except in the fragment positions streams.
+   * @throws IOException from a provided text tokenizer.
+   * @throws XMLStreamException from the <code>xmlEventReader</code>.
+   * @throws IllegalArgumentException when the <code>xmlEventReader</code> does not coalesce its elements texts.
+   */
+  public void consumeXmlEventReader(XMLEventReader xmlEventReader, int initialOffset)
+  throws IOException, XMLStreamException {
+    if (! Boolean.TRUE.equals(xmlEventReader.getProperty(XMLInputFactory.IS_COALESCING))) {
+      throw new IllegalArgumentException("xmlEventReader should be coalescing its element texts");
+    }
+    clear(); // any pending output.
+    iterateXmlEvents(xmlEventReader, initialOffset);
+  }
+
+  /** Provide an XMLEventReader for creating labeled fragments token streams.
+   * As {@link #consumeXmlEventReader(XMLEventReader,int)} with 0 initial offset.
+   */
+  public void consumeXmlEventReader(XMLEventReader xmlEventReader)
+  throws IOException, XMLStreamException {
+    consumeXmlEventReader(xmlEventReader, 0);
+  }
+
+  /** Release all resources built for the consumed input. */
+  private void clear() {
+    labelStream = new PrefillTokenStream(labelAttributes); // replace, do not close, may still be indexed.
+    labelTreeInfoBuilder.reInit();
+    attrNameFPSB.clear();
+    attrValueStream = new PrefillTokenStream(xmlAttributeStreamsTokenAttributes); // replace, do not close, may still be indexed.
+    if (textStreamTags != null) {
+      for (String tag: textStreamTags) {
+        TextFragmentsBuilder tfb = textFragmentsBuilderByTag.get(tag);
+        if (tfb != null) {
+          tfb.clear();
+        }
+      }
+    }
+  }
+
+
+  /** Make the label token stream from the tags of the XML elements that are not used to redirect text to fragment streams.
+   * This stream also contains the label tree info payload for the tree structure of these XML elements.
+   */
+  public TokenStream labelTokenStream() {
+    return labelStream;
+  }
+
+  /** Make the token stream for the XML attribute names. */
+  public TokenStream attrNameFragmentsTokenStream() {
+    return attrNameFPSB.fragmentsTokenStream();
+  }
+
+  /** Make the token stream for the XML attribute values. */
+  public TokenStream attrValueFragmentsTokenStream() {
+    return attrValueStream;
+  }
+
+  /** Make the token stream containing the XML attribute fragment positions payload. */
+  public TokenStream attrFragmentPositionsTokenStream(String fragmentPositionsTerm) {
+    return attrNameFPSB.fragmentPositionsTokenStream(fragmentPositionsTerm);
+  }
+
+  /** Make the token stream containing the tokenized XML element texts for the given text stream tag. */
+  public TokenStream textFragmentsStream(String textStreamTag) {
+    return textFragmentsBuilderByTag.get(textStreamTag).fragmentsTokenStream();
+  }
+
+  /** Make the token stream containing the payload for the fragment positions of the XML element text tokens
+   * for the given text stream tag.
+   */
+  public TokenStream textFragmentPositionsStream(String textStreamTag, String fragmentPositionsTerm) {
+    return textFragmentsBuilderByTag.get(textStreamTag).fragmentPositionsTokenStream(fragmentPositionsTerm);
+  }
+
+  private void iterateXmlEvents(XMLEventReader xmlEventReader, int initialOffset) throws IOException, XMLStreamException {
+    labelPayloadAttribute.setPayload(null); // only needed at end of label stream
+
+    elementAttrValueByName = new TreeMap<>(); // avoid reallocation for each tag.
+
+    class LevelInfo {
+      String tag;
+      boolean tagIsLabel; // otherwise the tag redirects text.
+      int previousLabelLevel;
+      boolean tagIsOpenAsLabel;
+      boolean labelAfterNestedElementOpen;
+      TextFragmentsBuilder tfb;
+    }
+    ArrayList<LevelInfo> levelInfos = new ArrayList<>();
+    int currentLevel = -1;
+    LevelInfo currentLevelInfo = null;
+
+    Location xmlLocation = null;
+    int lastCharacterOffset = initialOffset;
+    int prevCharacterOffset = initialOffset;
+    while (xmlEventReader.hasNext()) {
+      XMLEvent xmlEvent = xmlEventReader.nextEvent();
+      int eventType = xmlEvent.getEventType();
+
+      xmlLocation = xmlEvent.getLocation();
+      int curOffset = xmlLocation.getCharacterOffset(); // end position of last XML event, but -1 for ENDDOCUMENT event
+      if (curOffset >= 0) {
+        prevCharacterOffset = lastCharacterOffset;
+        lastCharacterOffset = curOffset + initialOffset;
+      }
+
+      switch (eventType) {
+
+      case XMLStreamConstants.START_ELEMENT:
+
+        StartElement startElement = xmlEvent.asStartElement();
+        QName qualifiedTagName = startElement.getName();
+        String tag = qualifiedTagName.getLocalPart();
+        TextFragmentsBuilder nextTextFragmentsBuilder = textFragmentsBuilderByTag.get(tag);
+
+        if (nextTextFragmentsBuilder == null) { // use the tag as a label
+          if (currentLevelInfo != null) {
+            if (currentLevelInfo.labelAfterNestedElementOpen) {
+              popLabel();
+              currentLevelInfo.labelAfterNestedElementOpen = false; // may be opened again.
+            }
+          }
+        }
+
+        int prevLabelLevel = (currentLevel < 0) ? -1
+                            : currentLevelInfo.tagIsLabel ? currentLevel
+                            : currentLevelInfo.previousLabelLevel;
+
+        TextFragmentsBuilder prevTextFragmentsBuilder = (currentLevel < 0) ? defaultTextFragmentsBuilder : currentLevelInfo.tfb;
+
+        currentLevel++;
+        if (levelInfos.size() <= currentLevel) {
+          levelInfos.add(new LevelInfo());
+        }
+        currentLevelInfo = levelInfos.get(currentLevel);
+        currentLevelInfo.tag = tag;
+
+        if (nextTextFragmentsBuilder == null) { // use the tag as a label
+          pushLabel(tag, prevCharacterOffset, lastCharacterOffset);
+          currentLevelInfo.tagIsLabel = true;
+          currentLevelInfo.previousLabelLevel = prevLabelLevel;
+          currentLevelInfo.tagIsOpenAsLabel = true;
+          currentLevelInfo.labelAfterNestedElementOpen = false;
+          currentLevelInfo.tfb = prevTextFragmentsBuilder;
+          if (currentLevelInfo.previousLabelLevel >= 0) {
+            levelInfos.get(currentLevelInfo.previousLabelLevel).tagIsOpenAsLabel = false;
+          }
+          addAttributes(startElement, prevCharacterOffset, lastCharacterOffset);
+        }
+        else if (currentLevelInfo == null) {
+          throw new IllegalArgumentException("text stream tag at top level: " + tag);
+        }
+        else { // tag redirects text, ignore attributes.
+          currentLevelInfo.tagIsLabel = false;
+          currentLevelInfo.previousLabelLevel = prevLabelLevel;
+          assert levelInfos.get(currentLevelInfo.previousLabelLevel).tagIsLabel;
+          // new level shares open extra text label:
+          currentLevelInfo.labelAfterNestedElementOpen = levelInfos.get(currentLevel-1).labelAfterNestedElementOpen;
+          currentLevelInfo.tfb = nextTextFragmentsBuilder;
+        }
+        break;
+
+      case XMLStreamConstants.END_ELEMENT:
+
+        if (currentLevelInfo.tagIsLabel) {
+          if (currentLevelInfo.labelAfterNestedElementOpen) {
+            popLabel();
+            currentLevelInfo.labelAfterNestedElementOpen = false;
+          }
+          popLabel();
+          currentLevelInfo.tagIsOpenAsLabel = false;
+        }
+        else { // current tag redirects text
+          if (currentLevelInfo.labelAfterNestedElementOpen) {  // next lower level shares open extra text label
+            levelInfos.get(currentLevel-1).labelAfterNestedElementOpen = true;
+          }
+        }
+
+        currentLevel--;
+        if (currentLevel < 0) {
+          currentLevelInfo = null;
+        }
+        else {
+          currentLevelInfo = levelInfos.get(currentLevel);
+        }
+        break;
+
+      case XMLStreamConstants.CHARACTERS:
+
+        if (currentLevelInfo.tfb == null) { // no text needs to be tokenized
+          break;
+        }
+        Characters characters = xmlEvent.asCharacters(); // coalesced
+        if (characters.isWhiteSpace()) {
+          break;
+        }
+        int labelLevel = currentLevelInfo.tagIsLabel ? currentLevel : currentLevelInfo.previousLabelLevel;
+        if (! levelInfos.get(labelLevel).tagIsOpenAsLabel) {
+          if (! currentLevelInfo.labelAfterNestedElementOpen) {
+            pushLabel(labeledTreeTokens.fragmentLabelAfterNestedElement(), prevCharacterOffset, prevCharacterOffset);
+            currentLevelInfo.labelAfterNestedElementOpen = true;
+          }
+        }
+        String elementText = characters.getData();
+        currentLevelInfo.tfb.tokenizeToFragmentStream(elementText, prevCharacterOffset);
+        break;
+
+      case XMLStreamConstants.COMMENT:
+      case XMLStreamConstants.PROCESSING_INSTRUCTION:
+      case XMLStreamConstants.START_DOCUMENT:
+      case XMLStreamConstants.END_DOCUMENT:
+      case XMLStreamConstants.NAMESPACE:
+      case XMLStreamConstants.DTD:
+        // ignore
+        break;
+
+      case XMLStreamConstants.ATTRIBUTE: // not used in XML input
+        throw new IllegalArgumentException("Unexpected attribute eventType=" + eventType);
+
+      default:
+        throw new IllegalStateException("Unknown eventType=" + eventType);
+      }
+    }
+
+    if (! labelTreeInfoBuilder.isEmptyStack()) {
+      throw new IllegalArgumentException("not all XML elements ended");
+    }
+
+    // final end positions:
+    attrNameFPSB.addSizeAsPosition();
+    for (TextFragmentsBuilder tfb: textFragmentsBuilderByTag.values()) {
+      tfb.addSizeAsPosition();
+    }
+
+    // final term in label stream with tree info payload
+    labelCharTermAttribute.setEmpty();
+    labelCharTermAttribute.append(labelTreeInfoPayloadTerm);
+    BytesRef payload = labelTreeInfoBuilder.treeInfoBytesRef();
+    labelTreeInfoBuilder.close();
+    if (payload != null) {
+      labelPayloadAttribute.setPayload(payload);
+    } // else only a root, no payload.
+    if (xmlLocation != null) {
+      labelOffsetAttribute.setOffset(lastCharacterOffset, lastCharacterOffset + labelTreeInfoPayloadTerm.length());
+    }
+    labelStream.addState(labelAttributes.captureState());
+  }
+
+  private void pushLabel(String label, int prevCharacterOffset, int lastCharacterOffset) {
+    if (label.equals(labelTreeInfoPayloadTerm)) {
+      throw new IllegalArgumentException("label tree info payload term should not occur as XML tag name " + label);
+    }
+
+    labelCharTermAttribute.setEmpty();
+    labelCharTermAttribute.append(label);
+
+    labelOffsetAttribute.setOffset(prevCharacterOffset, lastCharacterOffset);
+
+    labelStream.addState(labelAttributes.captureState());
+
+    labelTreeInfoBuilder.pushLabel();
+
+    // start positions for new label of attribute name fragment and all text fragments:
+    attrNameFPSB.addSizeAsPosition();
+    for (TextFragmentsBuilder tfb: textFragmentsBuilderByTag.values()) {
+      tfb.addSizeAsPosition();
+    }
+  }
+
+  private void popLabel() {
+    labelTreeInfoBuilder.popLabel();
+  }
+
+  private TreeMap<String,String> elementAttrValueByName;
+
+  private void addAttributes(StartElement startElement, int tagStartOffset, int tagEndOffset) {
+    elementAttrValueByName.clear();
+    Iterator<?> attributes = startElement.getAttributes();
+    while (attributes.hasNext()) {
+      javax.xml.stream.events.Attribute attribute = (javax.xml.stream.events.Attribute) attributes.next();
+      if (attribute.isSpecified()) {
+        QName qualifiedAttrName = attribute.getName();
+        String attrName = qualifiedAttrName.toString();
+        String attrValue = attribute.getValue();
+        elementAttrValueByName.put(attrName, attrValue);
+        // Location attrLocation = attribute.getLocation(); // attrLocation.getCharacterOffset() returns -1, ignore
+      }
+    }
+    if (! elementAttrValueByName.isEmpty()) {
+      xmlAttributeStreamsOffsetAttribute.setOffset(tagStartOffset, tagEndOffset); // best effort, see attrLocation above.
+    }
+    for (String attrName: elementAttrValueByName.keySet()) { // TreeMap sorted by attrName
+      xmlAttributeStreamsCharTermAttribute.setEmpty();
+      xmlAttributeStreamsCharTermAttribute.append(attrName);
+      attrNameFPSB.addTokenState(xmlAttributeStreamsTokenAttributes);
+      attrNameFPSB.incrementFragmentsSize();
+
+      String attrValue = elementAttrValueByName.get(attrName);
+      xmlAttributeStreamsCharTermAttribute.setEmpty();
+      xmlAttributeStreamsCharTermAttribute.append(attrValue);
+      attrValueStream.addState(xmlAttributeStreamsTokenAttributes.captureState());
+    }
+    elementAttrValueByName.clear();
+  }
+
+  private class TextFragmentsBuilder {
+    final Tokenizer tokenizer;
+    final PositionIncrementAttribute posIncrAttr;
+    final OffsetAttribute offsetAttr;
+
+    FragmentPositionsStreamBuilder fpsb;
+
+    TextFragmentsBuilder(Tokenizer tokenizer) {
+      this.tokenizer = tokenizer;
+      this.fpsb = new FragmentPositionsStreamBuilder(tokenizer);
+
+      if (tokenizer.hasAttribute(PositionIncrementAttribute.class)) {
+        posIncrAttr = tokenizer.getAttribute(PositionIncrementAttribute.class);
+      } else {
+        posIncrAttr = null;
+      }
+      if (tokenizer.hasAttribute(OffsetAttribute.class)) {
+        offsetAttr = tokenizer.getAttribute(OffsetAttribute.class);
+      } else {
+        offsetAttr = null;
+      }
+    }
+
+    TokenStream fragmentsTokenStream() {
+      return fpsb.fragmentsTokenStream();
+    }
+
+    TokenStream fragmentPositionsTokenStream(String fragmentPositionsTerm) {
+      return fpsb.fragmentPositionsTokenStream(fragmentPositionsTerm);
+    }
+
+    void addSizeAsPosition() {
+      fpsb.addSizeAsPosition();
+    }
+
+    void tokenizeToFragmentStream(String elementText, int initialOffset) throws IOException {
+      tokenizer.setReader(new StringReader(elementText));
+      tokenizer.reset();
+      while (tokenizer.incrementToken()) {
+        if (offsetAttr != null) {
+          offsetAttr.setOffset(offsetAttr.startOffset() + initialOffset, offsetAttr.endOffset() + initialOffset);
+        }
+        fpsb.addTokenState(tokenizer);
+        if (posIncrAttr != null) {
+          int posIncr = posIncrAttr.getPositionIncrement();
+          fpsb.incrementFragmentsSize(posIncr);
+        } else {
+          fpsb.incrementFragmentsSize();
+        }
+      }
+      tokenizer.end();
+      tokenizer.close();
+    }
+
+    void clear() {
+      fpsb.clear();
+    }
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/analysis/label/package.html b/lucene/label/src/java/org/apache/lucene/analysis/label/package.html
new file mode 100644
index 0000000..1fa4baf
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/analysis/label/package.html
@@ -0,0 +1,29 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<body>
+Split a labeled fragments stream into token streams for (nested) labels, fragments, and fragment start/end positions.
+<p>
+For labeled streams with <code>1 : 0..n</code> relationships between label token positions and fragment token positions this is done
+by {@link org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer}.
+<p>
+For labels nested in a tree, with fragments as leafs, this is done by {@link org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer}.
+<br>
+{@link org.apache.lucene.analysis.label.XmlAnalyzer} splits an XML parsing event stream consisting of tags, attributes and element texts
+into a label tree and various fragment token streams with fragment start/end positions.
+</body>
+</html>
diff --git a/lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java b/lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java
new file mode 100644
index 0000000..cf566f6
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java
@@ -0,0 +1,111 @@
+package org.apache.lucene.document.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import org.apache.lucene.index.Term;
+
+/** A field schema for a Lucene document with a single label field and some fragment fields labeled by the label field.
+ * The labels may form a hierarchy within a document.
+ */
+public class LabelFieldSchema {
+  private String labelFieldName;
+  private String treeInfoPayloadTermText;
+  private ArrayList<String> fragmentFieldNames = new ArrayList<>(0); // in input order.
+  private HashMap<String,Term> positionsPayloadTermByFragmentFieldName = new HashMap<>();
+
+  /** Create a LabelFieldSchema for a label field where the labels do not form a hierarchy within a document.
+   * @param labelFieldName The label field name.
+   */
+  public LabelFieldSchema(String labelFieldName) {
+    if (labelFieldName == null) {
+      throw new IllegalArgumentException("labelFieldName should not be null");
+    }
+    this.labelFieldName = labelFieldName;
+    this.treeInfoPayloadTermText = null;
+  }
+
+  /** Create a LabelFieldSchema for a label field where the labels form a hierarchy within a document.
+   * @param labelFieldName The label field name.
+   * @param treeInfoPayloadTermText The term text for the term in the label field that has a tree info payload.
+   */
+  public LabelFieldSchema(String labelFieldName, String treeInfoPayloadTermText) {
+    this(labelFieldName);
+    if (treeInfoPayloadTermText == null) {
+      throw new IllegalArgumentException("treeInfoPayloadTermText should not be null");
+    }
+    this.treeInfoPayloadTermText = treeInfoPayloadTermText;
+  }
+
+  /** Add a fragment field labeled by the labels in the label field of the same document.
+   * @param fragmentFieldName The fragment field name. Each name can only be added once, should be non null, and should not be equal the label field name.
+   * @param fragmentPositionsPayloadTerm The term that has a payload with the fragment positions for the labels.
+   *                                     This term may be shared between different fragment fields. This should be non null.
+   * @return The unique non negative schema index of the added fragment field.
+   */
+  public int addLabeledFragmentField(String fragmentFieldName, Term fragmentPositionsPayloadTerm) {
+    if (fragmentFieldName == null) {
+      throw new IllegalArgumentException("fragmentFieldName should not be null");
+    }
+    if (fragmentPositionsPayloadTerm == null) {
+      throw new IllegalArgumentException("fragmentPositionsPayloadTerm should not be null");
+    }
+    if (fragmentFieldName.equals(labelFieldName)) {
+      throw new IllegalArgumentException("fragment field should not be same as the label field: " + fragmentFieldName);
+    }
+    if (positionsPayloadTermByFragmentFieldName.containsKey(fragmentFieldName)) {
+      throw new IllegalArgumentException(fragmentFieldName + " can only be labeled once by " + labelFieldName);
+    }
+    int ffi = fragmentFieldNames.size();
+    fragmentFieldNames.add(fragmentFieldName);
+    positionsPayloadTermByFragmentFieldName.put(fragmentFieldName, fragmentPositionsPayloadTerm);
+    return ffi;
+  }
+
+  /** The label field name. */
+  public String getLabelFieldName() {
+    return labelFieldName;
+  }
+
+  /** The term text of the term with the tree info payload, or null. */
+  public String getTreeInfoPayloadTermText() {
+    return treeInfoPayloadTermText;
+  }
+
+  /** The fragment field name for the fragment field at the given schema index. */
+  public String getFragmentFieldName(int ffi) {
+    return fragmentFieldNames.get(ffi);
+  }
+
+  /** The fragment positions payload term for the fragment field at the given schema index. */
+  public Term getFragmentPositionsPayloadTerm(int ffi) {
+    return positionsPayloadTermByFragmentFieldName.get(fragmentFieldNames.get(ffi));
+  }
+
+  /** Returns the non negative fragment field schema index of the given field name when the given field is a fragment field in the schema, otherwise -1. */
+  public int fragmentFieldIndex(String fieldName) {
+    if (! positionsPayloadTermByFragmentFieldName.containsKey(fieldName)) {
+      return -1;
+    }
+    int ffi = fragmentFieldNames.indexOf(fieldName);
+    assert ffi >= 0;
+    return ffi;
+  }
+}
+
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java
new file mode 100644
index 0000000..7daea41
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java
@@ -0,0 +1,130 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to a child label.
+ *
+ * @lucene.experimental
+ */
+public class ChildLabelQuery extends LabeledTreeQuery {
+  private final int childNum;
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the label Spans of a child label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param childNum            The child number, starting from 0.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   */
+  public ChildLabelQuery(
+        SpanQuery labelQuery,
+        int childNum,
+        String treeInfoPayloadTerm) {
+    super(labelQuery, treeInfoPayloadTerm);
+    this.childNum = childNum;
+  }
+
+
+  /** The label Spans transformed to a Spans of a child of the labels.
+   * <br>The input start position is transformed the start position of the child.
+   * <br>The end position of the child is 1 after the start position of the child, i.e. the label end is ignored.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new ChildLabelSpans(context, getLabelQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class ChildLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    ChildLabelSpans(LeafReaderContext context, Spans labelSpans) throws IOException {
+      super(context, labelSpans);
+    }
+
+    int childNode = TreeInfo.NO_SUCH_NODE;
+
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      if (! super.next()) {
+        return false;
+      }
+      return spanWithChild();
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      if (! super.skipTo(target)) {
+        return false;
+      }
+      return spanWithChild();
+    }
+
+    boolean spanWithChild() throws IOException {
+      do {
+        int node = labelSpans.start();
+        childNode = treeInfo.childNode(node, childNum);
+        if (childNode != TreeInfo.NO_SUCH_NODE) {
+          return true;
+        }
+        if (! super.next()) {
+          return false;
+        }
+      } while(true);
+    }
+
+    @Override
+    public int start() {
+      assert (childNode != TreeInfo.NO_SUCH_NODE);
+      return childNode;
+    }
+
+    @Override
+    public int end() {
+      assert (childNode != TreeInfo.NO_SUCH_NODE);
+      return childNode + 1;
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (! super.equals(obj)) {
+      return false;
+    }
+    ChildLabelQuery other = (ChildLabelQuery) obj;
+    return childNum == other.childNum;
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode() ^ childNum;
+  }
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java
new file mode 100644
index 0000000..e5e9fae
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java
@@ -0,0 +1,136 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to a Spans for all descendant labels.
+ *
+ * @lucene.experimental
+ */
+public class DescendantsLabelQuery extends LabeledTreeQuery {
+
+  private final boolean includeLabel;
+
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to a spans for all descendant labels.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   * @param includeLabel        Indicates whether the label itself should be included in the result.
+   *                            In any case the result will only contain spans for which at least one child is available.
+   */
+  public DescendantsLabelQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm,
+        boolean includeLabel) {
+    super(labelQuery, treeInfoPayloadTerm);
+    this.includeLabel = includeLabel;
+  }
+
+
+  /** The label Spans transformed to a Spans a spans for all descendant labels.
+   * <br>The input start position is transformed its first child.
+   * <br>The output end position is taken from the last descendant of the input start position, the input end position is ignored.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new DescendantsLabelSpans(context, getLabelQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class DescendantsLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    DescendantsLabelSpans(LeafReaderContext context, Spans labelSpans) throws IOException {
+      super(context, labelSpans);
+    }
+
+    int currentStartNode = TreeInfo.NO_SUCH_NODE;
+    int firstChildNode = TreeInfo.NO_SUCH_NODE;
+    int lastDescendantNode = TreeInfo.NO_SUCH_NODE;
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      if (! super.next()) {
+        return false;
+      }
+      return spanWithDescendant();
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      if (! super.skipTo(target)) {
+        return false;
+      }
+      return spanWithDescendant();
+    }
+
+    boolean spanWithDescendant() throws IOException {
+      do {
+        currentStartNode = labelSpans.start();
+        int numDesc = treeInfo.numDescendants(currentStartNode);
+        if (numDesc > 0) {
+          firstChildNode = currentStartNode + 1;
+          lastDescendantNode = currentStartNode + numDesc;
+          return true;
+        }
+        if (! super.next()) {
+          return false;
+        }
+      } while(true);
+    }
+
+    @Override
+    public int start() {
+      assert (firstChildNode != TreeInfo.NO_SUCH_NODE);
+      return includeLabel ? currentStartNode : firstChildNode;
+    }
+
+    @Override
+    public int end() {
+      assert (lastDescendantNode != TreeInfo.NO_SUCH_NODE);
+      return lastDescendantNode + 1;
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (! super.equals(obj)) {
+      return false;
+    }
+    DescendantsLabelQuery other = (DescendantsLabelQuery) obj;
+    return includeLabel == other.includeLabel;
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode() ^ (includeLabel ? Boolean.TRUE.hashCode() : Boolean.FALSE.hashCode());
+  }
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java
new file mode 100644
index 0000000..cc194e9
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java
@@ -0,0 +1,108 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+
+import org.apache.lucene.util.packed.EliasFanoDecoder;
+
+/**
+ * Transform the Spans of a SpanQuery from a fragment field to a label field.
+ * <br>See also {@link LabeledFragmentsQuery}.
+ *
+ * @lucene.experimental
+ */
+public class FragmentToLabelQuery extends LabeledFragmentsQuery {
+  /** Transforms the Spans of a {@link SpanQuery} from a fragment field to a label field.
+   * @param fragmentQuery                Provides the Spans in the fragment field.
+   * @param fragmentPositionsPayloadTerm The term at which the fragment start/end positions are indexed.
+   * @param labelField                   The field to which the fragment spans are transformed.
+   */
+  public FragmentToLabelQuery(
+        SpanQuery fragmentQuery,
+        Term fragmentPositionsPayloadTerm,
+        String labelField) {
+    super(fragmentQuery, fragmentPositionsPayloadTerm, labelField);
+  }
+
+  public SpanQuery getFragmentQuery() {
+    return getSourceQuery();
+  }
+
+  /** The fragments Spans transformed to labels.
+   * <br>The start position of each fragment Span is changed to the start position of the associated label.
+   * <br>The end position of each fragment Span is changed to the end position of the associated label.
+   *     For an end position that is within an indexed fragment, the end position of the associated label is used.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new FragmentToLabelSpans(context, getSourceQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class FragmentToLabelSpans extends LabeledFragmentsSpans {
+    FragmentToLabelSpans(LeafReaderContext context, Spans fragmentSpans) throws IOException {
+      super(context, fragmentSpans);
+    }
+
+    @Override
+    public int start() {
+      int res = getLabelPosition(sourceSpans.start());
+      return res;
+    }
+
+    @Override
+    public int end() {
+      int res = getLabelPosition(sourceSpans.end() - 1) + 1; // end position of corresponding label.
+      return res;
+    }
+
+  }
+
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("FragmentToLabelQuery( fragmentQuery="); buffer.append(getSourceQuery().toString(field));
+    buffer.append(", labelField="); buffer.append(getTargetField());
+    buffer.append(", fragmentPositionsPayloadTerm="); buffer.append(getFragmentPositionsPayloadTerm().toString());
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  @Override
+  public boolean equals(Object obj) { // no attributes here
+    return super.equals(obj);
+  }
+
+  @Override
+  public int hashCode() { // no attributes here
+    return super.hashCode();
+  }
+
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java
new file mode 100644
index 0000000..6d87f4a
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java
@@ -0,0 +1,142 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+
+import org.apache.lucene.util.packed.EliasFanoDecoder;
+
+/**
+ * Transform the Spans of a SpanQuery from a label field to a fragment field.
+ * <br>See also {@link LabeledFragmentsQuery}.
+ *
+ * @lucene.experimental
+ */
+public class LabelToFragmentQuery extends LabeledFragmentsQuery {
+
+  /** Transforms the Spans of a {@link SpanQuery} from a label field to a fragment field.
+   * @param labelQuery                   Provides the Spans in the label field.
+   * @param fragmentPositionsPayloadTerm The term at which the fragment start/end positions are indexed.
+   * @param fragmentField                The field to which the label spans are transformed, only non empty fragments are provided.
+   */
+  public LabelToFragmentQuery(
+        SpanQuery labelQuery,
+        Term fragmentPositionsPayloadTerm,
+        String fragmentField) {
+    super(labelQuery, fragmentPositionsPayloadTerm, fragmentField);
+  }
+
+  public SpanQuery getLabelQuery() {
+    return getSourceQuery();
+  }
+
+  /** The label Spans transformed to fragments.
+   * <br>The start position of each label Span is changed to the start position of the associated non empty fragment.
+   * <br>The end position of each label Span is changed to the end position of the associated non empty fragment.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new LabelToFragmentSpans(context, getSourceQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class LabelToFragmentSpans extends LabeledFragmentsSpans {
+
+    LabelToFragmentSpans(LeafReaderContext context, Spans labelSpans) throws IOException {
+      super(context, labelSpans);
+    }
+
+    int currentStart = -1;
+    int currentEnd = -1;
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      if (! super.next()) {
+        return false;
+      }
+      return nonEmptySpan();
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      if (! super.skipTo(target)) {
+        return false;
+      }
+      return nonEmptySpan();
+    }
+
+    private boolean nonEmptySpan() throws IOException {
+      do {
+        currentStart = getFragmentPosition(sourceSpans.start());
+        currentEnd = getFragmentPosition(sourceSpans.end()); // This requires that the last fragment end position is available.
+        if (currentStart < currentEnd) {
+          return true;
+        }
+        if (! super.next()) {
+          return false;
+        }
+      } while (true);
+    }
+
+    @Override
+    public int start() {
+      return currentStart;
+    }
+
+    @Override
+    public int end() {
+      return currentEnd;
+    }
+  }
+
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("LabelToFragmentSpanQuery( labelQuery="); buffer.append(getSourceQuery().toString(field));
+    buffer.append(", fragmentField="); buffer.append(getTargetField());
+    buffer.append(", fragmentPositionsPayloadTerm="); buffer.append(getFragmentPositionsPayloadTerm().toString());
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  @Override
+  public boolean equals(Object obj) { // no attributes here
+    return super.equals(obj);
+  }
+
+  @Override
+  public int hashCode() { // no attributes here
+    return super.hashCode();
+  }
+
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java
new file mode 100644
index 0000000..adc2e41
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java
@@ -0,0 +1,279 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Set;
+import java.util.Collection;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoDecoder;
+
+/**
+ * Common superclass for queries on labeled fragments
+ * from streams provided by {@link org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer}.
+ * It is assumed that the output fragment token streams for a single labeled fragments input stream
+ * are indexed in one document in different fields.
+ *
+ * @lucene.experimental
+ */
+public abstract class LabeledFragmentsQuery extends SpanQuery { // Public mostly for javadocs
+  private SpanQuery sourceQuery;
+  private String targetField;
+  private Term fragmentPositionsPayloadTerm;
+
+  LabeledFragmentsQuery(
+        SpanQuery sourceQuery,
+        Term fragmentPositionsPayloadTerm,
+        String targetField) {
+    this.sourceQuery = sourceQuery;
+    this.fragmentPositionsPayloadTerm = fragmentPositionsPayloadTerm;
+    this.targetField = targetField;
+  }
+
+  SpanQuery getSourceQuery() {
+    return sourceQuery;
+  }
+
+  String getTargetField() {
+    return targetField;
+  }
+
+  Term getFragmentPositionsPayloadTerm() {
+    return fragmentPositionsPayloadTerm;
+  }
+
+  /** Return the field in which the spans are made available. */
+  @Override
+  public String getField() {
+    return targetField;
+  }
+
+  @Override
+  public void extractTerms(Set<Term> terms) {
+    sourceQuery.extractTerms(terms);
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher) throws IOException {
+    return sourceQuery.createWeight(searcher);
+  }
+
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    SpanQuery rewrittenSourceQuery = (SpanQuery) sourceQuery.rewrite(reader);
+    if (rewrittenSourceQuery == sourceQuery) {
+      return this;
+    }
+    LabeledFragmentsQuery clone = (LabeledFragmentsQuery) this.clone();
+    clone.sourceQuery = rewrittenSourceQuery;
+    return clone;
+  }
+
+  abstract class LabeledFragmentsSpans extends Spans {
+    Spans sourceSpans;
+    int currentDoc = -1;
+    EliasFanoBytes efBytes = null;
+    EliasFanoDecoder<EliasFanoBytes> efDecoder = null;
+    LeafReader leafReader = null;
+    DocsAndPositionsEnum fPosEnum = null;
+
+    LabeledFragmentsSpans(LeafReaderContext context, Spans sourceSpans) throws IOException {
+      this.leafReader = context.reader();
+      this.fPosEnum = leafReader.termPositionsEnum(fragmentPositionsPayloadTerm);
+      this.sourceSpans = sourceSpans;
+    }
+
+    private EliasFanoDecoder<EliasFanoBytes> efDecoderForDoc() throws IOException {
+      int doc = sourceSpans.doc();
+      assert doc >= 0;
+      int fPosDoc = fPosEnum.docID();
+      if (fPosDoc < doc) {
+        fPosDoc = fPosEnum.advance(doc);
+      }
+      if (fPosDoc != doc) {
+        return null; // missing fragment positions for document, i.e. only empty fragments.
+      }
+      // get the fragment positions payload for doc
+      int pos = fPosEnum.nextPosition();
+      if (pos != 0) {
+        throw new IOException("fragment positions term at non zero pos=" + pos + " at doc=" + doc + " for term " + fragmentPositionsPayloadTerm);
+      }
+      BytesRef payload = fPosEnum.getPayload();
+      if (payload == null) {
+        throw new IOException("missing fragment positions payload at doc=" + doc +  " for term " + fragmentPositionsPayloadTerm);
+      }
+      // make an Elias-Fano sequence from the payload
+      if (efBytes == null) {
+        efBytes = EliasFanoBytes.createFromBytesRef(payload);
+      } else {
+        efBytes.reInit(payload);
+      }
+      return efBytes.getDecoder(); // initialized to just before the sequence. CHECKME: implement and use efDecoder.reInit(efBytes)
+    }
+
+    private boolean toFragmentPositionsPayload() throws IOException {
+      int doc = sourceSpans.doc();
+      if (doc == currentDoc) {
+        return true;
+      }
+      currentDoc = doc;
+      if (fPosEnum == null) {
+        return false; // no fragment positions at all for this reader
+      }
+      do {
+        efDecoder = efDecoderForDoc();
+        if (efDecoder == null) { // no fragment positions for current doc
+          if (sourceSpans.skipTo(currentDoc+1)) {
+            currentDoc = sourceSpans.doc();
+          } else {
+            return false; // no more source documents
+          }
+        }
+      } while (efDecoder == null); // fragment positions payload for currentDoc not present?
+
+      long firstValue = efDecoder.nextValue();
+      if (firstValue == EliasFanoDecoder.NO_MORE_VALUES) { // only non empty sequences should be indexed
+        throw new IOException("empty Elias-Fano sequence at doc=" + doc +  " for term " + fragmentPositionsPayloadTerm);
+      }
+      return true;
+    }
+
+    int getLabelPosition(int fragmentPosition) {
+      assert fragmentPosition >= 0;
+      long decodingValue = efDecoder.currentValue();
+      if (decodingValue > fragmentPosition) {
+        decodingValue = efDecoder.backToValue(fragmentPosition); // to smaller or equal encoded fragment position
+        assert decodingValue != EliasFanoDecoder.NO_MORE_VALUES : "earlier fragmentPosition " + fragmentPosition + " not available, currentDoc=" + currentDoc;
+      }
+      if (decodingValue < fragmentPosition) {
+        decodingValue = efDecoder.advanceToValue(fragmentPosition); // to bigger or equal encoded fragment position
+        assert decodingValue != EliasFanoDecoder.NO_MORE_VALUES : "later fragmentPosition " + fragmentPosition + " not available, currentDoc=" + currentDoc;
+      }
+      long labelPos = efDecoder.currentPosition();
+      assert labelPos != EliasFanoDecoder.NO_MORE_VALUES;
+      return (int) ((decodingValue > fragmentPosition)
+                ? (labelPos-1) // decoder is at next fragment label
+                : labelPos); // decoder is at this fragment label
+    }
+
+    int getFragmentPosition(int labelPosition) {
+      assert labelPosition >= 0;
+      long decodingPos = efDecoder.currentPosition();
+      if (decodingPos > labelPosition) {
+        efDecoder.toBeforeSequence();
+        boolean ok = efDecoder.advanceToPosition(labelPosition);
+        //CHECKME: instead of toBeforeSequence/advanceToPosition do:  efDecoder.backToPosition(labelPosition);
+        assert ok : "earlier labelPosition " + labelPosition + " not available, currentDoc=" + currentDoc;
+      } else if (decodingPos < labelPosition) {
+        boolean ok = efDecoder.advanceToPosition(labelPosition);
+        assert ok : "later labelPosition " + labelPosition + " not available, currentDoc=" + currentDoc;
+      }
+      long fragmentPos = efDecoder.currentValue();
+      assert fragmentPos != EliasFanoDecoder.NO_MORE_VALUES;
+      return (int) fragmentPos;
+    }
+
+    /** Returns the document number of the current match.  Initially invalid. */
+    @Override
+    public int doc() {
+      return currentDoc;
+    }
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      return sourceSpans.next() && toFragmentPositionsPayload();
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      return sourceSpans.skipTo(target) && toFragmentPositionsPayload();
+    }
+
+    /**
+     * Payloads in the fragment field are not supported.
+     * @return nothing
+     * @throws UnsupportedOperationException always
+     */
+    @Override
+    public Collection<byte[]> getPayload() {
+      throw new UnsupportedOperationException();
+    }
+
+    /**
+     * Payloads in the fragment field are not supported.
+     * @return false
+     */
+    @Override
+    public boolean isPayloadAvailable() {
+      return false;
+    }
+
+    /**
+     * Returns the estimated cost of this spans.
+     * <p>
+     * This is generally an upper bound of the number of documents this iterator
+     * might match, but may be a rough heuristic, hardcoded value, or otherwise
+     * completely inaccurate.
+     */
+    @Override
+    public long cost() {
+      return sourceSpans.cost();
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (obj == null) {
+      return false;
+    }
+    if (! getClass().equals(obj.getClass())) {
+      return false;
+    }
+    LabeledFragmentsQuery other = (LabeledFragmentsQuery) obj;
+    return this.sourceQuery.equals(other.sourceQuery)
+            && (this.targetField == other.targetField)
+            && (this.fragmentPositionsPayloadTerm == other.fragmentPositionsPayloadTerm)
+            && (this.getBoost() == other.getBoost());
+  }
+
+  @Override
+  public int hashCode() {
+    return getClass().hashCode()
+      ^ sourceQuery.hashCode()
+      ^ targetField.hashCode()
+      ^ fragmentPositionsPayloadTerm.hashCode()
+      ^ Float.floatToRawIntBits(getBoost());
+  }
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java
new file mode 100644
index 0000000..8939b1f
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java
@@ -0,0 +1,334 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+import java.util.Collection;
+import java.util.Set;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+import org.apache.lucene.index.TermContext;
+
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+import org.apache.lucene.util.BytesRef;
+
+import org.apache.lucene.util.packed.label.LongsInBytes;
+
+/**
+ * Common superclass for queries on labeled trees
+ * as provided by {@link org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer}.
+ * @lucene.experimental
+ */
+public abstract class LabeledTreeQuery extends SpanQuery { // public only for javadocs
+  private SpanQuery labelQuery;
+  private String treeInfoPayloadTerm;
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the parent label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   */
+  public LabeledTreeQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm) {
+    this.labelQuery = labelQuery;
+    this.treeInfoPayloadTerm = treeInfoPayloadTerm;
+    assert labelQuery != null;
+    assert treeInfoPayloadTerm != null;
+  }
+
+  public SpanQuery getLabelQuery() {
+    return labelQuery;
+  }
+
+  /** Return the field in which the spans are made available. */
+  @Override
+  public String getField() {
+    return labelQuery.getField();
+  }
+
+  @Override
+  public void extractTerms(Set<Term> terms) {
+    labelQuery.extractTerms(terms);
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher) throws IOException {
+    return labelQuery.createWeight(searcher);
+  }
+
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    SpanQuery rewrittenLabelQuery = (SpanQuery) labelQuery.rewrite(reader);
+    if (rewrittenLabelQuery == labelQuery) {
+      return this;
+    }
+    LabeledTreeQuery clone = (LabeledTreeQuery) this.clone();
+    clone.labelQuery = rewrittenLabelQuery;
+    return clone;
+  }
+
+  abstract class LabeledTreeSpans extends Spans {
+    LeafReader leafReader;
+    Spans labelSpans;
+    int currentDoc = -1;
+    DocsAndPositionsEnum treeInfoEnum = null;
+    TreeInfo treeInfo;
+
+    LabeledTreeSpans(LeafReaderContext context, Spans labelSpans) throws IOException {
+      this.leafReader = context.reader();
+      this.labelSpans = labelSpans;
+      Term tipTerm = new Term(labelQuery.getField(), treeInfoPayloadTerm);
+      this.treeInfoEnum = leafReader.termPositionsEnum(tipTerm);
+    }
+
+    @Override
+    abstract public int start();
+
+    @Override
+    abstract public int end();
+
+    /** Returns the document number of the current match.  Initially invalid. */
+    @Override
+    public int doc() {
+      return currentDoc;
+    }
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      while (labelSpans.next()) {
+        if (treeInfoEnum == null) { // no tree info term at all for reader
+          treeInfo = null;
+          return false;
+        }
+        setTreeInfoPayloadForDoc();
+        if (treeInfo != null) {
+          return true;
+        }
+      }
+      return false;
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      if (! labelSpans.skipTo(target)) {
+        return false;
+      }
+      if (treeInfoEnum == null) {
+        treeInfo = null; // no tree info term at all for reader
+        return false;
+      }
+      setTreeInfoPayloadForDoc();
+      if (treeInfo != null) {
+        return true;
+      }
+      return next();
+    }
+
+    void setTreeInfoPayloadForDoc() throws IOException {
+      int doc = labelSpans.doc();
+      if (doc == currentDoc) {
+        return; // treeInfo already set
+      }
+      currentDoc = doc;
+      assert doc >= 0;
+      int treeInfoDoc = treeInfoEnum.docID();
+      if (treeInfoDoc < doc) {
+        treeInfoDoc = treeInfoEnum.advance(doc);
+      }
+      if (treeInfoDoc != doc) {
+        treeInfo = null; // missing tree info for document
+        return;
+      }
+      int numLabels = treeInfoEnum.nextPosition();
+      BytesRef payload = treeInfoEnum.getPayload();
+      if (payload == null) {
+        if (numLabels != 1) {
+          throw new IOException("missing tree info payload at doc=" + doc +  " for term " + treeInfoPayloadTerm + " numLabels=" + numLabels);
+        } else {
+          treeInfo = ROOT_ONLY;
+        }
+      } else {
+        if ((treeInfo == null) || (treeInfo == ROOT_ONLY)) {
+          treeInfo = new TreeInfo(numLabels, payload); // In case this gets costly, reuse an earlier non ROOT_ONLY treeInfo
+        } else {
+          treeInfo.reInit(numLabels, payload);
+        }
+      }
+    }
+
+
+    /**
+     * Payloads are taken from the labelSpans.
+     */
+    @Override
+    public Collection<byte[]> getPayload() throws IOException {
+      return labelSpans.getPayload();
+    }
+
+    /**
+     * Payloads are taken from the labelSpans.
+     */
+    @Override
+    public boolean isPayloadAvailable()  throws IOException {
+      return labelSpans.isPayloadAvailable();
+    }
+
+    /**
+     * Returns the estimated cost of this spans.
+     * <p>
+     * This is generally an upper bound of the number of documents this iterator
+     * might match, but may be a rough heuristic, hardcoded value, or otherwise
+     * completely inaccurate.
+     */
+    @Override
+    public long cost() {
+      return labelSpans.cost();
+    }
+
+  }
+
+  @Override
+  public String toString(String field) {
+    return "LabelTreeQuery treeInfoPayloadTerm=" + treeInfoPayloadTerm +" labelQuery=" + labelQuery;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (obj == null) {
+      return false;
+    }
+    if (getClass() != obj.getClass()) {
+      return false;
+    }
+    LabeledTreeQuery other = (LabeledTreeQuery) obj;
+    if (! treeInfoPayloadTerm.equals(other.treeInfoPayloadTerm)) {
+      return false;
+    }
+    return labelQuery.equals(other.labelQuery);
+  }
+
+  @Override
+  public int hashCode() {
+    return getClass().hashCode()
+          ^ labelQuery.hashCode()
+          ^ treeInfoPayloadTerm.hashCode();
+  }
+
+  static class TreeInfo {
+    BytesRef bytesRef;
+    int numNodes;
+    int numBits;
+    static final int NO_SUCH_NODE = -1;
+
+    TreeInfo() { // single root constructor
+      numNodes = 1;
+      numBits = 1;
+      bytesRef = null;
+    }
+
+    TreeInfo(int numNodes, BytesRef payload) {
+      reInit(numNodes, payload);
+    }
+
+    void reInit(int numNodes, BytesRef payload) {
+      assert numNodes >= 2;
+      this.numNodes = numNodes;
+      this.bytesRef = payload;
+      this.numBits = Integer.SIZE - Integer.numberOfLeadingZeros(numNodes - 1);
+      assert (bytesRef.offset + (((2*numBits*numNodes + 7)) >> 3)) <= bytesRef.bytes.length : numNodes;
+    }
+
+    int numNodes() {
+      return numNodes;
+    }
+
+    boolean checkNode(int node) {
+      if ((node < 0) || (node >= numNodes)) {
+        throw new ArrayIndexOutOfBoundsException(node);
+      }
+      return true;
+    }
+
+    int parentNode(int node) {
+      assert checkNode(node);
+      return (int) LongsInBytes.unPackValue(numBits, 2*node, bytesRef.bytes, bytesRef.offset);
+    }
+
+    int numDescendants(int node) {
+      assert checkNode(node);
+      return (int) LongsInBytes.unPackValue(numBits, 2*node+1, bytesRef.bytes, bytesRef.offset);
+    }
+
+    int childNode(int node, int childNum) {
+      assert childNum >= 0;
+      int numDesc = numDescendants(node);
+      if (childNum >= numDesc) {
+        return -1;
+      }
+      int childNode = node+1; // first child.
+      assert checkNode(childNode);
+      while (--childNum >= 0) {
+        childNode = nextSibling(childNode);
+        if (childNode == NO_SUCH_NODE) {
+          return NO_SUCH_NODE;
+        }
+      }
+      return childNode;
+    }
+
+    int nextSibling(int node) {
+      int parent = parentNode(node);
+      int nextSib = node + 1 + numDescendants(node);
+      if (nextSib <= parent + numDescendants(parent)) {
+        return nextSib;
+      }
+      return NO_SUCH_NODE;
+    }
+  }
+
+  static final TreeInfo ROOT_ONLY = new TreeInfo() {
+
+    @Override
+    int parentNode(int node) {
+      assert node == 0 : "root only: " + node;
+      return 0;
+    }
+
+    @Override
+    int numDescendants(int node) {
+      assert node == 0 : "root only: " + node;
+      return 0;
+    }
+  };
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/LeafFragmentsQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/LeafFragmentsQuery.java
new file mode 100644
index 0000000..c84dc2a
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/LeafFragmentsQuery.java
@@ -0,0 +1,174 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+
+import org.apache.lucene.util.packed.EliasFanoDecoder;
+
+/**
+ * Transform the Spans of a SpanQuery in a fragment field to all non empty fragments.
+ * <br>See also {@link LabeledFragmentsQuery}.
+ *
+ * @lucene.experimental
+ */
+public class LeafFragmentsQuery extends LabeledFragmentsQuery {
+
+  /** Transforms the Spans of a {@link SpanQuery} from a label field to a fragment field.
+   * @param fragmentQuery                Provides the Spans in the label field.
+   * @param fragmentPositionsPayloadTerm The term at which the fragment start/end positions are indexed.
+   */
+  public LeafFragmentsQuery(SpanQuery fragmentQuery, Term fragmentPositionsPayloadTerm) {
+    super(fragmentQuery, fragmentPositionsPayloadTerm, fragmentQuery.getField());
+  }
+
+  public SpanQuery getFragmentQuery() {
+    return getSourceQuery();
+  }
+
+  /** The label Spans transformed to fragments.
+   * <br>The start position of each label Span is changed to the start position of the associated non empty fragment.
+   * <br>The end position of each label Span is changed to the end position of the associated non empty fragment.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new LeafFragmentsSpans(context, getSourceQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class LeafFragmentsSpans extends LabeledFragmentsSpans {
+
+    LeafFragmentsSpans(LeafReaderContext context, Spans fragmentSpans) throws IOException {
+      super(context, fragmentSpans);
+    }
+
+    int currentInputStart = -1;
+    int currentInputEnd = -1;
+    int currentOutputStart = -1;
+    int currentOutputEnd = -1;
+
+    /** Move to the next match, returning true iff any such exists. */
+    @Override
+    public boolean next() throws IOException {
+      if (currentOutputEnd < currentInputEnd) { // still a non empty spans within current input
+        currentOutputStart = currentOutputEnd;
+        toNextLeafFragment();
+        return true;
+      }
+      if (! super.next()) {
+        return false;
+      }
+      return nonEmptyInputSpan();
+    }
+
+    /** Skips to the first match beyond the current, whose document number is
+     * greater than or equal to <i>target</i>.
+     */
+    @Override
+    public boolean skipTo(int target) throws IOException {
+      if (! super.skipTo(target)) {
+        return false;
+      }
+      return nonEmptyInputSpan();
+    }
+
+    private boolean nonEmptyInputSpan() throws IOException {
+      currentInputEnd = -1;
+      do {
+        currentInputStart = sourceSpans.start();
+        if (currentInputStart < currentInputEnd) { // overlap on input: ignore
+          currentInputStart = currentInputEnd;
+        }
+        currentInputEnd = sourceSpans.end();
+        if (currentInputStart < currentInputEnd) {
+          toFirstLeafFragment();
+          return true;
+        }
+        int currentDoc = doc();
+        if (! super.next()) {
+          return false;
+        }
+        if (currentDoc != doc()) { // next document, no overlap possible
+          currentInputEnd = -1;
+        }
+      } while (true);
+    }
+
+    private void toFirstLeafFragment() { // between currentInputStart and currentInputEnd, on entry currentInputStart < currentInputEnd
+      currentOutputStart = currentInputStart;
+      if (! toNextLeafFragment()) {
+        throw new IllegalStateException("non empty fragment expected");
+      }
+    }
+
+    private boolean toNextLeafFragment() { // between currentOutputStart and currentInputEnd, on entry currentOutputStart <= currentInputEnd
+      if (currentOutputStart == currentInputEnd) {
+        return false;
+      }
+      long nextFragmentEnd = efDecoder.advanceToValue(currentOutputStart+1);
+      if (nextFragmentEnd == EliasFanoDecoder.NO_MORE_VALUES) {
+        return false;
+      }
+      assert nextFragmentEnd <= currentInputEnd;
+      currentOutputEnd = (int) nextFragmentEnd;
+      return true;
+    }
+
+    @Override
+    public int start() {
+      return currentOutputStart;
+    }
+
+    @Override
+    public int end() {
+      return currentOutputEnd;
+    }
+  }
+
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("LabelToFragmentSpanQuery( fragmentQuery="); buffer.append(getSourceQuery().toString(field));
+    buffer.append(", fragmentField="); buffer.append(getTargetField());
+    buffer.append(", fragmentPositionsPayloadTerm="); buffer.append(getFragmentPositionsPayloadTerm().toString());
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  @Override
+  public boolean equals(Object obj) { // no attributes here
+    return super.equals(obj);
+  }
+
+  @Override
+  public int hashCode() {  // no attributes here
+    return super.hashCode();
+  }
+
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java
new file mode 100644
index 0000000..2a273bf
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java
@@ -0,0 +1,87 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.Bits;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to the parent label.
+ *
+ * @lucene.experimental
+ */
+public class ParentLabelQuery extends LabeledTreeQuery {
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the parent label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   */
+  public ParentLabelQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm) {
+    super(labelQuery, treeInfoPayloadTerm);
+  }
+
+
+  /** The label Spans transformed to a Spans for the parents of the labels.
+   * <br>The input start position is transformed to its parent.
+   * <br>When the input end position-1 is a descendant of the parent of the start position, it is transformed to the start parent+1.
+   * <br>Otherwise, the input end position is transformed to its parent.
+   */
+  @Override
+  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
+    return new ParentLabelSpans(context, getLabelQuery().getSpans(context, acceptDocs, termContexts));
+  }
+
+  private class ParentLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    ParentLabelSpans(LeafReaderContext context, Spans labelSpans) throws IOException {
+      super(context, labelSpans);
+    }
+
+    @Override
+    public int start() {
+      int res = treeInfo.parentNode(labelSpans.start());
+      return res;
+    }
+
+    @Override
+    public int end() {
+      int res = treeInfo.parentNode(labelSpans.end()-1)+1; // Could check that given end-1 is in descendants of parent start.
+      return res;
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) { // no attributes here
+    return super.equals(obj);
+  }
+
+  @Override
+  public int hashCode() { // no attributes here
+    return super.hashCode();
+  }
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java b/lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java
new file mode 100644
index 0000000..1029d6b
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java
@@ -0,0 +1,159 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+/**
+ * Factory for positional join queries.
+ * This provides queries for positional joins between fragment and label fields, and queries for label tree operations.
+ *
+ * @lucene.experimental
+ */
+public class PositionalJoinQueryFactory {
+  private final LabelFieldSchema fieldSchema;
+
+  /** Create a position join query factory based on a label field schema. */
+  public PositionalJoinQueryFactory(LabelFieldSchema fieldSchema) {
+    if (fieldSchema == null) {
+      throw new IllegalArgumentException("fieldSchema should be non null");
+    }
+    this.fieldSchema = fieldSchema;
+  }
+
+  /** The field schema provided to the constructor. */
+  public LabelFieldSchema getFieldSchema() {
+    return fieldSchema;
+  }
+
+  private String checkTreeInfo(SpanQuery spanQuery) {
+    if (fieldSchema.getTreeInfoPayloadTermText() == null) {
+      throw new IllegalStateException("fieldSchema has no tree info payload term");
+    }
+    if (! fieldSchema.getLabelFieldName().equals(spanQuery.getField())) {
+      throw new IllegalArgumentException("spanQuery field: " + spanQuery.getField() + " is not the label field of the schema: "
+                                          + fieldSchema.getLabelFieldName());
+    }
+    return fieldSchema.getTreeInfoPayloadTermText();
+  }
+
+  /** Transform the spans of a given SpanQuery in the label field of the schema
+   * to the parent label.
+   */
+  public ParentLabelQuery parentLabelQuery(SpanQuery labelQuery) {
+    return new ParentLabelQuery(labelQuery, checkTreeInfo(labelQuery));
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema
+   * to the label of the child with the given number.
+   */
+  public ChildLabelQuery childLabelQuery(SpanQuery labelQuery, int childNum) {
+    return new ChildLabelQuery(labelQuery, childNum, checkTreeInfo(labelQuery));
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema to
+   * a spans containing all descendants of the given label. 
+   */
+  public DescendantsLabelQuery descendantsLabelQuery(SpanQuery labelQuery) {
+    return new DescendantsLabelQuery(labelQuery, checkTreeInfo(labelQuery), false /* not including self */);
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema to
+   * a spans containing the given label and all its descendants.
+   */
+  public DescendantsLabelQuery descendantsOrSelfLabelQuery(SpanQuery labelQuery) {
+    return new DescendantsLabelQuery(labelQuery, checkTreeInfo(labelQuery), true /* including self */);
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery to a target field with a labeled fragment positions join.
+   * The source field for the join is taken from the given query. The source field and the target field must be in the schema. 
+   * @return The given query is wrapped, when:
+   * <ul>
+   * <li>the source field is the label field of the schema: in a {@link LabelToFragmentQuery},
+   * <li>the target field is the label field of the schema: in a {@link FragmentToLabelQuery},
+   * <li>the source and target fields share their labeled fragment positions: in a {@link FieldMaskingSpanQuery},
+   * <li>the source and target fields do not share their labeled fragment positions: in a {@link FragmentToLabelQuery} wrapping a {@link LabelToFragmentQuery}.
+   * </ul>
+   */
+  public SpanQuery positionalJoin(SpanQuery query, String targetField) {
+    if (query == null) {
+      throw new IllegalArgumentException("query should be non null");
+    }
+    if (targetField == null) {
+      throw new IllegalArgumentException("targetField should be non null");
+    }
+    String sourceField = query.getField();
+    int sourceFFI = -1;
+    int targetFFI = -1;
+    if (! sourceField.equals(fieldSchema.getLabelFieldName())) {
+      sourceFFI = fieldSchema.fragmentFieldIndex(sourceField);
+      if (sourceFFI < 0) {
+        throw new IllegalArgumentException("source field: " + sourceField + " is not a field of the schema");
+      }
+    }
+    if (! targetField.equals(fieldSchema.getLabelFieldName())) {
+      targetFFI = fieldSchema.fragmentFieldIndex(targetField);
+      if (targetFFI < 0) {
+        throw new IllegalArgumentException("targetField: " + targetField + " is not a field of the schema");
+      }
+    }
+    //  sourceField and targetField in fieldSchema, sourceFFI and targetFFI initialized for fragment fields.
+    if (sourceField.equals(targetField)) { // no join needed
+      return query;
+    }
+    if (targetField.equals(fieldSchema.getLabelFieldName())) { // fragment to label
+      assert sourceFFI >= 0;
+      Term sourceFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(sourceFFI);
+      return new FragmentToLabelQuery(query, sourceFpsTerm, targetField);
+    }
+    if (sourceField.equals(fieldSchema.getLabelFieldName())) { // label to fragment
+      assert targetFFI >= 0;
+      Term targetFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(targetFFI);
+      return new LabelToFragmentQuery(query, targetFpsTerm, targetField);
+    }
+    // fragment to fragment
+    assert sourceFFI >= 0;
+    assert targetFFI >= 0;
+    Term sourceFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(sourceFFI);
+    Term targetFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(targetFFI);
+    if (sourceFpsTerm.equals(targetFpsTerm)) { // labeled fragment positions shared
+      return new FieldMaskingSpanQuery(query, targetField);
+    }
+    // fragment to fragment via label:
+    FragmentToLabelQuery ftlq = new FragmentToLabelQuery(query, sourceFpsTerm, fieldSchema.getLabelFieldName());
+    return new LabelToFragmentQuery(ftlq, targetFpsTerm, targetField);
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in a fragment field of the schema
+   * to all non empty fragments.
+   */
+  public LeafFragmentsQuery leafFragmentsQuery(SpanQuery fragmentQuery) {
+    String fragmentField = fragmentQuery.getField();
+    int ffi = fieldSchema.fragmentFieldIndex(fragmentField);
+    if (ffi < 0) {
+      throw new IllegalArgumentException("fragmentQuery field: " + fragmentField + " is not a fragment field of the schema");
+    }
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(ffi);
+    return new LeafFragmentsQuery(fragmentQuery, fpsTerm);
+  }
+
+}
diff --git a/lucene/label/src/java/org/apache/lucene/search/spans/label/package.html b/lucene/label/src/java/org/apache/lucene/search/spans/label/package.html
new file mode 100644
index 0000000..afe8426
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/search/spans/label/package.html
@@ -0,0 +1,28 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<body>
+Querying labeled fragments.
+<p>
+This package provides <code>1 : 0..n</code> positional joins between text fields.
+For a <code>1 : 1</code> positional join see
+{@link org.apache.lucene.search.spans.FieldMaskingSpanQuery}.
+<p>
+Some labels can be highly repetitive, even within a single document.
+These will suffer from the same problems as other highly repetitive terms.
+</body>
+</html>
diff --git a/lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java b/lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java
new file mode 100644
index 0000000..0323872
--- /dev/null
+++ b/lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.packed.label;
+
+/** Pack/unpack Longs in/from a byte array with offset, for a given number of bits per number.
+ *  @lucene.internal
+ */
+public class LongsInBytes {
+  public static final int LOG2_BYTE_SIZE = Integer.numberOfTrailingZeros(Byte.SIZE);
+  public static final long LONG_BYTE_MASK = 0xFFL;
+
+  /** Pack the lower numBits bits of value into array bytes at bit position packIndex*numBytes + 8 * offset.
+   * The value must not have any other bits set, and numBits should be non negative and at most 64.
+   */
+  public static void packValue(long value, int numBits, long packIndex, byte[] bytes, int offset) {
+    assert numBits >= 0;
+    assert numBits <= Long.SIZE;
+    assert ((-1L << numBits) & value) == 0; // no more than numBits in value
+    long bitPos = numBits * packIndex;
+    int byteIndex = offset + (int) (bitPos >>> LOG2_BYTE_SIZE);
+    int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+    bytes[byteIndex] |= (byte) (value << bitPosAtIndex);
+    int rightShift = (Byte.SIZE - bitPosAtIndex);
+    int remainingBits = numBits - rightShift;
+    while (remainingBits > 0) {
+      bytes[++byteIndex] = (byte) (value >>> rightShift);
+      rightShift += Byte.SIZE;
+      remainingBits -= Byte.SIZE;
+    }
+  }
+
+  /** Pack the lower numBits bits of value into array bytes at bit position packIndex*numBytes.
+   * The value must not have any other bits set, and numBits should be non negative and at most 64.
+   */
+  public static void packValue(long value, int numBits, long packIndex, byte[] bytes) {
+    packValue(value, numBits, packIndex, bytes, 0); // zero offset
+  }
+
+  /** Return the lower numBits bits from array bytes at bit position packIndex*numBytes + 8 * offset.
+   * numBits should be non negative and at most 64.
+   */
+  public static long unPackValue(int numBits, long packIndex, byte[] bytes, int offset) {
+    assert numBits >= 0;
+    assert numBits <= Long.SIZE;
+    long bitPos = packIndex * numBits;
+    int byteIndex = offset + (int) (bitPos >>> LOG2_BYTE_SIZE);
+    int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+    long value = (bytes[byteIndex] & LONG_BYTE_MASK) >>> bitPosAtIndex;
+    int leftShift = Byte.SIZE - bitPosAtIndex;
+    int remainingBits = numBits - leftShift;
+    while (remainingBits > 0) {
+      value |= ((bytes[++byteIndex] & LONG_BYTE_MASK) << leftShift);
+      leftShift += Byte.SIZE;
+      remainingBits -= Byte.SIZE;
+    }
+    value &= ~(-1L << numBits); // mask numBits
+    return value;
+  }
+
+  /** Return the lower numBits bits from array bytes at bit position packIndex*numBytes.
+   * numBits should be non negative and at most 64.
+   */
+  public static long unPackValue(int numBits, long packIndex, byte[] bytes) {
+    return unPackValue(numBits, packIndex, bytes, 0);
+  }
+
+}
+
diff --git a/lucene/label/src/java/overview.html b/lucene/label/src/java/overview.html
new file mode 100644
index 0000000..e2361e2
--- /dev/null
+++ b/lucene/label/src/java/overview.html
@@ -0,0 +1,115 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<body>
+Lucene's label module
+
+<h2>Positional joins for labeled text fragments</h2>
+
+At index time labeled text fragments for a document are analyzed from a {@link org.apache.lucene.analysis.TokenStream}.
+<br>
+In package {@link org.apache.lucene.analysis.label} such a labeled fragments stream is split into
+a label stream, and into pairs of streams for fragments and fragment positions.
+<br>The fragments in each fragment stream will be contiguous,
+the labels and the other fragment streams have no influence on their positions.
+This provides some backward compability because an existing text can be reindexed as it is,
+while adding labels and extra text streams.
+<p>
+The labels may be nested in a tree, in that case the label output stream will also contain label tree information.
+<br>
+As a special case of a nested label tree, an {@link javax.xml.stream.XMLEventReader} can also be provided.
+<p>
+The output streams can be used to provide documents with a different {@link org.apache.lucene.index.Field} per stream.
+It is up to the user to associate the output streams with fields in documents to be indexed for search.
+<p>
+Labels and fragments are represented at query time by {@link org.apache.lucene.search.spans.Spans}.
+Querying labeled fragments with positional joins and with navigation of the label tree
+is supported in package {@link org.apache.lucene.search.spans.label}.
+
+
+<h3>Implementation, variations, limitations</h3>
+
+The current implementation is a prototype.
+<p>
+For querying it is assumed that all the output token streams for a single labeled fragments input stream are indexed
+in one document in different fields.
+<br>More query implementations may be considered, for example the fragment streams may be concatenated with position gaps,
+or each output stream may be put in different documents of a document block of the join module.
+<p>
+The fragment positions and the label tree information are each implemented as one payload per stream.
+Even though some compression is done, for documents with many labels these payloads will grow large,
+and loading larger payloads during searches will not scale well.
+<br>Docvalues might be used instead of payloads, but these have the same limitations.
+<br>For up to some hundreds of labels per document this implementation is expected to be usable to explore its possibilities.
+<p>
+Instead of payloads for the fragment positions and for the label tree information,
+special fields could allow more random access for searches, and that would probably scale much better.
+<p>
+There is no support for changes in the data formats of these payloads in the index,
+and it is recommended to add a data format version to the payload term names.
+
+<h3>Some literature</h3>
+
+With comments on what was used here.
+<p>
+<dl>
+<dt>
+Quanzyong Li, Bongki Moon, "Indexing and Querying XML Data for Regular Path Expressions", VLDB 2001.
+<dd>
+Describes a structure index and an element/attribute index for XML.
+The structure index there corresponds to the label tree information here.
+The element/attribute index there is mostly provided by Lucene's term positions index,
+except for the element/attribute positions per label.
+<br>
+Paragraph 2.1 mentions the positional join provided here:
+"Both elements and attributes use the order of the order/size pair as their unique identifier in the document tree."
+This order is the label preorder position.
+<p>
+<dt>
+Taro L. Saito, Shinichi Morishita, "Amoeba Join: Overcoming Structural Fluctuations in XML Data", WebDB 2006.
+<dd>
+Interval representation for XML nodes. An amoeba join is much like a proximity query in the element tree.
+<p>
+<dt>
+Guiseppe Ottaviano, Roberto Grossi, "Semi-Indexing Semi-Structured data in Tiny Space", CIKM 2011.
+<dd>
+Balanced Parentheses for JSON tree structure. Elias-Fano sequence for offsets.
+<p>
+<dt>
+Sebastiano Vigna, "Quasi Succinct Indices", 2012.
+<dd>
+Elias-Fano sequence for term positions.
+<p>
+<dt>
+Diego Arroyuelo, Rodrigo C'novas, Gonzalo Navarro, Kunihiko Sadakane, "Succinct Trees in practice", 2010.
+<dd>
+Recommends a "Fully Functional" representation for trees represented by Balanced Parentheses.
+This requires about 2.4 bits per tree node instead of the 2*2log(#nodes) bits per tree node here,
+and it is less easy to implement.
+<p>
+<dt>
+Paolo Ferragina, Fabrizio Luccio, Giovanni Manzini, S. Muthukrishnan,
+"Compressing and indexing labeled trees, with applications", 2009.
+<dd>Discusses the XBW transform that linearizes the labeled tree into two coordinated arrays,
+one capturing the structure and the other the labels.
+Here such coordinated arrays are represented by the label tree info payload and by the label token stream.
+</dl>
+
+@lucene.experimental
+
+</body>
+</html>
diff --git a/lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java b/lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java
new file mode 100644
index 0000000..68fcb9d
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java
@@ -0,0 +1,61 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+
+import org.apache.lucene.util.LuceneTestCase;
+
+class TPS { // for testing indexed term positions
+  Term term;
+  int[] expPosns;
+
+  TPS(String fieldName, String termText, int[] expPosns) { // at doc zero
+    this.term = new Term(fieldName, termText);
+    this.expPosns = expPosns;
+  }
+
+  void tstTermPositions(LeafReader lr) throws IOException {
+    int expDoc = 0;
+    DocsAndPositionsEnum actDPE = lr.termPositionsEnum(term);
+    String mes = term.toString() + " at doc " + expDoc;
+    if (actDPE == null) {
+      LuceneTestCase.assertEquals("#positions available for " + mes, expPosns.length, 0);
+    }
+    else {
+      LuceneTestCase.assertEquals(mes, expDoc, actDPE.nextDoc());
+      LuceneTestCase.assertEquals(mes, expPosns.length, actDPE.freq());
+      for (int expPos: expPosns) {
+        LuceneTestCase.assertEquals(mes, expPos, actDPE.nextPosition());
+      }
+      LuceneTestCase.assertEquals(DocsAndPositionsEnum.NO_MORE_DOCS, actDPE.nextDoc());
+    }
+  }
+
+  static void tstTermPositions(LeafReader lr, TPS[] expTPSs) throws IOException {
+    for (TPS expTPS: expTPSs) {
+      expTPS.tstTermPositions(lr);
+    }
+  }
+}
+
+
diff --git a/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java b/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java
new file mode 100644
index 0000000..d4cdebd
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java
@@ -0,0 +1,342 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.LinkedHashSet;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+
+import org.apache.lucene.analysis.TokenStream;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.store.RAMDirectory;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoDecoder;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.junit.Test;
+
+
+public class TestLabeledFragmentsAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels");
+  final int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments1", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+  final int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  final String FragFieldName1 = fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex);
+  final String FragFieldName2 = fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex);
+
+  final LabeledFragmentsAnalyzer.InputSplitter ENDING_COLON_DOUBLE_BAR =
+  new LabeledFragmentsAnalyzer.InputSplitter() {
+    @Override
+    public LabeledFragmentsAnalyzer.TokenType tokenType(String term) {
+      if (term.equals("||")) {
+        return LabeledFragmentsAnalyzer.TokenType.NEXT_FRAGMENT;
+      }
+      if (term.endsWith(":")) {
+        return LabeledFragmentsAnalyzer.TokenType.LABEL;
+      }
+      return LabeledFragmentsAnalyzer.TokenType.FRAGMENT;
+    }
+  };
+
+  Field makeLabelField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), lfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledFragmentsAnalyzer lfAnalyzer, int fragmentStreamNum) {
+    String ffName = fieldSchema.getFragmentFieldName(fragmentStreamNum);
+    return new TextField(ffName, lfAnalyzer.fragmentsTokenStream(fragmentStreamNum));
+  }
+
+  Field makeFragmentPositionsField(LabeledFragmentsAnalyzer lfAnalyzer, int fragmentStreamNum) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(fragmentStreamNum, fpsTerm.text()));
+  }
+
+  Document makeDocument(String labeledFragmentsStr, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(lfTokenizer, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+    lfAnalyzer.consumeInputStream();
+    Document doc = new Document();
+    Field labelField = makeLabelField(lfAnalyzer);
+    doc.add(labelField);
+    for (int i = 0; i < lfAnalyzer.numFragmentStreams(); i++) {
+      Field fragmentField = makeFragmentField(lfAnalyzer, i);
+      doc.add(fragmentField);
+      Field fragmentPositionsField = makeFragmentPositionsField(lfAnalyzer, i);
+      doc.add(fragmentPositionsField);
+    }
+    return doc;
+  }
+
+  void tstExpectedFieldsIndex(String labeledFragmentsStr, int numFragmentStreams, String[] expectedFieldNames)
+  throws IOException {
+    Document doc = makeDocument(labeledFragmentsStr, numFragmentStreams);
+    // index the document
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    IndexReader r = DirectoryReader.open(dir);
+    // test that the field names are the expected ones:
+    Fields fields = MultiFields.getFields(r);
+    if (fields != null) {
+      LinkedHashSet<String> names = new LinkedHashSet<>();
+      for (String fieldName: expectedFieldNames) {
+        names.add(fieldName);
+      }
+      Iterator<String> fieldNames = fields.iterator();
+      while (fieldNames.hasNext()) {
+        String fieldName = fieldNames.next();
+        assertTrue("field name not in expected set: " + fieldName, names.contains(fieldName));
+        names.remove(fieldName);
+      }
+      for (String fieldName: names) {
+        assertTrue("non present field name: " + fieldName, false);
+      }
+    } else {
+      assertEquals("no fields found, but some expected", 0, expectedFieldNames.length);
+    }
+    r.close();
+    dir.close();
+  }
+
+  static void tstDecodeAllNext(int[] expValues, EliasFanoBytes efSeq) {
+    EliasFanoDecoder<EliasFanoBytes> efd = efSeq.getDecoder();
+    long nextValue = efd.nextValue();
+    for (int expValue: expValues) {
+      assertFalse("nextValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == nextValue);
+      assertEquals(expValue, nextValue);
+      nextValue = efd.nextValue();
+    }
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, nextValue);
+  }
+
+  static void tstFragmentPositions(int[] expFragmentPositions, LeafReader lr, Term fpsTerm)
+  throws IOException {
+    DocsAndPositionsEnum dpfe = lr.termPositionsEnum(fpsTerm);
+    if (dpfe == null) {
+      assertEquals("number of fragment positions", 0, expFragmentPositions.length);
+    } else {
+      assertEquals("first doc", 0, dpfe.nextDoc());
+      assertEquals("frequency", 1, dpfe.freq());
+      assertEquals("position", 0, dpfe.nextPosition());
+      BytesRef payload = dpfe.getPayload();
+      assertTrue(payload != null);
+      EliasFanoBytes efSeq = EliasFanoBytes.createFromBytesRef(payload);
+      tstDecodeAllNext(expFragmentPositions, efSeq);
+      assertEquals(DocsAndPositionsEnum.NO_MORE_DOCS, dpfe.nextDoc());
+    }
+  }
+
+  void tstFragments(String[] labeledFragmentsStrs, int numFragmentStreams, int[][] expFragmentPositionsByField, TPS[] expTPSs)
+  throws IOException {
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    for (String lfStr: labeledFragmentsStrs) {
+      Document doc = makeDocument(lfStr, numFragmentStreams);
+      w.addDocument(doc);
+    }
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+    for (int fragmentStreamNum = 0; fragmentStreamNum < numFragmentStreams; fragmentStreamNum++) {
+      int[] expFragmentPositions = expFragmentPositionsByField[fragmentStreamNum];
+      Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+      tstFragmentPositions(expFragmentPositions, lr, fpsTerm);
+    }
+
+    TPS.tstTermPositions(lr, expTPSs);
+    lr.close();
+    dir.close();
+  }
+
+  void tstFragments(String labeledFragmentsStr, int numFragmentStreams, int[][] expFragmentPositionsByField, TPS[] expTPSs)
+  throws IOException {
+    tstFragments(new String[]{labeledFragmentsStr}, numFragmentStreams, expFragmentPositionsByField, expTPSs);
+  }
+
+  public void testFieldsEmpty1() throws IOException {
+    tstExpectedFieldsIndex("", 1, new String[0]);
+  }
+
+  public void testFieldsEmpty2() throws IOException {
+    tstExpectedFieldsIndex("", 2, new String[0]);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelOneFragmentField1() throws IOException {
+    // one fragment, no labels, no payload
+    tstExpectedFieldsIndex("a b", 1, new String[] {FragFieldName1});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelOneFragmentField2() throws IOException {
+    // one fragment, no labels, no payload
+    tstExpectedFieldsIndex("a b", 2, new String[] {FragFieldName1});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelTwoFragmentFields() throws IOException {
+    // two fragments fields, no labels, no payload
+    tstExpectedFieldsIndex("a b || c d", 2, new String[] {FragFieldName1,FragFieldName2});
+  }
+
+  public void testFieldsNoFragments() throws IOException {
+    tstExpectedFieldsIndex("A: B:", 1, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+    tstExpectedFieldsIndex("A: B:", 2, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+    tstExpectedFieldsIndex("A: B: ||", 2, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsInitialUnlabeledFragment1() throws IOException {
+    tstExpectedFieldsIndex("a B:", 1, new String[] {
+                                        fieldSchema.getLabelFieldName(),
+                                        FragFieldName1,
+                                        fieldSchema.getFragmentPositionsPayloadTerm(0).field()});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsInitialUnlabeledFragment2() throws IOException {
+    tstExpectedFieldsIndex("a B:", 2, new String[] {
+                                        fieldSchema.getLabelFieldName(),
+                                        FragFieldName1,
+                                        fieldSchema.getFragmentPositionsPayloadTerm(0).field()});
+  }
+
+  public void testOneFragmentOneFragmentField() throws IOException {
+    tstFragments("A: a1", 1,
+                  new int[][]{{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0})
+                  });
+  }
+
+  public void testOneFragmentTwoFragmentFields() throws IOException {
+    tstFragments("A: a1 || a2", 2,
+                  new int[][] {{0,1},{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testTooManyFragmentsPerLabel() throws IOException {
+    tstFragments("A: a1 || a2 || a3", 2,
+                  new int[][] {{0,1},{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testInitialUnlabeledFragmentOneFragmentField() throws IOException {
+    tstFragments("a1 B:", 1,
+                  new int[][]{{1,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testInitialUnlabeledFragmentTwoFragmentFields() throws IOException {
+    tstFragments("a1 || a2 B:", 2,
+                  new int[][]{{1,1},{1,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  public void testMoreFragmentsOneFragmentField() throws IOException {
+    tstFragments("A: a1 a2 z1 B: C: c1 c2 D: d1 z1 E:", 1,
+                  new int[][]{{0,3,3,5,7,7}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "C:", new int[]{2}),
+                    new TPS(fieldSchema.getLabelFieldName(), "D:", new int[]{3}),
+                    new TPS(fieldSchema.getLabelFieldName(), "E:", new int[]{4}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{1}),
+                    new TPS(FragFieldName1, "z1", new int[]{2,6}),
+                    new TPS(FragFieldName1, "c1", new int[]{3}),
+                    new TPS(FragFieldName1, "c2", new int[]{4}),
+                    new TPS(FragFieldName1, "d1", new int[]{5})
+                  });
+  }
+
+  public void testMoreFragmentsTwoFragmentFields() throws IOException {
+    tstFragments("A: a1 a2 z1 || aa1 B: C: c1 c2 D: d1 z1 E: || ee1", 2,
+                  new int[][]{{0,3,3,5,7,7},{0,1,1,1,1,2}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "C:", new int[]{2}),
+                    new TPS(fieldSchema.getLabelFieldName(), "D:", new int[]{3}),
+                    new TPS(fieldSchema.getLabelFieldName(), "E:", new int[]{4}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{1}),
+                    new TPS(FragFieldName1, "z1", new int[]{2,6}),
+                    new TPS(FragFieldName1, "c1", new int[]{3}),
+                    new TPS(FragFieldName1, "c2", new int[]{4}),
+                    new TPS(FragFieldName1, "d1", new int[]{5}),
+                    new TPS(FragFieldName2, "aa1", new int[]{0}),
+                    new TPS(FragFieldName2, "ee1", new int[]{1})
+                  });
+  }
+}
diff --git a/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java b/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java
new file mode 100644
index 0000000..a378ccb
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java
@@ -0,0 +1,226 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.LinkedHashSet;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.store.RAMDirectory;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.DocsAndPositionsEnum;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.packed.label.LongsInBytes;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.InputSplitter;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.junit.Test;
+
+public class TestLabeledTreeFragmentsAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels", "treeInfo-" + Version.LATEST); // add version until there is a real field for this
+  {
+    fieldSchema.addLabeledFragmentField("fragments", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+    fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+  }
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      return term.endsWith(":") ? TokenType.LABEL
+            : term.equals("||") ? TokenType.NEXT_FRAGMENT
+            : term.equals(";;") ? TokenType.END_LABEL
+                                : TokenType.FRAGMENT;
+    }
+  };
+
+  Field makeLabelField(LabeledTreeFragmentsAnalyzer ltfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), ltfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledTreeFragmentsAnalyzer ltfAnalyzer, int fragmentStreamNum) {
+    String ffName = fieldSchema.getFragmentFieldName(fragmentStreamNum);
+    return new TextField(ffName, ltfAnalyzer.fragmentsTokenStream(fragmentStreamNum));
+  }
+
+  Field makeFragmentPositionsField(LabeledTreeFragmentsAnalyzer ltfAnalyzer, int fragmentStreamNum) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+    return new TextField(fpsTerm.field(), ltfAnalyzer.fragmentPositionsTokenStream(fragmentStreamNum, fpsTerm.text()));
+  }
+
+  Document makeDocument(String labeledFragmentsStr, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledTreeFragmentsAnalyzer ltfAnalyzer = new LabeledTreeFragmentsAnalyzer(lfTokenizer,
+                                                      ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI,
+                                                      numFragmentStreams,
+                                                      fieldSchema.getTreeInfoPayloadTermText());
+    lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+    ltfAnalyzer.consumeInputStream();
+    Document doc = new Document();
+    Field labelField = makeLabelField(ltfAnalyzer);
+    doc.add(labelField);
+    for (int i = 0; i < ltfAnalyzer.numFragmentStreams(); i++) {
+      Field fragmentField = makeFragmentField(ltfAnalyzer, i);
+      doc.add(fragmentField);
+      Field fragmentPositionsField = makeFragmentPositionsField(ltfAnalyzer, i);
+      doc.add(fragmentPositionsField);
+    }
+    return doc;
+  }
+
+  static void tstIntsInBytesRef(int[] expLabelNodeInfo, BytesRef bytesRef) {
+    int numBits = Integer.SIZE - Integer.numberOfLeadingZeros(expLabelNodeInfo.length/2 - 1);
+    int numBytes = (expLabelNodeInfo.length * numBits + 7) >> 3;
+    byte[] bytes = bytesRef.bytes;
+    assertEquals("bytes.length", numBytes, bytesRef.length);
+    for (int i = 0; i < expLabelNodeInfo.length; i++) {
+      long actValue = LongsInBytes.unPackValue(numBits, i, bytes, bytesRef.offset);
+      assertEquals("at index " + i, expLabelNodeInfo[i], actValue);
+    }
+  }
+
+  static void tstLabelNodeInfo(int[] expLabelNodeInfo, LeafReader lr, Term labelTreeTerm)
+  throws IOException {
+    DocsAndPositionsEnum actDPE = lr.termPositionsEnum(labelTreeTerm);
+    if (actDPE == null) {
+      assertTrue("actual DocsAndPositionsEnum for tree info payload term should not be null", expLabelNodeInfo == null);
+    } else {
+      assertEquals("labelInfoTerm first doc", 0, actDPE.nextDoc());
+      assertEquals("labelInfoTerm freq", 1, actDPE.freq());
+      int numLabels = actDPE.nextPosition();
+      if (numLabels == 1) { // root only
+        assertEquals("root only label info at pos 1", null, expLabelNodeInfo);
+        assertEquals("no payload for root only", null, actDPE.getPayload());
+      } else {
+        assertEquals("two ints per node expected", 0, expLabelNodeInfo.length % 2);
+        assertEquals("labelInfoTerm pos", expLabelNodeInfo.length/2, numLabels);
+        // get the payload
+        BytesRef payload = actDPE.getPayload();
+        assertTrue(payload != null);
+        tstIntsInBytesRef(expLabelNodeInfo, payload);
+        assertEquals("labelInfoTerm no next doc", DocsAndPositionsEnum.NO_MORE_DOCS, actDPE.nextDoc());
+      }
+    }
+  }
+
+  void tstLabelNodeInfo(String labeledFragmentsStr, int[] expLabelNodeInfo) throws IOException {
+    final int numFragmentStreams = 1;
+    Document doc = makeDocument(labeledFragmentsStr, numFragmentStreams);
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+    Term labelTreeTerm = new Term(fieldSchema.getLabelFieldName(), fieldSchema.getTreeInfoPayloadTermText());
+    tstLabelNodeInfo(expLabelNodeInfo, lr, labelTreeTerm);
+    lr.close();
+    dir.close();
+  }
+
+  public void testEmpty() throws IOException {
+    tstLabelNodeInfo("", null);
+  }
+
+  public void testRootOnly() throws IOException {
+    tstLabelNodeInfo("A: ;;", null);
+  }
+
+  public void testOneChild() throws IOException {
+    tstLabelNodeInfo("A: B: ;; ;;", new int[]{0,1, 0,0}); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  public void testTwoChildren() throws IOException {
+    tstLabelNodeInfo("A: B: ;; C: ;; ;;", new int[]{0,2, 0,0, 0,0});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; ;; ;;", new int[]{0,2, 0,1, 1,0});
+  }
+
+  public void testGrandChildren() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; D: ;; ;; ;;", new int[]{0,3, 0,2, 1,0, 1,0});
+  }
+
+  public void testLarger() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; D: ;; ;; B: C: ;; D: ;; ;; ;;", new int[]{0,6, 0,2, 1,0, 1,0, 0,2, 4,0, 4,0});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxFragmentWithoutOpenLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;; c1 ;;", null); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxNextFragmentWithoutOpenLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;; || c1 ;;", null); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxLabelAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; B: ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxFragmentAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxNextFragmentAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; || b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxEndLabelAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; ;; b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxMissingEndLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;;", null);
+  }
+}
diff --git a/lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlAnalyzer.java b/lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlAnalyzer.java
new file mode 100644
index 0000000..c913e7d
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlAnalyzer.java
@@ -0,0 +1,556 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+import org.junit.Test;
+import org.junit.Ignore;
+
+import javax.xml.stream.XMLEventReader;
+import javax.xml.stream.XMLInputFactory;
+import javax.xml.stream.XMLStreamException;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.analysis.label.XmlAnalyzer.LabeledTreeTokens;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+
+public class TestXmlAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labelsField", "treeInfoTerm-" + Version.LATEST); // add version until there is a real field for this
+  Term attrFragmentPosnsPayloadTerm = new Term("attrFragmentPosnsField", "attrFragmentPosnsTerm-" + Version.LATEST);
+  final int ATTR_NAME_FFI = fieldSchema.addLabeledFragmentField("attrNamesField", attrFragmentPosnsPayloadTerm);
+  final int ATTR_VALUE_FFI = fieldSchema.addLabeledFragmentField("attrValuesField", attrFragmentPosnsPayloadTerm);
+  final int TEXT_FFI = fieldSchema.addLabeledFragmentField("textField", new Term("textFragmentPosnsField", "textFragmentPosnsTerm-" + Version.LATEST)); // default xml text
+  final int NFS_FFI = fieldSchema.addLabeledFragmentField("nfs", new Term("nfsFragmentPosnsField", "textFragmentPosnsTerm-" + Version.LATEST)); // nfs is also xml tag name
+
+  final static LabeledTreeTokens LABELED_TREE_TOKENS = new LabeledTreeTokens() {
+    @Override
+    public String fragmentLabelAfterNestedElement() {
+      return "txt";
+    }
+
+    @Override
+    public Tokenizer textTokenizer(String tag) {
+      WhitespaceTokenizer whitespaceTokenizer = new WhitespaceTokenizer();
+      return whitespaceTokenizer;
+    }
+  };
+
+  Field makeLabelField(XmlAnalyzer xmlAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), xmlAnalyzer.labelTokenStream());
+  }
+
+  Field makeAttributeNameField(XmlAnalyzer xmlAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(ATTR_NAME_FFI), xmlAnalyzer.attrNameFragmentsTokenStream());
+  }
+
+  Field makeAttributeValueField(XmlAnalyzer xmlAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI), xmlAnalyzer.attrValueFragmentsTokenStream());
+  }
+
+  Field makeAttributeFragmentPositionsField(XmlAnalyzer xmlAnalyzer) {
+    Term attrFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(ATTR_NAME_FFI); // fragment positions shared with attr values
+    return new TextField(attrFpsTerm.field(), xmlAnalyzer.attrFragmentPositionsTokenStream(attrFpsTerm.text()));
+  }
+
+  Field makeTextField(XmlAnalyzer xmlAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    return new TextField(textFieldName, xmlAnalyzer.textFragmentsStream(textFieldName));
+  }
+
+  Field makeTextFragmentPositionsField(XmlAnalyzer xmlAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(TEXT_FFI);
+    return new TextField(textFpsTerm.field(), xmlAnalyzer.textFragmentPositionsStream(textFieldName, textFpsTerm.text()));
+  }
+
+  Field makeNextTextField(XmlAnalyzer xmlAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    return new TextField(textFieldName, xmlAnalyzer.textFragmentsStream(textFieldName));
+  }
+
+  Field makeNextTextFragmentPositionsField(XmlAnalyzer xmlAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(NFS_FFI);
+    return new TextField(textFpsTerm.field(), xmlAnalyzer.textFragmentPositionsStream(textFieldName, textFpsTerm.text()));
+  }
+
+
+  XMLInputFactory xmlInputFactory;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    xmlInputFactory = XMLInputFactory.newInstance();
+    xmlInputFactory.setProperty(XMLInputFactory.IS_COALESCING, Boolean.TRUE);
+  }
+
+  XMLEventReader xmlEventReaderFromString(String xml) throws IOException {
+    try {
+      XMLEventReader r = xmlInputFactory.createXMLEventReader(new StringReader(xml));
+      return r;
+    } catch (XMLStreamException xse) {
+      throw new IOException(xse);
+    }
+  }
+
+  Document makeDocument(String xml, XmlAnalyzer xmlAnalyzer) throws IOException, XMLStreamException {
+    XMLEventReader xmlEventReader = xmlEventReaderFromString(xml);
+    int initialOffset = 0;
+    xmlAnalyzer.consumeXmlEventReader(xmlEventReader, initialOffset);
+
+    Document doc = new Document();
+    doc.add(makeLabelField(xmlAnalyzer));
+
+    doc.add(makeAttributeNameField(xmlAnalyzer));
+    doc.add(makeAttributeValueField(xmlAnalyzer));
+    doc.add(makeAttributeFragmentPositionsField(xmlAnalyzer));
+
+    doc.add(makeTextField(xmlAnalyzer));
+    doc.add(makeTextFragmentPositionsField(xmlAnalyzer));
+
+    doc.add(makeNextTextField(xmlAnalyzer));
+    doc.add(makeNextTextFragmentPositionsField(xmlAnalyzer));
+
+    return doc;
+  }
+
+  void tstXmlDocument(String xml,
+                      int[] expLabelNodeInfo,
+                      int[] expAttrFragmentPosns,
+                      int[] expTextFragmentPosns,
+                      int[] expNextTextFragmentPosns,
+                      TPS[] expTPSs)
+  throws IOException, XMLStreamException {
+    List<String> textStreamTags = new ArrayList<>(0);
+    textStreamTags.add(fieldSchema.getFragmentFieldName(TEXT_FFI));
+    textStreamTags.add(fieldSchema.getFragmentFieldName(NFS_FFI));
+    XmlAnalyzer xmlAnalyzer = new XmlAnalyzer(textStreamTags, LABELED_TREE_TOKENS, fieldSchema.getTreeInfoPayloadTermText());
+    Document doc = makeDocument(xml, xmlAnalyzer);
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+
+    TPS.tstTermPositions(lr, expTPSs);
+
+    Term labelTreeTerm = new Term(fieldSchema.getLabelFieldName(), fieldSchema.getTreeInfoPayloadTermText());
+    TestLabeledTreeFragmentsAnalyzer.tstLabelNodeInfo(expLabelNodeInfo, lr, labelTreeTerm);
+
+    Term attrFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(0);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expAttrFragmentPosns, lr, attrFpsTerm);
+
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(2);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expTextFragmentPosns, lr, textFpsTerm);
+
+    Term nextTextFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(3);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expNextTextFragmentPosns, lr, nextTextFpsTerm);
+
+    lr.close();
+    dir.close();
+  }
+
+  void tstXmlDocument(String xml,
+                      int[] expLabelNodeInfo,
+                      int[] expAttrFragmentPosns,
+                      int[] expTextFragmentPosns,
+                      TPS[] expTPSs)
+  throws IOException, XMLStreamException {
+    // add empty expNextFragmentPosns
+    tstXmlDocument(xml, expLabelNodeInfo, expAttrFragmentPosns, expTextFragmentPosns, new int[0], expTPSs);
+  }
+
+  @Test(expected=XMLStreamException.class) // unexpected end of file for empty xml stream
+  public void testEmpty() throws IOException, XMLStreamException {
+    String xml = "";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, null);
+  }
+
+  public void testEmptyElement() throws IOException, XMLStreamException {
+    String xml = "<tag1></tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0})
+                  });
+  }
+
+  @Test(expected=XMLStreamException.class) // attribute value missing quotes
+  public void testXmlSyntaxError1() throws IOException, XMLStreamException {
+    String xml = "<tag1 a1=v1/>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, null);
+  }
+
+  public void testSingleAttribute() throws IOException, XMLStreamException {
+    String xml = "<tag1 attr1=\"val1\"/>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {0,1};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(ATTR_NAME_FFI), "attr1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI), "val1", new int[]{0})
+                  });
+  }
+
+  public void testSingleTextToken() throws IOException, XMLStreamException {
+    String xml = "<tag1> token1 </tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {0,1};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(TEXT_FFI), "token1", new int[]{0})
+                  });
+  }
+
+  public void testThreeEmptyElements() throws IOException, XMLStreamException {
+    String xml = "<tag1> <tag2> </tag2> <tag3> </tag3> </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag3", new int[]{2})
+                  });
+  }
+
+  public void testThreeElements1() throws IOException, XMLStreamException {
+    String xml =   "<tag1 attr12=\"v12\" attr11=\"v11\">" // attributes descending by name
+                 + "  <tag2> some text </tag2>"
+                 + "  <tag3 attr31=\"v31\"> </tag3>"
+                 + "</tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,2,2,3};
+    int[] textPosns = {0,0,2,2};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag3", new int[]{2}),
+                    new TPS(attrNameFieldName, "attr11", new int[]{0}), // attributes ascending by name
+                    new TPS(attrValueFieldName, "v11", new int[]{0}),
+                    new TPS(attrNameFieldName, "attr12", new int[]{1}),
+                    new TPS(attrValueFieldName, "v12", new int[]{1}),
+                    new TPS(attrNameFieldName, "attr31", new int[]{2}),
+                    new TPS(attrValueFieldName, "v31", new int[]{2}),
+                    new TPS(textFieldName, "some", new int[]{0}),
+                    new TPS(textFieldName, "text", new int[]{1})
+                  });
+  }
+
+  public void testTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> before <tag2> inside </tag2> after </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,1,2,3};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "txt", new int[]{2}),
+                    new TPS(textFieldName, "before", new int[]{0}),
+                    new TPS(textFieldName, "inside", new int[]{1}),
+                    new TPS(textFieldName, "after", new int[]{2}),
+                  });
+  }
+
+  public void testTwoStreamsSingleTextToken() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs> token2 </nfs> </tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    int[] nextTextPosns = {0,1};
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(nfsFieldName, "token2", new int[]{0}),
+                  });
+  }
+
+  public void testTwoStreamsTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> default1 default2 <nfs> before <tag2> inside </tag2> after </nfs> default3 </tag1>"; // txt label after </tag2>
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,2,2,3};
+    int[] nextTextPosns = {0,1,2,3};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "txt", new int[]{2}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(nfsFieldName, "inside", new int[]{1}),
+                    new TPS(nfsFieldName, "after", new int[]{2}),
+                    new TPS(textFieldName, "default3", new int[]{2}),
+                  });
+  }
+
+  public void testTwoStreamsNoTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> default1 default2 <nfs> before </nfs> <tag2 a21=\"v21\"/> </tag1>"; // no txt label, attribute in < /> syntax
+    int[] labelNodeInfo = {0,1, 0,0};
+    int[] attrPosns = {0,0,1};
+    int[] textPosns = {0,2,2};
+    int[] nextTextPosns = {0,1,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(attrNameFieldName, "a21", new int[]{0}),
+                    new TPS(attrValueFieldName, "v21", new int[]{0}),
+                  });
+  }
+
+  public void testTwoStreamsTextAfterNestedElementWithAttribute() throws IOException, XMLStreamException {
+    String xml = "<tag1> <tag2 a21=\"v21\"/> default1 default2 <nfs> after </nfs> default3 </tag1>"; // txt label after tag with attribute <tag2 ... />
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,0,1,1};
+    int[] textPosns = {0,0,0,3};
+    int[] nextTextPosns = {0,0,0,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "txt", new int[]{2}),
+                    new TPS(attrNameFieldName, "a21", new int[]{0}),
+                    new TPS(attrValueFieldName, "v21", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "after", new int[]{0}),
+                    new TPS(textFieldName, "default3", new int[]{2}),
+                  });
+  }
+
+  public void testIgnoreAttrsAtTextRedirectingTag() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs a21=\"v21\"> inside </nfs> default1 default2 <tag2 a22=\"v22\"> after </tag2> default3 </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,0,1,1};
+    int[] textPosns = {0,2,3,4};
+    int[] nextTextPosns = {0,1,1,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "txt", new int[]{2}),
+                    new TPS(attrNameFieldName, "a21", new int[]{}), // ignored
+                    new TPS(attrValueFieldName, "v21", new int[]{}), // ignored
+                    new TPS(nfsFieldName, "inside", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(attrNameFieldName, "a22", new int[]{0}), // present
+                    new TPS(attrValueFieldName, "v22", new int[]{0}), // present
+                    new TPS(textFieldName, "after", new int[]{2}),
+                    new TPS(textFieldName, "default3", new int[]{3}),
+                  });
+  }
+
+  public void testRedirectTextToDefaultStream() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs> before <tag2> <textField> default1 </textField> </tag2> </nfs> default2 </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,0,1,2};
+    int[] nextTextPosns = {0,1,1,1};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "txt", new int[]{2}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                  });
+  }
+
+  public void testJavadocExample() throws IOException, XMLStreamException {
+    String xml =
+      "<kiosk> " +
+        "some" +
+        "<newspaper counter=\"42\"> " +
+          " <editor>J. More </editor> " +
+          "<title>Greatest</title> " +
+        "</newspaper> " +
+        " more text" +
+        "<newspaper counter=\"43\"> " +
+          "<editor>C. Less</editor> " +
+          "<title> Early Morning</title> " +
+        "</newspaper>" +
+      "</kiosk>";
+
+    List<String> textStreamTags = new ArrayList<>(0);
+    textStreamTags.add("txt");
+    textStreamTags.add("editor");
+    textStreamTags.add("title");
+
+    LabeledTreeTokens labeledTreeTokens = new LabeledTreeTokens() {
+      @Override
+      public String fragmentLabelAfterNestedElement() {
+        return "after";
+      }
+
+      @Override
+      public Tokenizer textTokenizer(String tag) {
+        WhitespaceTokenizer whitespaceTokenizer = new WhitespaceTokenizer();
+        return whitespaceTokenizer;
+      }
+    };
+
+    XmlAnalyzer xmlAnalyzer = new XmlAnalyzer(textStreamTags, labeledTreeTokens, "treeInfo");
+
+    XMLEventReader xmlEventReader = xmlEventReaderFromString(xml);
+    int initialOffset = 0;
+    xmlAnalyzer.consumeXmlEventReader(xmlEventReader, initialOffset);
+
+    tstTokenStreamWithPayload(xmlAnalyzer.labelTokenStream(),
+                              new String[] {"kiosk", "newspaper", "after", "newspaper", "treeInfo"},
+                              4, true /* tree info payload */,
+                              new int[] {0,3, 0,0, 0,0, 0,0});
+
+    tstTokenStream(xmlAnalyzer.attrNameFragmentsTokenStream(), new String[] {"counter", "counter"});
+    tstTokenStream(xmlAnalyzer.attrValueFragmentsTokenStream(), new String[] {"42", "43"});
+    tstTokenStreamWithPayload(xmlAnalyzer.attrFragmentPositionsTokenStream("fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 1, 1, 2});
+
+    tstTokenStream(xmlAnalyzer.textFragmentsStream("txt"), new String[] {"some", "more", "text"});
+    tstTokenStreamWithPayload(xmlAnalyzer.textFragmentPositionsStream("txt", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 1, 1, 3, 3});
+
+    tstTokenStream(xmlAnalyzer.textFragmentsStream("editor"), new String[] {"J.", "More", "C.", "Less"});
+    tstTokenStreamWithPayload(xmlAnalyzer.textFragmentPositionsStream("editor", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 2, 2, 4});
+
+    tstTokenStream(xmlAnalyzer.textFragmentsStream("title"), new String[] {"Greatest", "Early", "Morning"});
+    tstTokenStreamWithPayload(xmlAnalyzer.textFragmentPositionsStream("title", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 1, 1, 3});
+  }
+
+  static void tstTokenStream(TokenStream ts, String[] expTokenStrings) throws IOException {
+    tstTokenStreamWithPayload(ts, expTokenStrings, -1, false, null);
+  }
+
+  static void tstTokenStreamWithPayload(
+      TokenStream ts,
+      String[] expTokenStrings,
+      int expPayloadIndex,
+      boolean isTreeInfoPayload, // otherwise fragment positions payload
+      int[] expValues) // tree info or fragment positions.
+  throws IOException
+  {
+    int streamIndex = -1;
+    ts.reset();
+    CharTermAttribute cta = ts.getAttribute(CharTermAttribute.class);
+    PayloadAttribute pa = ts.getAttribute(PayloadAttribute.class);
+    while (ts.incrementToken()) {
+      streamIndex++;
+      assertEquals("token string at " + streamIndex, expTokenStrings[streamIndex], cta.toString());
+      if (streamIndex == expPayloadIndex) {
+        BytesRef payload = pa.getPayload();
+        if (isTreeInfoPayload) {
+          TestLabeledTreeFragmentsAnalyzer.tstIntsInBytesRef(expValues, payload);
+        }
+        else { // fragment positions payload
+          TestLabeledFragmentsAnalyzer.tstDecodeAllNext(expValues, EliasFanoBytes.createFromBytesRef(payload));
+        }
+      }
+    }
+    ts.close();
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java
new file mode 100644
index 0000000..eee380a
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java
@@ -0,0 +1,211 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+import org.apache.lucene.util.Bits;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer;
+import org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.analysis.MockAnalyzer;
+
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanTermQuery;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.InputSplitter;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+
+abstract class LabeledFragmentsTestCase extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels", "treeInfoTerm-" + Version.LATEST); // add version until there is a real field for this
+  final int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  Field makeLabelField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), lfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex), lfAnalyzer.fragmentsTokenStream(firstFragmentFieldSchemaIndex));
+  }
+
+  Field makeFragmentPositionsField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(firstFragmentFieldSchemaIndex, fpsTerm.text()));
+  }
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      if (term.equals("||")) {
+        return TokenType.NEXT_FRAGMENT;
+      }
+      if (term.endsWith(":")) {
+        return TokenType.LABEL;
+      }
+      return TokenType.FRAGMENT;
+    }
+  };
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      return term.endsWith(":") ? TokenType.LABEL
+            : term.equals("||") ? TokenType.NEXT_FRAGMENT
+            : term.equals(";;") ? TokenType.END_LABEL
+                                : TokenType.FRAGMENT;
+    }
+  };
+
+  Document makeDocument(LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    Document doc = new Document();
+    Field labelField = makeLabelField(lfAnalyzer);
+    doc.add(labelField);
+    Field fragmentField = makeFragmentField(lfAnalyzer);
+    doc.add(fragmentField);
+    Field fragmentPositionsField = makeFragmentPositionsField(lfAnalyzer);
+    doc.add(fragmentPositionsField);
+    return doc;
+  }
+
+  List<Document> makeDocuments(String[] labeledFragmentsStrs, Tokenizer lfTokenizer, LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    List<Document> docs = new ArrayList<>();
+    for (String labeledFragmentsStr: labeledFragmentsStrs) {
+      lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+      lfAnalyzer.consumeInputStream();
+      Document doc = makeDocument(lfAnalyzer);
+      docs.add(doc);
+    }
+    return docs;
+  }
+
+  List<Document> makeDocumentsLF(String[] labeledFragmentsStrs, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(lfTokenizer, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    return makeDocuments(labeledFragmentsStrs, lfTokenizer, lfAnalyzer);
+  }
+
+  List<Document> makeDocumentsLTF(String[] labeledFragmentsStrs, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledTreeFragmentsAnalyzer ltfAnalyzer = new LabeledTreeFragmentsAnalyzer(
+                                                      lfTokenizer,
+                                                      ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI,
+                                                      numFragmentStreams,
+                                                      fieldSchema.getTreeInfoPayloadTermText());
+    return makeDocuments(labeledFragmentsStrs, lfTokenizer, ltfAnalyzer);
+  }
+
+  void tstSpansFromDocs(List<Document> docs, SpanQuery spanQuery, int[][] expSpansByDoc) throws IOException {
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    for (Document doc: docs) {
+      w.addDocument(doc);
+    }
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir)); // slow, but ok for testing
+
+    LeafReaderContext lrContext = lr.getContext();
+
+    Query rewrittenQuery = spanQuery.rewrite(lr); // get the term contexts so getSpans can be called directly
+    HashSet<Term> termSet = new HashSet<>();
+    rewrittenQuery.extractTerms(termSet);
+    Map<Term,TermContext> termContexts = new HashMap<>();
+    for (Term term: termSet) {
+      TermContext termContext = TermContext.build(lrContext, term);
+      termContexts.put(term, termContext);
+    }
+
+    Spans actSpans = spanQuery.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()), termContexts);
+
+    assertEquals("expected spans present for each doc", docs.size(), expSpansByDoc.length);
+
+    int expDoc = 0;
+    while (expDoc < expSpansByDoc.length) {
+      int[] expSpans = expSpansByDoc[expDoc];
+      assertTrue("int[] expSpans should have even length", (expSpans.length % 2) == 0);
+      int i = 0;
+      while (i < expSpans.length) {
+        assertTrue("next spans", actSpans.next());
+        assertEquals("spans doc", expDoc, actSpans.doc());
+        assertEquals("spans start " + i, expSpans[i], actSpans.start());
+        i++;
+        assertEquals("spans end " + i, expSpans[i], actSpans.end());
+        i++;
+      }
+      expDoc++;
+    }
+    assertFalse("more actual spans than expected " + actSpans, actSpans.next());
+
+    lr.close();
+    dir.close();
+  }
+
+  void tstSpansFromLabeledFragments(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocumentsLF(labeledFragmentsStrs, 1);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  void tstSpansFromLabeledTree(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocumentsLTF(labeledFragmentsStrs, 1);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  SpanTermQuery labelSTQ(String label) {
+    return new SpanTermQuery(new Term(fieldSchema.getLabelFieldName(), label));
+  }
+
+  SpanTermQuery fragmentSTQ(String fragmentTerm) {
+    return new SpanTermQuery(new Term(fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex), fragmentTerm));
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java
new file mode 100644
index 0000000..ee785b7
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java
@@ -0,0 +1,72 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+
+public class TestChildLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstChildSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int childNum, int[][] expSpansByDoc)
+  throws IOException {
+    ChildLabelQuery clq = new ChildLabelQuery(labelSpanQuery, childNum, fieldSchema.getTreeInfoPayloadTermText());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.childLabelQuery(labelSpanQuery, childNum);
+    assertTrue(factoryRes.equals(clq));
+    tstSpansFromLabeledTree(labeledFragmentsStrs, clq, expSpansByDoc);
+  }
+
+  void tstChildSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int childNum, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstChildSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, childNum, new int[][]{expSpans});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), 0, new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstChildSpansFromLabelSpans("A: ;;", labelSTQ("A:"), 0, new int[]{});
+  }
+
+  public void testOneChildNotPresent() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), 0, new int[]{});
+  }
+
+  public void testOneChildPresent() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("A:"), 0, new int[]{1,2});
+  }
+
+  public void testTwoChildren1() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), 0, new int[]{1,2});
+  }
+
+  public void testTwoChildren2() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), 1, new int[]{2,3});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("B:"), 0, new int[]{2,3});
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java
new file mode 100644
index 0000000..2a6b23b
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java
@@ -0,0 +1,71 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+
+public class TestDescendantsLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstDescendantSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    boolean includeLabel = false;
+    DescendantsLabelQuery dlq = new DescendantsLabelQuery(labelSpanQuery, fieldSchema.getTreeInfoPayloadTermText(), includeLabel);
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = includeLabel ? pjqf.descendantsOrSelfLabelQuery(labelSpanQuery) : pjqf.descendantsLabelQuery(labelSpanQuery);
+    assertTrue(factoryRes.equals(dlq));
+    tstSpansFromLabeledTree(labeledFragmentsStrs, dlq, expSpansByDoc);
+  }
+
+  void tstDescendantSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstDescendantSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, new int[][]{expSpans});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: ;;", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testOneChildNotPresent() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), new int[]{});
+  }
+
+  public void testOneChildPresent() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("A:"), new int[]{1,2});
+  }
+
+  public void testOneChildPresent2() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("B:"), new int[]{2,3});
+  }
+
+  public void testTwoChildren() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), new int[]{1,3});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("A:"), new int[]{1,3});
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java
new file mode 100644
index 0000000..9f888ea
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java
@@ -0,0 +1,148 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer;
+
+import org.apache.lucene.util.Version;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.search.spans.SpanQuery;
+
+public class TestFragmentLabelFragment extends LabeledFragmentsTestCase {
+  final int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  Field makeFragmentField2(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex), lfAnalyzer.fragmentsTokenStream(secondFragmentFieldSchemaIndex));
+  }
+
+  Field makeFragmentPositionsField2(LabeledFragmentsAnalyzer lfAnalyzer) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(secondFragmentFieldSchemaIndex);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(secondFragmentFieldSchemaIndex, fpsTerm.text()));
+  }
+
+  Document makeDocument2(LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    Document doc = makeDocument(lfAnalyzer);
+    Field fragmentField2 = makeFragmentField2(lfAnalyzer);
+    doc.add(fragmentField2);
+    Field fragmentPositionsField2 = makeFragmentPositionsField2(lfAnalyzer);
+    doc.add(fragmentPositionsField2);
+    return doc;
+  }
+
+  List<Document> makeDocuments2(String[] labeledFragmentsStrs) throws IOException {
+    Tokenizer labeledFragments = new WhitespaceTokenizer();
+    int numFragmentStreams = 2;
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(labeledFragments, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    List<Document> docs = new ArrayList<>();
+    for (String labeledFragmentsStr: labeledFragmentsStrs) {
+      labeledFragments.setReader(new StringReader(labeledFragmentsStr));
+      lfAnalyzer.consumeInputStream();
+      Document doc = makeDocument2(lfAnalyzer);
+      docs.add(doc);
+    }
+    return docs;
+  }
+
+  void tstSpansFromLabeledFragments2(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocuments2(labeledFragmentsStrs);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  FragmentToLabelQuery fragmentToLabelQuery(SpanQuery fragmentQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    FragmentToLabelQuery res = new FragmentToLabelQuery(fragmentQuery, fpsTerm, fieldSchema.getLabelFieldName());
+    return res;
+  }
+
+  LabelToFragmentQuery labelToFragment2Query(SpanQuery labelQuery) {
+    Term fpsTerm2 = fieldSchema.getFragmentPositionsPayloadTerm(secondFragmentFieldSchemaIndex);
+    return new LabelToFragmentQuery(labelQuery, fpsTerm2, fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex));
+  }
+
+  void tstFragment2SpansFromFragmentSpans(String[] labeledFragmentsStrs, SpanQuery fragmentSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    FragmentToLabelQuery ftlq = fragmentToLabelQuery(fragmentSpanQuery);
+    LabelToFragmentQuery ltf2q = labelToFragment2Query(ftlq);
+
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(fragmentSpanQuery, fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex));
+    assertTrue(factoryRes.equals(ltf2q));
+
+    tstSpansFromLabeledFragments2(labeledFragmentsStrs, ltf2q, expSpansByDoc);
+  }
+
+  void tstFragment2SpansFromFragmentSpans(String labeledFragmentsStr, SpanQuery fragmentSpanQuery, int[] expLabelSpans)
+  throws IOException {
+    // single doc
+    tstFragment2SpansFromFragmentSpans(new String[]{labeledFragmentsStr}, fragmentSpanQuery, new int[][]{expLabelSpans});
+  }
+
+  public void testTooManyFragments() throws IOException {
+    boolean ok = false;
+    try {
+      tstFragment2SpansFromFragmentSpans("A: || ||", fragmentSTQ("x"), new int[]{});
+    } catch (IllegalArgumentException iae) {
+      ok = true;
+    }
+    assertTrue("no IllegalArgumentException for too many fragments", ok);
+  }
+
+  public void testFLFNonPresentTerm() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 || a21 a22", fragmentSTQ("a1"), new int[]{});
+  }
+
+  public void testFLFPresentTerm1() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 || a21 a22", fragmentSTQ("a11"), new int[]{0,2});
+  }
+
+  public void testFLFPresentTerm2() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23", fragmentSTQ("a11"), new int[]{0,3});
+  }
+
+  public void testFLFPresentTerm3() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23", fragmentSTQ("a12"), new int[]{0,3});
+  }
+
+  public void testFLFPresentTerm4() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23  B: a12 || ", fragmentSTQ("a12"), new int[]{0,3}); // ignore empty B:
+  }
+
+  public void testFLFPresentTerm5() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23  B: a13 || ", fragmentSTQ("a13"), new int[]{}); // ignore empty B:
+  }
+
+  public void testFLFPresentTermTwoDocs1() throws IOException {
+    tstFragment2SpansFromFragmentSpans(new String[]{"A: a11 || a21 a22","A: a11 a12 || a21 a22  B: a12 || a23"},
+                                        fragmentSTQ("a12"),
+                                        new int[][]{{},{0,2,2,3}});
+  }
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java
new file mode 100644
index 0000000..fc193f6
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java
@@ -0,0 +1,132 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+
+public class TestFragmentToLabelQuery extends LabeledFragmentsTestCase {
+
+  FragmentToLabelQuery fragmentToLabelQuery(SpanQuery fragmentQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    FragmentToLabelQuery res = new FragmentToLabelQuery(fragmentQuery, fpsTerm, fieldSchema.getLabelFieldName());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(fragmentQuery, fieldSchema.getLabelFieldName());
+    assertTrue(factoryRes.equals(res));
+    return res;
+  }
+
+  void tstLabelSpansFromFragmentSpans(String[] labeledFragmentsStrs, SpanQuery fragmentSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    FragmentToLabelQuery ftlq = fragmentToLabelQuery(fragmentSpanQuery);
+    tstSpansFromLabeledFragments(labeledFragmentsStrs, ftlq, expSpansByDoc);
+  }
+
+  void tstLabelSpansFromFragmentSpans(String labeledFragmentsStr, SpanQuery fragmentSpanQuery, int[] expLabelSpans)
+  throws IOException {
+    // single doc
+    tstLabelSpansFromFragmentSpans(new String[]{labeledFragmentsStr}, fragmentSpanQuery, new int[][]{expLabelSpans});
+  }
+
+  public void testEmptyFragment() throws IOException {
+    tstLabelSpansFromFragmentSpans("A:", fragmentSTQ("x"), new int[]{});
+  }
+
+  public void testOneFragmentPresentTerm1() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1", fragmentSTQ("a1"), new int[]{0,1});
+  }
+
+  public void testOneFragmentPresentTerm2() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2", fragmentSTQ("a1"), new int[]{0,1});
+  }
+
+  public void testOneFragmentPresentTerm3() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2", fragmentSTQ("a2"), new int[]{0,1});
+  }
+
+  public void testOneFragmentNonPresentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1", fragmentSTQ("a2"), new int[]{});
+  }
+
+  public void testTwoFragmentsOneLabel() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2", fragmentSTQ("b1"), new int[]{1,2});
+  }
+
+  public void testTwoFragmentsSameFragmentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 a2", fragmentSTQ("a2"), new int[]{0,1,1,2});
+  }
+
+  public void testTwoFragmentsTwoLabels() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2",
+                                  new SpanOrQuery(new SpanQuery[] { fragmentSTQ("a2"), fragmentSTQ("b1")}),
+                                  new int[]{0,1,1,2});
+  }
+
+  public void testLabelsForSpanNearOverFragments() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2",
+                                    new SpanNearQuery(new SpanQuery[] { fragmentSTQ("a2"), fragmentSTQ("b1")}, 1, false),
+                                    new int[]{0,2}); // "A: B:"
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchFragmentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[] {"A:","B:"}, fragmentSTQ("x"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsOneFragment1() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, fragmentSTQ("a2"), new int[][]{{0,1},{0,1}});
+  }
+
+  public void testTwoDocsOneFragment2() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, fragmentSTQ("a3"), new int[][]{{},{0,1}});
+  }
+
+  public void testTwoDocsOneFragment3() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2 a3", "A: a1 a2"}, fragmentSTQ("a3"), new int[][]{{0,1},{}});
+  }
+
+  public void testWithinLabelFieldBeforeFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentToLabelQuery(fragmentSTQ("a2")), labelSTQ("B:")} , 0, true),
+        new int[][]{{},{0,2}}); // "A: B:", a2 in fragment field of some label, directly followed by label B:
+  }
+
+  public void testWithinLabelFieldInFragment() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { labelSTQ("B:"), fragmentToLabelQuery(fragmentSTQ("b1"))}, -1, false),
+        new int[][]{{},{1,2}}); // "B:", B: label containing b1 in fragment
+  }
+
+
+  public void testNotWithinLabelFieldInFragment() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentToLabelQuery(fragmentSTQ("a2")), labelSTQ("B:") }, -1, false),
+        new int[][]{{},{}}); // label for fragment with a2 nowhere in label field for label B:
+  }
+
+  public void testNoWithinFragmentFieldAtFragmentEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 a2"},
+        new SpanNearQuery(new SpanQuery[] { labelSTQ("A:"), fragmentToLabelQuery(fragmentSTQ("b1")) }, 0, true),
+    new int[][]{{},{0,2}}); // "A: B:" label A: immediately followed by labelof fragment containing b1
+  }
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java
new file mode 100644
index 0000000..7c086b6
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java
@@ -0,0 +1,126 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+
+public class TestLabelToFragmentQuery extends LabeledFragmentsTestCase {
+
+  LabelToFragmentQuery labelToFragmentQuery(SpanQuery labelQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    LabelToFragmentQuery res = new LabelToFragmentQuery(labelQuery, fpsTerm, fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex));
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(labelQuery, fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex));
+    assertTrue(factoryRes.equals(res));
+    return res;
+  }
+
+  void tstFragmentSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    LabelToFragmentQuery ltfq = labelToFragmentQuery(labelSpanQuery);
+    tstSpansFromLabeledFragments(labeledFragmentsStrs, ltfq, expSpansByDoc);
+  }
+
+  void tstFragmentSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expFragmentSpans)
+  throws IOException {
+    // single doc
+    tstFragmentSpansFromLabelSpans(new String[]{labeledFragmentsStr}, labelSpanQuery, new int[][]{expFragmentSpans});
+  }
+
+  public void testEmptyFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans("A:", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testOneFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2", labelSTQ("A:"), new int[]{0,2});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2", labelSTQ("B:"), new int[]{});
+  }
+
+  public void testTwoFragmentsOneLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2", labelSTQ("B:"), new int[]{2,4});
+  }
+
+  public void testTwoFragmentsSameLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 A: b1 b2", labelSTQ("A:"), new int[]{0,2,2,4});
+  }
+
+  public void testTwoFragmentsTwoLabels() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2",
+                                  new SpanOrQuery(new SpanQuery[] { labelSTQ("A:"), labelSTQ("B:")}),
+                                  new int[]{0,2,2,4});
+  }
+
+  public void testFragmentsForSpanNearLabels() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2",
+                                    new SpanNearQuery(new SpanQuery[] { labelSTQ("A:"), labelSTQ("B:")}, 1, false),
+                                    new int[]{0,4}); // "a1 a2 b1 b2"
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchLabel1() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[] {"A:","B:"}, labelSTQ("A:"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchLabel2() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[] {"A:","B:"}, labelSTQ("B:"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsOneFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, labelSTQ("A:"), new int[][]{{0,2},{0,3}});
+  }
+
+  public void testWithinFragmentFieldBeforeFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("a2"), labelToFragmentQuery(labelSTQ("B:"))} , 0, true),
+        new int[][]{{},{1,4}}); // "a2 b1 b2", a2 in fragment field directly followed by label B:
+  }
+
+  public void testWithinFragmentFieldInFragmentAtStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("b1"), labelToFragmentQuery(labelSTQ("B:"))}, -1, false),
+        new int[][]{{},{2,4}}); // "b1 b2", b1 in fragment field for label B:
+  }
+
+  public void testWithinFragmentFieldInFragmentAtEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("b2"), labelToFragmentQuery(labelSTQ("B:")) }, -1, false),
+        new int[][]{{},{2,4}}); // "b1 b2", b2 in fragment field for label B:
+  }
+
+  public void testNotWithinFragmentFieldAtFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("a2"), labelToFragmentQuery(labelSTQ("B:")) }, -1, false),
+        new int[][]{{},{}}); // a2 nowhere in fragment field for label B:
+  }
+
+  public void testNoWithinFragmentFieldAtFragmentEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("b1"), labelToFragmentQuery(labelSTQ("A:")) }, -1, false),
+        new int[][]{{},{}}); // b1 nowhere in fragment field after label A:
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java
new file mode 100644
index 0000000..a06c1c2
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java
@@ -0,0 +1,79 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+
+public class TestParentLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstParentSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    ParentLabelQuery plq = new ParentLabelQuery(labelSpanQuery, fieldSchema.getTreeInfoPayloadTermText());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.parentLabelQuery(labelSpanQuery);
+    assertTrue(factoryRes.equals(plq));
+
+    tstSpansFromLabeledTree(labeledFragmentsStrs, plq, expSpansByDoc);
+  }
+
+  void tstParentSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstParentSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, new int[][]{expSpans});
+  }
+
+  public void testUnclosedLabel() throws IOException {
+    tstParentSpansFromLabelSpans("A:", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstParentSpansFromLabelSpans("A: ;;", labelSTQ("A:"), new int[]{0,1});
+  }
+
+  public void testOneChild() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), new int[]{0,1});
+  }
+
+  public void testTwoChildren1() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("B:"), new int[]{0,1});
+  }
+
+  public void testTwoChildren2() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("C:"), new int[]{0,1});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("C:"), new int[]{1,2});
+  }
+
+  public void testTwoDocsChildGrandChild() throws IOException {
+    // test indexing more than one document.
+    // test TreeInfo.reInit by label present in both docs.
+    tstParentSpansFromLabelSpans(new String[] {"B: A: ;; ;;", "A: C: B: ;; ;; ;;"}, labelSTQ("B:"), new int[][]{{0,1},{1,2}});
+  }
+
+}
diff --git a/lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java
new file mode 100644
index 0000000..4bd0865
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java
@@ -0,0 +1,44 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+
+public class TestPositionalJoinQueryFactory extends LabeledFragmentsTestCase {
+
+  public void testSharedPositions() { // other normal cases tested elsewhere in this package
+    LabelFieldSchema fieldSchema = new LabelFieldSchema("labelField", "treeInfoPayloadTerm");
+    Term fragmentPositionsPayloadTerm1 = new Term("labelToFragment", "positions");
+    Term fragmentPositionsPayloadTerm2 = new Term("labelToFragment", "positions"); // equal terms
+    int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments1", fragmentPositionsPayloadTerm1);
+    int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", fragmentPositionsPayloadTerm2);
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+
+    SpanTermQuery stq = new SpanTermQuery(new Term("fragments1", "value1"));
+    SpanQuery factoryRes = pjqf.positionalJoin(stq, "fragments2");
+    assertTrue(factoryRes instanceof FieldMaskingSpanQuery);
+  }
+}
diff --git a/lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java b/lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java
new file mode 100644
index 0000000..b18c216
--- /dev/null
+++ b/lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java
@@ -0,0 +1,45 @@
+package org.apache.lucene.util.packed.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestLongsInBytes extends LuceneTestCase {
+  public void testSingleOnes() {
+    for (int index = 0; index < Byte.SIZE; index++) {
+      for (int numBits = 1; numBits < Long.SIZE; numBits++) {
+        byte[] bytes = new byte[numBits];
+        long value = 1;
+        int offset = 0;
+        LongsInBytes.packValue(value, numBits, index, bytes, 0);
+        assertEquals(value, LongsInBytes.unPackValue(numBits, index, bytes, 0));
+      }
+    }
+  }
+  public void testAllOnes() {
+    for (int index = 0; index < Byte.SIZE; index++) {
+      for (int numBits = 1; numBits < Long.SIZE; numBits++) {
+        byte[] bytes = new byte[numBits];
+        long value = ~(-1L << numBits);
+        int offset = 0;
+        LongsInBytes.packValue(value, numBits, index, bytes, 0);
+        assertEquals(value, LongsInBytes.unPackValue(numBits, index, bytes, 0));
+      }
+    }
+  }
+}
diff --git a/lucene/module-build.xml b/lucene/module-build.xml
index c68900a..76a4773 100644
--- a/lucene/module-build.xml
+++ b/lucene/module-build.xml
@@ -138,8 +138,19 @@
   <target name="jar-join" unless="join.uptodate" depends="check-join-uptodate">
     <ant dir="${common.dir}/join" target="jar-core" inheritAll="false">
       <propertyset refid="uptodate.and.compiled.properties"/>
-	</ant>
-	<property name="join.uptodate" value="true"/>
+    </ant>
+    <property name="join.uptodate" value="true"/>
+  </target>
+
+  <property name="label.jar" value="${common.dir}/build/join/lucene-label-${version}.jar"/>
+  <target name="check-label-uptodate" unless="label.uptodate">
+    <module-uptodate name="label" jarfile="${label.jar}" property="label.uptodate"/>
+  </target>
+  <target name="jar-label" unless="label.uptodate" depends="check-label-uptodate">
+    <ant dir="${common.dir}/label" target="jar-core" inheritAll="false">
+      <propertyset refid="uptodate.and.compiled.properties"/>
+    </ant>
+    <property name="label.uptodate" value="true"/>
   </target>	
   
   <property name="analyzers-common.jar" value="${common.dir}/build/analysis/common/lucene-analyzers-common-${version}.jar"/>
