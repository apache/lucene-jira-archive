Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(date 1436204317000)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(revision )
@@ -903,18 +903,18 @@
         return map;
       }
       addDone(); // in case this wasn't previously called
-      DataInputStream in = new DataInputStream(new BufferedInputStream(
-          Files.newInputStream(tmpfile)));
+      try (DataInputStream in = new DataInputStream(new BufferedInputStream(
+          Files.newInputStream(tmpfile)))) {
-      map = new int[in.readInt()];
-      // NOTE: The current code assumes here that the map is complete,
-      // i.e., every ordinal gets one and exactly one value. Otherwise,
-      // we may run into an EOF here, or vice versa, not read everything.
+        map = new int[in.readInt()];
+        // NOTE: The current code assumes here that the map is complete,
+        // i.e., every ordinal gets one and exactly one value. Otherwise,
+        // we may run into an EOF here, or vice versa, not read everything.
-      for (int i=0; i<map.length; i++) {
+        for (int i = 0; i < map.length; i++) {
-        int origordinal = in.readInt();
-        int newordinal = in.readInt();
-        map[origordinal] = newordinal;
-      }
+          int origordinal = in.readInt();
+          int newordinal = in.readInt();
+          map[origordinal] = newordinal;
+        }
-      in.close();
+      }
 
       // Delete the temporary file, which is no longer needed.
       Files.delete(tmpfile);
Index: lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java	(date 1436204317000)
+++ lucene/analysis/stempel/src/java/org/egothor/stemmer/DiffIt.java	(revision )
@@ -98,26 +98,30 @@
     int nop = get(3, args[0]);
     
     for (int i = 1; i < args.length; i++) {
-      LineNumberReader in;
+      LineNumberReader in = null;
       // System.out.println("[" + args[i] + "]");
       Diff diff = new Diff(ins, del, rep, nop);
       String charset = System.getProperty("egothor.stemmer.charset", "UTF-8");
+      try {
-      in = new LineNumberReader(Files.newBufferedReader(Paths.get(args[i]), Charset.forName(charset)));
-      for (String line = in.readLine(); line != null; line = in.readLine()) {
-        try {
-          line = line.toLowerCase(Locale.ROOT);
-          StringTokenizer st = new StringTokenizer(line);
-          String stem = st.nextToken();
-          System.out.println(stem + " -a");
-          while (st.hasMoreTokens()) {
-            String token = st.nextToken();
-            if (token.equals(stem) == false) {
-              System.out.println(stem + " " + diff.exec(token, stem));
-            }
-          }
-        } catch (java.util.NoSuchElementException x) {
-          // no base token (stem) on a line
-        }
+        in = new LineNumberReader(Files.newBufferedReader(Paths.get(args[i]), Charset.forName(charset)));
+        for (String line = in.readLine(); line != null; line = in.readLine()) {
+          try {
+            line = line.toLowerCase(Locale.ROOT);
+            StringTokenizer st = new StringTokenizer(line);
+            String stem = st.nextToken();
+            System.out.println(stem + " -a");
+            while (st.hasMoreTokens()) {
+              String token = st.nextToken();
+              if (token.equals(stem) == false) {
+                System.out.println(stem + " " + diff.exec(token, stem));
+              }
+            }
+          } catch (java.util.NoSuchElementException x) {
+            // no base token (stem) on a line
+          }
+        }
+      } finally {
+        if (in != null) in.close();
       }
     }
   }
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java	(date 1436204317000)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java	(revision )
@@ -227,56 +227,60 @@
   public JaspellTernarySearchTrie(Path file, boolean compression)
           throws IOException {
     this();
-    BufferedReader in;
+    BufferedReader in = null;
+    try {
-    if (compression)
-      in = new BufferedReader(IOUtils.getDecodingReader(new GZIPInputStream(
-              Files.newInputStream(file)), StandardCharsets.UTF_8));
-    else in = Files.newBufferedReader(file, StandardCharsets.UTF_8);
-    String word;
-    int pos;
-    Float occur, one = new Float(1);
-    while ((word = in.readLine()) != null) {
-      pos = word.indexOf("\t");
-      occur = one;
-      if (pos != -1) {
-        occur = Float.parseFloat(word.substring(pos + 1).trim());
-        word = word.substring(0, pos);
-      }
-      String key = word.toLowerCase(locale);
-      if (rootNode == null) {
-        rootNode = new TSTNode(key.charAt(0), null);
-      }
-      TSTNode node = null;
-      if (key.length() > 0 && rootNode != null) {
-        TSTNode currentNode = rootNode;
-        int charIndex = 0;
-        while (true) {
-          if (currentNode == null) break;
-          int charComp = compareCharsAlphabetically(key.charAt(charIndex),
-                  currentNode.splitchar);
-          if (charComp == 0) {
-            charIndex++;
-            if (charIndex == key.length()) {
-              node = currentNode;
-              break;
-            }
-            currentNode = currentNode.relatives[TSTNode.EQKID];
-          } else if (charComp < 0) {
-            currentNode = currentNode.relatives[TSTNode.LOKID];
-          } else {
-            currentNode = currentNode.relatives[TSTNode.HIKID];
-          }
-        }
-        Float occur2 = null;
-        if (node != null) occur2 = ((Float) (node.data));
-        if (occur2 != null) {
-          occur += occur2.floatValue();
-        }
-        currentNode = getOrCreateNode(word.trim().toLowerCase(locale));
-        currentNode.data = occur;
-      }
-    }
+      if (compression)
+        in = new BufferedReader(IOUtils.getDecodingReader(new GZIPInputStream(
+            Files.newInputStream(file)), StandardCharsets.UTF_8));
+      else in = Files.newBufferedReader(file, StandardCharsets.UTF_8);
+      String word;
+      int pos;
+      Float occur, one = new Float(1);
+      while ((word = in.readLine()) != null) {
+        pos = word.indexOf("\t");
+        occur = one;
+        if (pos != -1) {
+          occur = Float.parseFloat(word.substring(pos + 1).trim());
+          word = word.substring(0, pos);
+        }
+        String key = word.toLowerCase(locale);
+        if (rootNode == null) {
+          rootNode = new TSTNode(key.charAt(0), null);
+        }
+        TSTNode node = null;
+        if (key.length() > 0 && rootNode != null) {
+          TSTNode currentNode = rootNode;
+          int charIndex = 0;
+          while (true) {
+            if (currentNode == null) break;
+            int charComp = compareCharsAlphabetically(key.charAt(charIndex),
+                currentNode.splitchar);
+            if (charComp == 0) {
+              charIndex++;
+              if (charIndex == key.length()) {
+                node = currentNode;
+                break;
+              }
+              currentNode = currentNode.relatives[TSTNode.EQKID];
+            } else if (charComp < 0) {
+              currentNode = currentNode.relatives[TSTNode.LOKID];
+            } else {
+              currentNode = currentNode.relatives[TSTNode.HIKID];
+            }
+          }
+          Float occur2 = null;
+          if (node != null) occur2 = ((Float) (node.data));
+          if (occur2 != null) {
+            occur += occur2.floatValue();
+          }
+          currentNode = getOrCreateNode(word.trim().toLowerCase(locale));
+          currentNode.data = occur;
+        }
+      }
-    in.close();
+    } finally {
+      if (in != null) { in.close(); }
+    }
+
   }
 
   /**
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CloseTaxonomyReaderTask.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CloseTaxonomyReaderTask.java	(date 1436204317000)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CloseTaxonomyReaderTask.java	(revision )
@@ -34,12 +34,17 @@
 
   @Override
   public int doLogic() throws IOException {
-    TaxonomyReader taxoReader = getRunData().getTaxonomyReader();
+    TaxonomyReader taxoReader = null;
+    try {
+      taxoReader = getRunData().getTaxonomyReader();
-    getRunData().setTaxonomyReader(null);
-    if (taxoReader.getRefCount() != 1) {
-      System.out.println("WARNING: CloseTaxonomyReader: reference count is currently " + taxoReader.getRefCount());
-    }
+      getRunData().setTaxonomyReader(null);
+      if (taxoReader.getRefCount() != 1) {
+        System.out.println("WARNING: CloseTaxonomyReader: reference count is currently " + taxoReader.getRefCount());
+      }
-    taxoReader.close();
+    } finally {
+      if (taxoReader != null) taxoReader.close();
+    }
+
     return 1;
   }
 
Index: lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java	(date 1436204317000)
+++ lucene/analysis/stempel/src/java/org/egothor/stemmer/Compile.java	(revision )
@@ -117,7 +117,6 @@
     }
     
     for (int i = 1; i < args.length; i++) {
-      LineNumberReader in;
       // System.out.println("[" + args[i] + "]");
       Diff diff = new Diff();
       int stems = 0;
@@ -126,29 +125,31 @@
       allocTrie();
       
       System.out.println(args[i]);
-      in = new LineNumberReader(Files.newBufferedReader(Paths.get(args[i]), Charset.forName(charset)));
+
+      try (LineNumberReader in = new LineNumberReader(
+          Files.newBufferedReader(Paths.get(args[i]), Charset.forName(charset)))) {
-      for (String line = in.readLine(); line != null; line = in.readLine()) {
-        try {
-          line = line.toLowerCase(Locale.ROOT);
-          StringTokenizer st = new StringTokenizer(line);
-          String stem = st.nextToken();
-          if (storeorig) {
-            trie.add(stem, "-a");
-            words++;
-          }
-          while (st.hasMoreTokens()) {
-            String token = st.nextToken();
-            if (token.equals(stem) == false) {
-              trie.add(token, diff.exec(token, stem));
-              words++;
-            }
-          }
-        } catch (java.util.NoSuchElementException x) {
-          // no base token (stem) on a line
-        }
-      }
+        for (String line = in.readLine(); line != null; line = in.readLine()) {
+          try {
+            line = line.toLowerCase(Locale.ROOT);
+            StringTokenizer st = new StringTokenizer(line);
+            String stem = st.nextToken();
+            if (storeorig) {
+              trie.add(stem, "-a");
+              words++;
+            }
+            while (st.hasMoreTokens()) {
+              String token = st.nextToken();
+              if (token.equals(stem) == false) {
+                trie.add(token, diff.exec(token, stem));
+                words++;
+              }
+            }
+          } catch (java.util.NoSuchElementException x) {
+            // no base token (stem) on a line
+          }
+        }
-      in.close();
+      }
-      
+
       Optimizer o = new Optimizer();
       Optimizer2 o2 = new Optimizer2();
       Lift l = new Lift(true);
Index: lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java	(date 1436204317000)
+++ lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java	(revision )
@@ -149,24 +149,22 @@
 
   private void loadFromObjectInputStream(InputStream serialObjectInputStream)
       throws IOException, ClassNotFoundException {
-    ObjectInputStream input = new ObjectInputStream(serialObjectInputStream);
+    try (ObjectInputStream input = new ObjectInputStream(serialObjectInputStream)){
-    wordIndexTable = (short[]) input.readObject();
-    charIndexTable = (char[]) input.readObject();
-    wordItem_charArrayTable = (char[][][]) input.readObject();
-    wordItem_frequencyTable = (int[][]) input.readObject();
-    // log.info("load core dict from serialization.");
+      wordIndexTable = (short[]) input.readObject();
+      charIndexTable = (char[]) input.readObject();
+      wordItem_charArrayTable = (char[][][]) input.readObject();
+      wordItem_frequencyTable = (int[][]) input.readObject();
+      // log.info("load core dict from serialization.");
-    input.close();
-  }
+    }
+  }
 
   private void saveToObj(Path serialObj) {
-    try {
-      ObjectOutputStream output = new ObjectOutputStream(Files.newOutputStream(
-          serialObj));
+    try (ObjectOutputStream output = new ObjectOutputStream(Files.newOutputStream(
+        serialObj))) {
       output.writeObject(wordIndexTable);
       output.writeObject(charIndexTable);
       output.writeObject(wordItem_charArrayTable);
       output.writeObject(wordItem_frequencyTable);
-      output.close();
       // log.info("serialize core dict.");
     } catch (Exception e) {
       // log.warn(e.getMessage());
