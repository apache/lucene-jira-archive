diff --git a/lucene/core/src/java/org/apache/lucene/index/TermContext.java b/lucene/core/src/java/org/apache/lucene/index/TermContext.java
index 3ba8dd9d84..d87b9c7a2d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermContext.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermContext.java
@@ -21,6 +21,8 @@ import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
 import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
 
 /**
  * Maintains a {@link IndexReader} {@link TermState} view over
@@ -33,18 +35,23 @@ import java.util.Arrays;
  */
 public final class TermContext {
 
+  private static final TermState EMPTY_TERMSTATE = new TermState() {
+    @Override
+    public void copyFrom(TermState other) {
+
+    }
+  };
+
   // Important: do NOT keep hard references to index readers
   private final Object topReaderContextIdentity;
   private final TermState[] states;
+  private final Term term;  // null if stats are to be used
   private int docFreq;
   private long totalTermFreq;
 
   //public static boolean DEBUG = BlockTreeTermsWriter.DEBUG;
 
-  /**
-   * Creates an empty {@link TermContext} from a {@link IndexReaderContext}
-   */
-  public TermContext(IndexReaderContext context) {
+  private TermContext(Term term, IndexReaderContext context) {
     assert context != null && context.isTopLevel;
     topReaderContextIdentity = context.identity;
     docFreq = 0;
@@ -56,6 +63,14 @@ public final class TermContext {
       len = context.leaves().size();
     }
     states = new TermState[len];
+    this.term = term;
+  }
+
+  /**
+   * Creates an empty {@link TermContext} from a {@link IndexReaderContext}
+   */
+  public TermContext(IndexReaderContext context) {
+    this(null, context);
   }
 
   /**
@@ -72,7 +87,7 @@ public final class TermContext {
    * {@link IndexReader} pair.
    */
   public TermContext(IndexReaderContext context, TermState state, int ord, int docFreq, long totalTermFreq) {
-    this(context);
+    this(null, context);
     register(state, ord, docFreq, totalTermFreq);
   }
 
@@ -83,20 +98,20 @@ public final class TermContext {
    * using the leaf reader's ordinal.
    * <p>
    * Note: the given context must be a top-level context.
+   *
+   * @param needsStats if {@code true} then all leaf contexts will be visited up-front to
+   *                   collect term statistics.  Otherwise, the {@link TermState} objects
+   *                   will be built only when requested
    */
-  public static TermContext build(IndexReaderContext context, Term term)
+  public static TermContext build(IndexReaderContext context, Term term, boolean needsStats)
       throws IOException {
     assert context != null && context.isTopLevel;
-    final String field = term.field();
-    final BytesRef bytes = term.bytes();
-    final TermContext perReaderTermState = new TermContext(context);
-    //if (DEBUG) System.out.println("prts.build term=" + term);
-    for (final LeafReaderContext ctx : context.leaves()) {
-      //if (DEBUG) System.out.println("  r=" + leaves[i].reader);
-      final Terms terms = ctx.reader().terms(field);
-      if (terms != null) {
-        final TermsEnum termsEnum = terms.iterator();
-        if (termsEnum.seekExact(bytes)) { 
+    final TermContext perReaderTermState = new TermContext(needsStats ? null : term, context);
+    if (needsStats) {
+      for (final LeafReaderContext ctx : context.leaves()) {
+        //if (DEBUG) System.out.println("  r=" + leaves[i].reader);
+        TermsEnum termsEnum = loadTermsEnum(ctx, term);
+        if (termsEnum != null) {
           final TermState termState = termsEnum.termState();
           //if (DEBUG) System.out.println("    found");
           perReaderTermState.register(termState, ctx.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());
@@ -106,6 +121,17 @@ public final class TermContext {
     return perReaderTermState;
   }
 
+  private static TermsEnum loadTermsEnum(LeafReaderContext ctx, Term term) throws IOException {
+    final Terms terms = ctx.reader().terms(term.field());
+    if (terms != null) {
+      final TermsEnum termsEnum = terms.iterator();
+      if (termsEnum.seekExact(term.bytes())) {
+        return termsEnum;
+      }
+    }
+    return null;
+  }
+
   /**
    * Clears the {@link TermContext} internal state and removes all
    * registered {@link TermState}s
@@ -149,17 +175,25 @@ public final class TermContext {
   }
 
   /**
-   * Returns the {@link TermState} for an leaf ordinal or <code>null</code> if no
-   * {@link TermState} for the ordinal was registered.
+   * Returns the {@link TermState} for a leaf reader context or <code>null</code> if no
+   * {@link TermState} for the context was registered.
    * 
-   * @param ord
-   *          the readers leaf ordinal to get the {@link TermState} for.
+   * @param ctx
+   *          the {@link LeafReaderContext} to get the {@link TermState} for.
    * @return the {@link TermState} for the given readers ord or <code>null</code> if no
    *         {@link TermState} for the reader was registered
    */
-  public TermState get(int ord) {
-    assert ord >= 0 && ord < states.length;
-    return states[ord];
+  public TermState get(LeafReaderContext ctx) throws IOException {
+    assert ctx.ord >= 0 && ctx.ord < states.length;
+    if (term == null)
+      return states[ctx.ord];
+    if (this.states[ctx.ord] == null) {
+      TermsEnum te = loadTermsEnum(ctx, term);
+      this.states[ctx.ord] = te == null ? EMPTY_TERMSTATE : te.termState();
+    }
+    if (this.states[ctx.ord] == EMPTY_TERMSTATE)
+      return null;
+    return this.states[ctx.ord];
   }
 
   /**
@@ -169,6 +203,8 @@ public final class TermContext {
    *         instances passed to {@link #register(TermState, int, int, long)}.
    */
   public int docFreq() {
+    if (term != null)
+      throw new IllegalStateException("Cannot call docFreq() on lazily constructed TermContext");
     return docFreq;
   }
   
@@ -179,6 +215,8 @@ public final class TermContext {
    *         instances passed to {@link #register(TermState, int, int, long)}.
    */
   public long totalTermFreq() {
+    if (term != null)
+      throw new IllegalStateException("Cannot call totalTermFreq() on lazily constructed TermContext");
     return totalTermFreq;
   }
 
@@ -194,4 +232,5 @@ public final class TermContext {
 
     return sb.toString();
   }
+
 }
diff --git a/lucene/core/src/java/org/apache/lucene/search/BlendedTermQuery.java b/lucene/core/src/java/org/apache/lucene/search/BlendedTermQuery.java
index 219d453582..064fe0c96d 100644
--- a/lucene/core/src/java/org/apache/lucene/search/BlendedTermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/BlendedTermQuery.java
@@ -266,7 +266,7 @@ public final class BlendedTermQuery extends Query {
     final TermContext[] contexts = Arrays.copyOf(this.contexts, this.contexts.length);
     for (int i = 0; i < contexts.length; ++i) {
       if (contexts[i] == null || contexts[i].wasBuiltFor(reader.getContext()) == false) {
-        contexts[i] = TermContext.build(reader.getContext(), terms[i]);
+        contexts[i] = TermContext.build(reader.getContext(), terms[i], true);
       }
     }
 
@@ -295,7 +295,7 @@ public final class BlendedTermQuery extends Query {
   }
 
   private static TermContext adjustFrequencies(IndexReaderContext readerContext,
-      TermContext ctx, int artificialDf, long artificialTtf) {
+      TermContext ctx, int artificialDf, long artificialTtf) throws IOException {
     List<LeafReaderContext> leaves = readerContext.leaves();
     final int len;
     if (leaves == null) {
@@ -305,7 +305,7 @@ public final class BlendedTermQuery extends Query {
     }
     TermContext newCtx = new TermContext(readerContext);
     for (int i = 0; i < len; ++i) {
-      TermState termState = ctx.get(i);
+      TermState termState = ctx.get(leaves.get(i));
       if (termState == null) {
         continue;
       }
diff --git a/lucene/core/src/java/org/apache/lucene/search/LeafSimScorer.java b/lucene/core/src/java/org/apache/lucene/search/LeafSimScorer.java
index 52b7d929a8..46f9dc23dc 100644
--- a/lucene/core/src/java/org/apache/lucene/search/LeafSimScorer.java
+++ b/lucene/core/src/java/org/apache/lucene/search/LeafSimScorer.java
@@ -37,7 +37,7 @@ public final class LeafSimScorer {
   public LeafSimScorer(SimScorer scorer, LeafReader reader, boolean needsScores, float maxFreq) throws IOException {
     this.scorer = scorer;
     norms = needsScores ? reader.getNormValues(scorer.getField()) : null;
-    maxScore = scorer.maxScore(maxFreq);
+    maxScore = needsScores ? scorer.maxScore(maxFreq) : Integer.MAX_VALUE;
   }
 
   private long getNormValue(int doc) throws IOException {
diff --git a/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
index 941416e160..ee0c5fb8d4 100644
--- a/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
@@ -207,12 +207,14 @@ public class MultiPhraseQuery extends Query {
         for (Term term: terms) {
           TermContext termContext = termContexts.get(term);
           if (termContext == null) {
-            termContext = TermContext.build(context, term);
+            termContext = TermContext.build(context, term, scoreMode.needsScores());
             termContexts.put(term, termContext);
           }
-          TermStatistics termStatistics = searcher.termStatistics(term, termContext);
-          if (termStatistics != null) {
-            allTermStats.add(termStatistics);
+          if (scoreMode.needsScores()) {
+            TermStatistics termStatistics = searcher.termStatistics(term, termContext);
+            if (termStatistics != null) {
+              allTermStats.add(termStatistics);
+            }
           }
         }
       }
@@ -260,7 +262,7 @@ public class MultiPhraseQuery extends Query {
         List<PostingsEnum> postings = new ArrayList<>();
 
         for (Term term : terms) {
-          TermState termState = termContexts.get(term).get(context.ord);
+          TermState termState = termContexts.get(term).get(context);
           if (termState != null) {
             termsEnum.seekExact(term.bytes(), termState);
             postings.add(termsEnum.postings(null, PostingsEnum.POSITIONS));
diff --git a/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
index 295cc903b7..a3afa95b35 100644
--- a/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
@@ -372,10 +372,12 @@ public class PhraseQuery extends Query {
       int termUpTo = 0;
       for (int i = 0; i < terms.length; i++) {
         final Term term = terms[i];
-        states[i] = TermContext.build(context, term);
-        TermStatistics termStatistics = searcher.termStatistics(term, states[i]);
-        if (termStatistics != null) {
-          termStats[termUpTo++] = termStatistics;
+        states[i] = TermContext.build(context, term, scoreMode.needsScores());
+        if (scoreMode.needsScores()) {
+          TermStatistics termStatistics = searcher.termStatistics(term, states[i]);
+          if (termStatistics != null) {
+            termStats[termUpTo++] = termStatistics;
+          }
         }
       }
       if (termUpTo > 0) {
@@ -414,7 +416,7 @@ public class PhraseQuery extends Query {
       
       for (int i = 0; i < terms.length; i++) {
         final Term t = terms[i];
-        final TermState state = states[i].get(context.ord);
+        final TermState state = states[i].get(context);
         if (state == null) { /* term doesnt exist in this segment */
           assert termNotInReader(reader, t): "no termstate found but term exists in reader";
           return null;
diff --git a/lucene/core/src/java/org/apache/lucene/search/SynonymQuery.java b/lucene/core/src/java/org/apache/lucene/search/SynonymQuery.java
index 3f4c06dd51..26c4954f22 100644
--- a/lucene/core/src/java/org/apache/lucene/search/SynonymQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/SynonymQuery.java
@@ -137,7 +137,7 @@ public final class SynonymQuery extends Query {
       long totalTermFreq = 0;
       termContexts = new TermContext[terms.length];
       for (int i = 0; i < termContexts.length; i++) {
-        termContexts[i] = TermContext.build(searcher.getTopReaderContext(), terms[i]);
+        termContexts[i] = TermContext.build(searcher.getTopReaderContext(), terms[i], true);
         TermStatistics termStats = searcher.termStatistics(terms[i], termContexts[i]);
         if (termStats != null) {
           docFreq = Math.max(termStats.docFreq(), docFreq);
@@ -202,7 +202,7 @@ public final class SynonymQuery extends Query {
       List<Scorer> subScorers = new ArrayList<>();
       long totalMaxFreq = 0;
       for (int i = 0; i < terms.length; i++) {
-        TermState state = termContexts[i].get(context.ord);
+        TermState state = termContexts[i].get(context);
         if (state != null) {
           TermsEnum termsEnum = context.reader().terms(terms[i].field()).iterator();
           termsEnum.seekExact(terms[i].bytes(), state);
diff --git a/lucene/core/src/java/org/apache/lucene/search/TermQuery.java b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
index 3fa465d21f..f6c9dcdb10 100644
--- a/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java
@@ -125,30 +125,17 @@ public class TermQuery extends Query {
      * the term does not exist in the given context
      */
     private TermsEnum getTermsEnum(LeafReaderContext context) throws IOException {
-      if (termStates != null) {
-        // TermQuery either used as a Query or the term states have been provided at construction time
-        assert termStates.wasBuiltFor(ReaderUtil.getTopLevelContext(context)) : "The top-reader used to create Weight is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
-        final TermState state = termStates.get(context.ord);
-        if (state == null) { // term is not present in that reader
-          assert termNotInReader(context.reader(), term) : "no termstate found but term exists in reader term=" + term;
-          return null;
-        }
-        final TermsEnum termsEnum = context.reader().terms(term.field()).iterator();
-        termsEnum.seekExact(term.bytes(), state);
-        return termsEnum;
-      } else {
-        // TermQuery used as a filter, so the term states have not been built up front
-        Terms terms = context.reader().terms(term.field());
-        if (terms == null) {
-          return null;
-        }
-        final TermsEnum termsEnum = terms.iterator();
-        if (termsEnum.seekExact(term.bytes())) {
-          return termsEnum;
-        } else {
-          return null;
-        }
+      assert termStates != null;
+      assert termStates.wasBuiltFor(ReaderUtil.getTopLevelContext(context)) :
+          "The top-reader used to create Weight is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
+      final TermState state = termStates.get(context);
+      if (state == null) { // term is not present in that reader
+        assert termNotInReader(context.reader(), term) : "no termstate found but term exists in reader term=" + term;
+        return null;
       }
+      final TermsEnum termsEnum = context.reader().terms(term.field()).iterator();
+      termsEnum.seekExact(term.bytes(), state);
+      return termsEnum;
     }
 
     private boolean termNotInReader(LeafReader reader, Term term) throws IOException {
@@ -206,15 +193,7 @@ public class TermQuery extends Query {
     final TermContext termState;
     if (perReaderTermState == null
         || perReaderTermState.wasBuiltFor(context) == false) {
-      if (scoreMode.needsScores()) {
-        // make TermQuery single-pass if we don't have a PRTS or if the context
-        // differs!
-        termState = TermContext.build(context, term);
-      } else {
-        // do not compute the term state, this will help save seeks in the terms
-        // dict on segments that have a cache entry for this query
-        termState = null;
-      }
+      termState = TermContext.build(context, term, scoreMode.needsScores());
     } else {
       // PRTS was pre-build for this IS
       termState = this.perReaderTermState;
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
index 0d62f749fb..bb1a24c518 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
@@ -45,8 +45,8 @@ public final class SpanContainingQuery extends SpanContainQuery {
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
-    SpanWeight bigWeight = big.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
-    SpanWeight littleWeight = little.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
+    SpanWeight bigWeight = big.createWeight(searcher, scoreMode, boost);
+    SpanWeight littleWeight = little.createWeight(searcher, scoreMode, boost);
     return new SpanContainingWeight(searcher, scoreMode.needsScores() ? getTermContexts(bigWeight, littleWeight) : null,
                                       bigWeight, littleWeight, boost);
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
index 24a047fce5..fc1351e52a 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
@@ -181,7 +181,7 @@ public class SpanNearQuery extends SpanQuery implements Cloneable {
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
     List<SpanWeight> subWeights = new ArrayList<>();
     for (SpanQuery q : clauses) {
-      subWeights.add(q.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost));
+      subWeights.add(q.createWeight(searcher, scoreMode, boost));
     }
     return new SpanNearWeight(subWeights, searcher, scoreMode.needsScores() ? getTermContexts(subWeights) : null, boost);
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
index 5b97f8da17..9964d51d48 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
@@ -99,9 +99,9 @@ public final class SpanNotQuery extends SpanQuery {
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
-    SpanWeight includeWeight = include.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
+    SpanWeight includeWeight = include.createWeight(searcher, scoreMode, boost);
     SpanWeight excludeWeight = exclude.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
-    return new SpanNotWeight(searcher, scoreMode.needsScores() ? getTermContexts(includeWeight, excludeWeight) : null,
+    return new SpanNotWeight(searcher, scoreMode.needsScores() ? getTermContexts(includeWeight) : null,
                                   includeWeight, excludeWeight, boost);
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
index 2e15c92f29..b134f9fa79 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
@@ -119,7 +119,7 @@ public final class SpanOrQuery extends SpanQuery {
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
     List<SpanWeight> subWeights = new ArrayList<>(clauses.size());
     for (SpanQuery q : clauses) {
-      subWeights.add(q.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost));
+      subWeights.add(q.createWeight(searcher, scoreMode, boost));
     }
     return new SpanOrWeight(searcher, scoreMode.needsScores() ? getTermContexts(subWeights) : null, subWeights, boost);
   }
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
index f9b7697202..75884dab31 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
@@ -69,7 +69,7 @@ public abstract class SpanPositionCheckQuery extends SpanQuery implements Clonea
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
-    SpanWeight matchWeight = match.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
+    SpanWeight matchWeight = match.createWeight(searcher, scoreMode, boost);
     return new SpanPositionCheckWeight(matchWeight, searcher, scoreMode.needsScores() ? getTermContexts(matchWeight) : null, boost);
   }
 
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
index 9eea3aac17..47ad804ff9 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
@@ -69,7 +69,7 @@ public class SpanTermQuery extends SpanQuery {
     final TermContext context;
     final IndexReaderContext topContext = searcher.getTopReaderContext();
     if (termContext == null || termContext.wasBuiltFor(topContext) == false) {
-      context = TermContext.build(topContext, term);
+      context = TermContext.build(topContext, term, scoreMode.needsScores());
     }
     else {
       context = termContext;
@@ -107,7 +107,7 @@ public class SpanTermQuery extends SpanQuery {
 
       assert termContext.wasBuiltFor(ReaderUtil.getTopLevelContext(context)) : "The top-reader used to create Weight is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
 
-      final TermState state = termContext.get(context.ord);
+      final TermState state = termContext.get(context);
       if (state == null) { // term is not present in that reader
         assert context.reader().docFreq(term) == 0 : "no termstate found but term exists in reader term=" + term;
         return null;
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
index 9c618dd2e4..55e5717424 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
@@ -46,8 +46,8 @@ public final class SpanWithinQuery extends SpanContainQuery {
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
-    SpanWeight bigWeight = big.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
-    SpanWeight littleWeight = little.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
+    SpanWeight bigWeight = big.createWeight(searcher, scoreMode, boost);
+    SpanWeight littleWeight = little.createWeight(searcher, scoreMode, boost);
     return new SpanWithinWeight(searcher, scoreMode.needsScores() ? getTermContexts(bigWeight, littleWeight) : null,
                                       bigWeight, littleWeight, boost);
   }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
index 268e8fc944..7af2bf0d09 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
@@ -329,7 +329,7 @@ public class TestMinShouldMatch2 extends LuceneTestCase {
         if (ord >= 0) {
           boolean success = ords.add(ord);
           assert success; // no dups
-          TermContext context = TermContext.build(reader.getContext(), term);
+          TermContext context = TermContext.build(reader.getContext(), term, true);
           SimScorer w = weight.similarity.scorer(1f,
                         searcher.collectionStatistics("field"),
                         searcher.termStatistics(term, context));
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestTermQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestTermQuery.java
index f65c54eac0..d37a250d89 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestTermQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestTermQuery.java
@@ -49,7 +49,7 @@ public class TestTermQuery extends LuceneTestCase {
         new TermQuery(new Term("foo", "baz")));
     QueryUtils.checkEqual(
         new TermQuery(new Term("foo", "bar")),
-        new TermQuery(new Term("foo", "bar"), TermContext.build(new MultiReader().getContext(), new Term("foo", "bar"))));
+        new TermQuery(new Term("foo", "bar"), TermContext.build(new MultiReader().getContext(), new Term("foo", "bar"), true)));
   }
 
   public void testCreateWeightDoesNotSeekIfScoresAreNotNeeded() throws IOException {
@@ -84,7 +84,7 @@ public class TestTermQuery extends LuceneTestCase {
     searcher.search(query, collector);
     assertEquals(1, collector.getTotalHits());
     TermQuery queryWithContext = new TermQuery(new Term("foo", "bar"),
-        TermContext.build(reader.getContext(), new Term("foo", "bar")));
+        TermContext.build(reader.getContext(), new Term("foo", "bar"), true));
     collector = new TotalHitCountCollector();
     searcher.search(queryWithContext, collector);
     assertEquals(1, collector.getTotalHits());
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/payloads/SpanPayloadCheckQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/payloads/SpanPayloadCheckQuery.java
index 05d6682230..fa8eb53f9a 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/payloads/SpanPayloadCheckQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/payloads/SpanPayloadCheckQuery.java
@@ -64,7 +64,7 @@ public class SpanPayloadCheckQuery extends SpanQuery {
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {
-    SpanWeight matchWeight = match.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, boost);
+    SpanWeight matchWeight = match.createWeight(searcher, scoreMode, boost);
     return new SpanPayloadCheckWeight(searcher, scoreMode.needsScores() ? getTermContexts(matchWeight) : null, matchWeight, boost);
   }
 
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
index 92c8d59566..f9faae2e64 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
@@ -198,7 +198,7 @@ public class TermAutomatonQuery extends Query {
 
     for (Map.Entry<BytesRef,Integer> ent : termToID.entrySet()) {
       if (ent.getKey() != null) {
-        termStates.put(ent.getValue(), TermContext.build(context, new Term(field, ent.getKey())));
+        termStates.put(ent.getValue(), TermContext.build(context, new Term(field, ent.getKey()), scoreMode.needsScores()));
       }
     }
 
@@ -387,7 +387,7 @@ public class TermAutomatonQuery extends Query {
         TermContext termContext = ent.getValue();
         assert termContext.wasBuiltFor(ReaderUtil.getTopLevelContext(context)) : "The top-reader used to create Weight is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
         BytesRef term = idToTerm.get(ent.getKey());
-        TermState state = termContext.get(context.ord);
+        TermState state = termContext.get(context);
         if (state != null) {
           TermsEnum termsEnum = context.reader().terms(field).iterator();
           termsEnum.seekExact(term, state);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
index 2fdef99aa3..63a5895658 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java
@@ -186,7 +186,7 @@ public abstract class ShardSearchingTestBase extends LuceneTestCase {
     }
     try {
       for(Term term : terms) {
-        final TermContext termContext = TermContext.build(s.getIndexReader().getContext(), term);
+        final TermContext termContext = TermContext.build(s.getIndexReader().getContext(), term, true);
         stats.put(term, s.termStatistics(term, termContext));
       }
     } finally {
diff --git a/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java
index 01b0ef88fa..60565b1da3 100644
--- a/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java
@@ -286,10 +286,10 @@ public class GraphTermsQParserPlugin extends QParserPlugin {
           DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);
           for (int i=0; i<finalContexts.size(); i++) {
             TermContext termContext = finalContexts.get(i);
-            TermState termState = termContext.get(context.ord);
+            TermState termState = termContext.get(context);
             if(termState != null) {
               Term term = finalTerms.get(i);
-              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));
+              termsEnum.seekExact(term.bytes(), termContext.get(context));
               docs = termsEnum.postings(docs, PostingsEnum.NONE);
               builder.add(docs);
             }
diff --git a/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java b/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java
index 35b1b382e3..ae7ee1d0f1 100644
--- a/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java
+++ b/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java
@@ -162,7 +162,7 @@ public class ExactStatsCache extends StatsCache {
       HashMap<String,TermStats> statsMap = new HashMap<>();
       HashMap<String,CollectionStats> colMap = new HashMap<>();
       for (Term t : terms) {
-        TermContext termContext = TermContext.build(context, t);
+        TermContext termContext = TermContext.build(context, t, true);
 
         if (!colMap.containsKey(t.field())) { // collection stats for this field
           CollectionStatistics collectionStatistics = searcher.localCollectionStatistics(t.field());
