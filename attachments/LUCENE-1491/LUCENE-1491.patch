Index: contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
===================================================================
--- contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java	(revision 726742)
+++ contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java	(working copy)
@@ -117,19 +117,25 @@
   /** Returns the next token in the stream, or null at EOS. */
   public final Token next(final Token reusableToken) throws IOException {
     assert reusableToken != null;
-    if (ngrams.size() > 0) {
-      return (Token) ngrams.removeFirst();
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
     }
 
-    Token nextToken = input.next(reusableToken);
-    if (nextToken == null)
-      return null;
+    Token token = null;
 
-    ngram(nextToken);
-    if (ngrams.size() > 0)
-      return (Token) ngrams.removeFirst();
-    else
-      return null;
+    while (ngrams.isEmpty() && (token = input.next()) != null) {
+        ngram(token);
+    }
+
+    if (token == null) {
+        return null;
+    }
+
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
+    } else {
+        return null;
+    }
   }
 
   private void ngram(final Token token) {
Index: contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
===================================================================
--- contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java	(revision 726742)
+++ contrib/analyzers/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java	(working copy)
@@ -64,19 +64,25 @@
   /** Returns the next token in the stream, or null at EOS. */
   public final Token next(final Token reusableToken) throws IOException {
     assert reusableToken != null;
-    if (ngrams.size() > 0) {
-      return (Token) ngrams.removeFirst();
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
     }
 
-    Token nextToken = input.next(reusableToken);
-    if (nextToken == null)
-      return null;
+    Token token = null;
 
-    ngram(nextToken);
-    if (ngrams.size() > 0)
-      return (Token) ngrams.removeFirst();
-    else
-      return null;
+    while (ngrams.isEmpty() && (token = input.next()) != null) {
+        ngram(token);
+    }
+
+    if (token == null) {
+        return null;
+    }
+
+    if (!ngrams.isEmpty()) {
+        return (Token)ngrams.removeFirst();
+    } else {
+        return null;
+    }
   }
 
   private void ngram(Token token) { 
Index: contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java
===================================================================
--- contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java	(revision 726742)
+++ contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilterTest.java	(working copy)
@@ -109,4 +109,16 @@
     assertEquals("(cde,2,5)", nextToken.toString());
     assertNull(tokenizer.next(reusableToken));
   }
+  
+  public void testSmallTokenInStream() throws Exception {
+    input = new WhitespaceTokenizer(new StringReader("abc de fgh"));
+    EdgeNGramTokenFilter tokenizer = new EdgeNGramTokenFilter(input, EdgeNGramTokenFilter.Side.FRONT, 3, 3);
+    final Token reusableToken = new Token();
+    Token nextToken = tokenizer.next(reusableToken);
+    assertEquals("(abc,0,3)", nextToken.toString());
+    nextToken = tokenizer.next(reusableToken);
+    assertNotNull(nextToken);
+    assertEquals("(fgh,0,3)", nextToken.toString());
+    assertNull(tokenizer.next(reusableToken));
+  }
 }
Index: contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java
===================================================================
--- contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java	(revision 726742)
+++ contrib/analyzers/src/test/org/apache/lucene/analysis/ngram/NGramTokenFilterTest.java	(working copy)
@@ -120,4 +120,16 @@
 
         assertTrue(tokens.isEmpty());
     }
+    
+    public void testSmallTokenInStream() throws Exception {
+      input = new WhitespaceTokenizer(new StringReader("abc de fgh"));
+      NGramTokenFilter filter = new NGramTokenFilter(input, 3, 3);
+      final Token reusableToken = new Token();
+      Token nextToken = filter.next(reusableToken);
+      assertEquals("(abc,0,3)", nextToken.toString());
+      nextToken = filter.next(reusableToken);
+      assertNotNull(nextToken);
+      assertEquals("(fgh,0,3)", nextToken.toString());
+      assertNull(filter.next(reusableToken));
+    }
 }
