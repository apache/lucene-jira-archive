Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(révision 1467141)
+++ lucene/CHANGES.txt	(copie de travail)
@@ -275,6 +275,13 @@
   now succeed even if the directory contains a corrupted index (Billow
   Gao, Robert Muir, Mike McCandless)
 
+* LUCENE-4928: Stored fields and term vectors could become super slow in case
+  of tiny documents (a few bytes). This is especially problematic when switching
+  codecs since bulk-merge strategies can't be applied and the same chunk of
+  documents can end up being decompressed thousands of times. A hard limit on
+  the number of documents per chunk has been added to fix this issue.
+  (Robert Muir, Adrien Grand)
+
 Documentation
 
 * LUCENE-4841: Added example SimpleSortedSetFacetsExample to show how
Index: lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java	(révision 1467141)
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java	(copie de travail)
@@ -56,6 +56,9 @@
  */
 public final class CompressingTermVectorsWriter extends TermVectorsWriter {
 
+  // hard limit on the maximum number of documents per chunk
+  static final int MAX_DOCUMENTS_PER_CHUNK = 128;
+
   static final String VECTORS_EXTENSION = "tvd";
   static final String VECTORS_INDEX_EXTENSION = "tvx";
 
@@ -322,7 +325,8 @@
   }
 
   private boolean triggerFlush() {
-    return termSuffixes.length >= chunkSize || pendingDocs.size() >= chunkSize;
+    return termSuffixes.length >= chunkSize
+        || pendingDocs.size() >= MAX_DOCUMENTS_PER_CHUNK;
   }
 
   private void flush() throws IOException {
Index: lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java	(révision 1467141)
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java	(copie de travail)
@@ -53,6 +53,9 @@
  */
 public final class CompressingStoredFieldsWriter extends StoredFieldsWriter {
 
+  // hard limit on the maximum number of documents per chunk
+  static final int MAX_DOCUMENTS_PER_CHUNK = 128;
+
   static final int         STRING = 0x00;
   static final int       BYTE_ARR = 0x01;
   static final int    NUMERIC_INT = 0x02;
@@ -200,7 +203,7 @@
 
   private boolean triggerFlush() {
     return bufferedDocs.length >= chunkSize || // chunks of at least chunkSize bytes
-        numBufferedDocs >= chunkSize; // can be necessary if most docs are empty
+        numBufferedDocs >= MAX_DOCUMENTS_PER_CHUNK;
   }
 
   private void flush() throws IOException {
