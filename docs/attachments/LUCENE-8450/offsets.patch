diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
index 4fba9fe..286ef90 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
@@ -17,10 +17,10 @@
 package org.apache.lucene.analysis.charfilter;
 
 import org.apache.lucene.analysis.CharFilter;
-import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.analysis.CharOffsetArrays;
+import org.apache.lucene.analysis.CharOffsetMap;
 
 import java.io.Reader;
-import java.util.Arrays;
 
 /**
  * Base utility class for implementing a {@link CharFilter}.
@@ -30,10 +30,8 @@ import java.util.Arrays;
  */
 public abstract class BaseCharFilter extends CharFilter {
 
-  private int offsets[];
-  private int diffs[];
-  private int size = 0;
-  
+  private CharOffsetArrays charOffsetMap;
+
   public BaseCharFilter(Reader in) {
     super(in);
   }
@@ -41,22 +39,23 @@ public abstract class BaseCharFilter extends CharFilter {
   /** Retrieve the corrected offset. */
   @Override
   protected int correct(int currentOff) {
-    if (offsets == null) {
+    if (charOffsetMap == null) {
       return currentOff;
     }
+    return charOffsetMap.correctOffset(currentOff);
+  }
 
-    int index = Arrays.binarySearch(offsets, 0, size, currentOff);
-    if (index < -1) {
-      index = -2 - index;
+  /** Retrieve the corrected offset. */
+  @Override
+  protected int uncorrect(int currentOff) {
+    if (charOffsetMap == null) {
+      return currentOff;
     }
-
-    final int diff = index < 0 ? 0 : diffs[index];
-    return currentOff + diff;
+    return charOffsetMap.uncorrectOffset(currentOff);
   }
-  
+
   protected int getLastCumulativeDiff() {
-    return offsets == null ?
-      0 : diffs[size-1];
+    return charOffsetMap == null ? 0 : charOffsetMap.getLastCumulativeDiff();
   }
 
   /**
@@ -73,23 +72,9 @@ public abstract class BaseCharFilter extends CharFilter {
    *                       to the output offset
    */
   protected void addOffCorrectMap(int off, int cumulativeDiff) {
-    if (offsets == null) {
-      offsets = new int[64];
-      diffs = new int[64];
-    } else if (size == offsets.length) {
-      offsets = ArrayUtil.grow(offsets);
-      diffs = ArrayUtil.grow(diffs);
-    }
-    
-    assert (size == 0 || off >= offsets[size - 1])
-        : "Offset #" + size + "(" + off + ") is less than the last recorded offset "
-          + offsets[size - 1] + "\n" + Arrays.toString(offsets) + "\n" + Arrays.toString(diffs);
-    
-    if (size == 0 || off != offsets[size - 1]) {
-      offsets[size] = off;
-      diffs[size++] = cumulativeDiff;
-    } else { // Overwrite the diff at the last recorded offset
-      diffs[size - 1] = cumulativeDiff;
+    if (charOffsetMap == null) {
+      charOffsetMap = new CharOffsetArrays(null);
     }
+    charOffsetMap.add(off, cumulativeDiff);
   }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
index 8009c49..97bbbd6 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
@@ -61,4 +61,9 @@ public class PersianCharFilter extends CharFilter {
   protected int correct(int currentOff) {
     return currentOff; // we don't change the length of the string
   }
+
+  @Override
+  protected int uncorrect(int correctOff) {
+    return correctOff; // we don't change the length of the string
+  }
 }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
index 6cdff4b..6ead12d 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
@@ -126,6 +126,11 @@ public class TestBugInSomething extends BaseTokenStreamTestCase {
     }
 
     @Override
+    public int uncorrect(int correctOff) {
+      throw new UnsupportedOperationException("uncorrect(int)");
+    }
+
+    @Override
     public void close() {
       throw new UnsupportedOperationException("close()");
     }
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFilterCharOffset.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFilterCharOffset.java
new file mode 100644
index 0000000..aafd476
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFilterCharOffset.java
@@ -0,0 +1,208 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.core;
+
+
+import java.io.IOException;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.CharOffsetArrays;
+import org.apache.lucene.analysis.CharOffsetMap;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+
+
+public class TestFilterCharOffset extends BaseTokenStreamTestCase {
+
+  /**
+   * Verify that VowelDoublingTokenFilter does what it is supposed to
+   */
+  public void testAddAndRemoveChars() throws IOException {
+    StringReader reader = new StringReader("Ars-longa, Vita-brevis.");
+    final WhitespaceTokenizer input = new WhitespaceTokenizer(newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new CharacterManglingFilter(input, "aei", "A");
+    assertTokenStreamContents(stream, new String[]{"rs-longaa,", "Viitaa-breeviis."},
+        new int[]{0, 11}, new int[]{10, 23});
+  }
+
+  /**
+   * Verify that HyphenSplittingTokenFilter does what it is supposed to
+   */
+  public void testSplitTokens() throws IOException {
+    StringReader reader = new StringReader("Ars-longa, Vita-brevis.");
+    final WhitespaceTokenizer input = new WhitespaceTokenizer(newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new HyphenSplittingTokenFilter(input);
+    assertTokenStreamContents(stream, new String[]{"Ars", "longa,", "Vita", "brevis."},
+        new int[]{0, 4, 11, 16}, new int[]{3, 10, 15, 23});
+  }
+
+  /**
+   * Verify that the combination of character manipulations and token splitting preserves offsets correctly
+   */
+  public void testCorrectOffset() throws IOException {
+    StringReader reader = new StringReader("Ars-longa, Vita-brevis.");
+    final WhitespaceTokenizer input = new WhitespaceTokenizer(newAttributeFactory());
+    input.setReader(reader);
+    TokenStream stream = new HyphenSplittingTokenFilter(new CharacterManglingFilter(input, "aei", "A"));
+    assertTokenStreamContents(stream, new String[]{"rs", "longaa,", "Viitaa", "breeviis."},
+        new int[]{0, 4, 11, 16}, new int[]{3, 10, 15, 23});
+  }
+
+  public void testRandomData() throws IOException {
+    checkRandomData(random(), new TestAnalyzer(), 100);
+  }
+
+  final class TestAnalyzer extends Analyzer {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      WhitespaceTokenizer tokenizer = new WhitespaceTokenizer();
+      return new TokenStreamComponents(tokenizer, new HyphenSplittingTokenFilter(new CharacterManglingFilter(tokenizer)));
+    }
+  }
+
+  final class HyphenSplittingTokenFilter extends TokenFilter {
+    private final CharTermAttribute term = addAttribute(CharTermAttribute.class);
+    private final OffsetAttribute offset = addAttribute(OffsetAttribute.class);
+    private State pending;
+
+    HyphenSplittingTokenFilter(TokenStream input) {
+      super(input);
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      if (pending != null) {
+        restoreState(pending);
+        pending = null;
+      } else if (!input.incrementToken()) {
+        return false;
+      }
+      int hyphenOffset = -1;
+      for (int i = 0; i < term.length(); i++) {
+        if (term.charAt(i) == '-') {
+          hyphenOffset = i;
+          break;
+        }
+      }
+      if (hyphenOffset > 0) {
+        int startOffset = offset.startOffset();
+        int endOffset = offset.endOffset();
+        // get offset with deltas from prior filters applied
+        CharOffsetMap charOffsetMap = getCharOffsetMap();
+        int currentStartOffset = charOffsetMap.uncorrectOffset(startOffset);
+        String lhs = new String(term.buffer(), 0, hyphenOffset);
+        term.copyBuffer(term.buffer(), hyphenOffset + 1, term.length() - hyphenOffset - 1);
+        offset.setOffset(charOffsetMap.correctOffset(currentStartOffset + hyphenOffset + 1), endOffset);
+        pending = captureState();
+        term.setEmpty();
+        term.append(lhs);
+        offset.setOffset(startOffset, charOffsetMap.correctOffset(currentStartOffset + hyphenOffset));
+      }
+      return true;
+    }
+  }
+
+  final class CharacterManglingFilter extends TokenFilter {
+
+    private final CharTermAttribute term = addAttribute(CharTermAttribute.class);
+    private final OffsetAttribute offset = addAttribute(OffsetAttribute.class);
+    private final String charsToDouble;
+    private final String charsToRemove;
+    private final int removeRemainder;
+    private final int doubleRemainder;
+
+    // double and remove the specified characters
+    CharacterManglingFilter(TokenStream input, String charsToDouble, String charsToRemove) {
+      super(input);
+      this.charsToDouble = charsToDouble;
+      this.charsToRemove = charsToRemove;
+      charOffsetMap = new CharOffsetArrays(input.getCharOffsetMap());
+      removeRemainder = random().nextInt(10);
+      doubleRemainder = removeRemainder + random().nextInt(8) + 1;
+    }
+
+    // double and remove the characters at random
+    CharacterManglingFilter(TokenStream input) {
+      this(input, null, null);
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      if (!input.incrementToken()) {
+        return false;
+      }
+      StringBuilder buf = new StringBuilder();
+      char[] termChars = term.buffer();
+      int start = offset.startOffset();
+      int cumDelta = 0;
+      for (int i = 0; i < term.length(); i++) {
+        char c = termChars[i];
+        int delta = 0;
+        if (shouldDoubleChar(c)) {
+          buf.append(c).append(c);
+          delta += -1;
+        } else if (shouldRemoveChar(c)) {
+          delta += 1;
+        } else {
+          buf.append(c);
+        }
+        if (delta != 0) {
+          cumDelta += delta;
+          ((CharOffsetArrays) charOffsetMap).add(start + i, cumDelta);
+        }
+      }
+      term.setEmpty();
+      term.append(buf);
+      return true;
+    }
+
+    private boolean shouldRemoveChar(char c) {
+      if (charsToRemove != null) {
+        return charsToRemove.indexOf(c) >= 0;
+      } else {
+        return c % 10 == removeRemainder;
+      }
+    }
+
+    private boolean shouldDoubleChar(char c) {
+      if (charsToDouble != null) {
+        return charsToDouble.indexOf(c) >= 0;
+      } else {
+        return c % 10 == doubleRemainder;
+      }
+    }
+
+    @Override
+    public void reset() throws IOException {
+      super.reset();
+      ((CharOffsetArrays) charOffsetMap).clear();
+    }
+  }
+
+  // print debug info depending on VERBOSE
+  private static void log(String s) {
+    if (VERBOSE) {
+      System.out.println(s);
+    }
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
index 557a69e..a6f4ca7 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
@@ -792,6 +792,11 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
     }
 
     @Override
+    public int uncorrect(int correctOff) {
+      return correctOff; // we don't change any offsets
+    }
+
+    @Override
     public int read(char[] cbuf, int off, int len) throws IOException {
       readSomething = true;
       return input.read(cbuf, off, len);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer.java
index 5c36e82..ef6f939 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer.java
@@ -365,6 +365,11 @@ public class TestCustomAnalyzer extends BaseTokenStreamTestCase {
     }
 
     @Override
+    protected int uncorrect(int correctOff) {
+      return correctOff;
+    }
+
+    @Override
     public int read(char[] cbuf, int off, int len) throws IOException {
       final int read = input.read(cbuf, off, len);
       for (int i = 0; i < read; ++i) {
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
index 7e1d7a1..32fc909 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
@@ -453,4 +453,9 @@ public class JapaneseIterationMarkCharFilter extends CharFilter {
   protected int correct(int currentOff) {
     return currentOff; // this filter doesn't change the length of strings
   }
+
+  @Override
+  protected int uncorrect(int correctOff) {
+    return correctOff; // this filter doesn't change the length of strings
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
index 0a3fcae..fdf6a02 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
@@ -38,7 +38,7 @@ import java.io.Reader;
  * {@link org.apache.lucene.analysis Analysis package documentation}.
  */
 // the way java.io.FilterReader should work!
-public abstract class CharFilter extends Reader {
+public abstract class CharFilter extends Reader implements CharOffsetMap {
   /** 
    * The underlying character-input stream. 
    */
@@ -81,4 +81,21 @@ public abstract class CharFilter extends Reader {
     final int corrected = correct(currentOff);
     return (input instanceof CharFilter) ? ((CharFilter) input).correctOffset(corrected) : corrected;
   }
+
+  /**
+   * Subclasses override to map the original offset into the current filter's (uncorrected) coordinates.
+   *
+   * @param correctOff correct offset
+   * @return uncorrected offset
+   */
+  protected abstract int uncorrect(int correctOff);
+
+  /**
+   * Chains the corrected offset through the input
+   * CharFilter(s).
+   */
+  public final int uncorrectOffset(int correctOff) {
+    final int uncorrected = uncorrect(correctOff);
+    return (input instanceof CharFilter) ? ((CharFilter) input).correctOffset(uncorrected) : uncorrected;
+  }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetArrays.java b/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetArrays.java
new file mode 100644
index 0000000..ace53b2
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetArrays.java
@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis;
+
+import java.util.Arrays;
+
+import org.apache.lucene.util.ArrayUtil;
+
+public class CharOffsetArrays implements CharOffsetMap {
+  private final CharOffsetMap priorMap;
+
+  private int offsets[] = new int[64];
+  private int corrected[] = new int[64];
+  private int size = 0;
+
+  public CharOffsetArrays(CharOffsetMap priorMap) {
+    this.priorMap = priorMap;
+  }
+
+  public int correctOffset(int currentOff) {
+    if (priorMap != null) {
+      return priorMap.correctOffset(correct(currentOff));
+    } else {
+      return correct(currentOff);
+    }
+  }
+
+  public int uncorrectOffset(int currentOff) {
+    if (priorMap != null) {
+      return uncorrect(priorMap.uncorrectOffset(currentOff));
+    } else {
+      return uncorrect(currentOff);
+    }
+  }
+
+  private int correct(int currentOff) {
+    int index = Arrays.binarySearch(offsets, 0, size, currentOff);
+    if (index == -1) {
+      return currentOff;
+    } else if (index >= 0) {
+      return corrected[index];
+    } else {
+      index = -2 - index;
+      return currentOff + corrected[index] - offsets[index];
+    }
+  }
+
+  private int uncorrect(int correctOffset) {
+    int index = Arrays.binarySearch(corrected, 0, size, correctOffset);
+    if (index == -1) {
+      return 0;
+    } else if (index >= 0) {
+      return offsets[index];
+    } else {
+      index = -2 - index;
+      return correctOffset + offsets[index] - corrected[index];
+    }
+  }
+
+ public int getLastCumulativeDiff() {
+    if (size > 0) {
+      return corrected[size - 1] - offsets[size - 1];
+    } else {
+      return 0;
+    }
+  }
+
+  public void add(int off, int cumulativeDiff) {
+    if (size == offsets.length) {
+      offsets = ArrayUtil.grow(offsets);
+      corrected = ArrayUtil.grow(corrected);
+    }
+
+    assert (size == 0 || off >= offsets[size - 1])
+        : "Offset #" + size + "(" + off + ") is less than the last recorded offset "
+        + offsets[size - 1] + "\n" + Arrays.toString(offsets) + "\n" + Arrays.toString(corrected);
+
+    if (size == 0 || off != offsets[size - 1]) {
+      offsets[size] = off;
+      corrected[size++] = off + cumulativeDiff;
+    } else { // Overwrite the diff at the last recorded offset
+      corrected[size - 1] = offsets[size - 1] + cumulativeDiff;
+    }
+  }
+
+  public void clear() {
+    size = 0;
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetMap.java b/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetMap.java
new file mode 100644
index 0000000..c97730e
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/CharOffsetMap.java
@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis;
+
+public interface CharOffsetMap {
+
+    CharOffsetMap IDENTITY = new CharOffsetMap() {
+        @Override
+        public int correctOffset(int currentOff) {
+            return currentOff;
+        }
+
+        @Override
+        public int uncorrectOffset(int currentOff) {
+            return currentOff;
+        }
+    };
+
+    int correctOffset(int currentOff);
+
+    int uncorrectOffset(int currentOff);
+
+}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
index c097c26..e388475 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/TokenFilter.java
@@ -69,4 +69,13 @@ public abstract class TokenFilter extends TokenStream {
   public void reset() throws IOException {
     input.reset();
   }
+
+  @Override
+  public CharOffsetMap getCharOffsetMap() {
+    if (charOffsetMap != null) {
+      return charOffsetMap;
+    }
+    return input.getCharOffsetMap();
+  }
+
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/TokenStream.java b/lucene/core/src/java/org/apache/lucene/analysis/TokenStream.java
index a19d31d..002b4ca 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/TokenStream.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/TokenStream.java
@@ -85,6 +85,8 @@ public abstract class TokenStream extends AttributeSource implements Closeable {
   public static final AttributeFactory DEFAULT_TOKEN_ATTRIBUTE_FACTORY =
     AttributeFactory.getStaticImplementation(AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY, PackedTokenAttributeImpl.class);
 
+  protected CharOffsetMap charOffsetMap;
+
   /**
    * A TokenStream using the default attribute factory.
    */
@@ -194,5 +196,9 @@ public abstract class TokenStream extends AttributeSource implements Closeable {
    */
   @Override
   public void close() throws IOException {}
-  
+
+  public CharOffsetMap getCharOffsetMap() {
+    return charOffsetMap;
+  }
+
 }
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
index 33f972a..889473d 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
@@ -77,7 +77,22 @@ public abstract class Tokenizer extends TokenStream {
    * @see CharFilter#correctOffset
    */
   protected final int correctOffset(int currentOff) {
-    return (input instanceof CharFilter) ? ((CharFilter) input).correctOffset(currentOff) : currentOff;
+    CharOffsetMap charOffsets = getCharOffsetMap();
+    if (charOffsets != null) {
+      return charOffsets.correctOffset(currentOff);
+    }
+    return currentOff;
+  }
+
+  @Override
+  public CharOffsetMap getCharOffsetMap() {
+    if (charOffsetMap != null) {
+      return charOffsetMap;
+    }
+    if (input instanceof CharFilter) {
+      return (CharFilter) input;
+    }
+    return CharOffsetMap.IDENTITY;
   }
 
   /** Expert: Set a new reader on the Tokenizer.  Typically, an
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java
index 0aa19a7..d4d0d29 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java
@@ -60,6 +60,11 @@ public class TestCharFilter extends LuceneTestCase {
     protected int correct(int currentOff) {
       return currentOff + 1;
     }
+
+    @Override
+    protected int uncorrect(int currentOff) {
+      return currentOff - 1;
+    }
   }
 
   static class CharFilter2 extends CharFilter {
@@ -77,5 +82,10 @@ public class TestCharFilter extends LuceneTestCase {
     protected int correct(int currentOff) {
       return currentOff + 2;
     }
+
+    @Override
+    protected int uncorrect(int currentOff) {
+      return currentOff - 2;
+    }
   }
 }
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestDelegatingAnalyzerWrapper.java b/lucene/core/src/test/org/apache/lucene/analysis/TestDelegatingAnalyzerWrapper.java
index 1d6cf15..ad142de 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestDelegatingAnalyzerWrapper.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestDelegatingAnalyzerWrapper.java
@@ -93,6 +93,11 @@ public class TestDelegatingAnalyzerWrapper extends LuceneTestCase {
     }
 
     @Override
+    protected int uncorrect(int correctOff) {
+      return correctOff;
+    }
+
+    @Override
     public int read(char[] cbuf, int off, int len) throws IOException {
       final int read = input.read(cbuf, off, len);
       for (int i = 0; i < read; ++i) {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
index c9bb2f2..1c1bd1e 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
@@ -93,10 +93,25 @@ public class MockCharFilter extends CharFilter {
     assert ret >= 0 : "currentOff=" + currentOff + ",diff=" + (ret-currentOff);
     return ret;
   }
-  
+
+  @Override
+  public int uncorrect(int correctOff) {
+    Map.Entry<Integer, Integer> lastEntry = uncorrections.lowerEntry(correctOff + 1);
+    int ret = lastEntry == null ? correctOff : correctOff + lastEntry.getValue();
+    Map.Entry<Integer, Integer> nextEntry = uncorrections.higherEntry(ret);
+    if (nextEntry != null) {
+      // clip so as not to overlap next entry
+      ret = Math.min(ret, nextEntry.getValue() - 1);
+    }
+    assert ret >= 0 : "correctOff=" + correctOff + ",diff=" + (ret-correctOff);
+    return ret;
+  }
+
   protected void addOffCorrectMap(int off, int cumulativeDiff) {
     corrections.put(off, cumulativeDiff);
+    uncorrections.put(off + cumulativeDiff, -cumulativeDiff);
   }
   
   TreeMap<Integer,Integer> corrections = new TreeMap<>();
+  TreeMap<Integer,Integer> uncorrections = new TreeMap<>();
 }
