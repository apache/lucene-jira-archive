Index: src/java/org/apache/lucene/analysis/SimpleAnalyzer.java
===================================================================
--- src/java/org/apache/lucene/analysis/SimpleAnalyzer.java	(revision 904406)
+++ src/java/org/apache/lucene/analysis/SimpleAnalyzer.java	(working copy)
@@ -19,14 +19,42 @@
 
 import java.io.Reader;
 
-/** An {@link Analyzer} that filters {@link LetterTokenizer} 
- *  with {@link LowerCaseFilter} */
+import org.apache.lucene.util.Version;
 
+/** An {@link Analyzer} that filters {@link LetterTokenizer} 
+ *  with {@link LowerCaseFilter} 
+ * <p>
+ * <a name="version">You must specify the required {@link Version} compatibility
+ * when creating {@link CharTokenizer}:
+ * <ul>
+ * <li>As of 3.1, {@link LowerCaseTokenizer} uses an int based API to normalize and
+ * detect token codepoints. See {@link CharTokenizer#isTokenChar(int)} and
+ * {@link CharTokenizer#normalize(int)} for details.</li>
+ * </ul>
+ * <p>
+ **/
 public final class SimpleAnalyzer extends ReusableAnalyzerBase {
 
+  private final Version matchVersion;
+  
+  /**
+   * Creates a new {@link SimpleAnalyzer}
+   * @param matchVersion Lucene version to match See {@link <a href="#version">above</a>}
+   */
+  public SimpleAnalyzer(Version matchVersion) {
+    this.matchVersion = matchVersion;
+  }
+  
+  /**
+   * Creates a new {@link SimpleAnalyzer}
+   * @deprecated use {@link #SimpleAnalyzer(Version)} instead 
+   */
+  @Deprecated  public SimpleAnalyzer() {
+    this(Version.LUCENE_30);
+  }
   @Override
   protected TokenStreamComponents createComponents(final String fieldName,
       final Reader reader) {
-    return new TokenStreamComponents(new LowerCaseTokenizer(reader));
+    return new TokenStreamComponents(new LowerCaseTokenizer(matchVersion, reader));
   }
 }
Index: src/java/org/apache/lucene/analysis/StopAnalyzer.java
===================================================================
--- src/java/org/apache/lucene/analysis/StopAnalyzer.java	(revision 904406)
+++ src/java/org/apache/lucene/analysis/StopAnalyzer.java	(working copy)
@@ -99,7 +99,7 @@
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
       Reader reader) {
-    final Tokenizer source = new LowerCaseTokenizer(reader);
+    final Tokenizer source = new LowerCaseTokenizer(matchVersion, reader);
     return new TokenStreamComponents(source, new StopFilter(matchVersion,
           source, stopwords));
   }
Index: src/java/org/apache/lucene/analysis/WhitespaceAnalyzer.java
===================================================================
--- src/java/org/apache/lucene/analysis/WhitespaceAnalyzer.java	(revision 904406)
+++ src/java/org/apache/lucene/analysis/WhitespaceAnalyzer.java	(working copy)
@@ -19,13 +19,44 @@
 
 import java.io.Reader;
 
-/** An Analyzer that uses {@link WhitespaceTokenizer}. */
+import org.apache.lucene.util.Version;
 
+/**
+ * An Analyzer that uses {@link WhitespaceTokenizer}.
+ * <p>
+ * <a name="version">You must specify the required {@link Version} compatibility
+ * when creating {@link CharTokenizer}:
+ * <ul>
+ * <li>As of 3.1, {@link WhitespaceTokenizer} uses an int based API to normalize and
+ * detect token codepoints. See {@link CharTokenizer#isTokenChar(int)} and
+ * {@link CharTokenizer#normalize(int)} for details.</li>
+ * </ul>
+ * <p>
+ **/
 public final class WhitespaceAnalyzer extends ReusableAnalyzerBase {
-
+  
+  private final Version matchVersion;
+  
+  /**
+   * Creates a new {@link WhitespaceAnalyzer}
+   * @param matchVersion Lucene version to match See {@link <a href="#version">above</a>}
+   */
+  public WhitespaceAnalyzer(Version matchVersion) {
+    this.matchVersion = matchVersion;
+  }
+  
+  /**
+   * Creates a new {@link WhitespaceAnalyzer}
+   * @deprecated use {@link #WhitespaceAnalyzer(Version)} instead 
+   */
+  @Deprecated
+  public WhitespaceAnalyzer() {
+    this(Version.LUCENE_30);
+  }
+  
   @Override
   protected TokenStreamComponents createComponents(final String fieldName,
       final Reader reader) {
-    return new TokenStreamComponents(new WhitespaceTokenizer(reader));
+    return new TokenStreamComponents(new WhitespaceTokenizer(matchVersion, reader));
   }
 }
