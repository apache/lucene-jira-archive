Index: contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java
===================================================================
--- contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java	(revision 619410)
+++ contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java	(working copy)
@@ -239,6 +239,29 @@
     assertTrue("token is not null and it should be", token == null);
   }
 
+  public void testQuotedChars() throws Exception {
+    String test = "''I''talics '''b'''old '''''B'''''old''I''talics regular";
+    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));
+    Token token = new Token();
+    token = tf.next(token);
+    assertTrue("token is null and it shouldn't be", token != null);
+    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + " is not equal to " + "Italics",
+            new String(token.termBuffer(), 0, token.termLength()).equals("Italics") == true);
+    assertTrue(token.type() + " is not equal to " + WikipediaTokenizer.ITALICS, token.type().equals(WikipediaTokenizer.ITALICS) == true);
+
+    token = tf.next(token);
+    assertTrue("token is null and it shouldn't be", token != null);
+    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + " is not equal to " + "Bold",
+            new String(token.termBuffer(), 0, token.termLength()).equals("Bold") == true);
+    assertTrue(token.type() + " is not equal to " + WikipediaTokenizer.BOLD, token.type().equals(WikipediaTokenizer.BOLD) == true);
+
+    token = tf.next(token);
+    assertTrue("token is null and it shouldn't be", token != null);
+    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + " is not equal to " + "BoldItalics",
+            new String(token.termBuffer(), 0, token.termLength()).equals("BoldItalics") == true);
+    assertTrue(token.type() + " is not equal to " + WikipediaTokenizer.BOLD_ITALICS, token.type().equals(WikipediaTokenizer.BOLD_ITALICS) == true);
+  }
+
   public void testLinks() throws Exception {
     String test = "[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]";
     WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));
