Index: lucene/core/src/java/org/apache/lucene/codecs/Codec.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/Codec.java	(revision 1681411)
+++ lucene/core/src/java/org/apache/lucene/codecs/Codec.java	(working copy)
@@ -122,7 +122,7 @@
     loader.reload(classloader);
   }
   
-  private static Codec defaultCodec = Codec.forName("Lucene50");
+  private static Codec defaultCodec = Codec.forName("Lucene53");
   
   /** expert: returns the default codec used for newly created
    *  {@link IndexWriterConfig}s.
Index: lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java	(revision 1681411)
+++ lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java	(working copy)
@@ -53,7 +53,6 @@
   private int numberOfLevelsToBuffer = 1;
   
   private int docCount;
-  private boolean haveSkipped;
 
   /** skipStream for each level. */
   private IndexInput[] skipStream;
@@ -120,12 +119,7 @@
    *  greater than or equal to <i>target</i>. Returns the current doc count. 
    */
   public int skipTo(int target) throws IOException {
-    if (!haveSkipped) {
-      // first time, load skip levels
-      loadSkipLevels();
-      haveSkipped = true;
-    }
-  
+
     // walk up the levels until highest level is found that has a skip
     // for this target
     int level = 0;
@@ -196,7 +190,7 @@
   }
 
   /** Initializes the reader, for reuse on a new term. */
-  public void init(long skipPointer, int df) {
+  public void init(long skipPointer, int df) throws IOException {
     this.skipPointer[0] = skipPointer;
     this.docCount = df;
     assert skipPointer >= 0 && skipPointer <= skipStream[0].length() 
@@ -205,10 +199,10 @@
     Arrays.fill(numSkipped, 0);
     Arrays.fill(childPointer, 0);
     
-    haveSkipped = false;
     for (int i = 1; i < numberOfSkipLevels; i++) {
       skipStream[i] = null;
     }
+    loadSkipLevels();
   }
   
   /** Loads the skip levels  */
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java	(revision 1681411)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java	(working copy)
@@ -414,7 +414,6 @@
           // Lazy init: first time this enum has ever been used for skipping
           skipper = new Lucene50SkipReader(docIn.clone(),
                                            MAX_SKIP_LEVELS,
-                                           BLOCK_SIZE,
                                            indexHasPos,
                                            indexHasOffsets,
                                            indexHasPayloads);
@@ -692,7 +691,6 @@
           // Lazy init: first time this enum has ever been used for skipping
           skipper = new Lucene50SkipReader(docIn.clone(),
                                            MAX_SKIP_LEVELS,
-                                           BLOCK_SIZE,
                                            true,
                                            indexHasOffsets,
                                            indexHasPayloads);
@@ -1121,7 +1119,6 @@
           // Lazy init: first time this enum has ever been used for skipping
           skipper = new Lucene50SkipReader(docIn.clone(),
                                         MAX_SKIP_LEVELS,
-                                        BLOCK_SIZE,
                                         true,
                                         indexHasOffsets,
                                         indexHasPayloads);
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50SkipReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50SkipReader.java	(revision 1681411)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50SkipReader.java	(working copy)
@@ -23,6 +23,8 @@
 import org.apache.lucene.codecs.MultiLevelSkipListReader;
 import org.apache.lucene.store.IndexInput;
 
+import static org.apache.lucene.codecs.lucene50.Lucene50PostingsFormat.BLOCK_SIZE;
+
 /**
  * Implements the skip list reader for block postings format
  * that stores positions and payloads.
@@ -51,8 +53,6 @@
  *
  */
 final class Lucene50SkipReader extends MultiLevelSkipListReader {
-  private final int blockSize;
-
   private long docPointer[];
   private long posPointer[];
   private long payPointer[];
@@ -65,9 +65,8 @@
   private long lastDocPointer;
   private int lastPosBufferUpto;
 
-  public Lucene50SkipReader(IndexInput skipStream, int maxSkipLevels, int blockSize, boolean hasPos, boolean hasOffsets, boolean hasPayloads) {
-    super(skipStream, maxSkipLevels, blockSize, 8);
-    this.blockSize = blockSize;
+  public Lucene50SkipReader(IndexInput skipStream, int maxSkipLevels, boolean hasPos, boolean hasOffsets, boolean hasPayloads) {
+    super(skipStream, maxSkipLevels, BLOCK_SIZE, 8);
     docPointer = new long[maxSkipLevels];
     if (hasPos) {
       posPointer = new long[maxSkipLevels];
@@ -97,10 +96,10 @@
    *
    */
   protected int trim(int df) {
-    return df % blockSize == 0? df - 1: df;
+    return df % BLOCK_SIZE == 0? df - 1: df;
   }
 
-  public void init(long skipPointer, long docBasePointer, long posBasePointer, long payBasePointer, int df) {
+  public void init(long skipPointer, long docBasePointer, long posBasePointer, long payBasePointer, int df) throws IOException {
     super.init(skipPointer, trim(df));
     lastDocPointer = docBasePointer;
     lastPosPointer = posBasePointer;
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53Codec.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53Codec.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53Codec.java	(working copy)
@@ -0,0 +1,169 @@
+package org.apache.lucene.codecs.lucene53;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Objects;
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.codecs.CompoundFormat;
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.FieldInfosFormat;
+import org.apache.lucene.codecs.FilterCodec;
+import org.apache.lucene.codecs.LiveDocsFormat;
+import org.apache.lucene.codecs.NormsFormat;
+import org.apache.lucene.codecs.PostingsFormat;
+import org.apache.lucene.codecs.SegmentInfoFormat;
+import org.apache.lucene.codecs.StoredFieldsFormat;
+import org.apache.lucene.codecs.TermVectorsFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50FieldInfosFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50LiveDocsFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50SegmentInfoFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50StoredFieldsFormat;
+import org.apache.lucene.codecs.lucene50.Lucene50StoredFieldsFormat.Mode;
+import org.apache.lucene.codecs.lucene50.Lucene50TermVectorsFormat;
+import org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat;
+import org.apache.lucene.codecs.perfield.PerFieldPostingsFormat;
+
+/**
+ * Implements the Lucene 5.3 index format, with configurable per-field postings
+ * and docvalues formats.
+ * <p>
+ * If you want to reuse functionality of this codec in another codec, extend
+ * {@link FilterCodec}.
+ *
+ * @see org.apache.lucene.codecs.lucene50 package documentation for file format details.
+ * @lucene.experimental
+ */
+public class Lucene53Codec extends Codec {
+  private final TermVectorsFormat vectorsFormat = new Lucene50TermVectorsFormat();
+  private final FieldInfosFormat fieldInfosFormat = new Lucene50FieldInfosFormat();
+  private final SegmentInfoFormat segmentInfosFormat = new Lucene50SegmentInfoFormat();
+  private final LiveDocsFormat liveDocsFormat = new Lucene50LiveDocsFormat();
+  private final CompoundFormat compoundFormat = new Lucene50CompoundFormat();
+  
+  private final PostingsFormat postingsFormat = new PerFieldPostingsFormat() {
+    @Override
+    public PostingsFormat getPostingsFormatForField(String field) {
+      return Lucene53Codec.this.getPostingsFormatForField(field);
+    }
+  };
+  
+  private final DocValuesFormat docValuesFormat = new PerFieldDocValuesFormat() {
+    @Override
+    public DocValuesFormat getDocValuesFormatForField(String field) {
+      return Lucene53Codec.this.getDocValuesFormatForField(field);
+    }
+  };
+  
+  private final StoredFieldsFormat storedFieldsFormat;
+
+  /** 
+   * Instantiates a new codec.
+   */
+  public Lucene53Codec() {
+    this(Mode.BEST_SPEED);
+  }
+  
+  /** 
+   * Instantiates a new codec, specifying the stored fields compression
+   * mode to use.
+   * @param mode stored fields compression mode to use for newly 
+   *             flushed/merged segments.
+   */
+  public Lucene53Codec(Mode mode) {
+    super("Lucene53");
+    this.storedFieldsFormat = new Lucene50StoredFieldsFormat(Objects.requireNonNull(mode));
+  }
+  
+  @Override
+  public final StoredFieldsFormat storedFieldsFormat() {
+    return storedFieldsFormat;
+  }
+  
+  @Override
+  public final TermVectorsFormat termVectorsFormat() {
+    return vectorsFormat;
+  }
+
+  @Override
+  public final PostingsFormat postingsFormat() {
+    return postingsFormat;
+  }
+  
+  @Override
+  public final FieldInfosFormat fieldInfosFormat() {
+    return fieldInfosFormat;
+  }
+  
+  @Override
+  public final SegmentInfoFormat segmentInfoFormat() {
+    return segmentInfosFormat;
+  }
+  
+  @Override
+  public final LiveDocsFormat liveDocsFormat() {
+    return liveDocsFormat;
+  }
+
+  @Override
+  public final CompoundFormat compoundFormat() {
+    return compoundFormat;
+  }
+
+  /** Returns the postings format that should be used for writing 
+   *  new segments of <code>field</code>.
+   *  
+   *  The default implementation always returns "Lucene50".
+   *  <p>
+   *  <b>WARNING:</b> if you subclass, you are responsible for index 
+   *  backwards compatibility: future version of Lucene are only 
+   *  guaranteed to be able to read the default implementation. 
+   */
+  public PostingsFormat getPostingsFormatForField(String field) {
+    return defaultFormat;
+  }
+  
+  /** Returns the docvalues format that should be used for writing 
+   *  new segments of <code>field</code>.
+   *  
+   *  The default implementation always returns "Lucene50".
+   *  <p>
+   *  <b>WARNING:</b> if you subclass, you are responsible for index 
+   *  backwards compatibility: future version of Lucene are only 
+   *  guaranteed to be able to read the default implementation. 
+   */
+  public DocValuesFormat getDocValuesFormatForField(String field) {
+    return defaultDVFormat;
+  }
+  
+  @Override
+  public final DocValuesFormat docValuesFormat() {
+    return docValuesFormat;
+  }
+
+  private final PostingsFormat defaultFormat = PostingsFormat.forName("Lucene50");
+  private final DocValuesFormat defaultDVFormat = DocValuesFormat.forName("Lucene50");
+
+  private final NormsFormat normsFormat = new Lucene53NormsFormat();
+
+  @Override
+  public final NormsFormat normsFormat() {
+    return normsFormat;
+  }
+}

Property changes on: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53Codec.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsConsumer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsConsumer.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsConsumer.java	(working copy)
@@ -0,0 +1,153 @@
+package org.apache.lucene.codecs.lucene53;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.NormsConsumer;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.IOUtils;
+
+import static org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.VERSION_CURRENT;
+
+/**
+ * Writer for {@link Lucene53NormsFormat}
+ */
+class Lucene53NormsConsumer extends NormsConsumer { 
+  IndexOutput data, meta;
+  final int maxDoc;
+
+  Lucene53NormsConsumer(SegmentWriteState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
+    boolean success = false;
+    try {
+      String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+      data = state.directory.createOutput(dataName, state.context);
+      CodecUtil.writeIndexHeader(data, dataCodec, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+      String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+      meta = state.directory.createOutput(metaName, state.context);
+      CodecUtil.writeIndexHeader(meta, metaCodec, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+      maxDoc = state.segmentInfo.maxDoc();
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this);
+      }
+    }
+  }
+
+  @Override
+  public void addNormsField(FieldInfo field, Iterable<Number> values) throws IOException {
+    meta.writeVInt(field.number);
+    long minValue = Long.MAX_VALUE;
+    long maxValue = Long.MIN_VALUE;
+    int count = 0;
+
+    for (Number nv : values) {
+      if (nv == null) {
+        throw new IllegalStateException("illegal norms data for field " + field.name + ", got null for value: " + count);
+      }
+      final long v = nv.longValue();
+      minValue = Math.min(minValue, v);
+      maxValue = Math.max(maxValue, v);
+      count++;
+    }
+
+    if (count != maxDoc) {
+      throw new IllegalStateException("illegal norms data for field " + field.name + ", expected count=" + maxDoc + ", got=" + count);
+    }
+
+    if (minValue == maxValue) {
+      addConstant(minValue);
+    } else if (minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {
+      addByte1(values);
+    } else if (minValue >= Short.MIN_VALUE && maxValue <= Short.MAX_VALUE) {
+      addByte2(values);
+    } else if (minValue >= Integer.MIN_VALUE && maxValue <= Integer.MAX_VALUE) {
+      addByte4(values);
+    } else {
+      addByte8(values);
+    }
+  }
+
+  private void addConstant(long constant) throws IOException {
+    meta.writeByte((byte) 0);
+    meta.writeLong(constant);
+  }
+
+  private void addByte1(Iterable<Number> values) throws IOException {
+    meta.writeByte((byte) 1);
+    meta.writeLong(data.getFilePointer());
+
+    for (Number value : values) {
+      data.writeByte(value.byteValue());
+    }
+  }
+
+  private void addByte2(Iterable<Number> values) throws IOException {
+    meta.writeByte((byte) 2);
+    meta.writeLong(data.getFilePointer());
+
+    for (Number value : values) {
+      data.writeShort(value.shortValue());
+    }
+  }
+
+  private void addByte4(Iterable<Number> values) throws IOException {
+    meta.writeByte((byte) 4);
+    meta.writeLong(data.getFilePointer());
+
+    for (Number value : values) {
+      data.writeInt(value.intValue());
+    }
+  }
+
+  private void addByte8(Iterable<Number> values) throws IOException {
+    meta.writeByte((byte) 8);
+    meta.writeLong(data.getFilePointer());
+
+    for (Number value : values) {
+      data.writeLong(value.longValue());
+    }
+  }
+
+  @Override
+  public void close() throws IOException {
+    boolean success = false;
+    try {
+      if (meta != null) {
+        meta.writeVInt(-1); // write EOF marker
+        CodecUtil.writeFooter(meta); // write checksum
+      }
+      if (data != null) {
+        CodecUtil.writeFooter(data); // write checksum
+      }
+      success = true;
+    } finally {
+      if (success) {
+        IOUtils.close(data, meta);
+      } else {
+        IOUtils.closeWhileHandlingException(data, meta);
+      }
+      meta = data = null;
+    }
+  }
+}

Property changes on: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsConsumer.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsFormat.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsFormat.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsFormat.java	(working copy)
@@ -0,0 +1,91 @@
+package org.apache.lucene.codecs.lucene53;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.NormsConsumer;
+import org.apache.lucene.codecs.NormsFormat;
+import org.apache.lucene.codecs.NormsProducer;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Lucene 5.3 Score normalization format.
+ * <p>
+ * Encodes normalization values by encoding each value with the minimum
+ * number of bytes needed to represent the range (which can be zero).
+ * <p>
+ * Files:
+ * <ol>
+ *   <li><tt>.nvd</tt>: Norms data</li>
+ *   <li><tt>.nvm</tt>: Norms metadata</li>
+ * </ol>
+ * <ol>
+ *   <li><a name="nvm"></a>
+ *   <p>The Norms metadata or .nvm file.</p>
+ *   <p>For each norms field, this stores metadata, such as the offset into the 
+ *      Norms data (.nvd)</p>
+ *   <p>Norms metadata (.dvm) --&gt; Header,&lt;Entry&gt;<sup>NumFields</sup>,Footer</p>
+ *   <ul>
+ *     <li>Header --&gt; {@link CodecUtil#writeIndexHeader IndexHeader}</li>
+ *     <li>Entry --&gt; FieldNumber,BytesPerValue, Address</li>
+ *     <li>FieldNumber --&gt; {@link DataOutput#writeVInt vInt}</li>
+ *     <li>BytesPerValue --&gt; {@link DataOutput#writeByte byte}</li>
+ *     <li>Offset --&gt; {@link DataOutput#writeLong Int64}</li>
+ *     <li>Footer --&gt; {@link CodecUtil#writeFooter CodecFooter}</li>
+ *   </ul>
+ *   <p>FieldNumber of -1 indicates the end of metadata.</p>
+ *   <p>Offset is the pointer to the start of the data in the norms data (.nvd), or the singleton value 
+ *      when BytesPerValue = 0</p>
+ *   <li><a name="nvd"></a>
+ *   <p>The Norms data or .nvd file.</p>
+ *   <p>For each Norms field, this stores the actual per-document data (the heavy-lifting)</p>
+ *   <p>Norms data (.nvd) --&gt; Header,&lt; BitPackedData &gt;<sup>NumFields</sup>,Footer</p>
+ *   <ul>
+ *     <li>Header --&gt; {@link CodecUtil#writeIndexHeader IndexHeader}</li>
+ *     <li>Data --&gt; {@link DataOutput#writeByte(byte) byte}<sup>MaxDoc * BytesPerValue</sup></li>
+ *     <li>Footer --&gt; {@link CodecUtil#writeFooter CodecFooter}</li>
+ *   </ul>
+ * </ol>
+ * @lucene.experimental
+ */
+public class Lucene53NormsFormat extends NormsFormat {
+
+  /** Sole Constructor */
+  public Lucene53NormsFormat() {}
+  
+  @Override
+  public NormsConsumer normsConsumer(SegmentWriteState state) throws IOException {
+    return new Lucene53NormsConsumer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+  }
+
+  @Override
+  public NormsProducer normsProducer(SegmentReadState state) throws IOException {
+    return new Lucene53NormsProducer(state, DATA_CODEC, DATA_EXTENSION, METADATA_CODEC, METADATA_EXTENSION);
+  }
+  
+  private static final String DATA_CODEC = "Lucene53NormsData";
+  private static final String DATA_EXTENSION = "nvd";
+  private static final String METADATA_CODEC = "Lucene53NormsMetadata";
+  private static final String METADATA_EXTENSION = "nvm";
+  static final int VERSION_START = 0;
+  static final int VERSION_CURRENT = VERSION_START;
+}

Property changes on: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsFormat.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsProducer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsProducer.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsProducer.java	(working copy)
@@ -0,0 +1,202 @@
+package org.apache.lucene.codecs.lucene53;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.VERSION_CURRENT;
+import static org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.VERSION_START;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.codecs.CodecUtil;
+import org.apache.lucene.codecs.NormsProducer;
+import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.store.ChecksumIndexInput;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.store.RandomAccessInput;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * Reader for {@link Lucene53NormsFormat}
+ */
+class Lucene53NormsProducer extends NormsProducer {
+  // metadata maps (just file pointers and minimal stuff)
+  private final Map<Integer,NormsEntry> norms = new HashMap<>();
+  private final IndexInput data;
+  private final int maxDoc;
+
+  Lucene53NormsProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
+    maxDoc = state.segmentInfo.maxDoc();
+    String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, metaExtension);
+    int version = -1;
+
+    // read in the entries from the metadata file.
+    try (ChecksumIndexInput in = state.directory.openChecksumInput(metaName, state.context)) {
+      Throwable priorE = null;
+      try {
+        version = CodecUtil.checkIndexHeader(in, metaCodec, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+        readFields(in, state.fieldInfos);
+      } catch (Throwable exception) {
+        priorE = exception;
+      } finally {
+        CodecUtil.checkFooter(in, priorE);
+      }
+    }
+
+    String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, dataExtension);
+    data = state.directory.openInput(dataName, state.context);
+    boolean success = false;
+    try {
+      final int version2 = CodecUtil.checkIndexHeader(data, dataCodec, VERSION_START, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);
+      if (version != version2) {
+        throw new CorruptIndexException("Format versions mismatch: meta=" + version + ",data=" + version2, data);
+      }
+
+      // NOTE: data file is too costly to verify checksum against all the bytes on open,
+      // but for now we at least verify proper structure of the checksum footer: which looks
+      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption
+      // such as file truncation.
+      CodecUtil.retrieveChecksum(data);
+
+      success = true;
+    } finally {
+      if (!success) {
+        IOUtils.closeWhileHandlingException(this.data);
+      }
+    }
+  }
+
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
+    int fieldNumber = meta.readVInt();
+    while (fieldNumber != -1) {
+      FieldInfo info = infos.fieldInfo(fieldNumber);
+      if (info == null) {
+        throw new CorruptIndexException("Invalid field number: " + fieldNumber, meta);
+      } else if (!info.hasNorms()) {
+        throw new CorruptIndexException("Invalid field: " + info.name, meta);
+      }
+      NormsEntry entry = new NormsEntry();
+      entry.bytesPerValue = meta.readByte();
+      entry.offset = meta.readLong();
+      norms.put(info.number, entry);
+      fieldNumber = meta.readVInt();
+    }
+  }
+
+  @Override
+  public NumericDocValues getNorms(FieldInfo field) throws IOException {
+    final NormsEntry entry = norms.get(field.number);
+
+    if (entry.bytesPerValue == 0) {
+      final long value = entry.offset;
+      return new NumericDocValues() {
+        @Override
+        public long get(int docID) {
+          return value;
+        }
+      };
+    }
+
+    RandomAccessInput slice;
+    synchronized (data) {
+      switch (entry.bytesPerValue) {
+        case 1: 
+          slice = data.randomAccessSlice(entry.offset, maxDoc);
+          return new NumericDocValues() {
+            @Override
+            public long get(int docID) {
+              try {
+                return slice.readByte(docID);
+              } catch (IOException e) {
+                throw new RuntimeException(e);
+              }
+            }
+          };
+        case 2: 
+          slice = data.randomAccessSlice(entry.offset, maxDoc * 2L);
+          return new NumericDocValues() {
+            @Override
+            public long get(int docID) {
+              try {
+                return slice.readShort(((long)docID) << 1L);
+              } catch (IOException e) {
+                throw new RuntimeException(e);
+              }
+            }
+          };
+        case 4: 
+          slice = data.randomAccessSlice(entry.offset, maxDoc * 4L);
+          return new NumericDocValues() {
+            @Override
+            public long get(int docID) {
+              try {
+                return slice.readInt(((long)docID) << 2L);
+              } catch (IOException e) {
+                throw new RuntimeException(e);
+              }
+            }
+          };
+        case 8: 
+          slice = data.randomAccessSlice(entry.offset, maxDoc * 8L);
+          return new NumericDocValues() {
+            @Override
+            public long get(int docID) {
+              try {
+                return slice.readLong(((long)docID) << 3L);
+              } catch (IOException e) {
+                throw new RuntimeException(e);
+              }
+            }
+          };
+        default:
+          throw new AssertionError();
+      }
+    }
+  }
+
+  @Override
+  public void close() throws IOException {
+    data.close();
+  }
+
+  @Override
+  public long ramBytesUsed() {
+    return 0;
+  }
+
+  @Override
+  public void checkIntegrity() throws IOException {
+    CodecUtil.checksumEntireFile(data);
+  }
+
+  static class NormsEntry {
+    byte bytesPerValue;
+    long offset;
+  }
+
+  @Override
+  public String toString() {
+    return getClass().getSimpleName() + "(fields=" + norms.size() + ")";
+  }
+}

Property changes on: lucene/core/src/java/org/apache/lucene/codecs/lucene53/Lucene53NormsProducer.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/core/src/java/org/apache/lucene/store/ByteBufferIndexInput.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/store/ByteBufferIndexInput.java	(revision 1681411)
+++ lucene/core/src/java/org/apache/lucene/store/ByteBufferIndexInput.java	(working copy)
@@ -54,7 +54,7 @@
     if (buffers.length == 1) {
       return new SingleBufferImpl(resourceDescription, buffers[0], length, chunkSizePower, cleaner, clones);
     } else {
-      return new DefaultImpl(resourceDescription, buffers, length, chunkSizePower, cleaner, clones);
+      return new MultiBufferImpl(resourceDescription, buffers, 0, length, chunkSizePower, cleaner, clones);
     }
   }
   
@@ -301,9 +301,7 @@
       newBuffers[0].position(offset);
       return new SingleBufferImpl(newResourceDescription, newBuffers[0].slice(), length, chunkSizePower, this.cleaner, this.clones);
     } else {
-      return (offset == 0) ?
-        new DefaultImpl(newResourceDescription, newBuffers, length, chunkSizePower, cleaner, clones) :
-        new WithOffsetImpl(newResourceDescription, newBuffers, offset, length, chunkSizePower, cleaner, clones);
+      return new MultiBufferImpl(newResourceDescription, newBuffers, offset, length, chunkSizePower, cleaner, clones);
     }
   }
   
@@ -388,21 +386,6 @@
     void freeBuffer(ByteBufferIndexInput parent, ByteBuffer b) throws IOException;
   }
   
-  /** Default implementation of ByteBufferIndexInput, supporting multiple buffers, but no offset. */
-  static final class DefaultImpl extends ByteBufferIndexInput {
-
-    DefaultImpl(String resourceDescription, ByteBuffer[] buffers, long length, int chunkSizePower, 
-        BufferCleaner cleaner, WeakIdentityMap<ByteBufferIndexInput,Boolean> clones) {
-      super(resourceDescription, buffers, length, chunkSizePower, cleaner, clones);
-      try {
-        seek(0L);
-      } catch (IOException ioe) {
-        throw new AssertionError(ioe);
-      }
-    }
-    
-  }
-  
   /** Optimization of ByteBufferIndexInput for when there is only one buffer */
   static final class SingleBufferImpl extends ByteBufferIndexInput {
 
@@ -502,10 +485,10 @@
   }
   
   /** This class adds offset support to ByteBufferIndexInput, which is needed for slices. */
-  static final class WithOffsetImpl extends ByteBufferIndexInput {
+  static final class MultiBufferImpl extends ByteBufferIndexInput {
     private final int offset;
     
-    WithOffsetImpl(String resourceDescription, ByteBuffer[] buffers, int offset, long length, int chunkSizePower,
+    MultiBufferImpl(String resourceDescription, ByteBuffer[] buffers, int offset, long length, int chunkSizePower,
         BufferCleaner cleaner, WeakIdentityMap<ByteBufferIndexInput,Boolean> clones) {
       super(resourceDescription, buffers, length, chunkSizePower, cleaner, clones);
       this.offset = offset;
@@ -518,10 +501,7 @@
     
     @Override
     public void seek(long pos) throws IOException {
-      // necessary in case offset != 0 and pos < 0, but pos >= -offset
-      if (pos < 0L) {
-        throw new IllegalArgumentException("Seeking to negative position: " + this);
-      }
+      assert pos >= 0L;
       super.seek(pos + offset);
     }
     
Index: lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.Codec
===================================================================
--- lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.Codec	(revision 1681411)
+++ lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.Codec	(working copy)
@@ -14,3 +14,4 @@
 #  limitations under the License.
 
 org.apache.lucene.codecs.lucene50.Lucene50Codec
+org.apache.lucene.codecs.lucene53.Lucene53Codec
Index: lucene/core/src/test/org/apache/lucene/codecs/lucene53/TestLucene53NormsFormat.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/lucene53/TestLucene53NormsFormat.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/codecs/lucene53/TestLucene53NormsFormat.java	(working copy)
@@ -0,0 +1,34 @@
+package org.apache.lucene.codecs.lucene53;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BaseNormsFormatTestCase;
+
+/**
+ * Tests Lucene53NormsFormat
+ */
+public class TestLucene53NormsFormat extends BaseNormsFormatTestCase {
+  private final Codec codec = new Lucene53Codec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  }
+
+}

Property changes on: lucene/core/src/test/org/apache/lucene/codecs/lucene53/TestLucene53NormsFormat.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java	(revision 1681411)
+++ lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java	(working copy)
@@ -386,7 +386,7 @@
       ii.seek(0L);
       
       // check impl (we must check size < chunksize: currently, if size==chunkSize, we get 2 buffers, the second one empty:
-      assertTrue((size < chunkSize) ? (ii instanceof ByteBufferIndexInput.SingleBufferImpl) : (ii instanceof ByteBufferIndexInput.DefaultImpl));
+      assertTrue((size < chunkSize) ? (ii instanceof ByteBufferIndexInput.SingleBufferImpl) : (ii instanceof ByteBufferIndexInput.MultiBufferImpl));
       
       // clone tests:
       assertSame(ii.getClass(), ii.clone().getClass());
@@ -394,7 +394,7 @@
       // slice test (offset 0)
       int sliceSize = random().nextInt(size);
       IndexInput slice = ii.slice("slice", 0, sliceSize);
-      assertTrue((sliceSize < chunkSize) ? (slice instanceof ByteBufferIndexInput.SingleBufferImpl) : (slice instanceof ByteBufferIndexInput.DefaultImpl));
+      assertTrue((sliceSize < chunkSize) ? (slice instanceof ByteBufferIndexInput.SingleBufferImpl) : (slice instanceof ByteBufferIndexInput.MultiBufferImpl));
 
       // slice test (offset > 0 )
       int offset = random().nextInt(size - 1) + 1;
@@ -403,10 +403,8 @@
       //System.out.println(offset + "/" + sliceSize + " chunkSize=" + chunkSize + " " + slice.getClass());
       if (offset % chunkSize + sliceSize < chunkSize) {
         assertTrue(slice instanceof ByteBufferIndexInput.SingleBufferImpl);
-      } else if (offset % chunkSize == 0) {
-        assertTrue(slice instanceof ByteBufferIndexInput.DefaultImpl);
       } else {
-        assertTrue(slice instanceof ByteBufferIndexInput.WithOffsetImpl);
+        assertTrue(slice instanceof ByteBufferIndexInput.MultiBufferImpl);
       }
 
       ii.close();
