diff --git a/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java b/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
index bb84a79f1..16c7693 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates.java
@@ -42,7 +42,7 @@ import org.apache.lucene.search.ScoreMode;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.store.ByteArrayDataInput;
-import org.apache.lucene.store.RAMOutputStream;
+import org.apache.lucene.store.ByteBuffersDataOutput;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -153,45 +153,42 @@ final class FrozenBufferedUpdates {
     throws IOException {
     // TODO: we could do better here, e.g. collate the updates by field
     // so if you are updating 2 fields interleaved we don't keep writing the field strings
-    try (RAMOutputStream out = new RAMOutputStream()) {
-      String lastTermField = null;
-      String lastUpdateField = null;
-      for (LinkedHashMap<Term, T> updates : dvUpdates.values()) {
-        updateSizeConsumer.accept(updates.size());
-        for (T update : updates.values()) {
-          int code = update.term.bytes().length << 3;
-
-          String termField = update.term.field();
-          if (termField.equals(lastTermField) == false) {
-            code |= 1;
-          }
-          String updateField = update.field;
-          if (updateField.equals(lastUpdateField) == false) {
-            code |= 2;
-          }
-          if (update.hasValue()) {
-            code |= 4;
-          }
-          out.writeVInt(code);
-          out.writeVInt(update.docIDUpto);
-          if (termField.equals(lastTermField) == false) {
-            out.writeString(termField);
-            lastTermField = termField;
-          }
-          if (updateField.equals(lastUpdateField) == false) {
-            out.writeString(updateField);
-            lastUpdateField = updateField;
-          }
-          out.writeBytes(update.term.bytes().bytes, update.term.bytes().offset, update.term.bytes().length);
-          if (update.hasValue()) {
-            update.writeTo(out);
-          }
+    ByteBuffersDataOutput out = new ByteBuffersDataOutput();
+    String lastTermField = null;
+    String lastUpdateField = null;
+    for (LinkedHashMap<Term, T> updates : dvUpdates.values()) {
+      updateSizeConsumer.accept(updates.size());
+      for (T update : updates.values()) {
+        int code = update.term.bytes().length << 3;
+
+        String termField = update.term.field();
+        if (termField.equals(lastTermField) == false) {
+          code |= 1;
+        }
+        String updateField = update.field;
+        if (updateField.equals(lastUpdateField) == false) {
+          code |= 2;
+        }
+        if (update.hasValue()) {
+          code |= 4;
+        }
+        out.writeVInt(code);
+        out.writeVInt(update.docIDUpto);
+        if (termField.equals(lastTermField) == false) {
+          out.writeString(termField);
+          lastTermField = termField;
+        }
+        if (updateField.equals(lastUpdateField) == false) {
+          out.writeString(updateField);
+          lastUpdateField = updateField;
+        }
+        out.writeBytes(update.term.bytes().bytes, update.term.bytes().offset, update.term.bytes().length);
+        if (update.hasValue()) {
+          update.writeTo(out);
         }
       }
-      byte[] bytes = new byte[(int) out.getFilePointer()];
-      out.writeTo(bytes, 0);
-      return bytes;
     }
+    return out.toArrayCopy();
   }
 
   /** Returns the {@link SegmentCommitInfo} that this packet is supposed to apply its deletes to, or null
@@ -594,7 +591,7 @@ final class FrozenBufferedUpdates {
       }
         
       // TODO: we traverse the terms in update order (not term order) so that we
-      // apply the updates in the correct order, i.e. if two terms udpate the
+      // apply the updates in the correct order, i.e. if two terms update the
       // same document, the last one that came in wins, irrespective of the
       // terms lexical order.
       // we can apply the updates in terms order if we keep an updatesGen (and
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDocValues.java b/lucene/core/src/test/org/apache/lucene/index/TestDocValues.java
index 3010047..98b7d9e 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDocValues.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDocValues.java
@@ -206,7 +206,6 @@ public class TestDocValues extends LuceneTestCase {
     iw.close();
 
     DirectoryReader dr = DirectoryReader.open(zeroDir);
-
     for (int id = 0 ; id < docValues.size() ; id++) {
       int readerIndex = dr.readerIndex(id);
       // We create a new reader each time as we want to test vBPV-skipping and not sequential iteration
@@ -215,6 +214,7 @@ public class TestDocValues extends LuceneTestCase {
       assertEquals(designation + ": The value for docID " + id + " should be as expected",
           docValues.get(id), Long.valueOf(numDV.longValue()));
     }
+    dr.close();
 
     // Clean up
     deleteAndClose(zeroDir);
