diff --git a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
index 41073fd02f..dd0c91f012 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
@@ -65,6 +65,7 @@ public final class FieldReader extends Terms implements Accountable {
   final FST<BytesRef> index;
   //private boolean DEBUG;
 
+
   FieldReader(BlockTreeTermsReader parent, FieldInfo fieldInfo, long numTerms, BytesRef rootCode, long sumTotalTermFreq, long sumDocFreq, int docCount,
               long indexStartFP, int longsSize, IndexInput indexIn, BytesRef minTerm, BytesRef maxTerm) throws IOException {
     assert numTerms > 0;
@@ -88,10 +89,12 @@ public final class FieldReader extends Terms implements Accountable {
 
     if (indexIn != null) {
       final IndexInput clone = indexIn.clone();
+      //System.out.println("start=" + indexStartFP + " field=" + fieldInfo.name);
       clone.seek(indexStartFP);
       // Initialize FST offheap if index is MMapDirectory and
       // docCount != sumDocFreq implying field is not primary key
-      if (clone instanceof ByteBufferIndexInput && this.docCount != this.sumDocFreq) {
+      String fstOffheap = this.fieldInfo.getReaderAttribute("fst.offheap");
+      if (fstOffheap != null && "true".equals(fstOffheap)) {
         index = new FST<>(clone, ByteSequenceOutputs.getSingleton(), new OffHeapFSTStore());
       } else {
         index = new FST<>(clone, ByteSequenceOutputs.getSingleton());
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
index 534652363f..30a8de6d56 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfo.java
@@ -17,6 +17,7 @@
 package org.apache.lucene.index;
 
 
+import java.util.HashMap;
 import java.util.Map;
 import java.util.Objects;
 
@@ -46,6 +47,8 @@ public final class FieldInfo {
 
   private final Map<String,String> attributes;
 
+  private final Map<String,String> readerAttributes;
+
   private long dvGen;
 
   /** If both of these are positive it means this field indexed points
@@ -84,6 +87,7 @@ public final class FieldInfo {
     this.pointIndexDimensionCount = pointIndexDimensionCount;
     this.pointNumBytes = pointNumBytes;
     this.softDeletesField = softDeletesField;
+    this.readerAttributes = new HashMap<>();
     assert checkConsistency();
   }
 
@@ -343,6 +347,13 @@ public final class FieldInfo {
   }
   
   /**
+   * Get a segment reader attribute value, or null if it does not exist
+   */
+  public String getReaderAttribute(String key) {
+    return readerAttributes.get(key);
+  }
+
+  /**
    * Puts a codec attribute value.
    * <p>
    * This is a key-value mapping for the field that the codec can use
@@ -358,6 +369,17 @@ public final class FieldInfo {
   }
   
   /**
+   * Puts a segment reader attribute value.
+   * <p>
+   * This is a key-value mapping for the field that the segment reader can
+   * use to store additional metadata that can be passed to lucene readers
+   * <p>
+   */
+  public String putReaderAttribute(String key, String value) {
+    return readerAttributes.put(key, value);
+  }
+
+  /**
    * Returns internal codec attributes map.
    */
   public Map<String,String> attributes() {
diff --git a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
index 193fbdf590..7ae39c0c24 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FieldInfos.java
@@ -23,6 +23,7 @@ import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 import java.util.Set;
@@ -252,6 +253,17 @@ public class FieldInfos implements Iterable<FieldInfo> {
     return byNumber[fieldNumber];
   }
 
+  public void updateFSTOffheap(List<String> offheapFieldNames) {
+    for (Map.Entry<String,FieldInfo> field: byName.entrySet()) {
+      if (offheapFieldNames.contains(field.getKey())) {
+        field.getValue().putReaderAttribute("fst.offheap", "true");
+      } else {
+        field.getValue().putReaderAttribute("fst.offheap", "false");
+      }
+    }
+  }
+
+
   static final class FieldDimensions {
     public final int dataDimensionCount;
     public final int indexDimensionCount;
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index f9aaf34685..84efd945c6 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -885,7 +885,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,
           enableTestPoints, this::newSegmentName,
           config, directoryOrig, directory, globalFieldNumberMap);
       readerPool = new ReaderPool(directory, directoryOrig, segmentInfos, globalFieldNumberMap,
-          bufferedUpdatesStream::getCompletedDelGen, infoStream, conf.getSoftDeletesField(), reader);
+          bufferedUpdatesStream::getCompletedDelGen, infoStream, conf.getSoftDeletesField(), reader, config.getOffheapFieldNames());
       if (config.getReaderPooling()) {
         readerPool.enableReaderPooling();
       }
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java
index a72aeab007..90460c3999 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java
@@ -20,6 +20,7 @@ package org.apache.lucene.index;
 import java.io.PrintStream;
 import java.util.Arrays;
 import java.util.EnumSet;
+import java.util.List;
 import java.util.stream.Collectors;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -110,7 +111,7 @@ public final class IndexWriterConfig extends LiveIndexWriterConfig {
   
   /** Default value for whether calls to {@link IndexWriter#close()} include a commit. */
   public final static boolean DEFAULT_COMMIT_ON_CLOSE = true;
-  
+
   // indicates whether this config instance is already attached to a writer.
   // not final so that it can be cloned properly.
   private SetOnce<IndexWriter> writer = new SetOnce<>();
@@ -482,6 +483,15 @@ public final class IndexWriterConfig extends LiveIndexWriterConfig {
     return this;
   }
 
+  /**
+   * Sets list of fields to be initialized offheap. 'ALL' is special keyword to
+   * initialize terms index for all the fields offheap.
+   */
+  public IndexWriterConfig setOffheapFieldNames(List<String> offheapFieldNames) {
+    this.offheapFieldNames = offheapFieldNames;
+    return this;
+  }
+
   /** We only allow sorting on these types */
   private static final EnumSet<SortField.Type> ALLOWED_INDEX_SORT_TYPES = EnumSet.of(SortField.Type.STRING,
                                                                                      SortField.Type.LONG,
@@ -507,6 +517,7 @@ public final class IndexWriterConfig extends LiveIndexWriterConfig {
   @Override
   public String toString() {
     StringBuilder sb = new StringBuilder(super.toString());
+    sb.append("offheapFieldNames=").append(this.offheapFieldNames).append("\n");
     sb.append("writer=").append(writer.get()).append("\n");
     return sb.toString();
   }
diff --git a/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java b/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java
index 259a020c3a..6980cb86b9 100644
--- a/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java
+++ b/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java
@@ -16,8 +16,8 @@
  */
 package org.apache.lucene.index;
 
-
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -50,6 +50,10 @@ public class LiveIndexWriterConfig {
    *  points are deleted. */
   protected volatile IndexDeletionPolicy delPolicy;
 
+  // modified by IndexWriterConfig
+  /** List of fields to be initialized offheap */
+  protected List<String> offheapFieldNames;
+
   /** {@link IndexCommit} that {@link IndexWriter} is
    *  opened on. */
   protected volatile IndexCommit commit;
@@ -203,7 +207,11 @@ public class LiveIndexWriterConfig {
   public double getRAMBufferSizeMB() {
     return ramBufferSizeMB;
   }
-  
+
+  public List<String> getOffheapFieldNames() {
+    return this.offheapFieldNames;
+  }
+
   /**
    * Determines the minimal number of documents required before the buffered
    * in-memory documents are flushed as a new Segment. Large values generally
diff --git a/lucene/core/src/java/org/apache/lucene/index/ReaderPool.java b/lucene/core/src/java/org/apache/lucene/index/ReaderPool.java
index b792be2687..4315591c66 100644
--- a/lucene/core/src/java/org/apache/lucene/index/ReaderPool.java
+++ b/lucene/core/src/java/org/apache/lucene/index/ReaderPool.java
@@ -54,6 +54,7 @@ final class ReaderPool implements Closeable {
   private final InfoStream infoStream;
   private final SegmentInfos segmentInfos;
   private final String softDeletesField;
+  private final List<String> offheapFieldNames;
   // This is a "write once" variable (like the organic dye
   // on a DVD-R that may or may not be heated by a laser and
   // then cooled to permanently record the event): it's
@@ -72,6 +73,12 @@ final class ReaderPool implements Closeable {
   ReaderPool(Directory directory, Directory originalDirectory, SegmentInfos segmentInfos,
              FieldInfos.FieldNumbers fieldNumbers, LongSupplier completedDelGenSupplier, InfoStream infoStream,
              String softDeletesField, StandardDirectoryReader reader) throws IOException {
+    this(directory, originalDirectory, segmentInfos, fieldNumbers, completedDelGenSupplier, infoStream, softDeletesField, reader, null);
+  }
+
+  ReaderPool(Directory directory, Directory originalDirectory, SegmentInfos segmentInfos,
+             FieldInfos.FieldNumbers fieldNumbers, LongSupplier completedDelGenSupplier, InfoStream infoStream,
+             String softDeletesField, StandardDirectoryReader reader, List<String> offheapFieldNames) throws IOException {
     this.directory = directory;
     this.originalDirectory = originalDirectory;
     this.segmentInfos = segmentInfos;
@@ -79,6 +86,7 @@ final class ReaderPool implements Closeable {
     this.completedDelGenSupplier = completedDelGenSupplier;
     this.infoStream = infoStream;
     this.softDeletesField = softDeletesField;
+    this.offheapFieldNames= offheapFieldNames;
     if (reader != null) {
       // Pre-enroll all segment readers into the reader pool; this is necessary so
       // any in-memory NRT live docs are correctly carried over, and so NRT readers
@@ -91,7 +99,7 @@ final class ReaderPool implements Closeable {
         SegmentReader newReader = new SegmentReader(segmentInfos.info(i), segReader, segReader.getLiveDocs(),
             segReader.getHardLiveDocs(), segReader.numDocs(), true);
         readerMap.put(newReader.getOriginalSegmentInfo(), new ReadersAndUpdates(segmentInfos.getIndexCreatedVersionMajor(),
-            newReader, newPendingDeletes(newReader, newReader.getOriginalSegmentInfo())));
+            newReader, newPendingDeletes(newReader, newReader.getOriginalSegmentInfo()), this.offheapFieldNames));
       }
     }
   }
@@ -372,7 +380,7 @@ final class ReaderPool implements Closeable {
       if (create == false) {
         return null;
       }
-      rld = new ReadersAndUpdates(segmentInfos.getIndexCreatedVersionMajor(), info, newPendingDeletes(info));
+      rld = new ReadersAndUpdates(segmentInfos.getIndexCreatedVersionMajor(), info, newPendingDeletes(info), this.offheapFieldNames);
       // Steal initial reference:
       readerMap.put(info, rld);
     } else {
@@ -409,4 +417,4 @@ final class ReaderPool implements Closeable {
     }
     return true;
   }
-}
\ No newline at end of file
+}
diff --git a/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java b/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
index 9afff9c19d..31f65e1259 100644
--- a/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
+++ b/lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates.java
@@ -74,6 +74,8 @@ final class ReadersAndUpdates {
   // updates on the merged segment too.
   private boolean isMerging = false;
 
+  private List<String> offheapFieldNames;
+
   // Holds resolved (to docIDs) doc values updates that have not yet been
   // written to the index
   private final Map<String,List<DocValuesFieldUpdates>> pendingDVUpdates = new HashMap<>();
@@ -89,17 +91,18 @@ final class ReadersAndUpdates {
   final AtomicLong ramBytesUsed = new AtomicLong();
 
   ReadersAndUpdates(int indexCreatedVersionMajor, SegmentCommitInfo info,
-                    PendingDeletes pendingDeletes) {
+                    PendingDeletes pendingDeletes, List<String> offheapFieldNames) {
     this.info = info;
     this.pendingDeletes = pendingDeletes;
     this.indexCreatedVersionMajor = indexCreatedVersionMajor;
+    this.offheapFieldNames = offheapFieldNames;
   }
 
   /** Init from a previously opened SegmentReader.
    *
    * <p>NOTE: steals incoming ref from reader. */
-  ReadersAndUpdates(int indexCreatedVersionMajor, SegmentReader reader, PendingDeletes pendingDeletes) throws IOException {
-    this(indexCreatedVersionMajor, reader.getOriginalSegmentInfo(), pendingDeletes);
+  ReadersAndUpdates(int indexCreatedVersionMajor, SegmentReader reader, PendingDeletes pendingDeletes, List<String> offheapFieldNames) throws IOException {
+    this(indexCreatedVersionMajor, reader.getOriginalSegmentInfo(), pendingDeletes, offheapFieldNames);
     this.reader = reader;
     pendingDeletes.onNewReader(reader, info);
   }
@@ -169,7 +172,7 @@ final class ReadersAndUpdates {
   public synchronized SegmentReader getReader(IOContext context) throws IOException {
     if (reader == null) {
       // We steal returned ref:
-      reader = new SegmentReader(info, indexCreatedVersionMajor, context);
+      reader = new SegmentReader(info, indexCreatedVersionMajor, context, this.offheapFieldNames);
       pendingDeletes.onNewReader(reader, info);
     }
 
@@ -536,7 +539,7 @@ final class ReadersAndUpdates {
       // IndexWriter.commitMergedDeletes).
       final SegmentReader reader;
       if (this.reader == null) {
-        reader = new SegmentReader(info, indexCreatedVersionMajor, IOContext.READONCE);
+        reader = new SegmentReader(info, indexCreatedVersionMajor, IOContext.READONCE, this.offheapFieldNames);
         pendingDeletes.onNewReader(reader, info);
       } else {
         reader = this.reader;
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java b/lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
index 0e7b9e43ca..7a32fc0cff 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
@@ -24,6 +24,7 @@ import java.io.IOException;
 import java.nio.file.NoSuchFileException;
 import java.util.Collections;
 import java.util.LinkedHashSet;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
@@ -89,7 +90,7 @@ final class SegmentCoreReaders {
   private final Set<IndexReader.ClosedListener> coreClosedListeners = 
       Collections.synchronizedSet(new LinkedHashSet<IndexReader.ClosedListener>());
   
-  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {
+  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context, List<String> offheapFieldNames) throws IOException {
 
     final Codec codec = si.info.getCodec();
     final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.
@@ -106,6 +107,9 @@ final class SegmentCoreReaders {
       segment = si.info.name;
 
       coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, "", context);
+      if (offheapFieldNames != null) {
+        coreFieldInfos.updateFSTOffheap(offheapFieldNames);
+      }
       
       final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);
       final PostingsFormat format = codec.postingsFormat();
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentReader.java b/lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
index b368b964b7..50c3d79b7e 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
@@ -19,6 +19,7 @@ package org.apache.lucene.index;
 
 import java.io.IOException;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -63,24 +64,27 @@ public final class SegmentReader extends CodecReader {
 
   /** True if we are holding RAM only liveDocs or DV updates, i.e. the SegmentCommitInfo delGen doesn't match our liveDocs. */
   final boolean isNRT;
-  
+
   final DocValuesProducer docValuesProducer;
   final FieldInfos fieldInfos;
 
+  SegmentReader(SegmentCommitInfo si, int createdVersionMajor, IOContext context) throws IOException {
+    this(si, createdVersionMajor, context, null);
+  }
+
   /**
    * Constructs a new SegmentReader with a new core.
    * @throws CorruptIndexException if the index is corrupt
    * @throws IOException if there is a low-level IO error
    */
-  SegmentReader(SegmentCommitInfo si, int createdVersionMajor, IOContext context) throws IOException {
+  SegmentReader(SegmentCommitInfo si, int createdVersionMajor, IOContext context, List<String> offheapFieldNames) throws IOException {
     this.si = si.clone();
     this.originalSi = si;
     this.metaData = new LeafMetaData(createdVersionMajor, si.info.getMinVersion(), si.info.getIndexSort());
 
     // We pull liveDocs/DV updates from disk:
     this.isNRT = false;
-    
-    core = new SegmentCoreReaders(si.info.dir, si, context);
+    core = new SegmentCoreReaders(si.info.dir, si, context, offheapFieldNames);
     segDocValues = new SegmentDocValues();
     
     boolean success = false;
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
index d882fae394..b1b440668f 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -313,7 +313,7 @@ public class TestFSTs extends LuceneTestCase {
     MockAnalyzer analyzer = new MockAnalyzer(random());
     analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));
 
-    final IndexWriterConfig conf = newIndexWriterConfig(analyzer).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64);
+    final IndexWriterConfig conf = newIndexWriterConfig(analyzer).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64).setOffheapFieldNames(new ArrayList<String>() {{add("id");}});
     final Path tempDir = createTempDir("fstlines");
     final Directory dir = newFSDirectory(tempDir);
     final IndexWriter writer = new IndexWriter(dir, conf);
@@ -847,7 +847,8 @@ public class TestFSTs extends LuceneTestCase {
         System.out.println("TEST: cycle=" + cycle);
       }
       RandomIndexWriter w = new RandomIndexWriter(random(), dir,
-                                                  newIndexWriterConfig(new MockAnalyzer(random())).setOpenMode(IndexWriterConfig.OpenMode.CREATE));
+                                                  newIndexWriterConfig(new MockAnalyzer(random())).setOpenMode(IndexWriterConfig.OpenMode.CREATE)
+												  .setOffheapFieldNames(new ArrayList<String>() {{add("id");}}));
       Document doc = new Document();
       Field idField = newStringField("id", "", Field.Store.NO);
       doc.add(idField);
@@ -977,7 +978,8 @@ public class TestFSTs extends LuceneTestCase {
     Directory dir = newDirectory();
 
     RandomIndexWriter w = new RandomIndexWriter(random(), dir,
-                                                newIndexWriterConfig(new MockAnalyzer(random())).setOpenMode(IndexWriterConfig.OpenMode.CREATE));
+                                                newIndexWriterConfig(new MockAnalyzer(random())).setOpenMode(IndexWriterConfig.OpenMode.CREATE)
+												.setOffheapFieldNames(new ArrayList<String>() {{add("id");}}));
     Document doc = new Document();
     Field f = newStringField("field", "", Field.Store.NO);
     doc.add(f);
