Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java	(revision 1661864)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java	(working copy)
@@ -114,7 +114,7 @@
       ts.end();
     }
 
-    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
     int[] ranks = new int[] { 0 };
     compareRanks(hits, ranks);
   }
@@ -139,7 +139,7 @@
       ts.end();
     }
 
-    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
     int[] ranks = new int[] { 1, 2, 0 };
     compareRanks(hits, ranks);
   }
Index: lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1661864)
+++ lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -729,7 +729,7 @@
       }
     }
     
-    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String("content"), "aaa")), null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String("content"), "aaa")), 1000).scoreDocs;
 
     // First document should be #0
     StoredDocument d = searcher.getIndexReader().document(hits[0].doc);
@@ -738,20 +738,20 @@
     doTestHits(hits, 34, searcher.getIndexReader());
     
     if (is40Index) {
-      hits = searcher.search(new TermQuery(new Term(new String("content5"), "aaa")), null, 1000).scoreDocs;
+      hits = searcher.search(new TermQuery(new Term(new String("content5"), "aaa")), 1000).scoreDocs;
 
       doTestHits(hits, 34, searcher.getIndexReader());
     
-      hits = searcher.search(new TermQuery(new Term(new String("content6"), "aaa")), null, 1000).scoreDocs;
+      hits = searcher.search(new TermQuery(new Term(new String("content6"), "aaa")), 1000).scoreDocs;
 
       doTestHits(hits, 34, searcher.getIndexReader());
     }
 
-    hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(new Term("utf8", "\u0000")), 1000).scoreDocs;
     assertEquals(34, hits.length);
-    hits = searcher.search(new TermQuery(new Term(new String("utf8"), "lu\uD834\uDD1Ece\uD834\uDD60ne")), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(new Term(new String("utf8"), "lu\uD834\uDD1Ece\uD834\uDD60ne")), 1000).scoreDocs;
     assertEquals(34, hits.length);
-    hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(new Term("utf8", "ab\ud917\udc17cd")), 1000).scoreDocs;
     assertEquals(34, hits.length);
 
     reader.close();
@@ -775,7 +775,7 @@
     // make sure searching sees right # hits
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
     StoredDocument d = searcher.getIndexReader().document(hits[0].doc);
     assertEquals("wrong first document", "0", d.get("id"));
     doTestHits(hits, 44, searcher.getIndexReader());
@@ -790,7 +790,7 @@
 
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
     assertEquals("wrong number of hits", 44, hits.length);
     d = searcher.doc(hits[0].doc);
     doTestHits(hits, 44, searcher.getIndexReader());
@@ -802,7 +802,7 @@
     // make sure searching sees right # hits
     DirectoryReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
     assertEquals("wrong number of hits", 34, hits.length);
     StoredDocument d = searcher.doc(hits[0].doc);
     assertEquals("wrong first document", "0", d.get("id"));
@@ -816,7 +816,7 @@
 
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(new TermQuery(new Term("content", "aaa")), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(new Term("content", "aaa")), 1000).scoreDocs;
     assertEquals("wrong number of hits", 34, hits.length);
     doTestHits(hits, 34, searcher.getIndexReader());
     reader.close();
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(revision 1661864)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(working copy)
@@ -124,7 +124,7 @@
             TopFieldCollector collector = TopFieldCollector.create(sort, numHits,
                                                                    true, withScore(),
                                                                    withMaxScore());
-            searcher.search(q, null, collector);
+            searcher.search(q, collector);
             hits = collector.topDocs();
           } else {
             hits = searcher.search(q, numHits);
@@ -131,7 +131,7 @@
           }
         } else {
           Collector collector = createCollector();
-          searcher.search(q, null, collector);
+          searcher.search(q, collector);
           //hits = collector.topDocs();
         }
 
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java	(revision 1661864)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java	(working copy)
@@ -94,7 +94,7 @@
       Query q = qqParser.parse(qq);
       // search with this query 
       long t1 = System.currentTimeMillis();
-      TopDocs td = searcher.search(q,null,maxResults);
+      TopDocs td = searcher.search(q,maxResults);
       long searchTime = System.currentTimeMillis()-t1;
       //most likely we either submit or judge, but check both 
       if (judge!=null) {
Index: lucene/core/src/java/org/apache/lucene/search/FieldDoc.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldDoc.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/FieldDoc.java	(working copy)
@@ -46,7 +46,7 @@
    * the <code>value</code> method corresponding
    * FieldComparator used to sort this field.
    * @see Sort
-   * @see IndexSearcher#search(Query,Filter,int,Sort)
+   * @see IndexSearcher#search(Query,int,Sort)
    */
   public Object[] fields;
 
Index: lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java	(working copy)
@@ -27,7 +27,7 @@
  * 
  * @lucene.experimental
  * @since 2.9
- * @see IndexSearcher#search(Query,Filter,int,Sort)
+ * @see IndexSearcher#search(Query,int,Sort)
  */
 public abstract class FieldValueHitQueue<T extends FieldValueHitQueue.Entry> extends PriorityQueue<T> {
 
@@ -202,7 +202,7 @@
    * 
    * @param entry The Entry used to create a FieldDoc
    * @return The newly created FieldDoc
-   * @see IndexSearcher#search(Query,Filter,int,Sort)
+   * @see IndexSearcher#search(Query,int,Sort)
    */
   FieldDoc fillFields(final Entry entry) {
     final int n = comparators.length;
Index: lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(working copy)
@@ -47,8 +47,7 @@
 /** Implements search over a single IndexReader.
  *
  * <p>Applications usually need only call the inherited
- * {@link #search(Query,int)}
- * or {@link #search(Query,Filter,int)} methods. For
+ * {@link #search(Query,int)} method. For
  * performance reasons, if your index is unchanging, you
  * should share a single IndexSearcher instance across
  * multiple searches instead of creating a new one
@@ -209,11 +208,6 @@
   public Similarity getSimilarity() {
     return similarity;
   }
-  
-  /** @lucene.internal */
-  protected Query wrapFilter(Query query, Filter filter) {
-    return (filter == null) ? query : new FilteredQuery(query, filter);
-  }
 
   /** Finds the top <code>n</code>
    * hits for <code>query</code> where all results are after a previous 
@@ -276,21 +270,6 @@
   }
   
   /** Finds the top <code>n</code>
-   * hits for <code>query</code>, applying <code>filter</code> if non-null,
-   * where all results are after a previous result (<code>after</code>).
-   * <p>
-   * By passing the bottom result from a previous page as <code>after</code>,
-   * this method can be used for efficient 'deep-paging' across potentially
-   * large result sets.
-   *
-   * @throws BooleanQuery.TooManyClauses If a query would exceed 
-   *         {@link BooleanQuery#getMaxClauseCount()} clauses.
-   */
-  public TopDocs searchAfter(ScoreDoc after, Query query, Filter filter, int n) throws IOException {
-    return searchAfter(after, wrapFilter(query, filter), n);
-  }
-  
-  /** Finds the top <code>n</code>
    * hits for <code>query</code>.
    *
    * @throws BooleanQuery.TooManyClauses If a query would exceed 
@@ -301,36 +280,8 @@
     return searchAfter(null, query, n);
   }
 
-
-  /** Finds the top <code>n</code>
-   * hits for <code>query</code>, applying <code>filter</code> if non-null.
-   *
-   * @throws BooleanQuery.TooManyClauses If a query would exceed 
-   *         {@link BooleanQuery#getMaxClauseCount()} clauses.
-   */
-  public TopDocs search(Query query, Filter filter, int n)
-    throws IOException {
-    return search(wrapFilter(query, filter), n);
-  }
-
   /** Lower-level search API.
    *
-   * <p>{@link LeafCollector#collect(int)} is called for every matching
-   * document.
-   *
-   * @param query to match documents
-   * @param filter if non-null, used to permit documents to be collected.
-   * @param results to receive hits
-   * @throws BooleanQuery.TooManyClauses If a query would exceed 
-   *         {@link BooleanQuery#getMaxClauseCount()} clauses.
-   */
-  public void search(Query query, Filter filter, Collector results)
-    throws IOException {
-    search(wrapFilter(query, filter), results);
-  }
-
-  /** Lower-level search API.
-   *
    * <p>{@link LeafCollector#collect(int)} is called for every matching document.
    *
    * @throws BooleanQuery.TooManyClauses If a query would exceed 
@@ -340,30 +291,13 @@
     throws IOException {
     search(leafContexts, createNormalizedWeight(query, results.needsScores()), results);
   }
-  
-  /** Search implementation with arbitrary sorting.  Finds
-   * the top <code>n</code> hits for <code>query</code>, applying
-   * <code>filter</code> if non-null, and sorting the hits by the criteria in
-   * <code>sort</code>.
-   * 
-   * <p>NOTE: this does not compute scores by default; use
-   * {@link IndexSearcher#search(Query,Filter,int,Sort,boolean,boolean)} to
-   * control scoring.
-   *
-   * @throws BooleanQuery.TooManyClauses If a query would exceed 
-   *         {@link BooleanQuery#getMaxClauseCount()} clauses.
-   */
-  public TopFieldDocs search(Query query, Filter filter, int n,
-                             Sort sort) throws IOException {
-    return search(query, filter, n, sort, false, false);
-  }
 
   /** Search implementation with arbitrary sorting, plus
    * control over whether hit scores and max score
    * should be computed.  Finds
-   * the top <code>n</code> hits for <code>query</code>, applying
-   * <code>filter</code> if non-null, and sorting the hits by the criteria in
-   * <code>sort</code>.  If <code>doDocScores</code> is <code>true</code>
+   * the top <code>n</code> hits for <code>query</code>, and sorting
+   * the hits by the criteria in <code>sort</code>.
+   * If <code>doDocScores</code> is <code>true</code>
    * then the score of each hit will be computed and
    * returned.  If <code>doMaxScore</code> is
    * <code>true</code> then the maximum score over all
@@ -372,28 +306,13 @@
    * @throws BooleanQuery.TooManyClauses If a query would exceed 
    *         {@link BooleanQuery#getMaxClauseCount()} clauses.
    */
-  public TopFieldDocs search(Query query, Filter filter, int n,
-                             Sort sort, boolean doDocScores, boolean doMaxScore) throws IOException {
-    return searchAfter(null, query, filter, n, sort, doDocScores, doMaxScore);
+  public TopFieldDocs search(Query query, int n,
+      Sort sort, boolean doDocScores, boolean doMaxScore) throws IOException {
+    return searchAfter(null, query, n, sort, doDocScores, doMaxScore);
   }
 
-  /** Finds the top <code>n</code>
-   * hits for <code>query</code>, applying <code>filter</code> if non-null,
-   * where all results are after a previous result (<code>after</code>).
-   * <p>
-   * By passing the bottom result from a previous page as <code>after</code>,
-   * this method can be used for efficient 'deep-paging' across potentially
-   * large result sets.
-   *
-   * @throws BooleanQuery.TooManyClauses If a query would exceed 
-   *         {@link BooleanQuery#getMaxClauseCount()} clauses.
-   */
-  public TopFieldDocs searchAfter(ScoreDoc after, Query query, Filter filter, int n, Sort sort) throws IOException {
-    return searchAfter(after, query, filter, n, sort, false, false);
-  }
-
   /**
-   * Search implementation with arbitrary sorting and no filter.
+   * Search implementation with arbitrary sorting.
    * @param query The query to search for
    * @param n Return only the top n results
    * @param sort The {@link org.apache.lucene.search.Sort} object
@@ -400,9 +319,8 @@
    * @return The top docs, sorted according to the supplied {@link org.apache.lucene.search.Sort} instance
    * @throws IOException if there is a low-level I/O error
    */
-  public TopFieldDocs search(Query query, int n,
-                             Sort sort) throws IOException {
-    return search(query, null, n, sort, false, false);
+  public TopFieldDocs search(Query query, int n, Sort sort) throws IOException {
+    return searchAfter(null, query, n, sort, false, false);
   }
 
   /** Finds the top <code>n</code>
@@ -417,7 +335,7 @@
    *         {@link BooleanQuery#getMaxClauseCount()} clauses.
    */
   public TopDocs searchAfter(ScoreDoc after, Query query, int n, Sort sort) throws IOException {
-    return searchAfter(after, query, null, n, sort, false, false);
+    return searchAfter(after, query, n, sort, false, false);
   }
 
   /** Finds the top <code>n</code>
@@ -436,7 +354,7 @@
    * @throws BooleanQuery.TooManyClauses If a query would exceed 
    *         {@link BooleanQuery#getMaxClauseCount()} clauses.
    */
-  public TopFieldDocs searchAfter(ScoreDoc after, Query query, Filter filter, int numHits, Sort sort,
+  public TopFieldDocs searchAfter(ScoreDoc after, Query query, int numHits, Sort sort,
       boolean doDocScores, boolean doMaxScore) throws IOException {
     if (after != null && !(after instanceof FieldDoc)) {
       // TODO: if we fix type safety of TopFieldDocs we can
@@ -443,7 +361,7 @@
       // remove this
       throw new IllegalArgumentException("after must be a FieldDoc; got " + after);
     }
-    return searchAfter((FieldDoc) after, wrapFilter(query, filter), numHits, sort, doDocScores, doMaxScore);
+    return searchAfter((FieldDoc) after, query, numHits, sort, doDocScores, doMaxScore);
   }
 
   private TopFieldDocs searchAfter(FieldDoc after, Query query, int numHits, Sort sort,
Index: lucene/core/src/java/org/apache/lucene/search/TopDocs.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopDocs.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/TopDocs.java	(working copy)
@@ -22,7 +22,6 @@
 import java.io.IOException;
 
 /** Represents hits returned by {@link
- * IndexSearcher#search(Query,Filter,int)} and {@link
  * IndexSearcher#search(Query,int)}. */
 public class TopDocs {
 
Index: lucene/core/src/java/org/apache/lucene/search/TopFieldDocs.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopFieldDocs.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/TopFieldDocs.java	(working copy)
@@ -19,7 +19,7 @@
 
 
 /** Represents hits returned by {@link
- * IndexSearcher#search(Query,Filter,int,Sort)}.
+ * IndexSearcher#search(Query,int,Sort)}.
  */
 public class TopFieldDocs extends TopDocs {
 
Index: lucene/core/src/java/org/apache/lucene/search/package-info.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/package-info.java	(revision 1661864)
+++ lucene/core/src/java/org/apache/lucene/search/package-info.java	(working copy)
@@ -40,8 +40,7 @@
  * on implementing your own Query class, see <a href="#customQueriesExpert">Custom Queries -- Expert Level</a> below.
  * <p>
  * To perform a search, applications usually call {@link
- * org.apache.lucene.search.IndexSearcher#search(Query,int)} or {@link
- * org.apache.lucene.search.IndexSearcher#search(Query,Filter,int)}.
+ * org.apache.lucene.search.IndexSearcher#search(Query,int)}.
  * <p>
  * Once a Query has been created and submitted to the {@link org.apache.lucene.search.IndexSearcher IndexSearcher}, the scoring
  * process begins. After some infrastructure setup, control finally passes to the {@link org.apache.lucene.search.Weight Weight}
Index: lucene/core/src/test/org/apache/lucene/TestDemo.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestDemo.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/TestDemo.java	(working copy)
@@ -61,7 +61,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -73,7 +73,7 @@
     PhraseQuery phraseQuery = new PhraseQuery();
     phraseQuery.add(new Term("fieldname", "to"));
     phraseQuery.add(new Term("fieldname", "be"));
-    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);
+    assertEquals(1, isearcher.search(phraseQuery, 1).totalHits);
 
     ireader.close();
     directory.close();
Index: lucene/core/src/test/org/apache/lucene/TestSearch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestSearch.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/TestSearch.java	(working copy)
@@ -57,7 +57,7 @@
       try {
         IndexSearcher searcher = newSearcher(reader);
         
-        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+        ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
         assertEquals(1, hits.length);
         assertTrue("score is not negative: " + hits[0].score,
                    hits[0].score < 0);
@@ -147,7 +147,7 @@
           System.out.println("TEST: query=" + query);
         }
 
-        hits = searcher.search(query, null, 1000, sort).scoreDocs;
+        hits = searcher.search(query, 1000, sort).scoreDocs;
 
         out.println(hits.length + " total results");
         for (int i = 0 ; i < hits.length && i < 10; i++) {
Index: lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/TestSearchForDuplicates.java	(working copy)
@@ -117,7 +117,7 @@
       final Sort sort = new Sort(SortField.FIELD_SCORE,
                                  new SortField(ID_FIELD, SortField.Type.INT));
 
-      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;
+      ScoreDoc[] hits = searcher.search(query, MAX_DOCS, sort).scoreDocs;
       printHits(out, hits, searcher);
       checkHits(hits, MAX_DOCS, searcher);
 
@@ -130,7 +130,7 @@
       booleanQuery.add(new TermQuery(new Term(PRIORITY_FIELD, MED_PRIORITY)), BooleanClause.Occur.SHOULD);
       out.println("Query: " + booleanQuery.toString(PRIORITY_FIELD));
 
-      hits = searcher.search(booleanQuery, null, MAX_DOCS, sort).scoreDocs;
+      hits = searcher.search(booleanQuery, MAX_DOCS, sort).scoreDocs;
       printHits(out, hits, searcher);
       checkHits(hits, MAX_DOCS, searcher);
 
Index: lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat.java	(working copy)
@@ -107,7 +107,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
Index: lucene/core/src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -218,7 +218,7 @@
     Query query = new TermQuery(new Term("keyword", "test1"));
     
     // ensure that queries return expected results without DateFilter first
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
     doAssert(searcher.doc(hits[0].doc));
@@ -250,7 +250,7 @@
     query.add(new Term("indexed_not_tokenized", "test1"));
     query.add(new Term("indexed_not_tokenized", "test2"));
     
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
     doAssert(searcher.doc(hits[0].doc));
@@ -332,7 +332,7 @@
     Query query = new TermQuery(new Term("keyword", "test"));
     
     // ensure that queries return expected results without DateFilter first
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     int result = 0;
     for (int i = 0; i < 3; i++) {
Index: lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestCodecs.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestCodecs.java	(working copy)
@@ -304,17 +304,6 @@
     dir.close();
   }
 
-  private ScoreDoc[] search(final IndexWriter writer, final Query q, final int n) throws IOException {
-    final IndexReader reader = writer.getReader();
-    final IndexSearcher searcher = newSearcher(reader);
-    try {
-      return searcher.search(q, null, n).scoreDocs;
-    }
-    finally {
-      reader.close();
-    }
-  }
-
   private class Verify extends Thread {
     final Fields termsDict;
     final FieldData[] fields;
Index: lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(working copy)
@@ -672,7 +672,7 @@
         writer.close();
         IndexReader reader = DirectoryReader.open(dir);
         IndexSearcher searcher = newSearcher(reader);
-        ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+        ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
         assertEquals(16, hits.length);
         reader.close();
 
@@ -690,7 +690,7 @@
 
       IndexReader rwReader = DirectoryReader.open(dir);
       IndexSearcher searcher = newSearcher(rwReader);
-      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+      ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
       assertEquals(0, hits.length);
 
       // Simplistic check: just verify only the past N segments_N's still
@@ -708,7 +708,7 @@
           // Work backwards in commits on what the expected
           // count should be.
           searcher = newSearcher(reader);
-          hits = searcher.search(query, null, 1000).scoreDocs;
+          hits = searcher.search(query, 1000).scoreDocs;
           assertEquals(expectedCount, hits.length);
           if (expectedCount == 0) {
             expectedCount = 16;
Index: lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestDirectoryReaderReopen.java	(working copy)
@@ -272,7 +272,7 @@
                 IndexSearcher searcher = newSearcher(refreshed);
                 ScoreDoc[] hits = searcher.search(
                     new TermQuery(new Term("field1", "a" + rnd.nextInt(refreshed.maxDoc()))),
-                    null, 1000).scoreDocs;
+                    1000).scoreDocs;
                 if (hits.length > 0) {
                   searcher.doc(hits[0].doc);
                 }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -444,7 +444,7 @@
 
       IndexReader reader = DirectoryReader.open(dir);
       IndexSearcher searcher = newSearcher(reader);
-      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
       assertEquals(10, hits.length);
       reader.close();
 
@@ -466,7 +466,7 @@
       writer.close();
       reader = DirectoryReader.open(dir);
       searcher = newSearcher(reader);
-      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
       assertEquals(27, hits.length);
       reader.close();
 
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterCommit.java	(working copy)
@@ -52,7 +52,7 @@
       Term searchTerm = new Term("content", "aaa");
       DirectoryReader reader = DirectoryReader.open(dir);
       IndexSearcher searcher = newSearcher(reader);
-      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
       assertEquals("first number of hits", 14, hits.length);
       reader.close();
 
@@ -65,7 +65,7 @@
         }
         IndexReader r = DirectoryReader.open(dir);
         searcher = newSearcher(r);
-        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+        hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
         assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
         r.close();
         assertTrue("reader should have still been current", reader.isCurrent());
@@ -77,7 +77,7 @@
 
       IndexReader r = DirectoryReader.open(dir);
       searcher = newSearcher(r);
-      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
       assertEquals("reader did not see changes after writer was closed", 47, hits.length);
       r.close();
       reader.close();
@@ -108,7 +108,7 @@
     Term searchTerm = new Term("content", "aaa");
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
     assertEquals("first number of hits", 14, hits.length);
     reader.close();
 
@@ -123,7 +123,7 @@
 
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
     assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
     reader.close();
 
@@ -134,7 +134,7 @@
 
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
     assertEquals("saw changes after writer.abort", 14, hits.length);
     reader.close();
 
@@ -156,7 +156,7 @@
       }
       IndexReader r = DirectoryReader.open(dir);
       searcher = newSearcher(r);
-      hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+      hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
       assertEquals("reader incorrectly sees changes from writer", 14, hits.length);
       r.close();
     }
@@ -164,7 +164,7 @@
     writer.close();
     IndexReader r = DirectoryReader.open(dir);
     searcher = newSearcher(r);
-    hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+    hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
     assertEquals("didn't see changes after close", 218, hits.length);
     r.close();
 
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(working copy)
@@ -473,7 +473,7 @@
   private int getHitCount(Directory dir, Term term) throws IOException {
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    int hitCount = searcher.search(new TermQuery(term), null, 1000).totalHits;
+    int hitCount = searcher.search(new TermQuery(term), 1000).totalHits;
     reader.close();
     return hitCount;
   }
@@ -656,7 +656,7 @@
         IndexSearcher searcher = newSearcher(newReader);
         ScoreDoc[] hits = null;
         try {
-          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
         }
         catch (IOException e) {
           e.printStackTrace();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMaxDocs.java	(working copy)
@@ -67,7 +67,7 @@
       assertEquals(IndexWriter.MAX_DOCS, hits.totalHits);
 
       // Sort by docID reversed:
-      hits = searcher.search(new TermQuery(new Term("field", "text")), null, 10, new Sort(new SortField(null, SortField.Type.DOC, true)));
+      hits = searcher.search(new TermQuery(new Term("field", "text")), 10, new Sort(new SortField(null, SortField.Type.DOC, true)));
       assertEquals(IndexWriter.MAX_DOCS, hits.totalHits);
       assertEquals(10, hits.scoreDocs.length);
       assertEquals(IndexWriter.MAX_DOCS-1, hits.scoreDocs[0].doc);
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java	(working copy)
@@ -202,7 +202,7 @@
     assertEquals("first docFreq", 57, reader.docFreq(searchTerm));
     
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;
     assertEquals("first number of hits", 57, hits.length);
     reader.close();
     
@@ -396,7 +396,7 @@
           
           searcher = newSearcher(reader);
           try {
-            hits = searcher.search(new TermQuery(searchTerm), null, END_COUNT).scoreDocs;
+            hits = searcher.search(new TermQuery(searchTerm), END_COUNT).scoreDocs;
           } catch (IOException e) {
             e.printStackTrace(System.out);
             fail(testName + ": exception when searching: " + e);
Index: lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(working copy)
@@ -114,7 +114,7 @@
         PhraseQuery pq = new PhraseQuery();
         pq.add(new Term(this.field, this.term1));
         pq.add(new Term(this.field, this.term2));
-        return this.searcher.search(pq, null, 1000).scoreDocs;        
+        return this.searcher.search(pq, 1000).scoreDocs;        
     }
     
     private void performTest(int numHits) throws IOException {
Index: lucene/core/src/test/org/apache/lucene/index/TestManyFields.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestManyFields.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestManyFields.java	(working copy)
@@ -107,7 +107,7 @@
 
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    int totalHits = searcher.search(new TermQuery(new Term("field", "aaa")), null, 1).totalHits;
+    int totalHits = searcher.search(new TermQuery(new Term("field", "aaa")), 1).totalHits;
     assertEquals(n*100, totalHits);
     reader.close();
 
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(working copy)
@@ -402,8 +402,8 @@
   }
   
   private void queryTest(Query query) throws IOException {
-    ScoreDoc[] parallelHits = parallel.search(query, null, 1000).scoreDocs;
-    ScoreDoc[] singleHits = single.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] parallelHits = parallel.search(query, 1000).scoreDocs;
+    ScoreDoc[] singleHits = single.search(query, 1000).scoreDocs;
     assertEquals(parallelHits.length, singleHits.length);
     for(int i = 0; i < parallelHits.length; i++) {
       assertEquals(parallelHits[i].score, singleHits[i].score, 0.001f);
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelLeafReader.java	(working copy)
@@ -244,8 +244,8 @@
   }
 
   private void queryTest(Query query) throws IOException {
-    ScoreDoc[] parallelHits = parallel.search(query, null, 1000).scoreDocs;
-    ScoreDoc[] singleHits = single.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] parallelHits = parallel.search(query, 1000).scoreDocs;
+    ScoreDoc[] singleHits = single.search(query, 1000).scoreDocs;
     assertEquals(parallelHits.length, singleHits.length);
     for(int i = 0; i < parallelHits.length; i++) {
       assertEquals(parallelHits[i].score, singleHits[i].score, 0.001f);
Index: lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java	(working copy)
@@ -132,11 +132,11 @@
     // sometimes return a default impl around the scorer so that we can
     // compare BS1 and BS2
     TopScoreDocCollector collector = TopScoreDocCollector.create(1000);
-    searcher.search(query, null, collector);
+    searcher.search(query, collector);
     ScoreDoc[] hits1 = collector.topDocs().scoreDocs;
 
     collector = TopScoreDocCollector.create(1000);
-    searcher.search(query, null, collector);
+    searcher.search(query, collector);
     ScoreDoc[] hits2 = collector.topDocs().scoreDocs; 
 
     assertEquals(mulFactor * collector.totalHits,
@@ -285,13 +285,13 @@
         TopFieldCollector collector = TopFieldCollector.create(sort, 1000,
             false, true, true);
 
-        searcher.search(q1, null, collector);
+        searcher.search(q1, collector);
         ScoreDoc[] hits1 = collector.topDocs().scoreDocs;
 
         collector = TopFieldCollector.create(sort, 1000,
             false, true, true);
         
-        searcher.search(q1, null, collector);
+        searcher.search(q1, collector);
         ScoreDoc[] hits2 = collector.topDocs().scoreDocs;
         tot+=hits2.length;
         CheckHits.checkEqual(q1, hits1, hits2);
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(working copy)
@@ -87,7 +87,7 @@
 
     public void verifyNrHits(Query q, int expected) throws Exception {
         // bs1
-        ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+        ScoreDoc[] h = s.search(q, 1000).scoreDocs;
         if (expected != h.length) {
             printHits(getTestName(), h, s);
         }
@@ -349,8 +349,8 @@
         // Can't use Hits because normalized scores will mess things
         // up.  The non-sorting version of search() that returns TopDocs
         // will not normalize scores.
-        TopDocs top1 = s.search(q1,null,100);
-        TopDocs top2 = s.search(q2,null,100);
+        TopDocs top1 = s.search(q1,100);
+        TopDocs top2 = s.search(q2,100);
         if (i < 100) {
           QueryUtils.check(random(), q1,s);
           QueryUtils.check(random(), q2,s);
@@ -410,8 +410,8 @@
         BooleanQuery q2 = new BooleanQuery();
         q2.add(new TermQuery(new Term("data", "1")), BooleanClause.Occur.SHOULD);
         q2.setMinimumNumberShouldMatch(1);
-        TopDocs top1 = s.search(q1,null,100);
-        TopDocs top2 = s.search(q2,null,100);
+        TopDocs top1 = s.search(q1,100);
+        TopDocs top2 = s.search(q2,100);
         assertSubsetOfSameScores(q2, top1, top2);
       } finally {
         s.setSimilarity(oldSimilarity);
@@ -432,8 +432,8 @@
         BooleanQuery q2 = new BooleanQuery();
         q2.add(new TermQuery(new Term("data", "1")), BooleanClause.Occur.SHOULD);
         q2.add(new TermQuery(new Term("data", "Z")), BooleanClause.Occur.MUST_NOT);
-        TopDocs top1 = s.search(q1,null,100);
-        TopDocs top2 = s.search(q2,null,100);
+        TopDocs top1 = s.search(q1,100);
+        TopDocs top2 = s.search(q2,100);
         assertSubsetOfSameScores(q2, top1, top2);
       } finally {
         s.setSimilarity(oldSimilarity);
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java	(working copy)
@@ -52,7 +52,7 @@
 
   private int search(Query q) throws IOException {
     QueryUtils.check(random(), q,searcher);
-    return searcher.search(q, null, 1000).totalHits;
+    return searcher.search(q, 1000).totalHits;
   }
 
   public void testElements() throws IOException {
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java	(working copy)
@@ -55,7 +55,7 @@
     query.add(new TermQuery(new Term(FIELD, "9")), BooleanClause.Occur.MUST_NOT);
 
     IndexSearcher indexSearcher = newSearcher(ir);
-    ScoreDoc[] hits = indexSearcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = indexSearcher.search(query, 1000).scoreDocs;
     assertEquals("Number of matched documents", 2, hits.length);
     ir.close();
     directory.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(working copy)
@@ -71,16 +71,16 @@
     IOUtils.close(ir, dir);
     super.tearDown();
   }
-  
+
   private void assertFilterEquals(Filter f1, Filter f2) throws Exception {
     Query query = new MatchAllDocsQuery();
-    TopDocs hits1 = is.search(query, f1, ir.maxDoc());
-    TopDocs hits2 = is.search(query, f2, ir.maxDoc());
+    TopDocs hits1 = is.search(new FilteredQuery(query, f1), ir.maxDoc());
+    TopDocs hits2 = is.search(new FilteredQuery(query, f2), ir.maxDoc());
     assertEquals(hits1.totalHits, hits2.totalHits);
     CheckHits.checkEqual(query, hits1.scoreDocs, hits2.scoreDocs);
     // now do it again to confirm caching works
-    TopDocs hits3 = is.search(query, f1, ir.maxDoc());
-    TopDocs hits4 = is.search(query, f2, ir.maxDoc());
+    TopDocs hits3 = is.search(new FilteredQuery(query, f1), ir.maxDoc());
+    TopDocs hits4 = is.search(new FilteredQuery(query, f2), ir.maxDoc());
     assertEquals(hits3.totalHits, hits4.totalHits);
     CheckHits.checkEqual(query, hits3.scoreDocs, hits4.scoreDocs);
   }
@@ -319,7 +319,7 @@
 
     CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);
 
-    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
+    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);
     assertTrue(filter.ramBytesUsed() > 0);
 
     assertEquals("[query + filter] Should find a hit...", 1, docs.totalHits);
@@ -356,7 +356,7 @@
     searcher = newSearcher(reader, false);
 
     missCount = filter.missCount;
-    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
+    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);
     assertEquals("[query + filter] Should *not* find a hit...", 0, docs.totalHits);
 
     // cache hit
@@ -370,7 +370,7 @@
     reader = refreshReader(reader);
     searcher = newSearcher(reader, false);
 
-    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
+    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);
     assertEquals("[query + filter] Should find a hit...", 1, docs.totalHits);
     missCount = filter.missCount;
     assertTrue(missCount > 0);
@@ -389,7 +389,7 @@
     reader = refreshReader(reader);
     searcher = newSearcher(reader, false);
         
-    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
+    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);
     assertEquals("[query + filter] Should find 2 hits...", 2, docs.totalHits);
     assertTrue(filter.missCount > missCount);
     missCount = filter.missCount;
@@ -405,7 +405,7 @@
     reader = refreshReader(reader);
     searcher = newSearcher(reader, false);
 
-    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);
+    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);
     assertEquals("[query + filter] Should *not* find a hit...", 0, docs.totalHits);
     // CWF reused the same entry (it dynamically applied the deletes):
     assertEquals(missCount, filter.missCount);
Index: lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java	(working copy)
@@ -144,12 +144,12 @@
     Query query = new ConstantScoreQuery(filterB);
 
     IndexSearcher s = newSearcher(r);
-    assertEquals(1, s.search(query, filterB, 1).totalHits); // Query for field:b, Filter field:b
+    assertEquals(1, s.search(new FilteredQuery(query, filterB), 1).totalHits); // Query for field:b, Filter field:b
 
     Filter filterA = new CachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("field", "a"))));
     query = new ConstantScoreQuery(filterA);
 
-    assertEquals(0, s.search(query, filterB, 1).totalHits); // Query field:b, Filter field:a
+    assertEquals(0, s.search(new FilteredQuery(query, filterB), 1).totalHits); // Query field:b, Filter field:a
 
     r.close();
     d.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(working copy)
@@ -112,7 +112,7 @@
   // make sure the documents returned by the search match the expected list
   private void matchHits(IndexSearcher searcher, Sort sort) throws IOException {
     // make a query without sorting first
-    ScoreDoc[] hitsByRank = searcher.search(query, null, Integer.MAX_VALUE).scoreDocs;
+    ScoreDoc[] hitsByRank = searcher.search(query, Integer.MAX_VALUE).scoreDocs;
     checkHits(hitsByRank, "Sort by rank: "); // check for duplicates
     Map<Integer,Integer> resultMap = new TreeMap<>();
     // store hits in TreeMap - TreeMap does not allow duplicates; existing
@@ -124,7 +124,7 @@
     }
     
     // now make a query using the sort criteria
-    ScoreDoc[] resultSort = searcher.search(query, null, Integer.MAX_VALUE,
+    ScoreDoc[] resultSort = searcher.search(query, Integer.MAX_VALUE,
         sort).scoreDocs;
     checkHits(resultSort, "Sort by custom criteria: "); // check for duplicates
     
@@ -192,23 +192,23 @@
     }
     
     @Override
-    public TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort)
+    public TopFieldDocs search(Query query, int nDocs, Sort sort)
         throws IOException {
       BooleanQuery bq = new BooleanQuery();
       bq.add(query, BooleanClause.Occur.MUST);
       bq.add(new TermQuery(new Term("mandant", Integer.toString(switcher))),
           BooleanClause.Occur.MUST);
-      return super.search(bq, filter, nDocs, sort);
+      return super.search(bq, nDocs, sort);
     }
     
     @Override
-    public TopDocs search(Query query, Filter filter, int nDocs)
+    public TopDocs search(Query query, int nDocs)
         throws IOException {
       BooleanQuery bq = new BooleanQuery();
       bq.add(query, BooleanClause.Occur.MUST);
       bq.add(new TermQuery(new Term("mandant", Integer.toString(switcher))),
           BooleanClause.Occur.MUST);
-      return super.search(bq, filter, nDocs);
+      return super.search(bq, nDocs);
     }
   }
   
Index: lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java	(working copy)
@@ -76,23 +76,23 @@
     ScoreDoc[] result;
     
     // ensure that queries return expected results without DateFilter first
-    result = searcher.search(query1, null, 1000).scoreDocs;
+    result = searcher.search(query1, 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query2, null, 1000).scoreDocs;
+    result = searcher.search(query2, 1000).scoreDocs;
     assertEquals(1, result.length);
     
     // run queries with DateFilter
-    result = searcher.search(query1, df1, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query1, df1), 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query1, df2, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query1, df2), 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query2, df1, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query2, df1), 1000).scoreDocs;
     assertEquals(1, result.length);
     
-    result = searcher.search(query2, df2, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query2, df2), 1000).scoreDocs;
     assertEquals(0, result.length);
     reader.close();
     indexStore.close();
@@ -140,23 +140,23 @@
     ScoreDoc[] result;
     
     // ensure that queries return expected results without DateFilter first
-    result = searcher.search(query1, null, 1000).scoreDocs;
+    result = searcher.search(query1, 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query2, null, 1000).scoreDocs;
+    result = searcher.search(query2, 1000).scoreDocs;
     assertEquals(1, result.length);
     
     // run queries with DateFilter
-    result = searcher.search(query1, df1, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query1, df1), 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query1, df2, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query1, df2), 1000).scoreDocs;
     assertEquals(0, result.length);
     
-    result = searcher.search(query2, df1, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query2, df1), 1000).scoreDocs;
     assertEquals(1, result.length);
     
-    result = searcher.search(query2, df2, 1000).scoreDocs;
+    result = searcher.search(new FilteredQuery(query2, df2), 1000).scoreDocs;
     assertEquals(0, result.length);
     reader.close();
     indexStore.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestDateSort.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDateSort.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestDateSort.java	(working copy)
@@ -83,7 +83,7 @@
 
     // Execute the search and process the search results.
     String[] actualOrder = new String[5];
-    ScoreDoc[] hits = searcher.search(query, null, 1000, sort).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000, sort).scoreDocs;
     for (int i = 0; i < hits.length; i++) {
       StoredDocument document = searcher.doc(hits[i].doc);
       String text = document.get(TEXT_FIELD);
Index: lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(working copy)
@@ -209,7 +209,7 @@
     q.add(tq("hed", "elephant"));
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("all docs should match " + q.toString(), 4, h.length);
@@ -233,7 +233,7 @@
     q.add(tq("dek", "elephant"));
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("3 docs should match " + q.toString(), 3, h.length);
@@ -258,7 +258,7 @@
     q.add(tq("dek", "elephant"));
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("all docs should match " + q.toString(), 4, h.length);
@@ -281,7 +281,7 @@
     q.add(tq("dek", "elephant"));
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("3 docs should match " + q.toString(), 3, h.length);
@@ -320,7 +320,7 @@
     
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("3 docs should match " + q.toString(), 3, h.length);
@@ -352,7 +352,7 @@
     }
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       assertEquals("4 docs should match " + q.toString(), 4, h.length);
@@ -388,7 +388,7 @@
     }
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       
@@ -442,7 +442,7 @@
     }
     QueryUtils.check(random(), q, s);
     
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     
     try {
       
Index: lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java	(working copy)
@@ -133,7 +133,7 @@
       }
     };
     
-    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);
+    Assert.assertEquals(0, searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), 10).totalHits);
     reader.close();
     dir.close();
   }
@@ -179,7 +179,7 @@
       }
     };
     
-    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);
+    Assert.assertEquals(0, searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), 10).totalHits);
     reader.close();
     dir.close();
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestElevationComparator.java	(working copy)
@@ -80,7 +80,7 @@
       );
 
     TopDocsCollector<Entry> topCollector = TopFieldCollector.create(sort, 50, false, true, true);
-    searcher.search(newq, null, topCollector);
+    searcher.search(newq, topCollector);
 
     TopDocs topDocs = topCollector.topDocs(0, 10);
     int nDocsReturned = topDocs.scoreDocs.length;
Index: lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java	(working copy)
@@ -21,7 +21,6 @@
 import org.apache.lucene.document.SortedDocValuesField;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -57,18 +56,18 @@
 
     List<String> terms = new ArrayList<>();
     terms.add("5");
-    results = searcher.search(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    results = searcher.search(new FilteredQuery(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0]))), numDocs).scoreDocs;
     assertEquals("Must match nothing", 0, results.length);
 
     terms = new ArrayList<>();
     terms.add("10");
-    results = searcher.search(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    results = searcher.search(new FilteredQuery(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0]))), numDocs).scoreDocs;
     assertEquals("Must match 1", 1, results.length);
 
     terms = new ArrayList<>();
     terms.add("10");
     terms.add("20");
-    results = searcher.search(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    results = searcher.search(new FilteredQuery(q, new DocValuesTermsFilter(fieldName,  terms.toArray(new String[0]))), numDocs).scoreDocs;
     assertEquals("Must match 2", 2, results.length);
 
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestFilteredQuery.java	(working copy)
@@ -136,33 +136,33 @@
 
   private void tFilteredQuery(final boolean useRandomAccess) throws Exception {
     Query filteredquery = new FilteredQuery(query, filter, randomFilterStrategy(random(), useRandomAccess));
-    ScoreDoc[] hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search (filteredquery, 1000).scoreDocs;
     assertEquals (1, hits.length);
     assertEquals (1, hits[0].doc);
     QueryUtils.check(random(), filteredquery,searcher);
 
-    hits = searcher.search (filteredquery, null, 1000, new Sort(new SortField("sorter", SortField.Type.STRING))).scoreDocs;
+    hits = searcher.search (filteredquery, 1000, new Sort(new SortField("sorter", SortField.Type.STRING))).scoreDocs;
     assertEquals (1, hits.length);
     assertEquals (1, hits[0].doc);
 
     filteredquery = new FilteredQuery(new TermQuery (new Term ("field", "one")), filter, randomFilterStrategy(random(), useRandomAccess));
-    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    hits = searcher.search (filteredquery, 1000).scoreDocs;
     assertEquals (2, hits.length);
     QueryUtils.check(random(), filteredquery,searcher);
 
     filteredquery = new FilteredQuery(new MatchAllDocsQuery(), filter, randomFilterStrategy(random(), useRandomAccess));
-    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    hits = searcher.search (filteredquery, 1000).scoreDocs;
     assertEquals (2, hits.length);
     QueryUtils.check(random(), filteredquery,searcher);
 
     filteredquery = new FilteredQuery(new TermQuery (new Term ("field", "x")), filter, randomFilterStrategy(random(), useRandomAccess));
-    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    hits = searcher.search (filteredquery, 1000).scoreDocs;
     assertEquals (1, hits.length);
     assertEquals (3, hits[0].doc);
     QueryUtils.check(random(), filteredquery,searcher);
 
     filteredquery = new FilteredQuery(new TermQuery (new Term ("field", "y")), filter, randomFilterStrategy(random(), useRandomAccess));
-    hits = searcher.search (filteredquery, null, 1000).scoreDocs;
+    hits = searcher.search (filteredquery, 1000).scoreDocs;
     assertEquals (0, hits.length);
     QueryUtils.check(random(), filteredquery,searcher);
     
@@ -209,8 +209,8 @@
    * Tests whether the scores of the two queries are the same.
    */
   public void assertScoreEquals(Query q1, Query q2) throws Exception {
-    ScoreDoc[] hits1 = searcher.search (q1, null, 1000).scoreDocs;
-    ScoreDoc[] hits2 = searcher.search (q2, null, 1000).scoreDocs;
+    ScoreDoc[] hits1 = searcher.search (q1, 1000).scoreDocs;
+    ScoreDoc[] hits2 = searcher.search (q2, 1000).scoreDocs;
       
     assertEquals(hits1.length, hits2.length);
     
@@ -233,7 +233,7 @@
         "sorter", "b", "d", true, true);
 
     Query filteredquery = new FilteredQuery(rq, filter, randomFilterStrategy(random(), useRandomAccess));
-    ScoreDoc[] hits = searcher.search(filteredquery, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(filteredquery, 1000).scoreDocs;
     assertEquals(2, hits.length);
     QueryUtils.check(random(), filteredquery,searcher);
   }
@@ -251,7 +251,7 @@
     bq.add(query, BooleanClause.Occur.MUST);
     query = new FilteredQuery(new TermQuery(new Term("field", "one")), new SingleDocTestFilter(1), randomFilterStrategy(random(), useRandomAccess));
     bq.add(query, BooleanClause.Occur.MUST);
-    ScoreDoc[] hits = searcher.search(bq, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(bq, 1000).scoreDocs;
     assertEquals(0, hits.length);
     QueryUtils.check(random(), query,searcher);    
   }
@@ -269,7 +269,7 @@
     bq.add(query, BooleanClause.Occur.SHOULD);
     query = new FilteredQuery(new TermQuery(new Term("field", "one")), new SingleDocTestFilter(1), randomFilterStrategy(random(), useRandomAccess));
     bq.add(query, BooleanClause.Occur.SHOULD);
-    ScoreDoc[] hits = searcher.search(bq, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(bq, 1000).scoreDocs;
     assertEquals(2, hits.length);
     QueryUtils.check(random(), query,searcher);    
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestFilteredSearch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestFilteredSearch.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestFilteredSearch.java	(working copy)
@@ -75,7 +75,7 @@
      
     IndexReader reader = DirectoryReader.open(directory);
     IndexSearcher indexSearcher = newSearcher(reader);
-    ScoreDoc[] hits = indexSearcher.search(booleanQuery, filter, 1000).scoreDocs;
+    ScoreDoc[] hits = indexSearcher.search(new FilteredQuery(booleanQuery, filter), 1000).scoreDocs;
     assertEquals("Number of matched documents", 1, hits.length);
     reader.close();
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(working copy)
@@ -48,7 +48,7 @@
     writer.close();
 
     FuzzyQuery query = new FuzzyQuery(new Term("field", "abc"), FuzzyQuery.defaultMaxEdits, 1);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     reader.close();
     directory.close();
@@ -70,32 +70,32 @@
     writer.close();
 
     FuzzyQuery query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 0);   
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     
     // same with prefix
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(2, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 6);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
     // test scoring
     query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMaxEdits, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("3 documents should match", 3, hits.length);
     List<String> order = Arrays.asList("bbbbb","abbbb","aabbb");
     for (int i = 0; i < hits.length; i++) {
@@ -107,7 +107,7 @@
     // test pq size by supplying maxExpansions=2
     // This query would normally return 3 documents, because 3 terms match (see above):
     query = new FuzzyQuery(new Term("field", "bbbbb"), FuzzyQuery.defaultMaxEdits, 0, 2, false); 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("only 2 documents should match", 2, hits.length);
     order = Arrays.asList("bbbbb","abbbb");
     for (int i = 0; i < hits.length; i++) {
@@ -118,15 +118,15 @@
 
     // not similar enough:
     query = new FuzzyQuery(new Term("field", "xxxxx"), FuzzyQuery.defaultMaxEdits, 0);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     query = new FuzzyQuery(new Term("field", "aaccc"), FuzzyQuery.defaultMaxEdits, 0);   // edit distance to "aaaaa" = 3
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // query identical to a word in the index:
     query = new FuzzyQuery(new Term("field", "aaaaa"), FuzzyQuery.defaultMaxEdits, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     // default allows for up to two edits:
@@ -135,7 +135,7 @@
 
     // query similar to a word in the index:
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
@@ -143,63 +143,63 @@
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(2, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     query = new FuzzyQuery(new Term("field", "aaaac"), FuzzyQuery.defaultMaxEdits, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
 
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     
     // now with prefix
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new FuzzyQuery(new Term("field", "ddddX"), FuzzyQuery.defaultMaxEdits, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
 
     // different field = no match:
     query = new FuzzyQuery(new Term("anotherfield", "ddddX"), FuzzyQuery.defaultMaxEdits, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     reader.close();
@@ -234,7 +234,7 @@
 
     FuzzyQuery query = new FuzzyQuery(new Term("field", "WEBER"), 2, 1);
     //query.setRewriteMethod(FuzzyQuery.SCORING_BOOLEAN_QUERY_REWRITE);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(8, hits.length);
 
     reader.close();
@@ -296,7 +296,7 @@
     
     FuzzyQuery query = new FuzzyQuery(new Term("field", "lucene"));
     query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(50));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     // normally, 'Lucenne' would be the first result as IDF will skew the score.
     assertEquals("Lucene", reader.document(hits[0].doc).get("field"));
Index: lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestIndexSearcher.java	(working copy)
@@ -81,10 +81,6 @@
         null,
         new Sort(new SortField("field2", SortField.Type.STRING))
     };
-    Filter filters[] = new Filter[] {
-        null,
-        new QueryWrapperFilter(new TermQuery(new Term("field2", "true")))
-    };
     ScoreDoc afters[] = new ScoreDoc[] {
         null,
         new FieldDoc(0, 0f, new Object[] { new BytesRef("boo!") })
@@ -94,24 +90,19 @@
       for (ScoreDoc after : afters) {
         for (Query query : queries) {
           for (Sort sort : sorts) {
-            for (Filter filter : filters) {
-              searcher.search(query, Integer.MAX_VALUE);
-              searcher.searchAfter(after, query, Integer.MAX_VALUE);
-              searcher.search(query, filter, Integer.MAX_VALUE);
-              searcher.searchAfter(after, query, filter, Integer.MAX_VALUE);
-              if (sort != null) {
-                searcher.search(query, Integer.MAX_VALUE, sort);
-                searcher.search(query, filter, Integer.MAX_VALUE, sort);
-                searcher.search(query, filter, Integer.MAX_VALUE, sort, true, true);
-                searcher.search(query, filter, Integer.MAX_VALUE, sort, true, false);
-                searcher.search(query, filter, Integer.MAX_VALUE, sort, false, true);
-                searcher.search(query, filter, Integer.MAX_VALUE, sort, false, false);
-                searcher.searchAfter(after, query, filter, Integer.MAX_VALUE, sort);
-                searcher.searchAfter(after, query, filter, Integer.MAX_VALUE, sort, true, true);
-                searcher.searchAfter(after, query, filter, Integer.MAX_VALUE, sort, true, false);
-                searcher.searchAfter(after, query, filter, Integer.MAX_VALUE, sort, false, true);
-                searcher.searchAfter(after, query, filter, Integer.MAX_VALUE, sort, false, false);
-              }
+            searcher.search(query, Integer.MAX_VALUE);
+            searcher.searchAfter(after, query, Integer.MAX_VALUE);
+            if (sort != null) {
+              searcher.search(query, Integer.MAX_VALUE, sort);
+              searcher.search(query, Integer.MAX_VALUE, sort, true, true);
+              searcher.search(query, Integer.MAX_VALUE, sort, true, false);
+              searcher.search(query, Integer.MAX_VALUE, sort, false, true);
+              searcher.search(query, Integer.MAX_VALUE, sort, false, false);
+              searcher.searchAfter(after, query, Integer.MAX_VALUE, sort);
+              searcher.searchAfter(after, query, Integer.MAX_VALUE, sort, true, true);
+              searcher.searchAfter(after, query, Integer.MAX_VALUE, sort, true, false);
+              searcher.searchAfter(after, query, Integer.MAX_VALUE, sort, false, true);
+              searcher.searchAfter(after, query, Integer.MAX_VALUE, sort, false, false);
             }
           }
         }
Index: lucene/core/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java	(working copy)
@@ -54,7 +54,7 @@
     IndexSearcher is = newSearcher(ir);
     ScoreDoc[] hits;
     
-    hits = is.search(new MatchAllDocsQuery(), null, 1000).scoreDocs;
+    hits = is.search(new MatchAllDocsQuery(), 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals("one", is.doc(hits[0].doc).get("key"));
     assertEquals("two", is.doc(hits[1].doc).get("key"));
@@ -65,13 +65,13 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
-    hits = is.search(bq, null, 1000).scoreDocs;
+    hits = is.search(bq, 1000).scoreDocs;
     assertEquals(3, hits.length);
 
     bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);
     bq.add(new TermQuery(new Term("key", "three")), BooleanClause.Occur.MUST);
-    hits = is.search(bq, null, 1000).scoreDocs;
+    hits = is.search(bq, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     iw.deleteDocuments(new Term("key", "one"));
@@ -79,7 +79,7 @@
     ir = DirectoryReader.open(iw, true);
     is = newSearcher(ir);
     
-    hits = is.search(new MatchAllDocsQuery(), null, 1000).scoreDocs;
+    hits = is.search(new MatchAllDocsQuery(), 1000).scoreDocs;
     assertEquals(2, hits.length);
 
     iw.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(working copy)
@@ -90,9 +90,9 @@
         .toString());
     
     ScoreDoc[] result;
-    result = searcher.search(query1, null, 1000).scoreDocs;
+    result = searcher.search(query1, 1000).scoreDocs;
     assertEquals(2, result.length);
-    result = searcher.search(query2, null, 1000).scoreDocs;
+    result = searcher.search(query2, 1000).scoreDocs;
     assertEquals(0, result.length);
     
     // search for "blue* pizza":
@@ -110,13 +110,13 @@
     query3.add(termsWithPrefix.toArray(new Term[0]));
     query3.add(new Term("body", "pizza"));
     
-    result = searcher.search(query3, null, 1000).scoreDocs;
+    result = searcher.search(query3, 1000).scoreDocs;
     assertEquals(2, result.length); // blueberry pizza, bluebird pizza
     assertEquals("body:\"(blueberry bluebird) pizza\"", query3.toString());
     
     // test slop:
     query3.setSlop(1);
-    result = searcher.search(query3, null, 1000).scoreDocs;
+    result = searcher.search(query3, 1000).scoreDocs;
     
     // just make sure no exc:
     searcher.explain(query3, 0);
@@ -224,7 +224,7 @@
     q.add(trouble, BooleanClause.Occur.MUST);
     
     // exception will be thrown here without fix
-    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
     
     assertEquals("Wrong number of hits", 2, hits.length);
     
@@ -256,7 +256,7 @@
     q.add(trouble, BooleanClause.Occur.MUST);
     
     // exception will be thrown here without fix for #35626:
-    ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
     assertEquals("Wrong number of hits", 0, hits.length);
     writer.close();
     reader.close();
@@ -275,7 +275,7 @@
     q.add(new Term("body", "a"));
     q.add(new Term[] {new Term("body", "nope"), new Term("body", "nope")});
     assertEquals("Wrong number of hits", 0,
-        searcher.search(q, null, 1).totalHits);
+        searcher.search(q, 1).totalHits);
     
     // just make sure no exc:
     searcher.explain(q, 0);
Index: lucene/core/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(working copy)
@@ -143,7 +143,7 @@
 
     // some hits match more terms then others, score should be the same
 
-    result = search.search(csrq("data", "1", "6", T, T), null, 1000).scoreDocs;
+    result = search.search(csrq("data", "1", "6", T, T), 1000).scoreDocs;
     int numHits = result.length;
     assertEquals("wrong number of results", 6, numHits);
     float score = result[0].score;
@@ -152,7 +152,7 @@
           result[i].score, SCORE_COMP_THRESH);
     }
 
-    result = search.search(csrq("data", "1", "6", T, T, MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE), null, 1000).scoreDocs;
+    result = search.search(csrq("data", "1", "6", T, T, MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE), 1000).scoreDocs;
     numHits = result.length;
     assertEquals("wrong number of results", 6, numHits);
     for (int i = 0; i < numHits; i++) {
@@ -160,7 +160,7 @@
           result[i].score, SCORE_COMP_THRESH);
     }
 
-    result = search.search(csrq("data", "1", "6", T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, 1000).scoreDocs;
+    result = search.search(csrq("data", "1", "6", T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), 1000).scoreDocs;
     numHits = result.length;
     assertEquals("wrong number of results", 6, numHits);
     for (int i = 0; i < numHits; i++) {
@@ -182,7 +182,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(dummyTerm, BooleanClause.Occur.SHOULD); // hits one doc
     bq.add(csrq("data", "#", "#", T, T), BooleanClause.Occur.SHOULD); // hits no docs
-    result = search.search(bq, null, 1000).scoreDocs;
+    result = search.search(bq, 1000).scoreDocs;
     int numHits = result.length;
     assertEquals("wrong number of results", 1, numHits);
     float score = result[0].score;
@@ -194,7 +194,7 @@
     bq = new BooleanQuery();
     bq.add(dummyTerm, BooleanClause.Occur.SHOULD); // hits one doc
     bq.add(csrq("data", "#", "#", T, T, MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE), BooleanClause.Occur.SHOULD); // hits no docs
-    result = search.search(bq, null, 1000).scoreDocs;
+    result = search.search(bq, 1000).scoreDocs;
     numHits = result.length;
     assertEquals("wrong number of results", 1, numHits);
     for (int i = 0; i < numHits; i++) {
@@ -205,7 +205,7 @@
     bq = new BooleanQuery();
     bq.add(dummyTerm, BooleanClause.Occur.SHOULD); // hits one doc
     bq.add(csrq("data", "#", "#", T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), BooleanClause.Occur.SHOULD); // hits no docs
-    result = search.search(bq, null, 1000).scoreDocs;
+    result = search.search(bq, 1000).scoreDocs;
     numHits = result.length;
     assertEquals("wrong number of results", 1, numHits);
     for (int i = 0; i < numHits; i++) {
@@ -226,7 +226,7 @@
     search.setSimilarity(new DefaultSimilarity());
     Query q = csrq("data", "1", "6", T, T);
     q.setBoost(100);
-    search.search(q, null, new SimpleCollector() {
+    search.search(q, new SimpleCollector() {
       private int base = 0;
       private Scorer scorer;
       @Override
@@ -259,7 +259,7 @@
     bq.add(q1, BooleanClause.Occur.SHOULD);
     bq.add(q2, BooleanClause.Occur.SHOULD);
 
-    ScoreDoc[] hits = search.search(bq, null, 1000).scoreDocs;
+    ScoreDoc[] hits = search.search(bq, 1000).scoreDocs;
     Assert.assertEquals(1, hits[0].doc);
     Assert.assertEquals(0, hits[1].doc);
     assertTrue(hits[0].score > hits[1].score);
@@ -271,7 +271,7 @@
     bq.add(q1, BooleanClause.Occur.SHOULD);
     bq.add(q2, BooleanClause.Occur.SHOULD);
 
-    hits = search.search(bq, null, 1000).scoreDocs;
+    hits = search.search(bq, 1000).scoreDocs;
     Assert.assertEquals(1, hits[0].doc);
     Assert.assertEquals(0, hits[1].doc);
     assertTrue(hits[0].score > hits[1].score);
@@ -283,7 +283,7 @@
     bq.add(q1, BooleanClause.Occur.SHOULD);
     bq.add(q2, BooleanClause.Occur.SHOULD);
 
-    hits = search.search(bq, null, 1000).scoreDocs;
+    hits = search.search(bq, 1000).scoreDocs;
     Assert.assertEquals(0, hits[0].doc);
     Assert.assertEquals(1, hits[1].doc);
     assertTrue(hits[0].score > hits[1].score);
@@ -300,7 +300,7 @@
 
     Query rq = TermRangeQuery.newStringRange("data", "1", "4", T, T);
 
-    ScoreDoc[] expected = search.search(rq, null, 1000).scoreDocs;
+    ScoreDoc[] expected = search.search(rq, 1000).scoreDocs;
     int numHits = expected.length;
 
     // now do a boolean where which also contains a
@@ -310,7 +310,7 @@
     q.add(rq, BooleanClause.Occur.MUST);// T, F);
     q.add(csrq("data", "1", "6", T, T), BooleanClause.Occur.MUST);// T, F);
 
-    ScoreDoc[] actual = search.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] actual = search.search(q, 1000).scoreDocs;
 
     assertEquals("wrong numebr of hits", numHits, actual.length);
     for (int i = 0; i < numHits; i++) {
@@ -344,110 +344,110 @@
 
     // test id, bounded on both ends
 
-    result = search.search(csrq("id", minIP, maxIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, T, T), numDocs).scoreDocs;
     assertEquals("find all", numDocs, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("find all", numDocs, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, T, F), numDocs).scoreDocs;
     assertEquals("all but last", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, T, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, T, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("all but last", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, F, T), numDocs).scoreDocs;
     assertEquals("all but first", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, F, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, F, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("all but first", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, F, F), numDocs).scoreDocs;
     assertEquals("all but ends", numDocs - 2, result.length);
 
-    result = search.search(csrq("id", minIP, maxIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, maxIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("all but ends", numDocs - 2, result.length);
 
-    result = search.search(csrq("id", medIP, maxIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, maxIP, T, T), numDocs).scoreDocs;
     assertEquals("med and up", 1 + maxId - medId, result.length);
 
-    result = search.search(csrq("id", medIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("med and up", 1 + maxId - medId, result.length);
 
-    result = search.search(csrq("id", minIP, medIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, medIP, T, T), numDocs).scoreDocs;
     assertEquals("up to med", 1 + medId - minId, result.length);
 
-    result = search.search(csrq("id", minIP, medIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, medIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("up to med", 1 + medId - minId, result.length);
 
     // unbounded id
 
-    result = search.search(csrq("id", minIP, null, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, null, T, F), numDocs).scoreDocs;
     assertEquals("min and up", numDocs, result.length);
 
-    result = search.search(csrq("id", null, maxIP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", null, maxIP, F, T), numDocs).scoreDocs;
     assertEquals("max and down", numDocs, result.length);
 
-    result = search.search(csrq("id", minIP, null, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, null, F, F), numDocs).scoreDocs;
     assertEquals("not min, but up", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", null, maxIP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", null, maxIP, F, F), numDocs).scoreDocs;
     assertEquals("not max, but down", numDocs - 1, result.length);
 
-    result = search.search(csrq("id", medIP, maxIP, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, maxIP, T, F), numDocs).scoreDocs;
     assertEquals("med and up, not max", maxId - medId, result.length);
 
-    result = search.search(csrq("id", minIP, medIP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, medIP, F, T), numDocs).scoreDocs;
     assertEquals("not min, up to med", medId - minId, result.length);
 
     // very small sets
 
-    result = search.search(csrq("id", minIP, minIP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, minIP, F, F), numDocs).scoreDocs;
     assertEquals("min,min,F,F", 0, result.length);
 
-    result = search.search(csrq("id", minIP, minIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, minIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("min,min,F,F", 0, result.length);
 
-    result = search.search(csrq("id", medIP, medIP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, medIP, F, F), numDocs).scoreDocs;
     assertEquals("med,med,F,F", 0, result.length);
 
-    result = search.search(csrq("id", medIP, medIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, medIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("med,med,F,F", 0, result.length);
 
-    result = search.search(csrq("id", maxIP, maxIP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, maxIP, F, F), numDocs).scoreDocs;
     assertEquals("max,max,F,F", 0, result.length);
 
-    result = search.search(csrq("id", maxIP, maxIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, maxIP, F, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("max,max,F,F", 0, result.length);
 
-    result = search.search(csrq("id", minIP, minIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, minIP, T, T), numDocs).scoreDocs;
     assertEquals("min,min,T,T", 1, result.length);
 
-    result = search.search(csrq("id", minIP, minIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", minIP, minIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("min,min,T,T", 1, result.length);
 
-    result = search.search(csrq("id", null, minIP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", null, minIP, F, T), numDocs).scoreDocs;
     assertEquals("nul,min,F,T", 1, result.length);
 
-    result = search.search(csrq("id", null, minIP, F, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", null, minIP, F, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("nul,min,F,T", 1, result.length);
 
-    result = search.search(csrq("id", maxIP, maxIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, maxIP, T, T), numDocs).scoreDocs;
     assertEquals("max,max,T,T", 1, result.length);
 
-    result = search.search(csrq("id", maxIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, maxIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("max,max,T,T", 1, result.length);
 
-    result = search.search(csrq("id", maxIP, null, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, null, T, F), numDocs).scoreDocs;
     assertEquals("max,nul,T,T", 1, result.length);
 
-    result = search.search(csrq("id", maxIP, null, T, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", maxIP, null, T, F, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("max,nul,T,T", 1, result.length);
 
-    result = search.search(csrq("id", medIP, medIP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, medIP, T, T), numDocs).scoreDocs;
     assertEquals("med,med,T,T", 1, result.length);
 
-    result = search.search(csrq("id", medIP, medIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), null, numDocs).scoreDocs;
+    result = search.search(csrq("id", medIP, medIP, T, T, MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE), numDocs).scoreDocs;
     assertEquals("med,med,T,T", 1, result.length);
   }
 
@@ -469,47 +469,47 @@
 
     // test extremes, bounded on both ends
 
-    result = search.search(csrq("rand", minRP, maxRP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, maxRP, T, T), numDocs).scoreDocs;
     assertEquals("find all", numDocs, result.length);
 
-    result = search.search(csrq("rand", minRP, maxRP, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, maxRP, T, F), numDocs).scoreDocs;
     assertEquals("all but biggest", numDocs - 1, result.length);
 
-    result = search.search(csrq("rand", minRP, maxRP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, maxRP, F, T), numDocs).scoreDocs;
     assertEquals("all but smallest", numDocs - 1, result.length);
 
-    result = search.search(csrq("rand", minRP, maxRP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, maxRP, F, F), numDocs).scoreDocs;
     assertEquals("all but extremes", numDocs - 2, result.length);
 
     // unbounded
 
-    result = search.search(csrq("rand", minRP, null, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, null, T, F), numDocs).scoreDocs;
     assertEquals("smallest and up", numDocs, result.length);
 
-    result = search.search(csrq("rand", null, maxRP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", null, maxRP, F, T), numDocs).scoreDocs;
     assertEquals("biggest and down", numDocs, result.length);
 
-    result = search.search(csrq("rand", minRP, null, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, null, F, F), numDocs).scoreDocs;
     assertEquals("not smallest, but up", numDocs - 1, result.length);
 
-    result = search.search(csrq("rand", null, maxRP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", null, maxRP, F, F), numDocs).scoreDocs;
     assertEquals("not biggest, but down", numDocs - 1, result.length);
 
     // very small sets
 
-    result = search.search(csrq("rand", minRP, minRP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, minRP, F, F), numDocs).scoreDocs;
     assertEquals("min,min,F,F", 0, result.length);
-    result = search.search(csrq("rand", maxRP, maxRP, F, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", maxRP, maxRP, F, F), numDocs).scoreDocs;
     assertEquals("max,max,F,F", 0, result.length);
 
-    result = search.search(csrq("rand", minRP, minRP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", minRP, minRP, T, T), numDocs).scoreDocs;
     assertEquals("min,min,T,T", 1, result.length);
-    result = search.search(csrq("rand", null, minRP, F, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", null, minRP, F, T), numDocs).scoreDocs;
     assertEquals("nul,min,F,T", 1, result.length);
 
-    result = search.search(csrq("rand", maxRP, maxRP, T, T), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", maxRP, maxRP, T, T), numDocs).scoreDocs;
     assertEquals("max,max,T,T", 1, result.length);
-    result = search.search(csrq("rand", maxRP, null, T, F), null, numDocs).scoreDocs;
+    result = search.search(csrq("rand", maxRP, null, T, F), numDocs).scoreDocs;
     assertEquals("max,nul,T,T", 1, result.length);
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java	(working copy)
@@ -80,7 +80,7 @@
     Query query = new MatchAllDocsQuery();
     Query term = new TermQuery(new Term("field", "this"));
     Filter filter = new QueryWrapperFilter(new AssertNeedsScores(term, false));
-    assertEquals(5, searcher.search(query, filter, 5).totalHits);
+    assertEquals(5, searcher.search(new FilteredQuery(query, filter), 5).totalHits);
   }
   
   /** when not sorting by score */
Index: lucene/core/src/test/org/apache/lucene/search/TestNot.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNot.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestNot.java	(working copy)
@@ -48,7 +48,7 @@
     query.add(new TermQuery(new Term("field", "a")), BooleanClause.Occur.SHOULD);
     query.add(new TermQuery(new Term("field", "b")), BooleanClause.Occur.MUST_NOT);
 
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     writer.close();
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(working copy)
@@ -158,16 +158,16 @@
         case 0:
           type = " (constant score filter rewrite)";
           q.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE);
-          topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
           break;
         case 1:
           type = " (constant score boolean rewrite)";
           q.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE);
-          topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
           break;
         case 2:
           type = " (filter)";
-          topDocs = searcher.search(new MatchAllDocsQuery(), f, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), noDocs, Sort.INDEXORDER);
           break;
         default:
           return;
@@ -222,7 +222,7 @@
     int count=3000;
     int upper=(count-1)*distance + (distance/3) + startOffset;
     NumericRangeQuery<Integer> q=NumericRangeQuery.newIntRange(field, precisionStep, null, upper, true, true);
-    TopDocs topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
@@ -232,7 +232,7 @@
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
     
     q=NumericRangeQuery.newIntRange(field, precisionStep, null, upper, false, true);
-    topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
@@ -262,7 +262,7 @@
     int count=3000;
     int lower=(count-1)*distance + (distance/3) +startOffset;
     NumericRangeQuery<Integer> q=NumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, true);
-    TopDocs topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
@@ -272,7 +272,7 @@
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().intValue());
 
     q=NumericRangeQuery.newIntRange(field, precisionStep, lower, null, true, false);
-    topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
@@ -550,7 +550,7 @@
     
     Filter tf=NumericRangeFilter.newFloatRange(field, precisionStep,
       NumericUtils.sortableIntToFloat(lower), NumericUtils.sortableIntToFloat(upper), true, true);
-    tTopDocs = searcher.search(new MatchAllDocsQuery(), tf, 1);
+    tTopDocs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), tf), 1);
     assertEquals("Returned count of range filter must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
   }
 
Index: lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(working copy)
@@ -167,16 +167,16 @@
         case 0:
           type = " (constant score filter rewrite)";
           q.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE);
-          topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
           break;
         case 1:
           type = " (constant score boolean rewrite)";
           q.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE);
-          topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
           break;
         case 2:
           type = " (filter)";
-          topDocs = searcher.search(new MatchAllDocsQuery(), f, noDocs, Sort.INDEXORDER);
+          topDocs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), noDocs, Sort.INDEXORDER);
           break;
         default:
           return;
@@ -239,7 +239,7 @@
     int count=3000;
     long upper=(count-1)*distance + (distance/3) + startOffset;
     NumericRangeQuery<Long> q=NumericRangeQuery.newLongRange(field, precisionStep, null, upper, true, true);
-    TopDocs topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
@@ -249,7 +249,7 @@
     assertEquals("Last doc", (count-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
 
     q=NumericRangeQuery.newLongRange(field, precisionStep, null, upper, false, true);
-    topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", count, sd.length );
@@ -284,7 +284,7 @@
     int count=3000;
     long lower=(count-1)*distance + (distance/3) +startOffset;
     NumericRangeQuery<Long> q=NumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, true);
-    TopDocs topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     ScoreDoc[] sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
@@ -294,7 +294,7 @@
     assertEquals("Last doc", (noDocs-1)*distance+startOffset, doc.getField(field).numericValue().longValue() );
 
     q=NumericRangeQuery.newLongRange(field, precisionStep, lower, null, true, false);
-    topDocs = searcher.search(q, null, noDocs, Sort.INDEXORDER);
+    topDocs = searcher.search(q, noDocs, Sort.INDEXORDER);
     sd = topDocs.scoreDocs;
     assertNotNull(sd);
     assertEquals("Score doc count", noDocs-count, sd.length );
@@ -587,7 +587,7 @@
     
     Filter tf=NumericRangeFilter.newDoubleRange(field, precisionStep,
       NumericUtils.sortableLongToDouble(lower), NumericUtils.sortableLongToDouble(upper), true, true);
-    tTopDocs = searcher.search(new MatchAllDocsQuery(), tf, 1);
+    tTopDocs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), tf), 1);
     assertEquals("Returned count of range filter must be equal to inclusive range length", upper-lower+1, tTopDocs.totalHits );
   }
 
Index: lucene/core/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java	(working copy)
@@ -88,10 +88,10 @@
     query2.add(termsWithPrefix.toArray(new Term[0]));
     
     ScoreDoc[] result;
-    result = searcher.search(query1, null, 1000).scoreDocs;
+    result = searcher.search(query1, 1000).scoreDocs;
     assertEquals(2, result.length);
     
-    result = searcher.search(query2, null, 1000).scoreDocs;
+    result = searcher.search(query2, 1000).scoreDocs;
     assertEquals(0, result.length);
     reader.close();
     indexStore.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java	(working copy)
@@ -113,7 +113,7 @@
     query.setSlop(2);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "five"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     QueryUtils.check(random(), query,searcher);
   }
@@ -122,7 +122,7 @@
     query.setSlop(3);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "five"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     QueryUtils.check(random(), query,searcher);
   }
@@ -134,7 +134,7 @@
     // slop is zero by default
     query.add(new Term("field", "four"));
     query.add(new Term("field", "five"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("exact match", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -142,7 +142,7 @@
     query = new PhraseQuery();
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("reverse not exact", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
   }
@@ -152,7 +152,7 @@
     query.setSlop(1);
     query.add(new Term("field", "one"));
     query.add(new Term("field", "two"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("in order", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -163,7 +163,7 @@
     query.setSlop(1);
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("reversed, slop not 2 or more", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
   }
@@ -175,7 +175,7 @@
     query.setSlop(2); // must be at least two for reverse order match
     query.add(new Term("field", "two"));
     query.add(new Term("field", "one"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -184,7 +184,7 @@
     query.setSlop(2);
     query.add(new Term("field", "three"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("not sloppy enough", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -199,7 +199,7 @@
     query.add(new Term("field", "one"));
     query.add(new Term("field", "three"));
     query.add(new Term("field", "five"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("two total moves", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -209,13 +209,13 @@
     query.add(new Term("field", "five"));
     query.add(new Term("field", "three"));
     query.add(new Term("field", "one"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("slop of 5 not close enough", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
 
 
     query.setSlop(6);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("slop of 6 just right", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -238,7 +238,7 @@
     PhraseQuery query = new PhraseQuery();
     query.add(new Term("field","stop"));
     query.add(new Term("field","words"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -267,7 +267,7 @@
     PhraseQuery phraseQuery = new PhraseQuery();
     phraseQuery.add(new Term("source", "marketing"));
     phraseQuery.add(new Term("source", "info"));
-    ScoreDoc[] hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(phraseQuery, 1000).scoreDocs;
     assertEquals(2, hits.length);
     QueryUtils.check(random(), phraseQuery,searcher);
 
@@ -276,7 +276,7 @@
     BooleanQuery booleanQuery = new BooleanQuery();
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    hits = searcher.search(booleanQuery, 1000).scoreDocs;
     assertEquals(1, hits.length);
     QueryUtils.check(random(), termQuery,searcher);
 
@@ -307,9 +307,9 @@
     phraseQuery.add(new Term("contents","map"));
     phraseQuery.add(new Term("contents","entry"));
     
-    hits = searcher.search(termQuery, null, 1000).scoreDocs;
+    hits = searcher.search(termQuery, 1000).scoreDocs;
     assertEquals(3, hits.length);
-    hits = searcher.search(phraseQuery, null, 1000).scoreDocs;
+    hits = searcher.search(phraseQuery, 1000).scoreDocs;
     assertEquals(2, hits.length);
 
     
@@ -316,13 +316,13 @@
     booleanQuery = new BooleanQuery();
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    hits = searcher.search(booleanQuery, 1000).scoreDocs;
     assertEquals(2, hits.length);
     
     booleanQuery = new BooleanQuery();
     booleanQuery.add(phraseQuery, BooleanClause.Occur.MUST);
     booleanQuery.add(termQuery, BooleanClause.Occur.MUST);
-    hits = searcher.search(booleanQuery, null, 1000).scoreDocs;
+    hits = searcher.search(booleanQuery, 1000).scoreDocs;
     assertEquals(2, hits.length);
     QueryUtils.check(random(), booleanQuery,searcher);
 
@@ -359,7 +359,7 @@
     query.add(new Term("field", "firstname"));
     query.add(new Term("field", "lastname"));
     query.setSlop(Integer.MAX_VALUE);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     // Make sure that those matches where the terms appear closer to
     // each other get a higher score:
@@ -407,13 +407,13 @@
     query.add(new Term("repeated", "part"));
     query.setSlop(100);
 
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("slop of 100 just right", 1, hits.length);
     QueryUtils.check(random(), query,searcher);
 
     query.setSlop(99);
 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("slop of 99 not enough", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
   }
@@ -426,7 +426,7 @@
     query.add(new Term("nonexist", "found"));
     query.setSlop(2); // would be found this way
 
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("phrase without repetitions exists in 2 docs", 2, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -437,7 +437,7 @@
     query.add(new Term("nonexist", "exist"));
     query.setSlop(1); // would be found 
 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("phrase with repetitions exists in two docs", 2, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -448,7 +448,7 @@
     query.add(new Term("nonexist", "phrase"));
     query.setSlop(1000); // would not be found no matter how high the slop is
 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -460,7 +460,7 @@
     query.add(new Term("nonexist", "exist"));
     query.setSlop(1000); // would not be found no matter how high the slop is
 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("nonexisting phrase with repetitions does not exist in any doc", 0, hits.length);
     QueryUtils.check(random(), query,searcher);
 
@@ -481,7 +481,7 @@
     query.setSlop(0); // to use exact phrase scorer
     query.add(new Term("field", "two"));
     query.add(new Term("field", "three"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("phrase found with exact phrase scorer", 1, hits.length);
     float score0 = hits[0].score;
     //System.out.println("(exact) field: two three: "+score0);
@@ -489,7 +489,7 @@
 
     // search on non palyndrome, find phrase with slop 2, though no slop required here.
     query.setSlop(2); // to use sloppy scorer 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     float score1 = hits[0].score;
     //System.out.println("(sloppy) field: two three: "+score1);
@@ -501,7 +501,7 @@
     query.setSlop(2); // must be at least two for both ordered and reversed to match
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "three"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     //float score2 = hits[0].score;
     //System.out.println("palindrome: two three: "+score2);
@@ -515,7 +515,7 @@
     query.setSlop(2); // must be at least two for both ordered and reversed to match
     query.add(new Term("palindrome", "three"));
     query.add(new Term("palindrome", "two"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     //float score3 = hits[0].score;
     //System.out.println("palindrome: three two: "+score3);
@@ -542,7 +542,7 @@
     query.add(new Term("field", "one"));
     query.add(new Term("field", "two"));
     query.add(new Term("field", "three"));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("phrase found with exact phrase scorer", 1, hits.length);
     float score0 = hits[0].score;
     //System.out.println("(exact) field: one two three: "+score0);
@@ -553,7 +553,7 @@
 
     // search on non palyndrome, find phrase with slop 3, though no slop required here.
     query.setSlop(4); // to use sloppy scorer 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     float score1 = hits[0].score;
     //System.out.println("(sloppy) field: one two three: "+score1);
@@ -566,7 +566,7 @@
     query.add(new Term("palindrome", "one"));
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "three"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
 
     // just make sure no exc:
     searcher.explain(query, 0);
@@ -585,7 +585,7 @@
     query.add(new Term("palindrome", "three"));
     query.add(new Term("palindrome", "two"));
     query.add(new Term("palindrome", "one"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("just sloppy enough", 1, hits.length);
     //float score3 = hits[0].score;
     //System.out.println("palindrome: three two one: "+score3);
Index: lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -122,7 +122,7 @@
     q = new PhraseQuery();
     q.add(new Term("field", "1"));
     q.add(new Term("field", "2"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // same as previous, just specify positions explicitely.
@@ -129,7 +129,7 @@
     q = new PhraseQuery(); 
     q.add(new Term("field", "1"),0);
     q.add(new Term("field", "2"),1);
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // specifying correct positions should find the phrase.
@@ -136,19 +136,19 @@
     q = new PhraseQuery();
     q.add(new Term("field", "1"),0);
     q.add(new Term("field", "2"),2);
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "3"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "3"));
     q.add(new Term("field", "4"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // phrase query would find it when correct positions are specified. 
@@ -155,7 +155,7 @@
     q = new PhraseQuery();
     q.add(new Term("field", "3"),0);
     q.add(new Term("field", "4"),0);
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     // phrase query should fail for non existing searched term 
@@ -163,7 +163,7 @@
     q = new PhraseQuery();
     q.add(new Term("field", "3"),0);
     q.add(new Term("field", "9"),0);
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // multi-phrase query should succed for non existing searched term
@@ -170,31 +170,31 @@
     // because there exist another searched terms in the same searched position. 
     MultiPhraseQuery mq = new MultiPhraseQuery();
     mq.add(new Term[]{new Term("field", "3"),new Term("field", "9")},0);
-    hits = searcher.search(mq, null, 1000).scoreDocs;
+    hits = searcher.search(mq, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "4"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "3"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "4"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     q = new PhraseQuery();
     q.add(new Term("field", "2"));
     q.add(new Term("field", "5"));
-    hits = searcher.search(q, null, 1000).scoreDocs;
+    hits = searcher.search(q, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestPrefixFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPrefixFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPrefixFilter.java	(working copy)
@@ -49,55 +49,55 @@
     PrefixFilter filter = new PrefixFilter(new Term("category", "/Computers"));
     Query query = new ConstantScoreQuery(filter);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(4, hits.length);
 
     // test middle of values
     filter = new PrefixFilter(new Term("category", "/Computers/Mac"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(2, hits.length);
 
     // test start of values
     filter = new PrefixFilter(new Term("category", "/Computers/Linux"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     // test end of values
     filter = new PrefixFilter(new Term("category", "/Computers/Windows"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     // test non-existant
     filter = new PrefixFilter(new Term("category", "/Computers/ObsoleteOS"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // test non-existant, before values
     filter = new PrefixFilter(new Term("category", "/Computers/AAA"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // test non-existant, after values
     filter = new PrefixFilter(new Term("category", "/Computers/ZZZ"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // test zero length prefix
     filter = new PrefixFilter(new Term("category", ""));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(4, hits.length);
 
     // test non existent field
     filter = new PrefixFilter(new Term("nonexistantfield", "/Computers"));
     query = new ConstantScoreQuery(filter);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     writer.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java	(working copy)
@@ -85,12 +85,12 @@
   public void testPrefixQuery() throws Exception {
     Query query = new PrefixQuery(new Term(FIELD, "tang"));
     assertEquals("Number of matched documents", 2,
-                 searcher.search(query, null, 1000).totalHits);
+                 searcher.search(query, 1000).totalHits);
   }
   public void testTermQuery() throws Exception {
     Query query = new TermQuery(new Term(FIELD, "tangfulin"));
     assertEquals("Number of matched documents", 2,
-                 searcher.search(query, null, 1000).totalHits);
+                 searcher.search(query, 1000).totalHits);
   }
   public void testTermBooleanQuery() throws Exception {
     BooleanQuery query = new BooleanQuery();
@@ -99,7 +99,7 @@
     query.add(new TermQuery(new Term(FIELD, "notexistnames")),
               BooleanClause.Occur.SHOULD);
     assertEquals("Number of matched documents", 2,
-                 searcher.search(query, null, 1000).totalHits);
+                 searcher.search(query, 1000).totalHits);
 
   }
   public void testPrefixBooleanQuery() throws Exception {
@@ -109,6 +109,6 @@
     query.add(new TermQuery(new Term(FIELD, "notexistnames")),
               BooleanClause.Occur.SHOULD);
     assertEquals("Number of matched documents", 2,
-                 searcher.search(query, null, 1000).totalHits);
+                 searcher.search(query, 1000).totalHits);
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/TestPrefixQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPrefixQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestPrefixQuery.java	(working copy)
@@ -48,17 +48,17 @@
 
     PrefixQuery query = new PrefixQuery(new Term("category", "/Computers"));
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("All documents in /Computers category and below", 3, hits.length);
 
     query = new PrefixQuery(new Term("category", "/Computers/Mac"));
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("One in /Computers/Mac", 1, hits.length);
 
     query = new PrefixQuery(new Term("category", ""));
     Terms terms = MultiFields.getTerms(searcher.getIndexReader(), "category");
     assertFalse(query.getTermsEnum(terms) instanceof PrefixTermsEnum);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("everything", 3, hits.length);
     writer.close();
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(working copy)
@@ -46,9 +46,9 @@
     QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
 
     IndexSearcher searcher = newSearcher(reader);
-    TopDocs hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
+    TopDocs hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), qwf), 10);
     assertEquals(1, hits.totalHits);
-    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf)), 10);
     assertEquals(1, hits.totalHits);
 
     // should not throw exception with complex primitive query
@@ -58,9 +58,9 @@
         Occur.MUST_NOT);
     qwf = new QueryWrapperFilter(termQuery);
 
-    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), qwf), 10);
     assertEquals(1, hits.totalHits);
-    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf)), 10);
     assertEquals(1, hits.totalHits);
 
     // should not throw exception with non primitive Query (doesn't implement
@@ -67,17 +67,17 @@
     // Query#createWeight)
     qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));
 
-    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), qwf), 10);
     assertEquals(1, hits.totalHits);
-    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf)), 10);
     assertEquals(1, hits.totalHits);
 
     // test a query with no hits
     termQuery = new TermQuery(new Term("field", "not_exist"));
     qwf = new QueryWrapperFilter(termQuery);
-    hits = searcher.search(new MatchAllDocsQuery(), qwf, 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), qwf), 10);
     assertEquals(0, hits.totalHits);
-    hits = searcher.search(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf), 10);
+    hits = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), new CachingWrapperFilter(qwf)), 10);
     assertEquals(0, hits.totalHits);
     reader.close();
     dir.close();
@@ -113,8 +113,8 @@
 
     final IndexReader r = w.getReader();
     w.close();
-    final TopDocs hits = newSearcher(r).search(new MatchAllDocsQuery(),
-                                                     new QueryWrapperFilter(new TermQuery(new Term("field", "a"))),
+    final TopDocs hits = newSearcher(r).search(new FilteredQuery(new MatchAllDocsQuery(),
+                                                     new QueryWrapperFilter(new TermQuery(new Term("field", "a")))),
                                                      numDocs);
     assertEquals(aDocs.size(), hits.totalHits);
     for(ScoreDoc sd: hits.scoreDocs) {
@@ -141,7 +141,7 @@
     for (int i = 0; i < 1000; i++) {
       TermQuery termQuery = new TermQuery(new Term("field", English.intToEnglish(i)));
       QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
-      TopDocs td = searcher.search(new MatchAllDocsQuery(), qwf, 10);
+      TopDocs td = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), qwf), 10);
       assertEquals(1, td.totalHits);
     }
     
Index: lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestSearchAfter.java	(working copy)
@@ -180,11 +180,8 @@
     // pages.
     int n = atLeast(20);
     for (int i = 0; i < n; i++) {
-      Filter odd = new QueryWrapperFilter(new TermQuery(new Term("oddeven", "odd")));
       assertQuery(new MatchAllDocsQuery(), null);
       assertQuery(new TermQuery(new Term("english", "one")), null);
-      assertQuery(new MatchAllDocsQuery(), odd);
-      assertQuery(new TermQuery(new Term("english", "four")), odd);
       BooleanQuery bq = new BooleanQuery();
       bq.add(new TermQuery(new Term("english", "one")), BooleanClause.Occur.SHOULD);
       bq.add(new TermQuery(new Term("oddeven", "even")), BooleanClause.Occur.SHOULD);
@@ -192,15 +189,15 @@
     }
   }
 
-  void assertQuery(Query query, Filter filter) throws Exception {
-    assertQuery(query, filter, null);
-    assertQuery(query, filter, Sort.RELEVANCE);
-    assertQuery(query, filter, Sort.INDEXORDER);
+  void assertQuery(Query query) throws Exception {
+    assertQuery(query, null);
+    assertQuery(query, Sort.RELEVANCE);
+    assertQuery(query, Sort.INDEXORDER);
     for(SortField sortField : allSortFields) {
-      assertQuery(query, filter, new Sort(new SortField[] {sortField}));
+      assertQuery(query, new Sort(new SortField[] {sortField}));
     }
     for(int i=0;i<20;i++) {
-      assertQuery(query, filter, getRandomSort());
+      assertQuery(query, getRandomSort());
     }
   }
 
@@ -212,21 +209,21 @@
     return new Sort(sortFields);
   }
 
-  void assertQuery(Query query, Filter filter, Sort sort) throws Exception {
+  void assertQuery(Query query, Sort sort) throws Exception {
     int maxDoc = searcher.getIndexReader().maxDoc();
     TopDocs all;
     int pageSize = TestUtil.nextInt(random(), 1, maxDoc * 2);
     if (VERBOSE) {
-      System.out.println("\nassertQuery " + (iter++) + ": query=" + query + " filter=" + filter + " sort=" + sort + " pageSize=" + pageSize);
+      System.out.println("\nassertQuery " + (iter++) + ": query=" + query + " sort=" + sort + " pageSize=" + pageSize);
     }
     final boolean doMaxScore = random().nextBoolean();
     final boolean doScores = random().nextBoolean();
     if (sort == null) {
-      all = searcher.search(query, filter, maxDoc);
+      all = searcher.search(query, maxDoc);
     } else if (sort == Sort.RELEVANCE) {
-      all = searcher.search(query, filter, maxDoc, sort, true, doMaxScore);
+      all = searcher.search(query, maxDoc, sort, true, doMaxScore);
     } else {
-      all = searcher.search(query, filter, maxDoc, sort, doScores, doMaxScore);
+      all = searcher.search(query, maxDoc, sort, doScores, doMaxScore);
     }
     if (VERBOSE) {
       System.out.println("  all.totalHits=" + all.totalHits);
@@ -243,15 +240,15 @@
         if (VERBOSE) {
           System.out.println("  iter lastBottom=" + lastBottom);
         }
-        paged = searcher.searchAfter(lastBottom, query, filter, pageSize);
+        paged = searcher.searchAfter(lastBottom, query, pageSize);
       } else {
         if (VERBOSE) {
           System.out.println("  iter lastBottom=" + lastBottom);
         }
         if (sort == Sort.RELEVANCE) {
-          paged = searcher.searchAfter(lastBottom, query, filter, pageSize, sort, true, doMaxScore);
+          paged = searcher.searchAfter(lastBottom, query, pageSize, sort, true, doMaxScore);
         } else {
-          paged = searcher.searchAfter(lastBottom, query, filter, pageSize, sort, doScores, doMaxScore);
+          paged = searcher.searchAfter(lastBottom, query, pageSize, sort, doScores, doMaxScore);
         }
       }
       if (VERBOSE) {
Index: lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java	(working copy)
@@ -148,7 +148,7 @@
       }
       final int hitCount = TestUtil.nextInt(random, 1, r.maxDoc() + 20);
       final RandomFilter f = new RandomFilter(random, random.nextFloat(), docValues);
-      int queryType = random.nextInt(3);
+      int queryType = random.nextInt(2);
       if (queryType == 0) {
         // force out of order
         BooleanQuery bq = new BooleanQuery();
@@ -158,13 +158,10 @@
         // Set minNrShouldMatch to 1 so that BQ will not optimize rewrite to return
         // the clause instead of BQ.
         bq.setMinimumNumberShouldMatch(1);
-        hits = s.search(bq, f, hitCount, sort, random.nextBoolean(), random.nextBoolean());
-      } else if (queryType == 1) {
+        hits = s.search(new FilteredQuery(bq, f), hitCount, sort, random.nextBoolean(), random.nextBoolean());
+      } else {
         hits = s.search(new ConstantScoreQuery(f),
-                        null, hitCount, sort, random.nextBoolean(), random.nextBoolean());
-      } else {
-        hits = s.search(new MatchAllDocsQuery(),
-                        f, hitCount, sort, random.nextBoolean(), random.nextBoolean());
+                        hitCount, sort, random.nextBoolean(), random.nextBoolean());
       }
 
       if (VERBOSE) {
Index: lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestSortedNumericSortField.java	(working copy)
@@ -37,13 +37,13 @@
   
     Sort sort = new Sort();
     sort.setSort(new SortedNumericSortField("sortednumeric", SortField.Type.LONG));
-    TopDocs td = empty.search(query, null, 10, sort, true, true);
+    TopDocs td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
     
     // for an empty index, any selector should work
     for (SortedNumericSelector.Type v : SortedNumericSelector.Type.values()) {
       sort.setSort(new SortedNumericSortField("sortednumeric", SortField.Type.LONG, false, v));
-      td = empty.search(query, null, 10, sort, true, true);
+      td = empty.search(query, 10, sort, true, true);
       assertEquals(0, td.totalHits);
     }
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestSortedSetSortField.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSortedSetSortField.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestSortedSetSortField.java	(working copy)
@@ -37,13 +37,13 @@
   
     Sort sort = new Sort();
     sort.setSort(new SortedSetSortField("sortedset", false));
-    TopDocs td = empty.search(query, null, 10, sort, true, true);
+    TopDocs td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
     
     // for an empty index, any selector should work
     for (SortedSetSelector.Type v : SortedSetSelector.Type.values()) {
       sort.setSort(new SortedSetSortField("sortedset", false, v));
-      td = empty.search(query, null, 10, sort, true, true);
+      td = empty.search(query, 10, sort, true, true);
       assertEquals(0, td.totalHits);
     }
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java	(working copy)
@@ -124,7 +124,7 @@
   public void testTermQuery() throws Exception {
     TermQuery q = new TermQuery(new Term("f", "d"));
     CountingCollector c = new CountingCollector(TopScoreDocCollector.create(10));
-    s.search(q, null, c);
+    s.search(q, c);
     final int maxDocs = s.getIndexReader().maxDoc();
     assertEquals(maxDocs, c.docCounts.size());
     for (int i = 0; i < maxDocs; i++) {
@@ -164,7 +164,7 @@
     for (final Set<String> occur : occurList) {
       CountingCollector c = new CountingCollector(TopScoreDocCollector.create(
           10), occur);
-      s.search(query, null, c);
+      s.search(query, c);
       final int maxDocs = s.getIndexReader().maxDoc();
       assertEquals(maxDocs, c.docCounts.size());
       boolean includeOptional = occur.contains("SHOULD");
@@ -196,7 +196,7 @@
     q.add(new Term("f", "b"));
     q.add(new Term("f", "c"));
     CountingCollector c = new CountingCollector(TopScoreDocCollector.create(10));
-    s.search(q, null, c);
+    s.search(q, c);
     final int maxDocs = s.getIndexReader().maxDoc();
     assertEquals(maxDocs, c.docCounts.size());
     for (int i = 0; i < maxDocs; i++) {
Index: lucene/core/src/test/org/apache/lucene/search/TestTermRangeFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestTermRangeFilter.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestTermRangeFilter.java	(working copy)
@@ -54,83 +54,83 @@
     
     // test id, bounded on both ends
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, maxIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, maxIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("find all", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, maxIP, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, maxIP, T, F)),
         numDocs).scoreDocs;
     assertEquals("all but last", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, maxIP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, maxIP, F, T)),
         numDocs).scoreDocs;
     assertEquals("all but first", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, maxIP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, maxIP, F, F)),
         numDocs).scoreDocs;
     assertEquals("all but ends", numDocs - 2, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", medIP, maxIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", medIP, maxIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("med and up", 1 + maxId - medId, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, medIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, medIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("up to med", 1 + medId - minId, result.length);
     
     // unbounded id
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, null, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, null, T, F)),
         numDocs).scoreDocs;
     assertEquals("min and up", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", null, maxIP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", null, maxIP, F, T)),
         numDocs).scoreDocs;
     assertEquals("max and down", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, null, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, null, F, F)),
         numDocs).scoreDocs;
     assertEquals("not min, but up", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", null, maxIP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", null, maxIP, F, F)),
         numDocs).scoreDocs;
     assertEquals("not max, but down", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", medIP, maxIP, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", medIP, maxIP, T, F)),
         numDocs).scoreDocs;
     assertEquals("med and up, not max", maxId - medId, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, medIP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, medIP, F, T)),
         numDocs).scoreDocs;
     assertEquals("not min, up to med", medId - minId, result.length);
     
     // very small sets
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, minIP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, minIP, F, F)),
         numDocs).scoreDocs;
     assertEquals("min,min,F,F", 0, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("id", medIP, medIP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", medIP, medIP, F, F)),
         numDocs).scoreDocs;
     assertEquals("med,med,F,F", 0, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("id", maxIP, maxIP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", maxIP, maxIP, F, F)),
         numDocs).scoreDocs;
     assertEquals("max,max,F,F", 0, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", minIP, minIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", minIP, minIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("min,min,T,T", 1, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("id", null, minIP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", null, minIP, F, T)),
         numDocs).scoreDocs;
     assertEquals("nul,min,F,T", 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", maxIP, maxIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", maxIP, maxIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("max,max,T,T", 1, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("id", maxIP, null, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", maxIP, null, T, F)),
         numDocs).scoreDocs;
     assertEquals("max,nul,T,T", 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("id", medIP, medIP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("id", medIP, medIP, T, T)),
         numDocs).scoreDocs;
     assertEquals("med,med,T,T", 1, result.length);
   }
@@ -153,60 +153,60 @@
     
     // test extremes, bounded on both ends
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, T, T)),
         numDocs).scoreDocs;
     assertEquals("find all", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, T, F)),
         numDocs).scoreDocs;
     assertEquals("all but biggest", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, F, T)),
         numDocs).scoreDocs;
     assertEquals("all but smallest", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, maxRP, F, F)),
         numDocs).scoreDocs;
     assertEquals("all but extremes", numDocs - 2, result.length);
     
     // unbounded
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, null, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, null, T, F)),
         numDocs).scoreDocs;
     assertEquals("smallest and up", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", null, maxRP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", null, maxRP, F, T)),
         numDocs).scoreDocs;
     assertEquals("biggest and down", numDocs, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, null, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, null, F, F)),
         numDocs).scoreDocs;
     assertEquals("not smallest, but up", numDocs - 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", null, maxRP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", null, maxRP, F, F)),
         numDocs).scoreDocs;
     assertEquals("not biggest, but down", numDocs - 1, result.length);
     
     // very small sets
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, minRP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, minRP, F, F)),
         numDocs).scoreDocs;
     assertEquals("min,min,F,F", 0, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("rand", maxRP, maxRP, F, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", maxRP, maxRP, F, F)),
         numDocs).scoreDocs;
     assertEquals("max,max,F,F", 0, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", minRP, minRP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", minRP, minRP, T, T)),
         numDocs).scoreDocs;
     assertEquals("min,min,T,T", 1, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("rand", null, minRP, F, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", null, minRP, F, T)),
         numDocs).scoreDocs;
     assertEquals("nul,min,F,T", 1, result.length);
     
-    result = search.search(q, TermRangeFilter.newStringRange("rand", maxRP, maxRP, T, T),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", maxRP, maxRP, T, T)),
         numDocs).scoreDocs;
     assertEquals("max,max,T,T", 1, result.length);
-    result = search.search(q, TermRangeFilter.newStringRange("rand", maxRP, null, T, F),
+    result = search.search(new FilteredQuery(q, TermRangeFilter.newStringRange("rand", maxRP, null, T, F)),
         numDocs).scoreDocs;
     assertEquals("max,nul,T,T", 1, result.length);
   }
Index: lucene/core/src/test/org/apache/lucene/search/TestTermRangeQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestTermRangeQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestTermRangeQuery.java	(working copy)
@@ -56,7 +56,7 @@
     initializeIndex(new String[] {"A", "B", "C", "D"});
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("A,B,C,D, only B in range", 1, hits.length);
     reader.close();
 
@@ -63,7 +63,7 @@
     initializeIndex(new String[] {"A", "B", "D"});
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("A,B,D, only B in range", 1, hits.length);
     reader.close();
 
@@ -70,7 +70,7 @@
     addDoc("C");
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("C added, still only B in range", 1, hits.length);
     reader.close();
   }
@@ -81,7 +81,7 @@
     initializeIndex(new String[]{"A", "B", "C", "D"});
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("A,B,C,D - A,B,C in range", 3, hits.length);
     reader.close();
 
@@ -88,7 +88,7 @@
     initializeIndex(new String[]{"A", "B", "D"});
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("A,B,D - A and B in range", 2, hits.length);
     reader.close();
 
@@ -95,7 +95,7 @@
     addDoc("C");
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("C added - A, B, C in range", 3, hits.length);
     reader.close();
   }
@@ -107,17 +107,17 @@
     TermRangeQuery query = new TermRangeQuery("content", null, null, true, true);
     Terms terms = MultiFields.getTerms(searcher.getIndexReader(), "content");
     assertFalse(query.getTermsEnum(terms) instanceof TermRangeTermsEnum);
-    assertEquals(4, searcher.search(query, null, 1000).scoreDocs.length);
+    assertEquals(4, searcher.search(query, 1000).scoreDocs.length);
     query = new TermRangeQuery("content", null, null, false, false);
     assertFalse(query.getTermsEnum(terms) instanceof TermRangeTermsEnum);
-    assertEquals(4, searcher.search(query, null, 1000).scoreDocs.length);
+    assertEquals(4, searcher.search(query, 1000).scoreDocs.length);
     query = TermRangeQuery.newStringRange("content", "", null, true, false);
     assertFalse(query.getTermsEnum(terms) instanceof TermRangeTermsEnum);
-    assertEquals(4, searcher.search(query, null, 1000).scoreDocs.length);
+    assertEquals(4, searcher.search(query, 1000).scoreDocs.length);
     // and now anothe one
     query = TermRangeQuery.newStringRange("content", "B", null, true, false);
     assertTrue(query.getTermsEnum(terms) instanceof TermRangeTermsEnum);
-    assertEquals(3, searcher.search(query, null, 1000).scoreDocs.length);
+    assertEquals(3, searcher.search(query, 1000).scoreDocs.length);
     reader.close();
   }
 
@@ -276,7 +276,7 @@
     initializeIndex(new String[] {"A", "B", "", "C", "D"}, analyzer);
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    int numHits = searcher.search(query, null, 1000).totalHits;
+    int numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("A,B,<empty string>,C,D => A, B & <empty string> are in range", 3, numHits);
     // until Lucene-38 is fixed, use this assert:
@@ -286,7 +286,7 @@
     initializeIndex(new String[] {"A", "B", "", "D"}, analyzer);
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    numHits = searcher.search(query, null, 1000).totalHits;
+    numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("A,B,<empty string>,D => A, B & <empty string> are in range", 3, numHits);
     // until Lucene-38 is fixed, use this assert:
@@ -295,7 +295,7 @@
     addDoc("C");
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    numHits = searcher.search(query, null, 1000).totalHits;
+    numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("C added, still A, B & <empty string> are in range", 3, numHits);
     // until Lucene-38 is fixed, use this assert
@@ -311,7 +311,7 @@
     initializeIndex(new String[]{"A", "B", "","C", "D"}, analyzer);
     IndexReader reader = DirectoryReader.open(dir);
     IndexSearcher searcher = newSearcher(reader);
-    int numHits = searcher.search(query, null, 1000).totalHits;
+    int numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("A,B,<empty string>,C,D => A,B,<empty string>,C in range", 4, numHits);
     // until Lucene-38 is fixed, use this assert
@@ -320,7 +320,7 @@
     initializeIndex(new String[]{"A", "B", "", "D"}, analyzer);
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    numHits = searcher.search(query, null, 1000).totalHits;
+    numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("A,B,<empty string>,D - A, B and <empty string> in range", 3, numHits);
     // until Lucene-38 is fixed, use this assert
@@ -329,7 +329,7 @@
     addDoc("C");
     reader = DirectoryReader.open(dir);
     searcher = newSearcher(reader);
-    numHits = searcher.search(query, null, 1000).totalHits;
+    numHits = searcher.search(query, 1000).totalHits;
     // When Lucene-38 is fixed, use the assert on the next line:
     assertEquals("C added => A,B,<empty string>,C in range", 4, numHits);
     // until Lucene-38 is fixed, use this assert
Index: lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java	(working copy)
@@ -105,7 +105,7 @@
     query = booleanQuery;
     
     // warm the searcher
-    searcher.search(query, null, 1000);
+    searcher.search(query, 1000);
   }
 
   @Override
Index: lucene/core/src/test/org/apache/lucene/search/TestTotalHitCountCollector.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestTotalHitCountCollector.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestTotalHitCountCollector.java	(working copy)
@@ -41,7 +41,7 @@
 
     IndexSearcher searcher = newSearcher(reader);
     TotalHitCountCollector c = new TotalHitCountCollector();
-    searcher.search(new MatchAllDocsQuery(), null, c);
+    searcher.search(new MatchAllDocsQuery(), c);
     assertEquals(5, c.getTotalHits());
     reader.close();
     indexStore.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestWildcard.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestWildcard.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/TestWildcard.java	(working copy)
@@ -254,7 +254,7 @@
 
   private void assertMatches(IndexSearcher searcher, Query q, int expectedMatches)
       throws IOException {
-    ScoreDoc[] result = searcher.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] result = searcher.search(q, 1000).scoreDocs;
     assertEquals(expectedMatches, result.length);
   }
 
@@ -354,7 +354,7 @@
     // test queries that must find all
     for (Query q : matchAll) {
       if (VERBOSE) System.out.println("matchAll: q=" + q + " " + q.getClass().getName());
-      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+      ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
       assertEquals(docs.length, hits.length);
     }
     
@@ -361,7 +361,7 @@
     // test queries that must find none
     for (Query q : matchNone) {
       if (VERBOSE) System.out.println("matchNone: q=" + q + " " + q.getClass().getName());
-      ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+      ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
       assertEquals(0, hits.length);
     }
 
@@ -370,7 +370,7 @@
       for (int j = 0; j < matchOneDocPrefix[i].length; j++) {
         Query q = matchOneDocPrefix[i][j];
         if (VERBOSE) System.out.println("match 1 prefix: doc="+docs[i]+" q="+q+" "+q.getClass().getName());
-        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+        ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
         assertEquals(1,hits.length);
         assertEquals(i,hits[0].doc);
       }
@@ -381,7 +381,7 @@
       for (int j = 0; j < matchOneDocWild[i].length; j++) {
         Query q = matchOneDocWild[i][j];
         if (VERBOSE) System.out.println("match 1 wild: doc="+docs[i]+" q="+q+" "+q.getClass().getName());
-        ScoreDoc[] hits = searcher.search(q, null, 1000).scoreDocs;
+        ScoreDoc[] hits = searcher.search(q, 1000).scoreDocs;
         assertEquals(1,hits.length);
         assertEquals(i,hits[0].doc);
       }
Index: lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java	(working copy)
@@ -141,7 +141,7 @@
 
     // all 10 hits should have score = 3 because adjacent terms have payloads of 2,4
     // and all the similarity factors are set to 1
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("should be 10 hits", hits.totalHits == 10);
     for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -155,7 +155,7 @@
       }
       // all should have score = 3 because adjacent terms have payloads of 2,4
       // and all the similarity factors are set to 1
-      hits = searcher.search(query, null, 100);
+      hits = searcher.search(query, 100);
       assertTrue("hits is null and it shouldn't be", hits != null);
       assertEquals("should be 100 hits", 100, hits.totalHits);
       for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -179,7 +179,7 @@
     clauses[1] = q2;
     query = new PayloadNearQuery(clauses, 10, false); 
     //System.out.println(query.toString());
-    assertEquals(12, searcher.search(query, null, 100).totalHits);
+    assertEquals(12, searcher.search(query, 100).totalHits);
     /*
     System.out.println(hits.totalHits);
     for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -197,7 +197,7 @@
     QueryUtils.check(query);
     // all 10 hits should have score = 3 because adjacent terms have payloads of 2,4
     // and all the similarity factors are set to 1
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("should be 10 hits", hits.totalHits == 10);
     for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -216,7 +216,7 @@
     query = newPhraseQuery("field", "twenty two", true, new MaxPayloadFunction());
     QueryUtils.check(query);
     // all 10 hits should have score = 4 (max payload value)
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("should be 10 hits", hits.totalHits == 10);
     for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -235,7 +235,7 @@
     query = newPhraseQuery("field", "twenty two", true, new MinPayloadFunction());
     QueryUtils.check(query);
     // all 10 hits should have score = 2 (min payload value)
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("should be 10 hits", hits.totalHits == 10);
     for (int j = 0; j < hits.scoreDocs.length; j++) {
@@ -269,7 +269,7 @@
     PayloadNearQuery query;
     TopDocs hits;
     query = newPhraseQuery("field", "nine hundred ninety nine", true, new AveragePayloadFunction());
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     ScoreDoc doc = hits.scoreDocs[0];
     //    System.out.println("Doc: " + doc.toString());
@@ -291,7 +291,7 @@
     SpanQuery q4 = newPhraseQuery("field", "hundred nine", false, new AveragePayloadFunction());
     SpanQuery[]clauses = new SpanQuery[] {new PayloadNearQuery(new SpanQuery[] {q1,q2}, 0, true), new PayloadNearQuery(new SpanQuery[] {q3,q4}, 0, false)};
     query = new PayloadNearQuery(clauses, 0, false);
-    hits = searcher.search(query, null, 100);
+    hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     // should be only 1 hit - doc 999
     assertTrue("should only be one hit", hits.scoreDocs.length == 1);
Index: lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(working copy)
@@ -147,7 +147,7 @@
   public void test() throws IOException {
     PayloadTermQuery query = new PayloadTermQuery(new Term("field", "seventy"),
             new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
+    TopDocs hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
 
@@ -188,7 +188,7 @@
   public void testMultipleMatchesPerDoc() throws Exception {
     PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, "seventy"),
             new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
+    TopDocs hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
 
@@ -230,7 +230,7 @@
     IndexReader reader = DirectoryReader.open(directory);
     IndexSearcher theSearcher = newSearcher(reader);
     theSearcher.setSimilarity(new FullSimilarity());
-    TopDocs hits = searcher.search(query, null, 100);
+    TopDocs hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("hits Size: " + hits.totalHits + " is not: " + 100, hits.totalHits == 100);
 
@@ -267,7 +267,7 @@
   public void testNoMatch() throws Exception {
     PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.FIELD, "junk"),
             new MaxPayloadFunction());
-    TopDocs hits = searcher.search(query, null, 100);
+    TopDocs hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("hits Size: " + hits.totalHits + " is not: " + 0, hits.totalHits == 0);
 
@@ -283,7 +283,7 @@
     BooleanQuery query = new BooleanQuery();
     query.add(c1);
     query.add(c2);
-    TopDocs hits = searcher.search(query, null, 100);
+    TopDocs hits = searcher.search(query, 100);
     assertTrue("hits is null and it shouldn't be", hits != null);
     assertTrue("hits Size: " + hits.totalHits + " is not: " + 1, hits.totalHits == 1);
     int[] results = new int[1];
Index: lucene/core/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(working copy)
@@ -136,7 +136,7 @@
     
     // Hits hits = searcher.search(query);
     // hits normalizes and throws things off if one score is greater than 1.0
-    TopDocs topdocs = s.search(query, null, 10000);
+    TopDocs topdocs = s.search(query, 10000);
     
     /*****
      * // display the hits System.out.println(hits.length() +
Index: lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/store/TestBufferedIndexInput.java	(working copy)
@@ -237,7 +237,7 @@
         writer.deleteDocuments(new Term("id", "0"));
         reader = DirectoryReader.open(writer, true);
         IndexSearcher searcher = newSearcher(reader);
-        ScoreDoc[] hits = searcher.search(new TermQuery(bbb), null, 1000).scoreDocs;
+        ScoreDoc[] hits = searcher.search(new TermQuery(bbb), 1000).scoreDocs;
         dir.tweakBufferSizes();
         assertEquals(36, hits.length);
         
@@ -248,14 +248,14 @@
         reader = DirectoryReader.open(writer, true);
         searcher = newSearcher(reader);
 
-        hits = searcher.search(new TermQuery(bbb), null, 1000).scoreDocs;
+        hits = searcher.search(new TermQuery(bbb), 1000).scoreDocs;
         dir.tweakBufferSizes();
         assertEquals(35, hits.length);
         dir.tweakBufferSizes();
-        hits = searcher.search(new TermQuery(new Term("id", "33")), null, 1000).scoreDocs;
+        hits = searcher.search(new TermQuery(new Term("id", "33")), 1000).scoreDocs;
         dir.tweakBufferSizes();
         assertEquals(1, hits.length);
-        hits = searcher.search(new TermQuery(aaa), null, 1000).scoreDocs;
+        hits = searcher.search(new TermQuery(aaa), 1000).scoreDocs;
         dir.tweakBufferSizes();
         assertEquals(35, hits.length);
         writer.close();
Index: lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java	(revision 1661864)
+++ lucene/core/src/test/org/apache/lucene/store/TestLockFactory.java	(working copy)
@@ -280,7 +280,7 @@
                     break;
                 }
                 try {
-                  searcher.search(query, null, 1000);
+                  searcher.search(query, 1000);
                 } catch (IOException e) {
                   hitException = true;
                   System.out.println("Stress Test Index Searcher: search hit unexpected exception: " + e.toString());
Index: lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(revision 1661864)
+++ lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java	(working copy)
@@ -120,7 +120,7 @@
       if (repeat > 0) {                           // repeat & time as benchmark
         Date start = new Date();
         for (int i = 0; i < repeat; i++) {
-          searcher.search(query, null, 100);
+          searcher.search(query, 100);
         }
         Date end = new Date();
         System.out.println("Time: "+(end.getTime()-start.getTime())+"ms");
Index: lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java
===================================================================
--- lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java	(revision 1661864)
+++ lucene/demo/src/java/org/apache/lucene/demo/facet/SimpleFacetsExample.java	(working copy)
@@ -131,7 +131,7 @@
     // MatchAllDocsQuery is for "browsing" (counts facets
     // for all non-deleted docs in the index); normally
     // you'd use a "normal" query:
-    searcher.search(new MatchAllDocsQuery(), null /*Filter */, fc);
+    searcher.search(new MatchAllDocsQuery(), fc);
 
     // Retrieve results
     List<FacetResult> results = new ArrayList<>();
Index: lucene/expressions/src/test/org/apache/lucene/expressions/TestDemoExpressions.java
===================================================================
--- lucene/expressions/src/test/org/apache/lucene/expressions/TestDemoExpressions.java	(revision 1661864)
+++ lucene/expressions/src/test/org/apache/lucene/expressions/TestDemoExpressions.java	(working copy)
@@ -105,7 +105,7 @@
     // create a sort field and sort by it (reverse order)
     Sort sort = new Sort(expr.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    searcher.search(query, null, 3, sort);
+    searcher.search(query, 3, sort);
   }
   
   /** tests the returned sort values are correct */
@@ -117,7 +117,7 @@
     
     Sort sort = new Sort(expr.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);
+    TopFieldDocs td = searcher.search(query, 3, sort, true, true);
     for (int i = 0; i < 3; i++) {
       FieldDoc d = (FieldDoc) td.scoreDocs[i];
       float expected = (float) Math.sqrt(d.score);
@@ -135,7 +135,7 @@
     
     Sort sort = new Sort(expr.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);
+    TopFieldDocs td = searcher.search(query, 3, sort, true, true);
     for (int i = 0; i < 3; i++) {
       FieldDoc d = (FieldDoc) td.scoreDocs[i];
       float expected = 2*d.score;
@@ -154,7 +154,7 @@
     
     Sort sort = new Sort(expr.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);
+    TopFieldDocs td = searcher.search(query, 3, sort, true, true);
     for (int i = 0; i < 3; i++) {
       FieldDoc d = (FieldDoc) td.scoreDocs[i];
       float expected = 2*d.score;
@@ -174,7 +174,7 @@
     
     Sort sort = new Sort(expr2.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);
+    TopFieldDocs td = searcher.search(query, 3, sort, true, true);
     for (int i = 0; i < 3; i++) {
       FieldDoc d = (FieldDoc) td.scoreDocs[i];
       float expected = 2*d.score;
@@ -206,7 +206,7 @@
     Expression expr = JavascriptCompiler.compile(sb.toString());
     Sort sort = new Sort(expr.getSortField(bindings, true));
     Query query = new TermQuery(new Term("body", "contents"));
-    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);
+    TopFieldDocs td = searcher.search(query, 3, sort, true, true);
     for (int i = 0; i < 3; i++) {
       FieldDoc d = (FieldDoc) td.scoreDocs[i];
       float expected = n*d.score;
@@ -221,7 +221,7 @@
     bindings.add(new SortField("latitude", SortField.Type.DOUBLE));
     bindings.add(new SortField("longitude", SortField.Type.DOUBLE));
     Sort sort = new Sort(distance.getSortField(bindings, false));
-    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), null, 3, sort);
+    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), 3, sort);
     
     FieldDoc d = (FieldDoc) td.scoreDocs[0];
     assertEquals(0.4619D, (Double)d.fields[0], 1E-4);
@@ -238,7 +238,7 @@
     SimpleBindings bindings = new SimpleBindings();
     bindings.add("doc['popularity'].value", new IntFieldSource("popularity"));
     Sort sort = new Sort(popularity.getSortField(bindings, true));
-    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), null, 3, sort);
+    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), 3, sort);
 
     FieldDoc d = (FieldDoc)td.scoreDocs[0];
     assertEquals(20D, (Double)d.fields[0], 1E-4);
@@ -288,7 +288,7 @@
       }
     };
     Sort sort = new Sort(popularity.getSortField(bindings, false));
-    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), null, 3, sort);
+    TopFieldDocs td = searcher.search(new MatchAllDocsQuery(), 3, sort);
 
     FieldDoc d = (FieldDoc)td.scoreDocs[0];
     assertEquals(2092D, (Double)d.fields[0], 1E-4);
Index: lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
===================================================================
--- lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java	(revision 1661864)
+++ lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java	(working copy)
@@ -86,23 +86,20 @@
   public void testQueries() throws Exception {
     int n = atLeast(4);
     for (int i = 0; i < n; i++) {
-      Filter odd = new QueryWrapperFilter(new TermQuery(new Term("oddeven", "odd")));
-      assertQuery(new MatchAllDocsQuery(), null);
-      assertQuery(new TermQuery(new Term("english", "one")), null);
-      assertQuery(new MatchAllDocsQuery(), odd);
-      assertQuery(new TermQuery(new Term("english", "four")), odd);
+      assertQuery(new MatchAllDocsQuery());
+      assertQuery(new TermQuery(new Term("english", "one")));
       BooleanQuery bq = new BooleanQuery();
       bq.add(new TermQuery(new Term("english", "one")), BooleanClause.Occur.SHOULD);
       bq.add(new TermQuery(new Term("oddeven", "even")), BooleanClause.Occur.SHOULD);
-      assertQuery(bq, null);
+      assertQuery(bq);
       // force in order
       bq.add(new TermQuery(new Term("english", "two")), BooleanClause.Occur.SHOULD);
       bq.setMinimumNumberShouldMatch(2);
-      assertQuery(bq, null);
+      assertQuery(bq);
     }
   }
   
-  void assertQuery(Query query, Filter filter) throws Exception {
+  void assertQuery(Query query) throws Exception {
     for (int i = 0; i < 10; i++) {
       boolean reversed = random().nextBoolean();
       SortField fields[] = new SortField[] {
@@ -114,13 +111,13 @@
       };
       Collections.shuffle(Arrays.asList(fields), random());
       int numSorts = TestUtil.nextInt(random(), 1, fields.length);
-      assertQuery(query, filter, new Sort(Arrays.copyOfRange(fields, 0, numSorts)));
+      assertQuery(query, new Sort(Arrays.copyOfRange(fields, 0, numSorts)));
     }
   }
 
-  void assertQuery(Query query, Filter filter, Sort sort) throws Exception {
+  void assertQuery(Query query, Sort sort) throws Exception {
     int size = TestUtil.nextInt(random(), 1, searcher.getIndexReader().maxDoc() / 5);
-    TopDocs expected = searcher.search(query, filter, size, sort, random().nextBoolean(), random().nextBoolean());
+    TopDocs expected = searcher.search(query, size, sort, random().nextBoolean(), random().nextBoolean());
     
     // make our actual sort, mutating original by replacing some of the 
     // sortfields with equivalent expressions
@@ -141,12 +138,12 @@
     }
     
     Sort mutatedSort = new Sort(mutated);
-    TopDocs actual = searcher.search(query, filter, size, mutatedSort, random().nextBoolean(), random().nextBoolean());
+    TopDocs actual = searcher.search(query, size, mutatedSort, random().nextBoolean(), random().nextBoolean());
     CheckHits.checkEqual(query, expected.scoreDocs, actual.scoreDocs);
     
     if (size < actual.totalHits) {
-      expected = searcher.searchAfter(expected.scoreDocs[size-1], query, filter, size, sort);
-      actual = searcher.searchAfter(actual.scoreDocs[size-1], query, filter, size, mutatedSort);
+      expected = searcher.searchAfter(expected.scoreDocs[size-1], query, size, sort);
+      actual = searcher.searchAfter(actual.scoreDocs[size-1], query, size, mutatedSort);
       CheckHits.checkEqual(query, expected.scoreDocs, actual.scoreDocs);
     }
   }
Index: lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
===================================================================
--- lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java	(revision 1661864)
+++ lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java	(working copy)
@@ -46,6 +46,7 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
@@ -752,7 +753,11 @@
       verifyEquals(dimValues, s, expected, actual, scores, doUseDV);
 
       // Make sure drill down doesn't change score:
-      TopDocs ddqHits = s.search(ddq, filter, numDocs);
+      Query q = ddq;
+      if (filter != null) {
+        q = new FilteredQuery(q, filter);
+      }
+      TopDocs ddqHits = s.search(q, numDocs);
       assertEquals(expected.hits.size(), ddqHits.totalHits);
       for(int i=0;i<expected.hits.size();i++) {
         // Score should be IDENTICAL:
Index: lucene/grouping/src/java/org/apache/lucene/search/grouping/GroupingSearch.java
===================================================================
--- lucene/grouping/src/java/org/apache/lucene/search/grouping/GroupingSearch.java	(revision 1661864)
+++ lucene/grouping/src/java/org/apache/lucene/search/grouping/GroupingSearch.java	(working copy)
@@ -124,27 +124,12 @@
    * @return the grouped result as a {@link TopGroups} instance
    * @throws IOException If any I/O related errors occur
    */
+  @SuppressWarnings("unchecked")
   public <T> TopGroups<T> search(IndexSearcher searcher, Query query, int groupOffset, int groupLimit) throws IOException {
-    return search(searcher, null, query, groupOffset, groupLimit);
-  }
-
-  /**
-   * Executes a grouped search. Both the first pass and second pass are executed on the specified searcher.
-   *
-   * @param searcher    The {@link org.apache.lucene.search.IndexSearcher} instance to execute the grouped search on.
-   * @param filter      The filter to execute with the grouping
-   * @param query       The query to execute with the grouping
-   * @param groupOffset The group offset
-   * @param groupLimit  The number of groups to return from the specified group offset
-   * @return the grouped result as a {@link TopGroups} instance
-   * @throws IOException If any I/O related errors occur
-   */
-  @SuppressWarnings("unchecked")
-  public <T> TopGroups<T> search(IndexSearcher searcher, Filter filter, Query query, int groupOffset, int groupLimit) throws IOException {
     if (groupField != null || groupFunction != null) {
-      return groupByFieldOrFunction(searcher, filter, query, groupOffset, groupLimit);
+      return groupByFieldOrFunction(searcher, query, groupOffset, groupLimit);
     } else if (groupEndDocs != null) {
-      return (TopGroups<T>) groupByDocBlock(searcher, filter, query, groupOffset, groupLimit);
+      return (TopGroups<T>) groupByDocBlock(searcher, query, groupOffset, groupLimit);
     } else {
       throw new IllegalStateException("Either groupField, groupFunction or groupEndDocs must be set."); // This can't happen...
     }
@@ -151,7 +136,7 @@
   }
 
   @SuppressWarnings({"unchecked", "rawtypes"})
-  protected TopGroups groupByFieldOrFunction(IndexSearcher searcher, Filter filter, Query query, int groupOffset, int groupLimit) throws IOException {
+  protected TopGroups groupByFieldOrFunction(IndexSearcher searcher, Query query, int groupOffset, int groupLimit) throws IOException {
     int topN = groupOffset + groupLimit;
     final AbstractFirstPassGroupingCollector firstPassCollector;
     final AbstractAllGroupsCollector allGroupsCollector;
@@ -204,9 +189,9 @@
       } else {
         cachedCollector = CachingCollector.create(firstRound, cacheScores, maxDocsToCache);
       }
-      searcher.search(query, filter, cachedCollector);
+      searcher.search(query, cachedCollector);
     } else {
-      searcher.search(query, filter, firstRound);
+      searcher.search(query, firstRound);
     }
 
     if (allGroups) {
@@ -236,7 +221,7 @@
     if (cachedCollector != null && cachedCollector.isCached()) {
       cachedCollector.replay(secondPassCollector);
     } else {
-      searcher.search(query, filter, secondPassCollector);
+      searcher.search(query, secondPassCollector);
     }
 
     if (allGroups) {
@@ -246,10 +231,10 @@
     }
   }
 
-  protected TopGroups<?> groupByDocBlock(IndexSearcher searcher, Filter filter, Query query, int groupOffset, int groupLimit) throws IOException {
+  protected TopGroups<?> groupByDocBlock(IndexSearcher searcher, Query query, int groupOffset, int groupLimit) throws IOException {
     int topN = groupOffset + groupLimit;
     BlockGroupingCollector c = new BlockGroupingCollector(groupSort, topN, includeScores, groupEndDocs);
-    searcher.search(query, filter, c);
+    searcher.search(query, c);
     int topNInsideGroup = groupDocsOffset + groupDocsLimit;
     return c.getTopGroups(sortWithinGroup, groupOffset, groupDocsOffset, topNInsideGroup, fillSortFields);
   }
Index: lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java
===================================================================
--- lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java	(revision 1661864)
+++ lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java	(working copy)
@@ -123,7 +123,7 @@
     Sort groupSort = Sort.RELEVANCE;
     GroupingSearch groupingSearch = createRandomGroupingSearch(groupField, groupSort, 5, canUseIDV);
 
-    TopGroups<?> groups = groupingSearch.search(indexSearcher, null, new TermQuery(new Term("content", "random")), 0, 10);
+    TopGroups<?> groups = groupingSearch.search(indexSearcher, new TermQuery(new Term("content", "random")), 0, 10);
 
     assertEquals(7, groups.totalHitCount);
     assertEquals(7, groups.totalGroupedHitCount);
@@ -161,7 +161,7 @@
 
     Filter lastDocInBlock = new CachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("groupend", "x"))));
     groupingSearch = new GroupingSearch(lastDocInBlock);
-    groups = groupingSearch.search(indexSearcher, null, new TermQuery(new Term("content", "random")), 0, 10);
+    groups = groupingSearch.search(indexSearcher, new TermQuery(new Term("content", "random")), 0, 10);
 
     assertEquals(7, groups.totalHitCount);
     assertEquals(7, groups.totalGroupedHitCount);
@@ -237,7 +237,7 @@
 
     GroupingSearch gs = new GroupingSearch("group");
     gs.setAllGroups(true);
-    TopGroups<?> groups = gs.search(indexSearcher, null, new TermQuery(new Term("group", "foo")), 0, 10);
+    TopGroups<?> groups = gs.search(indexSearcher, new TermQuery(new Term("group", "foo")), 0, 10);
     assertEquals(1, groups.totalHitCount);
     //assertEquals(1, groups.totalGroupCount.intValue());
     assertEquals(1, groups.totalGroupedHitCount);
Index: lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 1661864)
+++ lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -1014,7 +1014,7 @@
     // it rewrites to ConstantScoreQuery which cannot be highlighted
     // query = unReWrittenQuery.rewrite(reader);
     if (VERBOSE) System.out.println("Searching for: " + query.toString(FIELD_NAME));
-    hits = searcher.search(query, null, 1000);
+    hits = searcher.search(query, 1000);
 
     for (int i = 0; i < hits.totalHits; i++) {
       final StoredDocument doc = searcher.doc(hits.scoreDocs[i].doc);
@@ -1036,7 +1036,7 @@
     
     // try null field
     
-    hits = searcher.search(query, null, 1000);
+    hits = searcher.search(query, 1000);
     
     numHighlights = 0;
 
@@ -1061,7 +1061,7 @@
     
     // try default field
     
-    hits = searcher.search(query, null, 1000);
+    hits = searcher.search(query, 1000);
     
     numHighlights = 0;
 
@@ -1541,7 +1541,7 @@
         if (VERBOSE) System.out.println("Searching with primitive query");
         // forget to set this and...
         // query=query.rewrite(reader);
-        TopDocs hits = searcher.search(query, null, 1000);
+        TopDocs hits = searcher.search(query, 1000);
 
         // create an instance of the highlighter with the tags used to surround
         // highlighted text
@@ -1913,7 +1913,7 @@
     //Scorer scorer = new QueryTermScorer( query, "t_text1" );
     Highlighter h = new Highlighter( scorer );
 
-    TopDocs hits = searcher.search(query, null, 10);
+    TopDocs hits = searcher.search(query, 10);
     for( int i = 0; i < hits.totalHits; i++ ){
       StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );
       String result = h.getBestFragment( a, "t_text1", doc.get( "t_text1" ));
@@ -1944,7 +1944,7 @@
       scorer.setUsePayloads(true);
       Highlighter h = new Highlighter(scorer);
 
-      TopDocs hits = searcher.search(query, null, 10);
+      TopDocs hits = searcher.search(query, 10);
       assertEquals(1, hits.scoreDocs.length);
       TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);
       if (random().nextBoolean()) {
@@ -1996,7 +1996,7 @@
     // you must use a rewritten query!
     query = unReWrittenQuery.rewrite(reader);
     if (VERBOSE) System.out.println("Searching for: " + query.toString(FIELD_NAME));
-    hits = searcher.search(query, null, 1000);
+    hits = searcher.search(query, 1000);
   }
 
   public void assertExpectedHighlightCount(final int maxNumFragmentsRequired,
Index: lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting.java	(revision 1661864)
+++ lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting.java	(working copy)
@@ -92,7 +92,7 @@
       }
     };
     Query query = new WildcardQuery(new Term("body", "te*"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -103,7 +103,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(new WildcardQuery(new Term("bogus", "te*")), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -144,7 +144,7 @@
       }
     };
     Query query = new PrefixQuery(new Term("body", "te"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -155,7 +155,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(new PrefixQuery(new Term("bogus", "te")), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -196,7 +196,7 @@
       }
     };
     Query query = new RegexpQuery(new Term("body", "te.*"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -207,7 +207,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(new RegexpQuery(new Term("bogus", "te.*")), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -248,7 +248,7 @@
       }
     };
     Query query = new FuzzyQuery(new Term("body", "tets"), 1);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -257,7 +257,7 @@
     
     // with prefix
     query = new FuzzyQuery(new Term("body", "tets"), 1, 2);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -268,7 +268,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(new FuzzyQuery(new Term("bogus", "tets"), 1), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -309,7 +309,7 @@
       }
     };
     Query query = TermRangeQuery.newStringRange("body", "ta", "tf", true, true);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -318,7 +318,7 @@
     
     // null start
     query = TermRangeQuery.newStringRange("body", null, "tf", true, true);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -327,7 +327,7 @@
     
     // null end
     query = TermRangeQuery.newStringRange("body", "ta", null, true, true);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -336,7 +336,7 @@
     
     // exact start inclusive
     query = TermRangeQuery.newStringRange("body", "test", "tf", true, true);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -345,7 +345,7 @@
     
     // exact end inclusive
     query = TermRangeQuery.newStringRange("body", "ta", "test", true, true);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -356,7 +356,7 @@
     BooleanQuery bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(TermRangeQuery.newStringRange("body", "test", "tf", false, true), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -367,7 +367,7 @@
     bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(TermRangeQuery.newStringRange("body", "ta", "test", true, false), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -378,7 +378,7 @@
     bq = new BooleanQuery();
     bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     bq.add(TermRangeQuery.newStringRange("bogus", "ta", "tf", true, true), BooleanClause.Occur.SHOULD);
-    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", bq, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -420,7 +420,7 @@
     };
     BooleanQuery query = new BooleanQuery();
     query.add(new WildcardQuery(new Term("body", "te*")), BooleanClause.Occur.SHOULD);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -431,7 +431,7 @@
     query = new BooleanQuery();
     query.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);
     query.add(new WildcardQuery(new Term("bogus", "te*")), BooleanClause.Occur.MUST_NOT);
-    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     snippets = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -474,7 +474,7 @@
     FilteredQuery query = new FilteredQuery(
         new WildcardQuery(new Term("body", "te*")),
         new QueryWrapperFilter(new TermQuery(new Term("body", "test"))));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -515,7 +515,7 @@
       }
     };
     ConstantScoreQuery query = new ConstantScoreQuery(new WildcardQuery(new Term("body", "te*")));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -557,7 +557,7 @@
     };
     DisjunctionMaxQuery query = new DisjunctionMaxQuery(0);
     query.add(new WildcardQuery(new Term("body", "te*")));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -598,7 +598,7 @@
       }
     };
     Query query = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term("body", "te*")));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -640,7 +640,7 @@
     };
     SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term("body", "te*")));
     Query query = new SpanOrQuery(new SpanQuery[] { childQuery });
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -682,7 +682,7 @@
     };
     SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term("body", "te*")));
     Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -725,7 +725,7 @@
     SpanQuery include = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term("body", "te*")));
     SpanQuery exclude = new SpanTermQuery(new Term("body", "bogus"));
     Query query = new SpanNotQuery(include, exclude);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -767,7 +767,7 @@
     };
     SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term("body", "te*")));
     Query query = new SpanFirstQuery(childQuery, 1000000);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -811,7 +811,7 @@
     query.add(new WildcardQuery(new Term("body", "te*")), BooleanClause.Occur.SHOULD);
     query.add(new WildcardQuery(new Term("body", "one")), BooleanClause.Occur.SHOULD);
     query.add(new WildcardQuery(new Term("body", "se*")), BooleanClause.Occur.SHOULD);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(1, snippets.length);
Index: lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java	(revision 1661864)
+++ lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighter.java	(working copy)
@@ -76,7 +76,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "highlighting"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -145,7 +145,7 @@
     
     Query query = new TermQuery(new Term("body", "test"));
     
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     
     PostingsHighlighter highlighter = new PostingsHighlighter(maxLength);
@@ -179,7 +179,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(1, snippets.length);
@@ -214,7 +214,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -251,7 +251,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter(40);
     Query query = new TermQuery(new Term("body", "field"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(1, snippets.length);
@@ -291,7 +291,7 @@
     BooleanQuery query = new BooleanQuery();
     query.add(new TermQuery(new Term("body", "highlighting")), BooleanClause.Occur.SHOULD);
     query.add(new TermQuery(new Term("title", "best")), BooleanClause.Occur.SHOULD);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     Map<String,String[]> snippets = highlighter.highlightFields(new String [] { "body", "title" }, query, searcher, topDocs);
     assertEquals(2, snippets.size());
@@ -329,7 +329,7 @@
     query.add(new TermQuery(new Term("body", "highlighting")), BooleanClause.Occur.SHOULD);
     query.add(new TermQuery(new Term("body", "just")), BooleanClause.Occur.SHOULD);
     query.add(new TermQuery(new Term("body", "first")), BooleanClause.Occur.SHOULD);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(2, snippets.length);
@@ -363,7 +363,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 2);
     assertEquals(2, snippets.length);
@@ -401,7 +401,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     try {
       highlighter.highlight("body", query, searcher, topDocs, 2);
@@ -539,7 +539,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 2);
     assertEquals(1, snippets.length);
@@ -603,7 +603,7 @@
       }
     };
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 2);
     assertEquals(1, snippets.length);
@@ -636,7 +636,7 @@
     IndexSearcher searcher = newSearcher(ir);
     PostingsHighlighter highlighter = new PostingsHighlighter();
     Query query = new TermQuery(new Term("body", "highlighting"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(2, topDocs.totalHits);
     ScoreDoc[] hits = topDocs.scoreDocs;
     int[] docIDs = new int[2];
@@ -688,7 +688,7 @@
       };
 
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 2);
     assertEquals(1, snippets.length);
@@ -1015,7 +1015,7 @@
       }
     };
     Query query = new TermQuery(new Term("body", "highlighting"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(1, snippets.length);
@@ -1059,7 +1059,7 @@
       }
     };
     Query query = new TermQuery(new Term("body", "field"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs);
     assertEquals(1, snippets.length);
@@ -1106,7 +1106,7 @@
     };
 
     Query query = new TermQuery(new Term("body", "highlighting"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     int[] docIDs = new int[1];
     docIDs[0] = topDocs.scoreDocs[0].doc;
Index: lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java	(revision 1661864)
+++ lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.java	(working copy)
@@ -272,7 +272,7 @@
         }
       };
     Query query = new TermQuery(new Term("body", "test"));
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 1);
     assertEquals(1, snippets.length);
@@ -313,7 +313,7 @@
     BooleanQuery query = new BooleanQuery();
     query.add(new TermQuery(new Term("body", "foo")), BooleanClause.Occur.SHOULD);
     query.add(new TermQuery(new Term("body", "bar")), BooleanClause.Occur.SHOULD);
-    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);
+    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);
     assertEquals(1, topDocs.totalHits);
     String snippets[] = highlighter.highlight("body", query, searcher, topDocs, 1);
     assertEquals(1, snippets.length);
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(revision 1661864)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(working copy)
@@ -51,6 +51,7 @@
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.MultiTermQuery;
@@ -246,8 +247,8 @@
     assertEquals("Lisa", getParentDoc(r, parentsFilter, hits.scoreDocs[0].doc).get("name"));
 
     // Test with filter on child docs:
-    assertEquals(0, s.search(fullChildQuery,
-                             new QueryWrapperFilter(new TermQuery(new Term("skill", "foosball"))),
+    assertEquals(0, s.search(new FilteredQuery(fullChildQuery,
+                             new QueryWrapperFilter(new TermQuery(new Term("skill", "foosball")))),
                              1).totalHits);
     
     r.close();
@@ -354,20 +355,20 @@
       
     assertEquals("no filter - both passed", 2, s.search(childJoinQuery, 10).totalHits);
 
-    assertEquals("dummy filter passes everyone ", 2, s.search(childJoinQuery, parentsFilter, 10).totalHits);
-    assertEquals("dummy filter passes everyone ", 2, s.search(childJoinQuery, new QueryWrapperFilter(new TermQuery(new Term("docType", "resume"))), 10).totalHits);
+    assertEquals("dummy filter passes everyone ", 2, s.search(new FilteredQuery(childJoinQuery, parentsFilter), 10).totalHits);
+    assertEquals("dummy filter passes everyone ", 2, s.search(new FilteredQuery(childJoinQuery, new QueryWrapperFilter(new TermQuery(new Term("docType", "resume")))), 10).totalHits);
       
     // not found test
-    assertEquals("noone live there", 0, s.search(childJoinQuery, new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("country", "Oz")))), 1).totalHits);
-    assertEquals("noone live there", 0, s.search(childJoinQuery, new QueryWrapperFilter(new TermQuery(new Term("country", "Oz"))), 1).totalHits);
+    assertEquals("noone live there", 0, s.search(new FilteredQuery(childJoinQuery, new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("country", "Oz"))))), 1).totalHits);
+    assertEquals("noone live there", 0, s.search(new FilteredQuery(childJoinQuery, new QueryWrapperFilter(new TermQuery(new Term("country", "Oz")))), 1).totalHits);
       
     // apply the UK filter by the searcher
-    TopDocs ukOnly = s.search(childJoinQuery, new QueryWrapperFilter(parentQuery), 1);
+    TopDocs ukOnly = s.search(new FilteredQuery(childJoinQuery, new QueryWrapperFilter(parentQuery)), 1);
     assertEquals("has filter - single passed", 1, ukOnly.totalHits);
     assertEquals( "Lisa", r.document(ukOnly.scoreDocs[0].doc).get("name"));
 
     // looking for US candidates
-    TopDocs usThen = s.search(childJoinQuery , new QueryWrapperFilter(new TermQuery(new Term("country", "United States"))), 1);
+    TopDocs usThen = s.search(new FilteredQuery(childJoinQuery , new QueryWrapperFilter(new TermQuery(new Term("country", "United States")))), 1);
     assertEquals("has filter - single passed", 1, usThen.totalHits);
     assertEquals("Frank", r.document(usThen.scoreDocs[0].doc).get("name"));
     
@@ -377,14 +378,14 @@
         s.search(new ToChildBlockJoinQuery(us, 
                           parentsFilter), 10).totalHits );
 
-    assertEquals("java skills in US", 1, s.search(new ToChildBlockJoinQuery(us, parentsFilter),
-        skill("java"), 10).totalHits );
+    assertEquals("java skills in US", 1, s.search(new FilteredQuery(new ToChildBlockJoinQuery(us, parentsFilter),
+        skill("java")), 10).totalHits );
 
     BooleanQuery rubyPython = new BooleanQuery();
     rubyPython.add(new TermQuery(new Term("skill", "ruby")), Occur.SHOULD);
     rubyPython.add(new TermQuery(new Term("skill", "python")), Occur.SHOULD);
-    assertEquals("ruby skills in US", 1, s.search(new ToChildBlockJoinQuery(us, parentsFilter),
-                                          new QueryWrapperFilter(rubyPython), 10).totalHits );
+    assertEquals("ruby skills in US", 1, s.search(new FilteredQuery(new ToChildBlockJoinQuery(us, parentsFilter),
+                                          new QueryWrapperFilter(rubyPython)), 10).totalHits );
 
     r.close();
     dir.close();
@@ -786,7 +787,7 @@
       sortFields.addAll(Arrays.asList(childSort.getSort()));
       final Sort parentAndChildSort = new Sort(sortFields.toArray(new SortField[sortFields.size()]));
 
-      final TopDocs results = s.search(parentQuery, null, r.numDocs(),
+      final TopDocs results = s.search(parentQuery, r.numDocs(),
                                        parentAndChildSort);
 
       if (VERBOSE) {
@@ -922,30 +923,24 @@
       final ToChildBlockJoinQuery parentJoinQuery2 = new ToChildBlockJoinQuery(parentQuery2, parentsFilter);
 
       // To run against the block-join index:
-      final Query childJoinQuery2;
+      Query childJoinQuery2;
 
       // Same query as parentJoinQuery, but to run against
       // the fully denormalized index (so we can compare
       // results):
-      final Query childQuery2;
-      
-      // apply a filter to children
-      final Filter childFilter2, childJoinFilter2;
+      Query childQuery2;
 
       if (random().nextBoolean()) {
         childQuery2 = parentQuery2;
         childJoinQuery2 = parentJoinQuery2;
-        childFilter2 = null;
-        childJoinFilter2 = null;
       } else {
         final Term childTerm = randomChildTerm(childFields[0]);
         if (random().nextBoolean()) { // filtered case
           childJoinQuery2 = parentJoinQuery2;
           final Filter f = new QueryWrapperFilter(new TermQuery(childTerm));
-          childJoinFilter2 = random().nextBoolean()
-                  ? new BitDocIdSetCachingWrapperFilter(f): f;
+          childJoinQuery2 = new FilteredQuery(childJoinQuery2, random().nextBoolean()
+                  ? new BitDocIdSetCachingWrapperFilter(f): f);
         } else {
-          childJoinFilter2 = null;
           // AND child field w/ parent query:
           final BooleanQuery bq = new BooleanQuery();
           childJoinQuery2 = bq;
@@ -963,10 +958,9 @@
         if (random().nextBoolean()) { // filtered case
           childQuery2 = parentQuery2;
           final Filter f = new QueryWrapperFilter(new TermQuery(childTerm));
-          childFilter2 = random().nextBoolean()
-                  ? new BitDocIdSetCachingWrapperFilter(f): f;
+          childQuery2 = new FilteredQuery(childQuery2, random().nextBoolean()
+                  ? new BitDocIdSetCachingWrapperFilter(f): f);
         } else {
-          childFilter2 = null;
           final BooleanQuery bq2 = new BooleanQuery();
           childQuery2 = bq2;
           if (random().nextBoolean()) {
@@ -985,11 +979,9 @@
               
       // Search denormalized index:
       if (VERBOSE) {
-        System.out.println("TEST: run top down query=" + childQuery2 +
-            " filter=" + childFilter2 +
-            " sort=" + childSort2);
+        System.out.println("TEST: run top down query=" + childQuery2 + " sort=" + childSort2);
       }
-      final TopDocs results2 = s.search(childQuery2, childFilter2, r.numDocs(),
+      final TopDocs results2 = s.search(childQuery2, r.numDocs(),
                                         childSort2);
       if (VERBOSE) {
         System.out.println("  " + results2.totalHits + " totalHits:");
@@ -1001,10 +993,9 @@
 
       // Search join index:
       if (VERBOSE) {
-        System.out.println("TEST: run top down join query=" + childJoinQuery2 + 
-            " filter=" + childJoinFilter2 + " sort=" + childSort2);
+        System.out.println("TEST: run top down join query=" + childJoinQuery2 + " sort=" + childSort2);
       }
-      TopDocs joinResults2 = joinS.search(childJoinQuery2, childJoinFilter2, joinR.numDocs(), childSort2);
+      TopDocs joinResults2 = joinS.search(childJoinQuery2, joinR.numDocs(), childSort2);
       if (VERBOSE) {
         System.out.println("  " + joinResults2.totalHits + " totalHits:");
         for(ScoreDoc sd : joinResults2.scoreDocs) {
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java	(revision 1661864)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java	(working copy)
@@ -31,6 +31,7 @@
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
@@ -121,7 +122,7 @@
     Filter childFilter = new QueryWrapperFilter(new TermQuery(new Term("common_field", "1")));
     thrown.expect(IllegalStateException.class);
     thrown.expectMessage(ToChildBlockJoinQuery.ILLEGAL_ADVANCE_ON_PARENT);
-    indexSearcher.search(blockJoinQuery, childFilter, 1);
+    indexSearcher.search(new FilteredQuery(blockJoinQuery, childFilter), 1);
   }
 
   @Test
Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java	(revision 1661864)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSort.java	(working copy)
@@ -1006,7 +1006,7 @@
                     Collections.singletonMap("f", Type.SORTED));
     w.close();
     IndexSearcher s = newSearcher(r);
-    TopDocs hits = s.search(new TermQuery(new Term("t", "1")), null, 10, new Sort(new SortField("f", SortField.Type.STRING)));
+    TopDocs hits = s.search(new TermQuery(new Term("t", "1")), 10, new Sort(new SortField("f", SortField.Type.STRING)));
     assertEquals(2, hits.totalHits);
     // null sorts first
     assertEquals(1, hits.scoreDocs[0].doc);
@@ -1035,7 +1035,7 @@
                          Collections.singletonMap("string", Type.SORTED));
     IndexSearcher searcher = new IndexSearcher(reader);
     try {
-      searcher.search(new MatchAllDocsQuery(), null, 500, sort);
+      searcher.search(new MatchAllDocsQuery(), 500, sort);
       fail("didn't get expected exception");
     } catch (IllegalStateException expected) {}
     reader.close();
@@ -1069,10 +1069,10 @@
     Query q = new TermQuery(new Term("body", "text"));
     IndexSearcher s = newSearcher(r);
     float maxScore = s.search(q , 10).getMaxScore();
-    assertEquals(maxScore, s.search(q, null, 3, Sort.INDEXORDER, random().nextBoolean(), true).getMaxScore(), 0.0);
-    assertEquals(maxScore, s.search(q, null, 3, Sort.RELEVANCE, random().nextBoolean(), true).getMaxScore(), 0.0);
-    assertEquals(maxScore, s.search(q, null, 3, new Sort(new SortField[] {new SortField("id", SortField.Type.INT, false)}), random().nextBoolean(), true).getMaxScore(), 0.0);
-    assertEquals(maxScore, s.search(q, null, 3, new Sort(new SortField[] {new SortField("id", SortField.Type.INT, true)}), random().nextBoolean(), true).getMaxScore(), 0.0);
+    assertEquals(maxScore, s.search(q, 3, Sort.INDEXORDER, random().nextBoolean(), true).getMaxScore(), 0.0);
+    assertEquals(maxScore, s.search(q, 3, Sort.RELEVANCE, random().nextBoolean(), true).getMaxScore(), 0.0);
+    assertEquals(maxScore, s.search(q, 3, new Sort(new SortField[] {new SortField("id", SortField.Type.INT, false)}), random().nextBoolean(), true).getMaxScore(), 0.0);
+    assertEquals(maxScore, s.search(q, 3, new Sort(new SortField[] {new SortField("id", SortField.Type.INT, true)}), random().nextBoolean(), true).getMaxScore(), 0.0);
     TestUtil.checkReader(r);
     r.close();
     d.close();
@@ -1084,27 +1084,27 @@
     Query query = new TermQuery(new Term("contents", "foo"));
   
     Sort sort = new Sort();
-    TopDocs td = empty.search(query, null, 10, sort, true, true);
+    TopDocs td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
 
     sort.setSort(SortField.FIELD_DOC);
-    td = empty.search(query, null, 10, sort, true, true);
+    td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
 
     sort.setSort(new SortField("int", SortField.Type.INT), SortField.FIELD_DOC);
-    td = empty.search(query, null, 10, sort, true, true);
+    td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
     
     sort.setSort(new SortField("string", SortField.Type.STRING, true), SortField.FIELD_DOC);
-    td = empty.search(query, null, 10, sort, true, true);
+    td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
     
     sort.setSort(new SortField("string_val", SortField.Type.STRING_VAL, true), SortField.FIELD_DOC);
-    td = empty.search(query, null, 10, sort, true, true);
+    td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
 
     sort.setSort(new SortField("float", SortField.Type.FLOAT), new SortField("string", SortField.Type.STRING));
-    td = empty.search(query, null, 10, sort, true, true);
+    td = empty.search(query, 10, sort, true, true);
     assertEquals(0, td.totalHits);
   }
   
@@ -1146,7 +1146,7 @@
 
     TopDocs expected = searcher.search(new TermQuery(new Term("value", "foo")), 10);
     assertEquals(1, expected.totalHits);
-    TopDocs actual = searcher.search(new TermQuery(new Term("value", "foo")), null, 10, sort, true, true);
+    TopDocs actual = searcher.search(new TermQuery(new Term("value", "foo")), 10, sort, true, true);
     
     assertEquals(expected.totalHits, actual.totalHits);
     assertEquals(expected.scoreDocs[0].score, actual.scoreDocs[0].score, 0F);
Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java	(revision 1661864)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java	(working copy)
@@ -43,6 +43,7 @@
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Sort;
@@ -173,13 +174,13 @@
         // Set minNrShouldMatch to 1 so that BQ will not optimize rewrite to return
         // the clause instead of BQ.
         bq.setMinimumNumberShouldMatch(1);
-        hits = s.search(bq, f, hitCount, sort, random.nextBoolean(), random.nextBoolean());
+        hits = s.search(new FilteredQuery(bq, f), hitCount, sort, random.nextBoolean(), random.nextBoolean());
       } else if (queryType == 1) {
         hits = s.search(new ConstantScoreQuery(f),
-                        null, hitCount, sort, random.nextBoolean(), random.nextBoolean());
+                        hitCount, sort, random.nextBoolean(), random.nextBoolean());
       } else {
-        hits = s.search(new MatchAllDocsQuery(),
-                        f, hitCount, sort, random.nextBoolean(), random.nextBoolean());
+        hits = s.search(new FilteredQuery(new MatchAllDocsQuery(),
+                        f), hitCount, sort, random.nextBoolean(), random.nextBoolean());
       }
 
       if (VERBOSE) {
Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java	(revision 1661864)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms32.java	(working copy)
@@ -127,7 +127,7 @@
         int a=lower; lower=upper; upper=a;
       }
       Query tq=NumericRangeQuery.newIntRange(field, precisionStep, lower, upper, true, true);
-      TopDocs topDocs = searcher.search(tq, null, noDocs, new Sort(new SortField(field, SortField.Type.INT, true)));
+      TopDocs topDocs = searcher.search(tq, noDocs, new Sort(new SortField(field, SortField.Type.INT, true)));
       if (topDocs.totalHits==0) continue;
       ScoreDoc[] sd = topDocs.scoreDocs;
       assertNotNull(sd);
Index: lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java	(revision 1661864)
+++ lucene/misc/src/test/org/apache/lucene/uninverting/TestNumericTerms64.java	(working copy)
@@ -132,7 +132,7 @@
         long a=lower; lower=upper; upper=a;
       }
       Query tq=NumericRangeQuery.newLongRange(field, precisionStep, lower, upper, true, true);
-      TopDocs topDocs = searcher.search(tq, null, noDocs, new Sort(new SortField(field, SortField.Type.LONG, true)));
+      TopDocs topDocs = searcher.search(tq, noDocs, new Sort(new SortField(field, SortField.Type.LONG, true)));
       if (topDocs.totalHits==0) continue;
       ScoreDoc[] sd = topDocs.scoreDocs;
       assertNotNull(sd);
Index: lucene/queries/src/test/org/apache/lucene/queries/TestCustomScoreQuery.java
===================================================================
--- lucene/queries/src/test/org/apache/lucene/queries/TestCustomScoreQuery.java	(revision 1661864)
+++ lucene/queries/src/test/org/apache/lucene/queries/TestCustomScoreQuery.java	(working copy)
@@ -263,11 +263,11 @@
     log(q5CustomMulAdd);
 
     // do al the searches 
-    TopDocs td1 = s.search(q1, null, 1000);
-    TopDocs td2CustomNeutral = s.search(q2CustomNeutral, null, 1000);
-    TopDocs td3CustomMul = s.search(q3CustomMul, null, 1000);
-    TopDocs td4CustomAdd = s.search(q4CustomAdd, null, 1000);
-    TopDocs td5CustomMulAdd = s.search(q5CustomMulAdd, null, 1000);
+    TopDocs td1 = s.search(q1, 1000);
+    TopDocs td2CustomNeutral = s.search(q2CustomNeutral, 1000);
+    TopDocs td3CustomMul = s.search(q3CustomMul, 1000);
+    TopDocs td4CustomAdd = s.search(q4CustomAdd, 1000);
+    TopDocs td5CustomMulAdd = s.search(q5CustomMulAdd, 1000);
 
     // put results in map so we can verify the scores although they have changed
     Map<Integer,Float> h1               = topDocsToMap(td1);
Index: lucene/queries/src/test/org/apache/lucene/queries/function/TestFieldScoreQuery.java
===================================================================
--- lucene/queries/src/test/org/apache/lucene/queries/function/TestFieldScoreQuery.java	(revision 1661864)
+++ lucene/queries/src/test/org/apache/lucene/queries/function/TestFieldScoreQuery.java	(working copy)
@@ -64,7 +64,7 @@
     IndexSearcher s = newSearcher(r);
     log("test: "+ functionQuery);
     QueryUtils.check(random(), functionQuery,s);
-    ScoreDoc[] h = s.search(functionQuery, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(functionQuery, 1000).scoreDocs;
     assertEquals("All docs should be matched!",N_DOCS,h.length);
     String prevID = "ID"+(N_DOCS+1); // greater than all ids of docs in this test
     for (int i=0; i<h.length; i++) {
@@ -95,7 +95,7 @@
     FunctionQuery functionQuery = new FunctionQuery(valueSource);
     IndexReader r = DirectoryReader.open(dir);
     IndexSearcher s = newSearcher(r);
-    TopDocs td = s.search(functionQuery,null,1000);
+    TopDocs td = s.search(functionQuery,1000);
     assertEquals("All docs should be matched!",N_DOCS,td.totalHits);
     ScoreDoc sd[] = td.scoreDocs;
     for (ScoreDoc aSd : sd) {
Index: lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java
===================================================================
--- lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java	(revision 1661864)
+++ lucene/queries/src/test/org/apache/lucene/queries/function/TestValueSources.java	(working copy)
@@ -569,7 +569,7 @@
       expectedDocs[i] = i;
       expected[i] = new ScoreDoc(i, scores[i]);
     }
-    TopDocs docs = searcher.search(q, null, documents.size(),
+    TopDocs docs = searcher.search(q, documents.size(),
         new Sort(new SortField("id", SortField.Type.STRING)), true, false);
     CheckHits.checkHits(random(), q, "", searcher, expectedDocs);
     CheckHits.checkHitsQuery(q, expected, docs.scoreDocs, expectedDocs);
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestMultiFieldQueryParser.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestMultiFieldQueryParser.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestMultiFieldQueryParser.java	(working copy)
@@ -298,7 +298,7 @@
     Query q = mfqp.parse("the footest");
     IndexReader ir = DirectoryReader.open(ramDir);
     IndexSearcher is = newSearcher(ir);
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = is.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
     ir.close();
     ramDir.close();
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java	(working copy)
@@ -334,7 +334,7 @@
     Query q = mfqp.parse("the footest", null);
     IndexReader ir = DirectoryReader.open(ramDir);
     IndexSearcher is = newSearcher(ir);
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = is.search(q, 1000).scoreDocs;
     assertEquals(1, hits.length);
     ir.close();
     ramDir.close();
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java	(working copy)
@@ -1257,7 +1257,7 @@
     qp.setLocale(Locale.ENGLISH);
 
     Query q = qp.parse(query, "date");
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = is.search(q, 1000).scoreDocs;
     assertEquals(expected, hits.length);
   }
 
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java	(working copy)
@@ -1072,7 +1072,7 @@
     CommonQueryParserConfiguration qp = getParserConfig( new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));
     qp.setLocale(Locale.ENGLISH);
     Query q = getQuery(query,qp);
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] hits = is.search(q, 1000).scoreDocs;
     assertEquals(expected, hits.length);
     setDefaultField( oldDefaultField );
   }
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java	(working copy)
@@ -133,7 +133,7 @@
 
   public void testCustomFieldUserQueryXML() throws ParserException, IOException {
     Query q = parse("UserInputQueryCustomField.xml");
-    int h = searcher.search(q, null, 1000).totalHits;
+    int h = searcher.search(q, 1000).totalHits;
     assertEquals("UserInputQueryCustomField should produce 0 result ", 0, h);
   }
 
@@ -190,7 +190,7 @@
     List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();
     Assume.assumeTrue(leaves.size() == 1);
     Query q = parse("DuplicateFilterQuery.xml");
-    int h = searcher.search(q, null, 1000).totalHits;
+    int h = searcher.search(q, 1000).totalHits;
     assertEquals("DuplicateFilterQuery should produce 1 result ", 1, h);
   }
 
@@ -217,7 +217,7 @@
     if (VERBOSE) {
       System.out.println("TEST: query=" + q);
     }
-    TopDocs hits = searcher.search(q, null, numDocs);
+    TopDocs hits = searcher.search(q, numDocs);
     assertTrue(qType + " should produce results ", hits.totalHits > 0);
     if (VERBOSE) {
       System.out.println("=========" + qType + "============");
Index: lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestQueryTemplateManager.java
===================================================================
--- lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestQueryTemplateManager.java	(revision 1661864)
+++ lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestQueryTemplateManager.java	(working copy)
@@ -98,7 +98,7 @@
       Query q = builder.getQuery(doc.getDocumentElement());
 
       //Run the query
-      int h = searcher.search(q, null, 1000).totalHits;
+      int h = searcher.search(q, 1000).totalHits;
 
       //Check we have the expected number of results
       int expectedHits = Integer.parseInt(queryFormProperties.getProperty("expectedMatches"));
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java	(revision 1661864)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java	(working copy)
@@ -25,6 +25,7 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.*;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
@@ -84,7 +85,7 @@
   public void testDefaultFilter() throws Throwable {
     DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
     HashSet<String> results = new HashSet<>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new FilteredQuery(tq, df), 1000).scoreDocs;
 
     for (ScoreDoc hit : hits) {
       StoredDocument d = searcher.doc(hit.doc);
@@ -96,7 +97,7 @@
 
   public void testNoFilter() throws Throwable {
     HashSet<String> results = new HashSet<>();
-    ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(tq, 1000).scoreDocs;
     assertTrue("Default searching should have found some matches", hits.length > 0);
     boolean dupsFound = false;
 
@@ -114,7 +115,7 @@
     DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
     df.setProcessingMode(DuplicateFilter.ProcessingMode.PM_FAST_INVALIDATION);
     HashSet<String> results = new HashSet<>();
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new FilteredQuery(tq, df), 1000).scoreDocs;
     assertTrue("Filtered searching should have found some matches", hits.length > 0);
 
     for (ScoreDoc hit : hits) {
@@ -129,7 +130,7 @@
   public void testKeepsLastFilter() throws Throwable {
     DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
     df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_LAST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new FilteredQuery(tq, df), 1000).scoreDocs;
     assertTrue("Filtered searching should have found some matches", hits.length > 0);
     for (ScoreDoc hit : hits) {
       StoredDocument d = searcher.doc(hit.doc);
@@ -153,7 +154,7 @@
   public void testKeepsFirstFilter() throws Throwable {
     DuplicateFilter df = new DuplicateFilter(KEY_FIELD);
     df.setKeepMode(DuplicateFilter.KeepMode.KM_USE_FIRST_OCCURRENCE);
-    ScoreDoc[] hits = searcher.search(tq, df, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(new FilteredQuery(tq, df), 1000).scoreDocs;
     assertTrue("Filtered searching should have found some matches", hits.length > 0);
     for (ScoreDoc hit : hits) {
       StoredDocument d = searcher.doc(hit.doc);
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java	(revision 1661864)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java	(working copy)
@@ -60,32 +60,32 @@
     writer.close();
 
     SlowFuzzyQuery query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     
     // same with prefix
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(2, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 6);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
     // test scoring
     query = new SlowFuzzyQuery(new Term("field", "bbbbb"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("3 documents should match", 3, hits.length);
     List<String> order = Arrays.asList("bbbbb","abbbb","aabbb");
     for (int i = 0; i < hits.length; i++) {
@@ -97,7 +97,7 @@
     // test pq size by supplying maxExpansions=2
     // This query would normally return 3 documents, because 3 terms match (see above):
     query = new SlowFuzzyQuery(new Term("field", "bbbbb"), SlowFuzzyQuery.defaultMinSimilarity, 0, 2); 
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("only 2 documents should match", 2, hits.length);
     order = Arrays.asList("bbbbb","abbbb");
     for (int i = 0; i < hits.length; i++) {
@@ -108,15 +108,15 @@
 
     // not similar enough:
     query = new SlowFuzzyQuery(new Term("field", "xxxxx"), SlowFuzzyQuery.defaultMinSimilarity, 0);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "aaccc"), SlowFuzzyQuery.defaultMinSimilarity, 0);   // edit distance to "aaaaa" = 3
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // query identical to a word in the index:
     query = new SlowFuzzyQuery(new Term("field", "aaaaa"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     // default allows for up to two edits:
@@ -125,7 +125,7 @@
 
     // query similar to a word in the index:
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
@@ -133,63 +133,63 @@
     
     // now with prefix
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     assertEquals(searcher.doc(hits[2].doc).get("field"), ("aaabb"));
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(2, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaa"));
     assertEquals(searcher.doc(hits[1].doc).get("field"), ("aaaab"));
     query = new SlowFuzzyQuery(new Term("field", "aaaac"), SlowFuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
 
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     
     // now with prefix
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 3);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("ddddd"));
     query = new SlowFuzzyQuery(new Term("field", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
 
     // different field = no match:
     query = new SlowFuzzyQuery(new Term("anotherfield", "ddddX"), SlowFuzzyQuery.defaultMinSimilarity, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     reader.close();
@@ -210,11 +210,11 @@
      SlowFuzzyQuery query;
      
      query = new SlowFuzzyQuery(new Term("field", "abcxxxx"), 3f, 0);   
-     ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+     ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
      assertEquals(0, hits.length);
      
      query = new SlowFuzzyQuery(new Term("field", "abcxxxx"), 4f, 0);   
-     hits = searcher.search(query, null, 1000).scoreDocs;
+     hits = searcher.search(query, 1000).scoreDocs;
      assertEquals(1, hits.length);
      reader.close();
      directory.close();
@@ -233,63 +233,63 @@
     SlowFuzzyQuery query;
     // not similar enough:
     query = new SlowFuzzyQuery(new Term("field", "xxxxx"), 0.5f, 0);   
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     // edit distance to "aaaaaaa" = 3, this matches because the string is longer than
     // in testDefaultFuzziness so a bigger difference is allowed:
     query = new SlowFuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     
     // now with prefix
     query = new SlowFuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     query = new SlowFuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 4);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     assertEquals(searcher.doc(hits[0].doc).get("field"), ("aaaaaaa"));
     query = new SlowFuzzyQuery(new Term("field", "aaaaccc"), 0.5f, 5);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // no match, more than half of the characters is wrong:
     query = new SlowFuzzyQuery(new Term("field", "aaacccc"), 0.5f, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     // now with prefix
     query = new SlowFuzzyQuery(new Term("field", "aaacccc"), 0.5f, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // "student" and "stellent" are indeed similar to "segment" by default:
     query = new SlowFuzzyQuery(new Term("field", "student"), 0.5f, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "stellent"), 0.5f, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     
     // now with prefix
     query = new SlowFuzzyQuery(new Term("field", "student"), 0.5f, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "stellent"), 0.5f, 1);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "student"), 0.5f, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     query = new SlowFuzzyQuery(new Term("field", "stellent"), 0.5f, 2);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     // "student" doesn't match anymore thanks to increased minimum similarity:
     query = new SlowFuzzyQuery(new Term("field", "student"), 0.6f, 0);   
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     try {
@@ -363,22 +363,22 @@
     Query query;
     // term not over 10 chars, so optimization shortcuts
     query = new SlowFuzzyQuery(new Term("field", "1234569"), 0.9f);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
 
     // 10 chars, so no optimization
     query = new SlowFuzzyQuery(new Term("field", "1234567891"), 0.9f);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     // over 10 chars, so no optimization
     query = new SlowFuzzyQuery(new Term("field", "12345678911"), 0.9f);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(1, hits.length);
 
     // over 10 chars, no match
     query = new SlowFuzzyQuery(new Term("field", "sdfsdfsdfsdf"), 0.9f);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(0, hits.length);
     
     reader.close();
@@ -399,7 +399,7 @@
     
     SlowFuzzyQuery query = new SlowFuzzyQuery(new Term("field", "lucene"));
     query.setRewriteMethod(new MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite(50));
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals(3, hits.length);
     // normally, 'Lucenne' would be the first result as IDF will skew the score.
     assertEquals("Lucene", reader.document(hits[0].doc).get("field"));
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java	(revision 1661864)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestRegexQuery.java	(working copy)
@@ -69,7 +69,7 @@
     if ( capability != null )
       query.setRegexImplementation(capability);
     
-    return searcher.search(query, null, 1000).totalHits;
+    return searcher.search(query, 1000).totalHits;
   }
 
   private int  spanRegexQueryNrHits(String regex1, String regex2, int slop, boolean ordered) throws Exception {
@@ -77,7 +77,7 @@
     SpanQuery srq2 = new SpanMultiTermQueryWrapper<>(new RegexQuery(newTerm(regex2)));
     SpanNearQuery query = new SpanNearQuery( new SpanQuery[]{srq1, srq2}, slop, ordered);
 
-    return searcher.search(query, null, 1000).totalHits;
+    return searcher.search(query, 1000).totalHits;
   }
 
   public void testMatchAll() throws Exception {
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java	(revision 1661864)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/regex/TestSpanRegexQuery.java	(working copy)
@@ -73,7 +73,7 @@
     SpanFirstQuery sfq = new SpanFirstQuery(srq, 1);
     // SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {srq, stq}, 6,
     // true);
-    int numHits = searcher.search(sfq, null, 1000).totalHits;
+    int numHits = searcher.search(sfq, 1000).totalHits;
     assertEquals(1, numHits);
     reader.close();
     directory.close();
Index: lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java	(revision 1661864)
+++ lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java	(working copy)
@@ -575,15 +575,16 @@
         System.out.println(q.toDot());
       }
       
-      Filter filter;
+      Query q1 = q;
+      Query q2 = bq;
       if (random().nextInt(5) == 1) {
-        filter = new RandomFilter(random().nextLong(), random().nextFloat());
-      } else {
-        filter = null;
+        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());
+        q1 = new FilteredQuery(q1, filter);
+        q2 = new FilteredQuery(q2, filter);
       }
 
-      TopDocs hits1 = s.search(q, filter, numDocs);
-      TopDocs hits2 = s.search(bq, filter, numDocs);
+      TopDocs hits1 = s.search(q1, numDocs);
+      TopDocs hits2 = s.search(q2, numDocs);
       Set<String> hits1Docs = toDocIDs(s, hits1);
       Set<String> hits2Docs = toDocIDs(s, hits2);
 
Index: lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java
===================================================================
--- lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java	(revision 1661864)
+++ lucene/spatial/src/test/org/apache/lucene/spatial/SpatialExample.java	(working copy)
@@ -21,6 +21,7 @@
 import com.spatial4j.core.distance.DistanceUtils;
 import com.spatial4j.core.shape.Point;
 import com.spatial4j.core.shape.Shape;
+
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.IntField;
@@ -33,6 +34,7 @@
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Sort;
@@ -152,7 +154,7 @@
       SpatialArgs args = new SpatialArgs(SpatialOperation.Intersects,
           ctx.makeCircle(-80.0, 33.0, DistanceUtils.dist2Degrees(200, DistanceUtils.EARTH_MEAN_RADIUS_KM)));
       Filter filter = strategy.makeFilter(args);
-      TopDocs docs = indexSearcher.search(new MatchAllDocsQuery(), filter, 10, idSort);
+      TopDocs docs = indexSearcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 10, idSort);
       assertDocMatchedIds(indexSearcher, docs, 2);
       //Now, lets get the distance for the 1st doc via computing from stored point value:
       // (this computation is usually not redundant)
Index: lucene/spatial/src/test/org/apache/lucene/spatial/prefix/HeatmapFacetCounterTest.java
===================================================================
--- lucene/spatial/src/test/org/apache/lucene/spatial/prefix/HeatmapFacetCounterTest.java	(revision 1661864)
+++ lucene/spatial/src/test/org/apache/lucene/spatial/prefix/HeatmapFacetCounterTest.java	(working copy)
@@ -31,7 +31,9 @@
 import com.spatial4j.core.shape.Shape;
 import com.spatial4j.core.shape.SpatialRelation;
 import com.spatial4j.core.shape.impl.RectangleImpl;
+
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.TotalHitCountCollector;
 import org.apache.lucene.spatial.StrategyTestCase;
@@ -235,7 +237,7 @@
     Filter filter = new IntersectsPrefixTreeFilter(
         pt, strategy.getFieldName(), grid, facetLevel, grid.getMaxLevels(), !strategy.isPointsOnly());
     final TotalHitCountCollector collector = new TotalHitCountCollector();
-    indexSearcher.search(new MatchAllDocsQuery(), filter, collector);
+    indexSearcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), collector);
     cellsValidated++;
     if (collector.getTotalHits() > 0) {
       cellValidatedNonZero++;
Index: lucene/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java	(revision 1661864)
+++ lucene/suggest/src/java/org/apache/lucene/search/spell/SpellChecker.java	(working copy)
@@ -364,7 +364,7 @@
       int maxHits = 10 * numSug;
 
   //    System.out.println("Q: " + query);
-      ScoreDoc[] hits = indexSearcher.search(query, null, maxHits).scoreDocs;
+      ScoreDoc[] hits = indexSearcher.search(query, maxHits).scoreDocs;
   //    System.out.println("HITS: " + hits.length());
       SuggestWordQueue sugQueue = new SuggestWordQueue(numSug, comparator);
 
Index: lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase.java	(working copy)
@@ -34,6 +34,7 @@
 import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
@@ -77,11 +78,11 @@
     // Collator (or an Arabic one for the case when Farsi searcher not
     // supported).
     ScoreDoc[] result = searcher.search
-      (query, new TermRangeFilter("content", firstBeg, firstEnd, true, true), 1).scoreDocs;
+      (new FilteredQuery(query, new TermRangeFilter("content", firstBeg, firstEnd, true, true)), 1).scoreDocs;
     assertEquals("The index Term should not be included.", 0, result.length);
 
     result = searcher.search
-      (query, new TermRangeFilter("content", secondBeg, secondEnd, true, true), 1).scoreDocs;
+      (new FilteredQuery(query, new TermRangeFilter("content", secondBeg, secondEnd, true, true)), 1).scoreDocs;
     assertEquals("The index Term should be included.", 1, result.length);
 
     reader.close();
@@ -106,11 +107,11 @@
     IndexSearcher searcher = new IndexSearcher(reader);
 
     Query query = new TermRangeQuery("content", firstBeg, firstEnd, true, true);
-    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;
+    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("The index Term should not be included.", 0, hits.length);
 
     query = new TermRangeQuery("content", secondBeg, secondEnd, true, true);
-    hits = searcher.search(query, null, 1000).scoreDocs;
+    hits = searcher.search(query, 1000).scoreDocs;
     assertEquals("The index Term should be included.", 1, hits.length);
     reader.close();
     dir.close();
@@ -137,12 +138,12 @@
     // not supported).
     Query csrq 
       = new TermRangeQuery("content", firstBeg, firstEnd, true, true);
-    ScoreDoc[] result = search.search(csrq, null, 1000).scoreDocs;
+    ScoreDoc[] result = search.search(csrq, 1000).scoreDocs;
     assertEquals("The index Term should not be included.", 0, result.length);
 
     csrq = new TermRangeQuery
       ("content", secondBeg, secondEnd, true, true);
-    result = search.search(csrq, null, 1000).scoreDocs;
+    result = search.search(csrq, 1000).scoreDocs;
     assertEquals("The index Term should be included.", 1, result.length);
     reader.close();
     farsiIndex.close();
@@ -152,7 +153,7 @@
   // Copied from TestSort.java
   private void assertMatches(IndexSearcher searcher, Query query, Sort sort, 
                              String expectedResult) throws IOException {
-    ScoreDoc[] result = searcher.search(query, null, 1000, sort).scoreDocs;
+    ScoreDoc[] result = searcher.search(query, 1000, sort).scoreDocs;
     StringBuilder buff = new StringBuilder(10);
     int n = result.length;
     for (int i = 0 ; i < n ; ++i) {
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase.java	(working copy)
@@ -111,7 +111,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -143,7 +143,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -176,7 +176,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -211,7 +211,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -248,7 +248,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -285,7 +285,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -326,7 +326,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     BytesRef scratch = new BytesRef();
     // Iterate through the results:
@@ -488,7 +488,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     // Iterate through the results:
     for (int i = 0; i < hits.scoreDocs.length; i++) {
@@ -592,7 +592,7 @@
 
     assertEquals(1, isearcher.search(new TermQuery(new Term("fieldname", longTerm)), 1).totalHits);
     Query query = new TermQuery(new Term("fieldname", "text"));
-    TopDocs hits = isearcher.search(query, null, 1);
+    TopDocs hits = isearcher.search(query, 1);
     assertEquals(1, hits.totalHits);
     BytesRef scratch = new BytesRef();
     // Iterate through the results:
Index: lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/index/ThreadedIndexingAndSearchingTestCase.java	(working copy)
@@ -665,9 +665,9 @@
 
   private int runQuery(IndexSearcher s, Query q) throws Exception {
     s.search(q, 10);
-    int hitCount = s.search(q, null, 10, new Sort(new SortField("titleDV", SortField.Type.STRING))).totalHits;
+    int hitCount = s.search(q, 10, new Sort(new SortField("titleDV", SortField.Type.STRING))).totalHits;
     final Sort dvSort = new Sort(new SortField("titleDV", SortField.Type.STRING));
-    int hitCount2 = s.search(q, null, 10, dvSort).totalHits;
+    int hitCount2 = s.search(q, 10, dvSort).totalHits;
     assertEquals(hitCount, hitCount2);
     return hitCount;
   }
Index: lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/search/AssertingIndexSearcher.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Helper class that adds some extra checks to ensure correct
@@ -98,13 +97,6 @@
   }
 
   @Override
-  protected Query wrapFilter(Query query, Filter filter) {
-    if (random.nextBoolean())
-      return super.wrapFilter(query, filter);
-    return (filter == null) ? query : new FilteredQuery(query, filter, TestUtil.randomFilterStrategy(random));
-  }
-
-  @Override
   protected void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {
     // TODO: shouldn't we AssertingCollector.wrap(collector) here?
     super.search(leaves, AssertingWeight.wrap(random, weight), AssertingCollector.wrap(random, collector));
Index: lucene/test-framework/src/java/org/apache/lucene/search/CheckHits.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/CheckHits.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/search/CheckHits.java	(working copy)
@@ -424,18 +424,17 @@
       super(r);
     }
     protected void checkExplanations(Query q) throws IOException {
-      super.search(q, null,
+      super.search(q,
                    new ExplanationAsserter
                    (q, null, this));
     }
     @Override
     public TopFieldDocs search(Query query,
-                               Filter filter,
                                int n,
                                Sort sort) throws IOException {
       
       checkExplanations(query);
-      return super.search(query,filter,n,sort);
+      return super.search(query,n,sort);
     }
     @Override
     public void search(Query query, Collector results) throws IOException {
@@ -443,16 +442,10 @@
       super.search(query, results);
     }
     @Override
-    public void search(Query query, Filter filter, Collector results) throws IOException {
-      checkExplanations(query);
-      super.search(query, filter, results);
-    }
-    @Override
-    public TopDocs search(Query query, Filter filter,
-                          int n) throws IOException {
+    public TopDocs search(Query query, int n) throws IOException {
 
       checkExplanations(query);
-      return super.search(query,filter, n);
+      return super.search(query, n);
     }
   }
     
Index: lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java	(revision 1661864)
+++ lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java	(working copy)
@@ -180,11 +180,15 @@
    * Both queries will be filtered by <code>filter</code>
    */
   protected void assertSubsetOf(Query q1, Query q2, Filter filter) throws Exception {
+    if (filter != null) {
+      q1 = new FilteredQuery(q1, filter);
+      q2 = new FilteredQuery(q2, filter);
+    }
     // we test both INDEXORDER and RELEVANCE because we want to test needsScores=true/false
     for (Sort sort : new Sort[] { Sort.INDEXORDER, Sort.RELEVANCE }) {
       // not efficient, but simple!
-      TopDocs td1 = s1.search(q1, filter, reader.maxDoc(), sort);
-      TopDocs td2 = s2.search(q2, filter, reader.maxDoc(), sort);
+      TopDocs td1 = s1.search(q1, reader.maxDoc(), sort);
+      TopDocs td2 = s2.search(q2, reader.maxDoc(), sort);
       assertTrue(td1.totalHits <= td2.totalHits);
       
       // fill the superset into a bitset
@@ -222,8 +226,12 @@
 
   protected void assertSameScores(Query q1, Query q2, Filter filter) throws Exception {
     // not efficient, but simple!
-    TopDocs td1 = s1.search(q1, filter, reader.maxDoc());
-    TopDocs td2 = s2.search(q2, filter, reader.maxDoc());
+    if (filter != null) {
+      q1 = new FilteredQuery(q1, filter);
+      q2 = new FilteredQuery(q2, filter);
+    }
+    TopDocs td1 = s1.search(q1, reader.maxDoc());
+    TopDocs td2 = s2.search(q2, reader.maxDoc());
     assertEquals(td1.totalHits, td2.totalHits);
     for (int i = 0; i < td1.scoreDocs.length; ++i) {
       assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
Index: solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
===================================================================
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java	(revision 1661864)
+++ solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java	(working copy)
@@ -33,6 +33,7 @@
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.Query;
 import org.apache.solr.analytics.accumulator.facet.FacetValueAccumulator;
 import org.apache.solr.analytics.accumulator.facet.FieldFacetAccumulator;
@@ -611,7 +612,7 @@
         }
         // The searcher sends docIds to the QueryFacetAccumulator which forwards
         // them to <code>collectQuery()</code> in this class for collection.
-        searcher.search(q, filter, qAcc);
+        searcher.search(new FilteredQuery(q, filter), qAcc);
         computeQueryFacet(qfr.getName());
         queryCount++;
       }
@@ -715,7 +716,7 @@
         RangeFacetAccumulator rAcc = new RangeFacetAccumulator(this,rfr.getName(),facetValue);
         // The searcher sends docIds to the RangeFacetAccumulator which forwards
         // them to <code>collectRange()</code> in this class for collection.
-        searcher.search(q, filter, rAcc);
+        searcher.search(new FilteredQuery(q, filter), rAcc);
         computeRangeFacet(sf.getName());
       }
     }
Index: solr/core/src/java/org/apache/solr/handler/BlobHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/BlobHandler.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/handler/BlobHandler.java	(working copy)
@@ -119,7 +119,7 @@
         }
 
         TopFieldDocs docs = req.getSearcher().search(new TermQuery(new Term("blobName", blobName)),
-            null, 1, new Sort(new SortField("version", SortField.Type.LONG, true)));
+            1, new Sort(new SortField("version", SortField.Type.LONG, true)));
 
         long version = 0;
         if(docs.totalHits >0){
Index: solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java	(working copy)
@@ -40,6 +40,7 @@
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
@@ -377,7 +378,11 @@
       collector = groupExpandCollector;
     }
 
-    searcher.search(query, pfilter.filter, collector);
+    if (pfilter.filter == null) {
+      searcher.search(query, collector);
+    } else {
+      searcher.search(new FilteredQuery(query, pfilter.filter), collector);
+    }
     LongObjectMap groups = ((GroupCollector)groupExpandCollector).getGroups();
     Map<String, DocSlice> outMap = new HashMap<>();
     CharsRefBuilder charsRef = new CharsRefBuilder();
Index: solr/core/src/java/org/apache/solr/request/SimpleFacets.java
===================================================================
--- solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(working copy)
@@ -48,6 +48,7 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilterCollector;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
@@ -225,7 +226,7 @@
           return;
         }
         AbstractAllGroupHeadsCollector allGroupHeadsCollector = grouping.getCommands().get(0).createAllGroupCollector();
-        searcher.search(new MatchAllDocsQuery(), base.getTopFilter(), allGroupHeadsCollector);
+        searcher.search(new FilteredQuery(new MatchAllDocsQuery(), base.getTopFilter()), allGroupHeadsCollector);
         this.docs = new BitDocSet(allGroupHeadsCollector.retrieveGroupHeads(searcher.maxDoc()));
       } else {
         this.docs = base;
@@ -325,7 +326,7 @@
     
     TermAllGroupsCollector collector = new TermAllGroupsCollector(groupField);
     Filter mainQueryFilter = docs.getTopFilter(); // This returns a filter that only matches documents matching with q param and fq params
-    searcher.search(facetQuery, mainQueryFilter, collector);
+    searcher.search(new FilteredQuery(facetQuery, mainQueryFilter), collector);
     return collector.getGroupCount();
   }
 
@@ -495,7 +496,7 @@
     if (sf != null && sf.hasDocValues() == false && sf.multiValued() == false && sf.getType().getNumericType() != null) {
       // it's a single-valued numeric field: we must currently create insanity :(
       // there isn't a GroupedFacetCollector that works on numerics right now...
-      searcher.search(new MatchAllDocsQuery(), base.getTopFilter(), new FilterCollector(collector) {
+      searcher.search(new FilteredQuery(new MatchAllDocsQuery(), base.getTopFilter()), new FilterCollector(collector) {
         @Override
         public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
           LeafReader insane = Insanity.wrapInsanity(context.reader(), groupField);
@@ -503,7 +504,7 @@
         }
       });
     } else {
-      searcher.search(new MatchAllDocsQuery(), base.getTopFilter(), collector);
+      searcher.search(new FilteredQuery(new MatchAllDocsQuery(), base.getTopFilter()), collector);
     }
     
     boolean orderByCount = sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY);
Index: solr/core/src/java/org/apache/solr/search/Grouping.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/Grouping.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/search/Grouping.java	(working copy)
@@ -35,6 +35,7 @@
 import org.apache.lucene.search.CachingCollector;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
@@ -449,7 +450,11 @@
       collector = timeLimitingCollector;
     }
     try {
-      searcher.search(query, luceneFilter, collector);
+      Query q = query;
+      if (luceneFilter != null) {
+        q = new FilteredQuery(q, luceneFilter);
+      }
+      searcher.search(q, collector);
     } catch (TimeLimitingCollector.TimeExceededException | ExitableDirectoryReader.ExitingReaderException x) {
       logger.warn( "Query: " + query + "; " + x.getMessage() );
       qr.setPartialResults(true);
Index: solr/core/src/java/org/apache/solr/search/LuceneQueryOptimizer.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/LuceneQueryOptimizer.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/search/LuceneQueryOptimizer.java	(working copy)
@@ -110,7 +110,7 @@
       queryOut[0] = query; filterOut[0] = filter;
       return null;
     } else {
-      return searcher.search(query, filter, numHits);
+      return searcher.search(new FilteredQuery(query, filter), numHits);
     }
 
   }
Index: solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(working copy)
@@ -180,7 +180,7 @@
    * and postFilter as well as any needed collector wrappers for dealing with options 
    * specified in the QueryCOmmand.
    */
-  private void buildAndRunCollectorChain(QueryResult qr, Query query, Filter luceneFilter,
+  private void buildAndRunCollectorChain(QueryResult qr, Query query,
       Collector collector, QueryCommand cmd, DelegatingCollector postFilter) throws IOException {
     
     final boolean terminateEarly = (cmd.getFlags() & TERMINATE_EARLY) == TERMINATE_EARLY;
@@ -199,7 +199,7 @@
     }
     
     try {
-      super.search(query, luceneFilter, collector);
+      super.search(query, collector);
       if(collector instanceof DelegatingCollector) {
         ((DelegatingCollector)collector).finish();
       }
@@ -949,7 +949,11 @@
       collector = pf.postFilter;
     }
 
-    search(main, pf.filter, collector);
+    if (pf.filter != null) {
+      search(new FilteredQuery(main, pf.filter), collector);
+    } else {
+      search(main, collector);
+    }
 
     if(collector instanceof DelegatingCollector) {
       ((DelegatingCollector) collector).finish();
@@ -1229,10 +1233,10 @@
 
     try {
       if (filter == null) {
-        super.search(query, null, collector);
+        super.search(query, collector);
       } else {
         Filter luceneFilter = filter.getTopFilter();
-        super.search(query, luceneFilter, collector);
+        super.search(new FilteredQuery(query, luceneFilter), collector);
       }
     } catch ( ExitableDirectoryReader.ExitingReaderException e) {
         log.warn("Query: " + query + "; " + e.getMessage());
@@ -1596,7 +1600,9 @@
     Query query = QueryUtils.makeQueryable(cmd.getQuery());
 
     ProcessedFilter pf = getProcessedFilter(cmd.getFilter(), cmd.getFilterList());
-    final Filter luceneFilter = pf.filter;
+    if (pf.filter != null) {
+      query = new FilteredQuery(query, pf.filter);
+    }
 
     // handle zero case...
     if (lastDocRequested<=0) {
@@ -1638,7 +1644,7 @@
         };
       }
       
-      buildAndRunCollectorChain(qr, query, luceneFilter, collector, cmd, pf.postFilter);
+      buildAndRunCollectorChain(qr, query, collector, cmd, pf.postFilter);
 
       nDocsReturned=0;
       ids = new int[nDocsReturned];
@@ -1650,7 +1656,7 @@
     } else {
       final TopDocsCollector topCollector = buildTopDocsCollector(len, cmd);
       Collector collector = topCollector;
-      buildAndRunCollectorChain(qr, query, luceneFilter, collector, cmd, pf.postFilter);
+      buildAndRunCollectorChain(qr, query, collector, cmd, pf.postFilter);
 
       totalHits = topCollector.getTotalHits();
       TopDocs topDocs = topCollector.topDocs(0, len);
@@ -1691,9 +1697,10 @@
     int smallSetSize = maxDoc>>6;
 
     ProcessedFilter pf = getProcessedFilter(cmd.getFilter(), cmd.getFilterList());
-    final Filter luceneFilter = pf.filter;
-
     Query query = QueryUtils.makeQueryable(cmd.getQuery());
+    if (pf.filter != null) {
+      query = new FilteredQuery(query, pf.filter);
+    }
 
     // handle zero case...
     if (lastDocRequested<=0) {
@@ -1729,7 +1736,7 @@
         collector = MultiCollector.wrap(setCollector, topScoreCollector);
        }
        
-       buildAndRunCollectorChain(qr, query, luceneFilter, collector, cmd, pf.postFilter);
+       buildAndRunCollectorChain(qr, query, collector, cmd, pf.postFilter);
 
       set = setCollector.getDocSet();
 
@@ -1746,7 +1753,7 @@
       DocSetCollector setCollector = new DocSetCollector(maxDoc>>6, maxDoc);
       Collector collector = MultiCollector.wrap(topCollector, setCollector);
 
-      buildAndRunCollectorChain(qr, query, luceneFilter, collector, cmd, pf.postFilter);
+      buildAndRunCollectorChain(qr, query, collector, cmd, pf.postFilter);
 
       set = setCollector.getDocSet();      
 
@@ -2075,7 +2082,7 @@
       BooleanQuery bq = new BooleanQuery();
       bq.add(QueryUtils.makeQueryable(a), BooleanClause.Occur.MUST);
       bq.add(new ConstantScoreQuery(b.getTopFilter()), BooleanClause.Occur.MUST);
-      super.search(bq, null, collector);
+      super.search(bq, collector);
       return collector.getTotalHits();
     }
   }
Index: solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java	(revision 1661864)
+++ solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java	(working copy)
@@ -26,6 +26,7 @@
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TimeLimitingCollector;
@@ -208,8 +209,8 @@
    * Invokes search with the specified filter and collector.  
    * If a time limit has been specified then wrap the collector in the TimeLimitingCollector
    */
-  private void searchWithTimeLimiter(final Query query, 
-                                     final ProcessedFilter filter, 
+  private void searchWithTimeLimiter(Query query, 
+                                     ProcessedFilter filter, 
                                      Collector collector) throws IOException {
     if (queryCommand.getTimeAllowed() > 0 ) {
       collector = new TimeLimitingCollector(collector, TimeLimitingCollector.getGlobalCounter(), queryCommand.getTimeAllowed());
@@ -220,7 +221,9 @@
       collector = MultiCollector.wrap(collector, hitCountCollector);
     }
 
-    Filter luceneFilter = filter.filter;
+    if (filter.filter != null) {
+      query = new FilteredQuery(query, filter.filter);
+    }
     if (filter.postFilter != null) {
       filter.postFilter.setLastDelegate(collector);
       collector = filter.postFilter;
@@ -227,7 +230,7 @@
     }
 
     try {
-      searcher.search(query, luceneFilter, collector);
+      searcher.search(query, collector);
     } catch (TimeLimitingCollector.TimeExceededException | ExitableDirectoryReader.ExitingReaderException x) {
       partialResults = true;
       logger.warn( "Query: " + query + "; " + x.getMessage() );
Index: solr/core/src/test/org/apache/solr/search/TestSort.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/TestSort.java	(revision 1661864)
+++ solr/core/src/test/org/apache/solr/search/TestSort.java	(working copy)
@@ -40,6 +40,7 @@
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilterCollector;
 import org.apache.lucene.search.FilterLeafCollector;
+import org.apache.lucene.search.FilteredQuery;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.MatchAllDocsQuery;
@@ -52,8 +53,8 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.uninverting.UninvertingReader;
+import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4;
@@ -295,7 +296,7 @@
 
         };
 
-        searcher.search(new MatchAllDocsQuery(), filt, myCollector);
+        searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filt), myCollector);
 
         Collections.sort(collectedDocs, new Comparator<MyDoc>() {
           @Override
Index: solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java	(revision 1661864)
+++ solr/core/src/test/org/apache/solr/search/function/TestOrdValues.java	(working copy)
@@ -97,7 +97,7 @@
     Query q = new FunctionQuery(vs);
     log("test: " + q);
     QueryUtils.check(random(), q, s);
-    ScoreDoc[] h = s.search(q, null, 1000).scoreDocs;
+    ScoreDoc[] h = s.search(q, 1000).scoreDocs;
     assertEquals("All docs should be matched!", N_DOCS, h.length);
     String prevID = inOrder
             ? "IE"   // greater than all ids of docs in this test ("ID0001", etc.)
@@ -145,7 +145,7 @@
       vs = new ReverseOrdFieldSource(field);
     }
     Query q = new FunctionQuery(vs);
-    TopDocs td = s.search(q, null, 1000);
+    TopDocs td = s.search(q, 1000);
     assertEquals("All docs should be matched!", N_DOCS, td.totalHits);
     ScoreDoc sd[] = td.scoreDocs;
     for (int i = 0; i < sd.length; i++) {
