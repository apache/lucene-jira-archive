Index: lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java	(revision )
@@ -21,6 +21,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.lucene.index.MergePolicy.OneMerge;
 import org.apache.lucene.store.AlreadyClosedException;
@@ -336,13 +337,13 @@
           mergeStartNS = now;
         }
         message.append('\n');
-        message.append(String.format(Locale.ROOT, "merge thread %s estSize=%.1f MB (written=%.1f MB) runTime=%.1fs (stopped=%.1fs, paused=%.1fs) rate=%s\n",
+        message.append(String.format(Locale.ROOT, "merge thread %s estSize=%.1f MB (written=%.1f MB) runTime=%ds (stopped=%ds, paused=%ds) rate=%s\n",
                                      mergeThread.getName(),
                                      bytesToMB(merge.estimatedMergeBytes),
                                      bytesToMB(merge.rateLimiter.totalBytesWritten),
-                                     nsToSec(now - mergeStartNS),
-                                     nsToSec(merge.rateLimiter.getTotalStoppedNS()),
-                                     nsToSec(merge.rateLimiter.getTotalPausedNS()),
+                                     TimeUnit.NANOSECONDS.toSeconds(now - mergeStartNS),
+                                     TimeUnit.NANOSECONDS.toSeconds(merge.rateLimiter.getTotalStoppedNS()),
+                                     TimeUnit.NANOSECONDS.toSeconds(merge.rateLimiter.getTotalPausedNS()),
                                      rateToString(merge.rateLimiter.getMBPerSec())));
 
         if (newMBPerSec != curMBPerSec) {
@@ -692,11 +693,11 @@
   private boolean isBacklog(long now, OneMerge merge) {
     double mergeMB = bytesToMB(merge.estimatedMergeBytes);
     for (MergeThread mergeThread : mergeThreads) {
-      long mergeStartNS = mergeThread.merge.mergeStartNS;
+      final long mergeStartNS = mergeThread.merge.mergeStartNS;
       if (mergeThread.isAlive() && mergeThread.merge != merge &&
           mergeStartNS != -1 &&
           mergeThread.merge.estimatedMergeBytes >= MIN_BIG_MERGE_MB*1024*1024 &&
-          nsToSec(now-mergeStartNS) > 3.0) {
+          TimeUnit.NANOSECONDS.toSeconds(System.nanoTime() - mergeStartNS) > 3) {
         double otherMergeMB = bytesToMB(mergeThread.merge.estimatedMergeBytes);
         double ratio = otherMergeMB / mergeMB;
         if (ratio > 0.3 && ratio < 3.0) {
@@ -794,10 +795,6 @@
 
   /** Subclass can override to tweak targetMBPerSec. */
   protected void targetMBPerSecChanged() {
-  }
-
-  private static double nsToSec(long ns) {
-    return ns / 1000000000.0;
   }
 
   private static double bytesToMB(long bytes) {
Index: lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/IndexWriter.java	(revision )
@@ -36,6 +36,7 @@
 import java.util.Map.Entry;
 import java.util.Queue;
 import java.util.Set;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -3038,7 +3039,7 @@
     }
 
     if (infoStream.isEnabled("IW")) {
-      infoStream.message("IW", String.format(Locale.ROOT, "commit: took %.1f msec", (System.nanoTime()-startCommitTime)/1000000.0));
+      infoStream.message("IW", String.format(Locale.ROOT, "commit: took %d msec", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startCommitTime)));
       infoStream.message("IW", "commit: done");
     }
   }
@@ -4071,11 +4072,10 @@
 
       if (infoStream.isEnabled("IW")) {
         if (merger.shouldMerge()) {
-          long t1 = System.nanoTime();
-          double sec = (t1-merge.mergeStartNS)/1000000000.;
+          long sec = TimeUnit.NANOSECONDS.toSeconds(System.nanoTime() - merge.mergeStartNS);
           double segmentMB = (merge.info.sizeInBytes()/1024./1024.);
-          double stoppedSec = merge.rateLimiter.getTotalStoppedNS()/1000000000.;
-          double throttleSec = merge.rateLimiter.getTotalPausedNS()/1000000000.;
+          long stoppedSec = TimeUnit.NANOSECONDS.toSeconds(merge.rateLimiter.getTotalStoppedNS());
+          long throttleSec = TimeUnit.NANOSECONDS.toSeconds(merge.rateLimiter.getTotalPausedNS());
           infoStream.message("IW", "merge codec=" + codec + " maxDoc=" + merge.info.info.maxDoc() + "; merged segment has " +
                              (mergeState.mergeFieldInfos.hasVectors() ? "vectors" : "no vectors") + "; " +
                              (mergeState.mergeFieldInfos.hasNorms() ? "norms" : "no norms") + "; " + 
@@ -4083,7 +4083,7 @@
                              (mergeState.mergeFieldInfos.hasProx() ? "prox" : "no prox") + "; " + 
                              (mergeState.mergeFieldInfos.hasProx() ? "freqs" : "no freqs") + "; " +
                              String.format(Locale.ROOT,
-                                           "%.1f sec (%.1f sec stopped, %.1f sec paused) to merge segment [%.2f MB, %.2f MB/sec]",
+                                           "%d sec (%d sec stopped, %d sec paused) to merge segment [%.2f MB, %.2f MB/sec]",
                                            sec,
                                            stoppedSec,
                                            throttleSec,
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriterStallControl.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterStallControl.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterStallControl.java	(revision )
@@ -18,6 +18,7 @@
 
 import java.util.IdentityHashMap;
 import java.util.Map;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.lucene.index.DocumentsWriterPerThreadPool.ThreadState;
 import org.apache.lucene.util.InfoStream;
@@ -110,8 +111,7 @@
     assert waiting.remove(Thread.currentThread()) != null;
     assert numWaiting >= 0;
     if (infoStream.isEnabled("DW") && numWaiting == 0) {
-      long stallEndNS = System.nanoTime();
-      infoStream.message("DW", "done stalling flushes for " + ((stallEndNS - stallStartNS)/1000000.0) + " ms");
+      infoStream.message("DW", "done stalling flushes for " + TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - stallStartNS) + " ms");
     }
   }
   
Index: lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java	(revision )
@@ -31,6 +31,7 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Set;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 
 import org.apache.lucene.store.AlreadyClosedException;
@@ -540,8 +541,7 @@
     }
 
     if (infoStream.isEnabled("IFD")) {
-      long t1 = System.nanoTime();
-      infoStream.message("IFD", ((t1-t0)/1000000) + " msec to checkpoint");
+      infoStream.message("IFD", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to checkpoint");
     }
   }
 
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(revision )
@@ -24,6 +24,7 @@
 import java.util.HashSet;
 import java.util.Locale;
 import java.util.Set;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -415,7 +416,7 @@
       return null;
     }
 
-    long t0 = System.nanoTime();
+    final long t0 = System.nanoTime();
 
     if (infoStream.isEnabled("DWPT")) {
       infoStream.message("DWPT", "flush postings as segment " + flushState.segmentInfo.name + " numDocs=" + numDocsInRAM);
@@ -461,7 +462,7 @@
                                              segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);
       sealFlushedSegment(fs);
       if (infoStream.isEnabled("DWPT")) {
-        infoStream.message("DWPT", "flush time " + ((System.nanoTime() - t0)/1000000.0) + " msec");
+        infoStream.message("DWPT", "flush time " + TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec");
       }
 
       return fs;
Index: lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java	(revision )
@@ -24,6 +24,7 @@
 import java.util.Comparator;
 import java.util.List;
 import java.util.Locale;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -472,7 +473,7 @@
   /** Merge sorts the deleted terms and all segments to resolve terms to docIDs for deletion. */
   private synchronized long applyTermDeletes(CoalescedUpdates updates, SegmentState[] segStates) throws IOException {
 
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
 
     int numReaders = segStates.length;
 
@@ -589,8 +590,8 @@
 
     if (infoStream.isEnabled("BD")) {
       infoStream.message("BD",
-                         String.format(Locale.ROOT, "applyTermDeletes took %.1f msec for %d segments and %d packets; %d del terms visited; %d seg terms visited",
-                                       (System.nanoTime()-startNS)/1000000.,
+                         String.format(Locale.ROOT, "applyTermDeletes took %d msec for %d segments and %d packets; %d del terms visited; %d seg terms visited",
+                                       TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS),
                                        numReaders,
                                        updates.terms.size(),
                                        delTermVisitedCount, segTermVisitedCount));
Index: lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain.java	(revision )
@@ -21,6 +21,7 @@
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.codecs.PointFormat;
@@ -94,19 +95,19 @@
     long t0 = System.nanoTime();
     writeNorms(state);
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to write norms");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write norms");
     }
     
     t0 = System.nanoTime();
     writeDocValues(state);
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to write docValues");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write docValues");
     }
 
     t0 = System.nanoTime();
     writePoints(state);
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to write points");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write points");
     }
     
     // it's possible all docs hit non-aborting exceptions...
@@ -116,7 +117,7 @@
     storedFieldsWriter.finish(state.fieldInfos, maxDoc);
     storedFieldsWriter.close();
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to finish stored fields");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to finish stored fields");
     }
 
     t0 = System.nanoTime();
@@ -133,7 +134,7 @@
 
     termsHash.flush(fieldsToFlush, state);
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to write postings and finish vectors");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write postings and finish vectors");
     }
 
     // Important to save after asking consumer to flush so
@@ -143,7 +144,7 @@
     t0 = System.nanoTime();
     docWriter.codec.fieldInfosFormat().write(state.directory, state.segmentInfo, "", state.fieldInfos, IOContext.DEFAULT);
     if (docState.infoStream.isEnabled("IW")) {
-      docState.infoStream.message("IW", ((System.nanoTime()-t0)/1000000) + " msec to write fieldInfos");
+      docState.infoStream.message("IW", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write fieldInfos");
     }
   }
 
Index: lucene/core/src/java/org/apache/lucene/index/MergeRateLimiter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/MergeRateLimiter.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/MergeRateLimiter.java	(revision )
@@ -17,6 +17,8 @@
 package org.apache.lucene.index;
 
 
+import java.util.concurrent.TimeUnit;
+
 import org.apache.lucene.store.RateLimiter;
 import org.apache.lucene.util.ThreadInterruptedException;
 
@@ -136,7 +138,7 @@
     // Time we should sleep until; this is purely instantaneous
     // rate (just adds seconds onto the last time we had paused to);
     // maybe we should also offer decayed recent history one?
-    long targetNS = lastNS + (long) (1000000000 * secondsToPause);
+    long targetNS = lastNS + TimeUnit.SECONDS.toNanos((long)secondsToPause);
 
     long curPauseNS = targetNS - curNS;
 
@@ -144,16 +146,16 @@
     // wait/sleep time is 1 msec; if you pass just 1 nsec the impl
     // rounds up to 1 msec, so we don't bother unless it's > 2 msec:
 
-    if (curPauseNS <= 2000000) {
+    if (curPauseNS <= TimeUnit.MILLISECONDS.toNanos(2)) {
       return PauseResult.NO;
     }
 
     // Defensive: sleep for at most 250 msec; the loop above will call us again if we should keep sleeping:
-    if (curPauseNS > 250L*1000000) {
-      curPauseNS = 250L*1000000;
+    if (curPauseNS > TimeUnit.MILLISECONDS.toNanos(250)) {
+      curPauseNS = TimeUnit.MILLISECONDS.toNanos(250);
     }
 
-    int sleepMS = (int) (curPauseNS / 1000000);
+    int sleepMS = (int) TimeUnit.NANOSECONDS.toMillis(curPauseNS);
     int sleepNS = (int) (curPauseNS % 1000000);
 
     double rate = mbPerSec;
Index: lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(revision )
@@ -31,6 +31,7 @@
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.PointReader;
@@ -491,7 +492,7 @@
    *  time to run. */
   public Status checkIndex(List<String> onlySegments) throws IOException {
     ensureOpen();
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     NumberFormat nf = NumberFormat.getInstance(Locale.ROOT);
     SegmentInfos sis = null;
     Status result = new Status();
@@ -662,19 +663,19 @@
           segInfoStat.deletionsGen = info.getDelGen();
         }
         
-        long startOpenReaderNS = System.nanoTime();
+        final long startOpenReaderNS = System.nanoTime();
         if (infoStream != null)
           infoStream.print("    test: open reader.........");
         reader = new SegmentReader(info, IOContext.DEFAULT);
-        msg(infoStream, String.format(Locale.ROOT, "OK [took %.3f sec]", nsToSec(System.nanoTime()-startOpenReaderNS)));
+        msg(infoStream, String.format(Locale.ROOT, "OK [took %d milliseconds]", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startOpenReaderNS)));
 
         segInfoStat.openReaderPassed = true;
         
-        long startIntegrityNS = System.nanoTime();
+        final long startIntegrityNS = System.nanoTime();
         if (infoStream != null)
           infoStream.print("    test: check integrity.....");
         reader.checkIntegrity();
-        msg(infoStream, String.format(Locale.ROOT, "OK [took %.3f sec]", nsToSec(System.nanoTime()-startIntegrityNS)));
+        msg(infoStream, String.format(Locale.ROOT, "OK [took %d milliseconds]", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startIntegrityNS)));
 
         if (reader.maxDoc() != info.info.maxDoc()) {
           throw new RuntimeException("SegmentReader.maxDoc() " + reader.maxDoc() + " != SegmentInfo.maxDoc " + info.info.maxDoc());
@@ -788,7 +789,7 @@
       msg(infoStream, "No problems were detected with this index.\n");
     }
 
-    msg(infoStream, String.format(Locale.ROOT, "Took %.3f sec total.", nsToSec(System.nanoTime()-startNS)));
+    msg(infoStream, String.format(Locale.ROOT, "Took %d milliseconds total.", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
 
     return result;
   }
@@ -798,7 +799,7 @@
    * @lucene.experimental
    */
   public static Status.LiveDocStatus testLiveDocs(CodecReader reader, PrintStream infoStream, boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.LiveDocStatus status = new Status.LiveDocStatus();
     
     try {
@@ -822,7 +823,7 @@
         }
         
         status.numDeleted = reader.numDeletedDocs();
-        msg(infoStream, String.format(Locale.ROOT, "OK [%d deleted docs] [took %.3f sec]", status.numDeleted, nsToSec(System.nanoTime()-startNS)));
+        msg(infoStream, String.format(Locale.ROOT, "OK [%d deleted docs] [took %d milliseconds]", status.numDeleted, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
       } else {
         Bits liveDocs = reader.getLiveDocs();
         if (liveDocs != null) {
@@ -833,7 +834,7 @@
             }
           }
         }
-        msg(infoStream, String.format(Locale.ROOT, "OK [took %.3f sec]", (nsToSec(System.nanoTime()-startNS))));
+        msg(infoStream, String.format(Locale.ROOT, "OK [took %d milliseconds]", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
       }
       
     } catch (Throwable e) {
@@ -855,7 +856,7 @@
    * @lucene.experimental
    */
   public static Status.FieldInfoStatus testFieldInfos(CodecReader reader, PrintStream infoStream, boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.FieldInfoStatus status = new Status.FieldInfoStatus();
     
     try {
@@ -867,7 +868,7 @@
       for (FieldInfo f : fieldInfos) {
         f.checkConsistency();
       }
-      msg(infoStream, String.format(Locale.ROOT, "OK [%d fields] [took %.3f sec]", fieldInfos.size(), nsToSec(System.nanoTime()-startNS)));
+      msg(infoStream, String.format(Locale.ROOT, "OK [%d fields] [took %d milliseconds]", fieldInfos.size(), TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
       status.totFields = fieldInfos.size();
     } catch (Throwable e) {
       if (failFast) {
@@ -888,7 +889,7 @@
    * @lucene.experimental
    */
   public static Status.FieldNormStatus testFieldNorms(CodecReader reader, PrintStream infoStream, boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.FieldNormStatus status = new Status.FieldNormStatus();
 
     try {
@@ -907,7 +908,7 @@
         }
       }
 
-      msg(infoStream, String.format(Locale.ROOT, "OK [%d fields] [took %.3f sec]", status.totFields, nsToSec(System.nanoTime()-startNS)));
+      msg(infoStream, String.format(Locale.ROOT, "OK [%d fields] [took %d milliseconds]", status.totFields, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -1106,7 +1107,7 @@
    */
   private static Status.TermIndexStatus checkFields(Fields fields, Bits liveDocs, int maxDoc, FieldInfos fieldInfos, boolean doPrint, boolean isVectors, PrintStream infoStream, boolean verbose) throws IOException {
     // TODO: we should probably return our own stats thing...?!
-    long startNS;
+    final long startNS;
     if (doPrint) {
       startNS = System.nanoTime();
     } else {
@@ -1623,8 +1624,8 @@
     }
 
     if (doPrint) {
-      msg(infoStream, String.format(Locale.ROOT, "OK [%d terms; %d terms/docs pairs; %d tokens] [took %.3f sec]",
-                                    status.termCount, status.totFreq, status.totPos, nsToSec(System.nanoTime()-startNS)));
+      msg(infoStream, String.format(Locale.ROOT, "OK [%d terms; %d terms/docs pairs; %d tokens] [took %d milliseconds]",
+                                    status.termCount, status.totFreq, status.totPos, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
     }
     
     if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {
@@ -1780,7 +1781,7 @@
    * @lucene.experimental
    */
   public static Status.StoredFieldStatus testStoredFields(CodecReader reader, PrintStream infoStream, boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.StoredFieldStatus status = new Status.StoredFieldStatus();
 
     try {
@@ -1808,10 +1809,10 @@
         throw new RuntimeException("docCount=" + status.docCount + " but saw " + status.docCount + " undeleted docs");
       }
 
-      msg(infoStream, String.format(Locale.ROOT, "OK [%d total field count; avg %.1f fields per doc] [took %.3f sec]",
+      msg(infoStream, String.format(Locale.ROOT, "OK [%d total field count; avg %.1f fields per doc] [took %d milliseconds]",
                                     status.totFields,
                                     (((float) status.totFields)/status.docCount),
-                                    nsToSec(System.nanoTime() - startNS)));
+                                    TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -1833,7 +1834,7 @@
   public static Status.DocValuesStatus testDocValues(CodecReader reader,
                                                      PrintStream infoStream,
                                                      boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.DocValuesStatus status = new Status.DocValuesStatus();
     try {
       if (infoStream != null) {
@@ -1851,14 +1852,14 @@
       }
 
       msg(infoStream, String.format(Locale.ROOT,
-                                    "OK [%d docvalues fields; %d BINARY; %d NUMERIC; %d SORTED; %d SORTED_NUMERIC; %d SORTED_SET] [took %.3f sec]",
+                                    "OK [%d docvalues fields; %d BINARY; %d NUMERIC; %d SORTED; %d SORTED_NUMERIC; %d SORTED_SET] [took %d milliseconds]",
                                     status.totalValueFields,
                                     status.totalBinaryFields,
                                     status.totalNumericFields,
                                     status.totalSortedFields,
                                     status.totalSortedNumericFields,
                                     status.totalSortedSetFields,
-                                    nsToSec(System.nanoTime()-startNS)));
+                                    TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -2071,7 +2072,7 @@
    * @lucene.experimental
    */
   public static Status.TermVectorStatus testTermVectors(CodecReader reader, PrintStream infoStream, boolean verbose, boolean crossCheckTermVectors, boolean failFast) throws IOException {
-    long startNS = System.nanoTime();
+    final long startNS = System.nanoTime();
     final Status.TermVectorStatus status = new Status.TermVectorStatus();
     final FieldInfos fieldInfos = reader.getFieldInfos();
     
@@ -2250,8 +2251,8 @@
         }
       }
       float vectorAvg = status.docCount == 0 ? 0 : status.totVectors / (float)status.docCount;
-      msg(infoStream, String.format(Locale.ROOT, "OK [%d total term vector count; avg %.1f term/freq vector fields per doc] [took %.3f sec]",
-                                    status.totVectors, vectorAvg, nsToSec(System.nanoTime() - startNS)));
+      msg(infoStream, String.format(Locale.ROOT, "OK [%d total term vector count; avg %.1f term/freq vector fields per doc] [took %d milliseconds]",
+                                    status.totVectors, vectorAvg, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startNS)));
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -2534,9 +2535,5 @@
     } else {
       return 1;
     }
-  }
-
-  private static double nsToSec(long ns) {
-    return ns/1000000000.0;
   }
 }
Index: lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java	(revision b889109da12fd639fecee824fae2ffe0a8ef74c0)
+++ lucene/core/src/java/org/apache/lucene/index/SegmentMerger.java	(revision )
@@ -19,6 +19,7 @@
 
 import java.io.IOException;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.PointWriter;
@@ -83,8 +84,7 @@
     }
     int numMerged = mergeFields();
     if (mergeState.infoStream.isEnabled("SM")) {
-      long t1 = System.nanoTime();
-      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge stored fields [" + numMerged + " docs]");
+      mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge stored fields [" + numMerged + " docs]");
     }
     assert numMerged == mergeState.segmentInfo.maxDoc(): "numMerged=" + numMerged + " vs mergeState.segmentInfo.maxDoc()=" + mergeState.segmentInfo.maxDoc();
 
@@ -95,8 +95,7 @@
     }
     mergeTerms(segmentWriteState);
     if (mergeState.infoStream.isEnabled("SM")) {
-      long t1 = System.nanoTime();
-      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge postings [" + numMerged + " docs]");
+      mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge postings [" + numMerged + " docs]");
     }
 
     if (mergeState.infoStream.isEnabled("SM")) {
@@ -106,8 +105,7 @@
       mergeDocValues(segmentWriteState);
     }
     if (mergeState.infoStream.isEnabled("SM")) {
-      long t1 = System.nanoTime();
-      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge doc values [" + numMerged + " docs]");
+      mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge doc values [" + numMerged + " docs]");
     }
 
     if (mergeState.infoStream.isEnabled("SM")) {
@@ -117,8 +115,7 @@
       mergePoints(segmentWriteState);
     }
     if (mergeState.infoStream.isEnabled("SM")) {
-      long t1 = System.nanoTime();
-      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge points [" + numMerged + " docs]");
+      mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge points [" + numMerged + " docs]");
     }
     
     if (mergeState.mergeFieldInfos.hasNorms()) {
@@ -127,8 +124,7 @@
       }
       mergeNorms(segmentWriteState);
       if (mergeState.infoStream.isEnabled("SM")) {
-        long t1 = System.nanoTime();
-        mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge norms [" + numMerged + " docs]");
+        mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge norms [" + numMerged + " docs]");
       }
     }
 
@@ -138,8 +134,7 @@
       }
       numMerged = mergeVectors();
       if (mergeState.infoStream.isEnabled("SM")) {
-        long t1 = System.nanoTime();
-        mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to merge vectors [" + numMerged + " docs]");
+        mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to merge vectors [" + numMerged + " docs]");
       }
       assert numMerged == mergeState.segmentInfo.maxDoc();
     }
@@ -150,8 +145,7 @@
     }
     codec.fieldInfosFormat().write(directory, mergeState.segmentInfo, "", mergeState.mergeFieldInfos, context);
     if (mergeState.infoStream.isEnabled("SM")) {
-      long t1 = System.nanoTime();
-      mergeState.infoStream.message("SM", ((t1-t0)/1000000) + " msec to write field infos [" + numMerged + " docs]");
+      mergeState.infoStream.message("SM", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t0) + " msec to write field infos [" + numMerged + " docs]");
     }
 
     return mergeState;
