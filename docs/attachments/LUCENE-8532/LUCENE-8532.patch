diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 7a181bd240..292a7069f0 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -195,6 +195,9 @@ Bug fixes:
 * LUCENE-8522: throw InvalidShapeException when constructing a polygon and
   all points are coplanar. (Ignacio Vera)
 
+* LUCENE-8532: The Korean Tokenizer now ignores trailing whitespaces on inputs and removes
+  leading and trailing whitespaces on word dictionary entries. (Jim Ferenczi)
+
 New Features
 
 * LUCENE-8496: Selective indexing - modify BKDReader/BKDWriter to allow users
diff --git a/lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer.java b/lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer.java
index 822853b196..9928945efc 100644
--- a/lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer.java
+++ b/lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer.java
@@ -140,6 +140,9 @@ public final class KoreanTokenizer extends Tokenizer {
   // Next absolute position to process:
   private int pos;
 
+  // The last offset in the stream if it ends with trailing whitespace(s), -1 otherwise
+  private int lastPos;
+
   // Already parsed, but not yet passed to caller, tokens:
   private final List<Token> pending = new ArrayList<>();
 
@@ -220,6 +223,7 @@ public final class KoreanTokenizer extends Tokenizer {
   private void resetState() {
     positions.reset();
     pos = 0;
+    lastPos = -1;
     end = false;
     lastBackTracePos = 0;
     pending.clear();
@@ -232,7 +236,7 @@ public final class KoreanTokenizer extends Tokenizer {
   public void end() throws IOException {
     super.end();
     // Set final offset
-    int finalOffset = correctOffset(pos);
+    int finalOffset = correctOffset(lastPos == -1 ? pos : lastPos);
     offsetAtt.setOffset(finalOffset, finalOffset);
   }
 
@@ -330,10 +334,9 @@ public final class KoreanTokenizer extends Tokenizer {
     int leastCost = Integer.MAX_VALUE;
     int leastIDX = -1;
     assert fromPosData.count > 0;
+    // The number of spaces before the term
+    int numSpaces = wordPos - fromPosData.pos;
     for(int idx=0;idx<fromPosData.count;idx++) {
-      // The number of spaces before the term
-      int numSpaces = wordPos - fromPosData.pos;
-
       // Cost is path cost so far, plus word cost (added at
       // end of loop), plus bigram cost and space penalty cost.
       final int cost = fromPosData.costs[idx] + costs.get(fromPosData.lastRightID[idx], leftID) + computeSpacePenalty(leftPOS, numSpaces);
@@ -640,7 +643,10 @@ public final class KoreanTokenizer extends Tokenizer {
         }
       }
       if (buffer.get(pos) == -1) {
+        // trailing spaces
+        lastPos = pos;
         pos = posData.pos;
+        break;
       }
 
       boolean anyMatches = false;
@@ -756,7 +762,7 @@ public final class KoreanTokenizer extends Tokenizer {
 
     end = true;
 
-    if (pos > 0) {
+    if (pos > 0 && pos > lastBackTracePos) {
 
       final Position endPosData = positions.get(pos);
       int leastCost = Integer.MAX_VALUE;
diff --git a/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$buffer.dat b/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$buffer.dat
index 6958664db9..d7cc866ca3 100644
Binary files a/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$buffer.dat and b/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$buffer.dat differ
diff --git a/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$targetMap.dat b/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$targetMap.dat
index 7c0823c89a..09302667b0 100644
Binary files a/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$targetMap.dat and b/lucene/analysis/nori/src/resources/org/apache/lucene/analysis/ko/dict/TokenInfoDictionary$targetMap.dat differ
diff --git a/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer.java b/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer.java
index 0471e5f2cd..d4cac0e63f 100644
--- a/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer.java
+++ b/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer.java
@@ -100,6 +100,16 @@ public class TestKoreanTokenizer extends BaseTokenStreamTestCase {
     };
   }
 
+  public void testTrailingSpaces() throws IOException {
+    assertTokenStreamContents(analyzerDecompound.tokenStream("", "공단시 "),
+        new String[]{"공단", "시"},
+        new int[]{0, 2},
+        new int[]{2, 3},
+        new int[]{1, 1},
+        4
+    );
+  }
+
   public void testSpaces() throws IOException {
     assertAnalyzesTo(analyzer, "화학        이외의         것",
         new String[]{"화학", "이외", "의", "것"},
diff --git a/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary.java b/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary.java
index d278841e86..cc4b426e6b 100644
--- a/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary.java
+++ b/lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary.java
@@ -96,6 +96,8 @@ public class TestTokenInfoDictionary extends LuceneTestCase {
             int offset = 0;
             for (Dictionary.Morpheme morph : decompound) {
               assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));
+              assertTrue(morph.surfaceForm.length() > 0);
+              assertTrue(morph.surfaceForm.trim().equals(morph.surfaceForm));
               if (type != POS.Type.INFLECT) {
                 assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));
                 offset += morph.surfaceForm.length();
diff --git a/lucene/analysis/nori/src/tools/java/org/apache/lucene/analysis/ko/util/BinaryDictionaryWriter.java b/lucene/analysis/nori/src/tools/java/org/apache/lucene/analysis/ko/util/BinaryDictionaryWriter.java
index 35c16aec26..7e41c0abce 100644
--- a/lucene/analysis/nori/src/tools/java/org/apache/lucene/analysis/ko/util/BinaryDictionaryWriter.java
+++ b/lucene/analysis/nori/src/tools/java/org/apache/lucene/analysis/ko/util/BinaryDictionaryWriter.java
@@ -26,6 +26,7 @@ import java.nio.channels.Channels;
 import java.nio.channels.WritableByteChannel;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.List;
 
 import org.apache.lucene.analysis.ko.POS;
 import org.apache.lucene.analysis.ko.dict.Dictionary;
@@ -109,23 +110,23 @@ public abstract class BinaryDictionaryWriter {
     assert existing == null || existing.equals(fullPOSData);
     posDict.set(leftId, fullPOSData);
 
-    final Dictionary.Morpheme[] morphemes;
+    final List<Dictionary.Morpheme> morphemes = new ArrayList<>();
     // true if the POS and decompounds of the token are all the same.
     boolean hasSinglePOS = (leftPOS == rightPOS);
     if (posType != POS.Type.MORPHEME && expression.length() > 0) {
       String[] exprTokens = expression.split("\\+");
-      morphemes = new Dictionary.Morpheme[exprTokens.length];
       for (int i = 0; i < exprTokens.length; i++) {
         String[] tokenSplit = exprTokens[i].split("\\/");
         assert tokenSplit.length == 3;
         POS.Tag exprTag = POS.resolveTag(tokenSplit[1]);
-        morphemes[i] = new Dictionary.Morpheme(exprTag, tokenSplit[0]);
+        String displayForm = tokenSplit[0].trim();
+        if (displayForm.length() > 0) {
+          morphemes.add(new Dictionary.Morpheme(exprTag, displayForm));
+        }
         if (leftPOS != exprTag) {
           hasSinglePOS = false;
         }
       }
-    } else {
-      morphemes = new Dictionary.Morpheme[0];
     }
 
     int flags = 0;
@@ -151,17 +152,17 @@ public abstract class BinaryDictionaryWriter {
       if (hasSinglePOS == false) {
         buffer.put((byte) rightPOS.ordinal());
       }
-      buffer.put((byte) morphemes.length);
+      buffer.put((byte) morphemes.size());
       int compoundOffset = 0;
-      for (int i = 0; i < morphemes.length; i++) {
+      for (int i = 0; i < morphemes.size(); i++) {
         if (hasSinglePOS == false) {
-          buffer.put((byte) morphemes[i].posTag.ordinal());
+          buffer.put((byte) morphemes.get(i).posTag.ordinal());
         }
         if (posType != POS.Type.INFLECT) {
-          buffer.put((byte) morphemes[i].surfaceForm.length());
-          compoundOffset += morphemes[i].surfaceForm.length();
+          buffer.put((byte) morphemes.get(i).surfaceForm.length());
+          compoundOffset += morphemes.get(i).surfaceForm.length();
         } else {
-          writeString(morphemes[i].surfaceForm);
+          writeString(morphemes.get(i).surfaceForm);
         }
         assert compoundOffset <= entry[0].length() : Arrays.toString(entry);
       }
