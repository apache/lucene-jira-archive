Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java	(revision 1687080)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java	(working copy)
@@ -101,7 +101,6 @@
         reader,
         "partnum",
         new BytesRef("Q36"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -109,7 +108,6 @@
         reader,
         "partnum",
         new BytesRef("Q37"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(revision 1687080)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(working copy)
@@ -111,7 +111,7 @@
     TermsEnum termsEnum = vector.iterator();
     termsEnum.next();
     assertEquals(2, termsEnum.totalTermFreq());
-    PostingsEnum positions = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum positions = termsEnum.postings(null, PostingsEnum.ALL);
     assertTrue(positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(2, positions.freq());
     positions.nextPosition();
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java	(revision 1687080)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestClassicAnalyzer.java	(working copy)
@@ -300,7 +300,6 @@
     // Make sure position is still incremented when
     // massive term is skipped:
     PostingsEnum tps = MultiFields.getTermPositionsEnum(reader,
-                                                                MultiFields.getLiveDocs(reader),
                                                                 "content",
                                                                 new BytesRef("another"));
     assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1687080)
+++ lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -991,7 +991,7 @@
       // should be found exactly
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       // should hit end of field
@@ -1003,12 +1003,12 @@
       assertEquals(TermsEnum.SeekStatus.NOT_FOUND,
                    terms.seekCeil(new BytesRef("a")));
       assertTrue(terms.term().bytesEquals(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       assertEquals(TermsEnum.SeekStatus.FOUND,
                    terms.seekCeil(aaaTerm));
-      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, null, PostingsEnum.NONE)));
+      assertEquals(35, countDocs(TestUtil.docs(random(), terms, null, PostingsEnum.NONE)));
       assertNull(terms.next());
 
       r.close();
Index: lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
===================================================================
--- lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java	(revision 1687080)
+++ lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java	(working copy)
@@ -499,7 +499,7 @@
       TermsEnum termsEnum = terms.iterator();
       PostingsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = TestUtil.docs(random(), termsEnum, MultiFields.getLiveDocs(reader), docs, PostingsEnum.FREQS);
+        docs = TestUtil.docs(random(), termsEnum, docs, PostingsEnum.FREQS);
         while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           totalTokenCount2 += docs.freq();
         }
Index: lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java	(working copy)
@@ -651,11 +651,11 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         //System.out.println("BTR.docs this=" + this);
         decodeMetaData();
         //System.out.println("BTR.docs:  state.docFreq=" + state.docFreq);
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       @Override
Index: lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsIntersectTermsEnum.java	(working copy)
@@ -202,9 +202,9 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     currentFrame.decodeMetaData();
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, reuse, flags);
   }
 
   private int getState() {
Index: lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsSegmentTermsEnum.java	(working copy)
@@ -923,7 +923,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -932,7 +932,7 @@
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
Index: lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java	(working copy)
@@ -369,9 +369,9 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags)
+      public PostingsEnum postings(PostingsEnum reuse, int flags)
           throws IOException {
-        return delegate().postings(liveDocs, reuse, flags);
+        return delegate().postings(reuse, flags);
       }
 
     }
@@ -455,7 +455,7 @@
             bloomFilters.put(fieldInfo, bloomFilter);
           }
           // Make sure there's at least one doc for this term:
-          postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+          postingsEnum = termsEnum.postings(postingsEnum, 0);
           if (postingsEnum.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
             bloomFilter.addValue(term);
           }
Index: lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java	(working copy)
@@ -43,7 +43,6 @@
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
@@ -357,9 +356,9 @@
         termOffsets[count+1] = termOffset;
 
         if (hasPos) {
-          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
         } else {
-          postingsEnum = termsEnum.postings(null, postingsEnum);
+          postingsEnum = termsEnum.postings(postingsEnum);
         }
 
         final TermAndSkip ent;
@@ -848,7 +847,7 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         // TODO: implement reuse
         // it's hairy!
 
@@ -862,11 +861,8 @@
               LowFreqDocsEnumNoTF docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoTF) {
                 docsEnum = (LowFreqDocsEnumNoTF) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoTF();
               }
 
               return docsEnum.reset(postings);
@@ -875,23 +871,20 @@
               LowFreqDocsEnumNoPos docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoPos) {
                 docsEnum = (LowFreqDocsEnumNoPos) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoPos();
               }
 
               return docsEnum.reset(postings);
             }
             final byte[] payloads = term.payloads;
-            return new LowFreqPostingsEnum(liveDocs, hasOffsets, hasPayloads).reset(postings, payloads);
+            return new LowFreqPostingsEnum(hasOffsets, hasPayloads).reset(postings, payloads);
           } else {
             final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
             if (hasPos == false) {
-              return new HighFreqDocsEnum(liveDocs).reset(term.docIDs, term.freqs);
+              return new HighFreqDocsEnum().reset(term.docIDs, term.freqs);
             } else {
-              return new HighFreqPostingsEnum(liveDocs, hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
+              return new HighFreqPostingsEnum(hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
             }
           }
         }
@@ -912,11 +905,8 @@
               LowFreqDocsEnum docsEnum;
               if (reuse instanceof LowFreqDocsEnum) {
                 docsEnum = (LowFreqDocsEnum) reuse;
-                if (!docsEnum.canReuse(liveDocs, posLen)) {
-                  docsEnum = new LowFreqDocsEnum(liveDocs, posLen);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnum(liveDocs, posLen);
+                docsEnum = new LowFreqDocsEnum( posLen);
               }
 
               return docsEnum.reset(postings);
@@ -924,11 +914,8 @@
               LowFreqDocsEnumNoPos docsEnum;
               if (reuse instanceof LowFreqDocsEnumNoPos) {
                 docsEnum = (LowFreqDocsEnumNoPos) reuse;
-                if (!docsEnum.canReuse(liveDocs)) {
-                  docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
-                }
               } else {
-                docsEnum = new LowFreqDocsEnumNoPos(liveDocs);
+                docsEnum = new LowFreqDocsEnumNoPos();
               }
 
               return docsEnum.reset(postings);
@@ -937,11 +924,8 @@
             LowFreqDocsEnumNoTF docsEnum;
             if (reuse instanceof LowFreqDocsEnumNoTF) {
               docsEnum = (LowFreqDocsEnumNoTF) reuse;
-              if (!docsEnum.canReuse(liveDocs)) {
-                docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
-              }
             } else {
-              docsEnum = new LowFreqDocsEnumNoTF(liveDocs);
+              docsEnum = new LowFreqDocsEnumNoTF();
             }
 
             return docsEnum.reset(postings);
@@ -952,11 +936,8 @@
           HighFreqDocsEnum docsEnum;
           if (reuse instanceof HighFreqDocsEnum) {
             docsEnum = (HighFreqDocsEnum) reuse;
-            if (!docsEnum.canReuse(liveDocs)) {
-              docsEnum = new HighFreqDocsEnum(liveDocs);
-            }
           } else {
-            docsEnum = new HighFreqDocsEnum(liveDocs);
+            docsEnum = new HighFreqDocsEnum();
           }
 
           //System.out.println("  DE for term=" + new BytesRef(terms[termOrd].term).utf8ToString() + ": " + term.docIDs.length + " docs");
@@ -1471,7 +1452,7 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) {
         // TODO: implement reuse
         // it's hairy!
 
@@ -1481,10 +1462,10 @@
             final LowFreqTerm term = ((LowFreqTerm) terms[termOrd]);
             final int[] postings = term.postings;
             final byte[] payloads = term.payloads;
-            return new LowFreqPostingsEnum(liveDocs, hasOffsets, hasPayloads).reset(postings, payloads);
+            return new LowFreqPostingsEnum(hasOffsets, hasPayloads).reset(postings, payloads);
           } else {
             final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
-            return new HighFreqPostingsEnum(liveDocs, hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
+            return new HighFreqPostingsEnum(hasOffsets).reset(term.docIDs, term.freqs, term.positions, term.payloads);
           }
         }
 
@@ -1501,17 +1482,17 @@
               if (hasPayloads) {
                 posLen++;
               }
-              return new LowFreqDocsEnum(liveDocs, posLen).reset(postings);
+              return new LowFreqDocsEnum(posLen).reset(postings);
             } else {
-              return new LowFreqDocsEnumNoPos(liveDocs).reset(postings);
+              return new LowFreqDocsEnumNoPos().reset(postings);
             }
           } else {
-            return new LowFreqDocsEnumNoTF(liveDocs).reset(postings);
+            return new LowFreqDocsEnumNoTF().reset(postings);
           }
         } else {
           final HighFreqTerm term = (HighFreqTerm) terms[termOrd];
           //  System.out.println("DE for term=" + new BytesRef(terms[termOrd].term).utf8ToString() + ": " + term.docIDs.length + " docs");
-          return new HighFreqDocsEnum(liveDocs).reset(term.docIDs, term.freqs);
+          return new HighFreqDocsEnum().reset(term.docIDs, term.freqs);
         }
       }
 
@@ -1530,17 +1511,8 @@
   // Docs only:
   private final static class LowFreqDocsEnumNoTF extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private int upto;
 
-    public LowFreqDocsEnumNoTF(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
-
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
-
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
       upto = -1;
@@ -1552,17 +1524,8 @@
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto++;
-        }
+      if (upto < postings.length) {
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1619,17 +1582,10 @@
   // Docs + freqs:
   private final static class LowFreqDocsEnumNoPos extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private int upto;
 
-    public LowFreqDocsEnumNoPos(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
+    public LowFreqDocsEnumNoPos() {}
 
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
-
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
       upto = -2;
@@ -1640,17 +1596,8 @@
     @Override
     public int nextDoc() {
       upto += 2;
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto += 2;
-        }
+      if (upto < postings.length) {
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1707,13 +1654,11 @@
   // Docs + freqs + positions/offets:
   private final static class LowFreqDocsEnum extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private final int posMult;
     private int upto;
     private int freq;
 
-    public LowFreqDocsEnum(Bits liveDocs, int posMult) {
-      this.liveDocs = liveDocs;
+    public LowFreqDocsEnum(int posMult) {
       this.posMult = posMult;
       // if (DEBUG) {
       //   System.out.println("LowFreqDE: posMult=" + posMult);
@@ -1720,10 +1665,6 @@
       // }
     }
 
-    public boolean canReuse(Bits liveDocs, int posMult) {
-      return liveDocs == this.liveDocs && posMult == this.posMult;
-    }
-
     public PostingsEnum reset(int[] postings) {
       this.postings = postings;
       upto = -2;
@@ -1738,21 +1679,10 @@
       // if (DEBUG) {
       //   System.out.println("  nextDoc freq=" + freq + " upto=" + upto + " vs " + postings.length);
       // }
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          freq = postings[upto+1];
-          assert freq > 0;
-          return postings[upto];
-        }
-      } else {
-        while (upto < postings.length) {
-          freq = postings[upto+1];
-          assert freq > 0;
-          if (liveDocs.get(postings[upto])) {
-            return postings[upto];
-          }
-          upto += 2 + freq*posMult;
-        }
+      if (upto < postings.length) {
+        freq = postings[upto+1];
+        assert freq > 0;
+        return postings[upto];
       }
       return NO_MORE_DOCS;
     }
@@ -1811,7 +1741,6 @@
 
   private final static class LowFreqPostingsEnum extends PostingsEnum {
     private int[] postings;
-    private final Bits liveDocs;
     private final int posMult;
     private final boolean hasOffsets;
     private final boolean hasPayloads;
@@ -1828,8 +1757,7 @@
     private int payloadLength;
     private byte[] payloadBytes;
 
-    public LowFreqPostingsEnum(Bits liveDocs, boolean hasOffsets, boolean hasPayloads) {
-      this.liveDocs = liveDocs;
+    public LowFreqPostingsEnum(boolean hasOffsets, boolean hasPayloads) {
       this.hasOffsets = hasOffsets;
       this.hasPayloads = hasPayloads;
       if (hasOffsets) {
@@ -1873,33 +1801,11 @@
         upto += posMult * skipPositions;
       }
 
-      if (liveDocs == null) {
-        if (upto < postings.length) {
-          docID = postings[upto++];
-          freq = postings[upto++];
-          skipPositions = freq;
-          return docID;
-        }
-      } else {
-        while(upto < postings.length) {
-          docID = postings[upto++];
-          freq = postings[upto++];
-          if (liveDocs.get(docID)) {
-            skipPositions = freq;
-            return docID;
-          }
-          if (hasPayloads) {
-            for(int i=0;i<freq;i++) {
-              upto++;
-              if (hasOffsets) {
-                upto += 2;
-              }
-              payloadOffset += postings[upto++];
-            }
-          } else {
-            upto += posMult * freq;
-          }
-        }
+      if (upto < postings.length) {
+        docID = postings[upto++];
+        freq = postings[upto++];
+        skipPositions = freq;
+        return docID;
       }
 
       return docID = NO_MORE_DOCS;
@@ -1970,18 +1876,11 @@
   private final static class HighFreqDocsEnum extends PostingsEnum {
     private int[] docIDs;
     private int[] freqs;
-    private final Bits liveDocs;
     private int upto;
     private int docID = -1;
 
-    public HighFreqDocsEnum(Bits liveDocs) {
-      this.liveDocs = liveDocs;
-    }
+    public HighFreqDocsEnum() {}
 
-    public boolean canReuse(Bits liveDocs) {
-      return liveDocs == this.liveDocs;
-    }
-
     public int[] getDocIDs() {
       return docIDs;
     }
@@ -2000,18 +1899,9 @@
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        try {
-          return docID = docIDs[upto];
-        } catch (ArrayIndexOutOfBoundsException e) {
-        }
-      } else {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            return docID = docIDs[upto];
-          }
-          upto++;
-        }
+      try {
+        return docID = docIDs[upto];
+      } catch (ArrayIndexOutOfBoundsException e) {
       }
       return docID = NO_MORE_DOCS;
     }
@@ -2121,14 +2011,6 @@
 
       //System.out.println("    end upto=" + upto + " docID=" + (upto >= docIDs.length ? NO_MORE_DOCS : docIDs[upto]));
 
-      if (liveDocs != null) {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            break;
-          }
-          upto++;
-        }
-      }
       if (upto == docIDs.length) {
         //System.out.println("    return END");
         return docID = NO_MORE_DOCS;
@@ -2170,7 +2052,6 @@
     private int[] freqs;
     private int[][] positions;
     private byte[][][] payloads;
-    private final Bits liveDocs;
     private final boolean hasOffsets;
     private final int posJump;
     private int upto;
@@ -2178,8 +2059,7 @@
     private int posUpto;
     private int[] curPositions;
 
-    public HighFreqPostingsEnum(Bits liveDocs, boolean hasOffsets) {
-      this.liveDocs = liveDocs;
+    public HighFreqPostingsEnum(boolean hasOffsets) {
       this.hasOffsets = hasOffsets;
       posJump = hasOffsets ? 3 : 1;
     }
@@ -2196,10 +2076,6 @@
       return posJump;
     }
 
-    public Bits getLiveDocs() {
-      return liveDocs;
-    }
-
     public PostingsEnum reset(int[] docIDs, int[] freqs, int[][] positions, byte[][][] payloads) {
       this.docIDs = docIDs;
       this.freqs = freqs;
@@ -2212,21 +2088,10 @@
     @Override
     public int nextDoc() {
       upto++;
-      if (liveDocs == null) {
-        if (upto < docIDs.length) {
-          posUpto = -posJump;
-          curPositions = positions[upto];
-          return docID = docIDs[upto];
-        }
-      } else {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            posUpto = -posJump;
-            curPositions = positions[upto];
-            return docID = docIDs[upto];
-          }
-          upto++;
-        }
+      if (upto < docIDs.length) {
+        posUpto = -posJump;
+        curPositions = positions[upto];
+        return docID = docIDs[upto];
       }
 
       return docID = NO_MORE_DOCS;
@@ -2360,14 +2225,6 @@
 
       //System.out.println("    end upto=" + upto + " docID=" + (upto >= docIDs.length ? NO_MORE_DOCS : docIDs[upto]));
 
-      if (liveDocs != null) {
-        while (upto < docIDs.length) {
-          if (liveDocs.get(docIDs[upto])) {
-            break;
-          }
-          upto++;
-        }
-      }
       if (upto == docIDs.length) {
         //System.out.println("    return END");
         return docID = NO_MORE_DOCS;
Index: lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java	(working copy)
@@ -427,9 +427,9 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         decodeMetaData();
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       // TODO: this can be achieved by making use of Util.getByOutput()
Index: lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java	(working copy)
@@ -46,7 +46,6 @@
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.IOUtils;
@@ -290,9 +289,9 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         decodeMetaData();
-        return postingsReader.postings(fieldInfo, state, liveDocs, reuse, flags);
+        return postingsReader.postings(fieldInfo, state, reuse, flags);
       }
 
       @Override
Index: lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java	(working copy)
@@ -892,7 +892,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       throw new UnsupportedOperationException();
     }
 
Index: lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java	(working copy)
@@ -353,10 +353,10 @@
           termsWriter.postingsWriter.reset();
 
           if (writePositions) {
-            posEnum = termsEnum.postings(null, posEnum, enumFlags);
+            posEnum = termsEnum.postings(posEnum, enumFlags);
             postingsEnum = posEnum;
           } else {
-            postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+            postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
             posEnum = null;
           }
 
@@ -433,7 +433,6 @@
     private byte[] buffer = new byte[16];
     private final ByteArrayDataInput in = new ByteArrayDataInput(buffer);
 
-    private Bits liveDocs;
     private int docUpto;
     private int docID = -1;
     private int accum;
@@ -450,7 +449,7 @@
       return indexOptions == this.indexOptions && storePayloads == this.storePayloads;
     }
     
-    public FSTDocsEnum reset(BytesRef bufferIn, Bits liveDocs, int numDocs) {
+    public FSTDocsEnum reset(BytesRef bufferIn, int numDocs) {
       assert numDocs > 0;
       if (buffer.length < bufferIn.length) {
         buffer = ArrayUtil.grow(buffer, bufferIn.length);
@@ -457,7 +456,6 @@
       }
       in.reset(buffer, 0, bufferIn.length);
       System.arraycopy(bufferIn.bytes, bufferIn.offset, buffer, 0, bufferIn.length);
-      this.liveDocs = liveDocs;
       docID = -1;
       accum = 0;
       docUpto = 0;
@@ -469,62 +467,58 @@
 
     @Override
     public int nextDoc() {
-      while(true) {
-        //System.out.println("  nextDoc cycle docUpto=" + docUpto + " numDocs=" + numDocs + " fp=" + in.getPosition() + " this=" + this);
-        if (docUpto == numDocs) {
-          // System.out.println("    END");
-          return docID = NO_MORE_DOCS;
+      //System.out.println("  nextDoc cycle docUpto=" + docUpto + " numDocs=" + numDocs + " fp=" + in.getPosition() + " this=" + this);
+      if (docUpto == numDocs) {
+        // System.out.println("    END");
+        return docID = NO_MORE_DOCS;
+      }
+      docUpto++;
+      if (indexOptions == IndexOptions.DOCS) {
+        accum += in.readVInt();
+      } else {
+        final int code = in.readVInt();
+        accum += code >>> 1;
+        //System.out.println("  docID=" + accum + " code=" + code);
+        if ((code & 1) != 0) {
+          freq = 1;
+        } else {
+          freq = in.readVInt();
+          assert freq > 0;
         }
-        docUpto++;
-        if (indexOptions == IndexOptions.DOCS) {
-          accum += in.readVInt();
-        } else {
-          final int code = in.readVInt();
-          accum += code >>> 1;
-          //System.out.println("  docID=" + accum + " code=" + code);
-          if ((code & 1) != 0) {
-            freq = 1;
-          } else {
-            freq = in.readVInt();
-            assert freq > 0;
-          }
 
-          if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {
-            // Skip positions/payloads
-            for(int posUpto=0;posUpto<freq;posUpto++) {
-              if (!storePayloads) {
-                in.readVInt();
-              } else {
-                final int posCode = in.readVInt();
-                if ((posCode & 1) != 0) {
-                  payloadLen = in.readVInt();
-                }
-                in.skipBytes(payloadLen);
-              }
-            }
-          } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {
-            // Skip positions/offsets/payloads
-            for(int posUpto=0;posUpto<freq;posUpto++) {
-              int posCode = in.readVInt();
-              if (storePayloads && ((posCode & 1) != 0)) {
+        if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {
+          // Skip positions/payloads
+          for(int posUpto=0;posUpto<freq;posUpto++) {
+            if (!storePayloads) {
+              in.readVInt();
+            } else {
+              final int posCode = in.readVInt();
+              if ((posCode & 1) != 0) {
                 payloadLen = in.readVInt();
               }
-              if ((in.readVInt() & 1) != 0) {
-                // new offset length
-                in.readVInt();
-              }
-              if (storePayloads) {
-                in.skipBytes(payloadLen);
-              }
+              in.skipBytes(payloadLen);
             }
           }
+        } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {
+          // Skip positions/offsets/payloads
+          for(int posUpto=0;posUpto<freq;posUpto++) {
+            int posCode = in.readVInt();
+            if (storePayloads && ((posCode & 1) != 0)) {
+              payloadLen = in.readVInt();
+            }
+            if ((in.readVInt() & 1) != 0) {
+              // new offset length
+              in.readVInt();
+            }
+            if (storePayloads) {
+              in.skipBytes(payloadLen);
+            }
+          }
         }
+      }
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          //System.out.println("    return docID=" + accum + " freq=" + freq);
-          return (docID = accum);
-        }
-      }
+      //System.out.println("    return docID=" + accum + " freq=" + freq);
+      return (docID = accum);
     }
 
     @Override
@@ -577,7 +571,6 @@
     private byte[] buffer = new byte[16];
     private final ByteArrayDataInput in = new ByteArrayDataInput(buffer);
 
-    private Bits liveDocs;
     private int docUpto;
     private int docID = -1;
     private int accum;
@@ -601,7 +594,7 @@
       return storePayloads == this.storePayloads && storeOffsets == this.storeOffsets;
     }
     
-    public FSTPostingsEnum reset(BytesRef bufferIn, Bits liveDocs, int numDocs) {
+    public FSTPostingsEnum reset(BytesRef bufferIn, int numDocs) {
       assert numDocs > 0;
 
       // System.out.println("D&P reset bytes this=" + this);
@@ -614,7 +607,6 @@
       }
       in.reset(buffer, 0, bufferIn.length - bufferIn.offset);
       System.arraycopy(bufferIn.bytes, bufferIn.offset, buffer, 0, bufferIn.length);
-      this.liveDocs = liveDocs;
       docID = -1;
       accum = 0;
       docUpto = 0;
@@ -649,37 +641,11 @@
           assert freq > 0;
         }
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          pos = 0;
-          startOffset = storeOffsets ? 0 : -1;
-          posPending = freq;
-          //System.out.println("    return docID=" + accum + " freq=" + freq);
-          return (docID = accum);
-        }
-
-        // Skip positions
-        for(int posUpto=0;posUpto<freq;posUpto++) {
-          if (!storePayloads) {
-            in.readVInt();
-          } else {
-            final int skipCode = in.readVInt();
-            if ((skipCode & 1) != 0) {
-              payloadLength = in.readVInt();
-              //System.out.println("    new payloadLen=" + payloadLength);
-            }
-          }
-          
-          if (storeOffsets) {
-            if ((in.readVInt() & 1) != 0) {
-              // new offset length
-              offsetLength = in.readVInt();
-            }
-          }
-          
-          if (storePayloads) {
-            in.skipBytes(payloadLength);
-          }
-        }
+        pos = 0;
+        startOffset = storeOffsets ? 0 : -1;
+        posPending = freq;
+        //System.out.println("    return docID=" + accum + " freq=" + freq);
+        return (docID = accum);
       }
     }
 
@@ -827,7 +793,7 @@
     }
     
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
 
       // TODO: the logic of which enum impl to choose should be refactored to be simpler...
       boolean hasPositions = field.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
@@ -844,7 +810,7 @@
           }
         }
         //System.out.println("D&P reset this=" + this);
-        return docsAndPositionsEnum.reset(postingsSpare, liveDocs, docFreq);
+        return docsAndPositionsEnum.reset(postingsSpare, docFreq);
       }
 
       decodeMetaData();
@@ -858,7 +824,7 @@
           docsEnum = new FSTDocsEnum(field.getIndexOptions(), field.hasPayloads());
         }
       }
-      return docsEnum.reset(this.postingsSpare, liveDocs, docFreq);
+      return docsEnum.reset(this.postingsSpare, docFreq);
     }
 
     @Override
Index: lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java	(working copy)
@@ -207,7 +207,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
 
       boolean hasPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
       if (hasPositions && PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
@@ -218,7 +218,7 @@
         } else {
           docsAndPositionsEnum = new SimpleTextPostingsEnum();
         }
-        return docsAndPositionsEnum.reset(docsStart, liveDocs, indexOptions, docFreq);
+        return docsAndPositionsEnum.reset(docsStart, indexOptions, docFreq);
 
       }
 
@@ -228,7 +228,7 @@
       } else {
         docsEnum = new SimpleTextDocsEnum();
       }
-      return docsEnum.reset(docsStart, liveDocs, indexOptions == IndexOptions.DOCS, docFreq);
+      return docsEnum.reset(docsStart, indexOptions == IndexOptions.DOCS, docFreq);
     }
 
   }
@@ -239,7 +239,6 @@
     private boolean omitTF;
     private int docID = -1;
     private int tf;
-    private Bits liveDocs;
     private final BytesRefBuilder scratch = new BytesRefBuilder();
     private final CharsRefBuilder scratchUTF16 = new CharsRefBuilder();
     private int cost;
@@ -253,8 +252,7 @@
       return in == inStart;
     }
 
-    public SimpleTextDocsEnum reset(long fp, Bits liveDocs, boolean omitTF, int docFreq) throws IOException {
-      this.liveDocs = liveDocs;
+    public SimpleTextDocsEnum reset(long fp, boolean omitTF, int docFreq) throws IOException {
       in.seek(fp);
       this.omitTF = omitTF;
       docID = -1;
@@ -304,7 +302,7 @@
         final long lineStart = in.getFilePointer();
         SimpleTextUtil.readLine(in, scratch);
         if (StringHelper.startsWith(scratch.get(), DOC)) {
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             in.seek(lineStart);
             if (!omitTF) {
               tf = termFreq;
@@ -328,7 +326,7 @@
           // skip
         } else {
           assert StringHelper.startsWith(scratch.get(), TERM) || StringHelper.startsWith(scratch.get(), FIELD) || StringHelper.startsWith(scratch.get(), END): "scratch=" + scratch.get().utf8ToString();
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             in.seek(lineStart);
             if (!omitTF) {
               tf = termFreq;
@@ -357,7 +355,6 @@
     private final IndexInput in;
     private int docID = -1;
     private int tf;
-    private Bits liveDocs;
     private final BytesRefBuilder scratch = new BytesRefBuilder();
     private final BytesRefBuilder scratch2 = new BytesRefBuilder();
     private final CharsRefBuilder scratchUTF16 = new CharsRefBuilder();
@@ -380,8 +377,7 @@
       return in == inStart;
     }
 
-    public SimpleTextPostingsEnum reset(long fp, Bits liveDocs, IndexOptions indexOptions, int docFreq) {
-      this.liveDocs = liveDocs;
+    public SimpleTextPostingsEnum reset(long fp, IndexOptions indexOptions, int docFreq) {
       nextDocStart = fp;
       docID = -1;
       readPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
@@ -414,7 +410,7 @@
         SimpleTextUtil.readLine(in, scratch);
         //System.out.println("NEXT DOC: " + scratch.utf8ToString());
         if (StringHelper.startsWith(scratch.get(), DOC)) {
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             nextDocStart = lineStart;
             in.seek(posStart);
             return docID;
@@ -437,7 +433,7 @@
           // skip
         } else {
           assert StringHelper.startsWith(scratch.get(), TERM) || StringHelper.startsWith(scratch.get(), FIELD) || StringHelper.startsWith(scratch.get(), END);
-          if (!first && (liveDocs == null || liveDocs.get(docID))) {
+          if (!first) {
             nextDocStart = lineStart;
             in.seek(posStart);
             return docID;
Index: lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsWriter.java	(working copy)
@@ -101,7 +101,7 @@
           break;
         }
 
-        postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+        postingsEnum = termsEnum.postings(postingsEnum, flags);
 
         assert postingsEnum != null: "termsEnum=" + termsEnum + " hasPos=" + hasPositions + " flags=" + flags;
 
Index: lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
===================================================================
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java	(revision 1687080)
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java	(working copy)
@@ -387,7 +387,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         SimpleTVPostings postings = current.getValue();
@@ -394,7 +394,7 @@
         if (postings.positions != null || postings.startOffsets != null) {
           // TODO: reuse
           SimpleTVPostingsEnum e = new SimpleTVPostingsEnum();
-          e.reset(liveDocs, postings.positions, postings.startOffsets, postings.endOffsets, postings.payloads);
+          e.reset(postings.positions, postings.startOffsets, postings.endOffsets, postings.payloads);
           return e;
         }
       }
@@ -401,7 +401,7 @@
 
       // TODO: reuse
       SimpleTVDocsEnum e = new SimpleTVDocsEnum();
-      e.reset(liveDocs, PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) == false ? 1 : current.getValue().freq);
+      e.reset(PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) == false ? 1 : current.getValue().freq);
       return e;
     }
 
@@ -412,7 +412,6 @@
     private boolean didNext;
     private int doc = -1;
     private int freq;
-    private Bits liveDocs;
 
     @Override
     public int freq() throws IOException {
@@ -447,7 +446,7 @@
 
     @Override
     public int nextDoc() {
-      if (!didNext && (liveDocs == null || liveDocs.get(0))) {
+      if (!didNext) {
         didNext = true;
         return (doc = 0);
       } else {
@@ -460,8 +459,7 @@
       return slowAdvance(target);
     }
 
-    public void reset(Bits liveDocs, int freq) {
-      this.liveDocs = liveDocs;
+    public void reset(int freq) {
       this.freq = freq;
       this.doc = -1;
       didNext = false;
@@ -477,7 +475,6 @@
     private boolean didNext;
     private int doc = -1;
     private int nextPos;
-    private Bits liveDocs;
     private int[] positions;
     private BytesRef[] payloads;
     private int[] startOffsets;
@@ -500,7 +497,7 @@
 
     @Override
     public int nextDoc() {
-      if (!didNext && (liveDocs == null || liveDocs.get(0))) {
+      if (!didNext) {
         didNext = true;
         return (doc = 0);
       } else {
@@ -513,8 +510,7 @@
       return slowAdvance(target);
     }
 
-    public void reset(Bits liveDocs, int[] positions, int[] startOffsets, int[] endOffsets, BytesRef payloads[]) {
-      this.liveDocs = liveDocs;
+    public void reset(int[] positions, int[] startOffsets, int[] endOffsets, BytesRef payloads[]) {
       this.positions = positions;
       this.startOffsets = startOffsets;
       this.endOffsets = endOffsets;
Index: lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java
===================================================================
--- lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java	(revision 1687080)
+++ lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.java	(working copy)
@@ -55,7 +55,6 @@
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.store.Directory;
@@ -169,7 +168,7 @@
           System.out.println("  got term=" + te.term().utf8ToString());
         }
         verifier.sawTerm(te.term());
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           long v = docValues.get(docID);
@@ -296,7 +295,7 @@
           System.out.println("  got term=" + te.term() + " docFreq=" + te.docFreq());
         }
         verifier.sawTerm(te.term());        
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           long v = docValues.get(docID);
@@ -415,7 +414,7 @@
           System.out.println("TEST: got term=" + te.term().utf8ToString() + " docFreq=" + te.docFreq());
         }
         verifier.sawTerm(te.term());        
-        postingsEnum = te.postings(null, postingsEnum);
+        postingsEnum = te.postings(postingsEnum);
         int docID;
         while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
           assertTrue("prefixBR=" + prefixBR + " docBR=" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));
@@ -491,7 +490,7 @@
     //TermsEnum te = terms.intersect(new CompiledAutomaton(a, true, false), null);
     while (te.next() != null) {
       verifier.sawTerm(te.term());
-      postingsEnum = te.postings(null, postingsEnum);
+      postingsEnum = te.postings(postingsEnum);
       int docID;
       while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
         // The auto-prefix terms should never "overlap" one another, so we should only ever see a given docID one time:
Index: lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Bits;
 
 /** The core terms dictionaries (BlockTermsReader,
  *  BlockTreeTermsReader) interact with a single instance
@@ -65,7 +64,7 @@
 
   /** Must fully consume state, since after this call that
    *  TermState may be reused. */
-  public abstract PostingsEnum postings(FieldInfo fieldInfo, BlockTermState state, Bits skipDocs, PostingsEnum reuse, int flags) throws IOException;
+  public abstract PostingsEnum postings(FieldInfo fieldInfo, BlockTermState state, PostingsEnum reuse, int flags) throws IOException;
   
   /** 
    * Checks consistency of this reader.
Index: lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java	(working copy)
@@ -119,7 +119,7 @@
   @Override
   public final BlockTermState writeTerm(BytesRef term, TermsEnum termsEnum, FixedBitSet docsSeen) throws IOException {
     startTerm();
-    postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+    postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
     assert postingsEnum != null;
 
     int docFreq = 0;
Index: lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java	(working copy)
@@ -267,7 +267,7 @@
         startTerm(termsEnum.term(), freq);
 
         if (hasPositions || hasOffsets) {
-          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);
+          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);
           assert docsAndPositionsEnum != null;
           
           final int docID = docsAndPositionsEnum.nextDoc();
Index: lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/BitSetTermsEnum.java	(working copy)
@@ -21,7 +21,6 @@
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /** Silly stub class, used only when writing an auto-prefix
@@ -73,14 +72,11 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) {
     if (flags != PostingsEnum.NONE) {
       // We only work with DOCS_ONLY fields
       return null;
     }
-    if (liveDocs != null) {
-      throw new IllegalArgumentException("cannot handle live docs");
-    }
     postingsEnum.reset();
     return postingsEnum;
   }
Index: lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java	(working copy)
@@ -466,7 +466,7 @@
     while (prefixTermsEnum.next() != null) {
       //System.out.println("    got term=" + prefixTermsEnum.term().utf8ToString());
       //termCount++;
-      prefixDocsEnum = prefixTermsEnum.postings(null, prefixDocsEnum, 0);
+      prefixDocsEnum = prefixTermsEnum.postings(prefixDocsEnum, 0);
       //System.out.println("      " + prefixDocsEnum + " doc=" + prefixDocsEnum.docID());
       prefixDocs.or(prefixDocsEnum);
     }
Index: lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java	(working copy)
@@ -25,7 +25,6 @@
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.StringHelper;
@@ -232,9 +231,9 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     currentFrame.decodeMetaData();
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.termState, reuse, flags);
   }
 
   private int getState() {
Index: lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/SegmentTermsEnum.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -993,7 +992,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -1002,7 +1001,7 @@
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java	(working copy)
@@ -44,7 +44,6 @@
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LongsRef;
@@ -930,7 +929,7 @@
     }
 
     @Override
-    public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public final PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       final TVPostingsEnum docsEnum;
       if (reuse != null && reuse instanceof TVPostingsEnum) {
         docsEnum = (TVPostingsEnum) reuse;
@@ -938,7 +937,7 @@
         docsEnum = new TVPostingsEnum();
       }
 
-      docsEnum.reset(liveDocs, termFreqs[ord], positionIndex[ord], positions, startOffsets, lengths, payloads, payloadIndex);
+      docsEnum.reset(termFreqs[ord], positionIndex[ord], positions, startOffsets, lengths, payloads, payloadIndex);
       return docsEnum;
     }
 
@@ -946,7 +945,6 @@
 
   private static class TVPostingsEnum extends PostingsEnum {
 
-    private Bits liveDocs;
     private int doc = -1;
     private int termFreq;
     private int positionIndex;
@@ -962,10 +960,9 @@
       payload = new BytesRef();
     }
 
-    public void reset(Bits liveDocs, int freq, int positionIndex, int[] positions,
+    public void reset(int freq, int positionIndex, int[] positions,
         int[] startOffsets, int[] lengths, BytesRef payloads,
         int[] payloadIndex) {
-      this.liveDocs = liveDocs;
       this.termFreq = freq;
       this.positionIndex = positionIndex;
       this.positions = positions;
@@ -1061,7 +1058,7 @@
 
     @Override
     public int nextDoc() throws IOException {
-      if (doc == -1 && (liveDocs == null || liveDocs.get(0))) {
+      if (doc == -1) {
         return (doc = 0);
       } else {
         return (doc = NO_MORE_DOCS);
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesProducer.java	(working copy)
@@ -1140,7 +1140,7 @@
       }
       
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
         throw new UnsupportedOperationException();
       }
 
Index: lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50PostingsReader.java	(working copy)
@@ -32,7 +32,6 @@
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -192,7 +191,7 @@
   }
     
   @Override
-  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, PostingsEnum reuse, int flags) throws IOException {
     
     boolean indexHasPositions = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;
     boolean indexHasOffsets = fieldInfo.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;
@@ -208,7 +207,7 @@
       } else {
         docsEnum = new BlockDocsEnum(fieldInfo);
       }
-      return docsEnum.reset(liveDocs, (IntBlockTermState) termState, flags);
+      return docsEnum.reset((IntBlockTermState) termState, flags);
     } else if ((indexHasOffsets == false || PostingsEnum.featureRequested(flags, PostingsEnum.OFFSETS) == false) &&
                (indexHasPayloads == false || PostingsEnum.featureRequested(flags, PostingsEnum.PAYLOADS) == false)) {
       BlockPostingsEnum docsAndPositionsEnum;
@@ -220,7 +219,7 @@
       } else {
         docsAndPositionsEnum = new BlockPostingsEnum(fieldInfo);
       }
-      return docsAndPositionsEnum.reset(liveDocs, (IntBlockTermState) termState);
+      return docsAndPositionsEnum.reset((IntBlockTermState) termState);
     } else {
       EverythingEnum everythingEnum;
       if (reuse instanceof EverythingEnum) {
@@ -231,7 +230,7 @@
       } else {
         everythingEnum = new EverythingEnum(fieldInfo);
       }
-      return everythingEnum.reset(liveDocs, (IntBlockTermState) termState, flags);
+      return everythingEnum.reset((IntBlockTermState) termState, flags);
     }
   }
 
@@ -272,8 +271,6 @@
     // docID for next skip point, we won't use skipper if 
     // target docID is not larger than this
     private int nextSkipDoc;
-
-    private Bits liveDocs;
     
     private boolean needsFreq; // true if the caller actually needs frequencies
     private int singletonDocID; // docid when there is a single pulsed posting, otherwise -1
@@ -295,9 +292,7 @@
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public PostingsEnum reset(Bits liveDocs, IntBlockTermState termState, int flags) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public PostingsEnum reset(IntBlockTermState termState, int flags) throws IOException {
       docFreq = termState.docFreq;
       totalTermFreq = indexHasFreq ? termState.totalTermFreq : docFreq;
       docTermStartFP = termState.docStartFP;
@@ -380,26 +375,20 @@
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      accum += docDeltaBuffer[docBufferUpto];
+      docUpto++;
 
-        accum += docDeltaBuffer[docBufferUpto];
-        docUpto++;
-
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          freq = freqBuffer[docBufferUpto];
-          docBufferUpto++;
-          return doc;
-        }
-        docBufferUpto++;
-      }
+      doc = accum;
+      freq = freqBuffer[docBufferUpto];
+      docBufferUpto++;
+      return doc;
     }
 
     @Override
@@ -467,14 +456,9 @@
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        freq = freqBuffer[docBufferUpto];
-        docBufferUpto++;
-        return doc = accum;
-      } else {
-        docBufferUpto++;
-        return nextDoc();
-      }
+      freq = freqBuffer[docBufferUpto];
+      docBufferUpto++;
+      return doc = accum;
     }
     
     @Override
@@ -544,7 +528,6 @@
 
     private int nextSkipDoc;
 
-    private Bits liveDocs;
     private int singletonDocID; // docid when there is a single pulsed posting, otherwise -1
     
     public BlockPostingsEnum(FieldInfo fieldInfo) throws IOException {
@@ -562,9 +545,7 @@
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public PostingsEnum reset(Bits liveDocs, IntBlockTermState termState) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public PostingsEnum reset(IntBlockTermState termState) throws IOException {
       docFreq = termState.docFreq;
       docTermStartFP = termState.docStartFP;
       posTermStartFP = termState.posStartFP;
@@ -660,26 +641,22 @@
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        accum += docDeltaBuffer[docBufferUpto];
-        freq = freqBuffer[docBufferUpto];
-        posPendingCount += freq;
-        docBufferUpto++;
-        docUpto++;
+      accum += docDeltaBuffer[docBufferUpto];
+      freq = freqBuffer[docBufferUpto];
+      posPendingCount += freq;
+      docBufferUpto++;
+      docUpto++;
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          position = 0;
-          return doc;
-        }
-      }
+      doc = accum;
+      position = 0;
+      return doc;
     }
     
     @Override
@@ -745,12 +722,8 @@
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        position = 0;
-        return doc = accum;
-      } else {
-        return nextDoc();
-      }
+      position = 0;
+      return doc = accum;
     }
 
     // TODO: in theory we could avoid loading frq block
@@ -904,8 +877,6 @@
     private long skipOffset;
 
     private int nextSkipDoc;
-
-    private Bits liveDocs;
     
     private boolean needsOffsets; // true if we actually need offsets
     private boolean needsPayloads; // true if we actually need payloads
@@ -946,9 +917,7 @@
         indexHasPayloads == fieldInfo.hasPayloads();
     }
     
-    public EverythingEnum reset(Bits liveDocs, IntBlockTermState termState, int flags) throws IOException {
-      this.liveDocs = liveDocs;
-
+    public EverythingEnum reset(IntBlockTermState termState, int flags) throws IOException {
       docFreq = termState.docFreq;
       docTermStartFP = termState.docStartFP;
       posTermStartFP = termState.posStartFP;
@@ -1087,27 +1056,23 @@
 
     @Override
     public int nextDoc() throws IOException {
-      while (true) {
-        if (docUpto == docFreq) {
-          return doc = NO_MORE_DOCS;
-        }
-        if (docBufferUpto == BLOCK_SIZE) {
-          refillDocs();
-        }
+      if (docUpto == docFreq) {
+        return doc = NO_MORE_DOCS;
+      }
+      if (docBufferUpto == BLOCK_SIZE) {
+        refillDocs();
+      }
 
-        accum += docDeltaBuffer[docBufferUpto];
-        freq = freqBuffer[docBufferUpto];
-        posPendingCount += freq;
-        docBufferUpto++;
-        docUpto++;
+      accum += docDeltaBuffer[docBufferUpto];
+      freq = freqBuffer[docBufferUpto];
+      posPendingCount += freq;
+      docBufferUpto++;
+      docUpto++;
 
-        if (liveDocs == null || liveDocs.get(accum)) {
-          doc = accum;
-          position = 0;
-          lastStartOffset = 0;
-          return doc;
-        }
-      }
+      doc = accum;
+      position = 0;
+      lastStartOffset = 0;
+      return doc;
     }
     
     @Override
@@ -1174,13 +1139,9 @@
         }
       }
 
-      if (liveDocs == null || liveDocs.get(accum)) {
-        position = 0;
-        lastStartOffset = 0;
-        return doc = accum;
-      } else {
-        return nextDoc();
-      }
+      position = 0;
+      lastStartOffset = 0;
+      return doc = accum;
     }
 
     // TODO: in theory we could avoid loading frq block
Index: lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java	(working copy)
@@ -31,9 +31,9 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InfoStream;
@@ -550,7 +550,8 @@
         if (state.delGen < delGen) {
 
           // we don't need term frequencies for this
-          state.postingsEnum = state.termsEnum.postings(state.rld.getLiveDocs(), state.postingsEnum, PostingsEnum.NONE);
+          final Bits acceptDocs = state.rld.getLiveDocs();
+          state.postingsEnum = state.termsEnum.postings(state.postingsEnum, PostingsEnum.NONE);
 
           assert state.postingsEnum != null;
 
@@ -559,6 +560,9 @@
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
             }
+            if (acceptDocs != null && acceptDocs.get(docID) == false) {
+              continue;
+            }
             if (!state.any) {
               state.rld.initWritableLiveDocs();
               state.any = true;
@@ -646,7 +650,8 @@
 
       if (termsEnum.seekExact(term.bytes())) {
         // we don't need term frequencies for this
-        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+        final Bits acceptDocs = segState.rld.getLiveDocs();
+        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
 
         DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);
         if (dvUpdates == null) {
@@ -657,6 +662,9 @@
           if (doc >= limit) {
             break; // no more docs that can be updated for this term
           }
+          if (acceptDocs != null && acceptDocs.get(doc) == false) {
+            continue;
+          }
           dvUpdates.add(doc, update.value);
         }
       }
Index: lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java	(working copy)
@@ -528,9 +528,8 @@
       result.cantOpenSegments = true;
       return result;
     }
-    int format = 0;
     try {
-      format = input.readInt();
+      /*int format =*/ input.readInt();
     } catch (Throwable t) {
       if (failFast) {
         IOUtils.reThrow(t);
@@ -959,7 +958,7 @@
         }
       }
 
-      postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+      postingsEnum = termsEnum.postings(postingsEnum, 0);
 
       int lastDoc = -1;
       while (true) {
@@ -1203,7 +1202,6 @@
       
       long sumTotalTermFreq = 0;
       long sumDocFreq = 0;
-      long upto = 0;
       FixedBitSet visitedDocs = new FixedBitSet(maxDoc);
       while(true) {
         
@@ -1249,7 +1247,7 @@
         }
         sumDocFreq += docFreq;
 
-        postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);
+        postings = termsEnum.postings(postings, PostingsEnum.ALL);
 
         if (hasFreqs == false) {
           if (termsEnum.totalTermFreq() != -1) {
@@ -1275,6 +1273,7 @@
         
         int lastDoc = -1;
         int docCount = 0;
+        boolean hasNonDeletedDocs = false;
         long totalTermFreq = 0;
         while(true) {
           final int doc = postings.nextDoc();
@@ -1281,7 +1280,6 @@
           if (doc == DocIdSetIterator.NO_MORE_DOCS) {
             break;
           }
-          status.totFreq++;
           visitedDocs.set(doc);
           int freq = -1;
           if (hasFreqs) {
@@ -1289,7 +1287,6 @@
             if (freq <= 0) {
               throw new RuntimeException("term " + term + ": doc " + doc + ": freq " + freq + " is out of bounds");
             }
-            status.totPos += freq;
             totalTermFreq += freq;
           } else {
             // When a field didn't index freq, it must
@@ -1299,6 +1296,13 @@
               throw new RuntimeException("term " + term + ": doc " + doc + ": freq " + freq + " != 1 when Terms.hasFreqs() is false");
             }
           }
+          if (liveDocs == null || liveDocs.get(doc)) {
+            hasNonDeletedDocs = true;
+            status.totFreq++;
+            if (freq >= 0) {
+              status.totPos += freq;
+            }
+          }
           docCount++;
           
           if (doc <= lastDoc) {
@@ -1358,7 +1362,7 @@
           }
         }
         
-        if (docCount != 0) {
+        if (hasNonDeletedDocs) {
           status.termCount++;
         } else {
           status.delTermCount++;
@@ -1367,28 +1371,6 @@
         final long totalTermFreq2 = termsEnum.totalTermFreq();
         final boolean hasTotalTermFreq = hasFreqs && totalTermFreq2 != -1;
         
-        // Re-count if there are deleted docs:
-        if (liveDocs != null) {
-          if (hasFreqs) {
-            postings = termsEnum.postings(null, postings);
-            docCount = 0;
-            totalTermFreq = 0;
-            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-              visitedDocs.set(postings.docID());
-              docCount++;
-              totalTermFreq += postings.freq();
-            }
-          } else {
-            postings = termsEnum.postings(null, postings, PostingsEnum.NONE);
-            docCount = 0;
-            totalTermFreq = -1;
-            while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-              visitedDocs.set(postings.docID());
-              docCount++;
-            }
-          }
-        }
-        
         if (docCount != docFreq) {
           throw new RuntimeException("term " + term + " docFreq=" + docFreq + " != tot docs w/o deletions " + docCount);
         }
@@ -1406,7 +1388,7 @@
         if (hasPositions) {
           for(int idx=0;idx<7;idx++) {
             final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);
-            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.ALL);
+            postings = termsEnum.postings(postings, PostingsEnum.ALL);
             final int docID = postings.advance(skipDocID);
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
@@ -1470,7 +1452,7 @@
         } else {
           for(int idx=0;idx<7;idx++) {
             final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);
-            postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);
+            postings = termsEnum.postings(postings, PostingsEnum.NONE);
             final int docID = postings.advance(skipDocID);
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
               break;
@@ -1552,7 +1534,7 @@
           }
           
           int expectedDocFreq = termsEnum.docFreq();
-          PostingsEnum d = termsEnum.postings(null, null, PostingsEnum.NONE);
+          PostingsEnum d = termsEnum.postings(null, PostingsEnum.NONE);
           int docFreq = 0;
           while (d.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
             docFreq++;
@@ -1591,7 +1573,6 @@
             }
             
             // Seek by term
-            long totDocCount = 0;
             for(int i=seekCount-1;i>=0;i--) {
               if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {
                 throw new RuntimeException("seek to existing term " + seekTerms[i] + " failed");
@@ -1600,41 +1581,11 @@
                 throw new RuntimeException("seek to existing term " + seekTerms[i] + " returned FOUND but seeked to the wrong term " + termsEnum.term());
               }
               
-              postings = termsEnum.postings(liveDocs, postings, PostingsEnum.NONE);
+              postings = termsEnum.postings(postings, PostingsEnum.NONE);
               if (postings == null) {
                 throw new RuntimeException("null DocsEnum from to existing term " + seekTerms[i]);
               }
-
-              while (postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-                totDocCount++;
-              }
             }
-            
-            long totDocCountNoDeletes = 0;
-            long totDocFreq = 0;
-            for(int i=0;i<seekCount;i++) {
-              if (!termsEnum.seekExact(seekTerms[i])) {
-                throw new RuntimeException("seek to existing term " + seekTerms[i] + " failed");
-              }
-              
-              totDocFreq += termsEnum.docFreq();
-              postings = termsEnum.postings(null, postings, PostingsEnum.NONE);
-              if (postings == null) {
-                throw new RuntimeException("null DocsEnum from to existing term " + seekTerms[i]);
-              }
-              
-              while(postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-                totDocCountNoDeletes++;
-              }
-            }
-            
-            if (totDocCount > totDocCountNoDeletes) {
-              throw new RuntimeException("more postings with deletes=" + totDocCount + " than without=" + totDocCountNoDeletes);
-            }
-            
-            if (totDocCountNoDeletes != totDocFreq) {
-              throw new RuntimeException("docfreqs=" + totDocFreq + " != recomputed docfreqs=" + totDocCountNoDeletes);
-            }
           }
         }
       }
@@ -1685,7 +1636,6 @@
 
     Status.TermIndexStatus status;
     final int maxDoc = reader.maxDoc();
-    final Bits liveDocs = reader.getLiveDocs();
 
     try {
       if (infoStream != null) {
@@ -1694,13 +1644,7 @@
 
       final Fields fields = reader.getPostingsReader().getMergeInstance();
       final FieldInfos fieldInfos = reader.getFieldInfos();
-      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false, infoStream, verbose);
-      if (liveDocs != null) {
-        if (infoStream != null) {
-          infoStream.print("    test (ignoring deletes): terms, freq, prox...");
-        }
-        checkFields(fields, null, maxDoc, fieldInfos, true, false, infoStream, verbose);
-      }
+      status = checkFields(fields, reader.getLiveDocs(), maxDoc, fieldInfos, true, false, infoStream, verbose);
     } catch (Throwable e) {
       if (failFast) {
         IOUtils.reThrow(e);
@@ -2015,7 +1959,6 @@
     long startNS = System.nanoTime();
     final Status.TermVectorStatus status = new Status.TermVectorStatus();
     final FieldInfos fieldInfos = reader.getFieldInfos();
-    final Bits onlyDocIsDeleted = new FixedBitSet(1);
     
     try {
       if (infoStream != null) {
@@ -2026,7 +1969,6 @@
 
       // Only used if crossCheckTermVectors is true:
       PostingsEnum postingsDocs = null;
-      PostingsEnum postingsDocs2 = null;
 
       final Bits liveDocs = reader.getLiveDocs();
 
@@ -2055,12 +1997,6 @@
             // First run with no deletions:
             checkFields(tfv, null, 1, fieldInfos, false, true, infoStream, verbose);
             
-            if (j == 0) {
-              // Also test with the 1 doc deleted; we only do this for first doc because this really is just looking for a [slightly] buggy
-              // TermVectors impl that fails to respect the incoming live docs:
-              checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, false, true, infoStream, verbose);
-            }
-            
             // Only agg stats if the doc is live:
             final boolean doStats = liveDocs == null || liveDocs.get(j);
             
@@ -2097,7 +2033,7 @@
                 while ((term = termsEnum.next()) != null) {
 
                   // This is the term vectors:
-                  postings = termsEnum.postings(null, postings, PostingsEnum.ALL);
+                  postings = termsEnum.postings(postings, PostingsEnum.ALL);
                   assert postings != null;
 
                   if (!postingsTermsEnum.seekExact(term)) {
@@ -2105,11 +2041,11 @@
                   }
 
                   // This is the inverted index ("real" postings):
-                  postingsDocs2 = postingsTermsEnum.postings(null, postingsDocs2, PostingsEnum.ALL);
-                  assert postingsDocs2 != null;
+                  postingsDocs = postingsTermsEnum.postings(postingsDocs, PostingsEnum.ALL);
+                  assert postingsDocs != null;
 
                   
-                  final int advanceDoc = postingsDocs2.advance(j);
+                  final int advanceDoc = postingsDocs.advance(j);
                   if (advanceDoc != j) {
                     throw new RuntimeException("vector term=" + term + " field=" + field + ": doc=" + j + " was not found in postings (got: " + advanceDoc + ")");
                   }
@@ -2122,8 +2058,8 @@
                   
                   if (postingsHasFreq) {
                     final int tf = postings.freq();
-                    if (postingsHasFreq && postingsDocs2.freq() != tf) {
-                      throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": freq=" + tf + " differs from postings freq=" + postingsDocs2.freq());
+                    if (postingsHasFreq && postingsDocs.freq() != tf) {
+                      throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": freq=" + tf + " differs from postings freq=" + postingsDocs.freq());
                     }
 
                     // Term vectors has prox?
@@ -2131,7 +2067,7 @@
                       for (int i = 0; i < tf; i++) {
                         int pos = postings.nextPosition();
                         if (postingsTerms.hasPositions()) {
-                          int postingsPos = postingsDocs2.nextPosition();
+                          int postingsPos = postingsDocs.nextPosition();
                           if (terms.hasPositions() && pos != postingsPos) {
                             throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": pos=" + pos + " differs from postings pos=" + postingsPos);
                           }
@@ -2153,8 +2089,8 @@
                          */
 
                         if (startOffset != -1 && endOffset != -1 && postingsTerms.hasOffsets()) {
-                          int postingsStartOffset = postingsDocs2.startOffset();
-                          int postingsEndOffset = postingsDocs2.endOffset();
+                          int postingsStartOffset = postingsDocs.startOffset();
+                          int postingsEndOffset = postingsDocs.endOffset();
                           if (startOffset != postingsStartOffset) {
                             throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": startOffset=" + startOffset + " differs from postings startOffset=" + postingsStartOffset);
                           }
@@ -2174,16 +2110,16 @@
                           if (payload == null) {
                             // we have payloads, but not at this position. 
                             // postings has payloads too, it should not have one at this position
-                            if (postingsDocs2.getPayload() != null) {
-                              throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has no payload but postings does: " + postingsDocs2.getPayload());
+                            if (postingsDocs.getPayload() != null) {
+                              throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has no payload but postings does: " + postingsDocs.getPayload());
                             }
                           } else {
                             // we have payloads, and one at this position
                             // postings should also have one at this position, with the same bytes.
-                            if (postingsDocs2.getPayload() == null) {
+                            if (postingsDocs.getPayload() == null) {
                               throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has payload=" + payload + " but postings does not.");
                             }
-                            BytesRef postingsPayload = postingsDocs2.getPayload();
+                            BytesRef postingsPayload = postingsDocs.getPayload();
                             if (!payload.equals(postingsPayload)) {
                               throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + " has payload=" + payload + " but differs from postings payload=" + postingsPayload);
                             }
Index: lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/FilterLeafReader.java	(working copy)
@@ -216,8 +216,8 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      return in.postings(liveDocs, reuse, flags);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+      return in.postings(reuse, flags);
     }
 
   }
Index: lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java	(working copy)
@@ -21,7 +21,6 @@
 
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 
 /**
  * Abstract class for enumerating a subset of all terms. 
@@ -179,8 +178,8 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits bits, PostingsEnum reuse, int flags) throws IOException {
-    return tenum.postings(bits, reuse, flags);
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+    return tenum.postings(reuse, flags);
   }
   
   /** This enum does not support seeking!
Index: lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/FreqProxFields.java	(working copy)
@@ -25,7 +25,6 @@
 
 import org.apache.lucene.index.FreqProxTermsWriterPerField.FreqProxPostingsArray;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -226,11 +225,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
-
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         FreqProxPostingsEnum posEnum;
 
Index: lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(working copy)
@@ -56,7 +56,7 @@
         }
 
         if (termsEnum != null && termsEnum.seekExact(deleteTerm.bytes())) {
-          postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+          postingsEnum = termsEnum.postings(postingsEnum, 0);
           int delDocLimit = segDeletes.get(deleteTerm);
           assert delDocLimit < PostingsEnum.NO_MORE_DOCS;
           while (true) {
Index: lucene/core/src/java/org/apache/lucene/index/LeafReader.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/LeafReader.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/LeafReader.java	(working copy)
@@ -210,7 +210,8 @@
   /** Returns {@link PostingsEnum} for the specified term.
    *  This will return null if either the field or
    *  term does not exist.
-   *  @see TermsEnum#postings(Bits, PostingsEnum) */
+   *  <p><b>NOTE:</b> The returned {@link PostingsEnum} may contain deleted docs.
+   *  @see TermsEnum#postings(PostingsEnum) */
   public final PostingsEnum postings(Term term, int flags) throws IOException {
     assert term.field() != null;
     assert term.bytes() != null;
@@ -218,7 +219,7 @@
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term.bytes())) {
-        return termsEnum.postings(getLiveDocs(), null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
@@ -231,6 +232,7 @@
    *  and do not need any proximity data.
    *  This method is equivalent to 
    *  {@link #postings(Term, int) postings(term, PostingsEnum.FREQS)}
+   *  <p><b>NOTE:</b> The returned {@link PostingsEnum} may contain deleted docs.
    *  @see #postings(Term, int)
    */
   public final PostingsEnum postings(Term term) throws IOException {
Index: lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/MappedMultiFields.java	(working copy)
@@ -19,8 +19,6 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.util.Bits;
-
 import static org.apache.lucene.index.FilterLeafReader.FilterFields;
 import static org.apache.lucene.index.FilterLeafReader.FilterTerms;
 import static org.apache.lucene.index.FilterLeafReader.FilterTermsEnum;
@@ -107,11 +105,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
-
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       MappingMultiPostingsEnum mappingDocsAndPositionsEnum;
       if (reuse instanceof MappingMultiPostingsEnum) {
         MappingMultiPostingsEnum postings = (MappingMultiPostingsEnum) reuse;
@@ -124,7 +118,7 @@
         mappingDocsAndPositionsEnum = new MappingMultiPostingsEnum(field, mergeState);
       }
 
-      MultiPostingsEnum docsAndPositionsEnum = (MultiPostingsEnum) in.postings(liveDocs, mappingDocsAndPositionsEnum.multiDocsAndPositionsEnum, flags);
+      MultiPostingsEnum docsAndPositionsEnum = (MultiPostingsEnum) in.postings(mappingDocsAndPositionsEnum.multiDocsAndPositionsEnum, flags);
       mappingDocsAndPositionsEnum.reset(docsAndPositionsEnum);
       return mappingDocsAndPositionsEnum;
     }
Index: lucene/core/src/java/org/apache/lucene/index/MultiFields.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/MultiFields.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/MultiFields.java	(working copy)
@@ -123,8 +123,8 @@
   /** Returns {@link PostingsEnum} for the specified field and
    *  term.  This will return null if the field or term does
    *  not exist. */
-  public static PostingsEnum getTermDocsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
-    return getTermDocsEnum(r, liveDocs, field, term, PostingsEnum.FREQS);
+  public static PostingsEnum getTermDocsEnum(IndexReader r, String field, BytesRef term) throws IOException {
+    return getTermDocsEnum(r, field, term, PostingsEnum.FREQS);
   }
   
   /** Returns {@link PostingsEnum} for the specified field and
@@ -132,8 +132,8 @@
    *  Some codecs may be able to optimize their
    *  implementation when freqs are not required.  This will
    *  return null if the field or term does not exist.  See {@link
-   *  TermsEnum#postings(Bits, PostingsEnum,int)}.*/
-  public static PostingsEnum getTermDocsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term, int flags) throws IOException {
+   *  TermsEnum#postings(PostingsEnum,int)}.*/
+  public static PostingsEnum getTermDocsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {
     assert field != null;
     assert term != null;
     final Terms terms = getTerms(r, field);
@@ -140,7 +140,7 @@
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term)) {
-        return termsEnum.postings(liveDocs, null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
@@ -149,9 +149,9 @@
   /** Returns {@link PostingsEnum} for the specified
    *  field and term.  This will return null if the field or
    *  term does not exist or positions were not indexed. 
-   *  @see #getTermPositionsEnum(IndexReader, Bits, String, BytesRef, int) */
-  public static PostingsEnum getTermPositionsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
-    return getTermPositionsEnum(r, liveDocs, field, term, PostingsEnum.ALL);
+   *  @see #getTermPositionsEnum(IndexReader, String, BytesRef, int) */
+  public static PostingsEnum getTermPositionsEnum(IndexReader r, String field, BytesRef term) throws IOException {
+    return getTermPositionsEnum(r, field, term, PostingsEnum.ALL);
   }
 
   /** Returns {@link PostingsEnum} for the specified
@@ -159,8 +159,8 @@
    *  required.  Some codecs may be able to optimize
    *  their implementation when offsets and/or payloads are not
    *  required. This will return null if the field or term does not
-   *  exist. See {@link TermsEnum#postings(Bits, PostingsEnum,int)}. */
-  public static PostingsEnum getTermPositionsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term, int flags) throws IOException {
+   *  exist. See {@link TermsEnum#postings(PostingsEnum,int)}. */
+  public static PostingsEnum getTermPositionsEnum(IndexReader r, String field, BytesRef term, int flags) throws IOException {
     assert field != null;
     assert term != null;
     final Terms terms = getTerms(r, field);
@@ -167,7 +167,7 @@
     if (terms != null) {
       final TermsEnum termsEnum = terms.iterator();
       if (termsEnum.seekExact(term)) {
-        return termsEnum.postings(liveDocs, null, flags);
+        return termsEnum.postings(null, flags);
       }
     }
     return null;
Index: lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 import java.util.Arrays;
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
@@ -327,7 +326,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     MultiPostingsEnum docsEnum;
 
     // Can only reuse if incoming enum is also a MultiDocsEnum
@@ -340,13 +339,6 @@
     } else {
       docsEnum = new MultiPostingsEnum(this, subs.length);
     }
-    
-    final MultiBits multiLiveDocs;
-    if (liveDocs instanceof MultiBits) {
-      multiLiveDocs = (MultiBits) liveDocs;
-    } else {
-      multiLiveDocs = null;
-    }
 
     int upto = 0;
 
@@ -354,31 +346,8 @@
 
       final TermsEnumWithSlice entry = top[i];
 
-      final Bits b;
-
-      if (multiLiveDocs != null) {
-        // optimize for common case: requested skip docs is a
-        // congruent sub-slice of MultiBits: in this case, we
-        // just pull the liveDocs from the sub reader, rather
-        // than making the inefficient
-        // Slice(Multi(sub-readers)):
-        final MultiBits.SubResult sub = multiLiveDocs.getMatchingSub(entry.subSlice);
-        if (sub.matches) {
-          b = sub.result;
-        } else {
-          // custom case: requested skip docs is foreign:
-          // must slice it on every access
-          b = new BitsSlice(liveDocs, entry.subSlice);
-        }
-      } else if (liveDocs != null) {
-        b = new BitsSlice(liveDocs, entry.subSlice);
-      } else {
-        // no deletions
-        b = null;
-      }
-
       assert entry.index < docsEnum.subPostingsEnums.length: entry.index + " vs " + docsEnum.subPostingsEnums.length + "; " + subs.length;
-      final PostingsEnum subPostingsEnum = entry.terms.postings(b, docsEnum.subPostingsEnums[entry.index], flags);
+      final PostingsEnum subPostingsEnum = entry.terms.postings(docsEnum.subPostingsEnums[entry.index], flags);
       assert subPostingsEnum != null;
       docsEnum.subPostingsEnums[entry.index] = subPostingsEnum;
       subDocs[upto].postingsEnum = subPostingsEnum;
Index: lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/PostingsEnum.java	(working copy)
@@ -21,7 +21,6 @@
 
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /** Iterates through the postings.
@@ -30,29 +29,29 @@
 public abstract class PostingsEnum extends DocIdSetIterator {
   
   /**
-   * Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)} if you don't
+   * Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)} if you don't
    * require per-document postings in the returned enum.
    */
   public static final short NONE = 0;
 
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require term frequencies in the returned enum. */
   public static final short FREQS = 1 << 3;
 
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    * if you require term positions in the returned enum. */
   public static final short POSITIONS = FREQS | 1 << 4;
   
-  /** Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require offsets in the returned enum. */
   public static final short OFFSETS = POSITIONS | 1 << 5;
 
-  /** Flag to pass to  {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+  /** Flag to pass to  {@link TermsEnum#postings(PostingsEnum, int)}
    *  if you require payloads in the returned enum. */
   public static final short PAYLOADS = POSITIONS | 1 << 6;
 
   /**
-   * Flag to pass to {@link TermsEnum#postings(Bits, PostingsEnum, int)}
+   * Flag to pass to {@link TermsEnum#postings(PostingsEnum, int)}
    * to get positions, payloads and offsets in the returned enum
    */
   public static final short ALL = OFFSETS | PAYLOADS;
Index: lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/SortedDocValuesTermsEnum.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -106,7 +105,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     throw new UnsupportedOperationException();
   }
 
Index: lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/SortedSetDocValuesTermsEnum.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 
@@ -106,7 +105,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     throw new UnsupportedOperationException();
   }
 
Index: lucene/core/src/java/org/apache/lucene/index/TermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/TermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/index/TermsEnum.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefIterator;
 
@@ -145,15 +144,13 @@
    *  Use this method if you only require documents and frequencies,
    *  and do not need any proximity data.
    *  This method is equivalent to 
-   *  {@link #postings(Bits, PostingsEnum, int) postings(liveDocs, reuse, PostingsEnum.FREQS)}
-   *  
-   * @param liveDocs unset bits are documents that should not
-   * be returned
+   *  {@link #postings(PostingsEnum, int) postings(reuse, PostingsEnum.FREQS)}
+   *
    * @param reuse pass a prior PostingsEnum for possible reuse 
-   * @see #postings(Bits, PostingsEnum, int)
+   * @see #postings(PostingsEnum, int)
    */
-  public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse) throws IOException {
-    return postings(liveDocs, reuse, PostingsEnum.FREQS);
+  public final PostingsEnum postings(PostingsEnum reuse) throws IOException {
+    return postings(reuse, PostingsEnum.FREQS);
   }
 
   /** Get {@link PostingsEnum} for the current term, with
@@ -161,14 +158,12 @@
    *  are required.  Do not call this when the enum is
    *  unpositioned.  This method may return null if the postings
    *  information required is not available from the index
-   *  
-   * @param liveDocs unset bits are documents that should not
-   * be returned
+   *
    * @param reuse pass a prior PostingsEnum for possible reuse
    * @param flags specifies which optional per-document values
    *        you require; see {@link PostingsEnum#FREQS}
    */
-  public abstract PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException;
+  public abstract PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException;
 
   /**
    * Expert: Returns the TermsEnums internal state to position the TermsEnum
@@ -225,7 +220,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       throw new IllegalStateException("this method should never be called");
     }
       
Index: lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/BooleanScorer.java	(working copy)
@@ -21,7 +21,7 @@
 import java.util.Arrays;
 import java.util.Collection;
 
-import org.apache.lucene.search.BooleanWeight;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.PriorityQueue;
 
 /**
@@ -41,7 +41,7 @@
     return new BulkScorer() {
 
       @Override
-      public int score(final LeafCollector collector, int min, int max) throws IOException {
+      public int score(final LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
         final LeafCollector noScoreCollector = new LeafCollector() {
           FakeScorer fake = new FakeScorer();
 
@@ -56,7 +56,7 @@
             collector.collect(doc);
           }
         };
-        return scorer.score(noScoreCollector, min, max);
+        return scorer.score(noScoreCollector, acceptDocs, min, max);
       }
 
       @Override
@@ -83,11 +83,11 @@
     }
 
     void advance(int min) throws IOException {
-      score(min, min);
+      score(null, min, min);
     }
 
-    void score(int min, int max) throws IOException {
-      next = scorer.score(orCollector, min, max);
+    void score(Bits acceptDocs, int min, int max) throws IOException {
+      next = scorer.score(orCollector, acceptDocs, min, max);
     }
   }
 
@@ -237,12 +237,12 @@
     }
   }
 
-  private void scoreWindow(LeafCollector collector, int base, int min, int max,
+  private void scoreWindow(LeafCollector collector, Bits acceptDocs, int base, int min, int max,
       BulkScorerAndDoc[] scorers, int numScorers) throws IOException {
     for (int i = 0; i < numScorers; ++i) {
       final BulkScorerAndDoc scorer = scorers[i];
       assert scorer.next < max;
-      scorer.score(min, max);
+      scorer.score(acceptDocs, min, max);
     }
 
     scoreMatches(collector, base);
@@ -270,7 +270,7 @@
     return headTop;
   }
 
-  private void scoreWindow(LeafCollector collector, int windowBase, int windowMin, int windowMax) throws IOException {
+  private void scoreWindow(LeafCollector collector, Bits acceptDocs, int windowBase, int windowMin, int windowMax) throws IOException {
     // Fill 'leads' with all scorers from 'head' that are in the right window
     leads[0] = head.pop();
     int maxFreq = 1;
@@ -296,7 +296,7 @@
       }
       tail.clear();
 
-      scoreWindow(collector, windowBase, windowMin, windowMax, leads, maxFreq);
+      scoreWindow(collector, acceptDocs, windowBase, windowMin, windowMax, leads, maxFreq);
     }
 
     // Push back scorers into head and tail
@@ -309,7 +309,7 @@
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
     fakeScorer.doc = -1;
     collector.setScorer(fakeScorer);
 
@@ -321,7 +321,7 @@
       final int windowMax = Math.min(max, windowBase + SIZE);
 
       // general case
-      scoreWindow(collector, windowBase, windowMin, windowMax);
+      scoreWindow(collector, acceptDocs, windowBase, windowMin, windowMax);
       top = head.top();
     }
 
Index: lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.Bits;
 
 /**
  * Expert: the Weight for BooleanQuery, used to
@@ -194,12 +193,12 @@
   /** Try to build a boolean scorer for this weight. Returns null if {@link BooleanScorer}
    *  cannot be used. */
   // pkg-private for forcing use of BooleanScorer in tests
-  BooleanScorer booleanScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  BooleanScorer booleanScorer(LeafReaderContext context) throws IOException {
     List<BulkScorer> optional = new ArrayList<BulkScorer>();
     Iterator<BooleanClause> cIter = query.iterator();
     for (Weight w  : weights) {
       BooleanClause c =  cIter.next();
-      BulkScorer subScorer = w.bulkScorer(context, acceptDocs);
+      BulkScorer subScorer = w.bulkScorer(context);
       
       if (subScorer == null) {
         if (c.isRequired()) {
@@ -230,8 +229,8 @@
   }
 
   @Override
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    final BooleanScorer bulkScorer = booleanScorer(context, acceptDocs);
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+    final BooleanScorer bulkScorer = booleanScorer(context);
     if (bulkScorer != null) { // BooleanScorer is applicable
       // TODO: what is the right heuristic here?
       final long costThreshold;
@@ -254,11 +253,11 @@
         return bulkScorer;
       }
     }
-    return super.bulkScorer(context, acceptDocs);
+    return super.bulkScorer(context);
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     // initially the user provided value,
     // but if minNrShouldMatch == optional.size(),
     // we will optimize and move these to required, making this 0
@@ -272,7 +271,7 @@
     Iterator<BooleanClause> cIter = query.iterator();
     for (Weight w  : weights) {
       BooleanClause c =  cIter.next();
-      Scorer subScorer = w.scorer(context, acceptDocs);
+      Scorer subScorer = w.scorer(context);
       if (subScorer == null) {
         if (c.isRequired()) {
           return null;
Index: lucene/core/src/java/org/apache/lucene/search/BulkScorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BulkScorer.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/BulkScorer.java	(working copy)
@@ -19,6 +19,8 @@
 
 import java.io.IOException;
 
+import org.apache.lucene.util.Bits;
+
 /** This class is used to score a range of documents at
  *  once, and is returned by {@link Weight#bulkScorer}.  Only
  *  queries that have a more optimized means of scoring
@@ -30,9 +32,11 @@
 
   /** Scores and collects all matching documents.
    * @param collector The collector to which all matching documents are passed.
+   * @param acceptDocs {@link Bits} that represents the allowed documents to match, or
+   *                   {@code null} if they are all allowed to match.
    */
-  public void score(LeafCollector collector) throws IOException {
-    final int next = score(collector, 0, DocIdSetIterator.NO_MORE_DOCS);
+  public void score(LeafCollector collector, Bits acceptDocs) throws IOException {
+    final int next = score(collector, acceptDocs, 0, DocIdSetIterator.NO_MORE_DOCS);
     assert next == DocIdSetIterator.NO_MORE_DOCS;
   }
 
@@ -54,7 +58,7 @@
    * <pre class="prettyprint">
    * private final Scorer scorer; // set via constructor
    *
-   * public int score(LeafCollector collector, int min, int max) throws IOException {
+   * public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
    *   collector.setScorer(scorer);
    *   int doc = scorer.docID();
    *   if (doc &lt; min) {
@@ -61,7 +65,9 @@
    *     doc = scorer.advance(min);
    *   }
    *   while (doc &lt; max) {
-   *     collector.collect(doc);
+   *     if (acceptDocs == null || acceptDocs.get(doc)) {
+   *       collector.collect(doc);
+   *     }
    *     doc = scorer.nextDoc();
    *   }
    *   return doc;
@@ -69,11 +75,13 @@
    * </pre>
    *
    * @param  collector The collector to which all matching documents are passed.
+   * @param acceptDocs {@link Bits} that represents the allowed documents to match, or
+   *                   {@code null} if they are all allowed to match.
    * @param  min Score starting at, including, this document 
    * @param  max Score up to, but not including, this doc
    * @return an under-estimation of the next matching doc after max
    */
-  public abstract int score(LeafCollector collector, int min, int max) throws IOException;
+  public abstract int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException;
 
   /**
    * Same as {@link Scorer#cost()} for bulk scorers.
Index: lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/CachingWrapperQuery.java	(working copy)
@@ -33,7 +33,6 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RoaringDocIdSet;
 
 /**
@@ -124,7 +123,7 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         final LeafReader reader = context.reader();
         final Object key = reader.getCoreCacheKey();
 
@@ -133,7 +132,7 @@
           hitCount++;
         } else if (policy.shouldCache(query, context)) {
           missCount++;
-          final Scorer scorer = weight.scorer(context, null);
+          final Scorer scorer = weight.scorer(context);
           if (scorer == null) {
             docIdSet = DocIdSet.EMPTY;
           } else {
@@ -141,7 +140,7 @@
           }
           cache.put(key, docIdSet);
         } else {
-          return weight.scorer(context, acceptDocs);
+          return weight.scorer(context);
         }
 
         assert docIdSet != null;
@@ -153,21 +152,7 @@
           return null;
         }
 
-        // We apply acceptDocs as an approximation
-        if (acceptDocs == null) {
-          return new ConstantScoreScorer(this, 0f, disi);
-        } else {
-          final TwoPhaseIterator twoPhaseView = new TwoPhaseIterator(disi) {
-
-            @Override
-            public boolean matches() throws IOException {
-              final int doc = approximation.docID();
-              return acceptDocs.get(doc);
-            }
-
-          };
-          return new ConstantScoreScorer(this, 0f, twoPhaseView);
-        }
+        return new ConstantScoreScorer(this, 0f, disi);
       }
     };
   }
Index: lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/ConstantScoreQuery.java	(working copy)
@@ -83,8 +83,8 @@
     }
 
     @Override
-    public int score(LeafCollector collector, int min, int max) throws IOException {
-      return bulkScorer.score(wrapCollector(collector), min, max);
+    public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
+      return bulkScorer.score(wrapCollector(collector), acceptDocs, min, max);
     }
 
     private LeafCollector wrapCollector(LeafCollector collector) {
@@ -119,8 +119,8 @@
       return new ConstantScoreWeight(this) {
 
         @Override
-        public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final BulkScorer innerScorer = innerWeight.bulkScorer(context, acceptDocs);
+        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+          final BulkScorer innerScorer = innerWeight.bulkScorer(context);
           if (innerScorer == null) {
             return null;
           }
@@ -128,8 +128,8 @@
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final Scorer innerScorer = innerWeight.scorer(context, acceptDocs);
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          final Scorer innerScorer = innerWeight.scorer(context);
           if (innerScorer == null) {
             return null;
           }
Index: lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/ConstantScoreWeight.java	(working copy)
@@ -66,7 +66,7 @@
 
   @Override
   public final Explanation explain(LeafReaderContext context, int doc) throws IOException {
-    final Scorer s = scorer(context, context.reader().getLiveDocs());
+    final Scorer s = scorer(context);
     final boolean exists;
     if (s == null) {
       exists = false;
Index: lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.Bits;
 
 /**
  * A query that generates the union of documents produced by its subqueries, and that scores each document with the maximum
@@ -161,11 +160,11 @@
 
     /** Create the scorer used to score our associated DisjunctionMaxQuery */
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       List<Scorer> scorers = new ArrayList<>();
       for (Weight w : weights) {
         // we will advance() subscorers
-        Scorer subScorer = w.scorer(context, acceptDocs);
+        Scorer subScorer = w.scorer(context);
         if (subScorer != null) {
           scorers.add(subScorer);
         }
Index: lucene/core/src/java/org/apache/lucene/search/Filter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/Filter.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/Filter.java	(working copy)
@@ -96,7 +96,7 @@
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer scorer = scorer(context, context.reader().getLiveDocs());
+        final Scorer scorer = scorer(context);
         final boolean match = (scorer != null && scorer.advance(doc) == doc);
         if (match) {
           assert scorer.score() == 0f;
@@ -107,8 +107,8 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final DocIdSet set = getDocIdSet(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final DocIdSet set = getDocIdSet(context, null);
         if (set == null) {
           return null;
         }
Index: lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java	(working copy)
@@ -31,7 +31,6 @@
 import org.apache.lucene.util.Attribute;
 import org.apache.lucene.util.AttributeImpl;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.UnicodeUtil;
@@ -265,8 +264,8 @@
   }
   
   @Override
-  public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-    return actualEnum.postings(liveDocs, reuse, flags);
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+    return actualEnum.postings(reuse, flags);
   }
   
   @Override
Index: lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java	(working copy)
@@ -46,6 +46,7 @@
 import org.apache.lucene.search.similarities.DefaultSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.NIOFSDirectory;    // javadoc
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ThreadInterruptedException;
 
@@ -614,10 +615,10 @@
         // continue with the following leaf
         continue;
       }
-      BulkScorer scorer = weight.bulkScorer(ctx, ctx.reader().getLiveDocs());
+      BulkScorer scorer = weight.bulkScorer(ctx);
       if (scorer != null) {
         try {
-          scorer.score(leafCollector);
+          scorer.score(leafCollector, ctx.reader().getLiveDocs());
         } catch (CollectionTerminatedException e) {
           // collection was terminated prematurely
           // continue with the following leaf
@@ -667,7 +668,10 @@
     int n = ReaderUtil.subIndex(doc, leafContexts);
     final LeafReaderContext ctx = leafContexts.get(n);
     int deBasedDoc = doc - ctx.docBase;
-    
+    final Bits liveDocs = ctx.reader().getLiveDocs();
+    if (liveDocs != null && liveDocs.get(deBasedDoc) == false) {
+      return Explanation.noMatch("Document " + doc + " is deleted");
+    }
     return weight.explain(ctx, deBasedDoc);
   }
 
Index: lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/LRUQueryCache.java	(working copy)
@@ -36,7 +36,6 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.RoaringDocIdSet;
 
@@ -566,7 +565,7 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (context.ord == 0) {
         policy.onUse(getQuery());
       }
@@ -574,7 +573,7 @@
       if (docIdSet == null) {
         if (cacheEntryHasReasonableWorstCaseSize(ReaderUtil.getTopLevelContext(context).reader().maxDoc())
             && policy.shouldCache(in.getQuery(), context)) {
-          final Scorer scorer = in.scorer(context, null);
+          final Scorer scorer = in.scorer(context);
           if (scorer == null) {
             docIdSet = DocIdSet.EMPTY;
           } else {
@@ -582,7 +581,7 @@
           }
           putIfAbsent(in.getQuery(), context, docIdSet);
         } else {
-          return in.scorer(context, acceptDocs);
+          return in.scorer(context);
         }
       }
 
@@ -595,19 +594,7 @@
         return null;
       }
 
-      // we apply acceptDocs as an approximation
-      if (acceptDocs == null) {
-        return new ConstantScoreScorer(this, 0f, disi);
-      } else {
-        final TwoPhaseIterator twoPhaseView = new TwoPhaseIterator(disi) {
-          @Override
-          public boolean matches() throws IOException {
-            final int doc = approximation.docID();
-            return acceptDocs.get(doc);
-          }
-        };
-        return new ConstantScoreScorer(this, 0f, twoPhaseView);
-      }
+      return new ConstantScoreScorer(this, 0f, disi);
     }
 
   }
Index: lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java	(working copy)
@@ -33,7 +33,6 @@
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.PriorityQueue;
 import org.apache.lucene.util.ToStringUtils;
@@ -173,10 +172,9 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert !termArrays.isEmpty();
       final LeafReader reader = context.reader();
-      final Bits liveDocs = acceptDocs;
       
       PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];
 
@@ -201,7 +199,7 @@
           TermState termState = termContexts.get(term).get(context.ord);
           if (termState != null) {
             termsEnum.seekExact(term.bytes(), termState);
-            postings.add(termsEnum.postings(liveDocs, null, PostingsEnum.POSITIONS));
+            postings.add(termsEnum.postings(null, PostingsEnum.POSITIONS));
           }
         }
         
@@ -233,7 +231,7 @@
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/MultiTermQueryConstantScoreWrapper.java	(working copy)
@@ -31,7 +31,6 @@
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 /**
@@ -136,7 +135,7 @@
        * On the given leaf context, try to either rewrite to a disjunction if
        * there are few terms, or build a bitset containing matching docs.
        */
-      private WeightOrBitSet rewrite(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      private WeightOrBitSet rewrite(LeafReaderContext context) throws IOException {
         final Terms terms = context.reader().terms(query.field);
         if (terms == null) {
           // field does not exist
@@ -168,7 +167,7 @@
           TermsEnum termsEnum2 = terms.iterator();
           for (TermAndState t : collectedTerms) {
             termsEnum2.seekExact(t.term, t.state);
-            docs = termsEnum2.postings(acceptDocs, docs, PostingsEnum.NONE);
+            docs = termsEnum2.postings(docs, PostingsEnum.NONE);
             builder.or(docs);
           }
         }
@@ -175,7 +174,7 @@
 
         // Then keep filling the bit set with remaining terms
         do {
-          docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           builder.or(docs);
         } while (termsEnum.next() != null);
 
@@ -194,10 +193,10 @@
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.bulkScorer(context, acceptDocs);
+          return weightOrBitSet.weight.bulkScorer(context);
         } else {
           final Scorer scorer = scorer(weightOrBitSet.bitset);
           if (scorer == null) {
@@ -208,10 +207,10 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.scorer(context, acceptDocs);
+          return weightOrBitSet.weight.scorer(context);
         } else {
           return scorer(weightOrBitSet.bitset);
         }
Index: lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java	(working copy)
@@ -37,7 +37,6 @@
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ToStringUtils;
 
@@ -396,10 +395,9 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert terms.length > 0;
       final LeafReader reader = context.reader();
-      final Bits liveDocs = acceptDocs;
       PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];
 
       final Terms fieldTerms = reader.terms(field);
@@ -422,7 +420,7 @@
           return null;
         }
         te.seekExact(t.bytes(), state);
-        PostingsEnum postingsEnum = te.postings(liveDocs, null, PostingsEnum.POSITIONS);
+        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);
         postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);
       }
 
@@ -445,7 +443,7 @@
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java	(working copy)
@@ -82,7 +82,7 @@
       if (readerContext != null) {
         // We advanced to another segment:
         docBase = readerContext.docBase;
-        scorer = weight.scorer(readerContext, null);
+        scorer = weight.scorer(readerContext);
       }
 
       if(scorer != null) {
Index: lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java	(working copy)
@@ -61,10 +61,11 @@
     // get a private context that is used to rewrite, createWeight and score eventually
     final LeafReaderContext privateContext = context.reader().getContext();
     final Weight weight = new IndexSearcher(privateContext).createNormalizedWeight(query, false);
-    return new DocIdSet() {
+    
+    DocIdSet set = new DocIdSet() {
       @Override
       public DocIdSetIterator iterator() throws IOException {
-        return weight.scorer(privateContext, acceptDocs);
+        return weight.scorer(privateContext);
       }
 
       @Override
@@ -72,6 +73,7 @@
         return 0L;
       }
     };
+    return BitsFilteredDocIdSet.wrap(set, acceptDocs);
   }
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/RandomAccessWeight.java	(working copy)
@@ -48,7 +48,7 @@
   protected abstract Bits getMatchingDocs(LeafReaderContext context) throws IOException;
 
   @Override
-  public final Scorer scorer(LeafReaderContext context, final Bits acceptDocs) throws IOException {
+  public final Scorer scorer(LeafReaderContext context) throws IOException {
     final Bits matchingDocs = getMatchingDocs(context);
     if (matchingDocs == null || matchingDocs instanceof MatchNoBits) {
       return null;
@@ -60,10 +60,6 @@
       public boolean matches() throws IOException {
         final int doc = approximation.docID();
 
-        if (acceptDocs != null && acceptDocs.get(doc) == false) {
-          return false;
-        }
-
         return matchingDocs.get(doc);
       }
     };
Index: lucene/core/src/java/org/apache/lucene/search/TermQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TermQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/TermQuery.java	(working copy)
@@ -32,7 +32,6 @@
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.search.similarities.Similarity.SimScorer;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /**
@@ -98,13 +97,13 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       assert termStates.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termStates.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
       final TermsEnum termsEnum = getTermsEnum(context);
       if (termsEnum == null) {
         return null;
       }
-      PostingsEnum docs = termsEnum.postings(acceptDocs, null, needsScores ? PostingsEnum.FREQS : PostingsEnum.NONE);
+      PostingsEnum docs = termsEnum.postings(null, needsScores ? PostingsEnum.FREQS : PostingsEnum.NONE);
       assert docs != null;
       return new TermScorer(this, docs, similarity.simScorer(stats, context));
     }
@@ -136,7 +135,7 @@
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      Scorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/Weight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/Weight.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/Weight.java	(working copy)
@@ -36,7 +36,7 @@
  * {@link org.apache.lucene.index.LeafReader} dependent state should reside in the {@link Scorer}.
  * <p>
  * Since {@link Weight} creates {@link Scorer} instances for a given
- * {@link org.apache.lucene.index.LeafReaderContext} ({@link #scorer(org.apache.lucene.index.LeafReaderContext, Bits)})
+ * {@link org.apache.lucene.index.LeafReaderContext} ({@link #scorer(org.apache.lucene.index.LeafReaderContext)})
  * callers must maintain the relationship between the searcher's top-level
  * {@link IndexReaderContext} and the context used to create a {@link Scorer}. 
  * <p>
@@ -51,7 +51,7 @@
  * <li>The query normalization factor is passed to {@link #normalize(float, float)}. At
  * this point the weighting is complete.
  * <li>A <code>Scorer</code> is constructed by
- * {@link #scorer(org.apache.lucene.index.LeafReaderContext, Bits)}.
+ * {@link #scorer(org.apache.lucene.index.LeafReaderContext)}.
  * </ol>
  * 
  * @since 2.9
@@ -105,14 +105,11 @@
    * 
    * @param context
    *          the {@link org.apache.lucene.index.LeafReaderContext} for which to return the {@link Scorer}.
-   * @param acceptDocs
-   *          Bits that represent the allowable docs to match (typically deleted docs
-   *          but possibly filtering other documents)
    *          
    * @return a {@link Scorer} which scores documents in/out-of order.
    * @throws IOException if there is a low-level I/O error
    */
-  public abstract Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException;
+  public abstract Scorer scorer(LeafReaderContext context) throws IOException;
 
   /**
    * Optional method, to return a {@link BulkScorer} to
@@ -124,17 +121,14 @@
    *
    * @param context
    *          the {@link org.apache.lucene.index.LeafReaderContext} for which to return the {@link Scorer}.
-   * @param acceptDocs
-   *          Bits that represent the allowable docs to match (typically deleted docs
-   *          but possibly filtering other documents)
    *
    * @return a {@link BulkScorer} which scores documents and
    * passes them to a collector.
    * @throws IOException if there is a low-level I/O error
    */
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
 
-    Scorer scorer = scorer(context, acceptDocs);
+    Scorer scorer = scorer(context);
     if (scorer == null) {
       // No docs match
       return null;
@@ -164,23 +158,22 @@
     }
 
     @Override
-    public int score(LeafCollector collector, int min, int max) throws IOException {
-      // TODO: this may be sort of weird, when we are
-      // embedded in a BooleanScorer, because we are
-      // called for every chunk of 2048 documents.  But,
-      // then, scorer is a FakeScorer in that case, so any
-      // Collector doing something "interesting" in
-      // setScorer will be forced to use BS2 anyways:
+    public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
       collector.setScorer(scorer);
+      final TwoPhaseIterator twoPhase = scorer.asTwoPhaseIterator();
       if (scorer.docID() == -1 && min == 0 && max == DocIdSetIterator.NO_MORE_DOCS) {
-        scoreAll(collector, scorer);
+        scoreAll(collector, scorer, twoPhase, acceptDocs);
         return DocIdSetIterator.NO_MORE_DOCS;
       } else {
         int doc = scorer.docID();
         if (doc < min) {
-          doc = scorer.advance(min);
+          if (twoPhase == null) {
+            doc = scorer.advance(min);
+          } else {
+            doc = twoPhase.approximation().advance(min);
+          }
         }
-        return scoreRange(collector, scorer, doc, max);
+        return scoreRange(collector, scorer, twoPhase, acceptDocs, doc, max);
       }
     }
 
@@ -188,12 +181,26 @@
      *  separate this from {@link #scoreAll} to help out
      *  hotspot.
      *  See <a href="https://issues.apache.org/jira/browse/LUCENE-5487">LUCENE-5487</a> */
-    static int scoreRange(LeafCollector collector, Scorer scorer, int currentDoc, int end) throws IOException {
-      while (currentDoc < end) {
-        collector.collect(currentDoc);
-        currentDoc = scorer.nextDoc();
+    static int scoreRange(LeafCollector collector, Scorer scorer, TwoPhaseIterator twoPhase,
+        Bits acceptDocs, int currentDoc, int end) throws IOException {
+      if (twoPhase == null) {
+        while (currentDoc < end) {
+          if (acceptDocs == null || acceptDocs.get(currentDoc)) {
+            collector.collect(currentDoc);
+          }
+          currentDoc = scorer.nextDoc();
+        }
+        return currentDoc;
+      } else {
+        final DocIdSetIterator approximation = twoPhase.approximation();
+        while (currentDoc < end) {
+          if ((acceptDocs == null || acceptDocs.get(currentDoc)) && twoPhase.matches()) {
+            collector.collect(currentDoc);
+          }
+          currentDoc = approximation.nextDoc();
+        }
+        return currentDoc;
       }
-      return currentDoc;
     }
     
     /** Specialized method to bulk-score all hits; we
@@ -200,9 +207,21 @@
      *  separate this from {@link #scoreRange} to help out
      *  hotspot.
      *  See <a href="https://issues.apache.org/jira/browse/LUCENE-5487">LUCENE-5487</a> */
-    static void scoreAll(LeafCollector collector, Scorer scorer) throws IOException {
-      for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-        collector.collect(doc);
+    static void scoreAll(LeafCollector collector, Scorer scorer, TwoPhaseIterator twoPhase, Bits acceptDocs) throws IOException {
+      if (twoPhase == null) {
+        for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
+          if (acceptDocs == null || acceptDocs.get(doc)) {
+            collector.collect(doc);
+          }
+        }
+      } else {
+        // The scorer has an approximation, so run the approximation first, then check acceptDocs, then confirm
+        final DocIdSetIterator approximation = twoPhase.approximation();
+        for (int doc = approximation.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = approximation.nextDoc()) {
+          if ((acceptDocs == null || acceptDocs.get(doc)) && twoPhase.matches()) {
+            collector.collect(doc);
+          }
+        }
       }
     }
   }
Index: lucene/core/src/java/org/apache/lucene/search/package-info.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/package-info.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/package-info.java	(working copy)
@@ -470,7 +470,7 @@
  *         abstract method:
  *         <ol>
  *             <li>
- *                 {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,int,int) score(LeafCollector,int,int)} &mdash;
+ *                 {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,org.apache.lucene.util.Bits,int,int) score(LeafCollector,Bits,int,int)} &mdash;
  *     Score all documents up to but not including the specified max document.
  *       </li>
  *         </ol>
@@ -522,7 +522,7 @@
  * <p>If a Filter is being used, some initial setup is done to determine which docs to include. 
  *    Otherwise, we ask the Weight for a {@link org.apache.lucene.search.Scorer Scorer} for each
  *    {@link org.apache.lucene.index.IndexReader IndexReader} segment and proceed by calling
- *    {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector) BulkScorer.score(LeafCollector)}.
+ *    {@link org.apache.lucene.search.BulkScorer#score(org.apache.lucene.search.LeafCollector,org.apache.lucene.util.Bits) BulkScorer.score(LeafCollector,Bits)}.
  * <p>At last, we are actually going to score some documents. The score method takes in the Collector
  *    (most likely the TopScoreDocCollector or TopFieldCollector) and does its business.Of course, here 
  *    is where things get involved. The {@link org.apache.lucene.search.Scorer Scorer} that is returned
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java	(working copy)
@@ -144,8 +144,8 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Spans spans = super.getSpans(context, acceptDocs, Postings.PAYLOADS);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Spans spans = super.getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new PayloadNearSpanScorer(spans, this, simScorer);
     }
@@ -152,7 +152,7 @@
     
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      PayloadNearSpanScorer scorer = (PayloadNearSpanScorer) scorer(context, context.reader().getLiveDocs());
+      PayloadNearSpanScorer scorer = (PayloadNearSpanScorer) scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(working copy)
@@ -179,7 +179,7 @@
 
     PayloadSpanCollector collector = new PayloadSpanCollector();
     for (LeafReaderContext leafReaderContext : context.leaves()) {
-      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), SpanWeight.Postings.PAYLOADS);
+      final Spans spans = w.getSpans(leafReaderContext, SpanWeight.Postings.PAYLOADS);
       if (spans != null) {
         while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
           while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(working copy)
@@ -32,7 +32,6 @@
 import org.apache.lucene.search.spans.SpanTermQuery;
 import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
@@ -98,8 +97,8 @@
     }
 
     @Override
-    public PayloadTermSpanScorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Spans spans = super.getSpans(context, acceptDocs, Postings.PAYLOADS);
+    public PayloadTermSpanScorer scorer(LeafReaderContext context) throws IOException {
+      Spans spans = super.getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new PayloadTermSpanScorer(spans, this, simScorer);
     }
@@ -184,7 +183,7 @@
     
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      PayloadTermSpanScorer scorer = scorer(context, context.reader().getLiveDocs());
+      PayloadTermSpanScorer scorer = scorer(context);
       if (scorer != null) {
         int newDoc = scorer.advance(doc);
         if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/SpanPayloadCheckQuery.java	(working copy)
@@ -36,7 +36,6 @@
 import org.apache.lucene.search.spans.SpanScorer;
 import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /**
@@ -90,9 +89,9 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
       final PayloadSpanCollector collector = new PayloadSpanCollector();
-      Spans matchSpans = matchWeight.getSpans(context, acceptDocs, requiredPostings.atLeast(Postings.PAYLOADS));
+      Spans matchSpans = matchWeight.getSpans(context, requiredPostings.atLeast(Postings.PAYLOADS));
       return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
         @Override
         protected AcceptStatus accept(Spans candidate) throws IOException {
@@ -104,7 +103,7 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (field == null)
         return null;
 
@@ -113,7 +112,7 @@
         throw new IllegalStateException("field \"" + field + "\" was indexed without position data; cannot run SpanQuery (query=" + parentQuery + ")");
       }
 
-      Spans spans = getSpans(context, acceptDocs, Postings.PAYLOADS);
+      Spans spans = getSpans(context, Postings.PAYLOADS);
       Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null) ? null : new SpanScorer(spans, this, simScorer);
     }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java	(working copy)
@@ -23,7 +23,6 @@
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -71,12 +70,12 @@
       littleWeight.extractTerms(terms);
     }
 
-    ArrayList<Spans> prepareConjunction(final LeafReaderContext context, final Bits acceptDocs, Postings postings) throws IOException {
-      Spans bigSpans = bigWeight.getSpans(context, acceptDocs, postings);
+    ArrayList<Spans> prepareConjunction(final LeafReaderContext context, Postings postings) throws IOException {
+      Spans bigSpans = bigWeight.getSpans(context, postings);
       if (bigSpans == null) {
         return null;
       }
-      Spans littleSpans = littleWeight.getSpans(context, acceptDocs, postings);
+      Spans littleSpans = littleWeight.getSpans(context, postings);
       if (littleSpans == null) {
         return null;
       }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java	(working copy)
@@ -70,8 +70,8 @@
      * The payload is from the spans of <code>big</code>.
      */
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, requiredPostings);
       if (containerContained == null) {
         return null;
       }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java	(working copy)
@@ -31,7 +31,6 @@
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /** Matches spans which are near one another.  One can specify <i>slop</i>, the
@@ -131,7 +130,7 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
 
       Terms terms = context.reader().terms(field);
       if (terms == null) {
@@ -140,7 +139,7 @@
 
       ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
       for (SpanWeight w : subWeights) {
-        Spans subSpan = w.getSpans(context, acceptDocs, requiredPostings);
+        Spans subSpan = w.getSpans(context, requiredPostings);
         if (subSpan != null) {
           subSpans.add(subSpan);
         } else {
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(working copy)
@@ -25,7 +25,6 @@
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -128,13 +127,13 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      Spans includeSpans = includeWeight.getSpans(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      Spans includeSpans = includeWeight.getSpans(context, requiredPostings);
       if (includeSpans == null) {
         return null;
       }
 
-      Spans excludeSpans = excludeWeight.getSpans(context, acceptDocs, requiredPostings);
+      Spans excludeSpans = excludeWeight.getSpans(context, requiredPostings);
       if (excludeSpans == null) {
         return includeSpans;
       }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -170,13 +169,13 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings)
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings)
         throws IOException {
 
       ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
 
       for (SpanWeight w : subWeights) {
-        Spans spans = w.getSpans(context, acceptDocs, requiredPostings);
+        Spans spans = w.getSpans(context, requiredPostings);
         if (spans != null) {
           subSpans.add(spans);
         }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.spans.FilterSpans.AcceptStatus;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.Map;
@@ -93,8 +92,8 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
-      Spans matchSpans = matchWeight.getSpans(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      Spans matchSpans = matchWeight.getSpans(context, requiredPostings);
       return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
         @Override
         protected AcceptStatus accept(Spans candidate) throws IOException {
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -99,7 +98,7 @@
     }
 
     @Override
-    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Postings requiredPostings) throws IOException {
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
 
       assert termContext.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termContext.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
 
@@ -118,7 +117,7 @@
       final TermsEnum termsEnum = terms.iterator();
       termsEnum.seekExact(term.bytes(), state);
 
-      final PostingsEnum postings = termsEnum.postings(acceptDocs, null, requiredPostings.getRequiredPostings());
+      final PostingsEnum postings = termsEnum.postings(null, requiredPostings.getRequiredPostings());
       return new TermSpans(postings, term);
     }
   }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java	(working copy)
@@ -114,11 +114,10 @@
   /**
    * Expert: Return a Spans object iterating over matches from this Weight
    * @param ctx a LeafReaderContext for this Spans
-   * @param acceptDocs a bitset of documents to check
    * @return a Spans
    * @throws IOException on error
    */
-  public abstract Spans getSpans(LeafReaderContext ctx, Bits acceptDocs, Postings requiredPostings) throws IOException;
+  public abstract Spans getSpans(LeafReaderContext ctx, Postings requiredPostings) throws IOException;
 
   @Override
   public float getValueForNormalization() throws IOException {
@@ -133,7 +132,7 @@
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     if (field == null) {
       return null;
     }
@@ -141,7 +140,7 @@
     if (terms != null && terms.hasPositions() == false) {
       throw new IllegalStateException("field \"" + field + "\" was indexed without position data; cannot run SpanQuery (query=" + parentQuery + ")");
     }
-    Spans spans = getSpans(context, acceptDocs, Postings.POSITIONS);
+    Spans spans = getSpans(context, Postings.POSITIONS);
     Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
     return (spans == null) ? null : new SpanScorer(spans, this, simScorer);
   }
@@ -148,7 +147,7 @@
 
   @Override
   public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-    SpanScorer scorer = (SpanScorer) scorer(context, context.reader().getLiveDocs());
+    SpanScorer scorer = (SpanScorer) scorer(context);
     if (scorer != null) {
       int newDoc = scorer.advance(doc);
       if (newDoc == doc) {
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java	(revision 1687080)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java	(working copy)
@@ -21,7 +21,6 @@
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -71,8 +70,8 @@
      * The payload is from the spans of <code>little</code>.
      */
     @Override
-    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, Postings requiredPostings) throws IOException {
-      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, requiredPostings);
+    public Spans getSpans(final LeafReaderContext context, Postings requiredPostings) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, requiredPostings);
       if (containerContained == null) {
         return null;
       }
Index: lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(working copy)
@@ -85,7 +85,6 @@
     
     IndexReader reader = writer.getReader();
     PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                                          MultiFields.getLiveDocs(reader),
                                                                           "preanalyzed",
                                                                           new BytesRef("term1"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -93,7 +92,6 @@
     assertEquals(0, termPositions.nextPosition());
 
     termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                     MultiFields.getLiveDocs(reader),
                                                      "preanalyzed",
                                                      new BytesRef("term2"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -102,7 +100,6 @@
     assertEquals(3, termPositions.nextPosition());
     
     termPositions = MultiFields.getTermPositionsEnum(reader,
-                                                     MultiFields.getLiveDocs(reader),
                                                      "preanalyzed",
                                                      new BytesRef("term3"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/codecs/lucene50/TestBlockPostingsFormat3.java	(working copy)
@@ -283,7 +283,6 @@
    */
   public void assertTermsEnum(TermsEnum leftTermsEnum, TermsEnum rightTermsEnum, boolean deep, boolean hasPositions) throws Exception {
     BytesRef term;
-    Bits randomBits = new RandomBits(MAXDOC, random().nextDouble(), random());
     PostingsEnum leftPositions = null;
     PostingsEnum rightPositions = null;
     PostingsEnum leftDocs = null;
@@ -295,84 +294,54 @@
       if (deep) {
         if (hasPositions) {
           // with payloads + off
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
           // with payloads only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.PAYLOADS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.PAYLOADS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.PAYLOADS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.PAYLOADS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.PAYLOADS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.PAYLOADS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.PAYLOADS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.PAYLOADS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.PAYLOADS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.PAYLOADS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.PAYLOADS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.PAYLOADS));
 
           // with offsets only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.OFFSETS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.OFFSETS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.OFFSETS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.OFFSETS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.OFFSETS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.OFFSETS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.OFFSETS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.OFFSETS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.OFFSETS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.OFFSETS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.OFFSETS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.OFFSETS));
 
           // with positions only
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.POSITIONS),
-                                     rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.POSITIONS));
-          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.POSITIONS),
-                                     rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.POSITIONS));
+          assertDocsAndPositionsEnum(leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.POSITIONS),
+                                     rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.POSITIONS));
 
           assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.POSITIONS),
-                                  rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.POSITIONS));
-          assertPositionsSkipping(leftTermsEnum.docFreq(),
-                                  leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.POSITIONS),
-                                  rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.POSITIONS));
+                                  leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.POSITIONS),
+                                  rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.POSITIONS));
         }
         
         // with freqs:
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs));
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs));
+        assertDocsEnum(leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs));
 
         // w/o freqs:
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE));
-        assertDocsEnum(leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE));
-        
+        assertDocsEnum(leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE));
+
         // with freqs:
         assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs));
-        assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs));
+            leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs));
 
         // w/o freqs:
         assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE));
-        assertDocsSkipping(leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE));
+            leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE));
       }
     }
     assertNull(rightTermsEnum.next());
Index: lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -532,7 +532,7 @@
   private void verifyTermDocs(Directory dir, Term term, int numDocs)
       throws IOException {
     IndexReader reader = DirectoryReader.open(dir);
-    PostingsEnum postingsEnum = TestUtil.docs(random(), reader, term.field, term.bytes, null, null, PostingsEnum.NONE);
+    PostingsEnum postingsEnum = TestUtil.docs(random(), reader, term.field, term.bytes, null, PostingsEnum.NONE);
     int count = 0;
     while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)
       count++;
Index: lucene/core/src/test/org/apache/lucene/index/TestCodecs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestCodecs.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestCodecs.java	(working copy)
@@ -245,7 +245,7 @@
       // make sure it properly fully resets (rewinds) its
       // internal state:
       for(int iter=0;iter<2;iter++) {
-        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);
         assertEquals(terms[i].docs[0], postingsEnum.nextDoc());
         assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());
       }
@@ -382,9 +382,9 @@
         assertEquals(status, TermsEnum.SeekStatus.FOUND);
         assertEquals(term.docs.length, termsEnum.docFreq());
         if (field.omitTF) {
-          this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.NONE), false);
+          this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, PostingsEnum.NONE), false);
         } else {
-          this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, null, PostingsEnum.ALL), true);
+          this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, PostingsEnum.ALL), true);
         }
 
         // Test random seek by ord:
@@ -402,9 +402,9 @@
           assertTrue(termsEnum.term().bytesEquals(new BytesRef(term.text2)));
           assertEquals(term.docs.length, termsEnum.docFreq());
           if (field.omitTF) {
-            this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.NONE), false);
+            this.verifyDocs(term.docs, term.positions, TestUtil.docs(random(), termsEnum, null, PostingsEnum.NONE), false);
           } else {
-            this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, null, PostingsEnum.ALL), true);
+            this.verifyDocs(term.docs, term.positions, termsEnum.postings(null, PostingsEnum.ALL), true);
           }
         }
 
@@ -456,9 +456,9 @@
             if (!field.omitTF) {
               // TODO: we should randomize which postings features are available, but
               // need to coordinate this with the checks below that rely on such features
-              postings = termsEnum.postings(null, null, PostingsEnum.ALL);
+              postings = termsEnum.postings(null, PostingsEnum.ALL);
             } else {
-              postings = TestUtil.docs(random(), termsEnum, null, null, PostingsEnum.FREQS);
+              postings = TestUtil.docs(random(), termsEnum, null, PostingsEnum.FREQS);
             }
             assertNotNull(postings);
             int upto2 = -1;
@@ -677,8 +677,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      assert liveDocs == null;
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
       return new DataPostingsEnum(fieldData.terms[upto]);
     }
 
Index: lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java	(working copy)
@@ -96,13 +96,12 @@
     PostingsEnum td = TestUtil.docs(random(), mr2,
         "body",
         te2.term(),
-        MultiFields.getLiveDocs(mr2),
         null,
         0);
 
     TermsEnum te3 = MultiFields.getTerms(mr3, "body").iterator();
     te3.seekCeil(new BytesRef("wow"));
-    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),
+    td = TestUtil.docs(random(), te3,
         td,
         0);
     
@@ -351,7 +350,6 @@
   PostingsEnum tdocs = TestUtil.docs(random(), reader,
       term.field(),
       new BytesRef(term.text()),
-      MultiFields.getLiveDocs(reader),
       null,
       0);
   int count = 0;
@@ -617,7 +615,6 @@
     Fields fields1 = MultiFields.getFields(index1);
     Fields fields2 = MultiFields.getFields(index2);
     Iterator<String> fenum2 = fields2.iterator();
-    Bits liveDocs = MultiFields.getLiveDocs(index1);
     for (String field1 : fields1) {
       assertEquals("Different fields", field1, fenum2.next());
       Terms terms1 = fields1.terms(field1);
@@ -633,8 +630,8 @@
 
       while(enum1.next() != null) {
         assertEquals("Different terms", enum1.term(), enum2.next());
-        PostingsEnum tp1 = enum1.postings(liveDocs, null, PostingsEnum.ALL);
-        PostingsEnum tp2 = enum2.postings(liveDocs, null, PostingsEnum.ALL);
+        PostingsEnum tp1 = enum1.postings(null, PostingsEnum.ALL);
+        PostingsEnum tp2 = enum2.postings(null, PostingsEnum.ALL);
 
         while(tp1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           assertTrue(tp2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/core/src/test/org/apache/lucene/index/TestDoc.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDoc.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestDoc.java	(working copy)
@@ -44,6 +44,7 @@
 import org.apache.lucene.store.MergeInfo;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.TrackingDirectoryWrapper;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
@@ -262,9 +263,13 @@
         out.print("  term=" + field + ":" + tis.term());
         out.println("    DF=" + tis.docFreq());
 
-        PostingsEnum positions = tis.postings(reader.getLiveDocs(), null, PostingsEnum.POSITIONS);
+        PostingsEnum positions = tis.postings(null, PostingsEnum.POSITIONS);
 
+        final Bits liveDocs = reader.getLiveDocs();
         while (positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+          if (liveDocs != null && liveDocs.get(positions.docID()) == false) {
+            continue;
+          }
           out.print(" doc=" + positions.docID());
           out.print(" TF=" + positions.freq());
           out.print(" pos=");
Index: lucene/core/src/test/org/apache/lucene/index/TestDocCount.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocCount.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocCount.java	(working copy)
@@ -67,7 +67,7 @@
       FixedBitSet visited = new FixedBitSet(ir.maxDoc());
       TermsEnum te = terms.iterator();
       while (te.next() != null) {
-        PostingsEnum de = TestUtil.docs(random(), te, null, null, PostingsEnum.NONE);
+        PostingsEnum de = TestUtil.docs(random(), te, null, PostingsEnum.NONE);
         while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           visited.set(de.docID());
         }
Index: lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java	(working copy)
@@ -66,7 +66,7 @@
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
         if (leafReaderContext.reader().maxDoc() == 0) {
           continue;
@@ -91,12 +91,12 @@
   }
 
   public PostingsEnum getDocsAndPositions(LeafReader reader,
-      BytesRef bytes, Bits liveDocs) throws IOException {
+      BytesRef bytes) throws IOException {
     Terms terms = reader.terms(fieldName);
     if (terms != null) {
       TermsEnum te = terms.iterator();
       if (te.seekExact(bytes)) {
-        return te.postings(liveDocs, null, PostingsEnum.ALL);
+        return te.postings(null, PostingsEnum.ALL);
       }
     }
     return null;
@@ -149,7 +149,7 @@
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
         int initDoc = 0;
         int maxDoc = leafReaderContext.reader().maxDoc();
@@ -226,7 +226,7 @@
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext context : topReaderContext.leaves()) {
         int maxDoc = context.reader().maxDoc();
-        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, null, PostingsEnum.FREQS);
+        PostingsEnum postingsEnum = TestUtil.docs(random(), context.reader(), fieldName, bytes, null, PostingsEnum.FREQS);
         if (findNext(freqInDoc, context.docBase, context.docBase + maxDoc) == Integer.MAX_VALUE) {
           assertNull(postingsEnum);
           continue;
@@ -304,7 +304,7 @@
       IndexReaderContext topReaderContext = reader.getContext();
       for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {
         PostingsEnum docsAndPosEnum = getDocsAndPositions(
-            leafReaderContext.reader(), bytes, null);
+            leafReaderContext.reader(), bytes);
         assertNotNull(docsAndPosEnum);
 
         int initDoc = 0;
@@ -336,7 +336,7 @@
     writer.addDocument(doc);
     DirectoryReader reader = writer.getReader();
     LeafReader r = getOnlySegmentReader(reader);
-    PostingsEnum disi = TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, null, PostingsEnum.NONE);
+    PostingsEnum disi = TestUtil.docs(random(), r, "foo", new BytesRef("bar"), null, PostingsEnum.NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -344,7 +344,7 @@
     // now reuse and check again
     TermsEnum te = r.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = TestUtil.docs(random(), te, null, disi, PostingsEnum.NONE);
+    disi = TestUtil.docs(random(), te, disi, PostingsEnum.NONE);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -369,7 +369,7 @@
     // now reuse and check again
     TermsEnum te = r.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = te.postings(null, disi, PostingsEnum.ALL);
+    disi = te.postings(disi, PostingsEnum.ALL);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java	(working copy)
@@ -125,8 +125,7 @@
     writer.close();
     SegmentReader reader = new SegmentReader(info, newIOContext(random()));
 
-    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, MultiFields.getLiveDocs(reader),
-                                                                          "repeated", new BytesRef("repeated"));
+    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, "repeated", new BytesRef("repeated"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     int freq = termPositions.freq();
     assertEquals(2, freq);
@@ -197,7 +196,7 @@
     writer.close();
     SegmentReader reader = new SegmentReader(info, newIOContext(random()));
 
-    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, reader.getLiveDocs(), "f1", new BytesRef("a"));
+    PostingsEnum termPositions = MultiFields.getTermPositionsEnum(reader, "f1", new BytesRef("a"));
     assertTrue(termPositions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     int freq = termPositions.freq();
     assertEquals(3, freq);
Index: lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestFilterLeafReader.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -76,8 +75,8 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-        return new TestPositions(super.postings(liveDocs, reuse == null ? null : ((FilterPostingsEnum) reuse).in, flags));
+      public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+        return new TestPositions(super.postings(reuse == null ? null : ((FilterPostingsEnum) reuse).in, flags));
       }
     }
 
@@ -151,7 +150,7 @@
     
     assertEquals(TermsEnum.SeekStatus.FOUND, terms.seekCeil(new BytesRef("one")));
     
-    PostingsEnum positions = terms.postings(MultiFields.getLiveDocs(reader), null, PostingsEnum.ALL);
+    PostingsEnum positions = terms.postings(null, PostingsEnum.ALL);
     while (positions.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       assertTrue((positions.docID() % 2) == 1);
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -498,7 +498,6 @@
       PostingsEnum td = TestUtil.docs(random(), reader,
           "field",
           new BytesRef("a"),
-          MultiFields.getLiveDocs(reader),
           null,
           PostingsEnum.FREQS);
       td.nextDoc();
@@ -826,7 +825,7 @@
     Terms tpv = r.getTermVectors(0).terms("field");
     TermsEnum termsEnum = tpv.iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(dpEnum);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(1, dpEnum.freq());
@@ -833,7 +832,7 @@
     assertEquals(100, dpEnum.nextPosition());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertNotNull(dpEnum);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(1, dpEnum.freq());
@@ -1232,12 +1231,12 @@
 
 
     // test that the terms were indexed.
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
-    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc1field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc2field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "binary", new BytesRef("doc3field1"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc1field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc2field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+    assertTrue(TestUtil.docs(random(), ir, "string", new BytesRef("doc3field2"), null, PostingsEnum.NONE).nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
 
     ir.close();
     dir.close();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -531,13 +531,15 @@
     PostingsEnum tdocs = TestUtil.docs(random(), reader,
         t.field(),
         new BytesRef(t.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
 
+    final Bits liveDocs = MultiFields.getLiveDocs(reader);
     int count = 0;
     while(tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
-      count++;
+      if (liveDocs == null || liveDocs.get(tdocs.docID())) {
+        count++;
+      }
     }
     assertEquals(2, count);
 
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -38,6 +38,7 @@
 import org.apache.lucene.store.MockDirectoryWrapper.FakeIOException;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InfoStream;
 import org.apache.lucene.util.LuceneTestCase;
@@ -55,14 +56,16 @@
     int count = 0;
     PostingsEnum td = TestUtil.docs(random(), r,
         t.field(), new BytesRef(t.text()),
-        MultiFields.getLiveDocs(r),
         null,
         0);
 
     if (td != null) {
+      final Bits liveDocs = MultiFields.getLiveDocs(r);
       while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         td.docID();
-        count++;
+        if (liveDocs == null || liveDocs.get(td.docID())) {
+          count++;
+        }
       }
     }
     return count;
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java	(working copy)
@@ -247,7 +247,6 @@
       PostingsEnum tdocs = TestUtil.docs(random(), reader,
           "field",
           new BytesRef("aaa"),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
       int count = 0;
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java	(working copy)
@@ -332,7 +332,7 @@
             TermsEnum termsEnum = tfv.iterator();
             assertEquals(new BytesRef(""+counter), termsEnum.next());
             assertEquals(1, termsEnum.totalTermFreq());
-            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
             assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
             assertEquals(1, dpEnum.freq());
             assertEquals(1, dpEnum.nextPosition());
@@ -339,7 +339,7 @@
 
             assertEquals(new BytesRef("text"), termsEnum.next());
             assertEquals(1, termsEnum.totalTermFreq());
-            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
             assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
             assertEquals(1, dpEnum.freq());
             assertEquals(0, dpEnum.nextPosition());
Index: lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(working copy)
@@ -153,7 +153,6 @@
         IndexReader reader = DirectoryReader.open(directory);
 
         PostingsEnum tp = MultiFields.getTermPositionsEnum(reader,
-                                                                   MultiFields.getLiveDocs(reader),
                                                                    this.field,
                                                                    new BytesRef("b"));
 
@@ -164,7 +163,6 @@
         }
 
         tp = MultiFields.getTermPositionsEnum(reader,
-                                              MultiFields.getLiveDocs(reader),
                                               this.field,
                                               new BytesRef("a"));
 
Index: lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java	(working copy)
@@ -167,7 +167,7 @@
         System.out.println("\nTEST: iter=" + iter + " doS1=" + doS1);
       }
         
-      final PostingsEnum postings = MultiFields.getTermPositionsEnum(r, null, "field", new BytesRef(term));
+      final PostingsEnum postings = MultiFields.getTermPositionsEnum(r, "field", new BytesRef(term));
 
       int docID = -1;
       while(docID < DocIdSetIterator.NO_MORE_DOCS) {
@@ -374,10 +374,10 @@
       final PostingsEnum postings;
 
       if (options == IndexOptions.DOCS) {
-        docs = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, PostingsEnum.NONE);
+        docs = TestUtil.docs(random(), r, "field", new BytesRef(term), null, PostingsEnum.NONE);
         postings = null;
       } else {
-        docs = postings = TestUtil.docs(random(), r, "field", new BytesRef(term), null, null, PostingsEnum.FREQS);
+        docs = postings = TestUtil.docs(random(), r, "field", new BytesRef(term), null, PostingsEnum.FREQS);
         assert postings != null;
       }
       assert docs != null;
Index: lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestMaxPosition.java	(working copy)
@@ -81,7 +81,7 @@
     // Document should be visible:
     IndexReader r = DirectoryReader.open(iw, true);
     assertEquals(1, r.numDocs());
-    PostingsEnum postings = MultiFields.getTermPositionsEnum(r, null, "foo", new BytesRef("foo"));
+    PostingsEnum postings = MultiFields.getTermPositionsEnum(r, "foo", new BytesRef("foo"));
 
     // "foo" appears in docID=0
     assertEquals(0, postings.nextDoc());
Index: lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(working copy)
@@ -135,13 +135,11 @@
           System.out.println("TEST: seek term="+ UnicodeUtil.toHexString(term.utf8ToString()) + " " + term);
         }
         
-        PostingsEnum postingsEnum = TestUtil.docs(random(), reader, "field", term, liveDocs, null, PostingsEnum.NONE);
+        PostingsEnum postingsEnum = TestUtil.docs(random(), reader, "field", term, null, PostingsEnum.NONE);
         assertNotNull(postingsEnum);
 
         for(int docID : docs.get(term)) {
-          if (!deleted.contains(docID)) {
-            assertEquals(docID, postingsEnum.nextDoc());
-          }
+          assertEquals(docID, postingsEnum.nextDoc());
         }
         assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());
       }
@@ -176,8 +174,8 @@
     w.addDocument(d);
     IndexReader r = w.getReader();
     w.close();
-    PostingsEnum d1 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, PostingsEnum.NONE);
-    PostingsEnum d2 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, null, PostingsEnum.NONE);
+    PostingsEnum d1 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, PostingsEnum.NONE);
+    PostingsEnum d2 = TestUtil.docs(random(), r, "f", new BytesRef("j"), null, PostingsEnum.NONE);
     assertEquals(0, d1.nextDoc());
     assertEquals(0, d2.nextDoc());
     r.close();
@@ -194,7 +192,7 @@
     w.addDocument(d);
     IndexReader r = w.getReader();
     w.close();
-    PostingsEnum de = MultiFields.getTermDocsEnum(r, null, "f", new BytesRef("j"));
+    PostingsEnum de = MultiFields.getTermDocsEnum(r, "f", new BytesRef("j"));
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, de.nextDoc());
Index: lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java	(working copy)
@@ -51,9 +51,9 @@
     IndexReader reader = w.getReader();
     w.close();
     
-    assertNotNull(MultiFields.getTermPositionsEnum(reader, null, "foo", new BytesRef("test")));
+    assertNotNull(MultiFields.getTermPositionsEnum(reader, "foo", new BytesRef("test")));
     
-    PostingsEnum de = TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, null, PostingsEnum.FREQS);
+    PostingsEnum de = TestUtil.docs(random(), reader, "foo", new BytesRef("test"), null, PostingsEnum.FREQS);
     while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       assertEquals(2, de.freq());
     }
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(working copy)
@@ -72,7 +72,7 @@
     super.tearDown();
   }
   
-  private void checkTerms(Terms terms, Bits liveDocs, String... termsList) throws IOException {
+  private void checkTerms(Terms terms, String... termsList) throws IOException {
     assertNotNull(terms);
     final TermsEnum te = terms.iterator();
     
@@ -80,7 +80,7 @@
       BytesRef b = te.next();
       assertNotNull(b);
       assertEquals(t, b.utf8ToString());
-      PostingsEnum td = TestUtil.docs(random(), te, liveDocs, null, PostingsEnum.NONE);
+      PostingsEnum td = TestUtil.docs(random(), te, null, PostingsEnum.NONE);
       assertTrue(td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(0, td.docID());
       assertEquals(td.nextDoc(), DocIdSetIterator.NO_MORE_DOCS);
@@ -91,22 +91,20 @@
   public void test1() throws IOException {
     ParallelLeafReader pr = new ParallelLeafReader(ir1, ir2);
 
-    Bits liveDocs = pr.getLiveDocs();
-
     Fields fields = pr.fields();
     Iterator<String> fe = fields.iterator();
 
     String f = fe.next();
     assertEquals("field1", f);
-    checkTerms(fields.terms(f), liveDocs, "brown", "fox", "jumps", "quick", "the");
+    checkTerms(fields.terms(f), "brown", "fox", "jumps", "quick", "the");
 
     f = fe.next();
     assertEquals("field2", f);
-    checkTerms(fields.terms(f), liveDocs, "brown", "fox", "jumps", "quick", "the");
+    checkTerms(fields.terms(f), "brown", "fox", "jumps", "quick", "the");
 
     f = fe.next();
     assertEquals("field3", f);
-    checkTerms(fields.terms(f), liveDocs, "dog", "fox", "jumps", "lazy", "over", "the");
+    checkTerms(fields.terms(f), "dog", "fox", "jumps", "lazy", "over", "the");
 
     assertFalse(fe.hasNext());
   }
Index: lucene/core/src/test/org/apache/lucene/index/TestPayloads.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestPayloads.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestPayloads.java	(working copy)
@@ -193,7 +193,6 @@
     PostingsEnum[] tps = new PostingsEnum[numTerms];
     for (int i = 0; i < numTerms; i++) {
       tps[i] = MultiFields.getTermPositionsEnum(reader,
-                                                MultiFields.getLiveDocs(reader),
                                                 terms[i].field(),
                                                 new BytesRef(terms[i].text()));
     }
@@ -222,7 +221,6 @@
      *  test lazy skipping
      */        
     PostingsEnum tp = MultiFields.getTermPositionsEnum(reader,
-                                                               MultiFields.getLiveDocs(reader),
                                                                terms[0].field(),
                                                                new BytesRef(terms[0].text()));
     tp.nextDoc();
@@ -249,7 +247,6 @@
      * Test different lengths at skip points
      */
     tp = MultiFields.getTermPositionsEnum(reader,
-                                          MultiFields.getLiveDocs(reader),
                                           terms[1].field(),
                                           new BytesRef(terms[1].text()));
     tp.nextDoc();
@@ -287,7 +284,6 @@
         
     reader = DirectoryReader.open(dir);
     tp = MultiFields.getTermPositionsEnum(reader,
-                                          MultiFields.getLiveDocs(reader),
                                           fieldName,
                                           new BytesRef(singleTerm));
     tp.nextDoc();
@@ -485,11 +481,10 @@
     writer.close();
     IndexReader reader = DirectoryReader.open(dir);
     TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();
-    Bits liveDocs = MultiFields.getLiveDocs(reader);
     PostingsEnum tp = null;
     while (terms.next() != null) {
       String termText = terms.term().utf8ToString();
-      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);
+      tp = terms.postings(tp, PostingsEnum.PAYLOADS);
       while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         int freq = tp.freq();
         for (int i = 0; i < freq; i++) {
Index: lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.java	(working copy)
@@ -72,7 +72,7 @@
     assert terms != null;
     TermsEnum termsEnum = terms.iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("withPayload")));
-    PostingsEnum de = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum de = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(0, de.nextDoc());
     assertEquals(0, de.nextPosition());
     assertEquals(new BytesRef("test"), de.getPayload());
@@ -114,7 +114,7 @@
     assert terms != null;
     TermsEnum termsEnum = terms.iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("withPayload")));
-    PostingsEnum de = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum de = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(0, de.nextDoc());
     assertEquals(3, de.nextPosition());
     assertEquals(new BytesRef("test"), de.getPayload());
Index: lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java	(working copy)
@@ -226,7 +226,7 @@
     Terms cterms = fields.terms(term.field);
     TermsEnum ctermsEnum = cterms.iterator();
     if (ctermsEnum.seekExact(new BytesRef(term.text()))) {
-      PostingsEnum postingsEnum = TestUtil.docs(random(), ctermsEnum, bits, null, PostingsEnum.NONE);
+      PostingsEnum postingsEnum = TestUtil.docs(random(), ctermsEnum, null, PostingsEnum.NONE);
       return toArray(postingsEnum);
     }
     return null;
Index: lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java	(working copy)
@@ -82,7 +82,7 @@
     IndexReader r = w.getReader();
     w.close();
 
-    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("a"));
+    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("a"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(2, dp.freq());
@@ -94,7 +94,7 @@
     assertEquals(17, dp.endOffset());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
 
-    dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("b"));
+    dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("b"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(1, dp.freq());
@@ -103,7 +103,7 @@
     assertEquals(9, dp.endOffset());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
 
-    dp = MultiFields.getTermPositionsEnum(r, null, "content", new BytesRef("c"));
+    dp = MultiFields.getTermPositionsEnum(r, "content", new BytesRef("c"));
     assertNotNull(dp);
     assertEquals(0, dp.nextDoc());
     assertEquals(1, dp.freq());
@@ -154,7 +154,7 @@
     String terms[] = { "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "hundred" };
     
     for (String term : terms) {
-      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, null, "numbers", new BytesRef(term));
+      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, "numbers", new BytesRef(term));
       int doc;
       while((doc = dp.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
         String storedNumbers = reader.document(doc).get("numbers");
@@ -182,7 +182,7 @@
     
     for (int j = 0; j < numSkippingTests; j++) {
       int num = TestUtil.nextInt(random(), 100, Math.min(numDocs - 1, 999));
-      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, null, "numbers", new BytesRef("hundred"));
+      PostingsEnum dp = MultiFields.getTermPositionsEnum(reader, "numbers", new BytesRef("hundred"));
       int doc = dp.advance(num);
       assertEquals(num, doc);
       int freq = dp.freq();
@@ -207,7 +207,7 @@
     // check that other fields (without offsets) work correctly
     
     for (int i = 0; i < numDocs; i++) {
-      PostingsEnum dp = MultiFields.getTermDocsEnum(reader, null, "id", new BytesRef("" + i), 0);
+      PostingsEnum dp = MultiFields.getTermDocsEnum(reader, "id", new BytesRef("" + i), 0);
       assertEquals(i, dp.nextDoc());
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());
     }
@@ -301,7 +301,7 @@
       for(String term : terms) {
         //System.out.println("  term=" + term);
         if (termsEnum.seekExact(new BytesRef(term))) {
-          docs = termsEnum.postings(null, docs);
+          docs = termsEnum.postings(docs);
           assertNotNull(docs);
           int doc;
           //System.out.println("    doc/freq");
@@ -313,7 +313,7 @@
           }
 
           // explicitly exclude offsets here
-          docsAndPositions = termsEnum.postings(null, docsAndPositions, PostingsEnum.ALL);
+          docsAndPositions = termsEnum.postings(docsAndPositions, PostingsEnum.ALL);
           assertNotNull(docsAndPositions);
           //System.out.println("    doc/freq/pos");
           while((doc = docsAndPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
@@ -328,7 +328,7 @@
             }
           }
 
-          docsAndPositionsAndOffsets = termsEnum.postings(null, docsAndPositions, PostingsEnum.ALL);
+          docsAndPositionsAndOffsets = termsEnum.postings(docsAndPositions, PostingsEnum.ALL);
           assertNotNull(docsAndPositionsAndOffsets);
           //System.out.println("    doc/freq/pos/offs");
           while((doc = docsAndPositionsAndOffsets.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
Index: lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java	(working copy)
@@ -110,7 +110,6 @@
     PostingsEnum termDocs = TestUtil.docs(random(), mergedReader,
         DocHelper.TEXT_FIELD_2_KEY,
         new BytesRef("field"),
-        MultiFields.getLiveDocs(mergedReader),
         null,
         0);
     assertTrue(termDocs != null);
Index: lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java	(working copy)
@@ -130,7 +130,6 @@
     PostingsEnum termDocs = TestUtil.docs(random(), reader,
         DocHelper.TEXT_FIELD_1_KEY,
         new BytesRef("field"),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -138,7 +137,6 @@
     termDocs = TestUtil.docs(random(), reader,
         DocHelper.NO_NORMS_KEY,
         new BytesRef(DocHelper.NO_NORMS_TEXT),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
 
@@ -146,7 +144,6 @@
 
     
     PostingsEnum positions = MultiFields.getTermPositionsEnum(reader,
-                                                                      MultiFields.getLiveDocs(reader),
                                                                       DocHelper.TEXT_FIELD_1_KEY,
                                                                       new BytesRef("field"));
     // NOTE: prior rev of this test was failing to first
Index: lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java	(working copy)
@@ -58,7 +58,7 @@
 
     TermsEnum terms = reader.fields().terms(DocHelper.TEXT_FIELD_2_KEY).iterator();
     terms.seekCeil(new BytesRef("field"));
-    PostingsEnum termDocs = TestUtil.docs(random(), terms, reader.getLiveDocs(), null, PostingsEnum.FREQS);
+    PostingsEnum termDocs = TestUtil.docs(random(), terms, null, PostingsEnum.FREQS);
     if (termDocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)    {
       int docId = termDocs.docID();
       assertTrue(docId == 0);
@@ -76,7 +76,6 @@
       PostingsEnum termDocs = TestUtil.docs(random(), reader,
           "textField2",
           new BytesRef("bad"),
-          reader.getLiveDocs(),
           null,
           0);
 
@@ -90,7 +89,6 @@
       PostingsEnum termDocs = TestUtil.docs(random(), reader,
           "junk",
           new BytesRef("bad"),
-          reader.getLiveDocs(),
           null,
           0);
       assertNull(termDocs);
@@ -124,7 +122,6 @@
     PostingsEnum tdocs = TestUtil.docs(random(), reader,
         ta.field(),
         new BytesRef(ta.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
     
@@ -149,7 +146,6 @@
     tdocs = TestUtil.docs(random(), reader,
         ta.field(),
         new BytesRef(ta.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     
@@ -167,7 +163,6 @@
     tdocs = TestUtil.docs(random(), reader,
         tb.field(),
         new BytesRef(tb.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
 
@@ -191,7 +186,6 @@
     tdocs = TestUtil.docs(random(), reader,
         tb.field(),
         new BytesRef(tb.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
     
@@ -211,7 +205,6 @@
     tdocs = TestUtil.docs(random(), reader,
         tc.field(),
         new BytesRef(tc.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         PostingsEnum.FREQS);
 
@@ -237,7 +230,6 @@
     tdocs = TestUtil.docs(random(), reader,
         tc.field(),
         new BytesRef(tc.text()),
-        MultiFields.getLiveDocs(reader),
         null,
         0);
     assertTrue(tdocs.advance(5) != DocIdSetIterator.NO_MORE_DOCS);
Index: lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java	(working copy)
@@ -82,11 +82,11 @@
           System.out.println("\nTEST: iter=" + iter + " iter2=" + iter2);
         }
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("a")));
-        de = TestUtil.docs(random(), te, null, de, PostingsEnum.NONE);
+        de = TestUtil.docs(random(), te, de, PostingsEnum.NONE);
         testOne(de, aDocIDs);
 
         assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef("b")));
-        de = TestUtil.docs(random(), te, null, de, PostingsEnum.NONE);
+        de = TestUtil.docs(random(), te, de, PostingsEnum.NONE);
         testOne(de, bDocIDs);
       }
 
Index: lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -32,9 +32,13 @@
 import org.apache.lucene.document.TextField;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.*;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
 
 public class TestStressIndexing2 extends LuceneTestCase {
   static int maxFields=4;
@@ -285,6 +289,13 @@
     }
   }
 
+  private static int nextNonDeletedDoc(PostingsEnum it, Bits liveDocs) throws IOException {
+    int doc = it.nextDoc();
+    while (doc != DocIdSetIterator.NO_MORE_DOCS && liveDocs != null && liveDocs.get(doc) == false) {
+      doc = it.nextDoc();
+    }
+    return doc;
+  }
 
   public void verifyEquals(DirectoryReader r1, DirectoryReader r2, String idField) throws Throwable {
     if (VERBOSE) {
@@ -326,8 +337,8 @@
       Bits liveDocs = MultiFields.getLiveDocs(r1);
       PostingsEnum docs = null;
       while(termsEnum.next() != null) {
-        docs = TestUtil.docs(random(), termsEnum, liveDocs, docs, PostingsEnum.NONE);
-        while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+        docs = TestUtil.docs(random(), termsEnum, docs, PostingsEnum.NONE);
+        while(nextNonDeletedDoc(docs, liveDocs) != DocIdSetIterator.NO_MORE_DOCS) {
           fail("r1 is not empty but r2 is");
         }
       }
@@ -345,25 +356,25 @@
         break;
       }
 
-      termDocs1 = TestUtil.docs(random(), termsEnum, liveDocs1, termDocs1, PostingsEnum.NONE);
+      termDocs1 = TestUtil.docs(random(), termsEnum, termDocs1, PostingsEnum.NONE);
       if (termsEnum2.seekExact(term)) {
-        termDocs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, termDocs2, PostingsEnum.NONE);
+        termDocs2 = TestUtil.docs(random(), termsEnum2, termDocs2, PostingsEnum.NONE);
       } else {
         termDocs2 = null;
       }
 
-      if (termDocs1.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {
+      if (nextNonDeletedDoc(termDocs1, liveDocs1) == DocIdSetIterator.NO_MORE_DOCS) {
         // This doc is deleted and wasn't replaced
-        assertTrue(termDocs2 == null || termDocs2.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);
+        assertTrue(termDocs2 == null || nextNonDeletedDoc(termDocs2, liveDocs2) == DocIdSetIterator.NO_MORE_DOCS);
         continue;
       }
 
       int id1 = termDocs1.docID();
-      assertEquals(DocIdSetIterator.NO_MORE_DOCS, termDocs1.nextDoc());
+      assertEquals(DocIdSetIterator.NO_MORE_DOCS, nextNonDeletedDoc(termDocs1, liveDocs1));
 
-      assertTrue(termDocs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+      assertTrue(nextNonDeletedDoc(termDocs2, liveDocs2) != DocIdSetIterator.NO_MORE_DOCS);
       int id2 = termDocs2.docID();
-      assertEquals(DocIdSetIterator.NO_MORE_DOCS, termDocs2.nextDoc());
+      assertEquals(DocIdSetIterator.NO_MORE_DOCS, nextNonDeletedDoc(termDocs2, liveDocs2));
 
       r2r1[id2] = id1;
 
@@ -395,7 +406,7 @@
             BytesRef term2;
             while((term2 = termsEnum3.next()) != null) {
               System.out.println("      " + term2.utf8ToString() + ": freq=" + termsEnum3.totalTermFreq());
-              dpEnum = termsEnum3.postings(null, dpEnum, PostingsEnum.ALL);
+              dpEnum = termsEnum3.postings(dpEnum, PostingsEnum.ALL);
               if (terms3.hasPositions()) {
                 assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dpEnum.freq();
@@ -404,7 +415,7 @@
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, PostingsEnum.FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, dEnum, PostingsEnum.FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -427,7 +438,7 @@
             BytesRef term2;
             while((term2 = termsEnum3.next()) != null) {
               System.out.println("      " + term2.utf8ToString() + ": freq=" + termsEnum3.totalTermFreq());
-              dpEnum = termsEnum3.postings(null, dpEnum, PostingsEnum.ALL);
+              dpEnum = termsEnum3.postings(dpEnum, PostingsEnum.ALL);
               if (dpEnum != null) {
                 assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dpEnum.freq();
@@ -436,7 +447,7 @@
                   System.out.println("          pos=" + dpEnum.nextPosition());
                 }
               } else {
-                dEnum = TestUtil.docs(random(), termsEnum3, null, dEnum, PostingsEnum.FREQS);
+                dEnum = TestUtil.docs(random(), termsEnum3, dEnum, PostingsEnum.FREQS);
                 assertNotNull(dEnum);
                 assertTrue(dEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
                 final int freq = dEnum.freq();
@@ -495,9 +506,12 @@
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs1 = TestUtil.docs(random(), termsEnum1, liveDocs1, docs1, PostingsEnum.FREQS);
+        docs1 = TestUtil.docs(random(), termsEnum1, docs1, PostingsEnum.FREQS);
         while (docs1.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
           int d = docs1.docID();
+          if (liveDocs1 != null && liveDocs1.get(d) == false) {
+            continue;
+          }
           int f = docs1.freq();
           info1[len1] = (((long)d)<<32) | f;
           len1++;
@@ -528,8 +542,11 @@
         }
         
         //System.out.println("TEST: term1=" + term1);
-        docs2 = TestUtil.docs(random(), termsEnum2, liveDocs2, docs2, PostingsEnum.FREQS);
+        docs2 = TestUtil.docs(random(), termsEnum2, docs2, PostingsEnum.FREQS);
         while (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+          if (liveDocs2 != null && liveDocs2.get(docs2.docID()) == false) {
+            continue;
+          }
           int d = r2r1[docs2.docID()];
           int f = docs2.freq();
           info2[len2] = (((long)d)<<32) | f;
@@ -542,7 +559,7 @@
       if (len1==0) break;  // no more terms
 
       assertEquals(field1, field2);
-      assertTrue(term1.bytesEquals(term2));
+      assertEquals(term1, term2);
 
       if (!hasDeletes)
         assertEquals(termsEnum1.docFreq(), termsEnum2.docFreq());
@@ -617,8 +634,8 @@
         assertEquals(termsEnum1.totalTermFreq(),
                      termsEnum2.totalTermFreq());
         
-        dpEnum1 = termsEnum1.postings(null, dpEnum1, PostingsEnum.ALL);
-        dpEnum2 = termsEnum2.postings(null, dpEnum2, PostingsEnum.ALL);
+        dpEnum1 = termsEnum1.postings(dpEnum1, PostingsEnum.ALL);
+        dpEnum2 = termsEnum2.postings(dpEnum2, PostingsEnum.ALL);
 
         if (terms1.hasPositions()) {
           assertTrue(terms2.hasPositions());
@@ -648,8 +665,8 @@
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum1.nextDoc());
           assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum2.nextDoc());
         } else {
-          dEnum1 = TestUtil.docs(random(), termsEnum1, null, dEnum1, PostingsEnum.FREQS);
-          dEnum2 = TestUtil.docs(random(), termsEnum2, null, dEnum2, PostingsEnum.FREQS);
+          dEnum1 = TestUtil.docs(random(), termsEnum1, dEnum1, PostingsEnum.FREQS);
+          dEnum2 = TestUtil.docs(random(), termsEnum2, dEnum2, PostingsEnum.FREQS);
           assertNotNull(dEnum1);
           assertNotNull(dEnum2);
           int docID1 = dEnum1.nextDoc();
Index: lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(working copy)
@@ -228,7 +228,7 @@
         //System.out.println("Term: " + term);
         assertEquals(testTerms[i], term);
         
-        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);
         assertNotNull(postingsEnum);
         int doc = postingsEnum.docID();
         assertEquals(-1, doc);
@@ -255,7 +255,7 @@
       //System.out.println("Term: " + term);
       assertEquals(testTerms[i], term);
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertNotNull(dpEnum);
       int doc = dpEnum.docID();
       assertEquals(-1, doc);
@@ -266,7 +266,7 @@
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       doc = dpEnum.docID();
       assertEquals(-1, doc);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -291,8 +291,8 @@
       String term = text.utf8ToString();
       //System.out.println("Term: " + term);
       assertEquals(testTerms[i], term);
-      assertNotNull(termsEnum.postings(null, null));
-      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));
+      assertNotNull(termsEnum.postings(null));
+      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));
     }
     reader.close();
   }
@@ -311,7 +311,7 @@
       String term = text.utf8ToString();
       assertEquals(testTerms[i], term);
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertNotNull(dpEnum);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertEquals(dpEnum.freq(), positions[i].length);
@@ -320,7 +320,7 @@
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());
 
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
       assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
       assertNotNull(dpEnum);
       assertEquals(dpEnum.freq(), positions[i].length);
Index: lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java	(working copy)
@@ -68,7 +68,7 @@
     // Token "" occurred once
     assertEquals(1, termsEnum.totalTermFreq());
 
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(8, dpEnum.startOffset());
@@ -77,7 +77,7 @@
 
     // Token "abcd" occurred three times
     assertEquals(new BytesRef("abcd"), termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertEquals(3, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -117,7 +117,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -152,7 +152,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -190,7 +190,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -225,7 +225,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertEquals(2, termsEnum.totalTermFreq());
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -261,7 +261,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
@@ -269,7 +269,7 @@
     assertEquals(4, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(11, dpEnum.startOffset());
@@ -276,7 +276,7 @@
     assertEquals(17, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(18, dpEnum.startOffset());
@@ -305,7 +305,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertEquals(1, (int) termsEnum.totalTermFreq());
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -314,7 +314,7 @@
     assertEquals(7, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(8, dpEnum.startOffset());
@@ -347,7 +347,7 @@
     IndexReader r = DirectoryReader.open(dir);
     TermsEnum termsEnum = r.getTermVectors(0).terms("field").iterator();
     assertNotNull(termsEnum.next());
-    PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
 
     assertEquals(1, (int) termsEnum.totalTermFreq());
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -356,7 +356,7 @@
     assertEquals(4, dpEnum.endOffset());
 
     assertNotNull(termsEnum.next());
-    dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);
+    dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
     assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     dpEnum.nextPosition();
     assertEquals(6, dpEnum.startOffset());
Index: lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java	(working copy)
@@ -123,7 +123,7 @@
     final Random random = new Random(random().nextLong());
     for (int i=0; i<iter; i++) {
       tenum.seekCeil(new BytesRef("val"));
-      tdocs = TestUtil.docs(random, tenum, MultiFields.getLiveDocs(reader), tdocs, PostingsEnum.NONE);
+      tdocs = TestUtil.docs(random, tenum, tdocs, PostingsEnum.NONE);
       while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
         ret += tdocs.docID();
       }
Index: lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java	(working copy)
@@ -326,7 +326,7 @@
           }
           assertEquals(expected, actual);
           assertEquals(1, te.docFreq());
-          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);
           final int docID = postingsEnum.nextDoc();
           assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);
           assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());
@@ -740,25 +740,25 @@
     CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    
     TermsEnum te = terms.intersect(ca, null);
     assertEquals("aaa", te.next().utf8ToString());
-    assertEquals(0, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     te = terms.intersect(ca, new BytesRef("abc"));
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     te = terms.intersect(ca, new BytesRef("aaa"));
     assertEquals("bbb", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("ccc", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     r.close();
@@ -798,17 +798,17 @@
     // should seek to startTerm
     te = terms.intersect(ca, new BytesRef("aad"));
     assertEquals("abd", te.next().utf8ToString());
-    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("acd", te.next().utf8ToString());
-    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertEquals("bcd", te.next().utf8ToString());
-    assertEquals(3, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(3, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     // should fail to find ceil label on second arc, rewind 
     te = terms.intersect(ca, new BytesRef("add"));
     assertEquals("bcd", te.next().utf8ToString());
-    assertEquals(3, te.postings(null, null, PostingsEnum.NONE).nextDoc());
+    assertEquals(3, te.postings(null, PostingsEnum.NONE).nextDoc());
     assertNull(te.next());
 
     // should reach end
@@ -852,12 +852,12 @@
     PostingsEnum de;
 
     assertEquals("", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
     assertEquals("abc", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
@@ -867,7 +867,7 @@
     te = terms.intersect(ca, new BytesRef(""));
 
     assertEquals("abc", te.next().utf8ToString());
-    de = te.postings(null, null, PostingsEnum.NONE);
+    de = te.postings(null, PostingsEnum.NONE);
     assertEquals(0, de.nextDoc());
     assertEquals(1, de.nextDoc());
 
@@ -929,7 +929,7 @@
       boolean actualResult = termsEnum.seekExact(termBytesRef);
       assertEquals(shouldExist, actualResult);
       if (shouldExist) {
-        postingsEnum = termsEnum.postings(null, postingsEnum, 0);
+        postingsEnum = termsEnum.postings(postingsEnum, 0);
         int docID = postingsEnum.nextDoc();
         assertTrue(docID != PostingsEnum.NO_MORE_DOCS);
         assertEquals(docID, pkLookup.lookup(termBytesRef));
Index: lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java	(working copy)
@@ -298,7 +298,7 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) {
+    public Scorer scorer(LeafReaderContext context) {
       throw new UnsupportedOperationException(UNSUPPORTED_MSG);
     }
 
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanCoord.java	(working copy)
@@ -741,7 +741,7 @@
   private void assertScore(final float expected, Query query) throws Exception {
     // test in-order
     Weight weight = searcher.createNormalizedWeight(query, true);
-    Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer.docID() == -1 || scorer.docID() == DocIdSetIterator.NO_MORE_DOCS);
     assertEquals(0, scorer.nextDoc());
     assertEquals(expected, scorer.score(), 0.0001f);
@@ -748,7 +748,7 @@
 
     // test bulk scorer
     final AtomicBoolean seen = new AtomicBoolean(false);
-    BulkScorer bulkScorer = weight.bulkScorer(reader.leaves().get(0), null);
+    BulkScorer bulkScorer = weight.bulkScorer(reader.leaves().get(0));
     assertNotNull(bulkScorer);
     bulkScorer.score(new LeafCollector() {
       Scorer scorer;
@@ -765,7 +765,7 @@
         assertEquals(expected, scorer.score(), 0.0001f);
         seen.set(true);
       }
-    }, 0, 1);
+    }, null, 0, 1);
     assertTrue(seen.get());
 
     // test the explanation
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanOr.java	(working copy)
@@ -22,8 +22,6 @@
 import java.util.List;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.TextField;
@@ -31,10 +29,13 @@
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
+import com.carrotsearch.randomizedtesting.generators.RandomInts;
+
 public class TestBooleanOr extends LuceneTestCase {
 
   private static String FIELD_T = "T";
@@ -188,7 +189,7 @@
     Weight w = s.createNormalizedWeight(bq.build(), true);
 
     assertEquals(1, s.getIndexReader().leaves().size());
-    BulkScorer scorer = w.bulkScorer(s.getIndexReader().leaves().get(0), null);
+    BulkScorer scorer = w.bulkScorer(s.getIndexReader().leaves().get(0));
 
     final FixedBitSet hits = new FixedBitSet(docCount);
     final AtomicInteger end = new AtomicInteger();
@@ -210,7 +211,7 @@
       final int min = end.intValue();
       final int inc = TestUtil.nextInt(random(), 1, 1000);
       final int max = end.addAndGet(inc);
-      scorer.score(c, min, max);
+      scorer.score(c, null, min, max);
     }
 
     assertEquals(docCount, hits.cardinality());
@@ -223,7 +224,7 @@
       final FakeScorer scorer = new FakeScorer();
       int i = 0;
       @Override
-      public int score(LeafCollector collector, int min, int max) throws IOException {
+      public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
         collector.setScorer(scorer);
         while (i < matches.length && matches[i] < min) {
           i += 1;
@@ -230,7 +231,9 @@
         }
         while (i < matches.length && matches[i] < max) {
           scorer.doc = matches[i];
-          collector.collect(scorer.doc);
+          if (acceptDocs == null || acceptDocs.get(scorer.doc)) {
+            collector.collect(scorer.doc);
+          }
           i += 1;
         }
         if (i == matches.length) {
@@ -266,7 +269,7 @@
         matches.add(doc);
       }
       
-    });
+    }, null);
     assertEquals(Arrays.asList(4000, 5000, 100000, 1000001, 1000051, 9999998, 9999999), matches);
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanQuery.java	(working copy)
@@ -242,7 +242,7 @@
 
       Weight weight = s.createNormalizedWeight(q.build(), true);
 
-      Scorer scorer = weight.scorer(s.leafContexts.get(0), null);
+      Scorer scorer = weight.scorer(s.leafContexts.get(0));
 
       // First pass: just use .nextDoc() to gather all hits
       final List<ScoreDoc> hits = new ArrayList<>();
@@ -259,7 +259,7 @@
       for(int iter2=0;iter2<10;iter2++) {
 
         weight = s.createNormalizedWeight(q.build(), true);
-        scorer = weight.scorer(s.leafContexts.get(0), null);
+        scorer = weight.scorer(s.leafContexts.get(0));
 
         if (VERBOSE) {
           System.out.println("  iter2=" + iter2);
@@ -595,7 +595,7 @@
     query2.add(new TermQuery(new Term("field", "a")), Occur.FILTER);
     query2.add(new TermQuery(new Term("field", "b")), Occur.SHOULD);
     final Weight weight = searcher.createNormalizedWeight(query2.build(), true);
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertEquals(0, scorer.nextDoc());
     assertTrue(scorer.getClass().getName(), scorer instanceof FilterScorer);
     assertEquals(0f, scorer.score(), 0f);
@@ -627,7 +627,7 @@
     q.add(new TermQuery(new Term("field", "c")), Occur.FILTER);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertTrue(scorer instanceof ConjunctionScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -656,7 +656,7 @@
     q.add(new TermQuery(new Term("field", "c")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof DisjunctionScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -687,7 +687,7 @@
     q.add(new TermQuery(new Term("field", "d")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertTrue(scorer instanceof BoostedScorer || scorer instanceof ExactPhraseScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -716,7 +716,7 @@
     q.add(new TermQuery(new Term("field", "c")), Occur.MUST_NOT);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof ReqExclScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
@@ -745,7 +745,7 @@
     q.add(new TermQuery(new Term("field", "c")), Occur.SHOULD);
 
     final Weight weight = searcher.createNormalizedWeight(q.build(), true);
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertTrue(scorer instanceof ReqOptSumScorer);
     assertNotNull(scorer.asTwoPhaseIterator());
 
Index: lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestBooleanScorer.java	(working copy)
@@ -93,15 +93,15 @@
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) {
+        public Scorer scorer(LeafReaderContext context) {
           throw new UnsupportedOperationException();
         }
 
         @Override
-        public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) {
+        public BulkScorer bulkScorer(LeafReaderContext context) {
           return new BulkScorer() {
             @Override
-            public int score(LeafCollector collector, int min, int max) throws IOException {
+            public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
               assert min == 0;
               collector.setScorer(new FakeScorer());
               collector.collect(0);
Index: lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java	(working copy)
@@ -139,15 +139,15 @@
     CachingWrapperQuery cacher = new CachingWrapperQuery(filter, QueryCachingPolicy.ALWAYS_CACHE);
 
     // first time, nested filter is called
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
     assertTrue("first time", filter.wasCalled());
 
     // make sure no exception if cache is holding the wrong docIdSet
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
 
     // second time, nested filter should not be called
     filter.clear();
-    cacher.createWeight(searcher, false).scorer(context, context.reader().getLiveDocs());
+    cacher.createWeight(searcher, false).scorer(context);
     assertFalse("second time", filter.wasCalled());
 
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java	(working copy)
@@ -245,7 +245,7 @@
     ConstantScoreQuery q = new ConstantScoreQuery(pq);
 
     final Weight weight = searcher.createNormalizedWeight(q, true);
-    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0), null);
+    final Scorer scorer = weight.scorer(searcher.getIndexReader().leaves().get(0));
     assertNotNull(scorer.asTwoPhaseIterator());
 
     reader.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(working copy)
@@ -180,7 +180,7 @@
     assertTrue(s.getTopReaderContext() instanceof LeafReaderContext);
     final Weight dw = s.createNormalizedWeight(dq, true);
     LeafReaderContext context = (LeafReaderContext)s.getTopReaderContext();
-    final Scorer ds = dw.scorer(context, context.reader().getLiveDocs());
+    final Scorer ds = dw.scorer(context);
     final boolean skipOk = ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS;
     if (skipOk) {
       fail("firsttime skipTo found a match? ... "
@@ -196,7 +196,7 @@
     QueryUtils.check(random(), dq, s);
     final Weight dw = s.createNormalizedWeight(dq, true);
     LeafReaderContext context = (LeafReaderContext)s.getTopReaderContext();
-    final Scorer ds = dw.scorer(context, context.reader().getLiveDocs());
+    final Scorer ds = dw.scorer(context);
     assertTrue("firsttime skipTo found no match",
         ds.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
     assertEquals("found wrong docid", "d4", r.document(ds.docID()).get("id"));
Index: lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache.java	(working copy)
@@ -349,7 +349,7 @@
     public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
       return new ConstantScoreWeight(this) {
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           return null;
         }
       };
@@ -934,7 +934,7 @@
     public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
       return new ConstantScoreWeight(this) {
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           return null;
         }
       };
Index: lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestMinShouldMatch2.java	(working copy)
@@ -130,11 +130,11 @@
     case DOC_VALUES:
       return new SlowMinShouldMatchScorer(weight, reader, searcher);
     case SCORER:
-      return weight.scorer(reader.getContext(), null);
+      return weight.scorer(reader.getContext());
     case BULK_SCORER:
-      final BulkScorer bulkScorer = weight.booleanScorer(reader.getContext(), null);
+      final BulkScorer bulkScorer = weight.booleanScorer(reader.getContext());
       if (bulkScorer == null) {
-        if (weight.scorer(reader.getContext(), null) != null) {
+        if (weight.scorer(reader.getContext()) != null) {
           throw new AssertionError("BooleanScorer should be applicable for this query");
         }
         return null;
Index: lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java	(working copy)
@@ -132,9 +132,9 @@
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(LeafReaderContext context) throws IOException {
           assertEquals("query=" + in, value, needsScores);
-          return w.scorer(context, acceptDocs);
+          return w.scorer(context);
         }
       };
     }
Index: lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -105,7 +105,6 @@
     IndexSearcher searcher = newSearcher(reader);
     
     PostingsEnum pos = MultiFields.getTermPositionsEnum(searcher.getIndexReader(),
-                                                                MultiFields.getLiveDocs(searcher.getIndexReader()),
                                                                 "field",
                                                                 new BytesRef("1"));
     pos.nextDoc();
@@ -113,7 +112,6 @@
     assertEquals(0, pos.nextPosition());
     
     pos = MultiFields.getTermPositionsEnum(searcher.getIndexReader(),
-                                           MultiFields.getLiveDocs(searcher.getIndexReader()),
                                            "field",
                                            new BytesRef("2"));
     pos.nextDoc();
Index: lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java	(working copy)
@@ -431,7 +431,7 @@
         }
 
         @Override
-        public Scorer scorer(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+        public Scorer scorer(final LeafReaderContext context) throws IOException {
 
           return new Scorer(null) {
             int docID = -1;
Index: lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(working copy)
@@ -217,7 +217,7 @@
     searcher.setQueryCache(null); // to still have approximations
     final Query query = new QueryWrapperFilter(new RandomApproximationQuery(new TermQuery(new Term("foo", "bar")), random()));
     final Weight weight = searcher.createNormalizedWeight(query, random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0), null);
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
     assertNotNull(scorer.asTwoPhaseIterator());
     reader.close();
     dir.close();
Index: lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/TestTermScorer.java	(working copy)
@@ -80,7 +80,7 @@
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext)indexSearcher.getTopReaderContext();
-    BulkScorer ts = weight.bulkScorer(context, context.reader().getLiveDocs());
+    BulkScorer ts = weight.bulkScorer(context);
     // we have 2 documents with the term all in them, one document for all the
     // other values
     final List<TestHit> docs = new ArrayList<>();
@@ -114,7 +114,7 @@
       public boolean needsScores() {
         return true;
       }
-    });
+    }, null);
     assertTrue("docs Size: " + docs.size() + " is not: " + 2, docs.size() == 2);
     TestHit doc0 = docs.get(0);
     TestHit doc5 = docs.get(1);
@@ -142,7 +142,7 @@
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext) indexSearcher.getTopReaderContext();
-    Scorer ts = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer ts = weight.scorer(context);
     assertTrue("next did not return a doc",
         ts.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     assertTrue("score is not correct", ts.score() == 1.6931472f);
@@ -161,7 +161,7 @@
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     assertTrue(indexSearcher.getTopReaderContext() instanceof LeafReaderContext);
     LeafReaderContext context = (LeafReaderContext) indexSearcher.getTopReaderContext();
-    Scorer ts = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer ts = weight.scorer(context);
     assertTrue("Didn't skip", ts.advance(3) != DocIdSetIterator.NO_MORE_DOCS);
     // The next doc should be doc 5
     assertTrue("doc should be number 5", ts.docID() == 5);
@@ -199,7 +199,7 @@
     
     Weight weight = indexSearcher.createNormalizedWeight(termQuery, true);
     try {
-      weight.scorer(forbiddenNorms.getContext(), null).nextDoc();
+      weight.scorer(forbiddenNorms.getContext()).nextDoc();
       fail("Should load norms");
     } catch (AssertionError e) {
       // ok
@@ -207,6 +207,6 @@
     
     weight = indexSearcher.createNormalizedWeight(termQuery, false);
     // should not fail this time since norms are not necessary
-    weight.scorer(forbiddenNorms.getContext(), null).nextDoc();
+    weight.scorer(forbiddenNorms.getContext()).nextDoc();
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java	(working copy)
@@ -22,7 +22,6 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 
@@ -48,6 +47,6 @@
 
     SpanWeight w = spanQuery.createWeight(searcher, false);
 
-    return w.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()), requiredPostings);
+    return w.getSpans(lrContext, requiredPostings);
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java	(working copy)
@@ -191,7 +191,7 @@
     Weight w = searcher.createNormalizedWeight(q, true);
     IndexReaderContext topReaderContext = searcher.getTopReaderContext();
     LeafReaderContext leave = topReaderContext.leaves().get(0);
-    Scorer s = w.scorer(leave, leave.reader().getLiveDocs());
+    Scorer s = w.scorer(leave);
     assertEquals(1, s.advance(1));
   }
 
Index: lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java	(revision 1687080)
+++ lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java	(working copy)
@@ -298,7 +298,7 @@
       try {
         searcher.setSimilarity(sim);
         SpanQuery snq = spanNearOrderedQuery(field, 1, "t1", "t2");
-        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());
+        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);
       } finally {
         searcher.setSimilarity(oldSim);
       }
Index: lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java	(revision 1687080)
+++ lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysQuery.java	(working copy)
@@ -113,17 +113,17 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         // We can only run as a top scorer:
         throw new UnsupportedOperationException();
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
 
         // TODO: it could be better if we take acceptDocs
         // into account instead of baseScorer?
-        Scorer baseScorer = baseWeight.scorer(context, acceptDocs);
+        Scorer baseScorer = baseWeight.scorer(context);
 
         DrillSidewaysScorer.DocsAndCost[] dims = new DrillSidewaysScorer.DocsAndCost[drillDowns.length];
         int nullCount = 0;
@@ -168,7 +168,7 @@
               dims[dim].disi = disi;
             }
           } else {
-            DocIdSetIterator disi = ((Weight) drillDowns[dim]).scorer(context, null);
+            DocIdSetIterator disi = ((Weight) drillDowns[dim]).scorer(context);
             if (disi == null) {
               nullCount++;
               continue;
Index: lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java	(revision 1687080)
+++ lucene/facet/src/java/org/apache/lucene/facet/DrillSidewaysScorer.java	(working copy)
@@ -26,6 +26,7 @@
 import org.apache.lucene.search.BulkScorer;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.FilterLeafCollector;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -69,7 +70,7 @@
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int maxDoc) throws IOException {
+  public int score(LeafCollector originalCollector, Bits acceptDocs, int min, int maxDoc) throws IOException {
     if (min != 0) {
       throw new IllegalArgumentException("min must be 0, got " + min);
     }
@@ -76,6 +77,19 @@
     if (maxDoc != Integer.MAX_VALUE) {
       throw new IllegalArgumentException("maxDoc must be Integer.MAX_VALUE");
     }
+    final LeafCollector collector;
+    if (acceptDocs == null) {
+      collector = originalCollector;
+    } else {
+      collector = new FilterLeafCollector(originalCollector) {
+        @Override
+        public void collect(int doc) throws IOException {
+          if (acceptDocs.get(doc)) {
+            super.collect(doc);
+          }
+        }
+      };
+    }
     //if (DEBUG) {
     //  System.out.println("\nscore: reader=" + context.reader());
     //}
Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java	(revision 1687080)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java	(working copy)
@@ -273,7 +273,7 @@
     // If we're still here, we have a cache miss. We need to fetch the
     // value from disk, and then also put it in the cache:
     int ret = TaxonomyReader.INVALID_ORDINAL;
-    PostingsEnum docs = MultiFields.getTermDocsEnum(indexReader, null, Consts.FULL, new BytesRef(FacetsConfig.pathToString(cp.components, cp.length)), 0);
+    PostingsEnum docs = MultiFields.getTermDocsEnum(indexReader, Consts.FULL, new BytesRef(FacetsConfig.pathToString(cp.components, cp.length)), 0);
     if (docs != null && docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
       ret = docs.docID();
       
Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(revision 1687080)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java	(working copy)
@@ -389,7 +389,7 @@
           TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(catTerm)) {
             // liveDocs=null because the taxonomy has no deletes
-            docs = termsEnum.postings(null, docs, 0 /* freqs not required */);
+            docs = termsEnum.postings(docs, 0 /* freqs not required */);
             // if the term was found, we know it has exactly one document.
             doc = docs.nextDoc() + ctx.docBase;
             break;
@@ -689,7 +689,7 @@
               // is sufficient to call next(), and then doc(), exactly once with no
               // 'validation' checks.
               FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(t.utf8ToString()));
-              postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               boolean res = cache.put(cp, postingsEnum.nextDoc() + ctx.docBase);
               assert !res : "entries should not have been evicted from the cache";
             } else {
@@ -779,7 +779,7 @@
         while (te.next() != null) {
           FacetLabel cp = new FacetLabel(FacetsConfig.stringToPath(te.term().utf8ToString()));
           final int ordinal = addCategory(cp);
-          docs = te.postings(null, docs, PostingsEnum.NONE);
+          docs = te.postings(docs, PostingsEnum.NONE);
           ordinalMap.addMapping(docs.nextDoc() + base, ordinal);
         }
         base += ar.maxDoc(); // no deletions, so we're ok
Index: lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java
===================================================================
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java	(revision 1687080)
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/TaxonomyIndexArrays.java	(working copy)
@@ -129,7 +129,7 @@
     // it's ok to use MultiFields because we only iterate on one posting list.
     // breaking it to loop over the leaves() only complicates code for no
     // apparent gain.
-    PostingsEnum positions = MultiFields.getTermPositionsEnum(reader, null,
+    PostingsEnum positions = MultiFields.getTermPositionsEnum(reader,
         Consts.FIELD_PAYLOADS, Consts.PAYLOAD_PARENT_BYTES_REF,
         PostingsEnum.PAYLOADS);
 
Index: lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java	(revision 1687080)
+++ lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector.java	(working copy)
@@ -148,7 +148,7 @@
       final int termCharsOff = termCharsBuilder.length();
       termCharsBuilder.append(tempCharsRefBuilder.chars(), 0, termCharsLen);
 
-      dpEnum = termsEnum.postings(null, dpEnum, dpEnumFlags);
+      dpEnum = termsEnum.postings(dpEnum, dpEnumFlags);
       assert dpEnum != null; // presumably checked by TokenSources.hasPositions earlier
       dpEnum.nextDoc();
       final int freq = dpEnum.freq();
Index: lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java	(revision 1687080)
+++ lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java	(working copy)
@@ -299,7 +299,7 @@
       LeafReaderContext context = getLeafContext();
       SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);
       Bits acceptDocs = context.reader().getLiveDocs();
-      final Spans spans = w.getSpans(context, acceptDocs, SpanWeight.Postings.POSITIONS);
+      final Spans spans = w.getSpans(context, SpanWeight.Postings.POSITIONS);
       if (spans == null) {
         return;
       }
@@ -306,6 +306,9 @@
 
       // collect span positions
       while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
+        if (acceptDocs != null && acceptDocs.get(spans.docID()) == false) {
+          continue;
+        }
         while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
           spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));
         }
Index: lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java	(revision 1687080)
+++ lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter.java	(working copy)
@@ -566,7 +566,7 @@
         if (!termsEnum.seekExact(terms[i])) {
           continue; // term not found
         }
-        de = postings[i] = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+        de = postings[i] = termsEnum.postings(null, PostingsEnum.OFFSETS);
         assert de != null;
         pDoc = de.advance(doc);
       } else {
Index: lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java	(revision 1687080)
+++ lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java	(working copy)
@@ -104,7 +104,7 @@
       if (!termSet.contains(term)) {
         continue;
       }
-      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);
+      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.POSITIONS);
       dpEnum.nextDoc();
       
       // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html
Index: lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsQuery.java	(working copy)
@@ -139,13 +139,13 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       SortedDocValues values = DocValues.getSorted(context.reader(), joinField);
       if (values == null) {
         return null;
       }
 
-      Scorer approximationScorer = approximationWeight.scorer(context, acceptDocs);
+      Scorer approximationScorer = approximationWeight.scorer(context);
       if (approximationScorer == null) {
         return null;
       }
Index: lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/GlobalOrdinalsWithScoreQuery.java	(working copy)
@@ -155,13 +155,13 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       SortedDocValues values = DocValues.getSorted(context.reader(), joinField);
       if (values == null) {
         return null;
       }
 
-      Scorer approximationScorer = approximationWeight.scorer(context, acceptDocs);
+      Scorer approximationScorer = approximationWeight.scorer(context);
       if (approximationScorer == null) {
         return null;
       } else if (globalOrds != null) {
Index: lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java	(working copy)
@@ -133,7 +133,7 @@
           PostingsEnum postingsEnum = null;
           for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {
             if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {
-              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = segmentTermsEnum.postings(postingsEnum, PostingsEnum.NONE);
               if (postingsEnum.advance(doc) == doc) {
                 final float score = TermsIncludingScoreQuery.this.scores[ords[i]];
                 return Explanation.match(score, "Score based on join value " + segmentTermsEnum.term().utf8ToString());
@@ -155,7 +155,7 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         Terms terms = context.reader().terms(field);
         if (terms == null) {
           return null;
@@ -166,9 +166,9 @@
 
         TermsEnum segmentTermsEnum = terms.iterator();
         if (multipleValuesPerDocument) {
-          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);
+          return new MVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);
         } else {
-          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);
+          return new SVInOrderScorer(this, segmentTermsEnum, context.reader().maxDoc(), cost);
         }
       }
 
@@ -183,21 +183,21 @@
 
     int currentDoc = -1;
 
-    SVInOrderScorer(Weight weight, Bits acceptDocs, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
+    SVInOrderScorer(Weight weight, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
       super(weight);
       FixedBitSet matchingDocs = new FixedBitSet(maxDoc);
       this.scores = new float[maxDoc];
-      fillDocsAndScores(matchingDocs, acceptDocs, termsEnum);
+      fillDocsAndScores(matchingDocs, termsEnum);
       this.matchingDocsIterator = new BitSetIterator(matchingDocs, cost);
       this.cost = cost;
     }
 
-    protected void fillDocsAndScores(FixedBitSet matchingDocs, Bits acceptDocs, TermsEnum termsEnum) throws IOException {
+    protected void fillDocsAndScores(FixedBitSet matchingDocs, TermsEnum termsEnum) throws IOException {
       BytesRef spare = new BytesRef();
       PostingsEnum postingsEnum = null;
       for (int i = 0; i < terms.size(); i++) {
         if (termsEnum.seekExact(terms.get(ords[i], spare))) {
-          postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
           float score = TermsIncludingScoreQuery.this.scores[ords[i]];
           for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
             matchingDocs.set(doc);
@@ -243,17 +243,17 @@
   // This scorer deals with the fact that a document can have more than one score from multiple related documents.
   class MVInOrderScorer extends SVInOrderScorer {
 
-    MVInOrderScorer(Weight weight, Bits acceptDocs, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
-      super(weight, acceptDocs, termsEnum, maxDoc, cost);
+    MVInOrderScorer(Weight weight, TermsEnum termsEnum, int maxDoc, long cost) throws IOException {
+      super(weight, termsEnum, maxDoc, cost);
     }
 
     @Override
-    protected void fillDocsAndScores(FixedBitSet matchingDocs, Bits acceptDocs, TermsEnum termsEnum) throws IOException {
+    protected void fillDocsAndScores(FixedBitSet matchingDocs, TermsEnum termsEnum) throws IOException {
       BytesRef spare = new BytesRef();
       PostingsEnum postingsEnum = null;
       for (int i = 0; i < terms.size(); i++) {
         if (termsEnum.seekExact(terms.get(ords[i], spare))) {
-          postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
           float score = TermsIncludingScoreQuery.this.scores[ords[i]];
           for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
             // I prefer this:
Index: lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/ToChildBlockJoinQuery.java	(working copy)
@@ -33,7 +33,6 @@
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
 
 /**
  * Just like {@link ToParentBlockJoinQuery}, except this
@@ -122,9 +121,9 @@
     // NOTE: acceptDocs applies (and is checked) only in the
     // child document space
     @Override
-    public Scorer scorer(LeafReaderContext readerContext, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext readerContext) throws IOException {
 
-      final Scorer parentScorer = parentWeight.scorer(readerContext, null);
+      final Scorer parentScorer = parentWeight.scorer(readerContext);
 
       if (parentScorer == null) {
         // No matches
@@ -139,12 +138,12 @@
         return null;
       }
 
-      return new ToChildBlockJoinScorer(this, parentScorer, parents.bits(), doScores, acceptDocs);
+      return new ToChildBlockJoinScorer(this, parentScorer, parents.bits(), doScores);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      ToChildBlockJoinScorer scorer = (ToChildBlockJoinScorer) scorer(context, context.reader().getLiveDocs());
+      ToChildBlockJoinScorer scorer = (ToChildBlockJoinScorer) scorer(context);
       if (scorer != null && scorer.advance(doc) == doc) {
         int parentDoc = scorer.getParentDoc();
         return Explanation.match(
@@ -161,7 +160,6 @@
     private final Scorer parentScorer;
     private final BitSet parentBits;
     private final boolean doScores;
-    private final Bits acceptDocs;
 
     private float parentScore;
     private int parentFreq = 1;
@@ -169,12 +167,11 @@
     private int childDoc = -1;
     private int parentDoc = 0;
 
-    public ToChildBlockJoinScorer(Weight weight, Scorer parentScorer, BitSet parentBits, boolean doScores, Bits acceptDocs) {
+    public ToChildBlockJoinScorer(Weight weight, Scorer parentScorer, BitSet parentBits, boolean doScores) {
       super(weight);
       this.doScores = doScores;
       this.parentBits = parentBits;
       this.parentScorer = parentScorer;
-      this.acceptDocs = acceptDocs;
     }
 
     @Override
@@ -186,8 +183,6 @@
     public int nextDoc() throws IOException {
       //System.out.println("Q.nextDoc() parentDoc=" + parentDoc + " childDoc=" + childDoc);
 
-      // Loop until we hit a childDoc that's accepted
-      nextChildDoc:
       while (true) {
         if (childDoc+1 == parentDoc) {
           // OK, we are done iterating through all children
@@ -224,20 +219,6 @@
               continue;
             }
 
-            if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-              // find the first child that is accepted
-              while (true) {
-                if (childDoc+1 < parentDoc) {
-                  childDoc++;
-                  if (acceptDocs.get(childDoc))
-                    break;
-                } else {
-                  // no child for this parent doc matches acceptDocs
-                  continue nextChildDoc;
-                }
-              }
-            }
-
             if (childDoc < parentDoc) {
               if (doScores) {
                 parentScore = parentScorer.score();
@@ -252,9 +233,6 @@
         } else {
           assert childDoc < parentDoc: "childDoc=" + childDoc + " parentDoc=" + parentDoc;
           childDoc++;
-          if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-            continue;
-          }
           //System.out.println("  " + childDoc);
           return childDoc;
         }
@@ -323,9 +301,6 @@
       assert !parentBits.get(childTarget);
       childDoc = childTarget;
       //System.out.println("  " + childDoc);
-      if (acceptDocs != null && !acceptDocs.get(childDoc)) {
-        nextDoc();
-      }
       return childDoc;
     }
 
Index: lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinIndexSearcher.java	(working copy)
@@ -21,7 +21,6 @@
 import java.util.List;
 import java.util.concurrent.ExecutorService;
 
-import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Collector;
@@ -30,6 +29,7 @@
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
 
 /**
  * An {@link IndexSearcher} to use in conjunction with
@@ -56,12 +56,15 @@
       // we force the use of Scorer (not BulkScorer) to make sure
       // that the scorer passed to LeafCollector.setScorer supports
       // Scorer.getChildren
-      Scorer scorer = weight.scorer(ctx, ctx.reader().getLiveDocs());
+      Scorer scorer = weight.scorer(ctx);
       if (scorer != null) {
         final LeafCollector leafCollector = collector.getLeafCollector(ctx);
         leafCollector.setScorer(scorer);
+        final Bits liveDocs = ctx.reader().getLiveDocs();
         for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-          leafCollector.collect(doc);
+          if (liveDocs == null || liveDocs.get(doc)) {
+            leafCollector.collect(doc);
+          }
         }
       }
     }
Index: lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java	(revision 1687080)
+++ lucene/join/src/java/org/apache/lucene/search/join/ToParentBlockJoinQuery.java	(working copy)
@@ -157,9 +157,9 @@
     // NOTE: acceptDocs applies (and is checked) only in the
     // parent document space
     @Override
-    public Scorer scorer(LeafReaderContext readerContext, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext readerContext) throws IOException {
 
-      final Scorer childScorer = childWeight.scorer(readerContext, readerContext.reader().getLiveDocs());
+      final Scorer childScorer = childWeight.scorer(readerContext);
       if (childScorer == null) {
         // No matches
         return null;
@@ -180,12 +180,12 @@
         return null;
       }
 
-      return new BlockJoinScorer(this, childScorer, parents.bits(), firstChildDoc, scoreMode, acceptDocs);
+      return new BlockJoinScorer(this, childScorer, parents.bits(), firstChildDoc, scoreMode);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      BlockJoinScorer scorer = (BlockJoinScorer) scorer(context, context.reader().getLiveDocs());
+      BlockJoinScorer scorer = (BlockJoinScorer) scorer(context);
       if (scorer != null && scorer.advance(doc) == doc) {
         return scorer.explain(context.docBase);
       }
@@ -197,7 +197,6 @@
     private final Scorer childScorer;
     private final BitSet parentBits;
     private final ScoreMode scoreMode;
-    private final Bits acceptDocs;
     private int parentDoc = -1;
     private int prevParentDoc;
     private float parentScore;
@@ -207,13 +206,12 @@
     private float[] pendingChildScores;
     private int childDocUpto;
 
-    public BlockJoinScorer(Weight weight, Scorer childScorer, BitSet parentBits, int firstChildDoc, ScoreMode scoreMode, Bits acceptDocs) {
+    public BlockJoinScorer(Weight weight, Scorer childScorer, BitSet parentBits, int firstChildDoc, ScoreMode scoreMode) {
       super(weight);
       //System.out.println("Q.init firstChildDoc=" + firstChildDoc);
       this.parentBits = parentBits;
       this.childScorer = childScorer;
       this.scoreMode = scoreMode;
-      this.acceptDocs = acceptDocs;
       nextChildDoc = firstChildDoc;
     }
 
@@ -256,104 +254,84 @@
     @Override
     public int nextDoc() throws IOException {
       //System.out.println("Q.nextDoc() nextChildDoc=" + nextChildDoc);
-      // Loop until we hit a parentDoc that's accepted
-      while (true) {
-        if (nextChildDoc == NO_MORE_DOCS) {
-          //System.out.println("  end");
-          return parentDoc = NO_MORE_DOCS;
-        }
+      if (nextChildDoc == NO_MORE_DOCS) {
+        //System.out.println("  end");
+        return parentDoc = NO_MORE_DOCS;
+      }
 
-        // Gather all children sharing the same parent as
-        // nextChildDoc
+      // Gather all children sharing the same parent as
+      // nextChildDoc
 
-        parentDoc = parentBits.nextSetBit(nextChildDoc);
+      parentDoc = parentBits.nextSetBit(nextChildDoc);
 
-        // Parent & child docs are supposed to be
-        // orthogonal:
-        if (nextChildDoc == parentDoc) {
-          throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
-        }
+      // Parent & child docs are supposed to be
+      // orthogonal:
+      if (nextChildDoc == parentDoc) {
+        throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+      }
 
-        //System.out.println("  parentDoc=" + parentDoc);
-        assert parentDoc != DocIdSetIterator.NO_MORE_DOCS;
+      //System.out.println("  parentDoc=" + parentDoc);
+      assert parentDoc != DocIdSetIterator.NO_MORE_DOCS;
 
-        //System.out.println("  nextChildDoc=" + nextChildDoc);
-        if (acceptDocs != null && !acceptDocs.get(parentDoc)) {
-          // Parent doc not accepted; skip child docs until
-          // we hit a new parent doc:
-          do {
-            nextChildDoc = childScorer.nextDoc();
-          } while (nextChildDoc < parentDoc);
+      float totalScore = 0;
+      float maxScore = Float.NEGATIVE_INFINITY;
+      float minScore = Float.POSITIVE_INFINITY;
 
-          // Parent & child docs are supposed to be
-          // orthogonal:
-          if (nextChildDoc == parentDoc) {
-            throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
-          }
+      childDocUpto = 0;
+      parentFreq = 0;
+      do {
 
-          continue;
+        //System.out.println("  c=" + nextChildDoc);
+        if (pendingChildDocs != null && pendingChildDocs.length == childDocUpto) {
+          pendingChildDocs = ArrayUtil.grow(pendingChildDocs);
         }
-
-        float totalScore = 0;
-        float maxScore = Float.NEGATIVE_INFINITY;
-        float minScore = Float.POSITIVE_INFINITY;
-
-        childDocUpto = 0;
-        parentFreq = 0;
-        do {
-
-          //System.out.println("  c=" + nextChildDoc);
-          if (pendingChildDocs != null && pendingChildDocs.length == childDocUpto) {
-            pendingChildDocs = ArrayUtil.grow(pendingChildDocs);
+        if (pendingChildScores != null && scoreMode != ScoreMode.None && pendingChildScores.length == childDocUpto) {
+          pendingChildScores = ArrayUtil.grow(pendingChildScores);
+        }
+        if (pendingChildDocs != null) {
+          pendingChildDocs[childDocUpto] = nextChildDoc;
+        }
+        if (scoreMode != ScoreMode.None) {
+          // TODO: specialize this into dedicated classes per-scoreMode
+          final float childScore = childScorer.score();
+          final int childFreq = childScorer.freq();
+          if (pendingChildScores != null) {
+            pendingChildScores[childDocUpto] = childScore;
           }
-          if (pendingChildScores != null && scoreMode != ScoreMode.None && pendingChildScores.length == childDocUpto) {
-            pendingChildScores = ArrayUtil.grow(pendingChildScores);
-          }
-          if (pendingChildDocs != null) {
-            pendingChildDocs[childDocUpto] = nextChildDoc;
-          }
-          if (scoreMode != ScoreMode.None) {
-            // TODO: specialize this into dedicated classes per-scoreMode
-            final float childScore = childScorer.score();
-            final int childFreq = childScorer.freq();
-            if (pendingChildScores != null) {
-              pendingChildScores[childDocUpto] = childScore;
-            }
-            maxScore = Math.max(childScore, maxScore);
-            minScore = Math.min(childFreq, minScore);
-            totalScore += childScore;
-            parentFreq += childFreq;
-          }
-          childDocUpto++;
-          nextChildDoc = childScorer.nextDoc();
-        } while (nextChildDoc < parentDoc);
-
-        // Parent & child docs are supposed to be
-        // orthogonal:
-        if (nextChildDoc == parentDoc) {
-          throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+          maxScore = Math.max(childScore, maxScore);
+          minScore = Math.min(childFreq, minScore);
+          totalScore += childScore;
+          parentFreq += childFreq;
         }
+        childDocUpto++;
+        nextChildDoc = childScorer.nextDoc();
+      } while (nextChildDoc < parentDoc);
 
-        switch(scoreMode) {
-        case Avg:
-          parentScore = totalScore / childDocUpto;
-          break;
-        case Max:
-          parentScore = maxScore;
-          break;
-        case Min:
-          parentScore = minScore;
-          break;
-        case Total:
-          parentScore = totalScore;
-          break;
-        case None:
-          break;
-        }
+      // Parent & child docs are supposed to be
+      // orthogonal:
+      if (nextChildDoc == parentDoc) {
+        throw new IllegalStateException("child query must only match non-parent docs, but parent docID=" + nextChildDoc + " matched childScorer=" + childScorer.getClass());
+      }
 
-        //System.out.println("  return parentDoc=" + parentDoc + " childDocUpto=" + childDocUpto);
-        return parentDoc;
+      switch(scoreMode) {
+      case Avg:
+        parentScore = totalScore / childDocUpto;
+        break;
+      case Max:
+        parentScore = maxScore;
+        break;
+      case Min:
+        parentScore = minScore;
+        break;
+      case Total:
+        parentScore = totalScore;
+        break;
+      case None:
+        break;
       }
+
+      //System.out.println("  return parentDoc=" + parentDoc + " childDocUpto=" + childDocUpto);
+      return parentDoc;
     }
 
     @Override
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(revision 1687080)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(working copy)
@@ -55,6 +55,7 @@
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.NumericRangeQuery;
 import org.apache.lucene.search.PrefixQuery;
@@ -444,7 +445,7 @@
     w.close();
     IndexSearcher s = newSearcher(r);
     
-    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(new MatchAllDocsQuery(), new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new MatchAllDocsQuery())), ScoreMode.Avg);
+    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(new MatchNoDocsQuery(), new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new MatchAllDocsQuery())), ScoreMode.Avg);
     QueryUtils.check(random(), q, s);
     s.search(q, 10);
     BooleanQuery.Builder bqB = new BooleanQuery.Builder();
@@ -456,61 +457,6 @@
     dir.close();
   }
 
-  public void testNestedDocScoringWithDeletes() throws Exception {
-    final Directory dir = newDirectory();
-    final RandomIndexWriter w = new RandomIndexWriter(
-        random(),
-        dir,
-        newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
-
-    // Cannot assert this since we use NoMergePolicy:
-    w.setDoRandomForceMergeAssert(false);
-
-    List<Document> docs = new ArrayList<>();
-    docs.add(makeJob("java", 2007));
-    docs.add(makeJob("python", 2010));
-    docs.add(makeResume("Lisa", "United Kingdom"));
-    w.addDocuments(docs);
-
-    docs.clear();
-    docs.add(makeJob("c", 1999));
-    docs.add(makeJob("ruby", 2005));
-    docs.add(makeJob("java", 2006));
-    docs.add(makeResume("Frank", "United States"));
-    w.addDocuments(docs);
-
-    w.commit();
-    IndexSearcher s = newSearcher(DirectoryReader.open(dir));
-
-    ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(
-        NumericRangeQuery.newIntRange("year", 1990, 2010, true, true),
-        new BitDocIdSetCachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("docType", "resume")))),
-        ScoreMode.Total
-    );
-
-    TopDocs topDocs = s.search(q, 10);
-    assertEquals(2, topDocs.totalHits);
-    assertEquals(6, topDocs.scoreDocs[0].doc);
-    assertEquals(3.0f, topDocs.scoreDocs[0].score, 0.0f);
-    assertEquals(2, topDocs.scoreDocs[1].doc);
-    assertEquals(2.0f, topDocs.scoreDocs[1].score, 0.0f);
-
-    s.getIndexReader().close();
-    w.deleteDocuments(new Term("skill", "java"));
-    w.close();
-    s = newSearcher(DirectoryReader.open(dir));
-
-    topDocs = s.search(q, 10);
-    assertEquals(2, topDocs.totalHits);
-    assertEquals(6, topDocs.scoreDocs[0].doc);
-    assertEquals(2.0f, topDocs.scoreDocs[0].score, 0.0f);
-    assertEquals(2, topDocs.scoreDocs[1].doc);
-    assertEquals(1.0f, topDocs.scoreDocs[1].score, 0.0f);
-
-    s.getIndexReader().close();
-    dir.close();
-  }
-
   private String[][] getRandomFields(int maxUniqueValues) {
 
     final String[][] fields = new String[TestUtil.nextInt(random(), 2, 4)][];
@@ -699,7 +645,7 @@
       for(int docIDX=0;docIDX<joinR.maxDoc();docIDX++) {
         System.out.println("  docID=" + docIDX + " doc=" + joinR.document(docIDX) + " deleted?=" + (liveDocs != null && liveDocs.get(docIDX) == false));
       }
-      PostingsEnum parents = MultiFields.getTermDocsEnum(joinR, null, "isParent", new BytesRef("x"));
+      PostingsEnum parents = MultiFields.getTermDocsEnum(joinR, "isParent", new BytesRef("x"));
       System.out.println("parent docIDs:");
       while (parents.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
         System.out.println("  " + parents.docID());
@@ -1207,7 +1153,7 @@
 
     ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(tq, parentFilter, ScoreMode.Avg);
     Weight weight = s.createNormalizedWeight(q, true);
-    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0), null);
+    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0));
     assertEquals(1, disi.advance(1));
     r.close();
     dir.close();
@@ -1241,7 +1187,7 @@
 
     ToParentBlockJoinQuery q = new ToParentBlockJoinQuery(tq, parentFilter, ScoreMode.Avg);
     Weight weight = s.createNormalizedWeight(q, true);
-    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0), null);
+    DocIdSetIterator disi = weight.scorer(s.getIndexReader().leaves().get(0));
     assertEquals(2, disi.advance(0));
     r.close();
     dir.close();
@@ -1284,7 +1230,7 @@
     s.search(childJoinQuery, c);
 
     //Get all child documents within groups
-    @SuppressWarnings({"unchecked","rawtypes"})
+    @SuppressWarnings({"unchecked"})
     TopGroups<Integer>[] getTopGroupsResults = new TopGroups[2];
     getTopGroupsResults[0] = c.getTopGroups(childJoinQuery, null, 0, 10, 0, true);
     getTopGroupsResults[1] = c.getTopGroupsWithAllChildDocs(childJoinQuery, null, 0, 0, true);
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java	(revision 1687080)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinValidation.java	(working copy)
@@ -131,7 +131,7 @@
 
     final LeafReaderContext context = indexSearcher.getIndexReader().leaves().get(0);
     Weight weight = indexSearcher.createNormalizedWeight(blockJoinQuery, true);
-    Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());
+    Scorer scorer = weight.scorer(context);
     final Bits parentDocs = parentsFilter.getDocIdSet(context).bits();
 
     int target;
Index: lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java	(revision 1687080)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java	(working copy)
@@ -370,8 +370,8 @@
           }
 
           @Override
-          public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-            Scorer fieldScorer = fieldWeight.scorer(context, acceptDocs);
+          public Scorer scorer(LeafReaderContext context) throws IOException {
+            Scorer fieldScorer = fieldWeight.scorer(context);
             NumericDocValues price = context.reader().getNumericDocValues(priceField);
             return new FilterScorer(fieldScorer, this) {
               @Override
@@ -1096,7 +1096,7 @@
           for (BytesRef joinValue : joinValues) {
             TermsEnum termsEnum = terms.iterator();
             if (termsEnum.seekExact(joinValue)) {
-              postingsEnum = termsEnum.postings(slowCompositeReader.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               JoinScore joinScore = joinValueToJoinScores.get(joinValue);
 
               for (int doc = postingsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = postingsEnum.nextDoc()) {
@@ -1219,7 +1219,7 @@
         }
 
         for (RandomDoc otherSideDoc : otherMatchingDocs) {
-          PostingsEnum postingsEnum = MultiFields.getTermDocsEnum(topLevelReader, MultiFields.getLiveDocs(topLevelReader), "id", new BytesRef(otherSideDoc.id), 0);
+          PostingsEnum postingsEnum = MultiFields.getTermDocsEnum(topLevelReader, "id", new BytesRef(otherSideDoc.id), 0);
           assert postingsEnum != null;
           int doc = postingsEnum.nextDoc();
           expectedResult.set(doc);
Index: lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
===================================================================
--- lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(revision 1687080)
+++ lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(working copy)
@@ -989,12 +989,12 @@
       }
 
       @Override
-      public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
+      public PostingsEnum postings(PostingsEnum reuse, int flags) {
         if (reuse == null || !(reuse instanceof MemoryPostingsEnum)) {
           reuse = new MemoryPostingsEnum();
         }
         final int ord = info.sortedTerms[termUpto];
-        return ((MemoryPostingsEnum) reuse).reset(liveDocs, info.sliceArray.start[ord], info.sliceArray.end[ord], info.sliceArray.freq[ord]);
+        return ((MemoryPostingsEnum) reuse).reset(info.sliceArray.start[ord], info.sliceArray.end[ord], info.sliceArray.freq[ord]);
       }
 
       @Override
@@ -1016,7 +1016,6 @@
       private final SliceReader sliceReader;
       private int posUpto; // for assert
       private boolean hasNext;
-      private Bits liveDocs;
       private int doc = -1;
       private int freq;
       private int pos;
@@ -1030,8 +1029,7 @@
         this.payloadBuilder = storePayloads ? new BytesRefBuilder() : null;
       }
 
-      public PostingsEnum reset(Bits liveDocs, int start, int end, int freq) {
-        this.liveDocs = liveDocs;
+      public PostingsEnum reset(int start, int end, int freq) {
         this.sliceReader.reset(start, end);
         posUpto = 0; // for assert
         hasNext = true;
@@ -1049,7 +1047,7 @@
       @Override
       public int nextDoc() {
         pos = -1;
-        if (hasNext && (liveDocs == null || liveDocs.get(0))) {
+        if (hasNext) {
           hasNext = false;
           return doc = 0;
         } else {
Index: lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java
===================================================================
--- lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java	(revision 1687080)
+++ lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir.java	(working copy)
@@ -199,8 +199,8 @@
           while(iwTermsIter.next() != null) {
             assertNotNull(memTermsIter.next());
             assertEquals(iwTermsIter.term(), memTermsIter.term());
-            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, null, PostingsEnum.ALL);
-            PostingsEnum memDocsAndPos = memTermsIter.postings(null, null, PostingsEnum.ALL);
+            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, PostingsEnum.ALL);
+            PostingsEnum memDocsAndPos = memTermsIter.postings(null, PostingsEnum.ALL);
             while(iwDocsAndPos.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
               assertEquals(iwDocsAndPos.docID(), memDocsAndPos.nextDoc());
               assertEquals(iwDocsAndPos.freq(), memDocsAndPos.freq());
@@ -222,8 +222,8 @@
         } else {
           while(iwTermsIter.next() != null) {
             assertEquals(iwTermsIter.term(), memTermsIter.term());
-            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null, null);
-            PostingsEnum memDocsAndPos = memTermsIter.postings(null, null);
+            PostingsEnum iwDocsAndPos = iwTermsIter.postings(null);
+            PostingsEnum memDocsAndPos = memTermsIter.postings(null);
             while(iwDocsAndPos.nextDoc() != PostingsEnum.NO_MORE_DOCS) {
               assertEquals(iwDocsAndPos.docID(), memDocsAndPos.nextDoc());
               assertEquals(iwDocsAndPos.freq(), memDocsAndPos.freq());
@@ -320,7 +320,7 @@
     memory.addField("foo", "bar", analyzer);
     LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();
     TestUtil.checkReader(reader);
-    PostingsEnum disi = TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, null, PostingsEnum.NONE);
+    PostingsEnum disi = TestUtil.docs(random(), reader, "foo", new BytesRef("bar"), null, PostingsEnum.NONE);
     int docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -328,7 +328,7 @@
     // now reuse and check again
     TermsEnum te = reader.terms("foo").iterator();
     assertTrue(te.seekExact(new BytesRef("bar")));
-    disi = te.postings(null, disi, PostingsEnum.NONE);
+    disi = te.postings(disi, PostingsEnum.NONE);
     docid = disi.docID();
     assertEquals(-1, docid);
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -367,7 +367,7 @@
       // now reuse and check again
       TermsEnum te = reader.terms("foo").iterator();
       assertTrue(te.seekExact(new BytesRef("bar")));
-      disi = te.postings(null, disi);
+      disi = te.postings(disi);
       docid = disi.docID();
       assertEquals(-1, docid);
       assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
@@ -534,8 +534,8 @@
       assertNotNull(memTermEnum.next());
       assertThat(termEnum.totalTermFreq(), equalTo(memTermEnum.totalTermFreq()));
 
-      PostingsEnum docsPosEnum = termEnum.postings(null, null, PostingsEnum.POSITIONS);
-      PostingsEnum memDocsPosEnum = memTermEnum.postings(null, null, PostingsEnum.POSITIONS);
+      PostingsEnum docsPosEnum = termEnum.postings(null, PostingsEnum.POSITIONS);
+      PostingsEnum memDocsPosEnum = memTermEnum.postings(null, PostingsEnum.POSITIONS);
       String currentTerm = termEnum.term().utf8ToString();
 
       assertThat("Token mismatch for field: " + field_name, currentTerm, equalTo(memTermEnum.term().utf8ToString()));
Index: lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java	(revision 1687080)
+++ lucene/misc/src/java/org/apache/lucene/index/SortingLeafReader.java	(working copy)
@@ -132,7 +132,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, final int flags) throws IOException {
+    public PostingsEnum postings( PostingsEnum reuse, final int flags) throws IOException {
 
       if (hasPositions && PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         final PostingsEnum inReuse;
@@ -147,7 +147,7 @@
           inReuse = reuse;
         }
 
-        final PostingsEnum inDocsAndPositions = in.postings(newToOld(liveDocs), inReuse, flags);
+        final PostingsEnum inDocsAndPositions = in.postings(inReuse, flags);
         // we ignore the fact that offsets may be stored but not asked for,
         // since this code is expected to be used during addIndexes which will
         // ask for everything. if that assumption changes in the future, we can
@@ -168,7 +168,7 @@
         inReuse = reuse;
       }
 
-      final PostingsEnum inDocs = in.postings(newToOld(liveDocs), inReuse, flags);
+      final PostingsEnum inDocs = in.postings(inReuse, flags);
       final boolean withFreqs = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >=0 && PostingsEnum.featureRequested(flags, PostingsEnum.FREQS);
       return new SortingDocsEnum(docMap.size(), wrapReuse, inDocs, withFreqs, docMap);
     }
Index: lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java	(revision 1687080)
+++ lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java	(working copy)
@@ -346,7 +346,7 @@
       final int df = te.docFreq();
       if (df <= maxTermDocFreq) {
 
-        postingsEnum = te.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = te.postings(postingsEnum, PostingsEnum.NONE);
 
         // dF, but takes deletions into account
         int actualDF = 0;
@@ -593,8 +593,8 @@
     }
 
     @Override    
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      return termsEnum.postings(liveDocs, reuse, flags);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
+      return termsEnum.postings(reuse, flags);
     }
 
     @Override
Index: lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
===================================================================
--- lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java	(revision 1687080)
+++ lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java	(working copy)
@@ -288,7 +288,7 @@
             break;
           }
           visitTerm(term);
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
@@ -419,7 +419,7 @@
             res = new FixedBitSet(maxDoc);
           }
 
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           // TODO: use bulk API
           while (true) {
             final int docID = docs.nextDoc();
@@ -698,7 +698,7 @@
           }
 
           termOrdToBytesOffset.add(bytes.copyUsingLengthPrefix(term));
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
@@ -850,7 +850,7 @@
             break;
           }
           final long pointer = bytes.copyUsingLengthPrefix(term);
-          docs = termsEnum.postings(null, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           while (true) {
             final int docID = docs.nextDoc();
             if (docID == DocIdSetIterator.NO_MORE_DOCS) {
Index: lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java	(revision 1687080)
+++ lucene/misc/src/test/org/apache/lucene/index/SorterTestBase.java	(working copy)
@@ -235,7 +235,7 @@
   public void testDocsAndPositionsEnum() throws Exception {
     TermsEnum termsEnum = sortedReader.terms(DOC_POSITIONS_FIELD).iterator();
     assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));
-    PostingsEnum sortedPositions = termsEnum.postings(null, null, PostingsEnum.ALL);
+    PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);
     int doc;
     
     // test nextDoc()
@@ -252,7 +252,7 @@
     
     // test advance()
     final PostingsEnum reuse = sortedPositions;
-    sortedPositions = termsEnum.postings(null, reuse, PostingsEnum.ALL);
+    sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);
     if (sortedPositions instanceof SortingDocsEnum) {
       assertTrue(((SortingDocsEnum) sortedPositions).reused(reuse)); // make sure reuse worked
     }
@@ -293,26 +293,18 @@
 
   @Test
   public void testDocsEnum() throws Exception {
-    Bits mappedLiveDocs = randomLiveDocs(sortedReader.maxDoc());
     TermsEnum termsEnum = sortedReader.terms(DOCS_ENUM_FIELD).iterator();
     assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOCS_ENUM_TERM)));
-    PostingsEnum docs = termsEnum.postings(mappedLiveDocs, null);
+    PostingsEnum docs = termsEnum.postings(null);
 
     int doc;
     int prev = -1;
     while ((doc = docs.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-      assertTrue("document " + doc + " marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(doc));
       assertEquals("incorrect value; doc " + doc, sortedValues[doc].intValue(), Integer.parseInt(sortedReader.document(doc).get(ID_FIELD)));
-      while (++prev < doc) {
-        assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-      }
     }
-    while (++prev < sortedReader.maxDoc()) {
-      assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-    }
 
     PostingsEnum reuse = docs;
-    docs = termsEnum.postings(mappedLiveDocs, reuse);
+    docs = termsEnum.postings(reuse);
     if (docs instanceof SortingDocsEnum) {
       assertTrue(((SortingDocsEnum) docs).reused(reuse)); // make sure reuse worked
     }
@@ -319,15 +311,8 @@
     doc = -1;
     prev = -1;
     while ((doc = docs.advance(doc + 1)) != DocIdSetIterator.NO_MORE_DOCS) {
-      assertTrue("document " + doc + " marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(doc));
       assertEquals("incorrect value; doc " + doc, sortedValues[doc].intValue(), Integer.parseInt(sortedReader.document(doc).get(ID_FIELD)));
-      while (++prev < doc) {
-        assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-      }
     }
-    while (++prev < sortedReader.maxDoc()) {
-      assertFalse("document " + prev + " not marked as deleted", mappedLiveDocs == null || mappedLiveDocs.get(prev));
-    }
   }
   
   @Test
Index: lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java	(working copy)
@@ -94,12 +94,12 @@
         }
 
         @Override
-        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-          final Scorer matchScorer = matchWeight.scorer(context, acceptDocs);
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          final Scorer matchScorer = matchWeight.scorer(context);
           if (matchScorer == null) {
             return null;
           }
-          final Scorer contextScorer = contextWeight.scorer(context, acceptDocs);
+          final Scorer contextScorer = contextWeight.scorer(context);
           if (contextScorer == null) {
             return matchScorer;
           }
Index: lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/CustomScoreQuery.java	(working copy)
@@ -228,14 +228,14 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Scorer subQueryScorer = subQueryWeight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Scorer subQueryScorer = subQueryWeight.scorer(context);
       if (subQueryScorer == null) {
         return null;
       }
       Scorer[] valSrcScorers = new Scorer[valSrcWeights.length];
       for(int i = 0; i < valSrcScorers.length; i++) {
-         valSrcScorers[i] = valSrcWeights[i].scorer(context, acceptDocs);
+         valSrcScorers[i] = valSrcWeights[i].scorer(context);
       }
       return new CustomScorer(CustomScoreQuery.this.getCustomScoreProvider(context), this, queryWeight, subQueryScorer, valSrcScorers);
     }
Index: lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/TermsQuery.java	(working copy)
@@ -252,7 +252,7 @@
        * On the given leaf context, try to either rewrite to a disjunction if
        * there are few matching terms, or build a bitset containing matching docs.
        */
-      private WeightOrBitSet rewrite(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      private WeightOrBitSet rewrite(LeafReaderContext context) throws IOException {
         final LeafReader reader = context.reader();
 
         // We will first try to collect up to 'threshold' terms into 'matchingTerms'
@@ -282,7 +282,7 @@
           }
           if (termsEnum != null && termsEnum.seekExact(term)) {
             if (matchingTerms == null) {
-              docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+              docs = termsEnum.postings(docs, PostingsEnum.NONE);
               builder.or(docs);
             } else if (matchingTerms.size() < threshold) {
               matchingTerms.add(new TermAndState(field, termsEnum));
@@ -289,11 +289,11 @@
             } else {
               assert matchingTerms.size() == threshold;
               builder = new BitDocIdSet.Builder(reader.maxDoc());
-              docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+              docs = termsEnum.postings(docs, PostingsEnum.NONE);
               builder.or(docs);
               for (TermAndState t : matchingTerms) {
                 t.termsEnum.seekExact(t.term, t.state);
-                docs = t.termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+                docs = t.termsEnum.postings(docs, PostingsEnum.NONE);
                 builder.or(docs);
               }
               matchingTerms = null;
@@ -329,10 +329,10 @@
       }
 
       @Override
-      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.bulkScorer(context, acceptDocs);
+          return weightOrBitSet.weight.bulkScorer(context);
         } else {
           final Scorer scorer = scorer(weightOrBitSet.bitset);
           if (scorer == null) {
@@ -343,10 +343,10 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        final WeightOrBitSet weightOrBitSet = rewrite(context, acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final WeightOrBitSet weightOrBitSet = rewrite(context);
         if (weightOrBitSet.weight != null) {
-          return weightOrBitSet.weight.scorer(context, acceptDocs);
+          return weightOrBitSet.weight.scorer(context);
         } else {
           return scorer(weightOrBitSet.bitset);
         }
Index: lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/function/BoostedQuery.java	(working copy)
@@ -98,8 +98,8 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Scorer subQueryScorer = qWeight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      Scorer subQueryScorer = qWeight.scorer(context);
       if (subQueryScorer == null) {
         return null;
       }
Index: lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/function/FunctionQuery.java	(working copy)
@@ -89,13 +89,13 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return new AllScorer(context, acceptDocs, this, queryWeight);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return new AllScorer(context, this, queryWeight);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      return ((AllScorer)scorer(context, context.reader().getLiveDocs())).explain(doc);
+      return ((AllScorer)scorer(context)).explain(doc);
     }
   }
 
@@ -106,15 +106,13 @@
     final float qWeight;
     int doc=-1;
     final FunctionValues vals;
-    final Bits acceptDocs;
 
-    public AllScorer(LeafReaderContext context, Bits acceptDocs, FunctionWeight w, float qWeight) throws IOException {
+    public AllScorer(LeafReaderContext context, FunctionWeight w, float qWeight) throws IOException {
       super(w);
       this.weight = w;
       this.qWeight = qWeight;
       this.reader = context.reader();
       this.maxDoc = reader.maxDoc();
-      this.acceptDocs = acceptDocs;
       vals = func.getValues(weight.context, context);
     }
 
@@ -129,21 +127,16 @@
     // Boost:        foo:myTerm^floatline("myFloatField",1.0,0.0f)
     @Override
     public int nextDoc() throws IOException {
-      for(;;) {
-        ++doc;
-        if (doc>=maxDoc) {
-          return doc=NO_MORE_DOCS;
-        }
-        if (acceptDocs != null && !acceptDocs.get(doc)) continue;
-        return doc;
+      ++doc;
+      if (doc>=maxDoc) {
+        return doc=NO_MORE_DOCS;
       }
+      return doc;
     }
 
     @Override
     public int advance(int target) throws IOException {
-      // this will work even if target==NO_MORE_DOCS
-      doc=target-1;
-      return nextDoc();
+      return slowAdvance(target);
     }
 
     @Override
Index: lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/QueryValueSource.java	(working copy)
@@ -80,7 +80,6 @@
 
 class QueryDocValues extends FloatDocValues {
   final LeafReaderContext readerContext;
-  final Bits acceptDocs;
   final Weight weight;
   final float defVal;
   final Map fcontext;
@@ -99,7 +98,6 @@
     super(vs);
 
     this.readerContext = readerContext;
-    this.acceptDocs = readerContext.reader().getLiveDocs();
     this.defVal = vs.defVal;
     this.q = vs.q;
     this.fcontext = fcontext;
@@ -126,7 +124,7 @@
     try {
       if (doc < lastDocRequested) {
         if (noMatches) return defVal;
-        scorer = weight.scorer(readerContext, acceptDocs);
+        scorer = weight.scorer(readerContext);
         if (scorer==null) {
           noMatches = true;
           return defVal;
@@ -157,7 +155,7 @@
     try {
       if (doc < lastDocRequested) {
         if (noMatches) return false;
-        scorer = weight.scorer(readerContext, acceptDocs);
+        scorer = weight.scorer(readerContext);
         scorerDoc = -1;
         if (scorer==null) {
           noMatches = true;
@@ -215,7 +213,7 @@
             mval.exists = false;
             return;
           }
-          scorer = weight.scorer(readerContext, acceptDocs);
+          scorer = weight.scorer(readerContext);
           scorerDoc = -1;
           if (scorer==null) {
             noMatches = true;
Index: lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java	(working copy)
@@ -72,7 +72,7 @@
         if (terms != null) {
           final TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(indexedBytes)) {
-            docs = termsEnum.postings(null, null);
+            docs = termsEnum.postings(null);
           } else {
             docs = null;
           }
Index: lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java
===================================================================
--- lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java	(revision 1687080)
+++ lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java	(working copy)
@@ -65,7 +65,7 @@
         if (terms != null) {
           final TermsEnum termsEnum = terms.iterator();
           if (termsEnum.seekExact(indexedBytes)) {
-            docs = termsEnum.postings(null, null);
+            docs = termsEnum.postings(null);
           } else {
             docs = null;
           }
Index: lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInBBoxQuery.java	(working copy)
@@ -101,7 +101,7 @@
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer s = scorer(context, context.reader().getLiveDocs());
+        final Scorer s = scorer(context);
         final boolean exists = s != null && s.advance(doc) == doc;
 
         if (exists) {
@@ -113,7 +113,7 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         LeafReader reader = context.reader();
         SortedNumericDocValues sdv = reader.getSortedNumericDocValues(field);
         if (sdv == null) {
@@ -127,7 +127,7 @@
         BKDTreeSortedNumericDocValues treeDV = (BKDTreeSortedNumericDocValues) sdv;
         BKDTreeReader tree = treeDV.getBKDTreeReader();
 
-        DocIdSet result = tree.intersect(acceptDocs, minLat, maxLat, minLon, maxLon, treeDV.delegate);
+        DocIdSet result = tree.intersect(minLat, maxLat, minLon, maxLon, treeDV.delegate);
 
         final DocIdSetIterator disi = result.iterator();
 
Index: lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDPointInPolygonQuery.java	(working copy)
@@ -132,7 +132,7 @@
 
       @Override
       public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer s = scorer(context, context.reader().getLiveDocs());
+        final Scorer s = scorer(context);
         final boolean exists = s != null && s.advance(doc) == doc;
 
         if (exists) {
@@ -144,7 +144,7 @@
       }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         LeafReader reader = context.reader();
         SortedNumericDocValues sdv = reader.getSortedNumericDocValues(field);
         if (sdv == null) {
@@ -160,7 +160,7 @@
         
         // TODO: make this more efficient: as we recurse the BKD tree we should check whether the
         // bbox we are recursing into intersects our shape; Apache SIS may have (non-GPL!) code to do this?
-        DocIdSet result = tree.intersect(acceptDocs, minLat, maxLat, minLon, maxLon,
+        DocIdSet result = tree.intersect(minLat, maxLat, minLon, maxLon,
                                          new BKDTreeReader.LatLonFilter() {
                                            @Override
                                            public boolean accept(double lat, double lon) {
Index: lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/bkdtree/BKDTreeReader.java	(working copy)
@@ -95,11 +95,11 @@
     }
   }
 
-  public DocIdSet intersect(Bits acceptDocs, double latMin, double latMax, double lonMin, double lonMax, SortedNumericDocValues sndv) throws IOException {
-    return intersect(acceptDocs, latMin, latMax, lonMin, lonMax, null, sndv);
+  public DocIdSet intersect(double latMin, double latMax, double lonMin, double lonMax, SortedNumericDocValues sndv) throws IOException {
+    return intersect(latMin, latMax, lonMin, lonMax, null, sndv);
   }
 
-  public DocIdSet intersect(Bits acceptDocs, double latMin, double latMax, double lonMin, double lonMax, LatLonFilter filter, SortedNumericDocValues sndv) throws IOException {
+  public DocIdSet intersect(double latMin, double latMax, double lonMin, double lonMax, LatLonFilter filter, SortedNumericDocValues sndv) throws IOException {
     if (BKDTreeWriter.validLat(latMin) == false) {
       throw new IllegalArgumentException("invalid latMin: " + latMin);
     }
@@ -128,7 +128,7 @@
                                       filter,
                                       sndv);
 
-    int hitCount = intersect(acceptDocs, state, 1,
+    int hitCount = intersect(state, 1,
                              BKDTreeWriter.encodeLat(-90.0),
                              BKDTreeWriter.encodeLat(Math.nextAfter(90.0, Double.POSITIVE_INFINITY)),
                              BKDTreeWriter.encodeLon(-180.0),
@@ -139,7 +139,7 @@
   }
 
   /** Fast path: this is called when the query rect fully encompasses all cells under this node. */
-  private int addAll(Bits acceptDocs, QueryState state, int nodeID) throws IOException {
+  private int addAll(QueryState state, int nodeID) throws IOException {
 
     //long latRange = (long) cellLatMaxEnc - (long) cellLatMinEnc;
     //long lonRange = (long) cellLonMaxEnc - (long) cellLonMinEnc;
@@ -167,18 +167,9 @@
       //System.out.println("    seek to leafFP=" + fp);
       // How many points are stored in this leaf cell:
       int count = state.in.readVInt();
-      if (acceptDocs != null) {
-        for(int i=0;i<count;i++) {
-          int docID = state.in.readInt();
-          if (acceptDocs.get(docID)) {
-            state.bits.set(docID);
-          }
-        }
-      } else {
-        for(int i=0;i<count;i++) {
-          int docID = state.in.readInt();
-          state.bits.set(docID);
-        }
+      for(int i=0;i<count;i++) {
+        int docID = state.in.readInt();
+        state.bits.set(docID);
       }
 
       //bits.or(allLeafDISI);
@@ -195,14 +186,14 @@
       //System.out.println("  splitValue=" + splitValue);
 
       //System.out.println("  addAll: inner");
-      int count = addAll(acceptDocs, state, 2*nodeID);
-      count += addAll(acceptDocs, state, 2*nodeID+1);
+      int count = addAll(state, 2*nodeID);
+      count += addAll(state, 2*nodeID+1);
       //System.out.println("  addAll: return count=" + count);
       return count;
     }
   }
 
-  private int intersect(Bits acceptDocs, QueryState state,
+  private int intersect(QueryState state,
                         int nodeID,
                         int cellLatMinEnc, int cellLatMaxEnc, int cellLonMinEnc, int cellLonMaxEnc)
     throws IOException {
@@ -223,7 +214,7 @@
           return 0;
         } else if (r == Relation.INSIDE) {
           // This cell is fully inside of the query shape: recursively add all points in this cell without filtering
-          return addAll(acceptDocs, state, nodeID);
+          return addAll(state, nodeID);
         } else {
           // The cell crosses the shape boundary, so we fall through and do full filtering
         }
@@ -231,7 +222,7 @@
     } else if (state.latMinEnc <= cellLatMinEnc && state.latMaxEnc >= cellLatMaxEnc && state.lonMinEnc <= cellLonMinEnc && state.lonMaxEnc >= cellLonMaxEnc) {
       // Optimize the case when the query fully contains this cell: we can
       // recursively add all points without checking if they match the query:
-      return addAll(acceptDocs, state, nodeID);
+      return addAll(state, nodeID);
     }
 
     long latRange = (long) cellLatMaxEnc - (long) cellLatMinEnc;
@@ -273,28 +264,26 @@
 
       for(int i=0;i<count;i++) {
         int docID = state.in.readInt();
-        if (acceptDocs == null || acceptDocs.get(docID)) {
-          state.sndv.setDocument(docID);
-          // How many values this doc has:
-          int docValueCount = state.sndv.count();
-          for(int j=0;j<docValueCount;j++) {
-            long enc = state.sndv.valueAt(j);
+        state.sndv.setDocument(docID);
+        // How many values this doc has:
+        int docValueCount = state.sndv.count();
+        for(int j=0;j<docValueCount;j++) {
+          long enc = state.sndv.valueAt(j);
 
-            int latEnc = (int) ((enc>>32) & 0xffffffffL);
-            int lonEnc = (int) (enc & 0xffffffffL);
+          int latEnc = (int) ((enc>>32) & 0xffffffffL);
+          int lonEnc = (int) (enc & 0xffffffffL);
 
-            if (latEnc >= state.latMinEnc &&
-                latEnc < state.latMaxEnc &&
-                lonEnc >= state.lonMinEnc &&
-                lonEnc < state.lonMaxEnc &&
-                (state.latLonFilter == null ||
-                 state.latLonFilter.accept(BKDTreeWriter.decodeLat(latEnc), BKDTreeWriter.decodeLon(lonEnc)))) {
-              state.bits.set(docID);
-              hitCount++;
+          if (latEnc >= state.latMinEnc &&
+              latEnc < state.latMaxEnc &&
+              lonEnc >= state.lonMinEnc &&
+              lonEnc < state.lonMaxEnc &&
+              (state.latLonFilter == null ||
+               state.latLonFilter.accept(BKDTreeWriter.decodeLat(latEnc), BKDTreeWriter.decodeLon(lonEnc)))) {
+            state.bits.set(docID);
+            hitCount++;
 
-              // Stop processing values for this doc:
-              break;
-            }
+            // Stop processing values for this doc:
+            break;
           }
         }
       }
@@ -330,7 +319,7 @@
         // Left node:
         if (state.latMinEnc < splitValue) {
           //System.out.println("  recurse left");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID,
                              cellLatMinEnc, splitValue, cellLonMinEnc, cellLonMaxEnc);
         }
@@ -338,7 +327,7 @@
         // Right node:
         if (state.latMaxEnc >= splitValue) {
           //System.out.println("  recurse right");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID+1,
                              splitValue, cellLatMaxEnc, cellLonMinEnc, cellLonMaxEnc);
         }
@@ -352,7 +341,7 @@
         // Left node:
         if (state.lonMinEnc < splitValue) {
           // System.out.println("  recurse left");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID,
                              cellLatMinEnc, cellLatMaxEnc, cellLonMinEnc, splitValue);
         }
@@ -360,7 +349,7 @@
         // Right node:
         if (state.lonMaxEnc >= splitValue) {
           // System.out.println("  recurse right");
-          count += intersect(acceptDocs, state,
+          count += intersect(state,
                              2*nodeID+1,
                              cellLatMinEnc, cellLatMaxEnc, splitValue, cellLonMaxEnc);
         }
Index: lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java	(working copy)
@@ -63,7 +63,7 @@
   }
 
   @Override
-  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(FieldInfo fieldInfo, BlockTermState termState, PostingsEnum reuse, int flags) throws IOException {
     SingleDocsEnum docsEnum;
 
     if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
@@ -75,7 +75,7 @@
         posEnum = new SinglePostingsEnum();
       }
       IDVersionTermState _termState = (IDVersionTermState) termState;
-      posEnum.reset(_termState.docID, _termState.idVersion, liveDocs);
+      posEnum.reset(_termState.docID, _termState.idVersion);
       return posEnum;
     }
 
@@ -84,7 +84,7 @@
     } else {
       docsEnum = new SingleDocsEnum();
     }
-    docsEnum.reset(((IDVersionTermState) termState).docID, liveDocs);
+    docsEnum.reset(((IDVersionTermState) termState).docID);
 
     return docsEnum;
   }
Index: lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionSegmentTermsEnum.java	(working copy)
@@ -995,7 +995,7 @@
   }
 
   @Override
-  public PostingsEnum postings(Bits skipDocs, PostingsEnum reuse, int flags) throws IOException {
+  public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
     assert !eof;
     //if (DEBUG) {
     //System.out.println("BTTR.docs seg=" + segment);
@@ -1004,7 +1004,7 @@
     //if (DEBUG) {
     //System.out.println("  state=" + currentFrame.state);
     //}
-    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, skipDocs, reuse, flags);
+    return fr.parent.postingsReader.postings(fr.fieldInfo, currentFrame.state, reuse, flags);
   }
 
   @Override
Index: lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SingleDocsEnum.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 class SingleDocsEnum extends PostingsEnum {
@@ -27,18 +26,16 @@
 
   private int doc;
   private int singleDocID;
-  private Bits liveDocs;
 
   /** For reuse */
-  public void reset(int singleDocID, Bits liveDocs) {
+  public void reset(int singleDocID) {
     doc = -1;
-    this.liveDocs = liveDocs;
     this.singleDocID = singleDocID;
   }
 
   @Override
   public int nextDoc() {
-    if (doc == -1 && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
@@ -54,7 +51,7 @@
 
   @Override
   public int advance(int target) {
-    if (doc == -1 && target <= singleDocID && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1 && target <= singleDocID) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
Index: lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/SinglePostingsEnum.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 class SinglePostingsEnum extends PostingsEnum {
@@ -25,7 +24,6 @@
   private int doc;
   private int pos;
   private int singleDocID;
-  private Bits liveDocs;
   private long version;
   private final BytesRef payload;
 
@@ -35,9 +33,8 @@
   }
 
   /** For reuse */
-  public void reset(int singleDocID, long version, Bits liveDocs) {
+  public void reset(int singleDocID, long version) {
     doc = -1;
-    this.liveDocs = liveDocs;
     this.singleDocID = singleDocID;
     this.version = version;
   }
@@ -44,7 +41,7 @@
 
   @Override
   public int nextDoc() {
-    if (doc == -1 && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1) {
       doc = singleDocID;
     } else {
       doc = NO_MORE_DOCS;
@@ -61,7 +58,7 @@
 
   @Override
   public int advance(int target) {
-    if (doc == -1 && target <= singleDocID && (liveDocs == null || liveDocs.get(singleDocID))) {
+    if (doc == -1 && target <= singleDocID) {
       doc = singleDocID;
       pos = -1;
     } else {
Index: lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java	(working copy)
@@ -24,6 +24,7 @@
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Filter;
@@ -106,7 +107,7 @@
         if (currTerm == null) {
           break;
         } else {
-          docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+          docs = termsEnum.postings(docs, PostingsEnum.NONE);
           int doc = docs.nextDoc();
           if (doc != DocIdSetIterator.NO_MORE_DOCS) {
             if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
@@ -126,7 +127,7 @@
         }
       }
     }
-    return new BitDocIdSet(bits, bits.approximateCardinality());
+    return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bits, bits.approximateCardinality()), acceptDocs);
   }
 
   private DocIdSet fastBits(LeafReader reader, Bits acceptDocs) throws IOException {
@@ -144,7 +145,7 @@
         } else {
           if (termsEnum.docFreq() > 1) {
             // unset potential duplicates
-            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE);
+            docs = termsEnum.postings(docs, PostingsEnum.NONE);
             int doc = docs.nextDoc();
             if (doc != DocIdSetIterator.NO_MORE_DOCS) {
               if (keepMode == KeepMode.KM_USE_FIRST_OCCURRENCE) {
@@ -171,7 +172,7 @@
       }
     }
 
-    return new BitDocIdSet(bits);
+    return BitsFilteredDocIdSet.wrap(new BitDocIdSet(bits), acceptDocs);
   }
 
   public String getFieldName() {
Index: lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java
===================================================================
--- lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java	(revision 1687080)
+++ lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java	(working copy)
@@ -381,7 +381,7 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
 
       // Initialize the enums; null for a given slot means that term didn't appear in this reader
       EnumAndScorer[] enums = new EnumAndScorer[idToTerm.size()];
@@ -395,7 +395,7 @@
 
           TermsEnum termsEnum = context.reader().terms(field).iterator();
           termsEnum.seekExact(term, state);
-          enums[ent.getKey()] = new EnumAndScorer(ent.getKey(), termsEnum.postings(acceptDocs, null, PostingsEnum.POSITIONS));
+          enums[ent.getKey()] = new EnumAndScorer(ent.getKey(), termsEnum.postings(null, PostingsEnum.POSITIONS));
         }
       }
 
Index: lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java	(revision 1687080)
+++ lucene/sandbox/src/test/org/apache/lucene/codecs/idversion/TestIDVersionPostingsFormat.java	(working copy)
@@ -330,9 +330,9 @@
           if (VERBOSE) {
             System.out.println("  found in seg=" + termsEnums[seg]);
           }
-          postingsEnums[seg] = termsEnums[seg].postings(liveDocs[seg], postingsEnums[seg], 0);
+          postingsEnums[seg] = termsEnums[seg].postings(postingsEnums[seg], 0);
           int docID = postingsEnums[seg].nextDoc();
-          if (docID != PostingsEnum.NO_MORE_DOCS) {
+          if (docID != PostingsEnum.NO_MORE_DOCS && (liveDocs[seg] == null || liveDocs[seg].get(docID))) {
             lastVersion = ((IDVersionSegmentTermsEnum) termsEnums[seg]).getVersion();
             return docBases[seg] + docID;
           }
Index: lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java	(revision 1687080)
+++ lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java	(working copy)
@@ -155,7 +155,6 @@
       PostingsEnum td = TestUtil.docs(random(), reader,
           KEY_FIELD,
           new BytesRef(url),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
 
@@ -183,7 +182,6 @@
       PostingsEnum td = TestUtil.docs(random(), reader,
           KEY_FIELD,
           new BytesRef(url),
-          MultiFields.getLiveDocs(reader),
           null,
           0);
 
Index: lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
===================================================================
--- lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java	(revision 1687080)
+++ lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java	(working copy)
@@ -268,12 +268,12 @@
 
     Query q1 = DocValuesRangeQuery.newLongRange("dv1", 0L, 100L, random().nextBoolean(), random().nextBoolean());
     Weight w = searcher.createNormalizedWeight(q1, true);
-    Scorer s = w.scorer(ctx, null);
+    Scorer s = w.scorer(ctx);
     assertNotNull(s.asTwoPhaseIterator());
 
     Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(0L), toSortableBytes(100L), random().nextBoolean(), random().nextBoolean());
     w = searcher.createNormalizedWeight(q2, true);
-    s = w.scorer(ctx, null);
+    s = w.scorer(ctx);
     assertNotNull(s.asTwoPhaseIterator());
 
     reader.close();
Index: lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/composite/CompositeVerifyQuery.java	(working copy)
@@ -94,9 +94,9 @@
     return new ConstantScoreWeight(this) {
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
 
-        final Scorer indexQueryScorer = indexQueryWeight.scorer(context, acceptDocs);//pass acceptDocs through
+        final Scorer indexQueryScorer = indexQueryWeight.scorer(context);
         if (indexQueryScorer == null) {
           return null;
         }
Index: lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/composite/IntersectsRPTVerifyQuery.java	(working copy)
@@ -90,10 +90,10 @@
 
     return new ConstantScoreWeight(this) {
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      public Scorer scorer(LeafReaderContext context) throws IOException {
         // Compute approx & exact
         final IntersectsDifferentiatingFilter.IntersectsDifferentiatingVisitor result =
-            intersectsDiffFilter.compute(context, acceptDocs);
+            intersectsDiffFilter.compute(context, null);
         if (result.approxDocIdSet == null) {
           return null;
         }
Index: lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractPrefixTreeFilter.java	(working copy)
@@ -20,11 +20,14 @@
 import java.io.IOException;
 
 import com.spatial4j.core.shape.Shape;
+
+import org.apache.lucene.index.FilterLeafReader.FilterPostingsEnum;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.spatial.prefix.tree.SpatialPrefixTree;
 import org.apache.lucene.util.BitDocIdSet;
@@ -96,15 +99,51 @@
 
     protected void collectDocs(BitSet bitSet) throws IOException {
       assert termsEnum != null;
-      postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-      bitSet.or(postingsEnum);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      bitSet.or(wrap(postingsEnum, acceptDocs));
     }
 
     protected void collectDocs(BitDocIdSet.Builder bitSetBuilder) throws IOException {
       assert termsEnum != null;
-      postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-      bitSetBuilder.or(postingsEnum);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      bitSetBuilder.or(wrap(postingsEnum, acceptDocs));
     }
   }
 
+  /** Filter the given {@link PostingsEnum} with the given {@link Bits}. */
+  private static PostingsEnum wrap(PostingsEnum iterator, Bits acceptDocs) {
+    if (iterator == null || acceptDocs == null) {
+      return iterator;
+    }
+    return new BitsFilteredPostingsEnum(iterator, acceptDocs);
+  }
+
+  /** A {@link PostingsEnum} which is filtered by some random-access bits. */
+  private static class BitsFilteredPostingsEnum extends FilterPostingsEnum {
+
+    private final Bits bits;
+
+    private BitsFilteredPostingsEnum(PostingsEnum in, Bits bits) {
+      super(in);
+      this.bits = bits;
+    }
+
+    private int doNext(int doc) throws IOException {
+      while (doc != NO_MORE_DOCS && bits.get(doc) == false) {
+        doc = in.nextDoc();
+      }
+      return doc;
+    }
+
+    @Override
+    public int nextDoc() throws IOException {
+      return doNext(in.nextDoc());
+    }
+
+    @Override
+    public int advance(int target) throws IOException {
+      return doNext(in.advance(target));
+    }
+
+  }
 }
Index: lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/prefix/ContainsPrefixTreeFilter.java	(working copy)
@@ -218,9 +218,12 @@
     private SmallDocSet collectDocs(Bits acceptContains) throws IOException {
       SmallDocSet set = null;
 
-      postingsEnum = termsEnum.postings(acceptContains, postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
       int docid;
       while ((docid = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+        if (acceptContains != null && acceptContains.get(docid) == false) {
+          continue;
+        }
         if (set == null) {
           int size = termsEnum.docFreq();
           if (size <= 0)
Index: lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeFacetCounter.java	(working copy)
@@ -183,8 +183,11 @@
               return termsEnum.docFreq();
             }
             int count = 0;
-            postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
             while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+              if (acceptDocs != null && acceptDocs.get(postingsEnum.docID()) == false) {
+                continue;
+              }
               count++;
             }
             return count;
@@ -194,8 +197,12 @@
             if (acceptDocs == null) {
               return true;
             }
-            postingsEnum = termsEnum.postings(acceptDocs, postingsEnum, PostingsEnum.NONE);
-            return (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+            int nextDoc = postingsEnum.nextDoc();
+            while (nextDoc != DocIdSetIterator.NO_MORE_DOCS && acceptDocs.get(nextDoc) == false) {
+              nextDoc = postingsEnum.nextDoc();
+            }
+            return nextDoc != DocIdSetIterator.NO_MORE_DOCS;
           }
 
         }.getDocIdSet();
Index: lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java
===================================================================
--- lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java	(revision 1687080)
+++ lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java	(working copy)
@@ -69,7 +69,7 @@
       while (term != null) {
         T shape = readShape(term);
         if( shape != null ) {
-          docs = te.postings(null, docs, PostingsEnum.NONE);
+          docs = te.postings(docs, PostingsEnum.NONE);
           Integer docid = docs.nextDoc();
           while (docid != DocIdSetIterator.NO_MORE_DOCS) {
             idx.add( docid, shape );
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java	(working copy)
@@ -270,7 +270,7 @@
 
       if (matchedTokens.contains(docTerm) || (prefixToken != null && docTerm.startsWith(prefixToken))) {
  
-        PostingsEnum docPosEnum = it.postings(null, null, PostingsEnum.OFFSETS);
+        PostingsEnum docPosEnum = it.postings(null, PostingsEnum.OFFSETS);
         docPosEnum.nextDoc();
 
         // use the first occurrence of the term
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsConsumer.java	(working copy)
@@ -196,7 +196,7 @@
      * Writes all postings (surface form, weight, document id) for <code>term</code>
      */
     public void write(BytesRef term, TermsEnum termsEnum) throws IOException {
-      postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.PAYLOADS);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.PAYLOADS);
       builder.startTerm(term);
       int docFreq = 0;
       while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionScorer.java	(working copy)
@@ -30,10 +30,10 @@
  * appropriate suggester and collecting the results
  * via a collector.
  *
- * {@link #score(LeafCollector, int, int)} is called
+ * {@link #score(LeafCollector, Bits, int, int)} is called
  * for each leaf reader.
  *
- * {@link #accept(int)} and {@link #score(float, float)}
+ * {@link #accept(int,Bits)} and {@link #score(float, float)}
  * is called for every matched completion (i.e. document)
  *
  * @lucene.experimental
@@ -40,7 +40,7 @@
  */
 public class CompletionScorer extends BulkScorer {
   private final NRTSuggester suggester;
-  private final Bits acceptDocs;
+  private final Bits filterDocs;
 
   // values accessed by suggester
   /** weight that created this scorer */
@@ -53,7 +53,7 @@
    * Creates a scorer for a field-specific <code>suggester</code> scoped by <code>acceptDocs</code>
    */
   protected CompletionScorer(final CompletionWeight weight, final NRTSuggester suggester,
-                             final LeafReader reader, final Bits acceptDocs,
+                             final LeafReader reader, final Bits filterDocs,
                              final boolean filtered, final Automaton automaton) throws IOException {
     this.weight = weight;
     this.suggester = suggester;
@@ -60,15 +60,15 @@
     this.reader = reader;
     this.automaton = automaton;
     this.filtered = filtered;
-    this.acceptDocs = acceptDocs;
+    this.filterDocs = filterDocs;
   }
 
   @Override
-  public int score(LeafCollector collector, int min, int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
     if (!(collector instanceof TopSuggestDocsCollector)) {
       throw new IllegalArgumentException("collector is not of type TopSuggestDocsCollector");
     }
-    suggester.lookup(this, ((TopSuggestDocsCollector) collector));
+    suggester.lookup(this, acceptDocs, ((TopSuggestDocsCollector) collector));
     return max;
   }
 
@@ -81,9 +81,12 @@
    * Returns true if a document with <code>docID</code> is accepted,
    * false if the docID maps to a deleted
    * document or has been filtered out
+   * @param liveDocs the {@link Bits} representing live docs, or possibly
+   *                 {@code null} if all docs are live
    */
-  public final boolean accept(int docID) {
-    return acceptDocs == null || acceptDocs.get(docID);
+  public final boolean accept(int docID, Bits liveDocs) {
+    return (filterDocs == null || filterDocs.get(docID))
+        && (liveDocs == null || liveDocs.get(docID));
   }
 
   /**
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionWeight.java	(working copy)
@@ -70,7 +70,7 @@
   }
 
   @Override
-  public BulkScorer bulkScorer(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public BulkScorer bulkScorer(final LeafReaderContext context) throws IOException {
     final LeafReader reader = context.reader();
     final Terms terms;
     final NRTSuggester suggester;
@@ -91,7 +91,7 @@
     DocIdSet docIdSet = null;
     Filter filter = completionQuery.getFilter();
     if (filter != null) {
-      docIdSet = filter.getDocIdSet(context, acceptDocs);
+      docIdSet = filter.getDocIdSet(context, null);
       if (docIdSet == null || docIdSet.iterator() == null) {
         // filter matches no docs in current leave
         return null;
@@ -99,7 +99,7 @@
         throw new IllegalArgumentException("DocIDSet does not provide random access interface");
       }
     }
-    Bits acceptDocBits = (docIdSet != null) ? docIdSet.bits() : acceptDocs;
+    Bits acceptDocBits = (docIdSet != null) ? docIdSet.bits() : null;
     return new CompletionScorer(this, suggester, reader, acceptDocBits, filter != null, automaton);
   }
 
@@ -134,7 +134,7 @@
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+  public Scorer scorer(LeafReaderContext context) throws IOException {
     throw new UnsupportedOperationException();
   }
 
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester.java	(working copy)
@@ -28,6 +28,7 @@
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.fst.ByteSequenceOutputs;
@@ -44,7 +45,7 @@
  * <p>
  * NRTSuggester executes Top N search on a weighted FST specified by a {@link CompletionScorer}
  * <p>
- * See {@link #lookup(CompletionScorer, TopSuggestDocsCollector)} for more implementation
+ * See {@link #lookup(CompletionScorer, Bits, TopSuggestDocsCollector)} for more implementation
  * details.
  * <p>
  * FST Format:
@@ -56,7 +57,7 @@
  * NOTE:
  * <ul>
  *   <li>having too many deletions or using a very restrictive filter can make the search inadmissible due to
- *     over-pruning of potential paths. See {@link CompletionScorer#accept(int)}</li>
+ *     over-pruning of potential paths. See {@link CompletionScorer#accept(int, Bits)}</li>
  *   <li>when matched documents are arbitrarily filtered ({@link CompletionScorer#filtered} set to <code>true</code>,
  *     it is assumed that the filter will roughly filter out half the number of documents that match
  *     the provided automaton</li>
@@ -120,12 +121,12 @@
    * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.
    * {@link CompletionScorer#weight} is used to compute boosts and/or extract context
    * for each matched partial paths. A top N search is executed on {@link #fst} seeded with
-   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int)}
+   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}
    * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight
    * and query boost to filter and score the entry, before being collected via
    * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}
    */
-  public void lookup(final CompletionScorer scorer, final TopSuggestDocsCollector collector) throws IOException {
+  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {
     final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());
     if (liveDocsRatio == -1) {
       return;
@@ -143,7 +144,7 @@
       protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {
         int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);
         int docID = parseDocID(path.cost.output2, payloadSepIndex);
-        if (!scorer.accept(docID)) {
+        if (!scorer.accept(docID, acceptDocs)) {
           return false;
         }
         try {
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java	(revision 1687080)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/document/SuggestIndexSearcher.java	(working copy)
@@ -70,10 +70,10 @@
     query = (CompletionQuery) query.rewrite(getIndexReader());
     Weight weight = query.createWeight(this, collector.needsScores());
     for (LeafReaderContext context : getIndexReader().leaves()) {
-      BulkScorer scorer = weight.bulkScorer(context, context.reader().getLiveDocs());
+      BulkScorer scorer = weight.bulkScorer(context);
       if (scorer != null) {
         try {
-          scorer.score(collector.getLeafCollector(context));
+          scorer.score(collector.getLeafCollector(context), context.reader().getLiveDocs());
         } catch (CollectionTerminatedException e) {
           // collection was terminated prematurely
           // continue with the following leaf
Index: lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java	(working copy)
@@ -187,7 +187,7 @@
             if (hasFreqs) {
               flags = flags | PostingsEnum.FREQS;
             }
-            postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+            postingsEnum = termsEnum.postings(postingsEnum, flags);
           } else {
             flags = PostingsEnum.POSITIONS;
             if (hasPayloads) {
@@ -196,7 +196,7 @@
             if (hasOffsets) {
               flags = flags | PostingsEnum.OFFSETS;
             }
-            postingsEnum = termsEnum.postings(null, postingsEnum, flags);
+            postingsEnum = termsEnum.postings(postingsEnum, flags);
           }
 
           assert postingsEnum != null : "termsEnum=" + termsEnum + " hasPositions=" + hasPositions;
Index: lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java	(working copy)
@@ -47,7 +47,6 @@
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
@@ -284,7 +283,7 @@
             break;
           }
           RAMPostingsWriterImpl postingsWriter = termsConsumer.startTerm(term);
-          postingsEnum = termsEnum.postings(null, postingsEnum, enumFlags);
+          postingsEnum = termsEnum.postings(postingsEnum, enumFlags);
 
           int docFreq = 0;
           long totalTermFreq = 0;
@@ -470,8 +469,8 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) {
-      return new RAMDocsEnum(ramField.termToDocs.get(current), liveDocs);
+    public PostingsEnum postings(PostingsEnum reuse, int flags) {
+      return new RAMDocsEnum(ramField.termToDocs.get(current));
     }
 
   }
@@ -478,14 +477,12 @@
 
   private static class RAMDocsEnum extends PostingsEnum {
     private final RAMTerm ramTerm;
-    private final Bits liveDocs;
     private RAMDoc current;
     int upto = -1;
     int posUpto = 0;
 
-    public RAMDocsEnum(RAMTerm ramTerm, Bits liveDocs) {
+    public RAMDocsEnum(RAMTerm ramTerm) {
       this.ramTerm = ramTerm;
-      this.liveDocs = liveDocs;
     }
 
     @Override
@@ -496,17 +493,13 @@
     // TODO: override bulk read, for better perf
     @Override
     public int nextDoc() {
-      while(true) {
-        upto++;
-        if (upto < ramTerm.docs.size()) {
-          current = ramTerm.docs.get(upto);
-          if (liveDocs == null || liveDocs.get(current.docID)) {
-            posUpto = 0;
-            return current.docID;
-          }
-        } else {
-          return NO_MORE_DOCS;
-        }
+      upto++;
+      if (upto < ramTerm.docs.size()) {
+        current = ramTerm.docs.get(upto);
+        posUpto = 0;
+        return current.docID;
+      } else {
+        return NO_MORE_DOCS;
       }
     }
 
Index: lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/index/AssertingLeafReader.java	(working copy)
@@ -143,7 +143,7 @@
     }
 
     @Override
-    public PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       assertThread("Terms enums", creationThread);
       assert state == State.POSITIONED: "docs(...) called on unpositioned TermsEnum";
 
@@ -154,7 +154,7 @@
       } else {
         actualReuse = null;
       }
-      PostingsEnum docs = super.postings(liveDocs, actualReuse, flags);
+      PostingsEnum docs = super.postings(actualReuse, flags);
       assert docs != null;
       if (docs == actualReuse) {
         // codec reused, reset asserting state
Index: lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase.java	(working copy)
@@ -176,8 +176,8 @@
   }
 
   protected static void checkReuse(TermsEnum termsEnum, int firstFlags, int secondFlags, boolean shouldReuse) throws IOException {
-    PostingsEnum postings1 = termsEnum.postings(null, null, firstFlags);
-    PostingsEnum postings2 = termsEnum.postings(null, postings1, secondFlags);
+    PostingsEnum postings1 = termsEnum.postings(null, firstFlags);
+    PostingsEnum postings2 = termsEnum.postings(postings1, secondFlags);
     if (shouldReuse)
       assertSame("Expected PostingsEnum " + postings1.getClass().getName() + " to be reused", postings1, postings2);
     else
@@ -247,7 +247,7 @@
     LeafReader ar = getOnlySegmentReader(ir);
     TermsEnum termsEnum = ar.terms("field").iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("value")));
-    PostingsEnum docsEnum = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsEnum = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(0, docsEnum.nextDoc());
     assertEquals(1, docsEnum.freq());
     assertEquals(1, docsEnum.nextDoc());
@@ -270,7 +270,7 @@
     LeafReader ar = getOnlySegmentReader(ir);
     TermsEnum termsEnum = ar.terms("field").iterator();
     assertTrue(termsEnum.seekExact(new BytesRef("value")));
-    PostingsEnum docsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(0, docsEnum.nextDoc());
     assertEquals(1, docsEnum.freq());
     assertEquals(1, docsEnum.nextDoc());
@@ -306,7 +306,7 @@
       TermsEnum termsEnum = terms.iterator();
       BytesRef term = termsEnum.next();
       if (term != null) {
-        PostingsEnum postingsEnum = termsEnum.postings(null, null);
+        PostingsEnum postingsEnum = termsEnum.postings(null);
         assertTrue(postingsEnum.nextDoc() == PostingsEnum.NO_MORE_DOCS);
       }
     }
@@ -398,9 +398,9 @@
                       // TODO: also sometimes ask for payloads/offsets?
                       boolean noPositions = random().nextBoolean();
                       if (noPositions) {
-                        docs = termsEnum.postings(null, docs, PostingsEnum.FREQS);
+                        docs = termsEnum.postings(docs, PostingsEnum.FREQS);
                       } else {
-                        docs = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+                        docs = termsEnum.postings(null, PostingsEnum.POSITIONS);
                       }
                       int docFreq = 0;
                       long totalTermFreq = 0;
@@ -447,9 +447,9 @@
                         // TODO: also sometimes ask for payloads/offsets?
                         boolean noPositions = random().nextBoolean();
                         if (noPositions) {
-                          docs = termsEnum.postings(null, docs, PostingsEnum.FREQS);
+                          docs = termsEnum.postings(docs, PostingsEnum.FREQS);
                         } else {
-                          docs = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+                          docs = termsEnum.postings(null, PostingsEnum.POSITIONS);
                         }
 
                         int docFreq = 0;
@@ -579,7 +579,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -590,13 +590,13 @@
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       assertEquals(1, postings.freq());
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       assertReused("foo", postings, postings2);
       // and it had better work
@@ -637,7 +637,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -647,7 +647,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -654,7 +654,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -666,7 +666,7 @@
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       if (flag != NONE) {
@@ -674,7 +674,7 @@
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       assertReused("foo", postings, postings2);
       // and it had better work
@@ -715,7 +715,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -725,7 +725,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -732,7 +732,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -758,7 +758,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -790,7 +790,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -820,7 +820,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -849,7 +849,7 @@
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -895,7 +895,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -905,7 +905,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -912,7 +912,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -940,7 +940,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -976,7 +976,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1008,7 +1008,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1037,7 +1037,7 @@
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1080,7 +1080,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -1090,7 +1090,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1097,7 +1097,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -1125,7 +1125,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1158,7 +1158,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1190,7 +1190,7 @@
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1221,7 +1221,7 @@
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1266,7 +1266,7 @@
     // termsenum reuse (FREQS)
     TermsEnum termsEnum = getOnlySegmentReader(reader).terms("foo").iterator();
     termsEnum.seekExact(new BytesRef("bar"));
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     assertReused("foo", postings, postings2);
     // and it had better work
@@ -1276,7 +1276,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1283,7 +1283,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     assertReused("foo", docsOnly, docsOnly2);
     // and it had better work
@@ -1313,7 +1313,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1350,7 +1350,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1384,7 +1384,7 @@
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
@@ -1415,7 +1415,7 @@
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertReused("foo", docsAndPositionsEnum, docsAndPositionsEnum2);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.java	(working copy)
@@ -450,12 +450,8 @@
       assertEquals(sortedTerms[i], termsEnum.term());
       assertEquals(1, termsEnum.docFreq());
 
-      final FixedBitSet bits = new FixedBitSet(1);
-      PostingsEnum postingsEnum = termsEnum.postings(bits, random().nextBoolean() ? null : this.docsEnum.get());
-      assertEquals(PostingsEnum.NO_MORE_DOCS, postingsEnum.nextDoc());
-      bits.set(0);
-
-      postingsEnum = termsEnum.postings(random().nextBoolean() ? bits : null, random().nextBoolean() ? null : postingsEnum);
+      PostingsEnum postingsEnum = termsEnum.postings(null);
+      postingsEnum = termsEnum.postings(random().nextBoolean() ? null : postingsEnum);
       assertNotNull(postingsEnum);
       assertEquals(0, postingsEnum.nextDoc());
       assertEquals(0, postingsEnum.docID());
@@ -463,14 +459,8 @@
       assertEquals(PostingsEnum.NO_MORE_DOCS, postingsEnum.nextDoc());
       this.docsEnum.set(postingsEnum);
 
-      bits.clear(0);
-      PostingsEnum docsAndPositionsEnum = termsEnum.postings(bits, random().nextBoolean() ? null : this.docsEnum.get(), PostingsEnum.POSITIONS);
-      if (terms.hasPositions()) {
-        assertEquals(PostingsEnum.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-      }
-      bits.set(0);
-
-      docsAndPositionsEnum = termsEnum.postings(random().nextBoolean() ? bits : null, random().nextBoolean() ? null : docsAndPositionsEnum, PostingsEnum.POSITIONS);
+      PostingsEnum docsAndPositionsEnum = termsEnum.postings(null);
+      docsAndPositionsEnum = termsEnum.postings(random().nextBoolean() ? null : docsAndPositionsEnum, PostingsEnum.POSITIONS);
       if (terms.hasPositions() || terms.hasOffsets()) {
         assertEquals(0, docsAndPositionsEnum.nextDoc());
         final int freq = docsAndPositionsEnum.freq();
@@ -778,7 +768,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple use (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -785,7 +775,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -794,7 +784,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -801,7 +791,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -812,7 +802,7 @@
     
     // asking for any flags: ok
     for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {
-      postings = termsEnum.postings(null, null, flag);
+      postings = termsEnum.postings(null, flag);
       assertEquals(-1, postings.docID());
       assertEquals(0, postings.nextDoc());
       if (flag != NONE) {
@@ -820,7 +810,7 @@
       }
       assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
       // reuse that too
-      postings2 = termsEnum.postings(null, postings, flag);
+      postings2 = termsEnum.postings(postings, flag);
       assertNotNull(postings2);
       // and it had better work
       assertEquals(-1, postings2.docID());
@@ -859,7 +849,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple use (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -866,7 +856,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -875,7 +865,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -882,7 +872,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -892,7 +882,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -907,7 +897,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -922,7 +912,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads, offsets, etc don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -938,7 +928,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -952,7 +942,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -967,7 +957,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -981,7 +971,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -995,7 +985,7 @@
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1038,7 +1028,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple usage (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -1045,7 +1035,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1054,7 +1044,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1061,7 +1051,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1071,7 +1061,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1088,7 +1078,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1105,7 +1095,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -1123,7 +1113,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1139,7 +1129,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1154,7 +1144,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1168,7 +1158,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1182,7 +1172,7 @@
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1224,7 +1214,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // simple usage (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -1231,7 +1221,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1240,7 +1230,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1247,7 +1237,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1257,7 +1247,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1274,7 +1264,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1291,7 +1281,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads don't cause an error if they aren't there
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     // but make sure they work
     assertEquals(-1, docsAndPositionsEnum.docID());
@@ -1309,7 +1299,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1325,7 +1315,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1340,7 +1330,7 @@
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1354,7 +1344,7 @@
     assertNull(docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1368,7 +1358,7 @@
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertNull(docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1410,7 +1400,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // sugar method (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -1417,7 +1407,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1426,7 +1416,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1433,7 +1423,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1443,7 +1433,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1460,7 +1450,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1477,7 +1467,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1492,7 +1482,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1506,7 +1496,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1523,7 +1513,7 @@
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1539,7 +1529,7 @@
     assertTrue(docsAndPositionsEnum2.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum2.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1553,7 +1543,7 @@
     assertEquals(-1, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1596,7 +1586,7 @@
     assertEquals(new BytesRef("bar"), termsEnum.next());
     
     // sugar method (FREQS)
-    PostingsEnum postings = termsEnum.postings(null, null);
+    PostingsEnum postings = termsEnum.postings(null);
     assertEquals(-1, postings.docID());
     assertEquals(0, postings.nextDoc());
     assertEquals(2, postings.freq());
@@ -1603,7 +1593,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());
     
     // termsenum reuse (FREQS)
-    PostingsEnum postings2 = termsEnum.postings(null, postings);
+    PostingsEnum postings2 = termsEnum.postings(postings);
     assertNotNull(postings2);
     // and it had better work
     assertEquals(-1, postings2.docID());
@@ -1612,7 +1602,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());
     
     // asking for docs only: ok
-    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);
+    PostingsEnum docsOnly = termsEnum.postings(null, PostingsEnum.NONE);
     assertEquals(-1, docsOnly.docID());
     assertEquals(0, docsOnly.nextDoc());
     // we don't define what it is, but if its something else, we should look into it?
@@ -1619,7 +1609,7 @@
     assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());
     // reuse that too
-    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);
+    PostingsEnum docsOnly2 = termsEnum.postings(docsOnly, PostingsEnum.NONE);
     assertNotNull(docsOnly2);
     // and it had better work
     assertEquals(-1, docsOnly2.docID());
@@ -1629,7 +1619,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());
     
     // asking for positions, ok
-    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
     assertEquals(2, docsAndPositionsEnum.freq());
@@ -1648,7 +1638,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     
     // now reuse the positions
-    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.POSITIONS);
+    PostingsEnum docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.POSITIONS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1667,7 +1657,7 @@
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
     // payloads
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.PAYLOADS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1684,7 +1674,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.PAYLOADS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.PAYLOADS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1700,7 +1690,7 @@
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum2.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1717,7 +1707,7 @@
     assertTrue(docsAndPositionsEnum.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
     // reuse
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
@@ -1733,7 +1723,7 @@
     assertTrue(docsAndPositionsEnum2.getPayload() == null || new BytesRef("pay2").equals(docsAndPositionsEnum2.getPayload()));
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum2.nextDoc());
     
-    docsAndPositionsEnum = termsEnum.postings(null, null, PostingsEnum.ALL);
+    docsAndPositionsEnum = termsEnum.postings(null, PostingsEnum.ALL);
     assertNotNull(docsAndPositionsEnum);
     assertEquals(-1, docsAndPositionsEnum.docID());
     assertEquals(0, docsAndPositionsEnum.nextDoc());
@@ -1747,7 +1737,7 @@
     assertEquals(7, docsAndPositionsEnum.endOffset());
     assertEquals(new BytesRef("pay2"), docsAndPositionsEnum.getPayload());
     assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsAndPositionsEnum.nextDoc());
-    docsAndPositionsEnum2 = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.ALL);
+    docsAndPositionsEnum2 = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.ALL);
     assertEquals(-1, docsAndPositionsEnum2.docID());
     assertEquals(0, docsAndPositionsEnum2.nextDoc());
     assertEquals(2, docsAndPositionsEnum2.freq());
Index: lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup.java	(working copy)
@@ -78,9 +78,10 @@
   public int lookup(BytesRef id) throws IOException {
     for(int seg=0;seg<numSegs;seg++) {
       if (termsEnums[seg].seekExact(id)) {
-        postingsEnums[seg] = termsEnums[seg].postings(liveDocs[seg], postingsEnums[seg], 0);
+        postingsEnums[seg] = termsEnums[seg].postings(postingsEnums[seg], 0);
         int docID = postingsEnums[seg].nextDoc();
-        if (docID != PostingsEnum.NO_MORE_DOCS) {
+        if (docID != PostingsEnum.NO_MORE_DOCS
+            && (liveDocs[seg] == null || liveDocs[seg].get(docID))) {
           return docBases[seg] + docID;
         }
         assert hasDeletions;
Index: lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/index/RandomPostingsTester.java	(working copy)
@@ -40,9 +40,7 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FlushInfo;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.StringHelper;
@@ -99,8 +97,6 @@
 
   private FieldInfos fieldInfos;
 
-  private FixedBitSet globalLiveDocs;
-
   List<FieldAndTerm> allTerms;
   private int maxDoc;
 
@@ -169,7 +165,7 @@
 
         // NOTE: sort of silly: we enum all the docs just to
         // get the maxDoc
-        PostingsEnum postingsEnum = getSeedPostings(term, termSeed, false, globalLiveDocs, IndexOptions.DOCS, true);
+        PostingsEnum postingsEnum = getSeedPostings(term, termSeed, IndexOptions.DOCS, true);
         int doc;
         int lastDoc = 0;
         while((doc = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
@@ -190,14 +186,6 @@
     // It's the count, not the last docID:
     maxDoc++;
 
-    globalLiveDocs = new FixedBitSet(maxDoc);
-    double liveRatio = random.nextDouble();
-    for(int i=0;i<maxDoc;i++) {
-      if (random.nextDouble() <= liveRatio) {
-        globalLiveDocs.set(i);
-      }
-    }
-
     allTerms = new ArrayList<>();
     for(Map.Entry<String,SortedMap<BytesRef,SeedAndOrd>> fieldEnt : fields.entrySet()) {
       String field = fieldEnt.getKey();
@@ -212,7 +200,7 @@
     }
   }
 
-  public static SeedPostings getSeedPostings(String term, long seed, boolean withLiveDocs, Bits globalLiveDocs, IndexOptions options, boolean allowPayloads) {
+  public static SeedPostings getSeedPostings(String term, long seed, IndexOptions options, boolean allowPayloads) {
     int minDocFreq, maxDocFreq;
     if (term.startsWith("big_")) {
       minDocFreq = LuceneTestCase.RANDOM_MULTIPLIER * 50000;
@@ -228,7 +216,7 @@
       maxDocFreq = 3;
     }
 
-    return new SeedPostings(seed, minDocFreq, maxDocFreq, withLiveDocs ? globalLiveDocs : null, options, allowPayloads);
+    return new SeedPostings(seed, minDocFreq, maxDocFreq, options, allowPayloads);
   }
 
   /** Given the same random seed this always enumerates the
@@ -242,9 +230,7 @@
     private final int maxDocSpacing;
     private final int payloadSize;
     private final boolean fixedPayloads;
-    private final Bits liveDocs;
     private final BytesRef payload;
-    private final IndexOptions options;
     private final boolean doPositions;
     private final boolean allowPayloads;
 
@@ -259,11 +245,10 @@
     private int posSpacing;
     private int posUpto;
 
-    public SeedPostings(long seed, int minDocFreq, int maxDocFreq, Bits liveDocs, IndexOptions options, boolean allowPayloads) {
+    public SeedPostings(long seed, int minDocFreq, int maxDocFreq, IndexOptions options, boolean allowPayloads) {
       random = new Random(seed);
       docRandom = new Random(random.nextLong());
       docFreq = TestUtil.nextInt(random, minDocFreq, maxDocFreq);
-      this.liveDocs = liveDocs;
       this.allowPayloads = allowPayloads;
 
       // TODO: more realistic to inversely tie this to numDocs:
@@ -279,7 +264,6 @@
       fixedPayloads = random.nextBoolean();
       byte[] payloadBytes = new byte[payloadSize];
       payload = new BytesRef(payloadBytes);
-      this.options = options;
       doPositions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS.compareTo(options) <= 0;
     }
 
@@ -287,9 +271,7 @@
     public int nextDoc() {
       while(true) {
         _nextDoc();
-        if (liveDocs == null || docID == NO_MORE_DOCS || liveDocs.get(docID)) {
-          return docID;
-        }
+        return docID;
       }
     }
 
@@ -601,10 +583,7 @@
     }
 
     @Override
-    public final PostingsEnum postings(Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
-      if (liveDocs != null) {
-        throw new IllegalArgumentException("liveDocs must be null");
-      }
+    public final PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
       if (PostingsEnum.featureRequested(flags, PostingsEnum.POSITIONS)) {
         if (maxAllowed.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {
           return null;
@@ -619,7 +598,7 @@
       if (PostingsEnum.featureRequested(flags, PostingsEnum.FREQS) && maxAllowed.compareTo(IndexOptions.DOCS_AND_FREQS) < 0) {
         return null;
       }
-      return getSeedPostings(current.getKey().utf8ToString(), current.getValue().seed, false, null, maxAllowed, allowPayloads);
+      return getSeedPostings(current.getKey().utf8ToString(), current.getValue().seed, maxAllowed, allowPayloads);
     }
   }
 
@@ -723,28 +702,11 @@
     // expected term:
     assertEquals(term, termsEnum.term());
 
-    // 50% of the time time pass liveDocs:
-    boolean useLiveDocs = options.contains(Option.LIVE_DOCS) && random.nextBoolean();
-    Bits liveDocs;
-    if (useLiveDocs) {
-      liveDocs = globalLiveDocs;
-      if (LuceneTestCase.VERBOSE) {
-        System.out.println("  use liveDocs: " + globalLiveDocs.length());
-      }
-    } else {
-      liveDocs = null;
-      if (LuceneTestCase.VERBOSE) {
-        System.out.println("  no liveDocs");
-      }
-    }
-
     FieldInfo fieldInfo = currentFieldInfos.fieldInfo(field);
 
     // NOTE: can be empty list if we are using liveDocs:
     SeedPostings expected = getSeedPostings(term.utf8ToString(), 
                                             fields.get(field).get(term).seed,
-                                            useLiveDocs,
-                                            globalLiveDocs,
                                             maxIndexOptions,
                                             true);
     assertEquals(expected.docFreq, termsEnum.docFreq());
@@ -787,7 +749,7 @@
           System.out.println("  get DocsEnum (but we won't check positions) flags=" + flags);
         }
 
-        threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, flags);
+        threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, flags);
         postingsEnum = threadState.reusePostingsEnum;
       } else {
         if (LuceneTestCase.VERBOSE) {
@@ -796,7 +758,7 @@
         if (options.contains(Option.REUSE_ENUMS) && random.nextInt(10) < 9) {
           prevPostingsEnum = threadState.reusePostingsEnum;
         }
-        threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, doCheckFreqs ? PostingsEnum.FREQS : PostingsEnum.NONE);
+        threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, doCheckFreqs ? PostingsEnum.FREQS : PostingsEnum.NONE);
         postingsEnum = threadState.reusePostingsEnum;
       }
     } else {
@@ -816,7 +778,7 @@
         System.out.println("  get DocsEnum flags=" + flags);
       }
 
-      threadState.reusePostingsEnum = termsEnum.postings(liveDocs, prevPostingsEnum, flags);
+      threadState.reusePostingsEnum = termsEnum.postings(prevPostingsEnum, flags);
       postingsEnum = threadState.reusePostingsEnum;
     }
 
Index: lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/AssertingBulkScorer.java	(working copy)
@@ -21,6 +21,7 @@
 import java.util.Random;
 
 import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.util.Bits;
 
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 
@@ -55,28 +56,28 @@
   }
 
   @Override
-  public void score(LeafCollector collector) throws IOException {
+  public void score(LeafCollector collector, Bits acceptDocs) throws IOException {
     assert max == 0;
     collector = new AssertingLeafCollector(random, collector, 0, PostingsEnum.NO_MORE_DOCS);
     if (random.nextBoolean()) {
       try {
-        final int next = score(collector, 0, PostingsEnum.NO_MORE_DOCS);
+        final int next = score(collector, acceptDocs, 0, PostingsEnum.NO_MORE_DOCS);
         assert next == DocIdSetIterator.NO_MORE_DOCS;
       } catch (UnsupportedOperationException e) {
-        in.score(collector);
+        in.score(collector, acceptDocs);
       }
     } else {
-      in.score(collector);
+      in.score(collector, acceptDocs);
     }
   }
 
   @Override
-  public int score(LeafCollector collector, int min, final int max) throws IOException {
+  public int score(LeafCollector collector, Bits acceptDocs, int min, final int max) throws IOException {
     assert min >= this.max: "Scoring backward: min=" + min + " while previous max was max=" + this.max;
     assert min <= max : "max must be greater than min, got min=" + min + ", and max=" + max;
     this.max = max;
     collector = new AssertingLeafCollector(random, collector, min, max);
-    final int next = in.score(collector, min, max);
+    final int next = in.score(collector, acceptDocs, min, max);
     assert next >= max;
     if (max >= maxDoc || next >= maxDoc) {
       assert next == DocIdSetIterator.NO_MORE_DOCS;
Index: lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/AssertingScorer.java	(working copy)
@@ -39,7 +39,7 @@
   final boolean needsScores;
 
   IteratorState state = IteratorState.START;
-  int doc = -1;
+  int doc;
 
   private AssertingScorer(Random random, Scorer in, boolean needsScores) {
     super(in.weight);
@@ -46,6 +46,7 @@
     this.random = random;
     this.in = in;
     this.needsScores = needsScores;
+    this.doc = in.docID();
   }
 
   public Scorer getIn() {
@@ -90,7 +91,6 @@
 
   @Override
   public int docID() {
-    assert state != IteratorState.APPROXIMATING : "calling docId() on the Scorer while the match has not been confirmed";
     return in.docID();
   }
 
@@ -159,7 +159,7 @@
           state = IteratorState.APPROXIMATING;
         }
         assert inApproximation.docID() == nextDoc;
-        return nextDoc;
+        return doc = nextDoc;
       }
 
       @Override
@@ -174,7 +174,7 @@
           state = IteratorState.APPROXIMATING;
         }
         assert inApproximation.docID() == advanced;
-        return advanced;
+        return doc = advanced;
       }
 
       @Override
Index: lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/AssertingWeight.java	(working copy)
@@ -23,7 +23,6 @@
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.util.Bits;
 
 class AssertingWeight extends Weight {
 
@@ -59,15 +58,15 @@
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    final Scorer inScorer = in.scorer(context, acceptDocs);
+  public Scorer scorer(LeafReaderContext context) throws IOException {
+    final Scorer inScorer = in.scorer(context);
     assert inScorer == null || inScorer.docID() == -1;
     return AssertingScorer.wrap(new Random(random.nextLong()), inScorer, needsScores);
   }
 
   @Override
-  public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    BulkScorer inScorer = in.bulkScorer(context, acceptDocs);
+  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+    BulkScorer inScorer = in.bulkScorer(context);
     if (inScorer == null) {
       return null;
     }
Index: lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/BulkScorerWrapperScorer.java	(working copy)
@@ -63,7 +63,7 @@
           scores[bufferLength] = scorer.score();
           bufferLength += 1;
         }
-      }, min, max);
+      }, null, min, max);
     }
     i = -1;
   }
Index: lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils.java	(working copy)
@@ -341,7 +341,7 @@
               if (scorer == null) {
                 Weight w = s.createNormalizedWeight(q, true);
                 LeafReaderContext context = readerContextArray.get(leafPtr);
-                scorer = w.scorer(context, context.reader().getLiveDocs());
+                scorer = w.scorer(context);
               }
               
               int op = order[(opidx[0]++) % order.length];
@@ -405,9 +405,16 @@
               indexSearcher.setSimilarity(s.getSimilarity(true));
               Weight w = indexSearcher.createNormalizedWeight(q, true);
               LeafReaderContext ctx = (LeafReaderContext)indexSearcher.getTopReaderContext();
-              Scorer scorer = w.scorer(ctx, ctx.reader().getLiveDocs());
+              Scorer scorer = w.scorer(ctx);
               if (scorer != null) {
-                boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+                boolean more = false;
+                final Bits liveDocs = context.reader().getLiveDocs();
+                for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+                  if (liveDocs == null || liveDocs.get(d)) {
+                    more = true;
+                    break;
+                  }
+                }
                 Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
               }
               leafPtr++;
@@ -427,9 +434,16 @@
           indexSearcher.setSimilarity(s.getSimilarity(true));
           Weight w = indexSearcher.createNormalizedWeight(q, true);
           LeafReaderContext ctx = previousReader.getContext();
-          Scorer scorer = w.scorer(ctx, ctx.reader().getLiveDocs());
+          Scorer scorer = w.scorer(ctx);
           if (scorer != null) {
-            boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+            boolean more = false;
+            final Bits liveDocs = lastReader[0].getLiveDocs();
+            for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+              if (liveDocs == null || liveDocs.get(d)) {
+                more = true;
+                break;
+              }
+            }
             Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
           }
         }
@@ -446,7 +460,6 @@
     s.search(q,new SimpleCollector() {
       private Scorer scorer;
       private int leafPtr;
-      private Bits liveDocs;
       @Override
       public void setScorer(Scorer scorer) {
         this.scorer = scorer;
@@ -458,7 +471,7 @@
           long startMS = System.currentTimeMillis();
           for (int i=lastDoc[0]+1; i<=doc; i++) {
             Weight w = s.createNormalizedWeight(q, true);
-            Scorer scorer = w.scorer(context.get(leafPtr), liveDocs);
+            Scorer scorer = w.scorer(context.get(leafPtr));
             Assert.assertTrue("query collected "+doc+" but advance("+i+") says no more docs!",scorer.advance(i) != DocIdSetIterator.NO_MORE_DOCS);
             Assert.assertEquals("query collected "+doc+" but advance("+i+") got to "+scorer.docID(),doc,scorer.docID());
             float advanceScore = scorer.score();
@@ -491,9 +504,16 @@
           IndexSearcher indexSearcher = LuceneTestCase.newSearcher(previousReader);
           indexSearcher.setSimilarity(s.getSimilarity(true));
           Weight w = indexSearcher.createNormalizedWeight(q, true);
-          Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext(), previousReader.getLiveDocs());
+          Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext());
           if (scorer != null) {
-            boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+            boolean more = false;
+            final Bits liveDocs = context.reader().getLiveDocs();
+            for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+              if (liveDocs == null || liveDocs.get(d)) {
+                more = true;
+                break;
+              }
+            }
             Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
           }
           leafPtr++;
@@ -501,7 +521,6 @@
 
         lastReader[0] = context.reader();
         lastDoc[0] = -1;
-        liveDocs = context.reader().getLiveDocs();
       }
     });
 
@@ -512,9 +531,16 @@
       IndexSearcher indexSearcher = LuceneTestCase.newSearcher(previousReader);
       indexSearcher.setSimilarity(s.getSimilarity(true));
       Weight w = indexSearcher.createNormalizedWeight(q, true);
-      Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext(), previousReader.getLiveDocs());
+      Scorer scorer = w.scorer((LeafReaderContext)indexSearcher.getTopReaderContext());
       if (scorer != null) {
-        boolean more = scorer.advance(lastDoc[0] + 1) != DocIdSetIterator.NO_MORE_DOCS;
+        boolean more = false;
+        final Bits liveDocs = lastReader[0].getLiveDocs();
+        for (int d = scorer.advance(lastDoc[0] + 1); d != DocIdSetIterator.NO_MORE_DOCS; d = scorer.nextDoc()) {
+          if (liveDocs == null || liveDocs.get(d)) {
+            more = true;
+            break;
+          }
+        }
         Assert.assertFalse("query's last doc was "+ lastDoc[0] +" but advance("+(lastDoc[0]+1)+") got to "+scorer.docID(),more);
       }
     }
@@ -524,8 +550,8 @@
   public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {
     Weight weight = searcher.createNormalizedWeight(query, true);
     for (LeafReaderContext context : searcher.getIndexReader().leaves()) {
-      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());
-      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());
+      final Scorer scorer = weight.scorer(context);
+      final BulkScorer bulkScorer = weight.bulkScorer(context);
       if (scorer == null && bulkScorer == null) {
         continue;
       } else if (bulkScorer == null) {
@@ -554,7 +580,7 @@
             Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);
             scorer.nextDoc();
           }
-        }, min, max);
+        }, null, min, max);
         assert max <= next;
         assert next <= scorer.docID();
         upTo = max;
@@ -569,7 +595,7 @@
               // no more matches
               assert false;
             }
-          }, upTo, DocIdSetIterator.NO_MORE_DOCS);
+          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);
           break;
         }
       }
Index: lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/RandomApproximationQuery.java	(working copy)
@@ -113,8 +113,8 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      final Scorer scorer = weight.scorer(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      final Scorer scorer = weight.scorer(context);
       if (scorer == null) {
         return null;
       }
Index: lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/ScorerIndexSearcher.java	(working copy)
@@ -23,6 +23,7 @@
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.util.Bits;
 
 /**
  * An {@link IndexSearcher} that always uses the {@link Scorer} API, never {@link BulkScorer}.
@@ -48,12 +49,15 @@
       // we force the use of Scorer (not BulkScorer) to make sure
       // that the scorer passed to LeafCollector.setScorer supports
       // Scorer.getChildren
-      Scorer scorer = weight.scorer(ctx, ctx.reader().getLiveDocs());
+      Scorer scorer = weight.scorer(ctx);
       if (scorer != null) {
         final LeafCollector leafCollector = collector.getLeafCollector(ctx);
         leafCollector.setScorer(scorer);
+        final Bits liveDocs = ctx.reader().getLiveDocs();
         for (int doc = scorer.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = scorer.nextDoc()) {
-          leafCollector.collect(doc);
+          if (liveDocs == null || liveDocs.get(doc)) {
+            leafCollector.collect(doc);
+          }
         }
       }
     }
Index: lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/SearchEquivalenceTestBase.java	(working copy)
@@ -74,7 +74,7 @@
     doc.add(field);
     
     // index some docs
-    int numDocs = TEST_NIGHTLY ? atLeast(1000) : atLeast(100);
+    int numDocs = atLeast(20); //nocommit TEST_NIGHTLY ? atLeast(1000) : atLeast(100);
     for (int i = 0; i < numDocs; i++) {
       id.setStringValue(Integer.toString(i));
       field.setStringValue(randomFieldContents());
@@ -190,7 +190,7 @@
       return new DocIdSet() {
         @Override
         public DocIdSetIterator iterator() throws IOException {
-          return weight.scorer(privateContext, acceptDocs);
+          return weight.scorer(privateContext);
         }
 
         @Override
Index: lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java	(working copy)
@@ -23,7 +23,6 @@
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Scorer;
-import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
 import java.util.Map;
@@ -52,8 +51,8 @@
   }
 
   @Override
-  public Spans getSpans(LeafReaderContext context, Bits liveDocs, Postings requiredPostings) throws IOException {
-    Spans spans = in.getSpans(context, liveDocs, requiredPostings);
+  public Spans getSpans(LeafReaderContext context, Postings requiredPostings) throws IOException {
+    Spans spans = in.getSpans(context, requiredPostings);
     if (spans == null)
       return null;
     return new AssertingSpans(spans);
@@ -75,8 +74,8 @@
   }
 
   @Override
-  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    return in.scorer(context, acceptDocs);
+  public Scorer scorer(LeafReaderContext context) throws IOException {
+    return in.scorer(context);
   }
 
   @Override
Index: lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java	(working copy)
@@ -2025,7 +2025,6 @@
    */
   public void assertTermsEnumEquals(String info, IndexReader leftReader, TermsEnum leftTermsEnum, TermsEnum rightTermsEnum, boolean deep) throws IOException {
     BytesRef term;
-    Bits randomBits = new RandomBits(leftReader.maxDoc(), random().nextDouble(), random());
     PostingsEnum leftPositions = null;
     PostingsEnum rightPositions = null;
     PostingsEnum leftDocs = null;
@@ -2035,53 +2034,37 @@
       assertEquals(info, term, rightTermsEnum.next());
       assertTermStatsEquals(info, leftTermsEnum, rightTermsEnum);
       if (deep) {
-        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                   rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-                                   rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+        assertDocsAndPositionsEnumEquals(info, leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                   rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
 
         assertPositionsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-                                leftPositions = leftTermsEnum.postings(null, leftPositions, PostingsEnum.ALL),
-                                rightPositions = rightTermsEnum.postings(null, rightPositions, PostingsEnum.ALL));
-        assertPositionsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-                                leftPositions = leftTermsEnum.postings(randomBits, leftPositions, PostingsEnum.ALL),
-            rightPositions = rightTermsEnum.postings(randomBits, rightPositions, PostingsEnum.ALL));
+                                leftPositions = leftTermsEnum.postings(leftPositions, PostingsEnum.ALL),
+                                rightPositions = rightTermsEnum.postings(rightPositions, PostingsEnum.ALL));
 
+
         // with freqs:
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs),
+        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs),
             true);
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs),
-            true);
 
+
         // w/o freqs:
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE),
+        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE),
             false);
-        assertDocsEnumEquals(info, leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE),
-            false);
+
         
         // with freqs:
         assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs),
-            rightDocs = rightTermsEnum.postings(null, rightDocs),
+            leftDocs = leftTermsEnum.postings(leftDocs),
+            rightDocs = rightTermsEnum.postings(rightDocs),
             true);
-        assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs),
-            true);
 
         // w/o freqs:
         assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(null, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(null, rightDocs, PostingsEnum.NONE),
+            leftDocs = leftTermsEnum.postings(leftDocs, PostingsEnum.NONE),
+            rightDocs = rightTermsEnum.postings(rightDocs, PostingsEnum.NONE),
             false);
-        assertDocsSkippingEquals(info, leftReader, leftTermsEnum.docFreq(), 
-            leftDocs = leftTermsEnum.postings(randomBits, leftDocs, PostingsEnum.NONE),
-            rightDocs = rightTermsEnum.postings(randomBits, rightDocs, PostingsEnum.NONE),
-            false);
       }
     }
     assertNull(info, rightTermsEnum.next());
Index: lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java	(revision 1687080)
+++ lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java	(working copy)
@@ -1081,7 +1081,7 @@
   // Returns a DocsEnum, but randomly sometimes uses a
   // DocsAndFreqsEnum, DocsAndPositionsEnum.  Returns null
   // if field/term doesn't exist:
-  public static PostingsEnum docs(Random random, IndexReader r, String field, BytesRef term, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public static PostingsEnum docs(Random random, IndexReader r, String field, BytesRef term, PostingsEnum reuse, int flags) throws IOException {
     final Terms terms = MultiFields.getTerms(r, field);
     if (terms == null) {
       return null;
@@ -1090,11 +1090,11 @@
     if (!termsEnum.seekExact(term)) {
       return null;
     }
-    return docs(random, termsEnum, liveDocs, reuse, flags);
+    return docs(random, termsEnum, reuse, flags);
   }
 
   // Returns a PostingsEnum with random features available
-  public static PostingsEnum docs(Random random, TermsEnum termsEnum, Bits liveDocs, PostingsEnum reuse, int flags) throws IOException {
+  public static PostingsEnum docs(Random random, TermsEnum termsEnum, PostingsEnum reuse, int flags) throws IOException {
     // TODO: simplify this method? it would be easier to randomly either use the flags passed, or do the random selection,
     // FREQS should be part fo the random selection instead of outside on its own?
     if (random.nextBoolean()) {
@@ -1106,11 +1106,11 @@
           case 2: posFlags = PostingsEnum.PAYLOADS; break;
           default: posFlags = PostingsEnum.ALL; break;
         }
-        return termsEnum.postings(liveDocs, null, posFlags);
+        return termsEnum.postings(null, posFlags);
       }
       flags |= PostingsEnum.FREQS;
     }
-    return termsEnum.postings(liveDocs, reuse, flags);
+    return termsEnum.postings(reuse, flags);
   }
   
   public static CharSequence stringToCharSequence(String string, Random random) {
Index: lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
===================================================================
--- lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java	(revision 1687080)
+++ lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java	(working copy)
@@ -321,7 +321,7 @@
     final Terms terms = fields.terms("f");
     final TermsEnum te = terms.iterator();
     assertEquals(new BytesRef("a"), te.next());
-    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);
+    final PostingsEnum dpe = te.postings(null, PostingsEnum.ALL);
     assertEquals(0, dpe.nextDoc());
     assertEquals(2, dpe.freq());
     assertEquals(0, dpe.nextPosition());
Index: solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java	(working copy)
@@ -54,6 +54,7 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.PriorityQueue;
@@ -417,8 +418,12 @@
       if (text == null) { // Ran off the end of the terms enum without finding any live docs with that field in them.
         return null;
       }
-      postingsEnum = termsEnum.postings(reader.getLiveDocs(), postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      final Bits liveDocs = reader.getLiveDocs();
       if (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
+        if (liveDocs != null && liveDocs.get(postingsEnum.docID())) {
+          continue;
+        }
         return reader.document(postingsEnum.docID());
       }
     }
Index: solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java	(working copy)
@@ -575,8 +575,11 @@
         while(it.hasNext()) {
           BytesRef ref = it.next();
           if(termsEnum.seekExact(ref)) {
-            postingsEnum = termsEnum.postings(liveDocs, postingsEnum);
+            postingsEnum = termsEnum.postings(postingsEnum);
             int doc = postingsEnum.nextDoc();
+            while (doc != PostingsEnum.NO_MORE_DOCS && liveDocs != null && liveDocs.get(doc) == false) {
+              doc = postingsEnum.nextDoc();
+            }
             if(doc != PostingsEnum.NO_MORE_DOCS) {
               //Found the document.
               int p = boosted.get(ref);
@@ -692,8 +695,11 @@
         for (String id : elevations.ids) {
           term.copyChars(id);
           if (seen.contains(id) == false  && termsEnum.seekExact(term.get())) {
-            postingsEnum = termsEnum.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
             int docId = postingsEnum.nextDoc();
+            while (docId != DocIdSetIterator.NO_MORE_DOCS && liveDocs != null && liveDocs.get(docId) == false) {
+              docId = postingsEnum.nextDoc();
+            }
             if (docId == DocIdSetIterator.NO_MORE_DOCS ) continue;  // must have been deleted
             termValues[ordSet.put(docId)] = term.toBytesRef();
             seen.add(id);
Index: solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java	(working copy)
@@ -357,7 +357,7 @@
       //payloads require offsets
       dpEnumFlags |= (fieldOptions.offsets || fieldOptions.payloads) ? PostingsEnum.OFFSETS : 0;
       dpEnumFlags |= fieldOptions.payloads ? PostingsEnum.PAYLOADS : 0;
-      dpEnum = termsEnum.postings(null, dpEnum, dpEnumFlags);
+      dpEnum = termsEnum.postings(dpEnum, dpEnumFlags);
 
       boolean atNextDoc = false;
       if (dpEnum != null) {
Index: solr/core/src/java/org/apache/solr/request/SimpleFacets.java
===================================================================
--- solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/request/SimpleFacets.java	(working copy)
@@ -821,7 +821,7 @@
               // TODO: specialize when base docset is a bitset or hash set (skipDocs)?  or does it matter for this?
               // TODO: do this per-segment for better efficiency (MultiDocsEnum just uses base class impl)
               // TODO: would passing deleted docs lead to better efficiency over checking the fastForRandomSet?
-              postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+              postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
               c = 0;
 
               if (postingsEnum instanceof MultiPostingsEnum) {
Index: solr/core/src/java/org/apache/solr/schema/LatLonType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/LatLonType.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/schema/LatLonType.java	(working copy)
@@ -340,13 +340,13 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return new SpatialScorer(context, acceptDocs, this, queryWeight);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return new SpatialScorer(context, this, queryWeight);
     }
 
     @Override
     public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-      return ((SpatialScorer)scorer(context, context.reader().getLiveDocs())).explain(doc);
+      return ((SpatialScorer)scorer(context)).explain(doc);
     }
   }
 
@@ -358,7 +358,6 @@
     int doc=-1;
     final FunctionValues latVals;
     final FunctionValues lonVals;
-    final Bits acceptDocs;
 
 
     final double lonMin, lonMax, lon2Min, lon2Max, latMin, latMax;
@@ -374,13 +373,12 @@
     int lastDistDoc;
     double lastDist;
 
-    public SpatialScorer(LeafReaderContext readerContext, Bits acceptDocs, SpatialWeight w, float qWeight) throws IOException {
+    public SpatialScorer(LeafReaderContext readerContext, SpatialWeight w, float qWeight) throws IOException {
       super(w);
       this.weight = w;
       this.qWeight = qWeight;
       this.reader = readerContext.reader();
       this.maxDoc = reader.maxDoc();
-      this.acceptDocs = acceptDocs;
       latVals = latSource.getValues(weight.latContext, readerContext);
       lonVals = lonSource.getValues(weight.lonContext, readerContext);
 
@@ -458,7 +456,6 @@
         if (doc>=maxDoc) {
           return doc=NO_MORE_DOCS;
         }
-        if (acceptDocs != null && !acceptDocs.get(doc)) continue;
         if (!match()) continue;
         return doc;
       }
@@ -538,7 +535,7 @@
     protected void doSetNextReader(LeafReaderContext context) throws IOException {
       super.doSetNextReader(context);
       maxdoc = context.reader().maxDoc();
-      spatialScorer = new SpatialScorer(context, null, weight, 1.0f);
+      spatialScorer = new SpatialScorer(context, weight, 1.0f);
     }
   }
 
Index: solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java	(revision 0)
+++ solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java	(working copy)
@@ -0,0 +1,58 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.FilterLeafReader.FilterPostingsEnum;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.util.Bits;
+
+public class BitsFilteredPostingsEnum extends FilterPostingsEnum {
+
+  public static PostingsEnum wrap(PostingsEnum in, Bits acceptDocs) {
+    if (in == null || acceptDocs == null) {
+      return in;
+    }
+    return new BitsFilteredPostingsEnum(in, acceptDocs);
+  }
+
+  private final Bits acceptDocs;
+
+  private BitsFilteredPostingsEnum(PostingsEnum in, Bits acceptDocs) {
+    super(in);
+    this.acceptDocs = acceptDocs;
+  }
+
+  private int doNext(int doc) throws IOException {
+    while (doc != NO_MORE_DOCS && acceptDocs.get(doc) == false) {
+      doc = super.nextDoc();
+    }
+    return doc;
+  }
+
+  @Override
+  public int nextDoc() throws IOException {
+    return doNext(super.nextDoc());
+  }
+
+  @Override
+  public int advance(int target) throws IOException {
+    return doNext(super.advance(target));
+  }
+}

Property changes on: solr/core/src/java/org/apache/solr/search/BitsFilteredPostingsEnum.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java	(working copy)
@@ -277,7 +277,7 @@
 
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    public Scorer scorer(LeafReaderContext context) throws IOException {
       if (filter == null) {
         boolean debug = rb != null && rb.isDebug();
         long start = debug ? System.currentTimeMillis() : 0;
@@ -309,7 +309,7 @@
       }
 
       // Although this set only includes live docs, other filters can be pushed down to queries.
-      DocIdSet readerSet = filter.getDocIdSet(context, acceptDocs);
+      DocIdSet readerSet = filter.getDocIdSet(context, null);
       if (readerSet == null) {
         return null;
       }
@@ -409,7 +409,7 @@
         if (freq < minDocFreqFrom) {
           fromTermDirectCount++;
           // OK to skip liveDocs, since we check for intersection with docs matching query
-          fromDeState.postingsEnum = fromDeState.termsEnum.postings(null, fromDeState.postingsEnum, PostingsEnum.NONE);
+          fromDeState.postingsEnum = fromDeState.termsEnum.postings(fromDeState.postingsEnum, PostingsEnum.NONE);
           PostingsEnum postingsEnum = fromDeState.postingsEnum;
 
           if (postingsEnum instanceof MultiPostingsEnum) {
@@ -474,7 +474,8 @@
               toTermDirectCount++;
 
               // need to use liveDocs here so we don't map to any deleted ones
-              toDeState.postingsEnum = toDeState.termsEnum.postings(toDeState.liveDocs, toDeState.postingsEnum, PostingsEnum.NONE);
+              toDeState.postingsEnum = toDeState.termsEnum.postings(toDeState.postingsEnum, PostingsEnum.NONE);
+              toDeState.postingsEnum = BitsFilteredPostingsEnum.wrap(toDeState.postingsEnum, toDeState.liveDocs);
               PostingsEnum postingsEnum = toDeState.postingsEnum;
 
               if (postingsEnum instanceof MultiPostingsEnum) {
Index: solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/ReRankQParserPlugin.java	(working copy)
@@ -204,8 +204,8 @@
       return mainWeight.getValueForNormalization();
     }
 
-    public Scorer scorer(LeafReaderContext context, Bits bits) throws IOException {
-      return mainWeight.scorer(context, bits);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return mainWeight.scorer(context);
     }
 
     public void normalize(float norm, float topLevelBoost) {
Index: solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java	(working copy)
@@ -103,8 +103,8 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      DocIdSet docIdSet = filter instanceof SolrFilter ? ((SolrFilter)filter).getDocIdSet(this.context, context, acceptDocs) : filter.getDocIdSet(context, acceptDocs);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      DocIdSet docIdSet = filter instanceof SolrFilter ? ((SolrFilter)filter).getDocIdSet(this.context, context, null) : filter.getDocIdSet(context, null);
       if (docIdSet == null) {
         return null;
       }
Index: solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/SolrIndexSearcher.java	(working copy)
@@ -807,7 +807,8 @@
     if (!termsEnum.seekExact(termBytes)) {
       return -1;
     }
-    PostingsEnum docs = termsEnum.postings(leafReader.getLiveDocs(), null, PostingsEnum.NONE);
+    PostingsEnum docs = termsEnum.postings(null, PostingsEnum.NONE);
+    docs = BitsFilteredPostingsEnum.wrap(docs, leafReader.getLiveDocs());
     int id = docs.nextDoc();
     return id == DocIdSetIterator.NO_MORE_DOCS ? -1 : id;
   }
@@ -828,7 +829,8 @@
       
       TermsEnum te = terms.iterator();
       if (te.seekExact(idBytes)) {
-        PostingsEnum docs = te.postings(reader.getLiveDocs(), null, PostingsEnum.NONE);
+        PostingsEnum docs = te.postings(null, PostingsEnum.NONE);
+        docs = BitsFilteredPostingsEnum.wrap(docs, reader.getLiveDocs());
         int id = docs.nextDoc();
         if (id == DocIdSetIterator.NO_MORE_DOCS) continue;
         assert docs.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;
@@ -1200,7 +1202,8 @@
     int bitsSet = 0;
     FixedBitSet fbs = null;
 
-    PostingsEnum postingsEnum = deState.termsEnum.postings(deState.liveDocs, deState.postingsEnum, PostingsEnum.NONE);
+    PostingsEnum postingsEnum = deState.termsEnum.postings(deState.postingsEnum, PostingsEnum.NONE);
+    postingsEnum = BitsFilteredPostingsEnum.wrap(postingsEnum, deState.liveDocs);
     if (deState.postingsEnum == null) {
       deState.postingsEnum = postingsEnum;
     }
@@ -2526,7 +2529,7 @@
         iterators.add(iter);
       }
       for (Weight w : weights) {
-        Scorer scorer = w.scorer(context, context.reader().getLiveDocs());
+        Scorer scorer = w.scorer(context);
         if (scorer == null) return null;
         iterators.add(scorer);
       }
Index: solr/core/src/java/org/apache/solr/search/facet/FacetField.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/facet/FacetField.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/facet/FacetField.java	(working copy)
@@ -744,7 +744,7 @@
             }
           }
           // iterate over TermDocs to calculate the intersection
-          postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+          postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
 
           if (postingsEnum instanceof MultiPostingsEnum) {
             MultiPostingsEnum.EnumWithSlice[] subs = ((MultiPostingsEnum) postingsEnum).getSubs();
Index: solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/function/FileFloatSource.java	(working copy)
@@ -305,7 +305,7 @@
           continue;
         }
 
-        postingsEnum = termsEnum.postings(null, postingsEnum, PostingsEnum.NONE);
+        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
         int doc;
         while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
           vals[doc] = fval;
Index: solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/search/join/IgnoreAcceptDocsQuery.java	(working copy)
@@ -23,8 +23,10 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BulkScorer;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
@@ -82,9 +84,27 @@
     }
 
     @Override
-    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return w.scorer(context, null);
+    public Scorer scorer(LeafReaderContext context) throws IOException {
+      return w.scorer(context);
     }
+
+    @Override
+    public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
+      final BulkScorer in = w.bulkScorer(context);
+      return new BulkScorer() {
+
+        @Override
+        public int score(LeafCollector collector, Bits acceptDocs, int min, int max) throws IOException {
+          return in.score(collector, null, min, max);
+        }
+
+        @Override
+        public long cost() {
+          return in.cost();
+        }
+        
+      };
+    }
   }
 
   @Override
Index: solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/update/DeleteByQueryWrapper.java	(working copy)
@@ -86,8 +86,8 @@
       public void normalize(float norm, float topLevelBoost) { inner.normalize(norm, topLevelBoost); }
 
       @Override
-      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        return inner.scorer(privateContext.getIndexReader().leaves().get(0), acceptDocs);
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        return inner.scorer(privateContext.getIndexReader().leaves().get(0));
       }
     };
   }
Index: solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java	(revision 1687080)
+++ solr/core/src/java/org/apache/solr/update/SolrIndexSplitter.java	(working copy)
@@ -42,6 +42,7 @@
 import org.apache.solr.common.cloud.HashBasedRouter;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.schema.SchemaField;
+import org.apache.solr.search.BitsFilteredPostingsEnum;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.RefCounted;
 import org.slf4j.Logger;
@@ -201,7 +202,8 @@
         hash = hashRouter.sliceHash(idString, null, null, null);
       }
 
-      postingsEnum = termsEnum.postings(liveDocs, postingsEnum, PostingsEnum.NONE);
+      postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);
+      postingsEnum = BitsFilteredPostingsEnum.wrap(postingsEnum, liveDocs);
       for (;;) {
         int doc = postingsEnum.nextDoc();
         if (doc == DocIdSetIterator.NO_MORE_DOCS) break;
Index: solr/core/src/test/org/apache/solr/search/TestRTGBase.java
===================================================================
--- solr/core/src/test/org/apache/solr/search/TestRTGBase.java	(revision 1687080)
+++ solr/core/src/test/org/apache/solr/search/TestRTGBase.java	(working copy)
@@ -132,7 +132,8 @@
     if (!termsEnum.seekExact(termBytes)) {
       return -1;
     }
-    PostingsEnum docs = termsEnum.postings(MultiFields.getLiveDocs(r), null, PostingsEnum.NONE);
+    PostingsEnum docs = termsEnum.postings(null, PostingsEnum.NONE);
+    docs = BitsFilteredPostingsEnum.wrap(docs, MultiFields.getLiveDocs(r));
     int id = docs.nextDoc();
     if (id != DocIdSetIterator.NO_MORE_DOCS) {
       int next = docs.nextDoc();
