Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java	(working copy)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java	(working copy)
@@ -1,4 +1,4 @@
-package org.apache.lucene.analysis.fr;
+package org.apache.lucene.analysis.util;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java	(working copy)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java	(working copy)
@@ -1,4 +1,4 @@
-package org.apache.lucene.analysis.fr;
+package org.apache.lucene.analysis.util;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -28,6 +28,7 @@
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.fr.FrenchAnalyzer;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
@@ -41,7 +42,7 @@
     String test = "Plop, juste pour voir l'embrouille avec O'brian. M'enfin.";
     Tokenizer tokenizer = new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(test));
     CharArraySet articles = new CharArraySet(TEST_VERSION_CURRENT, asSet("l", "M"), false);
-    TokenFilter filter = new ElisionFilter(TEST_VERSION_CURRENT, tokenizer, articles);
+    TokenFilter filter = new ElisionFilter(tokenizer, articles);
     List<String> tas = filter(filter);
     assertEquals("embrouille", tas.get(4));
     assertEquals("O'brian", tas.get(6));
@@ -62,7 +63,7 @@
       @Override
       protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
         Tokenizer tokenizer = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(tokenizer, new ElisionFilter(TEST_VERSION_CURRENT, tokenizer));
+        return new TokenStreamComponents(tokenizer, new ElisionFilter(tokenizer, FrenchAnalyzer.DEFAULT_ARTICLES));
       }
     };
     checkOneTermReuse(a, "", "");
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElision.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElision.java	(revision 1366186)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElision.java	(working copy)
@@ -1,71 +0,0 @@
-package org.apache.lucene.analysis.fr;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.util.CharArraySet;
-
-/**
- * 
- */
-public class TestElision extends BaseTokenStreamTestCase {
-
-  public void testElision() throws Exception {
-    String test = "Plop, juste pour voir l'embrouille avec O'brian. M'enfin.";
-    Tokenizer tokenizer = new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(test));
-    CharArraySet articles = new CharArraySet(TEST_VERSION_CURRENT, asSet("l", "M"), false);
-    TokenFilter filter = new ElisionFilter(TEST_VERSION_CURRENT, tokenizer, articles);
-    List<String> tas = filter(filter);
-    assertEquals("embrouille", tas.get(4));
-    assertEquals("O'brian", tas.get(6));
-    assertEquals("enfin", tas.get(7));
-  }
-
-  private List<String> filter(TokenFilter filter) throws IOException {
-    List<String> tas = new ArrayList<String>();
-    CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);
-    while (filter.incrementToken()) {
-      tas.add(termAtt.toString());
-    }
-    return tas;
-  }
-  
-  public void testEmptyTerm() throws IOException {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        Tokenizer tokenizer = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(tokenizer, new ElisionFilter(TEST_VERSION_CURRENT, tokenizer));
-      }
-    };
-    checkOneTermReuse(a, "", "");
-  }
-
-}
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/frenchArticles.txt
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/frenchArticles.txt	(revision 1366186)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/frenchArticles.txt	(working copy)
@@ -1,24 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# A set of articles for testing the French Elision filter.
-# Requiring a text file is a bit weird here...
-l
-m
-t
-qu
-n
-s
-j
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java	(revision 1366186)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java	(working copy)
@@ -1,88 +0,0 @@
-package org.apache.lucene.analysis.fr;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceAsStreamResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoader;
-
-/**
- * Simple tests to ensure the French elision filter factory is working.
- */
-public class TestElisionFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually normalizes text.
-   */
-  public void testElision() throws Exception {
-    Reader reader = new StringReader("l'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    ResourceLoader loader = new ResourceAsStreamResourceLoader(getClass());
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("articles", "frenchArticles.txt");
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-  /**
-   * Test creating an elision filter without specifying any articles
-   */
-  public void testDefaultArticles() throws Exception {
-    Reader reader = new StringReader("l'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    ResourceLoader loader = new ResourceAsStreamResourceLoader(getClass());
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-  /**
-   * Test setting ignoreCase=true
-   */
-  public void testCaseInsensitive() throws Exception {
-    Reader reader = new StringReader("L'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    ResourceLoader loader = new ResourceAsStreamResourceLoader(getClass());
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("articles", "frenchArticles.txt");
-    args.put("ignoreCase", "true");
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-}
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java	(working copy)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java	(working copy)
@@ -1,4 +1,4 @@
-package org.apache.lucene.analysis.fr;
+package org.apache.lucene.analysis.util;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -17,10 +17,9 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.util.*;
-
 import java.io.IOException;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.fr.FrenchAnalyzer;
 
 /**
  * Factory for {@link ElisionFilter}.
@@ -46,12 +45,13 @@
     if (articlesFile != null) {
       articles = getWordSet(loader, articlesFile, ignoreCase);
     }
+    if (articles == null) {
+      articles = FrenchAnalyzer.DEFAULT_ARTICLES;
+    }
   }
 
   public ElisionFilter create(TokenStream input) {
-    assureMatchVersion();
-    return articles == null ? new ElisionFilter(luceneMatchVersion,input) : 
-        new ElisionFilter(luceneMatchVersion,input,articles);
+    return new ElisionFilter(input, articles);
   }
 }
 
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java	(working copy)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java	(working copy)
@@ -1,4 +1,4 @@
-package org.apache.lucene.analysis.fr;
+package org.apache.lucene.analysis.util;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -18,13 +18,11 @@
  */
 
 import java.io.IOException;
-import java.util.Arrays;
 
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.util.Version;
 
 /**
  * Removes elisions from a {@link TokenStream}. For example, "l'avion" (the plane) will be
@@ -33,31 +31,17 @@
  * @see <a href="http://fr.wikipedia.org/wiki/%C3%89lision">Elision in Wikipedia</a>
  */
 public final class ElisionFilter extends TokenFilter {
-  private CharArraySet articles = CharArraySet.EMPTY_SET;
+  private final CharArraySet articles;
   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(
-      new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(
-          "l", "m", "t", "qu", "n", "s", "j"), true));
   
-  private static char[] apostrophes = {'\'', '\u2019'};
-  
   /**
-   * Constructs an elision filter with standard stop words
-   */
-  public ElisionFilter(Version matchVersion, TokenStream input) {
-    this(matchVersion, input, DEFAULT_ARTICLES);
-  }
-
-  /**
    * Constructs an elision filter with a Set of stop words
-   * @param matchVersion the lucene backwards compatibility version
    * @param input the source {@link TokenStream}
    * @param articles a set of stopword articles
    */
-  public ElisionFilter(Version matchVersion, TokenStream input, CharArraySet articles) {
+  public ElisionFilter(TokenStream input, CharArraySet articles) {
     super(input);
-    this.articles = CharArraySet.unmodifiableSet(
-        new CharArraySet(matchVersion, articles, true));
+    this.articles = articles;
   }
 
   /**
@@ -69,22 +53,18 @@
       char[] termBuffer = termAtt.buffer();
       int termLength = termAtt.length();
 
-      int minPoz = Integer.MAX_VALUE;
-      for (int i = 0; i < apostrophes.length; i++) {
-        char apos = apostrophes[i];
-        // The equivalent of String.indexOf(ch)
-        for (int poz = 0; poz < termLength ; poz++) {
-          if (termBuffer[poz] == apos) {
-            minPoz = Math.min(poz, minPoz);
-            break;
-          }
+      int index = -1;
+      for (int i = 0; i < termLength; i++) {
+        char ch = termBuffer[i];
+        if (ch == '\'' || ch == '\u2019') {
+          index = i;
+          break;
         }
       }
 
       // An apostrophe has been found. If the prefix is an article strip it off.
-      if (minPoz != Integer.MAX_VALUE
-          && articles.contains(termAtt.buffer(), 0, minPoz)) {
-        termAtt.copyBuffer(termAtt.buffer(), minPoz + 1, termAtt.length() - (minPoz + 1));
+      if (index >= 0 && articles.contains(termBuffer, 0, index)) {
+        termAtt.copyBuffer(termBuffer, index + 1, termLength - (index + 1));
       }
 
       return true;
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.fr.ElisionFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -32,6 +31,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
@@ -129,7 +129,7 @@
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
     TokenStream result = new StandardFilter(matchVersion, source);
-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);
+    result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java	(working copy)
@@ -1,95 +0,0 @@
-package org.apache.lucene.analysis.fr;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Arrays;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.util.Version;
-
-/**
- * Removes elisions from a {@link TokenStream}. For example, "l'avion" (the plane) will be
- * tokenized as "avion" (plane).
- * 
- * @see <a href="http://fr.wikipedia.org/wiki/%C3%89lision">Elision in Wikipedia</a>
- */
-public final class ElisionFilter extends TokenFilter {
-  private CharArraySet articles = CharArraySet.EMPTY_SET;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(
-      new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(
-          "l", "m", "t", "qu", "n", "s", "j"), true));
-  
-  private static char[] apostrophes = {'\'', '\u2019'};
-  
-  /**
-   * Constructs an elision filter with standard stop words
-   */
-  public ElisionFilter(Version matchVersion, TokenStream input) {
-    this(matchVersion, input, DEFAULT_ARTICLES);
-  }
-
-  /**
-   * Constructs an elision filter with a Set of stop words
-   * @param matchVersion the lucene backwards compatibility version
-   * @param input the source {@link TokenStream}
-   * @param articles a set of stopword articles
-   */
-  public ElisionFilter(Version matchVersion, TokenStream input, CharArraySet articles) {
-    super(input);
-    this.articles = CharArraySet.unmodifiableSet(
-        new CharArraySet(matchVersion, articles, true));
-  }
-
-  /**
-   * Increments the {@link TokenStream} with a {@link CharTermAttribute} without elisioned start
-   */
-  @Override
-  public final boolean incrementToken() throws IOException {
-    if (input.incrementToken()) {
-      char[] termBuffer = termAtt.buffer();
-      int termLength = termAtt.length();
-
-      int minPoz = Integer.MAX_VALUE;
-      for (int i = 0; i < apostrophes.length; i++) {
-        char apos = apostrophes[i];
-        // The equivalent of String.indexOf(ch)
-        for (int poz = 0; poz < termLength ; poz++) {
-          if (termBuffer[poz] == apos) {
-            minPoz = Math.min(poz, minPoz);
-            break;
-          }
-        }
-      }
-
-      // An apostrophe has been found. If the prefix is an article strip it off.
-      if (minPoz != Integer.MAX_VALUE
-          && articles.contains(termAtt.buffer(), 0, minPoz)) {
-        termAtt.copyBuffer(termAtt.buffer(), minPoz + 1, termAtt.length() - (minPoz + 1));
-      }
-
-      return true;
-    } else {
-      return false;
-    }
-  }
-}
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java	(working copy)
@@ -28,6 +28,7 @@
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.IOUtils;
@@ -35,6 +36,7 @@
 
 import java.io.IOException;
 import java.io.Reader;
+import java.util.Arrays;
 
 /**
  * {@link Analyzer} for French language. 
@@ -54,6 +56,11 @@
   /** File containing default French stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "french_stop.txt";
   
+  /** Default set of articles for ElisionFilter */
+  public static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(
+      new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(
+          "l", "m", "t", "qu", "n", "s", "j"), true));
+
   /**
    * Contains words that should be indexed but not stemmed.
    */
@@ -134,7 +141,7 @@
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
     TokenStream result = new StandardFilter(matchVersion, source);
-    result = new ElisionFilter(matchVersion, result);
+    result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!excltable.isEmpty())
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java	(working copy)
@@ -1,57 +0,0 @@
-package org.apache.lucene.analysis.fr;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.util.*;
-
-import java.io.IOException;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Factory for {@link ElisionFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_elsn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ElisionFilterFactory" 
- *       articles="stopwordarticles.txt" ignoreCase="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ElisionFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-
-  private CharArraySet articles;
-
-  public void inform(ResourceLoader loader) throws IOException {
-    String articlesFile = args.get("articles");
-    boolean ignoreCase = getBoolean("ignoreCase", false);
-
-    if (articlesFile != null) {
-      articles = getWordSet(loader, articlesFile, ignoreCase);
-    }
-  }
-
-  public ElisionFilter create(TokenStream input) {
-    assureMatchVersion();
-    return articles == null ? new ElisionFilter(luceneMatchVersion,input) : 
-        new ElisionFilter(luceneMatchVersion,input,articles);
-  }
-}
-
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java	(working copy)
@@ -24,7 +24,6 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.fr.ElisionFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -32,6 +31,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.CatalanStemmer;
@@ -127,7 +127,7 @@
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
     TokenStream result = new StandardFilter(matchVersion, source);
-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);
+    result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java	(revision 1366186)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java	(working copy)
@@ -23,7 +23,6 @@
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.fr.ElisionFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -31,6 +30,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ElisionFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.IrishStemmer;
@@ -140,7 +140,7 @@
     StopFilter s = new StopFilter(matchVersion, result, HYPHENATIONS);
     s.setEnablePositionIncrements(false);
     result = s;
-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);
+    result = new ElisionFilter(result, DEFAULT_ARTICLES);
     result = new IrishLowerCaseFilter(result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
Index: lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
===================================================================
--- lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory	(revision 1366186)
+++ lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory	(working copy)
@@ -40,7 +40,6 @@
 org.apache.lucene.analysis.es.SpanishLightStemFilterFactory
 org.apache.lucene.analysis.fa.PersianNormalizationFilterFactory
 org.apache.lucene.analysis.fi.FinnishLightStemFilterFactory
-org.apache.lucene.analysis.fr.ElisionFilterFactory
 org.apache.lucene.analysis.fr.FrenchLightStemFilterFactory
 org.apache.lucene.analysis.fr.FrenchMinimalStemFilterFactory
 org.apache.lucene.analysis.ga.IrishLowerCaseFilterFactory
@@ -88,3 +87,4 @@
 org.apache.lucene.analysis.synonym.SynonymFilterFactory
 org.apache.lucene.analysis.th.ThaiWordFilterFactory
 org.apache.lucene.analysis.tr.TurkishLowerCaseFilterFactory
+org.apache.lucene.analysis.util.ElisionFilterFactory
