Index: solr/core/src/java/org/apache/solr/search/function/distance/HaversineConstFunction.java
===================================================================
--- solr/core/src/java/org/apache/solr/search/function/distance/HaversineConstFunction.java	(revision 1214047)
+++ solr/core/src/java/org/apache/solr/search/function/distance/HaversineConstFunction.java	(working copy)
@@ -141,7 +141,7 @@
     } catch (InvalidGeoException e) {
       throw new ParseException("Bad spatial pt:" + pt);
     }
-    return new VectorValueSource(Arrays.asList(new ValueSource[] {new DoubleConstValueSource(point[0]),new DoubleConstValueSource(point[1])}));
+    return new VectorValueSource(Arrays.<ValueSource>asList(new DoubleConstValueSource(point[0]),new DoubleConstValueSource(point[1])));
   }
 
   private static double[] getConstants(MultiValueSource vs) {
Index: solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java	(revision 1214047)
+++ solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java	(working copy)
@@ -368,10 +368,9 @@
       // insert documents in their proper place 
       SortSpec sortSpec = rb.getSortSpec();
       if( sortSpec.getSort() == null ) {
-        sortSpec.setSort( new Sort( new SortField[] {
+        sortSpec.setSort( new Sort(
             new SortField(idField, booster.comparatorSource, false ),
-            new SortField(null, SortField.SCORE, false)
-        }));
+            new SortField(null, SortField.SCORE, false)));
       }
       else {
         // Check if the sort is based on score
Index: solr/core/src/java/org/apache/solr/spelling/SpellCheckCollator.java
===================================================================
--- solr/core/src/java/org/apache/solr/spelling/SpellCheckCollator.java	(revision 1214047)
+++ solr/core/src/java/org/apache/solr/spelling/SpellCheckCollator.java	(working copy)
@@ -76,7 +76,7 @@
         checkResponse.setQparser(ultimateResponse.getQparser());
         checkResponse.setFilters(ultimateResponse.getFilters());
         checkResponse.setQueryString(collationQueryStr);
-        checkResponse.components = Arrays.asList(new SearchComponent[] { queryComponent });
+        checkResponse.components = Arrays.<SearchComponent>asList(queryComponent);
 
         ModifiableSolrParams params = new ModifiableSolrParams(ultimateResponse.req.getParams());
         params.set(CommonParams.Q, collationQueryStr);
Index: solr/solrj/src/test/org/apache/solr/client/solrj/beans/TestDocumentObjectBinder.java
===================================================================
--- solr/solrj/src/test/org/apache/solr/client/solrj/beans/TestDocumentObjectBinder.java	(revision 1214047)
+++ solr/solrj/src/test/org/apache/solr/client/solrj/beans/TestDocumentObjectBinder.java	(working copy)
@@ -101,8 +101,8 @@
     item.inStock = false;
     item.categories =  new String[] { "aaa", "bbb", "ccc" };
     item.features = Arrays.asList( item.categories );
-    List<String> supA =  Arrays.asList(  new String[] { "supA1", "supA2", "supA3" } );
-    List<String> supB =  Arrays.asList(  new String[] { "supB1", "supB2", "supB3"});
+    List<String> supA =  Arrays.asList("supA1", "supA2", "supA3");
+    List<String> supB =  Arrays.asList("supB1", "supB2", "supB3");
     item.supplier = new HashMap<String, List<String>>();
     item.supplier.put("supplier_supA", supA);
     item.supplier.put("supplier_supB", supB);
Index: solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestTemplateTransformer.java
===================================================================
--- solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestTemplateTransformer.java	(revision 1214047)
+++ solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestTemplateTransformer.java	(working copy)
@@ -51,7 +51,7 @@
     fields.add(createMap("column", "mrname",
             TemplateTransformer.TEMPLATE,"Mr ${e.name}"));
 
-    List<String> mails = Arrays.asList(new String[]{"a@b.com", "c@d.com"});
+    List<String> mails = Arrays.asList("a@b.com", "c@d.com");
     Map row = createMap(
             "firstName", "Shalin",
             "middleName", "Shekhar", 
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java	(revision 1214047)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java	(working copy)
@@ -28,8 +28,8 @@
     FieldQueryNode nodeA = new FieldQueryNode("foo", "A", 0, 1);
     FieldQueryNode nodeB = new FieldQueryNode("foo", "B", 1, 2);
     BooleanQueryNode bq = new BooleanQueryNode(
-        Arrays.asList(new QueryNode[] { nodeA }));
-    bq.add(Arrays.asList(new QueryNode[] { nodeB }));
+        Arrays.<QueryNode>asList(nodeA));
+    bq.add(Arrays.<QueryNode>asList(nodeB));
     assertEquals(2, bq.getChildren().size());
   }
   
Index: lucene/contrib/facet/src/test/org/apache/lucene/facet/search/BaseTestTopK.java
===================================================================
--- lucene/contrib/facet/src/test/org/apache/lucene/facet/search/BaseTestTopK.java	(revision 1214047)
+++ lucene/contrib/facet/src/test/org/apache/lucene/facet/search/BaseTestTopK.java	(working copy)
@@ -86,7 +86,7 @@
     if (VERBOSE) {
       System.out.println("Adding CP: " + cp.toString());
     }
-    return Arrays.asList(new CategoryPath[] { cp });
+    return Arrays.asList(cp);
   }
 
   protected FacetSearchParams searchParamsWithRequests(int numResults) {
Index: lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewCollationAnalyzerTask.java
===================================================================
--- lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewCollationAnalyzerTask.java	(revision 1214047)
+++ lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewCollationAnalyzerTask.java	(working copy)
@@ -60,7 +60,7 @@
       throws Exception {
     final Class<?> collatorClazz = Class.forName(impl.collatorClassName);
     Method collatorMethod = collatorClazz.getMethod("getInstance",
-        new Class[] {Locale.class});
+        Locale.class);
     Object collator = collatorMethod.invoke(null, locale);
     
     final Class<? extends Analyzer> clazz = Class.forName(impl.className)
Index: lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocSource.java
===================================================================
--- lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocSource.java	(revision 1214047)
+++ lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocSource.java	(working copy)
@@ -248,7 +248,7 @@
       try {
         final Class<? extends LineParser> clazz = 
           Class.forName(docDataLineReaderClassName).asSubclass(LineParser.class);
-        Constructor<? extends LineParser> cnstr = clazz.getConstructor(new Class[]{String[].class});
+        Constructor<? extends LineParser> cnstr = clazz.getConstructor(String[].class);
         return cnstr.newInstance((Object)header);
       } catch (Exception e) {
         throw new RuntimeException("Failed to instantiate "+docDataLineReaderClassName, e);
Index: lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java
===================================================================
--- lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java	(revision 1214047)
+++ lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java	(working copy)
@@ -32,7 +32,7 @@
 
 /**
  * This tool splits input index into multiple equal parts. The method employed
- * here uses {@link IndexWriter#addIndexes(IndexReader[])} where the input data
+ * here uses {@link IndexWriter#addIndexes(IndexReader...)} where the input data
  * comes from the input index with artificially applied deletes to the document
  * id-s that fall outside the selected partition.
  * <p>Note 1: Deletes are only applied to a buffered list of deleted docs and
Index: lucene/contrib/misc/src/java/org/apache/lucene/index/IndexSorter.java
===================================================================
--- lucene/contrib/misc/src/java/org/apache/lucene/index/IndexSorter.java	(revision 1214047)
+++ lucene/contrib/misc/src/java/org/apache/lucene/index/IndexSorter.java	(working copy)
@@ -281,7 +281,7 @@
     SortingReader sorter = new SortingReader(reader, oldToNew(reader, field));
     IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_31, new WhitespaceAnalyzer(Version.LUCENE_31));
     IndexWriter writer = new IndexWriter(output, cfg);
-    writer.addIndexes(new IndexReader[] { sorter });
+    writer.addIndexes(sorter);
     writer.close();
     long end = System.currentTimeMillis();
     LOG.info("IndexSorter: done, " + (end - start)
Index: lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java
===================================================================
--- lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java	(revision 1214047)
+++ lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java	(working copy)
@@ -212,7 +212,7 @@
   @Test
   public void testRemoteSort() throws Exception {
     Searchable searcher = lookupRemote();
-    MultiSearcher multi = new MultiSearcher (new Searchable[] { searcher });
+    MultiSearcher multi = new MultiSearcher (searcher);
     runMultiSorts(multi, true); // this runs on the full index
   }
 
@@ -227,7 +227,7 @@
     HashMap<String,Float> scoresA = getScores (full.search (queryA, null, 1000).scoreDocs, full);
 
     // we'll test searching locally, remote and multi
-    MultiSearcher remote = new MultiSearcher (new Searchable[] { lookupRemote() });
+    MultiSearcher remote = new MultiSearcher (lookupRemote());
 
     // change sorting and make sure relevancy stays the same
 
Index: lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java
===================================================================
--- lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java	(revision 1214047)
+++ lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java	(working copy)
@@ -74,7 +74,7 @@
     document = searcher.doc(0, fs);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 1, document.getFields().size() == 1);
-    fs = new MapFieldSelector(new String[]{"other"});
+    fs = new MapFieldSelector("other");
     document = searcher.doc(0, fs);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 1, document.getFields().size() == 1);
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 1214047)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -302,8 +302,7 @@
   }
   
   public void testSpanRegexQuery() throws Exception {
-    query = new SpanOrQuery(new SpanQuery [] {
-        new SpanRegexQuery(new Term(FIELD_NAME, "ken.*")) });
+    query = new SpanOrQuery(new SpanRegexQuery(new Term(FIELD_NAME, "ken.*")));
     searcher = new IndexSearcher(reader);
     hits = searcher.search(query, 100);
     int maxNumFragmentsRequired = 2;
Index: lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
===================================================================
--- lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java	(revision 1214047)
+++ lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java	(working copy)
@@ -119,13 +119,13 @@
   
   @Deprecated
   protected String[] getFieldValues( IndexReader reader, int docId, String fieldName) throws IOException {
-    Document doc = reader.document( docId, new MapFieldSelector( new String[]{ fieldName } ) );
+    Document doc = reader.document( docId, new MapFieldSelector(  fieldName) );
     return doc.getValues( fieldName ); // according to Document class javadoc, this never returns null
   }
   
   protected Field[] getFields( IndexReader reader, int docId, String fieldName) throws IOException {
     // according to javadoc, doc.getFields(fieldName) cannot be used with lazy loaded field???
-    Document doc = reader.document( docId, new MapFieldSelector( new String[]{ fieldName } ) );
+    Document doc = reader.document( docId, new MapFieldSelector(  fieldName) );
     return doc.getFields( fieldName ); // according to Document class javadoc, this never returns null
   }
 
Index: lucene/contrib/join/src/test/org/apache/lucene/search/TestBlockJoin.java
===================================================================
--- lucene/contrib/join/src/test/org/apache/lucene/search/TestBlockJoin.java	(revision 1214047)
+++ lucene/contrib/join/src/test/org/apache/lucene/search/TestBlockJoin.java	(working copy)
@@ -603,7 +603,7 @@
     childDoc.add(newField("child", "1", Field.Store.NO, Field.Index.NOT_ANALYZED));
     Document parentDoc = new Document();
     parentDoc.add(newField("parent", "1", Field.Store.NO, Field.Index.NOT_ANALYZED));
-    w.addDocuments(Arrays.asList(new Document[] {childDoc, parentDoc}));
+    w.addDocuments(Arrays.asList(childDoc, parentDoc));
     IndexReader r = w.getReader();
     w.close();
     IndexSearcher s = newSearcher(r);
@@ -634,7 +634,7 @@
     Document parentDoc = new Document();
     parentDoc.add(newField("parent", "1", Field.Store.NO, Field.Index.NOT_ANALYZED));
     parentDoc.add(newField("isparent", "yes", Field.Store.NO, Field.Index.NOT_ANALYZED));
-    w.addDocuments(Arrays.asList(new Document[] {parentDoc}));
+    w.addDocuments(Arrays.asList(parentDoc));
 
     // Add another doc so scorer is not null
     parentDoc = new Document();
@@ -642,7 +642,7 @@
     parentDoc.add(newField("isparent", "yes", Field.Store.NO, Field.Index.NOT_ANALYZED));
     Document childDoc = new Document();
     childDoc.add(newField("child", "2", Field.Store.NO, Field.Index.NOT_ANALYZED));
-    w.addDocuments(Arrays.asList(new Document[] {childDoc, parentDoc}));
+    w.addDocuments(Arrays.asList(childDoc, parentDoc));
 
     // Need single seg:
     w.forceMerge(1);
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java	(revision 1214047)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java	(working copy)
@@ -215,7 +215,7 @@
    * Test that custom stopwords work, and are not case-sensitive.
    */
   public void testCustomStopwords() throws Exception {
-    PersianAnalyzer a = new PersianAnalyzer(TEST_VERSION_CURRENT, new String[] { "the", "and", "a" });
+    PersianAnalyzer a = new PersianAnalyzer(TEST_VERSION_CURRENT, "the", "and", "a");
     assertAnalyzesTo(a, "The quick brown fox.", new String[] { "quick",
         "brown", "fox" });
   }
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java	(revision 1214047)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java	(working copy)
@@ -136,7 +136,7 @@
  
   public void testStemExclusionTable() throws Exception {
     BrazilianAnalyzer a = new BrazilianAnalyzer(TEST_VERSION_CURRENT);
-    a.setStemExclusionTable(new String[] { "quintessência" });
+    a.setStemExclusionTable("quintessência");
     checkReuse(a, "quintessência", "quintessência"); // excluded words will be completely unchanged.
   }
   
@@ -175,7 +175,7 @@
   public void testExclusionTableReuse() throws Exception {
     BrazilianAnalyzer a = new BrazilianAnalyzer(TEST_VERSION_CURRENT);
     checkReuse(a, "quintessência", "quintessente");
-    a.setStemExclusionTable(new String[] { "quintessência" });
+    a.setStemExclusionTable("quintessência");
     checkReuse(a, "quintessência", "quintessência");
   }
   
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java	(revision 1214047)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java	(working copy)
@@ -231,7 +231,7 @@
 	public void testExclusionTableReuse() throws Exception {
 	  FrenchAnalyzer fa = new FrenchAnalyzer(TEST_VERSION_CURRENT);
 	  assertAnalyzesToReuse(fa, "habitable", new String[] { "habit" });
-	  fa.setStemExclusionTable(new String[] { "habitable" });
+	  fa.setStemExclusionTable("habitable");
 	  assertAnalyzesToReuse(fa, "habitable", new String[] { "habitable" });
 	}
 	
Index: lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
===================================================================
--- lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java	(revision 1214047)
+++ lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java	(working copy)
@@ -146,7 +146,7 @@
   public void testExclusionTableReuse() throws Exception {
     DutchAnalyzer a = new DutchAnalyzer(TEST_VERSION_CURRENT);
     checkOneTermReuse(a, "lichamelijk", "licham");
-    a.setStemExclusionTable(new String[] { "lichamelijk" });
+    a.setStemExclusionTable("lichamelijk");
     checkOneTermReuse(a, "lichamelijk", "lichamelijk");
 
     
Index: lucene/contrib/analyzers/common/src/java/org/tartarus/snowball/TestApp.java
===================================================================
--- lucene/contrib/analyzers/common/src/java/org/tartarus/snowball/TestApp.java	(revision 1214047)
+++ lucene/contrib/analyzers/common/src/java/org/tartarus/snowball/TestApp.java	(working copy)
@@ -57,7 +57,7 @@
 	Class<? extends SnowballProgram> stemClass = Class.forName("org.tartarus.snowball.ext." +
 					args[0] + "Stemmer").asSubclass(SnowballProgram.class);
         SnowballProgram stemmer = stemClass.newInstance();
-	Method stemMethod = stemClass.getMethod("stem", new Class[0]);
+	Method stemMethod = stemClass.getMethod("stem");
 
 	Reader reader;
 	reader = new InputStreamReader(new FileInputStream(args[1]));
Index: lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java	(working copy)
@@ -166,13 +166,13 @@
     }
     
     try{
-      set.addAll(Arrays.asList(new String[]{NOT_IN_SET}));  
+      set.addAll(Arrays.asList(NOT_IN_SET));  
       fail("Modified unmodifiable set");
     }catch (UnsupportedOperationException e) {
       // expected
       assertFalse("Test String has been added to unmodifiable set", set.contains(NOT_IN_SET));
     }
-    
+    List<String> = Collections.emptyList();
     for (int i = 0; i < TEST_STOP_WORDS.length; i++) {
       assertTrue(set.contains(TEST_STOP_WORDS[i]));  
     }
Index: lucene/src/test/org/apache/lucene/TestSearch.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestSearch.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/TestSearch.java	(working copy)
@@ -112,9 +112,8 @@
       };
       ScoreDoc[] hits = null;
 
-      Sort sort = new Sort(new SortField[] {
-          SortField.FIELD_SCORE,
-          new SortField("id", SortField.INT)});
+      Sort sort = new Sort(SortField.FIELD_SCORE,
+                           new SortField("id", SortField.INT));
 
       QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, "contents", analyzer);
       parser.setPhraseSlop(4);
Index: lucene/src/test/org/apache/lucene/search/TestSort.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSort.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/search/TestSort.java	(working copy)
@@ -627,7 +627,7 @@
     assertMatches (full, queryG, sort, "ZYXW");
 
     // Do the same for a MultiSearcher
-    Searcher multiSearcher=new MultiSearcher (new Searchable[] { full });
+    Searcher multiSearcher=new MultiSearcher (full);
 
     sort.setSort (new SortField ("int", SortField.INT),
                                 new SortField ("string", SortField.STRING),
@@ -702,7 +702,7 @@
     // Test the MultiSearcher's ability to preserve locale-sensitive ordering
     // by wrapping it around a single searcher
   public void testInternationalMultiSearcherSort() throws Exception {
-    Searcher multiSearcher = new MultiSearcher (new Searchable[] { full });
+    Searcher multiSearcher = new MultiSearcher (full);
     
     sort.setSort (new SortField ("i18n", new Locale("sv", "se")));
     assertMatches (multiSearcher, queryY, sort, "BJDFH");
@@ -716,7 +716,7 @@
 
   // test a variety of sorts using more than one searcher
   public void testMultiSort() throws Exception {
-    MultiSearcher searcher = new MultiSearcher (new Searchable[] { searchX, searchY });
+    MultiSearcher searcher = new MultiSearcher (searchX, searchY);
     runMultiSorts(searcher, false);
   }
 
@@ -740,7 +740,7 @@
 
     // we'll test searching locally, remote and multi
     
-    MultiSearcher multi  = new MultiSearcher (new Searchable[] { searchX, searchY });
+    MultiSearcher multi  = new MultiSearcher (searchX, searchY);
 
     // change sorting and make sure relevancy stays the same
 
Index: lucene/src/test/org/apache/lucene/search/TestBoolean2.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBoolean2.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/search/TestBoolean2.java	(working copy)
@@ -75,7 +75,7 @@
     do {
       final Directory copy = new MockDirectoryWrapper(random, new RAMDirectory(dir2));
       RandomIndexWriter w = new RandomIndexWriter(random, dir2);
-      w.addIndexes(new Directory[] {copy});
+      w.addIndexes(copy);
       docCount = w.maxDoc();
       w.close();
       mulFactor *= 2;
Index: lucene/src/test/org/apache/lucene/search/TestExplanations.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestExplanations.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/search/TestExplanations.java	(working copy)
@@ -171,7 +171,7 @@
   }
   /** MACRO for SpanOrQuery containing two SpanQueries */
   public SpanOrQuery sor(SpanQuery s, SpanQuery e) {
-    return new SpanOrQuery(new SpanQuery[] { s, e });
+    return new SpanOrQuery(s, e);
   }
   
   /** MACRO for SpanOrQuery containing three SpanTerm queries */
@@ -180,7 +180,7 @@
   }
   /** MACRO for SpanOrQuery containing two SpanQueries */
   public SpanOrQuery sor(SpanQuery s, SpanQuery m, SpanQuery e) {
-    return new SpanOrQuery(new SpanQuery[] { s, m, e });
+    return new SpanOrQuery(s, m, e);
   }
   
   /** MACRO for SpanNearQuery containing two SpanTerm queries */
Index: lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java	(working copy)
@@ -120,7 +120,7 @@
   private static class CustomMulAddQuery extends CustomScoreQuery {
     // constructor
     CustomMulAddQuery(Query q, ValueSourceQuery qValSrc1, ValueSourceQuery qValSrc2) {
-      super(q, new ValueSourceQuery[]{qValSrc1, qValSrc2});
+      super(q, qValSrc1, qValSrc2);
     }
 
     /*(non-Javadoc) @see org.apache.lucene.search.function.CustomScoreQuery#name() */
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java	(working copy)
@@ -298,7 +298,7 @@
     IndexReader r1 = IndexReader.open(dir1, false);
     IndexReader r2 = IndexReader.open(dir2, false);
 
-    MultiReader multiReader = new MultiReader(new IndexReader[] { r1, r2 });
+    MultiReader multiReader = new MultiReader(r1, r2);
     performDefaultTests(multiReader);
     multiReader.close();
     dir1.close();
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -1338,7 +1338,7 @@
 
     IndexReader r1 = IndexReader.open(dir2, true);
     IndexReader r2 = (IndexReader) r1.clone();
-    writer.addIndexes(new IndexReader[] {r1, r2});
+    writer.addIndexes(r1, r2);
     writer.close();
 
     IndexReader r3 = IndexReader.open(dir, true);
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -243,7 +243,7 @@
 
     IndexReader r0 = writer.getReader();
     assertTrue(r0.isCurrent());
-    writer.addIndexes(new Directory[] { dir2 });
+    writer.addIndexes(dir2);
     assertFalse(r0.isCurrent());
     r0.close();
 
@@ -284,11 +284,11 @@
     createIndexNoClose(!doFullMerge, "index2", writer2);
     writer2.close();
 
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
 
     IndexReader r1 = writer.getReader();
     assertEquals(500, r1.maxDoc());
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(working copy)
@@ -216,9 +216,8 @@
 
       @Override
       protected IndexReader openReader() throws IOException {
-        return new MultiReader(new IndexReader[] 
-                        {IndexReader.open(dir1, false), 
-                         IndexReader.open(dir2, false)});
+        return new MultiReader(IndexReader.open(dir1, false),
+                               IndexReader.open(dir2, false));
       }
       
     });
@@ -242,12 +241,11 @@
 
       @Override
       protected IndexReader openReader() throws IOException {
-        return new MultiReader(new IndexReader[] 
-                        {IndexReader.open(dir3, false), 
-                         IndexReader.open(dir4, false),
-                         // Does not implement reopen, so
-                         // hits exception:
-                         new FilterIndexReader(IndexReader.open(dir3, false))});
+        return new MultiReader(IndexReader.open(dir3, false), 
+                               IndexReader.open(dir4, false),
+                               // Does not implement reopen, so
+                               // hits exception:
+                               new FilterIndexReader(IndexReader.open(dir3, false)));
       }
       
     });
@@ -283,10 +281,9 @@
         ParallelReader pr = new ParallelReader();
         pr.add(IndexReader.open(dir1, false));
         pr.add(IndexReader.open(dir2, false));
-        MultiReader mr = new MultiReader(new IndexReader[] {
-            IndexReader.open(dir3, false), IndexReader.open(dir4, false)});
-        return new MultiReader(new IndexReader[] {
-           pr, mr, IndexReader.open(dir5, false)});
+        MultiReader mr = new MultiReader(IndexReader.open(dir3, false), 
+                                         IndexReader.open(dir4, false));
+        return new MultiReader(pr, mr, IndexReader.open(dir5, false));
       }
     });
     dir1.close();
Index: lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -77,7 +77,7 @@
     // test doc count before segments are merged
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
     assertEquals(100, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux, aux2 });
+    writer.addIndexes(aux, aux2);
     assertEquals(190, writer.maxDoc());
     writer.close();
 
@@ -98,7 +98,7 @@
     // test doc count before segments are merged
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
     assertEquals(190, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux3 });
+    writer.addIndexes(aux3);
     assertEquals(230, writer.maxDoc());
     writer.close();
 
@@ -129,7 +129,7 @@
 
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
     assertEquals(230, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux4 });
+    writer.addIndexes(aux4);
     assertEquals(231, writer.maxDoc());
     writer.close();
 
@@ -199,7 +199,7 @@
       writer.updateDocument(new Term("id", "" + (i%10)), doc);
     }
     
-    writer.addIndexes(new Directory[] {aux});
+    writer.addIndexes(aux);
     
     // Deletes one of the 10 added docs, leaving 9:
     PhraseQuery q = new PhraseQuery();
@@ -244,7 +244,7 @@
     q.add(new Term("content", "14"));
     writer.deleteDocuments(q);
 
-    writer.addIndexes(new Directory[] {aux});
+    writer.addIndexes(aux);
 
     writer.forceMerge(1);
     writer.commit();
@@ -296,7 +296,7 @@
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));
     try {
       // cannot add self
-      writer.addIndexes(new Directory[] { aux, dir });
+      writer.addIndexes(aux, dir);
       assertTrue(false);
     }
     catch (IllegalArgumentException e) {
@@ -330,7 +330,7 @@
     );
     addDocs(writer, 10);
 
-    writer.addIndexes(new Directory[] { aux });
+    writer.addIndexes(aux);
     assertEquals(1040, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -359,7 +359,7 @@
     );
     addDocs(writer, 2);
 
-    writer.addIndexes(new Directory[] { aux });
+    writer.addIndexes(aux);
     assertEquals(1032, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -387,7 +387,7 @@
             setMergePolicy(newLogMergePolicy(4))
     );
 
-    writer.addIndexes(new Directory[] { aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)) });
+    writer.addIndexes(aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)));
     assertEquals(1060, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -422,7 +422,7 @@
             setMergePolicy(newLogMergePolicy(4))
     );
 
-    writer.addIndexes(new Directory[] { aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)) });
+    writer.addIndexes(aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)));
     assertEquals(1020, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -474,7 +474,7 @@
             setMergePolicy(newLogMergePolicy(4))
     );
 
-    writer.addIndexes(new Directory[] { aux, aux2 });
+    writer.addIndexes(aux, aux2);
     assertEquals(1040, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -598,7 +598,7 @@
     writer = new IndexWriter(dir2, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer(random))
         .setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(lmp));
-    writer.addIndexes(new Directory[] {dir});
+    writer.addIndexes(dir);
     writer.close();
     dir.close();
     dir2.close();
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -64,7 +64,7 @@
             setMergePolicy(newLogMergePolicy(2))
     );
     writer.setInfoStream(VERBOSE ? System.out : null);
-    writer.addIndexes(new Directory[]{indexA, indexB});
+    writer.addIndexes(indexA, indexB);
     writer.forceMerge(1);
     writer.close();
 
Index: lucene/src/test/org/apache/lucene/index/TestParallelReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestParallelReader.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestParallelReader.java	(working copy)
@@ -100,9 +100,9 @@
     pr.add(IndexReader.open(dir1, false));
     pr.add(IndexReader.open(dir2, false));
 
-    Document doc11 = pr.document(0, new MapFieldSelector(new String[] {"f1"}));
-    Document doc24 = pr.document(1, new MapFieldSelector(Arrays.asList(new String[] {"f4"})));
-    Document doc223 = pr.document(1, new MapFieldSelector(new String[] {"f2", "f3"}));
+    Document doc11 = pr.document(0, new MapFieldSelector("f1"));
+    Document doc24 = pr.document(1, new MapFieldSelector(Arrays.<String>asList("f4")));
+    Document doc223 = pr.document(1, new MapFieldSelector("f2", "f3"));
     
     assertEquals(1, doc11.getFields().size());
     assertEquals(1, doc24.getFields().size());
Index: lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(working copy)
@@ -57,7 +57,7 @@
     pr.add(IndexReader.open(rd2,true));
 		
     // When unpatched, Lucene crashes here with a NoSuchElementException (caused by ParallelTermEnum)
-    iwOut.addIndexes(new IndexReader[] { pr });
+    iwOut.addIndexes(pr);
 		
     iwOut.forceMerge(1);
     iwOut.close();
@@ -109,7 +109,7 @@
     pr.add(IndexReader.open(rd2,true));
 
     // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)
-    iwOut.addIndexes(new IndexReader[] { pr });
+    iwOut.addIndexes(pr);
 
     // ParallelReader closes any IndexReader you added to it:
     pr.close();
Index: lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -216,7 +216,7 @@
       Directory targetDir = newDirectory();
       IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));
-      w.addIndexes(new Directory[] { dir });
+      w.addIndexes(dir);
       w.close();
       
       dir.close();
@@ -235,7 +235,7 @@
       Directory targetDir = newDirectory();
       IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));
-      w.addIndexes(new IndexReader[] { reader });
+      w.addIndexes(reader);
       w.close();
       reader.close();
             
Index: lucene/src/test/org/apache/lucene/index/TestNorms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestNorms.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/index/TestNorms.java	(working copy)
@@ -100,7 +100,7 @@
     IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
                                      .setMaxBufferedDocs(5).setMergePolicy(newLogMergePolicy(3)));
-    iw.addIndexes(new Directory[]{dir1,dir2});
+    iw.addIndexes(dir1,dir2);
     iw.forceMerge(1);
     iw.close();
     
Index: lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java	(working copy)
@@ -108,9 +108,8 @@
       Query query = parser.parse(HIGH_PRIORITY);
       out.println("Query: " + query.toString(PRIORITY_FIELD));
 
-      final Sort sort = new Sort(new SortField[] {
-          SortField.FIELD_SCORE,
-          new SortField(ID_FIELD, SortField.INT)});
+      final Sort sort = new Sort(SortField.FIELD_SCORE,
+                                 new SortField(ID_FIELD, SortField.INT));
 
       ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;
       printHits(out, hits, searcher);
Index: lucene/src/test/org/apache/lucene/util/TestCollectionUtil.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestCollectionUtil.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/util/TestCollectionUtil.java	(working copy)
@@ -92,7 +92,7 @@
   
   public void testEmptyListSort() {
     // should produce no exceptions
-    List<Integer> list = Arrays.asList(new Integer[0]);
+    List<Integer> list = Arrays.asList(new Integer[0]); // LUCENE-2989
     CollectionUtil.quickSort(list);
     CollectionUtil.mergeSort(list);
     CollectionUtil.insertionSort(list);
Index: lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java	(revision 1214047)
+++ lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java	(working copy)
@@ -71,7 +71,7 @@
     wB.close();
     readerA = IndexReader.open(dirA, true);
     readerB = IndexReader.open(dirB, true);
-    readerX = new MultiReader(new IndexReader[] { readerA, readerB });
+    readerX = new MultiReader(readerA, readerB);
   }
 
   @Override
Index: lucene/src/java/org/apache/lucene/search/BooleanScorer2.java
===================================================================
--- lucene/src/java/org/apache/lucene/search/BooleanScorer2.java	(revision 1214047)
+++ lucene/src/java/org/apache/lucene/search/BooleanScorer2.java	(working copy)
@@ -196,7 +196,7 @@
   private Scorer dualConjunctionSumScorer(boolean disableCoord,
                                           Similarity similarity,
                                           Scorer req1, Scorer req2) throws IOException { // non counting.
-    return new ConjunctionScorer(weight, disableCoord ? 1.0f : similarity.coord(2, 2), new Scorer[]{req1, req2});
+    return new ConjunctionScorer(weight, disableCoord ? 1.0f : similarity.coord(2, 2), req1, req2);
     // All scorers match, so defaultSimilarity always has 1 as
     // the coordination factor.
     // Therefore the sum of the scores of two scorers
Index: lucene/src/test-framework/java/org/apache/lucene/search/QueryUtils.java
===================================================================
--- lucene/src/test-framework/java/org/apache/lucene/search/QueryUtils.java	(revision 1214047)
+++ lucene/src/test-framework/java/org/apache/lucene/search/QueryUtils.java	(working copy)
@@ -156,18 +156,14 @@
     IndexReader[] readers = new IndexReader[] {
       edge < 0 ? r : IndexReader.open(makeEmptyIndex(random, 0), true),
       IndexReader.open(makeEmptyIndex(random, 0), true),
-      new MultiReader(new IndexReader[] {
-        IndexReader.open(makeEmptyIndex(random, edge < 0 ? 4 : 0), true),
-        IndexReader.open(makeEmptyIndex(random, 0), true),
-        0 == edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)
-      }),
+      new MultiReader(IndexReader.open(makeEmptyIndex(random, edge < 0 ? 4 : 0), true),
+                      IndexReader.open(makeEmptyIndex(random, 0), true),
+                      0 == edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)),
       IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 7), true),
       IndexReader.open(makeEmptyIndex(random, 0), true),
-      new MultiReader(new IndexReader[] {
-        IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 5), true),
-        IndexReader.open(makeEmptyIndex(random, 0), true),
-        0 < edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)
-      })
+      new MultiReader(IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 5), true),
+                      IndexReader.open(makeEmptyIndex(random, 0), true),
+                      0 < edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true))
     };
     IndexSearcher out = new IndexSearcher(new MultiReader(readers));
     out.setSimilarity(s.getSimilarity());
