Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenPositionFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenPositionFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenPositionFilterFactory.java	(revision )
@@ -33,8 +33,8 @@
       tokenizer.setEnableChecks(consumeAll);
       TokenStream stream = tokenizer;
       stream = tokenFilterFactory("LimitTokenPosition",
-          LimitTokenPositionFilterFactory.MAX_TOKEN_POSITION_KEY, "1",
-          LimitTokenPositionFilterFactory.CONSUME_ALL_TOKENS_KEY, Boolean.toString(consumeAll)
+          "maxTokenPosition", "1",
+          "consumeAllTokens", Boolean.toString(consumeAll)
       ).create(stream);
       assertTokenStreamContents(stream, new String[]{"A1"});
     }
@@ -45,7 +45,7 @@
       tokenFilterFactory("LimitTokenPosition");
     });
     assertTrue("exception doesn't mention param: " + expected.getMessage(),
-        0 < expected.getMessage().indexOf(LimitTokenPositionFilterFactory.MAX_TOKEN_POSITION_KEY));
+        0 < expected.getMessage().indexOf("maxTokenPosition"));
   }
 
   public void testMaxPosition1WithShingles() throws Exception {
@@ -60,8 +60,8 @@
           "maxShingleSize", "3",
           "outputUnigrams", "true").create(stream);
       stream = tokenFilterFactory("LimitTokenPosition",
-          LimitTokenPositionFilterFactory.MAX_TOKEN_POSITION_KEY, "1",
-          LimitTokenPositionFilterFactory.CONSUME_ALL_TOKENS_KEY, Boolean.toString(consumeAll)
+          "maxTokenPosition", "1",
+          "consumeAllTokens", Boolean.toString(consumeAll)
       ).create(stream);
       assertTokenStreamContents(stream, new String[]{"one", "one two", "one two three"});
     }
Index: lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java	(revision )
@@ -17,12 +17,15 @@
 package org.apache.lucene.search.suggest.analyzing;
 
 import java.io.IOException;
+import java.util.Arrays;
 import java.util.Map;
 
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.WordlistLoader; // jdocs
 import org.apache.lucene.analysis.core.StopAnalyzer;
+import static org.apache.lucene.analysis.core.StopFilterFactory.FORMAT_WORDSET;
+import static org.apache.lucene.analysis.core.StopFilterFactory.FORMAT_SNOWBALL;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
@@ -72,22 +75,18 @@
  * </ul>
  */
   public class SuggestStopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  /** the default format, one word per line, whole line comments start with "#" */
-  public static final String FORMAT_WORDSET = "wordset";
-  /** multiple words may be specified on each line, trailing comments start with "&#124;" */
-  public static final String FORMAT_SNOWBALL = "snowball";
 
   private CharArraySet stopWords;
   private final String stopWordFiles;
   private final String format;
   private final boolean ignoreCase;
 
-  /** Creates a new StopFilterFactory */
+  /** Creates a new SuggestStopFilterFactory */
   public SuggestStopFilterFactory(Map<String,String> args) {
     super(args);
-    stopWordFiles = get(args, "words");
-    format = get(args, "format", (null == stopWordFiles ? null : FORMAT_WORDSET));
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    stopWordFiles = get(args, WORDS);
+    format = get(args, FORMAT, Arrays.asList(FORMAT_WORDSET, FORMAT_SNOWBALL), (null == stopWordFiles ? null : FORMAT_WORDSET));
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikFilterFactory.java	(revision )
@@ -50,10 +50,8 @@
  * @see <a href="http://morfologik.blogspot.com/">Morfologik web site</a>
  */
 public class MorfologikFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  /** Dictionary resource attribute (should have {@code ".dict"} suffix), loaded from {@link ResourceLoader}. */
-  public static final String DICTIONARY_ATTRIBUTE = "dictionary";
 
-  /** {@link #DICTIONARY_ATTRIBUTE} value passed to {@link #inform}. */
+  /** {@link #DICTIONARY} value (should have {@code ".dict"} suffix) passed to {@link #inform}. */
   private String resourceName;
 
   /** Loaded {@link Dictionary}, initialized on {@link #inform(ResourceLoader)}. */
@@ -68,10 +66,10 @@
     String dictionaryResource = get(args, DICTIONARY_RESOURCE_ATTRIBUTE);
     if (dictionaryResource != null && !dictionaryResource.isEmpty()) {
       throw new IllegalArgumentException("The " + DICTIONARY_RESOURCE_ATTRIBUTE + " attribute is no "
-          + "longer supported. Use the '" + DICTIONARY_ATTRIBUTE + "' attribute instead (see LUCENE-6833).");
+          + "longer supported. Use the '" + DICTIONARY + "' attribute instead (see LUCENE-6833).");
     }
 
-    resourceName = get(args, DICTIONARY_ATTRIBUTE);
+    resourceName = get(args, DICTIONARY);
 
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilterFactory.java	(revision )
@@ -50,8 +50,6 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class WordDelimiterGraphFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-  public static final String TYPES = "types";
 
   private final String wordFiles;
   private final String types;
@@ -84,13 +82,13 @@
     if (getInt(args, "splitOnNumerics", 1) != 0) {
       flags |= SPLIT_ON_NUMERICS;
     }
-    if (getInt(args, "preserveOriginal", 0) != 0) {
-      flags |= PRESERVE_ORIGINAL;
+    if (getInt(args, PRESERVE_ORIGINAL, 0) != 0) {
+      flags |= WordDelimiterGraphFilter.PRESERVE_ORIGINAL;
     }
     if (getInt(args, "stemEnglishPossessive", 1) != 0) {
       flags |= STEM_ENGLISH_POSSESSIVE;
     }
-    wordFiles = get(args, PROTECTED_TOKENS);
+    wordFiles = get(args, PROTECTED);
     types = get(args, TYPES);
     this.flags = flags;
     if (!args.isEmpty()) {
Index: solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedWordSetResource.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedWordSetResource.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedWordSetResource.java	(revision )
@@ -35,6 +35,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static org.apache.solr.rest.schema.analysis.BaseManagedTokenFilterFactory.IGNORE_CASE;
+
 /**
  * ManagedResource implementation for managing a set of words using the REST API;
  * useful for managing stop words and/or protected words for analysis components 
@@ -44,8 +46,7 @@
   implements ManagedResource.ChildResourceSupport {
   
   public static final String WORD_SET_JSON_FIELD = "wordSet";
-  public static final String IGNORE_CASE_INIT_ARG = "ignoreCase";
-      
+
   private SortedSet<String> managedWords = null;
 
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
@@ -63,7 +64,7 @@
   }
 
   /**
-   * Returns the boolean value of the {@link #IGNORE_CASE_INIT_ARG} init arg,
+   * Returns the boolean value of the {@link BaseManagedTokenFilterFactory#IGNORE_CASE} init arg,
    * or the default value (false) if it has not been specified
    */
   public boolean getIgnoreCase() {
@@ -71,11 +72,11 @@
   }
 
   /**
-   * Returns the boolean value of the {@link #IGNORE_CASE_INIT_ARG} init arg,
+   * Returns the boolean value of the {@link BaseManagedTokenFilterFactory#IGNORE_CASE} init arg,
    * or the default value (false) if it has not been specified
    */
   public boolean getIgnoreCase(NamedList<?> initArgs) {
-    Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE_INIT_ARG);
+    Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE);
     // ignoreCase = false by default
     return null == ignoreCase ? false : ignoreCase;
   }
@@ -93,9 +94,9 @@
 
     // the default behavior is to not ignore case,
     boolean ignoreCase = getIgnoreCase(initArgs);
-    if (null == initArgs.get(IGNORE_CASE_INIT_ARG)) {
+    if (null == initArgs.get(IGNORE_CASE)) {
       // Explicitly include the default value of ignoreCase
-      ((NamedList<Object>)initArgs).add(IGNORE_CASE_INIT_ARG, false);
+      ((NamedList<Object>)initArgs).add(IGNORE_CASE, false);
     }
 
     managedWords = new TreeSet<>();
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java	(revision )
@@ -18,6 +18,7 @@
 
 
 import java.io.IOException;
+import java.util.Arrays;
 import java.util.Map;
 
 import org.apache.lucene.analysis.CharArraySet;
@@ -81,9 +82,9 @@
   /** Creates a new StopFilterFactory */
   public StopFilterFactory(Map<String,String> args) {
     super(args);
-    stopWordFiles = get(args, "words");
-    format = get(args, "format", (null == stopWordFiles ? null : FORMAT_WORDSET));
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    stopWordFiles = get(args, WORDS);
+    format = get(args, FORMAT, Arrays.asList(FORMAT_WORDSET, FORMAT_SNOWBALL), (null == stopWordFiles ? null : FORMAT_WORDSET));
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java	(revision )
@@ -72,7 +72,7 @@
   /** Creates a new HyphenationCompoundWordTokenFilterFactory */
   public HyphenationCompoundWordTokenFilterFactory(Map<String, String> args) {
     super(args);
-    dictFile = get(args, "dictionary");
+    dictFile = get(args, DICTIONARY);
     encoding = get(args, "encoding");
     hypFile = require(args, "hyphenator");
     minWordSize = getInt(args, "minWordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DelimitedTermFrequencyTokenFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DelimitedTermFrequencyTokenFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DelimitedTermFrequencyTokenFilterFactory.java	(revision )
@@ -33,14 +33,13 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class DelimitedTermFrequencyTokenFilterFactory extends TokenFilterFactory {
-  public static final String DELIMITER_ATTR = "delimiter";
 
   private final char delimiter;
 
   /** Creates a new DelimitedPayloadTokenFilterFactory */
   public DelimitedTermFrequencyTokenFilterFactory(Map<String, String> args) {
     super(args);
-    delimiter = getChar(args, DELIMITER_ATTR, DelimitedTermFrequencyTokenFilter.DEFAULT_DELIMITER);
+    delimiter = getChar(args, DELIMITER, DelimitedTermFrequencyTokenFilter.DEFAULT_DELIMITER);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
\ No newline at end of file
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java	(revision )
@@ -83,19 +83,18 @@
     });
 
     String msg = expected.getMessage();
-    assertTrue(msg, msg.contains("Unknown"));
+    assertTrue(msg, msg.contains("Configuration Error:"));
     assertTrue(msg, msg.contains("format"));
-    assertTrue(msg, msg.contains("bogus"));
     
     expected = expectThrows(IllegalArgumentException.class, () -> {
       createFactory(
           // implicit default words file
-          "format", "bogus");
+          "format", "wordset");
     });
     msg = expected.getMessage();
     assertTrue(msg, msg.contains("can not be specified"));
     assertTrue(msg, msg.contains("format"));
-    assertTrue(msg, msg.contains("bogus"));
+    assertTrue(msg, msg.contains("wordset"));
   }                                             
 
   private SuggestStopFilterFactory createFactory(String ... params) throws IOException {
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenOffsetFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenOffsetFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenOffsetFilterFactory.java	(revision )
@@ -34,8 +34,8 @@
       tokenizer.setEnableChecks(consumeAll);
       TokenStream stream = tokenizer;
       stream = tokenFilterFactory("LimitTokenOffset",
-          LimitTokenOffsetFilterFactory.MAX_START_OFFSET, "3",
-          LimitTokenOffsetFilterFactory.CONSUME_ALL_TOKENS_KEY, Boolean.toString(consumeAll)
+          "maxStartOffset", "3",
+          "consumeAllTokens", Boolean.toString(consumeAll)
       ).create(stream);
       assertTokenStreamContents(stream, new String[]{"A1", "B2"});
     }
@@ -47,7 +47,7 @@
       tokenFilterFactory("LimitTokenOffset");
     });
     assertTrue("exception doesn't mention param: " + expected.getMessage(),
-          0 < expected.getMessage().indexOf(LimitTokenOffsetFilterFactory.MAX_START_OFFSET));
+          0 < expected.getMessage().indexOf("maxStartOffset"));
   }
 
   /**
@@ -56,7 +56,7 @@
   public void testBogusArguments() throws Exception {
     IllegalArgumentException expected = expectThrows(IllegalArgumentException.class, () -> {
       tokenFilterFactory("LimitTokenOffset",
-          LimitTokenOffsetFilterFactory.MAX_START_OFFSET, "3",
+          "maxStartOffset", "3",
           "bogusArg", "bogusValue");
     });
     assertTrue(expected.getMessage().contains("Unknown parameters"));
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java	(revision )
@@ -48,7 +48,7 @@
   /** Creates a new DictionaryCompoundWordTokenFilterFactory */
   public DictionaryCompoundWordTokenFilterFactory(Map<String, String> args) {
     super(args);
-    dictFile = require(args, "dictionary");
+    dictFile = require(args, DICTIONARY);
     minWordSize = getInt(args, "minWordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
     minSubwordSize = getInt(args, "minSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE);
     maxSubwordSize = getInt(args, "maxSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java	(revision )
@@ -45,7 +45,7 @@
   public ElisionFilterFactory(Map<String,String> args) {
     super(args);
     articlesFile = get(args, "articles");
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java	(revision )
@@ -55,8 +55,6 @@
  */
 @Deprecated
 public class WordDelimiterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-  public static final String TYPES = "types";
 
   private final String wordFiles;
   private final String types;
@@ -89,13 +87,13 @@
     if (getInt(args, "splitOnNumerics", 1) != 0) {
       flags |= SPLIT_ON_NUMERICS;
     }
-    if (getInt(args, "preserveOriginal", 0) != 0) {
-      flags |= PRESERVE_ORIGINAL;
+    if (getInt(args, PRESERVE_ORIGINAL, 0) != 0) {
+      flags |= WordDelimiterFilter.PRESERVE_ORIGINAL;
     }
     if (getInt(args, "stemEnglishPossessive", 1) != 0) {
       flags |= STEM_ENGLISH_POSSESSIVE;
     }
-    wordFiles = get(args, PROTECTED_TOKENS);
+    wordFiles = get(args, PROTECTED);
     types = get(args, TYPES);
     this.flags = flags;
     if (!args.isEmpty()) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java	(revision )
@@ -59,7 +59,6 @@
  * @since solr1.2
  */
 public class PatternTokenizerFactory extends TokenizerFactory {
-  public static final String PATTERN = "pattern";
   public static final String GROUP = "group";
  
   protected final Pattern pattern;
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java	(revision )
@@ -38,8 +38,7 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class KeywordMarkerFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-  public static final String PATTERN = "pattern";
+
   private final String wordFiles;
   private final String stringPattern;
   private final boolean ignoreCase;
@@ -49,9 +48,9 @@
   /** Creates a new KeywordMarkerFilterFactory */
   public KeywordMarkerFilterFactory(Map<String,String> args) {
     super(args);
-    wordFiles = get(args, PROTECTED_TOKENS);
+    wordFiles = get(args, PROTECTED);
     stringPattern = get(args, PATTERN);
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java	(revision )
@@ -91,9 +91,9 @@
   
   public SynonymFilterFactory(Map<String,String> args) {
     super(args);
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     synonyms = require(args, "synonyms");
-    format = get(args, "format");
+    format = get(args, FORMAT);
     expand = getBoolean(args, "expand", true);
 
     analyzerName = get(args, "analyzer");
@@ -104,7 +104,7 @@
     }
 
     if (tokenizerFactory != null) {
-      tokArgs.put("luceneMatchVersion", getLuceneMatchVersion().toString());
+      tokArgs.put(LUCENE_MATCH_VERSION, getLuceneMatchVersion().toString());
       for (Iterator<String> itr = args.keySet().iterator(); itr.hasNext();) {
         String key = itr.next();
         tokArgs.put(key.replaceAll("^tokenizerFactory\\.",""), args.get(key));
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java	(revision )
@@ -43,7 +43,6 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class SnowballPorterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
 
   private final String language;
   private final String wordFiles;
@@ -54,7 +53,7 @@
   public SnowballPorterFilterFactory(Map<String,String> args) {
     super(args);
     language = get(args, "language", "English");
-    wordFiles = get(args, PROTECTED_TOKENS);
+    wordFiles = get(args, PROTECTED);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymGraphFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymGraphFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymGraphFilterFactory.java	(revision )
@@ -56,7 +56,6 @@
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
   public static final String SYNONYM_MAPPINGS = "synonymMappings";
-  public static final String IGNORE_CASE_INIT_ARG = "ignoreCase";
 
   /**
    * Used internally to preserve the case of synonym mappings regardless
@@ -116,7 +115,7 @@
     {
       NamedList<Object> initArgs = (NamedList<Object>)managedInitArgs;
 
-      String format = (String)initArgs.get("format");
+      String format = (String)initArgs.get(FORMAT);
       if (format != null && !"solr".equals(format)) {
         throw new SolrException(ErrorCode.BAD_REQUEST, "Invalid format "+
             format+"! Only 'solr' is supported.");
@@ -124,8 +123,8 @@
 
       // the default behavior is to not ignore case, 
       // so if not supplied, then install the default
-      if (initArgs.get(IGNORE_CASE_INIT_ARG) == null) {
-        initArgs.add(IGNORE_CASE_INIT_ARG, Boolean.FALSE);
+      if (initArgs.get(IGNORE_CASE) == null) {
+        initArgs.add(IGNORE_CASE, Boolean.FALSE);
       }
 
       boolean ignoreCase = getIgnoreCase(managedInitArgs);
@@ -275,7 +274,7 @@
     }
 
     public boolean getIgnoreCase(NamedList<?> initArgs) {
-      Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE_INIT_ARG);
+      Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE);
       // ignoreCase = false by default
       return null == ignoreCase ? false : ignoreCase;
     }
@@ -398,7 +397,7 @@
     NamedList<Object> args = (NamedList<Object>)initArgs;
     args.add("synonyms", getResourceId());
     args.add("expand", "false");
-    args.add("format", "solr");
+    args.add(FORMAT, "solr");
 
     Map<String,String> filtArgs = new HashMap<>();
     for (Map.Entry<String,?> entry : args) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CommonAnalysisFactoryParams.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CommonAnalysisFactoryParams.java	(revision )
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CommonAnalysisFactoryParams.java	(revision )
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.util;
+
+/**
+ * Parameters used across analysis factories ({@link CharFilterFactory}, {@link TokenizerFactory} and {@link TokenFilterFactory}).
+ */
+interface CommonAnalysisFactoryParams {
+
+  /** Boolean flag to consume all tokens. If set to true then the full stream of tokens is exhausted */
+  String CONSUME_ALL_TOKENS = "consumeAllTokens";
+
+  /** delimiter is a separator character */
+  String DELIMITER = "delimiter";
+
+  /** dictionary refers to a file */
+  String DICTIONARY = "dictionary";
+
+  /** encoder refers to a string */
+  String ENCODER = "encoder";
+
+  /** format defines how the input file will be parsed */
+  String FORMAT = "format";
+
+  /** Boolean flag to ignore case */
+  String IGNORE_CASE = "ignoreCase";
+
+  /** Lucene match version */
+  String LUCENE_MATCH_VERSION = "luceneMatchVersion";
+
+  /** maximum */
+  String MAX = "max";
+
+  /** maximum token length */
+  String MAX_TOKEN_LENGTH = "maxTokenLength";
+
+  /** minimum */
+  String MIN = "min";
+
+  /** pattern refers to a regular expression */
+  String PATTERN = "pattern";
+
+  /** Boolean flag to preserve original token */
+  String PRESERVE_ORIGINAL = "preserveOriginal";
+
+  /** protected refers to a file, which contains list of words to be skipped/protected */
+  String PROTECTED = "protected";
+
+  /** types refers to a file */
+  String TYPES = "types";
+
+  /** words refers to a file, which contains list of words to be processed */
+  String WORDS = "words";
+}
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java	(revision )
@@ -38,14 +38,14 @@
  * @see PatternReplaceFilter
  */
 public class PatternReplaceFilterFactory extends TokenFilterFactory {
-  final Pattern pattern;
-  final String replacement;
-  final boolean replaceAll;
+  private final Pattern pattern;
+  private final String replacement;
+  private final boolean replaceAll;
   
   /** Creates a new PatternReplaceFilterFactory */
   public PatternReplaceFilterFactory(Map<String, String> args) {
     super(args);
-    pattern = getPattern(args, "pattern");
+    pattern = getPattern(args, PATTERN);
     replacement = get(args, "replacement");
     replaceAll = "all".equals(get(args, "replace", Arrays.asList("all", "first"), "all"));
     if (!args.isEmpty()) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymGraphFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymGraphFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymGraphFilterFactory.java	(revision )
@@ -84,12 +84,12 @@
   private final Map<String, String> tokArgs = new HashMap<>();
 
   private SynonymMap map;
-  
+
   public SynonymGraphFilterFactory(Map<String,String> args) {
     super(args);
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     synonyms = require(args, "synonyms");
-    format = get(args, "format");
+    format = get(args, FORMAT);
     expand = getBoolean(args, "expand", true);
 
     analyzerName = get(args, "analyzer");
@@ -100,7 +100,7 @@
     }
 
     if (tokenizerFactory != null) {
-      tokArgs.put("luceneMatchVersion", getLuceneMatchVersion().toString());
+      tokArgs.put(LUCENE_MATCH_VERSION, getLuceneMatchVersion().toString());
       for (Iterator<String> itr = args.keySet().iterator(); itr.hasNext();) {
         String key = itr.next();
         tokArgs.put(key.replaceAll("^tokenizerFactory\\.",""), args.get(key));
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java	(revision )
@@ -37,7 +37,7 @@
   /** Creates a new ClassicTokenizerFactory */
   public ClassicTokenizerFactory(Map<String,String> args) {
     super(args);
-    maxTokenLength = getInt(args, "maxTokenLength", StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+    maxTokenLength = getInt(args, MAX_TOKEN_LENGTH, StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java	(revision )
@@ -37,7 +37,7 @@
   /** Creates a new StandardTokenizerFactory */
   public StandardTokenizerFactory(Map<String,String> args) {
     super(args);
-    maxTokenLength = getInt(args, "maxTokenLength", StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+    maxTokenLength = getInt(args, MAX_TOKEN_LENGTH, StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternSplitTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternSplitTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternSplitTokenizerFactory.java	(revision )
@@ -55,7 +55,7 @@
  * @see SimplePatternSplitTokenizer
  */
 public class SimplePatternSplitTokenizerFactory extends TokenizerFactory {
-  public static final String PATTERN = "pattern";
+
   private final Automaton dfa;
   private final int maxDeterminizedStates;
  
@@ -64,7 +64,7 @@
     super(args);
     maxDeterminizedStates = getInt(args, "maxDeterminizedStates", Operations.DEFAULT_MAX_DETERMINIZED_STATES);
     dfa = Operations.determinize(new RegExp(require(args, PATTERN)).toAutomaton(), maxDeterminizedStates);
-    if (args.isEmpty() == false) {
+    if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
   }
Index: solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedStopFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedStopFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedStopFilterFactory.java	(revision )
@@ -76,7 +76,7 @@
     // first thing is to rebuild the Lucene CharArraySet from our managedWords set
     // which is slightly inefficient to do for every instance of the managed filter
     // but ManagedResource's don't have access to the luceneMatchVersion
-    boolean ignoreCase = args.getBooleanArg("ignoreCase");
+    boolean ignoreCase = args.getBooleanArg(IGNORE_CASE);
     stopWords = new CharArraySet(managedWords.size(), ignoreCase);
     stopWords.addAll(managedWords);
   }
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilterFactory.java	(revision )
@@ -32,8 +32,8 @@
     TokenStream stream = new MockTokenizer(MockTokenizer.WHITESPACE, false);
     ((Tokenizer)stream).setReader(reader);
     stream = tokenFilterFactory("Length",
-        LengthFilterFactory.MIN_KEY, "4",
-        LengthFilterFactory.MAX_KEY, "10").create(stream);
+        "min", "4",
+        "max", "10").create(stream);
     assertTokenStreamContents(stream, new String[] { "foobar" }, new int[] { 2 });
   }
 
@@ -41,8 +41,8 @@
   public void testBogusArguments() throws Exception {
     IllegalArgumentException expected = expectThrows(IllegalArgumentException.class, () -> {
       tokenFilterFactory("Length",
-          LengthFilterFactory.MIN_KEY, "4",
-          LengthFilterFactory.MAX_KEY, "5",
+          "min", "4",
+          "max", "5",
           "bogusArg", "bogusValue");
     });
     assertTrue(expected.getMessage().contains("Unknown parameters"));
@@ -55,9 +55,9 @@
       TokenStream stream = new MockTokenizer(MockTokenizer.WHITESPACE, false);
       ((Tokenizer)stream).setReader(reader);
       tokenFilterFactory("Length",
-          LengthFilterFactory.MIN_KEY, "5",
-          LengthFilterFactory.MAX_KEY, "4").create(stream);
+          "min", "5",
+          "max", "4").create(stream);
     });
     assertTrue(expected.getMessage().contains("maximum length must not be greater than minimum length"));
   }
-}
\ No newline at end of file
+}
Index: solr/core/src/java/org/apache/solr/schema/FieldType.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/schema/FieldType.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/schema/FieldType.java	(revision )
@@ -73,7 +73,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import static org.apache.lucene.analysis.util.AbstractAnalysisFactory.LUCENE_MATCH_VERSION_PARAM;
+import static org.apache.lucene.analysis.util.AbstractAnalysisFactory.LUCENE_MATCH_VERSION;
 
 /**
  * Base class for all field types used by an index schema.
@@ -959,7 +959,7 @@
           if (null != factoryArgs) {
             for (String key : factoryArgs.keySet()) {
               if ( ! CLASS_NAME.equals(key)) {
-                if (LUCENE_MATCH_VERSION_PARAM.equals(key)) {
+                if (LUCENE_MATCH_VERSION.equals(key)) {
                   if (charFilterFactory.isExplicitLuceneMatchVersion()) {
                     props.add(key, factoryArgs.get(key));
                   }
@@ -981,7 +981,7 @@
       if (null != factoryArgs) {
         for (String key : factoryArgs.keySet()) {
           if ( ! CLASS_NAME.equals(key)) {
-            if (LUCENE_MATCH_VERSION_PARAM.equals(key)) {
+            if (LUCENE_MATCH_VERSION.equals(key)) {
               if (tokenizerFactory.isExplicitLuceneMatchVersion()) {
                 tokenizerProps.add(key, factoryArgs.get(key));
               }
@@ -1003,7 +1003,7 @@
           if (null != factoryArgs) {
             for (String key : factoryArgs.keySet()) {
               if ( ! CLASS_NAME.equals(key)) {
-                if (LUCENE_MATCH_VERSION_PARAM.equals(key)) {
+                if (LUCENE_MATCH_VERSION.equals(key)) {
                   if (filterFactory.isExplicitLuceneMatchVersion()) {
                     props.add(key, factoryArgs.get(key));
                   }
@@ -1020,7 +1020,7 @@
     } else { // analyzer is not instanceof TokenizerChain
       analyzerProps.add(CLASS_NAME, analyzer.getClass().getName());
       if (analyzer.getVersion() != Version.LATEST) {
-        analyzerProps.add(LUCENE_MATCH_VERSION_PARAM, analyzer.getVersion().toString());
+        analyzerProps.add(LUCENE_MATCH_VERSION, analyzer.getVersion().toString());
       }
     }
     return analyzerProps;
Index: lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java	(revision )
@@ -20,9 +20,11 @@
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
+import static org.apache.lucene.analysis.phonetic.PhoneticFilterFactory.INJECT;
+import static org.apache.lucene.analysis.phonetic.PhoneticFilterFactory.MAX_CODE_LENGTH;
+
 /**
  * Factory for {@link DoubleMetaphoneFilter}.
  * <pre class="prettyprint">
@@ -35,10 +37,6 @@
  */
 public class DoubleMetaphoneFilterFactory extends TokenFilterFactory
 {
-  /** parameter name: true if encoded tokens should be added as synonyms */
-  public static final String INJECT = "inject"; 
-  /** parameter name: restricts the length of the phonetic code */
-  public static final String MAX_CODE_LENGTH = "maxCodeLength"; 
   /** default maxCodeLength if not specified */
   public static final int DEFAULT_MAX_CODE_LENGTH = 4;
 
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountFilterFactory.java	(revision )
@@ -34,8 +34,8 @@
       tokenizer.setEnableChecks(consumeAll);
       TokenStream stream = tokenizer;
       stream = tokenFilterFactory("LimitTokenCount",
-          LimitTokenCountFilterFactory.MAX_TOKEN_COUNT_KEY, "3",
-          LimitTokenCountFilterFactory.CONSUME_ALL_TOKENS_KEY, Boolean.toString(consumeAll)
+          "maxTokenCount", "3",
+          "consumeAllTokens", Boolean.toString(consumeAll)
       ).create(stream);
       assertTokenStreamContents(stream, new String[]{"A1", "B2", "C3"});
     }
@@ -47,7 +47,7 @@
       tokenFilterFactory("LimitTokenCount");
     });
     assertTrue("exception doesn't mention param: " + expected.getMessage(),
-        0 < expected.getMessage().indexOf(LimitTokenCountFilterFactory.MAX_TOKEN_COUNT_KEY));
+        0 < expected.getMessage().indexOf("maxTokenCount"));
   }
 
   /**
@@ -56,7 +56,7 @@
   public void testBogusArguments() throws Exception {
     IllegalArgumentException expected = expectThrows(IllegalArgumentException.class, () -> {
       tokenFilterFactory("LimitTokenCount",
-          LimitTokenCountFilterFactory.MAX_TOKEN_COUNT_KEY, "3",
+          "maxTokenCount", "3",
           "bogusArg", "bogusValue");
     });
     assertTrue(expected.getMessage().contains("Unknown parameters"));
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java	(revision )
@@ -35,14 +35,12 @@
 public class LengthFilterFactory extends TokenFilterFactory {
   final int min;
   final int max;
-  public static final String MIN_KEY = "min";
-  public static final String MAX_KEY = "max";
 
   /** Creates a new LengthFilterFactory */
   public LengthFilterFactory(Map<String, String> args) {
     super(args);
-    min = requireInt(args, MIN_KEY);
-    max = requireInt(args, MAX_KEY);
+    min = requireInt(args, MIN);
+    max = requireInt(args, MAX);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikFilterFactory.java	(revision )
@@ -64,7 +64,7 @@
 
     StringReader reader = new StringReader("inflected1 inflected2");
     Map<String,String> params = new HashMap<>();
-    params.put(MorfologikFilterFactory.DICTIONARY_ATTRIBUTE, "custom-dictionary.dict");
+    params.put("dictionary", "custom-dictionary.dict");
     MorfologikFilterFactory factory = new MorfologikFilterFactory(params);
     factory.inform(loader);
     TokenStream stream = whitespaceMockTokenizer(reader);
@@ -77,7 +77,7 @@
 
     IOException expected = expectThrows(IOException.class, () -> {
       Map<String,String> params = new HashMap<>();
-      params.put(MorfologikFilterFactory.DICTIONARY_ATTRIBUTE, "missing-dictionary-resource.dict");
+      params.put("dictionary", "missing-dictionary-resource.dict");
       MorfologikFilterFactory factory = new MorfologikFilterFactory(params);
       factory.inform(loader);
     });
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternCaptureGroupFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternCaptureGroupFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternCaptureGroupFilterFactory.java	(revision )
@@ -36,13 +36,13 @@
  * @see PatternCaptureGroupTokenFilter
  */
 public class PatternCaptureGroupFilterFactory extends TokenFilterFactory {
-  private Pattern pattern;
-  private boolean preserveOriginal = true;
+  private final Pattern pattern;
+  private final boolean preserveOriginal;
   
   public  PatternCaptureGroupFilterFactory(Map<String,String> args) {
     super(args);
-    pattern = getPattern(args, "pattern");
-    preserveOriginal = args.containsKey("preserve_original") ? Boolean.parseBoolean(args.get("preserve_original")) : true;
+    pattern = getPattern(args, PATTERN);
+    preserveOriginal = getBoolean(args, "preserve_original", true);
   }
   @Override
   public PatternCaptureGroupTokenFilter create(TokenStream input) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java	(revision )
@@ -46,9 +46,9 @@
   /** Creates a new CommonGramsFilterFactory */
   public CommonGramsFilterFactory(Map<String,String> args) {
     super(args);
-    commonWordFiles = get(args, "words");
-    format = get(args, "format");
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    commonWordFiles = get(args, WORDS);
+    format = get(args, FORMAT);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java	(revision )
@@ -46,7 +46,7 @@
   /** Creates a new PatternReplaceCharFilterFactory */
   public PatternReplaceCharFilterFactory(Map<String, String> args) {
     super(args);
-    pattern = getPattern(args, "pattern");
+    pattern = getPattern(args, PATTERN);
     replacement = get(args, "replacement", "");
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
Index: solr/core/src/java/org/apache/solr/util/PayloadUtils.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/util/PayloadUtils.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/util/PayloadUtils.java	(revision )
@@ -51,7 +51,7 @@
       TokenFilterFactory[] factories = tc.getTokenFilterFactories();
       for (TokenFilterFactory factory : factories) {
         if (factory instanceof DelimitedPayloadTokenFilterFactory) {
-          encoder = factory.getOriginalArgs().get(DelimitedPayloadTokenFilterFactory.ENCODER_ATTR);
+          encoder = factory.getOriginalArgs().get(DelimitedPayloadTokenFilterFactory.ENCODER);
           break;
         }
 
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/custom/CustomAnalyzer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/custom/CustomAnalyzer.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/custom/CustomAnalyzer.java	(revision )
@@ -394,8 +394,8 @@
     }
     
     private Map<String,String> applyDefaultParams(Map<String,String> map) {
-      if (defaultMatchVersion.get() != null && !map.containsKey(AbstractAnalysisFactory.LUCENE_MATCH_VERSION_PARAM)) {
-        map.put(AbstractAnalysisFactory.LUCENE_MATCH_VERSION_PARAM, defaultMatchVersion.get().toString());
+      if (defaultMatchVersion.get() != null && !map.containsKey(AbstractAnalysisFactory.LUCENE_MATCH_VERSION)) {
+        map.put(AbstractAnalysisFactory.LUCENE_MATCH_VERSION, defaultMatchVersion.get().toString());
       }
       return map;
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java	(revision )
@@ -45,8 +45,8 @@
   /** Creates a new StemmerOverrideFilterFactory */
   public StemmerOverrideFilterFactory(Map<String,String> args) {
     super(args);
-    dictionaryFiles = get(args, "dictionary");
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    dictionaryFiles = get(args, DICTIONARY);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java	(revision )
@@ -37,7 +37,6 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class ASCIIFoldingFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  private static final String PRESERVE_ORIGINAL = "preserveOriginal";
 
   private final boolean preserveOriginal;
   
Index: solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ solr/core/src/java/org/apache/solr/rest/schema/analysis/ManagedSynonymFilterFactory.java	(revision )
@@ -61,7 +61,6 @@
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
   
   public static final String SYNONYM_MAPPINGS = "synonymMappings";
-  public static final String IGNORE_CASE_INIT_ARG = "ignoreCase";
 
   /**
    * Used internally to preserve the case of synonym mappings regardless
@@ -121,7 +120,7 @@
     {
       NamedList<Object> initArgs = (NamedList<Object>)managedInitArgs;
       
-      String format = (String)initArgs.get("format");
+      String format = (String)initArgs.get(FORMAT);
       if (format != null && !"solr".equals(format)) {
         throw new SolrException(ErrorCode.BAD_REQUEST, "Invalid format "+
            format+"! Only 'solr' is supported.");
@@ -129,8 +128,8 @@
       
       // the default behavior is to not ignore case, 
       // so if not supplied, then install the default
-      if (initArgs.get(IGNORE_CASE_INIT_ARG) == null) {
-        initArgs.add(IGNORE_CASE_INIT_ARG, Boolean.FALSE);
+      if (initArgs.get(IGNORE_CASE) == null) {
+        initArgs.add(IGNORE_CASE, Boolean.FALSE);
       }
 
       boolean ignoreCase = getIgnoreCase(managedInitArgs);
@@ -280,7 +279,7 @@
     }
 
     public boolean getIgnoreCase(NamedList<?> initArgs) {
-      Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE_INIT_ARG);
+      Boolean ignoreCase = initArgs.getBooleanArg(IGNORE_CASE);
       // ignoreCase = false by default
       return null == ignoreCase ? false : ignoreCase;
     }
@@ -403,7 +402,7 @@
     NamedList<Object> args = (NamedList<Object>)initArgs;    
     args.add("synonyms", getResourceId());
     args.add("expand", "false");
-    args.add("format", "solr");
+    args.add(FORMAT, "solr");
     
     Map<String,String> filtArgs = new HashMap<>();
     for (Map.Entry<String,?> entry : args) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java	(revision )
@@ -47,7 +47,7 @@
   /** Creates a new TypeTokenFilterFactory */
   public TypeTokenFilterFactory(Map<String,String> args) {
     super(args);
-    stopTypesFiles = require(args, "types");
+    stopTypesFiles = require(args, TYPES);
     useWhitelist = getBoolean(args, "useWhitelist", false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java	(revision )
@@ -37,7 +37,7 @@
   /** Creates a new UAX29URLEmailTokenizerFactory */
   public UAX29URLEmailTokenizerFactory(Map<String,String> args) {
     super(args);
-    maxTokenLength = getInt(args, "maxTokenLength", StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+    maxTokenLength = getInt(args, MAX_TOKEN_LENGTH, StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java	(revision )
@@ -17,6 +17,7 @@
 package org.apache.lucene.analysis.no;
 
 
+import java.util.Arrays;
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
@@ -44,7 +45,7 @@
   /** Creates a new NorwegianMinimalStemFilterFactory */
   public NorwegianMinimalStemFilterFactory(Map<String,String> args) {
     super(args);
-    String variant = get(args, "variant");
+    String variant = get(args, "variant", Arrays.asList("nb", "nn", "no"));
     if (variant == null || "nb".equals(variant)) {
       flags = BOKMAAL;
     } else if ("nn".equals(variant)) {
Index: lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DaitchMokotoffSoundexFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DaitchMokotoffSoundexFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DaitchMokotoffSoundexFilterFactory.java	(revision )
@@ -21,6 +21,8 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
+import static org.apache.lucene.analysis.phonetic.PhoneticFilterFactory.INJECT;
+
 /**
  * Factory for {@link DaitchMokotoffSoundexFilter}.
  *
@@ -44,12 +46,10 @@
  * @lucene.experimental
  */
 public class DaitchMokotoffSoundexFilterFactory extends TokenFilterFactory {
-  /** parameter name: true if encoded tokens should be added as synonyms */
-  public static final String INJECT = "inject"; // boolean
 
   final boolean inject; //accessed by the test
 
-  /** Creates a new PhoneticFilterFactory */
+  /** Creates a new DaitchMokotoffSoundexFilterFactory */
   public DaitchMokotoffSoundexFilterFactory(Map<String,String> args) {
     super(args);
     inject = getBoolean(args, INJECT, true);
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCodepointCountFilterFactory.java	(revision )
@@ -55,9 +55,9 @@
       TokenStream stream = new MockTokenizer(MockTokenizer.WHITESPACE, false);
       ((Tokenizer)stream).setReader(reader);
       tokenFilterFactory("CodepointCount",
-          CodepointCountFilterFactory.MIN_KEY, "5",
-          CodepointCountFilterFactory.MAX_KEY, "4").create(stream);
+          "min", "5",
+          "max", "4").create(stream);
     });
     assertTrue(expected.getMessage().contains("maximum length must not be greater than minimum length"));
   }
-}
\ No newline at end of file
+}
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java	(revision )
@@ -50,11 +50,8 @@
  * @lucene.experimental
  */
 public class HunspellStemFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  private static final String PARAM_DICTIONARY    = "dictionary";
   private static final String PARAM_AFFIX         = "affix";
-  // NOTE: this one is currently unused?:
   private static final String PARAM_RECURSION_CAP = "recursionCap";
-  private static final String PARAM_IGNORE_CASE   = "ignoreCase";
   private static final String PARAM_LONGEST_ONLY  = "longestOnly";
 
   private final String dictionaryFiles;
@@ -66,9 +63,9 @@
   /** Creates a new HunspellStemFilterFactory */
   public HunspellStemFilterFactory(Map<String,String> args) {
     super(args);
-    dictionaryFiles = require(args, PARAM_DICTIONARY);
+    dictionaryFiles = require(args, DICTIONARY);
     affixFile = get(args, PARAM_AFFIX);
-    ignoreCase = getBoolean(args, PARAM_IGNORE_CASE, false);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     longestOnly = getBoolean(args, PARAM_LONGEST_ONLY, false);
     // this isnt necessary: we properly load all dictionaries.
     // but recognize and ignore for back compat
@@ -76,7 +73,7 @@
     // this isn't necessary: multi-stage stripping is fixed and 
     // flags like COMPLEXPREFIXES in the data itself control this.
     // but recognize and ignore for back compat
-    getInt(args, "recursionCap", 0);
+    getInt(args, PARAM_RECURSION_CAP, 0);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java	(revision )
@@ -44,8 +44,8 @@
   /** Creates a new KeepWordFilterFactory */
   public KeepWordFilterFactory(Map<String,String> args) {
     super(args);
-    wordFiles = get(args, "words");
-    ignoreCase = getBoolean(args, "ignoreCase", false);
+    wordFiles = get(args, WORDS);
+    ignoreCase = getBoolean(args, IGNORE_CASE, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java	(revision )
@@ -51,7 +51,7 @@
   /** Creates a new ICUNormalizer2FilterFactory */
   public ICUNormalizer2FilterFactory(Map<String,String> args) {
     super(args);
-    String name = get(args, "name", "nfkc_cf");
+    String name = get(args, "name", Arrays.asList("nfc", "nfkc", "nfkc_cf"), "nfkc_cf");
     String mode = get(args, "mode", Arrays.asList("compose", "decompose"), "compose");
     Normalizer2 normalizer = Normalizer2.getInstance
         (null, name, "compose".equals(mode) ? Normalizer2.Mode.COMPOSE : Normalizer2.Mode.DECOMPOSE);
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/SimplePatternTokenizerFactory.java	(revision )
@@ -55,7 +55,7 @@
  * @see SimplePatternTokenizer
  */
 public class SimplePatternTokenizerFactory extends TokenizerFactory {
-  public static final String PATTERN = "pattern";
+
   private final Automaton dfa;
   private final int maxDeterminizedStates;
  
@@ -64,7 +64,7 @@
     super(args);
     maxDeterminizedStates = getInt(args, "maxDeterminizedStates", Operations.DEFAULT_MAX_DETERMINIZED_STATES);
     dfa = Operations.determinize(new RegExp(require(args, PATTERN)).toAutomaton(), maxDeterminizedStates);
-    if (args.isEmpty() == false) {
+    if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
   }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java	(revision )
@@ -54,8 +54,7 @@
  *   <li>Consumer calls create() to obtain instances.
  * </ol>
  */
-public abstract class AbstractAnalysisFactory {
-  public static final String LUCENE_MATCH_VERSION_PARAM = "luceneMatchVersion";
+public abstract class AbstractAnalysisFactory implements CommonAnalysisFactoryParams {
 
   /** The original args, before any processing */
   private final Map<String,String> originalArgs;
@@ -70,7 +69,7 @@
    */
   protected AbstractAnalysisFactory(Map<String,String> args) {
     originalArgs = Collections.unmodifiableMap(new HashMap<>(args));
-    String version = get(args, LUCENE_MATCH_VERSION_PARAM);
+    String version = get(args, LUCENE_MATCH_VERSION);
     if (version == null) {
       luceneMatchVersion = Version.LATEST;
     } else {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java	(revision )
@@ -17,6 +17,7 @@
 package org.apache.lucene.analysis.no;
 
 
+import java.util.Arrays;
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
@@ -44,7 +45,7 @@
   /** Creates a new NorwegianLightStemFilterFactory */
   public NorwegianLightStemFilterFactory(Map<String,String> args) {
     super(args);
-    String variant = get(args, "variant");
+    String variant = get(args, "variant", Arrays.asList("nb", "nn", "no"));
     if (variant == null || "nb".equals(variant)) {
       flags = BOKMAAL;
     } else if ("nn".equals(variant)) {
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java	(revision )
@@ -63,7 +63,6 @@
   public static final String OK_PREFIX = "okPrefix";
   public static final String MIN_WORD_LENGTH = "minWordLength";
   public static final String MAX_WORD_COUNT = "maxWordCount";
-  public static final String MAX_TOKEN_LENGTH = "maxTokenLength";
   public static final String ONLY_FIRST_WORD = "onlyFirstWord";
   public static final String FORCE_FIRST_LETTER = "forceFirstLetter";
 
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java	(revision )
@@ -38,15 +38,14 @@
 public class LimitTokenCountFilterFactory extends TokenFilterFactory {
 
   public static final String MAX_TOKEN_COUNT_KEY = "maxTokenCount";
-  public static final String CONSUME_ALL_TOKENS_KEY = "consumeAllTokens";
-  final int maxTokenCount;
-  final boolean consumeAllTokens;
+  private final int maxTokenCount;
+  private final boolean consumeAllTokens;
 
   /** Creates a new LimitTokenCountFilterFactory */
   public LimitTokenCountFilterFactory(Map<String, String> args) {
     super(args);
     maxTokenCount = requireInt(args, MAX_TOKEN_COUNT_KEY);
-    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS_KEY, false);
+    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenOffsetFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenOffsetFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenOffsetFilterFactory.java	(revision )
@@ -37,7 +37,6 @@
 public class LimitTokenOffsetFilterFactory extends TokenFilterFactory {
 
   public static final String MAX_START_OFFSET = "maxStartOffset";
-  public static final String CONSUME_ALL_TOKENS_KEY = "consumeAllTokens";
 
   private int maxStartOffset;
   private boolean consumeAllTokens;
@@ -45,7 +44,7 @@
   public LimitTokenOffsetFilterFactory(Map<String, String> args) {
     super(args);
     maxStartOffset = requireInt(args, MAX_START_OFFSET);
-    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS_KEY, false);
+    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java	(revision )
@@ -76,7 +76,7 @@
   /** Creates a new PathHierarchyTokenizerFactory */
   public PathHierarchyTokenizerFactory(Map<String,String> args) {
     super(args);
-    delimiter = getChar(args, "delimiter", PathHierarchyTokenizer.DEFAULT_DELIMITER);
+    delimiter = getChar(args, DELIMITER, PathHierarchyTokenizer.DEFAULT_DELIMITER);
     replacement = getChar(args, "replace", delimiter);
     reverse = getBoolean(args, "reverse", false);
     skip = getInt(args, "skip", PathHierarchyTokenizer.DEFAULT_SKIP);
Index: lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java	(revision )
@@ -64,8 +64,7 @@
  * @see PhoneticFilter
  */
 public class PhoneticFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  /** parameter name: either a short name or a full class name */
-  public static final String ENCODER = "encoder";
+
   /** parameter name: true if encoded tokens should be added as synonyms */
   public static final String INJECT = "inject"; // boolean
   /** parameter name: restricts the length of the phonetic code */
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CodepointCountFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CodepointCountFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CodepointCountFilterFactory.java	(revision )
@@ -33,16 +33,14 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class CodepointCountFilterFactory extends TokenFilterFactory {
-  final int min;
-  final int max;
-  public static final String MIN_KEY = "min";
-  public static final String MAX_KEY = "max";
+  private final int min;
+  private final int max;
 
   /** Creates a new CodepointCountFilterFactory */
   public CodepointCountFilterFactory(Map<String, String> args) {
     super(args);
-    min = requireInt(args, MIN_KEY);
-    max = requireInt(args, MAX_KEY);
+    min = requireInt(args, MIN);
+    max = requireInt(args, MAX);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenPositionFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenPositionFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenPositionFilterFactory.java	(revision )
@@ -37,15 +37,14 @@
 public class LimitTokenPositionFilterFactory extends TokenFilterFactory {
 
   public static final String MAX_TOKEN_POSITION_KEY = "maxTokenPosition";
-  public static final String CONSUME_ALL_TOKENS_KEY = "consumeAllTokens";
-  final int maxTokenPosition;
-  final boolean consumeAllTokens;
+  private final int maxTokenPosition;
+  private final boolean consumeAllTokens;
 
   /** Creates a new LimitTokenPositionFilterFactory */
   public LimitTokenPositionFilterFactory(Map<String,String> args) {
     super(args);
     maxTokenPosition = requireInt(args, MAX_TOKEN_POSITION_KEY);
-    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS_KEY, false);
+    consumeAllTokens = getBoolean(args, CONSUME_ALL_TOKENS, false);
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java	(revision )
@@ -35,8 +35,6 @@
  * &lt;/fieldType&gt;</pre>
  */
 public class DelimitedPayloadTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String ENCODER_ATTR = "encoder";
-  public static final String DELIMITER_ATTR = "delimiter";
 
   private final String encoderClass;
   private final char delimiter;
@@ -46,8 +44,8 @@
   /** Creates a new DelimitedPayloadTokenFilterFactory */
   public DelimitedPayloadTokenFilterFactory(Map<String, String> args) {
     super(args);
-    encoderClass = require(args, ENCODER_ATTR);
-    delimiter = getChar(args, DELIMITER_ATTR, '|');
+    encoderClass = require(args, ENCODER);
+    delimiter = getChar(args, DELIMITER, '|');
     if (!args.isEmpty()) {
       throw new IllegalArgumentException("Unknown parameters: " + args);
     }
@@ -70,4 +68,4 @@
       encoder = loader.newInstance(encoderClass, PayloadEncoder.class);
     }
   }
-}
\ No newline at end of file
+}
Index: lucene/build.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/build.xml	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/build.xml	(revision )
@@ -161,12 +161,12 @@
          can prevent the modules that don't have problems
          from getting any worse -->
     <!-- analyzers-common: problems -->
-    <check-missing-javadocs dir="build/docs/analyzers-icu" level="method"/>
+    <check-missing-javadocs dir="build/docs/analyzers-icu" level="package"/>
     <!-- analyzers-kuromoji: problems -->
-    <check-missing-javadocs dir="build/docs/analyzers-morfologik" level="method"/>
-    <check-missing-javadocs dir="build/docs/analyzers-phonetic" level="method"/>
+    <check-missing-javadocs dir="build/docs/analyzers-morfologik" level="package"/>
+    <check-missing-javadocs dir="build/docs/analyzers-phonetic" level="package"/>
     <!-- analyzers-smartcn: problems -->
-    <check-missing-javadocs dir="build/docs/analyzers-stempel" level="method"/>
+    <check-missing-javadocs dir="build/docs/analyzers-stempel" level="package"/>
     <!-- analyzers-uima: problems -->
     <!-- benchmark: problems -->
     <check-missing-javadocs dir="build/docs/classification" level="method"/>
@@ -185,7 +185,7 @@
     <!-- sandbox: problems -->
     <check-missing-javadocs dir="build/docs/spatial" level="method"/>
     <!-- spatial-extras: problems -->
-    <check-missing-javadocs dir="build/docs/suggest" level="method"/>
+    <check-missing-javadocs dir="build/docs/suggest" level="package"/>
     <!-- test-framework: problems -->
 
     <!-- too much to fix core/ for now, but enforce full javadocs for key packages -->
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java	(revision )
@@ -80,19 +80,18 @@
                          "format", "bogus");
     });
     String msg = expected.getMessage();
-    assertTrue(msg, msg.contains("Unknown"));
+    assertTrue(msg, msg.contains("Configuration Error:"));
     assertTrue(msg, msg.contains("format"));
-    assertTrue(msg, msg.contains("bogus"));
 
     expected = expectThrows(IllegalArgumentException.class, () -> {
       tokenFilterFactory("Stop", 
                          // implicit default words file
-                         "format", "bogus");
+                         "format", "snowball");
       fail();
     });
     msg = expected.getMessage();
     assertTrue(msg, msg.contains("can not be specified"));
     assertTrue(msg, msg.contains("format"));
-    assertTrue(msg, msg.contains("bogus"));
+    assertTrue(msg, msg.contains("snowball"));
   }
 }
Index: lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2CharFilterFactory.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2CharFilterFactory.java	(revision 8218a5b2c6ca78c05a6060af4770c504e28a6f99)
+++ lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2CharFilterFactory.java	(revision )
@@ -51,7 +51,7 @@
   /** Creates a new ICUNormalizer2CharFilterFactory */
   public ICUNormalizer2CharFilterFactory(Map<String,String> args) {
     super(args);
-    String name = get(args, "name", "nfkc_cf");
+    String name = get(args, "name", Arrays.asList("nfc", "nfkc", "nfkc_cf"), "nfkc_cf");
     String mode = get(args, "mode", Arrays.asList("compose", "decompose"), "compose");
     Normalizer2 normalizer = Normalizer2.getInstance
         (null, name, "compose".equals(mode) ? Normalizer2.Mode.COMPOSE : Normalizer2.Mode.DECOMPOSE);
