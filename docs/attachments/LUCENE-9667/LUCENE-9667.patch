Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java	(revision 9466af576a4a9d3cd750438123063928329fbb46)
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java	(date 1610558313285)
@@ -32,16 +32,7 @@
 import java.nio.file.Path;
 import java.nio.file.Paths;
 import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.TreeMap;
+import java.util.*;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import org.apache.lucene.codecs.CodecUtil;
@@ -86,6 +77,8 @@
   private static final String OCONV_KEY = "OCONV";
   private static final String FULLSTRIP_KEY = "FULLSTRIP";
   private static final String LANG_KEY = "LANG";
+  private static final String BREAK_KEY = "BREAK";
+  private static final String FORBIDDENWORD_KEY = "FORBIDDENWORD";
   private static final String KEEPCASE_KEY = "KEEPCASE";
   private static final String NEEDAFFIX_KEY = "NEEDAFFIX";
   private static final String PSEUDOROOT_KEY = "PSEUDOROOT";
@@ -101,6 +94,7 @@
 
   FST<IntsRef> prefixes;
   FST<IntsRef> suffixes;
+  Breaks breaks = Breaks.DEFAULT;
 
   // all condition checks used by prefixes and suffixes. these are typically re-used across
   // many affix stripping rules. so these are deduplicated, to save RAM.
@@ -149,6 +143,7 @@
   int circumfix = -1; // circumfix flag, or -1 if one is not defined
   int keepcase = -1; // keepcase flag, or -1 if one is not defined
   int needaffix = -1; // needaffix flag, or -1 if one is not defined
+  int forbiddenword = -1; // forbiddenword flag, or -1 if one is not defined
   int onlyincompound = -1; // onlyincompound flag, or -1 if one is not defined
 
   // ignored characters (dictionary, affix, inputs)
@@ -250,6 +245,10 @@
     }
   }
 
+  int formStep() {
+    return hasStemExceptions ? 2 : 1;
+  }
+
   /** Looks up Hunspell word forms from the dictionary */
   IntsRef lookupWord(char word[], int offset, int length) {
     return lookup(words, word, offset, length);
@@ -394,6 +393,14 @@
       } else if (line.startsWith(LANG_KEY)) {
         language = line.substring(LANG_KEY.length()).trim();
         alternateCasing = "tr_TR".equals(language) || "az_AZ".equals(language);
+      } else if (line.startsWith(BREAK_KEY)) {
+        breaks = parseBreaks(reader, line);
+      } else if (line.startsWith(FORBIDDENWORD_KEY)) {
+        String[] parts = line.split("\\s+");
+        if (parts.length != 2) {
+          throw new ParseException("Illegal FORBIDDENWORD declaration", reader.getLineNumber());
+        }
+        forbiddenword = flagParsingStrategy.parseFlag(parts[1]);
       }
     }
 
@@ -417,6 +424,30 @@
     stripOffsets[currentIndex] = currentOffset;
   }
 
+  private Breaks parseBreaks(LineNumberReader reader, String line)
+      throws IOException, ParseException {
+    Set<String> starting = new LinkedHashSet<>();
+    Set<String> ending = new LinkedHashSet<>();
+    Set<String> middle = new LinkedHashSet<>();
+    int num = Integer.parseInt(line.substring(BREAK_KEY.length()).trim());
+    for (int i = 0; i < num; i++) {
+      line = reader.readLine();
+      String[] parts = line.split("\\s+");
+      if (!line.startsWith(BREAK_KEY) || parts.length != 2) {
+        throw new ParseException("BREAK chars expected", reader.getLineNumber());
+      }
+      String breakStr = parts[1];
+      if (breakStr.startsWith("^")) {
+        starting.add(breakStr.substring(1));
+      } else if (breakStr.endsWith("$")) {
+        ending.add(breakStr.substring(0, breakStr.length() - 1));
+      } else {
+        middle.add(breakStr);
+      }
+    }
+    return new Breaks(starting, ending, middle);
+  }
+
   private FST<IntsRef> affixFST(TreeMap<String, List<Integer>> affixes) throws IOException {
     IntSequenceOutputs outputs = IntSequenceOutputs.getSingleton();
     FSTCompiler<IntsRef> fstCompiler = new FSTCompiler<>(FST.INPUT_TYPE.BYTE4, outputs);
@@ -1092,6 +1123,22 @@
     return null;
   }
 
+  boolean isForbiddenWord(char[] word, BytesRef scratch) {
+    if (forbiddenword != -1) {
+      IntsRef forms = lookupWord(word, 0, word.length);
+      if (forms != null) {
+        int formStep = formStep();
+        for (int i = 0; i < forms.length; i += formStep) {
+          flagLookup.get(forms.ints[forms.offset + i], scratch);
+          if (hasFlag(Dictionary.decodeFlags(scratch), (char) forbiddenword)) {
+            return true;
+          }
+        }
+      }
+    }
+    return false;
+  }
+
   /** Abstraction of the process of parsing flags taken from the affix and dic files */
   abstract static class FlagParsingStrategy {
 
@@ -1315,4 +1362,21 @@
 
     return DEFAULT_TEMP_DIR;
   }
+
+  /** Possible word breaks according to BREAK directives */
+  static class Breaks {
+    private static final Set<String> MINUS = Collections.singleton("-");
+    static final Breaks DEFAULT = new Breaks(MINUS, MINUS, MINUS);
+    final String[] starting, ending, middle;
+
+    Breaks(Collection<String> starting, Collection<String> ending, Collection<String> middle) {
+      this.starting = starting.toArray(new String[0]);
+      this.ending = ending.toArray(new String[0]);
+      this.middle = middle.toArray(new String[0]);
+    }
+
+    boolean isNotEmpty() {
+      return middle.length > 0 || starting.length > 0 || ending.length > 0;
+    }
+  }
 }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/SpellChecker.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/SpellChecker.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/SpellChecker.java
new file mode 100644
--- /dev/null	(date 1610559125217)
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/SpellChecker.java	(date 1610559125217)
@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.hunspell;
+
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * A spell checker based on Hunspell dictionaries. Thread-safe. Not all Hunspell features are
+ * supported yet.
+ */
+public class SpellChecker {
+  private final Dictionary dictionary;
+  private final ThreadLocal<Stemmer> stemmer;
+  private final ThreadLocal<BytesRef> scratch = ThreadLocal.withInitial(BytesRef::new);
+
+  public SpellChecker(Dictionary dictionary) {
+    this.dictionary = dictionary;
+    stemmer = ThreadLocal.withInitial(() -> new Stemmer(this.dictionary));
+  }
+
+  /** @return whether the given word's spelling is considered correct according to Hunspell rules */
+  public boolean spell(String word) {
+    char[] wordChars = word.toCharArray();
+    if (dictionary.isForbiddenWord(wordChars, scratch.get())) {
+      return false;
+    }
+
+    if (!stemmer.get().stem(wordChars, word.length()).isEmpty()) {
+      return true;
+    }
+
+    if (dictionary.breaks.isNotEmpty() && !hasTooManyBreakOccurrences(word)) {
+      return tryBreaks(word);
+    }
+
+    return false;
+  }
+
+  private boolean tryBreaks(String word) {
+    for (String br : dictionary.breaks.starting) {
+      if (word.startsWith(br) && spell(word.substring(br.length()))) {
+        return true;
+      }
+    }
+
+    for (String br : dictionary.breaks.ending) {
+      if (word.endsWith(br) && spell(word.substring(0, word.length() - br.length()))) {
+        return true;
+      }
+    }
+
+    for (String br : dictionary.breaks.middle) {
+      int pos = word.indexOf(br);
+      if (canBeBrokenAt(word, br, pos)) {
+        return true;
+      }
+
+      // try to break at the second occurrence
+      // to recognize dictionary words with a word break
+      if (pos > 0 && canBeBrokenAt(word, br, word.indexOf(br, pos + 1))) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  private boolean hasTooManyBreakOccurrences(String word) {
+    int occurrences = 0;
+    for (String br : dictionary.breaks.middle) {
+      int pos = 0;
+      while ((pos = word.indexOf(br, pos)) >= 0) {
+        if (++occurrences >= 10) return true;
+        pos += br.length();
+      }
+    }
+    return false;
+  }
+
+  private boolean canBeBrokenAt(String word, String breakStr, int breakPos) {
+    return breakPos > 0
+        && breakPos < word.length() - breakStr.length()
+        && spell(word.substring(0, breakPos))
+        && spell(word.substring(breakPos + breakStr.length()));
+  }
+}
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer.java
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer.java	(revision 9466af576a4a9d3cd750438123063928329fbb46)
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer.java	(date 1610555693096)
@@ -67,7 +67,7 @@
         suffixReaders[level] = dictionary.suffixes.getBytesReader();
       }
     }
-    formStep = dictionary.hasStemExceptions ? 2 : 1;
+    formStep = dictionary.formStep();
   }
 
   /**
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.aff
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.aff b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.aff
new file mode 100644
--- /dev/null	(date 1610553529787)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.aff	(date 1610553529787)
@@ -0,0 +1,10 @@
+# word break points test, recursive break at dash and n-dash
+SET UTF-8
+
+BREAK 2
+BREAK -
+BREAK –
+
+WORDCHARS -–
+
+FORBIDDENWORD !
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.dic
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.dic b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.dic
new file mode 100644
--- /dev/null	(date 1610553529791)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.dic	(date 1610553529791)
@@ -0,0 +1,7 @@
+6
+foo
+bar
+baz
+fox-bax
+foo-baz/!
+e-mail
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.good
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.good b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.good
new file mode 100644
--- /dev/null	(date 1610553529795)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.good	(date 1610553529795)
@@ -0,0 +1,12 @@
+foo
+bar
+fox-bax
+foo-bar
+foo–bar
+foo-bar-foo-bar
+foo-bar–foo-bar
+bar-baz
+baz-foo
+foo-bar-foo-bar-foo-bar-foo-bar-foo-bar
+e-mail
+e-mail-foo
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.wrong
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.wrong b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.wrong
new file mode 100644
--- /dev/null	(date 1610553529795)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/break.wrong	(date 1610553529795)
@@ -0,0 +1,13 @@
+fox
+bax
+-foo
+bar-
+fox-bar
+foo-bax
+foo–bax
+fox–bar
+foo-bar-fox-bar
+foo-bax-foo-bar
+foo-bar–fox-bar
+foo-bax–foo-bar
+foo-baz
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.aff
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.aff b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.aff
new file mode 100644
--- /dev/null	(date 1610553529803)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.aff	(date 1610553529803)
@@ -0,0 +1,6 @@
+# default word break at hyphens and n-dashes
+
+SET UTF-8
+MAXNGRAMSUGS 0
+WORDCHARS -
+TRY ot
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.dic
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.dic b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.dic
new file mode 100644
--- /dev/null	(date 1610553529803)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.dic	(date 1610553529803)
@@ -0,0 +1,6 @@
+3
+foo
+bar
+free
+scott
+scot-free
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.good
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.good b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.good
new file mode 100644
--- /dev/null	(date 1610553529807)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.good	(date 1610553529807)
@@ -0,0 +1,7 @@
+foo
+bar
+foo-
+-foo
+scot-free
+foo-bar
+foo-bar-foo-bar
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.wrong
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.wrong b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.wrong
new file mode 100644
--- /dev/null	(date 1610553529807)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakdefault.wrong	(date 1610553529807)
@@ -0,0 +1,5 @@
+scot
+sco-free
+fo-bar
+foo-fo-bar
+foo-foo-fo
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.aff
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.aff b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.aff
new file mode 100644
--- /dev/null	(date 1610553529811)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.aff	(date 1610553529811)
@@ -0,0 +1,7 @@
+# switch off default word break at hyphens and n-dashes by BREAK 0
+SET UTF-8
+MAXNGRAMSUGS 0
+WORDCHARS -
+TRY ot
+
+BREAK 0
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.dic
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.dic b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.dic
new file mode 100644
--- /dev/null	(date 1610553529815)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.dic	(date 1610553529815)
@@ -0,0 +1,6 @@
+3
+foo
+bar
+free
+scott
+scot-free
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.good
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.good b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.good
new file mode 100644
--- /dev/null	(date 1610553529819)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.good	(date 1610553529819)
@@ -0,0 +1,3 @@
+foo
+bar
+scot-free
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.wrong
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.wrong b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.wrong
new file mode 100644
--- /dev/null	(date 1610553529819)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/breakoff.wrong	(date 1610553529819)
@@ -0,0 +1,5 @@
+foo-
+-foo
+foo-bar
+foo-bar-foo-bar
+scot
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/SpellCheckerTest.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/SpellCheckerTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/SpellCheckerTest.java
new file mode 100644
--- /dev/null	(date 1610559188889)
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/SpellCheckerTest.java	(date 1610559188889)
@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.analysis.hunspell;
+
+import java.io.InputStream;
+import java.net.URL;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.util.Objects;
+import org.apache.lucene.store.ByteBuffersDirectory;
+import org.apache.lucene.util.IOUtils;
+
+public class SpellCheckerTest extends StemmerTestBase {
+
+  public void testBreak() throws Exception {
+    doTest("break");
+  }
+
+  public void testBreakDefault() throws Exception {
+    doTest("breakdefault");
+  }
+
+  public void testBreakOff() throws Exception {
+    doTest("breakoff");
+  }
+
+  protected void doTest(String name) throws Exception {
+    InputStream affixStream =
+        Objects.requireNonNull(getClass().getResourceAsStream(name + ".aff"), name);
+    InputStream dictStream =
+        Objects.requireNonNull(getClass().getResourceAsStream(name + ".dic"), name);
+
+    SpellChecker speller;
+    try {
+      Dictionary dictionary =
+          new Dictionary(new ByteBuffersDirectory(), "dictionary", affixStream, dictStream);
+      speller = new SpellChecker(dictionary);
+    } finally {
+      IOUtils.closeWhileHandlingException(affixStream);
+      IOUtils.closeWhileHandlingException(dictStream);
+    }
+
+    URL good = StemmerTestBase.class.getResource(name + ".good");
+    if (good != null) {
+      for (String word : Files.readAllLines(Path.of(good.toURI()))) {
+        assertTrue("Unexpectedly considered misspelled: " + word, speller.spell(word));
+      }
+    }
+
+    URL wrong = StemmerTestBase.class.getResource(name + ".wrong");
+    if (wrong != null) {
+      for (String word : Files.readAllLines(Path.of(wrong.toURI()))) {
+        assertFalse("Unexpectedly considered correct: " + word, speller.spell(word));
+      }
+    }
+  }
+}
