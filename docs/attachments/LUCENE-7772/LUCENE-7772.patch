diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilter.java
index 32423e9..1f4cbf1 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilter.java
@@ -47,8 +47,7 @@ public final class StemmerOverrideFilter extends TokenFilter {
   private final KeywordAttribute keywordAtt = addAttribute(KeywordAttribute.class);
   private final BytesReader fstReader;
   private final Arc<BytesRef> scratchArc = new FST.Arc<>();
-  private char[] spare = new char[0];
-  
+
   /**
    * Create a new StemmerOverrideFilter, performing dictionary-based stemming
    * with the provided <code>dictionary</code>.
@@ -73,7 +72,7 @@ public final class StemmerOverrideFilter extends TokenFilter {
       if (!keywordAtt.isKeyword()) { // don't muck with already-keyworded terms
         final BytesRef stem = stemmerOverrideMap.get(termAtt.buffer(), termAtt.length(), scratchArc, fstReader);
         if (stem != null) {
-          spare = ArrayUtil.grow(termAtt.buffer(), stem.length);
+          char[] spare = ArrayUtil.grow(termAtt.buffer(), stem.length);
           final int length = UnicodeUtil.UTF8toUTF16(stem, spare);
           if (spare != termAtt.buffer()) {
             termAtt.copyBuffer(spare, 0, length);
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecContentSource.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecContentSource.java
index 6ceb922..4607bc0 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecContentSource.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/TrecContentSource.java
@@ -84,7 +84,6 @@ public class TrecContentSource extends ContentSource {
 
   private ThreadLocal<DateFormatInfo> dateFormats = new ThreadLocal<>();
   private ThreadLocal<StringBuilder> trecDocBuffer = new ThreadLocal<>();
-  private Path dataDir = null;
   private ArrayList<Path> inputFiles = new ArrayList<>();
   private int nextFile = 0;
   // Use to synchronize threads on reading from the TREC documents.
@@ -293,7 +292,7 @@ public class TrecContentSource extends ContentSource {
     // dirs
     Path workDir = Paths.get(config.get("work.dir", "work"));
     String d = config.get("docs.dir", "trec");
-    dataDir = Paths.get(d);
+    Path dataDir = Paths.get(d);
     if (!dataDir.isAbsolute()) {
       dataDir = workDir.resolve(d);
     }
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SubmissionReport.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SubmissionReport.java
index b64f600..cc9176f 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SubmissionReport.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/SubmissionReport.java
@@ -85,10 +85,10 @@ public class SubmissionReport {
     }
   }
   
-  private static String padd = "                                    ";
+  private static final String PADD = "                                    ";
   private String format(String s, int minLen) {
     s = (s==null ? "" : s);
     int n = Math.max(minLen,s.length());
-    return (s+padd).substring(0,n);
+    return (s+ PADD).substring(0,n);
   }
 }
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java
index b59114a..701951d 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsWriter.java
@@ -39,8 +39,6 @@ import org.apache.lucene.util.IOUtils;
  */
 public class SimpleTextStoredFieldsWriter extends StoredFieldsWriter {
   private int numDocsWritten = 0;
-  private final Directory directory;
-  private final String segment;
   private IndexOutput out;
   
   final static String FIELDS_EXTENSION = "fld";
@@ -62,8 +60,6 @@ public class SimpleTextStoredFieldsWriter extends StoredFieldsWriter {
   private final BytesRefBuilder scratch = new BytesRefBuilder();
   
   public SimpleTextStoredFieldsWriter(Directory directory, String segment, IOContext context) throws IOException {
-    this.directory = directory;
-    this.segment = segment;
     boolean success = false;
     try {
       out = directory.createOutput(IndexFileNames.segmentFileName(segment, "", FIELDS_EXTENSION), context);
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsWriter.java
index 117ec19..6563049 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsWriter.java
@@ -55,9 +55,7 @@ public class SimpleTextTermVectorsWriter extends TermVectorsWriter {
   static final BytesRef ENDOFFSET          = new BytesRef("        endoffset ");
 
   static final String VECTORS_EXTENSION = "vec";
-  
-  private final Directory directory;
-  private final String segment;
+
   private IndexOutput out;
   private int numDocsWritten = 0;
   private final BytesRefBuilder scratch = new BytesRefBuilder();
@@ -66,8 +64,6 @@ public class SimpleTextTermVectorsWriter extends TermVectorsWriter {
   private boolean payloads;
 
   public SimpleTextTermVectorsWriter(Directory directory, String segment, IOContext context) throws IOException {
-    this.directory = directory;
-    this.segment = segment;
     boolean success = false;
     try {
       out = directory.createOutput(IndexFileNames.segmentFileName(segment, "", VECTORS_EXTENSION), context);
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java b/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java
index c937886..9d10e0c 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListReader.java
@@ -50,7 +50,7 @@ public abstract class MultiLevelSkipListReader implements Closeable {
   // the skipInterval. The top level can not contain more than
   // skipLevel entries, the second top level can not contain more
   // than skipLevel^2 entries and so forth.
-  private int numberOfLevelsToBuffer = 1;
+  private static final int NUMBER_OF_LEVELS_TO_BUFFER = 1;
   
   private int docCount;
 
@@ -222,7 +222,7 @@ public abstract class MultiLevelSkipListReader implements Closeable {
 
     skipStream[0].seek(skipPointer[0]);
     
-    int toBuffer = numberOfLevelsToBuffer;
+    int toBuffer = NUMBER_OF_LEVELS_TO_BUFFER;
     
     for (int i = numberOfSkipLevels - 1; i > 0; i--) {
       // the length of the current level
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
index 8cd8ccb..982e4fb 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
@@ -76,7 +76,6 @@ public final class CompressingStoredFieldsWriter extends StoredFieldsWriter {
   static final int VERSION_START = 1;
   static final int VERSION_CURRENT = VERSION_START;
 
-  private final String segment;
   private CompressingStoredFieldsIndexWriter indexWriter;
   private IndexOutput fieldsStream;
 
@@ -98,7 +97,7 @@ public final class CompressingStoredFieldsWriter extends StoredFieldsWriter {
   public CompressingStoredFieldsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,
       String formatName, CompressionMode compressionMode, int chunkSize, int maxDocsPerChunk, int blockSize) throws IOException {
     assert directory != null;
-    this.segment = si.name;
+    String segment = si.name;
     this.compressionMode = compressionMode;
     this.compressor = compressionMode.newCompressor();
     this.chunkSize = chunkSize;
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java
index 26fe890..bb68be3 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter.java
@@ -74,7 +74,6 @@ public final class CompressingTermVectorsWriter extends TermVectorsWriter {
   static final int  PAYLOADS = 0x04;
   static final int FLAGS_BITS = PackedInts.bitsRequired(POSITIONS | OFFSETS | PAYLOADS);
 
-  private final String segment;
   private CompressingStoredFieldsIndexWriter indexWriter;
   private IndexOutput vectorsStream;
 
@@ -206,7 +205,7 @@ public final class CompressingTermVectorsWriter extends TermVectorsWriter {
   public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,
       String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {
     assert directory != null;
-    this.segment = si.name;
+    String segment = si.name;
     this.compressionMode = compressionMode;
     this.compressor = compressionMode.newCompressor();
     this.chunkSize = chunkSize;
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
index d360adb..6f27af1 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
@@ -49,7 +49,6 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
   final BytesRefHash bytesHash;
 
   ParallelPostingsArray postingsArray;
-  private final Counter bytesUsed;
 
   /** streamCount: how many streams this field stores per term.
    * E.g. doc(+freq) is 1 stream, prox+offset is a second. */
@@ -60,7 +59,7 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
     termBytePool = termsHash.termBytePool;
     docState = termsHash.docState;
     this.termsHash = termsHash;
-    bytesUsed = termsHash.bytesUsed;
+    Counter bytesUsed = termsHash.bytesUsed;
     this.fieldState = fieldState;
     this.streamCount = streamCount;
     numPostingInt = 2*streamCount;
diff --git a/lucene/core/src/java/org/apache/lucene/store/DataOutput.java b/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
index 9c11249..8f87a26 100644
--- a/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
+++ b/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
@@ -259,7 +259,7 @@ public abstract class DataOutput {
     writeBytes(utf8Result.bytes, utf8Result.offset, utf8Result.length);
   }
 
-  private static int COPY_BUFFER_SIZE = 16384;
+  private static final int COPY_BUFFER_SIZE = 16384;
   private byte[] copyBuffer;
 
   /** Copy numBytes bytes from input to ourself. */
diff --git a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
index a20dece..1fa3748 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java
@@ -55,7 +55,6 @@ public class TestDoc extends LuceneTestCase {
 
   private Path workDir;
   private Path indexDir;
-  private LinkedList<Path> files;
 
   /** Set the test case. This test case needs
    *  a few text files created in the current working directory.
@@ -72,14 +71,13 @@ public class TestDoc extends LuceneTestCase {
     Directory directory = newFSDirectory(indexDir);
     directory.close();
 
-    files = new LinkedList<>();
-    files.add(createOutput("test.txt",
-                           "This is the first test file"
-                           ));
+    createOutput("test.txt",
+                 "This is the first test file"
+                 );
 
-    files.add(createOutput("test2.txt",
-                           "This is the second test file"
-                           ));
+    createOutput("test2.txt",
+                 "This is the second test file"
+                 );
   }
 
   private Path createOutput(String name, String text) throws IOException {
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java b/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
index 828dcbe..4a8fe45 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/Test2BFST.java
@@ -37,7 +37,7 @@ import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
 @TimeoutSuite(millis = 100 * TimeUnits.HOUR)
 public class Test2BFST extends LuceneTestCase {
 
-  private static long LIMIT = 3L*1024*1024*1024;
+  private static final long LIMIT = 3L*1024*1024*1024;
 
   public void test() throws Exception {
     assumeWorkingMMapOnWindows();
diff --git a/lucene/expressions/src/test/org/apache/lucene/expressions/js/TestJavascriptFunction.java b/lucene/expressions/src/test/org/apache/lucene/expressions/js/TestJavascriptFunction.java
index ed68a5f..29a02fe 100644
--- a/lucene/expressions/src/test/org/apache/lucene/expressions/js/TestJavascriptFunction.java
+++ b/lucene/expressions/src/test/org/apache/lucene/expressions/js/TestJavascriptFunction.java
@@ -20,7 +20,7 @@ import org.apache.lucene.expressions.Expression;
 import org.apache.lucene.util.LuceneTestCase;
 
 public class TestJavascriptFunction extends LuceneTestCase {
-  private static double DELTA = 0.0000001;
+  private static final double DELTA = 0.0000001;
   
   private void assertEvaluatesTo(String expression, double expected) throws Exception {
     Expression evaluator = JavascriptCompiler.compile(expression);
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java
index f1e2c44..93f91c5 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java
@@ -118,7 +118,7 @@ public class UnifiedHighlighter {
 
   private boolean defaultHighlightPhrasesStrictly = true; // AKA "accuracy" or "query debugging"
 
-  private boolean defaultPassageRelevancyOverSpeed = true; //For analysis, prefer MemoryIndexOffsetStrategy
+  private static final boolean DEFAULT_PASSAGE_RELEVANCY_OVER_SPEED = true; //For analysis, prefer MemoryIndexOffsetStrategy
 
   private int maxLength = DEFAULT_MAX_LENGTH;
 
@@ -222,7 +222,7 @@ public class UnifiedHighlighter {
 
 
   protected boolean shouldPreferPassageRelevancyOverSpeed(String field) {
-    return defaultPassageRelevancyOverSpeed;
+    return DEFAULT_PASSAGE_RELEVANCY_OVER_SPEED;
   }
 
   /**
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/BoostingQueryBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/BoostingQueryBuilder.java
index f58804b..cdfcd07 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/BoostingQueryBuilder.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/BoostingQueryBuilder.java
@@ -28,7 +28,7 @@ import org.w3c.dom.Element;
  */
 public class BoostingQueryBuilder implements QueryBuilder {
 
-  private static float DEFAULT_BOOST = 0.01f;
+  private static final float DEFAULT_BOOST = 0.01f;
   
   private final QueryBuilder factory;
 
diff --git a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
index 9ccb2c7..3f81dad 100644
--- a/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
+++ b/lucene/replicator/src/test/org/apache/lucene/replicator/IndexAndTaxonomyReplicationClientTest.java
@@ -136,8 +136,7 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
   private SnapshotDirectoryTaxonomyWriter publishTaxoWriter;
   private FacetsConfig config;
   private IndexAndTaxonomyReadyCallback callback;
-  private Path clientWorkDir;
-  
+
   private static final String VERSION_ID = "version";
   
   private void assertHandlerRevision(int expectedID, Directory dir) throws IOException {
@@ -194,7 +193,7 @@ public class IndexAndTaxonomyReplicationClientTest extends ReplicatorTestCase {
     publishTaxoDir = newDirectory();
     handlerIndexDir = newMockDirectory();
     handlerTaxoDir = newMockDirectory();
-    clientWorkDir = createTempDir("replicationClientTest");
+    Path clientWorkDir = createTempDir("replicationClientTest");
     sourceDirFactory = new PerSessionDirectoryFactory(clientWorkDir);
     replicator = new LocalReplicator();
     callback = new IndexAndTaxonomyReadyCallback(handlerIndexDir, handlerTaxoDir);
diff --git a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
index 590eb86..9461d90 100644
--- a/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
+++ b/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
@@ -668,7 +668,7 @@ public class AnalyzingSuggesterTest extends LuceneTestCase {
     }
   }
 
-  private static char SEP = '\u001F';
+  private static final char SEP = '\u001F';
 
   public void testRandom() throws Exception {
 
diff --git a/lucene/test-framework/src/java/org/apache/lucene/geo/EarthDebugger.java b/lucene/test-framework/src/java/org/apache/lucene/geo/EarthDebugger.java
index 3553b15..4702979 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/geo/EarthDebugger.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/geo/EarthDebugger.java
@@ -71,7 +71,7 @@ public class EarthDebugger {
     }
   }
 
-  private static double MAX_KM_PER_STEP = 100.0;
+  private static final double MAX_KM_PER_STEP = 100.0;
 
   // Web GL earth connects dots by tunneling under the earth, so we approximate a great circle by sampling it, to minimize how deep in the
   // earth each segment tunnels:
diff --git a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/EntityProcessorWrapper.java b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/EntityProcessorWrapper.java
index 8a76e11..7492a91 100644
--- a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/EntityProcessorWrapper.java
+++ b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/EntityProcessorWrapper.java
@@ -51,7 +51,6 @@ public class EntityProcessorWrapper extends EntityProcessor {
   private boolean initialized;
   private String onError;
   private Context context;
-  private VariableResolver resolver;
   private String entityName;
 
   protected List<Transformer> transformers;
@@ -68,7 +67,7 @@ public class EntityProcessorWrapper extends EntityProcessor {
   public void init(Context context) {
     rowcache = null;
     this.context = context;
-    resolver = (VariableResolver) context.getVariableResolver();
+    VariableResolver resolver = (VariableResolver) context.getVariableResolver();
     if (entityName == null) {
       onError = resolver.replaceTokens(context.getEntityAttribute(ON_ERROR));
       if (onError == null) onError = ABORT;
diff --git a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/config/Entity.java b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/config/Entity.java
index 0d0ba4f..28d1aee 100644
--- a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/config/Entity.java
+++ b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/config/Entity.java
@@ -45,12 +45,10 @@ public class Entity {
   private final Map<String,Set<EntityField>> colNameVsField;
   private final Map<String,String> allAttributes;
   private final List<Map<String,String>> allFieldAttributes;
-  private final DIHConfiguration config;
-  
+
   public Entity(boolean docRootFound, Element element, DataImporter di, DIHConfiguration config, Entity parent) {
     this.parentEntity = parent;
-    this.config = config;
-    
+
     String modName = ConfigParseUtil.getStringAttribute(element, ConfigNameConstants.NAME, null);
     if (modName == null) {
       throw new DataImportHandlerException(SEVERE, "Entity must have a name.");
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestErrorHandling.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestErrorHandling.java
index 74eaf9e..8f50871 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestErrorHandling.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestErrorHandling.java
@@ -62,30 +62,30 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
   
   public void testMalformedStreamingXml() throws Exception {
     StringDataSource.xml = malformedXml;
-    runFullImport(dataConfigWithStreaming);
+    runFullImport(DATA_CONFIG_WITH_STREAMING);
     assertQ(req("id:1"), "//*[@numFound='1']");
     assertQ(req("id:2"), "//*[@numFound='1']");
   }
 
   public void testMalformedNonStreamingXml() throws Exception {
     StringDataSource.xml = malformedXml;
-    runFullImport(dataConfigWithoutStreaming);
+    runFullImport(DATA_CONFIG_WITHOUT_STREAMING);
     assertQ(req("id:1"), "//*[@numFound='1']");
     assertQ(req("id:2"), "//*[@numFound='1']");
   }
 
   public void testAbortOnError() throws Exception {
     StringDataSource.xml = malformedXml;
-    runFullImport(dataConfigAbortOnError);
+    runFullImport(DATA_CONFIG_ABORT_ON_ERROR);
     assertQ(req("*:*"), "//*[@numFound='0']");
   }
 
   public void testTransformerErrorContinue() throws Exception {
-    StringDataSource.xml = wellformedXml;
+    StringDataSource.xml = WELLFORMED_XML;
     List<Map<String, Object>> rows = new ArrayList<>();
     rows.add(createMap("id", "3", "desc", "exception-transformer"));
     MockDataSource.setIterator("select * from foo", rows.iterator());
-    runFullImport(dataConfigWithTransformer);
+    runFullImport(DATA_CONFIG_WITH_TRANSFORMER);
     assertQ(req("*:*"), "//*[@numFound='3']");
   }
 
@@ -114,7 +114,7 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
     }
   }
 
-  private String dataConfigWithStreaming = "<dataConfig>\n" +
+  private static final String DATA_CONFIG_WITH_STREAMING = "<dataConfig>\n" +
           "        <dataSource name=\"str\" type=\"TestErrorHandling$StringDataSource\" />" +
           "    <document>\n" +
           "        <entity name=\"node\" dataSource=\"str\" processor=\"XPathEntityProcessor\" url=\"test\" stream=\"true\" forEach=\"/root/node\" onError=\"skip\">\n" +
@@ -124,7 +124,7 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
           "    </document>\n" +
           "</dataConfig>";
 
-  private String dataConfigWithoutStreaming = "<dataConfig>\n" +
+  private static final String DATA_CONFIG_WITHOUT_STREAMING = "<dataConfig>\n" +
           "        <dataSource name=\"str\" type=\"TestErrorHandling$StringDataSource\" />" +
           "    <document>\n" +
           "        <entity name=\"node\" dataSource=\"str\" processor=\"XPathEntityProcessor\" url=\"test\" forEach=\"/root/node\" onError=\"skip\">\n" +
@@ -134,7 +134,7 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
           "    </document>\n" +
           "</dataConfig>";
 
-  private String dataConfigAbortOnError = "<dataConfig>\n" +
+  private static final String DATA_CONFIG_ABORT_ON_ERROR = "<dataConfig>\n" +
           "        <dataSource name=\"str\" type=\"TestErrorHandling$StringDataSource\" />" +
           "    <document>\n" +
           "        <entity name=\"node\" dataSource=\"str\" processor=\"XPathEntityProcessor\" url=\"test\" forEach=\"/root/node\" onError=\"abort\">\n" +
@@ -144,7 +144,7 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
           "    </document>\n" +
           "</dataConfig>";
 
-  private String dataConfigWithTransformer = "<dataConfig>\n" +
+  private static final String DATA_CONFIG_WITH_TRANSFORMER = "<dataConfig>\n" +
           "        <dataSource name=\"str\" type=\"TestErrorHandling$StringDataSource\" />" +
           "<dataSource  type=\"MockDataSource\"/>" +
           "    <document>\n" +
@@ -172,7 +172,7 @@ public class TestErrorHandling extends AbstractDataImportHandlerTestCase {
           "    </node>\n" +
           "</root>";
 
-  private String wellformedXml = "<root>\n" +
+  private static final String WELLFORMED_XML = "<root>\n" +
           "    <node>\n" +
           "        <id>1</id>\n" +
           "        <desc>test1</desc>\n" +
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestNonWritablePersistFile.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestNonWritablePersistFile.java
index a7d3d0a..9837997 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestNonWritablePersistFile.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestNonWritablePersistFile.java
@@ -47,11 +47,10 @@ public class TestNonWritablePersistFile extends AbstractDataImportHandlerTestCas
     "    </entity>\n" +
     "  </document>\n" +
     "</dataConfig>\n";
-  private static String tmpSolrHome;
 
   @BeforeClass
   public static void createTempSolrHomeAndCore() throws Exception {
-    tmpSolrHome = createTempDir().toFile().getAbsolutePath();
+    String tmpSolrHome = createTempDir().toFile().getAbsolutePath();
     FileUtils.copyDirectory(getFile("dih/solr"), new File(tmpSolrHome).getAbsoluteFile());
     initCore("dataimport-solrconfig.xml", "dataimport-schema.xml", 
              new File(tmpSolrHome).getAbsolutePath());
diff --git a/solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRThreadModule.java b/solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRThreadModule.java
index b8d0bda..cab5722 100644
--- a/solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRThreadModule.java
+++ b/solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRThreadModule.java
@@ -76,7 +76,7 @@ final public class LTRThreadModule implements NamedListInitializedPlugin {
     return threadManager;
   }
 
-  private static String CONFIG_PREFIX = "threadModule.";
+  private static final String CONFIG_PREFIX = "threadModule.";
 
   private static NamedList extractThreadModuleParams(NamedList args) {
 
diff --git a/solr/core/src/java/org/apache/solr/api/V2HttpCall.java b/solr/core/src/java/org/apache/solr/api/V2HttpCall.java
index fb4aa56..8daae6c 100644
--- a/solr/core/src/java/org/apache/solr/api/V2HttpCall.java
+++ b/solr/core/src/java/org/apache/solr/api/V2HttpCall.java
@@ -64,7 +64,6 @@ public class V2HttpCall extends HttpSolrCall {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
   private Api api;
   List<String> pieces;
-  private String prefix;
   HashMap<String, String> parts = new HashMap<>();
   static final Set<String> knownPrefixes = ImmutableSet.of("cluster", "node", "collections", "cores", "c");
 
@@ -78,6 +77,7 @@ public class V2HttpCall extends HttpSolrCall {
     String fullPath = path = path.substring(7);//strip off '/____v2'
     try {
       pieces = getPathSegments(path);
+      String prefix;
       if (pieces.size() == 0) {
         prefix = "c";
         path = "/c";
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
index 2c08305..d073ff2 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler.java
@@ -998,13 +998,11 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler
       message.getStr(COLLECTION_PROP) : message.getStr(NAME);
   }
 
-
-  private long sessionId = -1;
   private LockTree.Session lockSession;
 
   @Override
   public Lock lockTask(ZkNodeProps message, OverseerTaskProcessor.TaskBatch taskBatch) {
-    if (lockSession == null || sessionId != taskBatch.getId()) {
+    if (lockSession == null || -1 != taskBatch.getId()) {
       //this is always called in the same thread.
       //Each batch is supposed to have a new taskBatch
       //So if taskBatch changes we must create a new Session
diff --git a/solr/core/src/java/org/apache/solr/cloud/ZkController.java b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
index 677bf29..0efe52d 100644
--- a/solr/core/src/java/org/apache/solr/cloud/ZkController.java
+++ b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
@@ -176,7 +176,6 @@ public class ZkController {
   private final Map<ContextKey, ElectionContext> electionContexts = Collections.synchronizedMap(new HashMap<>());
 
   private final SolrZkClient zkClient;
-  private final ZkCmdExecutor cmdExecutor;
   private final ZkStateReader zkStateReader;
 
   private final String zkServerAddress;          // example: 127.0.0.1:54062/solr
@@ -416,7 +415,6 @@ public class ZkController {
     this.overseerRunningMap = Overseer.getRunningMap(zkClient);
     this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);
     this.overseerFailureMap = Overseer.getFailureMap(zkClient);
-    cmdExecutor = new ZkCmdExecutor(clientTimeout);
     zkStateReader = new ZkStateReader(zkClient, () -> {
       if (cc != null) cc.securityNodeChanged();
     });
diff --git a/solr/core/src/java/org/apache/solr/core/CachingDirectoryFactory.java b/solr/core/src/java/org/apache/solr/core/CachingDirectoryFactory.java
index e710063..c681198 100644
--- a/solr/core/src/java/org/apache/solr/core/CachingDirectoryFactory.java
+++ b/solr/core/src/java/org/apache/solr/core/CachingDirectoryFactory.java
@@ -95,14 +95,6 @@ public abstract class CachingDirectoryFactory extends DirectoryFactory {
   
   protected Set<CacheValue> removeEntries = new HashSet<>();
 
-  private Double maxWriteMBPerSecFlush;
-
-  private Double maxWriteMBPerSecMerge;
-
-  private Double maxWriteMBPerSecRead;
-
-  private Double maxWriteMBPerSecDefault;
-
   private boolean closed;
   
   public interface CloseListener {
@@ -391,10 +383,6 @@ public abstract class CachingDirectoryFactory extends DirectoryFactory {
   
   @Override
   public void init(NamedList args) {
-    maxWriteMBPerSecFlush = (Double) args.get("maxWriteMBPerSecFlush");
-    maxWriteMBPerSecMerge = (Double) args.get("maxWriteMBPerSecMerge");
-    maxWriteMBPerSecRead = (Double) args.get("maxWriteMBPerSecRead");
-    maxWriteMBPerSecDefault = (Double) args.get("maxWriteMBPerSecDefault");
   }
   
   /*
diff --git a/solr/core/src/java/org/apache/solr/core/RunExecutableListener.java b/solr/core/src/java/org/apache/solr/core/RunExecutableListener.java
index c6d0090..b4267f5 100644
--- a/solr/core/src/java/org/apache/solr/core/RunExecutableListener.java
+++ b/solr/core/src/java/org/apache/solr/core/RunExecutableListener.java
@@ -143,6 +143,6 @@ class RunExecutableListener extends AbstractSolrEventListener implements SolrCor
   }
 
   /** Non-zero value for an invalid return code **/
-  private static int INVALID_PROCESS_RETURN_CODE = -1;
+  private static final int INVALID_PROCESS_RETURN_CODE = -1;
 
 }
diff --git a/solr/core/src/java/org/apache/solr/core/SolrCore.java b/solr/core/src/java/org/apache/solr/core/SolrCore.java
index a6ba2dc..efaeeca 100644
--- a/solr/core/src/java/org/apache/solr/core/SolrCore.java
+++ b/solr/core/src/java/org/apache/solr/core/SolrCore.java
@@ -206,7 +206,6 @@ public final class SolrCore implements SolrInfoMBean, SolrMetricProducer, Closea
   private final IndexDeletionPolicyWrapper solrDelPolicy;
   private final SolrSnapshotMetaDataManager snapshotMgr;
   private final DirectoryFactory directoryFactory;
-  private final RecoveryStrategy.Builder recoveryStrategyBuilder;
   private IndexReaderFactory indexReaderFactory;
   private final Codec codec;
   private final MemClassLoader memClassLoader;
@@ -882,6 +881,7 @@ public final class SolrCore implements SolrInfoMBean, SolrMetricProducer, Closea
     this.coreMetricManager = initCoreMetricManager(config);
     this.coreMetricManager.loadReporters();
 
+    RecoveryStrategy.Builder recoveryStrategyBuilder;
     if (updateHandler == null) {
       directoryFactory = initDirectoryFactory();
       recoveryStrategyBuilder = initRecoveryStrategyBuilder();
diff --git a/solr/core/src/java/org/apache/solr/handler/CdcrReplicatorScheduler.java b/solr/core/src/java/org/apache/solr/handler/CdcrReplicatorScheduler.java
index 62abeab..15769db 100644
--- a/solr/core/src/java/org/apache/solr/handler/CdcrReplicatorScheduler.java
+++ b/solr/core/src/java/org/apache/solr/handler/CdcrReplicatorScheduler.java
@@ -38,7 +38,6 @@ class CdcrReplicatorScheduler {
   private ScheduledExecutorService scheduler;
   private ExecutorService replicatorsPool;
 
-  private final CdcrReplicatorManager replicatorManager;
   private final ConcurrentLinkedQueue<CdcrReplicatorState> statesQueue;
 
   private int poolSize = DEFAULT_POOL_SIZE;
@@ -52,8 +51,7 @@ class CdcrReplicatorScheduler {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
   CdcrReplicatorScheduler(final CdcrReplicatorManager replicatorStatesManager, final SolrParams replicatorConfiguration) {
-    this.replicatorManager = replicatorStatesManager;
-    this.statesQueue = new ConcurrentLinkedQueue<>(replicatorManager.getReplicatorStates());
+    this.statesQueue = new ConcurrentLinkedQueue<>(replicatorStatesManager.getReplicatorStates());
     if (replicatorConfiguration != null) {
       poolSize = replicatorConfiguration.getInt(CdcrParams.THREAD_POOL_SIZE_PARAM, DEFAULT_POOL_SIZE);
       timeSchedule = replicatorConfiguration.getInt(CdcrParams.SCHEDULE_PARAM, DEFAULT_TIME_SCHEDULE);
diff --git a/solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.java b/solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.java
index ba174f9..560ea1f 100644
--- a/solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.java
@@ -120,7 +120,6 @@ public class CdcrRequestHandler extends RequestHandlerBase implements SolrCoreAw
   private CdcrReplicatorManager replicatorManager;
   private CdcrLeaderStateManager leaderStateManager;
   private CdcrUpdateLogSynchronizer updateLogSynchronizer;
-  private CdcrBufferManager bufferManager;
 
   @Override
   public void init(NamedList args) {
@@ -302,7 +301,7 @@ public class CdcrRequestHandler extends RequestHandlerBase implements SolrCoreAw
     updateLogSynchronizer.stateUpdate();
 
     // Initialise the buffer manager
-    bufferManager = new CdcrBufferManager(core);
+    CdcrBufferManager bufferManager = new CdcrBufferManager(core);
     bufferManager.setLeaderStateManager(leaderStateManager);
     bufferManager.setBufferStateManager(bufferStateManager);
     // we need to inform it of a state event since the leader state
diff --git a/solr/core/src/java/org/apache/solr/handler/IndexFetcher.java b/solr/core/src/java/org/apache/solr/handler/IndexFetcher.java
index d79effd..d76661d 100644
--- a/solr/core/src/java/org/apache/solr/handler/IndexFetcher.java
+++ b/solr/core/src/java/org/apache/solr/handler/IndexFetcher.java
@@ -153,8 +153,6 @@ public class IndexFetcher {
 
   private boolean useInternalCompression = false;
 
-  private boolean useExternalCompression = false;
-
   private boolean fetchFromLeader = false;
 
   private final HttpClient myHttpClient;
@@ -237,7 +235,7 @@ public class IndexFetcher {
     this.replicationHandler = handler;
     String compress = (String) initArgs.get(COMPRESSION);
     useInternalCompression = INTERNAL.equals(compress);
-    useExternalCompression = EXTERNAL.equals(compress);
+    boolean useExternalCompression = EXTERNAL.equals(compress);
     connTimeout = getParameter(initArgs, HttpClientUtil.PROP_CONNECTION_TIMEOUT, 30000, null);
     
     // allow a master override for tests - you specify this in /replication slave section of solrconfig and some 
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/MetricsCollectorHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/MetricsCollectorHandler.java
index de39a61..914ac21 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/MetricsCollectorHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/MetricsCollectorHandler.java
@@ -84,7 +84,6 @@ public class MetricsCollectorHandler extends RequestHandlerBase {
   private final CoreContainer coreContainer;
   private final SolrMetricManager metricManager;
   private final Map<String, ContentStreamLoader> loaders = new HashMap<>();
-  private SolrParams params;
 
   public MetricsCollectorHandler(final CoreContainer coreContainer) {
     this.coreContainer = coreContainer;
@@ -95,6 +94,7 @@ public class MetricsCollectorHandler extends RequestHandlerBase {
   @Override
   public void init(NamedList initArgs) {
     super.init(initArgs);
+    SolrParams params;
     if (initArgs != null) {
       params = SolrParams.toSolrParams(initArgs);
     } else {
diff --git a/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java b/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
index 656ac71..5a1d234 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
@@ -115,11 +115,9 @@ import org.apache.solr.util.plugin.SolrCoreAware;
 public class ExpandComponent extends SearchComponent implements PluginInfoInitialized, SolrCoreAware {
   public static final String COMPONENT_NAME = "expand";
   private static final int finishingStage = ResponseBuilder.STAGE_GET_FIELDS;
-  private PluginInfo info = PluginInfo.EMPTY_INFO;
 
   @Override
   public void init(PluginInfo info) {
-    this.info = info;
   }
 
   @Override
diff --git a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
index 40e17a9..afab5a4 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
@@ -172,11 +172,6 @@ public class HttpShardHandler extends ShardHandler {
         srsp.setException(cex); //????
       } catch (Exception th) {
         srsp.setException(th);
-        if (th instanceof SolrException) {
-          srsp.setResponseCode(((SolrException)th).code());
-        } else {
-          srsp.setResponseCode(-1);
-        }
       }
 
       ssr.elapsedTime = TimeUnit.MILLISECONDS.convert(System.nanoTime() - startTime, TimeUnit.NANOSECONDS);
diff --git a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
index 4262c20..28c3fe0 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
@@ -101,8 +101,6 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
 
   private String scheme = null;
 
-  private HttpClientMetricNameStrategy metricNameStrategy;
-
   protected final Random r = new Random();
 
   private final ReplicaListTransformer shufflingReplicaListTransformer = new ShufflingReplicaListTransformer(r);
@@ -151,8 +149,8 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
     }
 
     String strategy = getParameter(args, "metricNameStrategy", UpdateShardHandlerConfig.DEFAULT_METRICNAMESTRATEGY, sb);
-    this.metricNameStrategy = KNOWN_METRIC_NAME_STRATEGIES.get(strategy);
-    if (this.metricNameStrategy == null)  {
+    HttpClientMetricNameStrategy metricNameStrategy = KNOWN_METRIC_NAME_STRATEGIES.get(strategy);
+    if (metricNameStrategy == null)  {
       throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,
           "Unknown metricNameStrategy: " + strategy + " found. Must be one of: " + KNOWN_METRIC_NAME_STRATEGIES.keySet());
     }
@@ -186,7 +184,7 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
     );
 
     ModifiableSolrParams clientParams = getClientParams();
-    httpRequestExecutor = new InstrumentedHttpRequestExecutor(this.metricNameStrategy);
+    httpRequestExecutor = new InstrumentedHttpRequestExecutor(metricNameStrategy);
     clientConnectionManager = new InstrumentedPoolingHttpClientConnectionManager(HttpClientUtil.getSchemaRegisteryProvider().getSchemaRegistry());
     this.defaultClient = HttpClientUtil.createClient(clientParams, clientConnectionManager, false, httpRequestExecutor);
     this.loadbalancer = createLoadbalancer(defaultClient);
diff --git a/solr/core/src/java/org/apache/solr/handler/component/ShardResponse.java b/solr/core/src/java/org/apache/solr/handler/component/ShardResponse.java
index 5da721c..64e1bcd 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/ShardResponse.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/ShardResponse.java
@@ -23,7 +23,6 @@ public final class ShardResponse {
   private String shard;
   private String nodeName;
   private String shardAddress;  // the specific shard that this response was received from
-  private int rspCode;
   private Throwable exception;
   private SolrResponse rsp;
 
@@ -81,12 +80,7 @@ public final class ShardResponse {
     this.exception = exception;
   }
 
-  void setResponseCode(int rspCode)
-  {
-    this.rspCode = rspCode;
-  }
-  
-  void setNodeName(String nodeName) 
+  void setNodeName(String nodeName)
   {
     this.nodeName = nodeName;
   }
diff --git a/solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java b/solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
index 6a6e9be..465e3c0 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
@@ -175,14 +175,12 @@ public class StatsComponent extends SearchComponent {
  */
 class StatsInfo {
 
-  private final ResponseBuilder rb;
   private final List<StatsField> statsFields = new ArrayList<>(7);
   private final Map<String, StatsValues> distribStatsValues = new LinkedHashMap<>();
   private final Map<String, StatsField> statsFieldMap = new LinkedHashMap<>();
   private final Map<String, List<StatsField>> tagToStatsFields = new LinkedHashMap<>();
 
-  public StatsInfo(ResponseBuilder rb) { 
-    this.rb = rb;
+  public StatsInfo(ResponseBuilder rb) {
     SolrParams params = rb.req.getParams();
     String[] statsParams = params.getParams(StatsParams.STATS_FIELD);
     if (null == statsParams) {
diff --git a/solr/core/src/java/org/apache/solr/handler/sql/SolrEnumerator.java b/solr/core/src/java/org/apache/solr/handler/sql/SolrEnumerator.java
index 7ba3838..e595780 100644
--- a/solr/core/src/java/org/apache/solr/handler/sql/SolrEnumerator.java
+++ b/solr/core/src/java/org/apache/solr/handler/sql/SolrEnumerator.java
@@ -35,7 +35,7 @@ class SolrEnumerator implements Enumerator<Object> {
   private final TupleStream tupleStream;
   private final List<Map.Entry<String, Class>> fields;
   private Tuple current;
-  private char sep = 31;
+  private static final char SEP = 31;
 
   /** Creates a SolrEnumerator.
    *
@@ -92,7 +92,7 @@ class SolrEnumerator implements Enumerator<Object> {
       StringBuilder buf = new StringBuilder();
 
       for(Object o : arrayList) {
-        buf.append(sep);
+        buf.append(SEP);
         buf.append(o.toString());
       }
       val = buf.toString();
diff --git a/solr/core/src/java/org/apache/solr/request/macro/MacroExpander.java b/solr/core/src/java/org/apache/solr/request/macro/MacroExpander.java
index 9d432fa..b1e0c37 100644
--- a/solr/core/src/java/org/apache/solr/request/macro/MacroExpander.java
+++ b/solr/core/src/java/org/apache/solr/request/macro/MacroExpander.java
@@ -31,8 +31,7 @@ public class MacroExpander {
 
   private Map<String,String[]> orig;
   private Map<String,String[]> expanded;
-  private String macroStart = MACRO_START;
-  private char escape = '\\';
+  private static final char ESCAPE = '\\';
   private int level;
   private final boolean failOnMissingParams;
 
@@ -106,13 +105,13 @@ public class MacroExpander {
 
   private String _expand(String val) {
     // quickest short circuit
-    int idx = val.indexOf(macroStart.charAt(0));
+    int idx = val.indexOf(MACRO_START.charAt(0));
     if (idx < 0) return val;
 
     int start = 0;  // start of the unprocessed part of the string
     StringBuilder sb = null;
     for (;;) {
-      idx = val.indexOf(macroStart, idx);
+      idx = val.indexOf(MACRO_START, idx);
       int matchedStart = idx;
 
       // check if escaped
@@ -122,8 +121,8 @@ public class MacroExpander {
         // of the escape character?
 
         char ch = val.charAt(idx-1);
-        if (ch == escape) {
-          idx += macroStart.length();
+        if (ch == ESCAPE) {
+          idx += MACRO_START.length();
           continue;
         }
       }
@@ -134,7 +133,7 @@ public class MacroExpander {
       }
 
       // found unescaped "${"
-      idx += macroStart.length();
+      idx += MACRO_START.length();
 
       int rbrace = val.indexOf('}', idx);
       if (rbrace == -1) {
diff --git a/solr/core/src/java/org/apache/solr/response/DocsStreamer.java b/solr/core/src/java/org/apache/solr/response/DocsStreamer.java
index 40e0afc..daa6d0a 100644
--- a/solr/core/src/java/org/apache/solr/response/DocsStreamer.java
+++ b/solr/core/src/java/org/apache/solr/response/DocsStreamer.java
@@ -61,7 +61,6 @@ public class DocsStreamer implements Iterator<SolrDocument> {
 
   private final org.apache.solr.response.ResultContext rctx;
   private final SolrDocumentFetcher docFetcher; // a collaborator of SolrIndexSearcher
-  private final DocList docs;
 
   private final DocTransformer transformer;
   private final DocIterator docIterator;
@@ -74,9 +73,9 @@ public class DocsStreamer implements Iterator<SolrDocument> {
 
   public DocsStreamer(ResultContext rctx) {
     this.rctx = rctx;
-    this.docs = rctx.getDocList();
+    DocList docs = rctx.getDocList();
     transformer = rctx.getReturnFields().getTransformer();
-    docIterator = this.docs.iterator();
+    docIterator = docs.iterator();
     fnames = rctx.getReturnFields().getLuceneFieldNames();
     //TODO move onlyPseudoFields calc to ReturnFields
     onlyPseudoFields = (fnames == null && !rctx.getReturnFields().wantsAllFields() && !rctx.getReturnFields().hasPatternMatching())
diff --git a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
index 7b27c3f..326841c 100644
--- a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
+++ b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
@@ -80,7 +80,6 @@ public class CurrencyField extends FieldType implements SchemaAware, ResourceLoa
   private IndexSchema schema;
   protected FieldType fieldTypeCurrency;
   protected FieldType fieldTypeAmountRaw;
-  private String exchangeRateProviderClass;
   private String defaultCurrency;
   private ExchangeRateProvider provider;
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
@@ -110,15 +109,15 @@ public class CurrencyField extends FieldType implements SchemaAware, ResourceLoa
                               this.typeName);
     }
     this.schema = schema;
-    this.exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);
+    String exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);
     this.defaultCurrency = args.get(PARAM_DEFAULT_CURRENCY);
 
     if (this.defaultCurrency == null) {
       this.defaultCurrency = DEFAULT_DEFAULT_CURRENCY;
     }
     
-    if (this.exchangeRateProviderClass == null) {
-      this.exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;
+    if (exchangeRateProviderClass == null) {
+      exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;
     }
 
     if (null == getCurrency(this.defaultCurrency)) {
diff --git a/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java b/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
index feba4e0..55bb2b4 100644
--- a/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
+++ b/solr/core/src/java/org/apache/solr/schema/ExternalFileField.java
@@ -57,7 +57,6 @@ import org.apache.solr.uninverting.UninvertingReader.Type;
  * @see ExternalFileFieldReloader
  */
 public class ExternalFileField extends FieldType implements SchemaAware {
-  private FieldType ftype;
   private String keyFieldName;
   private IndexSchema schema;
   private float defVal;
@@ -69,7 +68,7 @@ public class ExternalFileField extends FieldType implements SchemaAware {
     // code (see getValueSource) gives you a FileFloatSource.
     String ftypeS = args.remove("valType");
     if (ftypeS != null) {
-      ftype = schema.getFieldTypes().get(ftypeS);
+      FieldType ftype = schema.getFieldTypes().get(ftypeS);
       if (ftype != null && !(ftype instanceof TrieFloatField)) {
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,
             "Only float (TrieFloatField) is currently supported as external field type.  Got " + ftypeS);
diff --git a/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchemaFactory.java b/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchemaFactory.java
index d4a10bd..829a1a9 100644
--- a/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchemaFactory.java
+++ b/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchemaFactory.java
@@ -59,7 +59,6 @@ public class ManagedIndexSchemaFactory extends IndexSchemaFactory implements Sol
   private String resourceName;
   private ManagedIndexSchema schema;
   private SolrCore core;
-  private ZkIndexSchemaReader zkIndexSchemaReader;
 
 
   private String loadedResource;
@@ -374,9 +373,9 @@ public class ManagedIndexSchemaFactory extends IndexSchemaFactory implements Sol
   public void inform(SolrCore core) {
     this.core = core;
     if (loader instanceof ZkSolrResourceLoader) {
-      this.zkIndexSchemaReader = new ZkIndexSchemaReader(this, core);
+      ZkIndexSchemaReader zkIndexSchemaReader = new ZkIndexSchemaReader(this, core);
       ZkSolrResourceLoader zkLoader = (ZkSolrResourceLoader)loader;
-      zkLoader.setZkIndexSchemaReader(this.zkIndexSchemaReader);
+      zkLoader.setZkIndexSchemaReader(zkIndexSchemaReader);
       try {
         zkIndexSchemaReader.refreshSchemaFromZk(-1); // update immediately if newer is available
         core.setLatestSchema(getSchema());
@@ -389,8 +388,6 @@ public class ManagedIndexSchemaFactory extends IndexSchemaFactory implements Sol
         Thread.currentThread().interrupt();
         log.warn("", e);
       }
-    } else {
-      this.zkIndexSchemaReader = null;
     }
   }
 
diff --git a/solr/core/src/java/org/apache/solr/search/DisMaxQParser.java b/solr/core/src/java/org/apache/solr/search/DisMaxQParser.java
index 90fc7e9..18c8732 100644
--- a/solr/core/src/java/org/apache/solr/search/DisMaxQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/DisMaxQParser.java
@@ -46,7 +46,7 @@ public class DisMaxQParser extends QParser {
    * A field we can't ever find in any schema, so we can safely tell DisjunctionMaxQueryParser to use it as our
    * defaultField, and map aliases from it to any field in our schema.
    */
-  private static String IMPOSSIBLE_FIELD_NAME = "\uFFFC\uFFFC\uFFFC";
+  private static final String IMPOSSIBLE_FIELD_NAME = "\uFFFC\uFFFC\uFFFC";
 
   /**
    * Applies the appropriate default rules for the "mm" param based on the 
diff --git a/solr/core/src/java/org/apache/solr/search/FastLRUCache.java b/solr/core/src/java/org/apache/solr/search/FastLRUCache.java
index 9c4b892..5364486 100644
--- a/solr/core/src/java/org/apache/solr/search/FastLRUCache.java
+++ b/solr/core/src/java/org/apache/solr/search/FastLRUCache.java
@@ -55,8 +55,6 @@ public class FastLRUCache<K, V> extends SolrCacheBase implements SolrCache<K,V>
   private ConcurrentLRUCache<K,V> cache;
   private int showItems = 0;
 
-  private long maxRamBytes;
-
   @Override
   public Object init(Map args, Object persistence, CacheRegenerator regenerator) {
     super.init(args, regenerator);
@@ -91,7 +89,7 @@ public class FastLRUCache<K, V> extends SolrCacheBase implements SolrCache<K,V>
     showItems = str == null ? 0 : Integer.parseInt(str);
 
     str = (String) args.get("maxRamMB");
-    this.maxRamBytes = str == null ? Long.MAX_VALUE : (long) (Double.parseDouble(str) * 1024L * 1024L);
+    long maxRamBytes = str == null ? Long.MAX_VALUE : (long) (Double.parseDouble(str) * 1024L * 1024L);
     if (maxRamBytes != Long.MAX_VALUE)  {
       int ramLowerWatermark = (int) (maxRamBytes * 0.8);
       description = generateDescription(maxRamBytes, ramLowerWatermark, newThread);
diff --git a/solr/core/src/java/org/apache/solr/search/Grouping.java b/solr/core/src/java/org/apache/solr/search/Grouping.java
index 9cf9ebc..018cdea 100644
--- a/solr/core/src/java/org/apache/solr/search/Grouping.java
+++ b/solr/core/src/java/org/apache/solr/search/Grouping.java
@@ -99,7 +99,6 @@ public class Grouping {
 
   private int maxDoc;
   private boolean needScores;
-  private boolean getDocSet;
   private boolean getGroupedDocSet;
   private boolean getDocList; // doclist needed for debugging or highlighting
   private Query query;
@@ -313,7 +312,7 @@ public class Grouping {
     } else if (needScores) {
       cacheScores = needScores;
     }
-    getDocSet = (cmd.getFlags() & SolrIndexSearcher.GET_DOCSET) != 0;
+    boolean getDocSet = (cmd.getFlags() & SolrIndexSearcher.GET_DOCSET) != 0;
     getDocList = (cmd.getFlags() & SolrIndexSearcher.GET_DOCLIST) != 0;
     query = QueryUtils.makeQueryable(cmd.getQuery());
 
diff --git a/solr/core/src/java/org/apache/solr/search/QueryParsing.java b/solr/core/src/java/org/apache/solr/search/QueryParsing.java
index 692de1a..4089c1e 100644
--- a/solr/core/src/java/org/apache/solr/search/QueryParsing.java
+++ b/solr/core/src/java/org/apache/solr/search/QueryParsing.java
@@ -268,8 +268,8 @@ public class QueryParsing {
   }
 
 
-  private static int FLAG_BOOSTED=0x01;
-  private static int FLAG_IS_CLAUSE=0x02;
+  private static final int FLAG_BOOSTED=0x01;
+  private static final int FLAG_IS_CLAUSE=0x02;
   /**
    * @see #toString(Query,IndexSchema)
    */
diff --git a/solr/core/src/java/org/apache/solr/search/join/BlockJoinFieldFacetAccumulator.java b/solr/core/src/java/org/apache/solr/search/join/BlockJoinFieldFacetAccumulator.java
index 141b095..00c24ad 100644
--- a/solr/core/src/java/org/apache/solr/search/join/BlockJoinFieldFacetAccumulator.java
+++ b/solr/core/src/java/org/apache/solr/search/join/BlockJoinFieldFacetAccumulator.java
@@ -51,12 +51,11 @@ class BlockJoinFieldFacetAccumulator {
   private long[] segmentAccums = new long[0];
   // for mapping per-segment ords to global ones
   private MultiDocValues.OrdinalMap ordinalMap;
-  private SchemaField schemaField;
   private SortedDocValues segmentSDV;
   
   BlockJoinFieldFacetAccumulator(String fieldName, SolrIndexSearcher searcher) throws IOException {
     this.fieldName = fieldName;
-    schemaField = searcher.getSchema().getField(fieldName);
+    SchemaField schemaField = searcher.getSchema().getField(fieldName);
     fieldType = schemaField.getType();
     ordinalMap = null;
     if (schemaField.multiValued()) {
diff --git a/solr/core/src/java/org/apache/solr/security/Sha256AuthenticationProvider.java b/solr/core/src/java/org/apache/solr/security/Sha256AuthenticationProvider.java
index 0cc58cd..37c9468 100644
--- a/solr/core/src/java/org/apache/solr/security/Sha256AuthenticationProvider.java
+++ b/solr/core/src/java/org/apache/solr/security/Sha256AuthenticationProvider.java
@@ -41,7 +41,6 @@ import static org.apache.solr.handler.admin.SecurityConfHandler.getMapValue;
 
 public class Sha256AuthenticationProvider implements ConfigEditablePlugin,  BasicAuthPlugin.AuthenticationProvider {
   private Map<String, String> credentials;
-  private String realm;
   private Map<String, String> promptHeader;
 
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
@@ -60,8 +59,9 @@ public class Sha256AuthenticationProvider implements ConfigEditablePlugin,  Basi
 
   @Override
   public void init(Map<String, Object> pluginConfig) {
-    if (pluginConfig.get("realm") != null) this.realm = (String) pluginConfig.get("realm");
-    else this.realm = "solr";
+    String realm;
+    if (pluginConfig.get("realm") != null) realm = (String) pluginConfig.get("realm");
+    else realm = "solr";
     
     promptHeader = Collections.unmodifiableMap(Collections.singletonMap("WWW-Authenticate", "Basic realm=\"" + realm + "\""));
     credentials = new LinkedHashMap<>();
diff --git a/solr/core/src/java/org/apache/solr/spelling/QueryConverter.java b/solr/core/src/java/org/apache/solr/spelling/QueryConverter.java
index edb94c4..d966a91 100644
--- a/solr/core/src/java/org/apache/solr/spelling/QueryConverter.java
+++ b/solr/core/src/java/org/apache/solr/spelling/QueryConverter.java
@@ -46,7 +46,6 @@ import java.util.Collection;
  * @since solr 1.3
  */
 public abstract class QueryConverter implements NamedListInitializedPlugin {
-  private NamedList args;
 
   protected Analyzer analyzer;
   
@@ -77,7 +76,6 @@ public abstract class QueryConverter implements NamedListInitializedPlugin {
   public static final int TERM_IN_BOOLEAN_QUERY_FLAG = 131072;
   @Override
   public void init(NamedList args) {
-    this.args = args;
   }
 
   /**
diff --git a/solr/core/src/java/org/apache/solr/store/blockcache/BlockCache.java b/solr/core/src/java/org/apache/solr/store/blockcache/BlockCache.java
index 9deef6c..0ba35bd 100644
--- a/solr/core/src/java/org/apache/solr/store/blockcache/BlockCache.java
+++ b/solr/core/src/java/org/apache/solr/store/blockcache/BlockCache.java
@@ -39,7 +39,6 @@ public class BlockCache {
   private final AtomicInteger[] lockCounters;
   private final int blockSize;
   private final int numberOfBlocksPerBank;
-  private final int maxEntries;
   private final Metrics metrics;
   private final List<OnRelease> onReleases = new CopyOnWriteArrayList<>();
 
@@ -65,7 +64,7 @@ public class BlockCache {
     banks = new ByteBuffer[numberOfBanks];
     locks = new BlockLocks[numberOfBanks];
     lockCounters = new AtomicInteger[numberOfBanks];
-    maxEntries = (numberOfBlocksPerBank * numberOfBanks) - 1;
+    int maxEntries = (numberOfBlocksPerBank * numberOfBanks) - 1;
     for (int i = 0; i < numberOfBanks; i++) {
       if (directAllocation) {
         banks[i] = ByteBuffer.allocateDirect(numberOfBlocksPerBank * blockSize);
diff --git a/solr/core/src/java/org/apache/solr/update/CommitTracker.java b/solr/core/src/java/org/apache/solr/update/CommitTracker.java
index 6cf7504..396e32a 100644
--- a/solr/core/src/java/org/apache/solr/update/CommitTracker.java
+++ b/solr/core/src/java/org/apache/solr/update/CommitTracker.java
@@ -68,11 +68,8 @@ public final class CommitTracker implements Runnable {
   private boolean openSearcher;
   private static final boolean WAIT_SEARCHER = true;
 
-  private String name;
-  
   public CommitTracker(String name, SolrCore core, int docsUpperBound, int timeUpperBound, boolean openSearcher, boolean softCommit) {
     this.core = core;
-    this.name = name;
     pending = null;
     
     this.docsUpperBound = docsUpperBound;
diff --git a/solr/core/src/java/org/apache/solr/update/VersionInfo.java b/solr/core/src/java/org/apache/solr/update/VersionInfo.java
index 061e7f6..67d9248 100644
--- a/solr/core/src/java/org/apache/solr/update/VersionInfo.java
+++ b/solr/core/src/java/org/apache/solr/update/VersionInfo.java
@@ -50,7 +50,6 @@ public class VersionInfo {
   private final UpdateLog ulog;
   private final VersionBucket[] buckets;
   private SchemaField versionField;
-  private SchemaField idField;
   final ReadWriteLock lock = new ReentrantReadWriteLock(true);
 
   /**
@@ -92,7 +91,6 @@ public class VersionInfo {
     this.ulog = ulog;
     IndexSchema schema = ulog.uhandler.core.getLatestSchema(); 
     versionField = getAndCheckVersionField(schema);
-    idField = schema.getUniqueKeyField();
     buckets = new VersionBucket[ BitUtil.nextHighestPowerOfTwo(nBuckets) ];
     for (int i=0; i<buckets.length; i++) {
       buckets[i] = new VersionBucket();
diff --git a/solr/core/src/java/org/apache/solr/update/processor/FieldNameMutatingUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/FieldNameMutatingUpdateProcessorFactory.java
index 1c53732..6314bac 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/FieldNameMutatingUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/FieldNameMutatingUpdateProcessorFactory.java
@@ -46,7 +46,7 @@ import org.apache.solr.update.DeleteUpdateCommand;
 
 public class FieldNameMutatingUpdateProcessorFactory  extends UpdateRequestProcessorFactory{
 
-  private String sourcePattern, replacement;
+  private String replacement;
   private Pattern pattern;
 
 
@@ -83,7 +83,7 @@ public class FieldNameMutatingUpdateProcessorFactory  extends UpdateRequestProce
 
   @Override
   public void init(NamedList args) {
-    sourcePattern = (String) args.get("pattern");
+    String sourcePattern = (String) args.get("pattern");
     replacement = (String) args.get("replacement");
     if(sourcePattern ==null || replacement == null) {
       throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"'pattern' and 'replacement' are required values");
@@ -91,7 +91,7 @@ public class FieldNameMutatingUpdateProcessorFactory  extends UpdateRequestProce
     try {
       pattern = Pattern.compile(sourcePattern);
     } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"invalid pattern "+ sourcePattern );
+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,"invalid pattern "+ sourcePattern);
     }
     super.init(args);
   }
diff --git a/solr/core/src/java/org/apache/solr/util/CryptoKeys.java b/solr/core/src/java/org/apache/solr/util/CryptoKeys.java
index 1122860..ad531a5 100644
--- a/solr/core/src/java/org/apache/solr/util/CryptoKeys.java
+++ b/solr/core/src/java/org/apache/solr/util/CryptoKeys.java
@@ -53,7 +53,6 @@ import org.slf4j.LoggerFactory;
 public final class CryptoKeys {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
   private final Map<String, PublicKey> keys;
-  private Exception exception;
 
   public CryptoKeys(Map<String, byte[]> trustedKeys) throws Exception {
     HashMap<String, PublicKey> m = new HashMap<>();
@@ -68,7 +67,6 @@ public final class CryptoKeys {
    * Try with all signatures and return the name of the signature that matched
    */
   public String verify(String sig, ByteBuffer data) {
-    exception = null;
     for (Map.Entry<String, PublicKey> entry : keys.entrySet()) {
       boolean verified;
       try {
@@ -76,7 +74,6 @@ public final class CryptoKeys {
         log.info("verified {} ", verified);
         if (verified) return entry.getKey();
       } catch (Exception e) {
-        exception = e;
         log.info("NOT verified  ");
       }
 
diff --git a/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java b/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
index 4941bd1..56aadc6 100644
--- a/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
+++ b/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
@@ -32,16 +32,12 @@ import java.io.File;
 import java.io.IOException;
 
 public class AnalysisAfterCoreReloadTest extends SolrTestCaseJ4 {
-  
-  private static String tmpSolrHome;
-  int port = 0;
-  static final String context = "/solr";
 
   static final String collection = "collection1";
   
   @BeforeClass
   public static void beforeClass() throws Exception {
-    tmpSolrHome = createTempDir().toFile().getAbsolutePath();
+    String tmpSolrHome = createTempDir().toFile().getAbsolutePath();
     FileUtils.copyDirectory(new File(TEST_HOME()), new File(tmpSolrHome).getAbsoluteFile());
     initCore("solrconfig.xml", "schema.xml", new File(tmpSolrHome).getAbsolutePath());
   }
diff --git a/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java b/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java
index 795c3e8..d329268 100644
--- a/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java
+++ b/solr/core/src/test/org/apache/solr/SolrTestCaseJ4Test.java
@@ -26,13 +26,11 @@ import org.junit.Test;
 
 public class SolrTestCaseJ4Test extends SolrTestCaseJ4 {
 
-  private static String tmpSolrHome;
-
   @BeforeClass
   public static void beforeClass() throws Exception {
     // Create a temporary directory that holds a core NOT named "collection1". Use the smallest configuration sets
     // we can so we don't copy that much junk around.
-    tmpSolrHome = createTempDir().toFile().getAbsolutePath();
+    String tmpSolrHome = createTempDir().toFile().getAbsolutePath();
 
     File subHome = new File(new File(tmpSolrHome, "core0"), "conf");
     assertTrue("Failed to make subdirectory ", subHome.mkdirs());
diff --git a/solr/core/src/test/org/apache/solr/TestTolerantSearch.java b/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
index cb485d0..c397c50 100644
--- a/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
+++ b/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
@@ -43,8 +43,7 @@ public class TestTolerantSearch extends SolrJettyTestBase {
   private static SolrClient collection2;
   private static String shard1;
   private static String shard2;
-  private static File solrHome;
-  
+
   private static File createSolrHome() throws Exception {
     File workDir = createTempDir().toFile();
     setupJettyTestHome(workDir, "collection1");
@@ -56,7 +55,7 @@ public class TestTolerantSearch extends SolrJettyTestBase {
   
   @BeforeClass
   public static void createThings() throws Exception {
-    solrHome = createSolrHome();
+    File solrHome = createSolrHome();
     createJetty(solrHome.getAbsolutePath());
     String url = jetty.getBaseUrl().toString();
     collection1 = getHttpSolrClient(url + "/collection1");
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java b/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
index 5fd8e42..ebd340a 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
@@ -69,9 +69,9 @@ import org.slf4j.LoggerFactory;
 public class TestAuthenticationFramework extends LuceneTestCase {
   
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
-  private int NUM_SERVERS = 5;
-  private int NUM_SHARDS = 2;
-  private int REPLICATION_FACTOR = 2;
+  private static final int NUM_SERVERS = 5;
+  private static final int NUM_SHARDS = 2;
+  private static final int REPLICATION_FACTOR = 2;
   
   static String requestUsername = MockAuthenticationPlugin.expectedUsername;
   static String requestPassword = MockAuthenticationPlugin.expectedPassword;
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java b/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
index b13cb78..7ed69c4 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCloudPivotFacet.java
@@ -85,13 +85,13 @@ public class TestCloudPivotFacet extends AbstractFullDistribZkTestBase {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
   // param used by test purely for tracing & validation
-  private static String TRACE_MIN = "_test_min";
+  private static final String TRACE_MIN = "_test_min";
   // param used by test purely for tracing & validation
-  private static String TRACE_DISTRIB_MIN = "_test_distrib_min";
+  private static final String TRACE_DISTRIB_MIN = "_test_distrib_min";
   // param used by test purely for tracing & validation
-  private static String TRACE_MISS = "_test_miss";
+  private static final String TRACE_MISS = "_test_miss";
   // param used by test purely for tracing & validation
-  private static String TRACE_SORT = "_test_sort";
+  private static final String TRACE_SORT = "_test_sort";
 
   /** 
    * Controls the odds of any given doc having a value in any given field -- as this gets lower, 
diff --git a/solr/core/src/test/org/apache/solr/core/DummyValueSourceParser.java b/solr/core/src/test/org/apache/solr/core/DummyValueSourceParser.java
index 2d83438..2929676 100644
--- a/solr/core/src/test/org/apache/solr/core/DummyValueSourceParser.java
+++ b/solr/core/src/test/org/apache/solr/core/DummyValueSourceParser.java
@@ -29,11 +29,9 @@ import org.apache.solr.search.ValueSourceParser;
  *
  **/
 public class DummyValueSourceParser extends ValueSourceParser {
-  private NamedList args;
 
   @Override
   public void init(NamedList args) {
-    this.args = args;
   }
 
   @Override
diff --git a/solr/core/src/test/org/apache/solr/core/TestJmxMonitoredMap.java b/solr/core/src/test/org/apache/solr/core/TestJmxMonitoredMap.java
index aa107bc..25c08c1 100644
--- a/solr/core/src/test/org/apache/solr/core/TestJmxMonitoredMap.java
+++ b/solr/core/src/test/org/apache/solr/core/TestJmxMonitoredMap.java
@@ -53,8 +53,6 @@ public class TestJmxMonitoredMap extends LuceneTestCase {
 
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
-  private int port = 0;
-
   private JMXConnector connector;
 
   private MBeanServerConnection mbeanServer;
@@ -81,7 +79,7 @@ public class TestJmxMonitoredMap extends LuceneTestCase {
       };
       LocalhostRMIServerSocketFactory factory = new LocalhostRMIServerSocketFactory();
       LocateRegistry.createRegistry(0, null, factory);
-      port = factory.socket.getLocalPort();
+      int port = factory.socket.getLocalPort();
       log.info("Using port: " + port);
       String url = "service:jmx:rmi:///jndi/rmi://127.0.0.1:"+port+"/solrjmx";
       JmxConfiguration config = new JmxConfiguration(true, null, url, null);
diff --git a/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java b/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
index ec81c25..bfb7f22 100644
--- a/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
+++ b/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
@@ -61,17 +61,9 @@ import static org.apache.solr.handler.TestBlobHandler.getAsString;
 public class TestSolrConfigHandler extends RestTestBase {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
-  private static File tmpSolrHome;
-  private static File tmpConfDir;
-
-  private static final String collection = "collection1";
-  private static final String confDir = collection + "/conf";
-
-
   @Before
   public void before() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = createTempDir().toFile();
     FileUtils.copyDirectory(new File(TEST_HOME()), tmpSolrHome.getAbsoluteFile());
 
     final SortedMap<ServletHolder, String> extraServlets = new TreeMap<>();
diff --git a/solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java b/solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java
index a07d491..7056daa 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java
@@ -99,14 +99,13 @@ public class TestHdfsBackupRestoreCore extends SolrCloudTestCase {
 
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
   private static MiniDFSCluster dfsCluster;
-  private static String hdfsUri;
   private static FileSystem fs;
   private static long docsSeed; // see indexDocs()
 
   @BeforeClass
   public static void setupClass() throws Exception {
     dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());
-    hdfsUri = HdfsTestUtil.getURI(dfsCluster);
+    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);
     try {
       URI uri = new URI(hdfsUri);
       Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);
diff --git a/solr/core/src/test/org/apache/solr/handler/TestRestoreCore.java b/solr/core/src/test/org/apache/solr/handler/TestRestoreCore.java
index eaf773a..a49e4dc 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestRestoreCore.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestRestoreCore.java
@@ -54,7 +54,7 @@ public class TestRestoreCore extends SolrJettyTestBase {
   private static final String CONF_DIR = "solr" + File.separator + DEFAULT_TEST_CORENAME + File.separator + "conf"
       + File.separator;
 
-  private static String context = "/solr";
+  private static final String CONTEXT = "/solr";
   private static long docsSeed; // see indexDocs()
 
   private static JettySolrRunner createJetty(TestReplicationHandler.SolrInstance instance) throws Exception {
@@ -70,7 +70,7 @@ public class TestRestoreCore extends SolrJettyTestBase {
   private static SolrClient createNewSolrClient(int port) {
     try {
       // setup the client...
-      final String baseUrl = buildUrl(port, context);
+      final String baseUrl = buildUrl(port, CONTEXT);
       HttpSolrClient client = getHttpSolrClient(baseUrl);
       client.setConnectionTimeout(15000);
       client.setSoTimeout(60000);
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminCreateDiscoverTest.java b/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminCreateDiscoverTest.java
index 41807c7..1b6ad5e 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminCreateDiscoverTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminCreateDiscoverTest.java
@@ -40,9 +40,9 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
 
   private static CoreAdminHandler admin = null;
 
-  private static String coreNormal = "normal";
-  private static String coreSysProps = "sys_props";
-  private static String coreDuplicate = "duplicate";
+  private static final String CORE_NORMAL = "normal";
+  private static final String CORE_SYS_PROPS = "sys_props";
+  private static final String CORE_DUPLICATE = "duplicate";
 
   @BeforeClass
   public static void beforeClass() throws Exception {
@@ -78,11 +78,11 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
   @Test
   public void testCreateSavesSysProps() throws Exception {
 
-    setupCore(coreSysProps, true);
+    setupCore(CORE_SYS_PROPS, true);
 
     // create a new core (using CoreAdminHandler) w/ properties
     // Just to be sure it's NOT written to the core.properties file
-    File workDir = new File(solrHomeDirectory, coreSysProps);
+    File workDir = new File(solrHomeDirectory, CORE_SYS_PROPS);
     System.setProperty("INSTDIR_TEST", workDir.getAbsolutePath());
     System.setProperty("CONFIG_TEST", "solrconfig_ren.xml");
     System.setProperty("SCHEMA_TEST", "schema_ren.xml");
@@ -94,7 +94,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
     admin.handleRequestBody
         (req(CoreAdminParams.ACTION,
             CoreAdminParams.CoreAdminAction.CREATE.toString(),
-            CoreAdminParams.NAME, coreSysProps,
+            CoreAdminParams.NAME, CORE_SYS_PROPS,
             CoreAdminParams.INSTANCE_DIR, "${INSTDIR_TEST}",
             CoreAdminParams.CONFIG, "${CONFIG_TEST}",
             CoreAdminParams.SCHEMA, "${SCHEMA_TEST}",
@@ -105,7 +105,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
     // verify props are in persisted file
 
     Properties props = new Properties();
-    File propFile = new File(solrHomeDirectory, coreSysProps + "/" + CorePropertiesLocator.PROPERTIES_FILENAME);
+    File propFile = new File(solrHomeDirectory, CORE_SYS_PROPS + "/" + CorePropertiesLocator.PROPERTIES_FILENAME);
     FileInputStream is = new FileInputStream(propFile);
     try {
       props.load(new InputStreamReader(is, StandardCharsets.UTF_8));
@@ -114,7 +114,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
     }
 
     assertEquals("Unexpected value preserved in properties file " + propFile.getAbsolutePath(),
-        props.getProperty(CoreAdminParams.NAME), coreSysProps);
+        props.getProperty(CoreAdminParams.NAME), CORE_SYS_PROPS);
 
     assertEquals("Unexpected value preserved in properties file " + propFile.getAbsolutePath(),
         props.getProperty(CoreAdminParams.CONFIG), "${CONFIG_TEST}");
@@ -145,9 +145,9 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
   @Test
   public void testCannotCreateTwoCoresWithSameInstanceDir() throws Exception {
 
-    setupCore(coreDuplicate, true);
+    setupCore(CORE_DUPLICATE, true);
 
-    File workDir = new File(solrHomeDirectory, coreDuplicate);
+    File workDir = new File(solrHomeDirectory, CORE_DUPLICATE);
     File data = new File(workDir, "data");
 
     // Create one core
@@ -155,7 +155,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
     admin.handleRequestBody
         (req(CoreAdminParams.ACTION,
             CoreAdminParams.CoreAdminAction.CREATE.toString(),
-            CoreAdminParams.NAME, coreDuplicate,
+            CoreAdminParams.NAME, CORE_DUPLICATE,
             CoreAdminParams.INSTANCE_DIR, workDir.getAbsolutePath(),
             CoreAdminParams.CONFIG, "solrconfig_ren.xml",
             CoreAdminParams.SCHEMA, "schema_ren.xml",
@@ -223,18 +223,18 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
   @Test
   public void testCreateSavesRegProps() throws Exception {
 
-    setupCore(coreNormal, true);
+    setupCore(CORE_NORMAL, true);
 
     // create a new core (using CoreAdminHandler) w/ properties
     // Just to be sure it's NOT written to the core.properties file
-    File workDir = new File(solrHomeDirectory, coreNormal);
+    File workDir = new File(solrHomeDirectory, CORE_NORMAL);
     File data = new File(workDir, "data");
 
     SolrQueryResponse resp = new SolrQueryResponse();
     admin.handleRequestBody
         (req(CoreAdminParams.ACTION,
             CoreAdminParams.CoreAdminAction.CREATE.toString(),
-            CoreAdminParams.NAME, coreNormal,
+            CoreAdminParams.NAME, CORE_NORMAL,
             CoreAdminParams.INSTANCE_DIR, workDir.getAbsolutePath(),
             CoreAdminParams.CONFIG, "solrconfig_ren.xml",
             CoreAdminParams.SCHEMA, "schema_ren.xml",
@@ -244,7 +244,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
 
     // verify props are in persisted file
     Properties props = new Properties();
-    File propFile = new File(solrHomeDirectory, coreNormal + "/" + CorePropertiesLocator.PROPERTIES_FILENAME);
+    File propFile = new File(solrHomeDirectory, CORE_NORMAL + "/" + CorePropertiesLocator.PROPERTIES_FILENAME);
     FileInputStream is = new FileInputStream(propFile);
     try {
       props.load(new InputStreamReader(is, StandardCharsets.UTF_8));
@@ -253,7 +253,7 @@ public class CoreAdminCreateDiscoverTest extends SolrTestCaseJ4 {
     }
 
     assertEquals("Unexpected value preserved in properties file " + propFile.getAbsolutePath(),
-        props.getProperty(CoreAdminParams.NAME), coreNormal);
+        props.getProperty(CoreAdminParams.NAME), CORE_NORMAL);
 
     assertEquals("Unexpected value preserved in properties file " + propFile.getAbsolutePath(),
         props.getProperty(CoreAdminParams.CONFIG), "solrconfig_ren.xml");
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
index b447668..67fc149 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
@@ -51,8 +51,7 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
   private static SolrClient collection2;
   private static String shard1;
   private static String shard2;
-  private static File solrHome;
-  
+
   private static File createSolrHome() throws Exception {
     File workDir = createTempDir().toFile();
     setupJettyTestHome(workDir, "collection1");
@@ -63,7 +62,7 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
   
   @BeforeClass
   public static void createThings() throws Exception {
-    solrHome = createSolrHome();
+    File solrHome = createSolrHome();
     createJetty(solrHome.getAbsolutePath());
     String url = jetty.getBaseUrl().toString();
 
diff --git a/solr/core/src/test/org/apache/solr/metrics/SolrMetricsIntegrationTest.java b/solr/core/src/test/org/apache/solr/metrics/SolrMetricsIntegrationTest.java
index dfb5a0f..7aefc1c 100644
--- a/solr/core/src/test/org/apache/solr/metrics/SolrMetricsIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/metrics/SolrMetricsIntegrationTest.java
@@ -52,7 +52,6 @@ public class SolrMetricsIntegrationTest extends SolrTestCaseJ4 {
   private static final String[] RENAMED_REPORTERS = {REPORTER_NAMES[0], REPORTER_NAMES[1], UNIVERSAL, MULTIGROUP};
   private static final SolrInfoMBean.Category HANDLER_CATEGORY = SolrInfoMBean.Category.QUERY;
 
-  private CoreContainer cc;
   private SolrMetricManager metricManager;
   private String tag;
 
@@ -68,7 +67,7 @@ public class SolrMetricsIntegrationTest extends SolrTestCaseJ4 {
     System.setProperty("solr.test.sys.prop2", "proptwo");
     String solrXml = FileUtils.readFileToString(Paths.get(home.toString(), "solr-metricreporter.xml").toFile(), "UTF-8");
     NodeConfig cfg = SolrXmlConfig.fromString(new SolrResourceLoader(home), solrXml);
-    cc = createCoreContainer(cfg,
+    CoreContainer cc = createCoreContainer(cfg,
         new TestHarness.TestCoresLocator(DEFAULT_TEST_CORENAME, initCoreDataDir.getAbsolutePath(), "solrconfig.xml", "schema.xml"));
     h.coreName = DEFAULT_TEST_CORENAME;
     metricManager = cc.getMetricManager();
diff --git a/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterTest.java b/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterTest.java
index 82b9d58..971baf7 100644
--- a/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterTest.java
+++ b/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterTest.java
@@ -50,7 +50,6 @@ public class SolrJmxReporterTest extends SolrTestCaseJ4 {
 
   private SolrCoreMetricManager coreMetricManager;
   private SolrMetricManager metricManager;
-  private SolrJmxReporter reporter;
   private MBeanServer mBeanServer;
   private String reporterName;
 
@@ -74,7 +73,7 @@ public class SolrJmxReporterTest extends SolrTestCaseJ4 {
     assertNotNull("reporter " + taggedName + " not present among " + reporters, reporters.get(taggedName));
     assertTrue("wrong reporter class: " + reporters.get(taggedName), reporters.get(taggedName) instanceof SolrJmxReporter);
 
-    reporter = (SolrJmxReporter) reporters.get(taggedName);
+    SolrJmxReporter reporter = (SolrJmxReporter) reporters.get(taggedName);
     mBeanServer = reporter.getMBeanServer();
     assertNotNull("MBean server not found.", mBeanServer);
   }
diff --git a/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java b/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
index 16a8bf1..5eb8d35 100644
--- a/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
+++ b/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
@@ -49,12 +49,11 @@ import java.nio.charset.StandardCharsets;
  */
 @SuppressSSL     // does not yet work with ssl yet - uses raw java.net.URL API rather than HttpClient
 public class TestRemoteStreaming extends SolrJettyTestBase {
-  private static File solrHomeDirectory;
-  
+
   @BeforeClass
   public static void beforeTest() throws Exception {
     //this one has handleSelect=true which a test here needs
-    solrHomeDirectory = createTempDir(LuceneTestCase.getTestClass().getSimpleName()).toFile();
+    File solrHomeDirectory = createTempDir(LuceneTestCase.getTestClass().getSimpleName()).toFile();
     setupJettyTestHome(solrHomeDirectory, "collection1");
     createJetty(solrHomeDirectory.getAbsolutePath());
   }
diff --git a/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java b/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
index 9f37967..35b6bdb 100644
--- a/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
+++ b/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
@@ -55,11 +55,9 @@ public class TestBulkSchemaAPI extends RestTestBase {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
 
-  private static File tmpSolrHome;
-
   @Before
   public void before() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
+    File tmpSolrHome = createTempDir().toFile();
     FileUtils.copyDirectory(new File(TEST_HOME()), tmpSolrHome.getAbsoluteFile());
 
     System.setProperty("managed.schema.mutable", "true");
diff --git a/solr/core/src/test/org/apache/solr/rest/schema/analysis/TestManagedStopFilterFactory.java b/solr/core/src/test/org/apache/solr/rest/schema/analysis/TestManagedStopFilterFactory.java
index be8c394..f276565 100644
--- a/solr/core/src/test/org/apache/solr/rest/schema/analysis/TestManagedStopFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/rest/schema/analysis/TestManagedStopFilterFactory.java
@@ -35,16 +35,14 @@ import org.restlet.ext.servlet.ServerServlet;
  * PUT: add some words to the current list
  */
 public class TestManagedStopFilterFactory extends RestTestBase {
-  private static File tmpSolrHome;
-  private static File tmpConfDir;
 
   private static final String collection = "collection1";
   private static final String confDir = collection + "/conf";
 
   @Before
   public void before() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = createTempDir().toFile();
+    File tmpConfDir = new File(tmpSolrHome, confDir);
     FileUtils.copyDirectory(new File(TEST_HOME()), tmpSolrHome.getAbsoluteFile());
 
     final SortedMap<ServletHolder,String> extraServlets = new TreeMap<>();
diff --git a/solr/core/src/test/org/apache/solr/schema/ChangedSchemaMergeTest.java b/solr/core/src/test/org/apache/solr/schema/ChangedSchemaMergeTest.java
index d56382e..ae291aa 100644
--- a/solr/core/src/test/org/apache/solr/schema/ChangedSchemaMergeTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/ChangedSchemaMergeTest.java
@@ -32,7 +32,6 @@ import org.apache.solr.core.CoreContainer;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.request.LocalSolrQueryRequest;
 import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.schema.SimilarityFactory;
 import org.apache.solr.search.similarities.LMJelinekMercerSimilarityFactory;
 import org.apache.solr.search.similarities.SchemaSimilarityFactory;
 import org.apache.solr.update.AddUpdateCommand;
@@ -90,7 +89,7 @@ public class ChangedSchemaMergeTest extends SolrTestCaseJ4 {
     copyMinConf(changed, "name=changed");
     // Overlay with my local schema
     schemaFile = new File(new File(changed, "conf"), "schema.xml");
-    FileUtils.writeStringToFile(schemaFile, withWhich, StandardCharsets.UTF_8);
+    FileUtils.writeStringToFile(schemaFile, WITH_WHICH, StandardCharsets.UTF_8);
 
     String discoveryXml = "<solr></solr>";
     File solrXml = new File(solrHomeDirectory, "solr.xml");
@@ -133,7 +132,7 @@ public class ChangedSchemaMergeTest extends SolrTestCaseJ4 {
       changed.getUpdateHandler().commit(new CommitUpdateCommand(req, false));
 
       // write the new schema out and make it current
-      FileUtils.writeStringToFile(schemaFile, withoutWhich, StandardCharsets.UTF_8);
+      FileUtils.writeStringToFile(schemaFile, WITHOUT_WHICH, StandardCharsets.UTF_8);
 
       IndexSchema iSchema = IndexSchemaFactory.buildIndexSchema("schema.xml", changed.getSolrConfig());
       changed.setLatestSchema(iSchema);
@@ -163,7 +162,7 @@ public class ChangedSchemaMergeTest extends SolrTestCaseJ4 {
     assertNotNull(actual.getSimilarity());
   }
 
-  private static String withWhich = "<schema name=\"tiny\" version=\"1.1\">\n" +
+  private static final String WITH_WHICH = "<schema name=\"tiny\" version=\"1.1\">\n" +
       "    <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\"/>\n" +
       "    <field name=\"text\" type=\"text\" indexed=\"true\" stored=\"true\"/>\n" +
       "    <field name=\"which\" type=\"int\" indexed=\"true\" stored=\"true\"/>\n" +
@@ -181,7 +180,7 @@ public class ChangedSchemaMergeTest extends SolrTestCaseJ4 {
       "  <similarity class=\"${solr.test.simfac1}\"/> " +
       "</schema>";
 
-  private static String withoutWhich = "<schema name=\"tiny\" version=\"1.1\">\n" +
+  private static final String WITHOUT_WHICH = "<schema name=\"tiny\" version=\"1.1\">\n" +
       "    <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\"/>\n" +
       "    <field name=\"text\" type=\"text\" indexed=\"true\" stored=\"true\"/>\n" +
       "  <uniqueKey>id</uniqueKey>\n" +
diff --git a/solr/core/src/test/org/apache/solr/schema/TestUseDocValuesAsStored.java b/solr/core/src/test/org/apache/solr/schema/TestUseDocValuesAsStored.java
index 48a3f22..75e2aa3 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestUseDocValuesAsStored.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestUseDocValuesAsStored.java
@@ -52,9 +52,6 @@ public class TestUseDocValuesAsStored extends AbstractBadConfigTestBase {
 
   private int id = 1;
 
-  private static File tmpSolrHome;
-  private static File tmpConfDir;
-  
   private static final String collection = "collection1";
   private static final String confDir = collection + "/conf";
 
@@ -91,8 +88,8 @@ public class TestUseDocValuesAsStored extends AbstractBadConfigTestBase {
 
   @Before
   private void initManagedSchemaCore() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = createTempDir().toFile();
+    File tmpConfDir = new File(tmpSolrHome, confDir);
     File testHomeConfDir = new File(TEST_HOME(), confDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig-managed-schema.xml"), tmpConfDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig.snippet.randomindexconfig.xml"), tmpConfDir);
diff --git a/solr/core/src/test/org/apache/solr/search/TestAddFieldRealTimeGet.java b/solr/core/src/test/org/apache/solr/search/TestAddFieldRealTimeGet.java
index 34f7cde..bf9ebe8 100644
--- a/solr/core/src/test/org/apache/solr/search/TestAddFieldRealTimeGet.java
+++ b/solr/core/src/test/org/apache/solr/search/TestAddFieldRealTimeGet.java
@@ -26,17 +26,14 @@ import org.junit.Before;
 
 public class TestAddFieldRealTimeGet extends TestRTGBase {
 
-  private static File tmpSolrHome;
-  private static File tmpConfDir;
-
   private static final String collection = "collection1";
   private static final String confDir = collection + "/conf";
 
   @Before
   private void initManagedSchemaCore() throws Exception {
     final String tmpSolrHomePath = createTempDir().toFile().getAbsolutePath();
-    tmpSolrHome = new File(tmpSolrHomePath).getAbsoluteFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = new File(tmpSolrHomePath).getAbsoluteFile();
+    File tmpConfDir = new File(tmpSolrHome, confDir);
     File testHomeConfDir = new File(TEST_HOME(), confDir);
     final String configFileName = "solrconfig-managed-schema.xml";
     final String schemaFileName = "schema-id-and-version-fields-only.xml";
diff --git a/solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java b/solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java
index e6bb9a6..1d7c88b 100644
--- a/solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java
+++ b/solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java
@@ -72,14 +72,12 @@ public class TestRecoveryHdfs extends SolrTestCaseJ4 {
   
   private static MiniDFSCluster dfsCluster;
 
-  private static String hdfsUri;
-  
   private static FileSystem fs;
   
   @BeforeClass
   public static void beforeClass() throws Exception {
     dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());
-    hdfsUri = HdfsTestUtil.getURI(dfsCluster);
+    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);
     
     try {
       URI uri = new URI(hdfsUri);
diff --git a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
index 42b35bc..053e44e 100644
--- a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTest.java
@@ -41,11 +41,10 @@ import java.util.Date;
  * A test case for the several HTTP cache headers emitted by Solr
  */
 public class CacheHeaderTest extends CacheHeaderTestBase {
-  private static File solrHomeDirectory;
-    
+
   @BeforeClass
   public static void beforeTest() throws Exception {
-    solrHomeDirectory = createTempDir().toFile();
+    File solrHomeDirectory = createTempDir().toFile();
     setupJettyTestHome(solrHomeDirectory, "collection1");
     createJetty(solrHomeDirectory.getAbsolutePath());
   }
diff --git a/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java b/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
index 9c791c2..46b586a 100644
--- a/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
+++ b/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
@@ -76,8 +76,7 @@ public class AddBlockUpdateTest extends SolrTestCaseJ4 {
   
   private static ExecutorService exe;
   private static AtomicInteger counter = new AtomicInteger();
-  private static boolean cachedMode;
-  
+
   private static XMLInputFactory inputFactory;
   
   private RefCounted<SolrIndexSearcher> searcherRef;
@@ -87,8 +86,8 @@ public class AddBlockUpdateTest extends SolrTestCaseJ4 {
   public static void beforeClass() throws Exception {
     String oldCacheNamePropValue = System
         .getProperty("blockJoinParentFilterCache");
-    System.setProperty("blockJoinParentFilterCache", (cachedMode = random()
-        .nextBoolean()) ? "blockJoinParentFilterCache" : "don't cache");
+    System.setProperty("blockJoinParentFilterCache", random()
+        .nextBoolean() ? "blockJoinParentFilterCache" : "don't cache");
     if (oldCacheNamePropValue != null) {
       System.setProperty("blockJoinParentFilterCache", oldCacheNamePropValue);
     }
diff --git a/solr/core/src/test/org/apache/solr/update/DataDrivenBlockJoinTest.java b/solr/core/src/test/org/apache/solr/update/DataDrivenBlockJoinTest.java
index 5d643df..0fa36c2 100644
--- a/solr/core/src/test/org/apache/solr/update/DataDrivenBlockJoinTest.java
+++ b/solr/core/src/test/org/apache/solr/update/DataDrivenBlockJoinTest.java
@@ -24,8 +24,6 @@ import org.junit.Before;
 import org.junit.Test;
 
 public class DataDrivenBlockJoinTest extends SolrTestCaseJ4 {
-  private File tmpSolrHome;
-  private File tmpConfDir;
 
   private static final String collection = "collection1";
   private static final String confDir = collection + "/conf";
@@ -33,8 +31,8 @@ public class DataDrivenBlockJoinTest extends SolrTestCaseJ4 {
 
   @Before
   public void before() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = createTempDir().toFile();
+    File tmpConfDir = new File(tmpSolrHome, confDir);
     File testHomeConfDir = new File(TEST_HOME(), confDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, "solrconfig-schemaless.xml"), tmpConfDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, "schema-add-schema-fields-update-processor.xml"), tmpConfDir);
diff --git a/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java b/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
index 848d1bc..a02a01f 100644
--- a/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
+++ b/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
@@ -42,7 +42,7 @@ import static org.junit.internal.matchers.StringContains.containsString;
 
 @SuppressSSL(bugUrl = "https://issues.apache.org/jira/browse/SOLR-5776")
 public class PeerSyncTest extends BaseDistributedSearchTestCase {
-  private static int numVersions = 100;  // number of versions to use when syncing
+  private static final int NUM_VERSIONS = 100;  // number of versions to use when syncing
   private final String FROM_LEADER = DistribPhase.FROMLEADER.toString();
 
   private ModifiableSolrParams seenLeader = 
@@ -86,13 +86,13 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
 
     // this fails because client0 has no context (i.e. no updates of its own to judge if applying the updates
     // from client1 will bring it into sync with client1)
-    assertSync(client1, numVersions, false, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, false, shardsArr[0]);
 
     // bring client1 back into sync with client0 by adding the doc
     add(client1, seenLeader, sdoc("id","1","_version_",v));
 
     // both have the same version list, so sync should now return true
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     // TODO: test that updates weren't necessary
 
     client0.commit(); client1.commit(); queryAndCompare(params("q", "*:*"), client0, client1);
@@ -100,7 +100,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     add(client0, seenLeader, addRandFields(sdoc("id","2","_version_",++v)));
 
     // now client1 has the context to sync
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     client0.commit(); client1.commit(); queryAndCompare(params("q", "*:*"), client0, client1);
 
@@ -113,26 +113,26 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     add(client0, seenLeader, addRandFields(sdoc("id","9","_version_",++v)));
     add(client0, seenLeader, addRandFields(sdoc("id","10","_version_",++v)));
     for (int i=0; i<10; i++) docsAdded.add(i+1);
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     validateDocs(docsAdded, client0, client1);
 
-    int toAdd = (int)(numVersions *.95);
+    int toAdd = (int)(NUM_VERSIONS *.95);
     for (int i=0; i<toAdd; i++) {
       add(client0, seenLeader, sdoc("id",Integer.toString(i+11),"_version_",v+i+1));
       docsAdded.add(i+11);
     }
 
     // sync should fail since there's not enough overlap to give us confidence
-    assertSync(client1, numVersions, false, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, false, shardsArr[0]);
 
     // add some of the docs that were missing... just enough to give enough overlap
-    int toAdd2 = (int)(numVersions * .25);
+    int toAdd2 = (int)(NUM_VERSIONS * .25);
     for (int i=0; i<toAdd2; i++) {
       add(client1, seenLeader, sdoc("id",Integer.toString(i+11),"_version_",v+i+1));
     }
 
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     validateDocs(docsAdded, client0, client1);
 
     // test delete and deleteByQuery
@@ -145,7 +145,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     del(client0, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_",Long.toString(-++v)), "1000");
     docsAdded.add(1002); // 1002 added
 
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     validateDocs(docsAdded, client0, client1);
 
     // test that delete by query is returned even if not requested, and that it doesn't delete newer stuff than it should
@@ -167,7 +167,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     add(client, seenLeader, sdoc("id","2002","_version_",++v));
     del(client, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_",Long.toString(-++v)), "2000");
 
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     validateDocs(docsAdded, client0, client1);
 
@@ -194,14 +194,14 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     docsAdded.add(3001); // 3001 added
     docsAdded.add(3002); // 3002 added
     
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     validateDocs(docsAdded, client0, client1);
 
     // now lets check fingerprinting causes appropriate fails
     v = 4000;
     add(client0, seenLeader, sdoc("id",Integer.toString((int)v),"_version_",v));
     docsAdded.add(4000);
-    toAdd = numVersions+10;
+    toAdd = NUM_VERSIONS +10;
     for (int i=0; i<toAdd; i++) {
       add(client0, seenLeader, sdoc("id",Integer.toString((int)v+i+1),"_version_",v+i+1));
       add(client1, seenLeader, sdoc("id",Integer.toString((int)v+i+1),"_version_",v+i+1));
@@ -209,32 +209,32 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     }
 
     // client0 now has an additional add beyond our window and the fingerprint should cause this to fail
-    assertSync(client1, numVersions, false, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, false, shardsArr[0]);
 
     // if we turn of fingerprinting, it should succeed
     System.setProperty("solr.disableFingerprint", "true");
     try {
-      assertSync(client1, numVersions, true, shardsArr[0]);
+      assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     } finally {
       System.clearProperty("solr.disableFingerprint");
     }
 
     // lets add the missing document and verify that order doesn't matter
     add(client1, seenLeader, sdoc("id",Integer.toString((int)v),"_version_",v));
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     // lets do some overwrites to ensure that repeated updates and maxDoc don't matter
     for (int i=0; i<10; i++) {
       add(client0, seenLeader, sdoc("id", Integer.toString((int) v + i + 1), "_version_", v + i + 1));
     }
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     
     validateDocs(docsAdded, client0, client1);
 
     // lets add some in-place updates
     add(client0, seenLeader, sdoc("id", "5000", "val_i_dvo", 0, "title", "mytitle", "_version_", 5000)); // full update
     docsAdded.add(5000);
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     // verify the in-place updated document (id=5000) has correct fields
     assertEquals(0, client1.getById("5000").get("val_i_dvo"));
     assertEquals(client0.getById("5000")+" and "+client1.getById("5000"), 
@@ -243,7 +243,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     ModifiableSolrParams inPlaceParams = new ModifiableSolrParams(seenLeader);
     inPlaceParams.set(DistributedUpdateProcessor.DISTRIB_INPLACE_PREVVERSION, "5000");
     add(client0, inPlaceParams, sdoc("id", "5000", "val_i_dvo", 1, "_version_", 5001)); // in-place update
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     // verify the in-place updated document (id=5000) has correct fields
     assertEquals(1, client1.getById("5000").get("val_i_dvo"));
     assertEquals(client0.getById("5000")+" and "+client1.getById("5000"), 
@@ -257,7 +257,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     
     inPlaceParams.set(DistributedUpdateProcessor.DISTRIB_INPLACE_PREVVERSION, "5001");
     add(client0, inPlaceParams, sdoc("id", 5000, "val_i_dvo", 2, "_version_", 5004)); // in-place update
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     // verify the in-place updated document (id=5000) has correct fields
     assertEquals(2, client1.getById("5000").get("val_i_dvo"));
     assertEquals(client0.getById("5000")+" and "+client1.getById("5000"), 
@@ -265,16 +265,16 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
 
     // a DBQ with value
     delQ(client0, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_","5005"),  "val_i_dvo:1"); // current val is 2, so this should not delete anything
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
 
 
     add(client0, seenLeader, sdoc("id", "5000", "val_i_dvo", 0, "title", "mytitle", "_version_", 5000)); // full update
     docsAdded.add(5000);
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     inPlaceParams.set(DistributedUpdateProcessor.DISTRIB_INPLACE_PREVVERSION, "5004");
     add(client0, inPlaceParams, sdoc("id", 5000, "val_i_dvo", 3, "_version_", 5006));
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     // verify the in-place updated document (id=5000) has correct fields
     assertEquals(3, client1.getById("5000").get("val_i_dvo"));
@@ -285,7 +285,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
 
     del(client0, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_","5007"),  5000);
     docsAdded.remove(5000);
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
 
     validateDocs(docsAdded, client0, client1);
 
@@ -293,7 +293,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     // if doc with id=6000 is deleted, further in-place-updates should fail
     add(client0, seenLeader, sdoc("id", "6000", "val_i_dvo", 6, "title", "mytitle", "_version_", 6000)); // full update
     delQ(client0, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_","6004"),  "val_i_dvo:6"); // current val is 6000, this will delete id=6000
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     SolrException ex = expectThrows(SolrException.class, () -> {
       inPlaceParams.set(DistributedUpdateProcessor.DISTRIB_INPLACE_PREVVERSION, "6000");
       add(client0, inPlaceParams, sdoc("id", 6000, "val_i_dvo", 6003, "_version_", 5007));
@@ -311,7 +311,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     docsAdded.add(7001001);
     docsAdded.add(7001002);
     delQ(client0, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_","7000"),  "id:*"); // reordered delete
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     validateDocs(docsAdded, client0, client1);
 
     // Reordered DBQ should not affect update
@@ -321,7 +321,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     docsAdded.add(8000);
     docsAdded.add(8000001);
     docsAdded.add(8000002);
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     validateDocs(docsAdded, client0, client1);
 
   }
diff --git a/solr/core/src/test/org/apache/solr/update/PeerSyncWithIndexFingerprintCachingTest.java b/solr/core/src/test/org/apache/solr/update/PeerSyncWithIndexFingerprintCachingTest.java
index 9617ff2..a7716cf 100644
--- a/solr/core/src/test/org/apache/solr/update/PeerSyncWithIndexFingerprintCachingTest.java
+++ b/solr/core/src/test/org/apache/solr/update/PeerSyncWithIndexFingerprintCachingTest.java
@@ -43,7 +43,7 @@ import org.junit.Test;
  */
 @SuppressSSL(bugUrl = "https://issues.apache.org/jira/browse/SOLR-5776")
 public class PeerSyncWithIndexFingerprintCachingTest extends BaseDistributedSearchTestCase {
-  private static int numVersions = 100;  // number of versions to use when syncing
+  private static final int NUM_VERSIONS = 100;  // number of versions to use when syncing
   private final String FROM_LEADER = DistribPhase.FROMLEADER.toString();
 
   private ModifiableSolrParams seenLeader = 
@@ -87,7 +87,7 @@ public class PeerSyncWithIndexFingerprintCachingTest extends BaseDistributedSear
     Assert.assertTrue(IndexFingerprint.compare(before, after) != 0);
     
     // replica which missed the delete should be able to sync
-    assertSync(client1, numVersions, true, shardsArr[0]);
+    assertSync(client1, NUM_VERSIONS, true, shardsArr[0]);
     client0.commit(); client1.commit();  
 
     queryAndCompare(params("q", "*:*", "sort","_version_ desc"), client0, client1);
diff --git a/solr/core/src/test/org/apache/solr/update/TestHdfsUpdateLog.java b/solr/core/src/test/org/apache/solr/update/TestHdfsUpdateLog.java
index 646ed51..c71c3eb 100644
--- a/solr/core/src/test/org/apache/solr/update/TestHdfsUpdateLog.java
+++ b/solr/core/src/test/org/apache/solr/update/TestHdfsUpdateLog.java
@@ -43,14 +43,12 @@ public class TestHdfsUpdateLog extends SolrTestCaseJ4 {
   
   private static MiniDFSCluster dfsCluster;
 
-  private static String hdfsUri;
-  
   private static FileSystem fs;
   
   @BeforeClass
   public static void beforeClass() throws Exception {
     dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());
-    hdfsUri = HdfsTestUtil.getURI(dfsCluster);
+    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);
     
     try {
       URI uri = new URI(hdfsUri);
diff --git a/solr/core/src/test/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactoryTest.java b/solr/core/src/test/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactoryTest.java
index 8b59d0e..4df40bd 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactoryTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactoryTest.java
@@ -37,16 +37,13 @@ public class AddSchemaFieldsUpdateProcessorFactoryTest extends UpdateProcessorTe
   private static final String SOLRCONFIG_XML = "solrconfig-add-schema-fields-update-processor-chains.xml";
   private static final String SCHEMA_XML     = "schema-add-schema-fields-update-processor.xml";
 
-  private static File tmpSolrHome;
-  private static File tmpConfDir;
-
   private static final String collection = "collection1";
   private static final String confDir = collection + "/conf";
 
   @Before
   private void initManagedSchemaCore() throws Exception {
-    tmpSolrHome = createTempDir().toFile();
-    tmpConfDir = new File(tmpSolrHome, confDir);
+    File tmpSolrHome = createTempDir().toFile();
+    File tmpConfDir = new File(tmpSolrHome, confDir);
     File testHomeConfDir = new File(TEST_HOME(), confDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, SOLRCONFIG_XML), tmpConfDir);
     FileUtils.copyFileToDirectory(new File(testHomeConfDir, SCHEMA_XML), tmpConfDir);
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/io/graph/TraversalIterator.java b/solr/solrj/src/java/org/apache/solr/client/solrj/io/graph/TraversalIterator.java
index 7cfe375..b6f3373 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/io/graph/TraversalIterator.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/io/graph/TraversalIterator.java
@@ -28,10 +28,6 @@ import org.apache.solr.client.solrj.io.graph.Traversal.Scatter;
 
 class TraversalIterator implements Iterator {
 
-  private List<Map<String,Node>> graph;
-  private List<String> collections;
-  private List<String> fields;
-
   private Iterator<Iterator<Node>> graphIterator;
   private Iterator<Node> levelIterator;
 
@@ -45,9 +41,9 @@ class TraversalIterator implements Iterator {
 
   public TraversalIterator(Traversal traversal, Set<Scatter> scatter) {
     this.traversal = traversal;
-    graph = traversal.getGraph();
-    collections = traversal.getCollections();
-    fields = traversal.getFields();
+    List<Map<String, Node>> graph = traversal.getGraph();
+    List<String> collections = traversal.getCollections();
+    List<String> fields = traversal.getFields();
 
     List<String> outCollections = new ArrayList();
     List<String> outFields = new ArrayList();
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/io/ops/GroupOperation.java b/solr/solrj/src/java/org/apache/solr/client/solrj/io/ops/GroupOperation.java
index a2bd8c9..ac7c465 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/io/ops/GroupOperation.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/io/ops/GroupOperation.java
@@ -47,7 +47,6 @@ public class GroupOperation implements ReduceOperation {
   private UUID operationNodeId = UUID.randomUUID();
   
   private PriorityQueue<Tuple> priorityQueue;
-  private Comparator comp;
   private StreamComparator streamComparator;
   private int size;
 
@@ -79,8 +78,8 @@ public class GroupOperation implements ReduceOperation {
   private void init(StreamComparator streamComparator, int size) {
     this.size = size;
     this.streamComparator = streamComparator;
-    this.comp = new ReverseComp(streamComparator);
-    this.priorityQueue = new PriorityQueue(size, this.comp);
+    Comparator comp = new ReverseComp(streamComparator);
+    this.priorityQueue = new PriorityQueue(size, comp);
   }
 
   public StreamExpressionParameter toExpression(StreamFactory factory) throws IOException {
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/io/sql/ResultSetMetaDataImpl.java b/solr/solrj/src/java/org/apache/solr/client/solrj/io/sql/ResultSetMetaDataImpl.java
index c32ed43..bb7b515 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/io/sql/ResultSetMetaDataImpl.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/io/sql/ResultSetMetaDataImpl.java
@@ -25,14 +25,12 @@ import java.util.Map;
 import org.apache.solr.client.solrj.io.Tuple;
 
 class ResultSetMetaDataImpl implements ResultSetMetaData {
-  private final ResultSetImpl resultSet;
   private final Tuple metadataTuple;
   private final Tuple firstTuple;
 
   ResultSetMetaDataImpl(ResultSetImpl resultSet) {
-    this.resultSet = resultSet;
-    this.metadataTuple = this.resultSet.getMetadataTuple();
-    this.firstTuple = this.resultSet.getFirstTuple();
+    this.metadataTuple = resultSet.getMetadataTuple();
+    this.firstTuple = resultSet.getFirstTuple();
   }
 
   private Class getColumnClass(int column) throws SQLException {
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
index f87f149..973c2cf 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
@@ -56,7 +56,7 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
 
   protected final CollectionAction action;
 
-  private static String PROPERTY_PREFIX = "property.";
+  private static final String PROPERTY_PREFIX = "property.";
 
   public CollectionAdminRequest(CollectionAction action) {
     this("/admin/collections", action);
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java b/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
index 4e78005..2329a73 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
@@ -44,21 +44,11 @@ public class QueryResponse extends SolrResponseBase
   private SolrDocumentList _results = null;
   private NamedList<ArrayList> _sortvalues = null;
   private NamedList<Object> _facetInfo = null;
-  private NamedList<Object> _debugInfo = null;
-  private NamedList<Object> _highlightingInfo = null;
-  private NamedList<Object> _spellInfo = null;
-  private List<NamedList<Object>> _clusterInfo = null;
-  private Map<String,NamedList<Object>> _suggestInfo = null;
-  private NamedList<Object> _statsInfo = null;
-  private NamedList<NamedList<Object>> _termsInfo = null;
   private NamedList<SolrDocumentList> _moreLikeThisInfo = null;
   private String _cursorMarkNext = null;
 
-  // Grouping response
-  private NamedList<Object> _groupedInfo = null;
   private GroupResponse _groupResponse = null;
 
-  private NamedList<Object> _expandedInfo = null;
   private Map<String, SolrDocumentList> _expandedResults = null;
 
   // Facet stuff
@@ -134,40 +124,40 @@ public class QueryResponse extends SolrResponseBase
         // in case it hasn't been populated yet.
       }
       else if( "debug".equals( n ) ) {
-        _debugInfo = (NamedList<Object>) res.getVal( i );
-        extractDebugInfo( _debugInfo );
+        NamedList<Object> _debugInfo = (NamedList<Object>) res.getVal(i);
+        extractDebugInfo(_debugInfo);
       }
       else if( "grouped".equals( n ) ) {
-        _groupedInfo = (NamedList<Object>) res.getVal( i );
-        extractGroupedInfo( _groupedInfo );
+        NamedList<Object> _groupedInfo = (NamedList<Object>) res.getVal(i);
+        extractGroupedInfo(_groupedInfo);
       }
       else if("expanded".equals(n)) {
         NamedList map = (NamedList) res.getVal(i);
         _expandedResults = map.asMap(1);
       }
       else if( "highlighting".equals( n ) ) {
-        _highlightingInfo = (NamedList<Object>) res.getVal( i );
-        extractHighlightingInfo( _highlightingInfo );
+        NamedList<Object> _highlightingInfo = (NamedList<Object>) res.getVal(i);
+        extractHighlightingInfo(_highlightingInfo);
       }
       else if ( "spellcheck".equals( n ) )  {
-        _spellInfo = (NamedList<Object>) res.getVal( i );
-        extractSpellCheckInfo( _spellInfo );
+        NamedList<Object> _spellInfo = (NamedList<Object>) res.getVal(i);
+        extractSpellCheckInfo(_spellInfo);
       }
       else if ("clusters".equals(n)) {
-        _clusterInfo = (ArrayList<NamedList<Object>>) res.getVal(i);
+        List<NamedList<Object>> _clusterInfo = (ArrayList<NamedList<Object>>) res.getVal(i);
         extractClusteringInfo(_clusterInfo);
       }
       else if ( "suggest".equals( n ) )  {
-        _suggestInfo = (Map<String,NamedList<Object>>) res.getVal( i );
+        Map<String, NamedList<Object>> _suggestInfo = (Map<String, NamedList<Object>>) res.getVal(i);
         extractSuggesterInfo(_suggestInfo);
       }
       else if ( "stats".equals( n ) )  {
-        _statsInfo = (NamedList<Object>) res.getVal( i );
-        extractStatsInfo( _statsInfo );
+        NamedList<Object> _statsInfo = (NamedList<Object>) res.getVal(i);
+        extractStatsInfo(_statsInfo);
       }
       else if ( "terms".equals( n ) ) {
-        _termsInfo = (NamedList<NamedList<Object>>) res.getVal( i );
-        extractTermsInfo( _termsInfo );
+        NamedList<NamedList<Object>> _termsInfo = (NamedList<NamedList<Object>>) res.getVal(i);
+        extractTermsInfo(_termsInfo);
       }
       else if ( "moreLikeThis".equals( n ) ) {
         _moreLikeThisInfo = (NamedList<SolrDocumentList>) res.getVal( i );
diff --git a/solr/solrj/src/java/org/apache/solr/common/cloud/CompositeIdRouter.java b/solr/solrj/src/java/org/apache/solr/common/cloud/CompositeIdRouter.java
index a1cd02c..4b3b6e4 100644
--- a/solr/solrj/src/java/org/apache/solr/common/cloud/CompositeIdRouter.java
+++ b/solr/solrj/src/java/org/apache/solr/common/cloud/CompositeIdRouter.java
@@ -39,7 +39,7 @@ public class CompositeIdRouter extends HashBasedRouter {
 
   // separator used to optionally specify number of bits to allocate toward first part.
   public static final int bitsSeparator = '/';
-  private int bits = 16;
+  private static final int BITS = 16;
 
   @Override
   public int sliceHash(String id, SolrInputDocument doc, SolrParams params, DocCollection collection) {
@@ -145,7 +145,7 @@ public class CompositeIdRouter extends HashBasedRouter {
     // With default bits==16, one would need to create more than 4000 shards before this
     // becomes false by default.
     int mask = 0x0000ffff;
-    boolean round = rangeStep >= (1 << bits) * 16;
+    boolean round = rangeStep >= (1 << BITS) * 16;
 
     while (end < max) {
       targetEnd = targetStart + rangeStep;
@@ -153,7 +153,7 @@ public class CompositeIdRouter extends HashBasedRouter {
 
       if (round && ((end & mask) != mask)) {
         // round up or down?
-        int increment = 1 << bits;  // 0x00010000
+        int increment = 1 << BITS;  // 0x00010000
         long roundDown = (end | mask) - increment;
         long roundUp = (end | mask) + increment;
         if (end - roundDown < roundUp - end && roundDown > start) {
diff --git a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkCmdExecutor.java b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkCmdExecutor.java
index c27f767..9cf662c 100644
--- a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkCmdExecutor.java
+++ b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkCmdExecutor.java
@@ -24,8 +24,7 @@ import org.apache.zookeeper.KeeperException.NodeExistsException;
 public class ZkCmdExecutor {
   private long retryDelay = 1500L; // 1 second would match timeout, so 500 ms over for padding
   private int retryCount;
-  private double timeouts;
-  
+
   /**
    * TODO: At this point, this should probably take a SolrZkClient in
    * its constructor.
@@ -35,7 +34,7 @@ public class ZkCmdExecutor {
    *          with this class.
    */
   public ZkCmdExecutor(int timeoutms) {
-    timeouts = timeoutms / 1000.0;
+    double timeouts = timeoutms / 1000.0;
     this.retryCount = Math.round(0.5f * ((float)Math.sqrt(8.0f * timeouts + 1.0f) - 1.0f)) + 1;
   }
   
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
index 9508a27..6ce4021 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
@@ -44,7 +44,6 @@ public abstract class MergeIndexesExampleTestBase extends SolrExampleTestBase {
 
   protected CoreContainer cores;
   private String saveProp;
-  private File dataDir2;
 
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
@@ -73,9 +72,9 @@ public abstract class MergeIndexesExampleTestBase extends SolrExampleTestBase {
     // setup datadirs
     System.setProperty( "solr.core0.data.dir", dataDir1.getCanonicalPath() );
 
-    dataDir2 = createTempDir().toFile();
+    File dataDir2 = createTempDir().toFile();
 
-    System.setProperty( "solr.core1.data.dir", this.dataDir2.getCanonicalPath() );
+    System.setProperty( "solr.core1.data.dir", dataDir2.getCanonicalPath() );
 
     setupCoreContainer();
     log.info("CORES=" + cores + " : " + cores.getCoreNames());
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
index d260b02..7e4825a 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
@@ -79,7 +79,7 @@ public class CloudSolrClientCacheTest extends SolrTestCaseJ4 {
 
         .build()) {
       livenodes.addAll(ImmutableSet.of("192.168.1.108:7574_solr", "192.168.1.108:8983_solr"));
-      ClusterState cs = ClusterState.load(1, coll1State.getBytes(UTF_8),
+      ClusterState cs = ClusterState.load(1, COLL_1_STATE.getBytes(UTF_8),
           Collections.emptySet(), "/collections/gettingstarted/state.json");
       refs.put(collName, new Ref(collName));
       colls.put(collName, cs.getCollectionOrNull(collName));
@@ -157,7 +157,7 @@ public class CloudSolrClientCacheTest extends SolrTestCaseJ4 {
   }
 
 
-  private String coll1State = "{'gettingstarted':{\n" +
+  private static final String COLL_1_STATE = "{'gettingstarted':{\n" +
       "    'replicationFactor':'2',\n" +
       "    'router':{'name':'compositeId'},\n" +
       "    'maxShardsPerNode':'2',\n" +
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/SelectWithEvaluatorsTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/SelectWithEvaluatorsTest.java
index b91df8d..44c71b1 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/SelectWithEvaluatorsTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/SelectWithEvaluatorsTest.java
@@ -51,8 +51,6 @@ public class SelectWithEvaluatorsTest extends SolrCloudTestCase {
   private static final int TIMEOUT = DEFAULT_TIMEOUT;
   private static final String id = "id";
 
-  private static boolean useAlias;
-
   @BeforeClass
   public static void setupCluster() throws Exception {
     configureCluster(4)
@@ -61,7 +59,7 @@ public class SelectWithEvaluatorsTest extends SolrCloudTestCase {
         .configure();
 
     String collection;
-    useAlias = random().nextBoolean();
+    boolean useAlias = random().nextBoolean();
     if (useAlias) {
       collection = COLLECTIONORALIAS + "_collection";
     } else {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
index 2f2273e..84084d1 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
@@ -80,13 +80,12 @@ private static final StreamFactory streamFactory = new StreamFactory()
 
 private static String zkHost;
 
-private static int numShards;
 private static int numWorkers;
 private static boolean useAlias;
 
 @BeforeClass
 public static void configureCluster() throws Exception {
-  numShards = random().nextInt(2) + 1;  //1 - 3
+  int numShards = random().nextInt(2) + 1;  //1 - 3
   numWorkers = numShards > 2 ? random().nextInt(numShards - 1) + 1 : numShards;
   configureCluster(numShards)
       .addConfig("conf", getFile("solrj").toPath().resolve("solr").resolve("configsets").resolve("streaming").resolve("conf"))
