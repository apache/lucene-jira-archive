diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index 0bfa1e1..633cb93 100644
--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -2079,4 +2079,89 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
 
     dir.close();
   }
+
+  
+  public void testRandomCorruptionIsTragic() throws Exception {
+    // we're going to loop (effectively) forever
+    // introducing a small amount of corruption then attempting an index update
+    // once we encounter an exception from the index update, we will assert that the IW
+    // has recorded a traggic exception
+    
+    final MockDirectoryWrapper dir = newMockDirectory();
+    dir.setCheckIndexOnClose(false); // we are corrupting it!
+    
+    final IndexWriterConfig iwc = newIndexWriterConfig();
+    final MergeScheduler ms = iwc.getMergeScheduler();
+    if (ms instanceof ConcurrentMergeScheduler) {
+      ((ConcurrentMergeScheduler) ms).setSuppressExceptions();
+    }
+    final IndexWriter w = new IndexWriter(dir, iwc);
+    
+    int totalCorruption = 0;
+    int numIndexOpsSucceded = 0;
+    boolean gotExpectedFailure = false;
+    try {
+      // "while (true)" safety valve, prevent infinite loop if IW is so broken it never throws exceptions
+      // nocommit: better approach to this?
+      // nocommit: test could get very 'lucky' (need MockDirectoryWrapper.alwaysCorrupt to be publc)
+      while (totalCorruption < 999999) {
+
+        // do some random corruption
+        for (String file : dir.listAll()) {
+          if (random().nextBoolean() ||
+              // nocommit: not sure why Solr's LeaderTragicEventTest protected these files from corruption?
+              // nocommit: we should allow them to be corrupted in this test?
+              // nocommit: perhaps just at a lower probability?
+              file.contains("segments_") || file.endsWith("si") || file.endsWith("fnm")) {
+            continue;
+          } else {
+            try {
+              dir.corruptFiles(Collections.singleton(file));
+              totalCorruption++;
+            } catch (RuntimeException | FileNotFoundException | NoSuchFileException e) {
+              // merges can lead to this exception
+            }
+          }
+        }
+
+        // do some index updates
+        try {
+          // nocommit: randomize the type of updates we do every loop...
+          // nocommit: add, updateDocument, deleteDocument, deleteByQuery, commit, etc...
+          Document doc = new Document();
+          doc.add(newStringField("field", "string", Field.Store.NO));
+          w.addDocument(doc);
+          numIndexOpsSucceded++;
+          
+          w.commit();
+          numIndexOpsSucceded++;
+          
+        } catch (Throwable t) {
+          // NOTE: we don't use expectThrows because there's no garuntee that
+          // the update we attempt will cause an exception, but if it *does* cause an exception,
+          // then it must have been tragic.
+          //
+          // (nothing we're doing that might cause an exception should ever be "non-tragic")
+          
+          assertNotNull("index update encountered throwable, but no tragic event recorded: "
+                        + t.toString(),
+                        w.getTragicException());
+          assertFalse(w.isOpen());
+          gotExpectedFailure = true;
+          break;
+        }
+      }
+      assertTrue("Safety Valve: " + totalCorruption + " files corrupted and " + numIndexOpsSucceded +
+                 " index ops succeded w/o any IndexWriter exceptions?",
+                 gotExpectedFailure);
+    } finally {
+      if (ms instanceof ConcurrentMergeScheduler) {
+        // Sneaky: CMS's merge thread will be concurrently rolling back IW due
+        // to the tragedy, with this main thread, so we have to wait here
+        // to ensure the rollback has finished, else MDW still sees open files:
+        ((ConcurrentMergeScheduler) ms).sync();
+      }
+      dir.close();
+    }
+  }
 }
