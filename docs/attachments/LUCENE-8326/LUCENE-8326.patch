diff --git a/lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java b/lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java
index 1bc53b0202..7035de55c5 100644
--- a/lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java
+++ b/lucene/classification/src/java/org/apache/lucene/classification/KNearestNeighborClassifier.java
@@ -31,6 +31,7 @@ import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
+import org.apache.lucene.queries.mlt.MoreLikeThisParameters;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.IndexSearcher;
@@ -90,8 +91,8 @@ public class KNearestNeighborClassifier implements Classifier<BytesRef> {
    * @param query          a {@link Query} to eventually filter the docs used for training the classifier, or {@code null}
    *                       if all the indexed docs should be used
    * @param k              the no. of docs to select in the MLT results to find the nearest neighbor
-   * @param minDocsFreq    {@link MoreLikeThis#minDocFreq} parameter
-   * @param minTermFreq    {@link MoreLikeThis#minTermFreq} parameter
+   * @param minDocsFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThisParameters#minDocFreq} parameter
+   * @param minTermFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThisParameters#minTermFreq} parameter
    * @param classFieldName the name of the field used as the output for the classifier
    * @param textFieldNames the name of the fields used as the inputs for the classifier, they can contain boosting indication e.g. title^10
    */
@@ -158,19 +159,11 @@ public class KNearestNeighborClassifier implements Classifier<BytesRef> {
 
   private TopDocs knnSearch(String text) throws IOException {
     BooleanQuery.Builder mltQuery = new BooleanQuery.Builder();
+    MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
+    boostConfiguration.setBoost(true); //terms boost actually helps in MLT queries
     for (String fieldName : textFieldNames) {
-      String boost = null;
-      mlt.setBoost(true); //terms boost actually helps in MLT queries
-      if (fieldName.contains("^")) {
-        String[] field2boost = fieldName.split("\\^");
-        fieldName = field2boost[0];
-        boost = field2boost[1];
-      }
-      if (boost != null) {
-        mlt.setBoostFactor(Float.parseFloat(boost));//if we have a field boost, we add it
-      }
+      boostConfiguration.addFieldWithBoost(fieldName);
       mltQuery.add(new BooleanClause(mlt.like(fieldName, new StringReader(text)), BooleanClause.Occur.SHOULD));
-      mlt.setBoostFactor(1);// restore neutral boost for next field
     }
     Query classFieldQuery = new WildcardQuery(new Term(classFieldName, "*"));
     mltQuery.add(new BooleanClause(classFieldQuery, BooleanClause.Occur.MUST));
diff --git a/lucene/classification/src/java/org/apache/lucene/classification/document/KNearestNeighborDocumentClassifier.java b/lucene/classification/src/java/org/apache/lucene/classification/document/KNearestNeighborDocumentClassifier.java
index 39684ee25e..0e30c8ebc5 100644
--- a/lucene/classification/src/java/org/apache/lucene/classification/document/KNearestNeighborDocumentClassifier.java
+++ b/lucene/classification/src/java/org/apache/lucene/classification/document/KNearestNeighborDocumentClassifier.java
@@ -29,6 +29,7 @@ import org.apache.lucene.classification.KNearestNeighborClassifier;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.mlt.MoreLikeThisParameters;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.IndexSearcher;
@@ -60,8 +61,8 @@ public class KNearestNeighborDocumentClassifier extends KNearestNeighborClassifi
    * @param query          a {@link org.apache.lucene.search.Query} to eventually filter the docs used for training the classifier, or {@code null}
    *                       if all the indexed docs should be used
    * @param k              the no. of docs to select in the MLT results to find the nearest neighbor
-   * @param minDocsFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThis#minDocFreq} parameter
-   * @param minTermFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThis#minTermFreq} parameter
+   * @param minDocsFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThisParameters#minDocFreq} parameter
+   * @param minTermFreq    {@link org.apache.lucene.queries.mlt.MoreLikeThisParameters#minTermFreq} parameter
    * @param classFieldName the name of the field used as the output for the classifier
    * @param field2analyzer map with key a field name and the related {org.apache.lucene.analysis.Analyzer}
    * @param textFieldNames the name of the fields used as the inputs for the classifier, they can contain boosting indication e.g. title^10
@@ -103,24 +104,17 @@ public class KNearestNeighborDocumentClassifier extends KNearestNeighborClassifi
    */
   private TopDocs knnSearch(Document document) throws IOException {
     BooleanQuery.Builder mltQuery = new BooleanQuery.Builder();
-
-    for (String fieldName : textFieldNames) {
-      String boost = null;
-      if (fieldName.contains("^")) {
-        String[] field2boost = fieldName.split("\\^");
-        fieldName = field2boost[0];
-        boost = field2boost[1];
-      }
+    MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
+    boostConfiguration.setBoost(true);
+    for (String fieldNameWithBoost : textFieldNames) {
+      boostConfiguration.addFieldWithBoost(fieldNameWithBoost);
+    }
+    for (String fieldName : mlt.getFieldNames()) {
       String[] fieldValues = document.getValues(fieldName);
-      mlt.setBoost(true); // we want always to use the boost coming from TF * IDF of the term
-      if (boost != null) {
-        mlt.setBoostFactor(Float.parseFloat(boost)); // this is an additional multiplicative boost coming from the field boost
-      }
       mlt.setAnalyzer(field2analyzer.get(fieldName));
       for (String fieldContent : fieldValues) {
         mltQuery.add(new BooleanClause(mlt.like(fieldName, new StringReader(fieldContent)), BooleanClause.Occur.SHOULD));
       }
-      mlt.setBoostFactor(1);// restore neutral boost for next field
     }
     Query classFieldQuery = new WildcardQuery(new Term(classFieldName, "*"));
     mltQuery.add(new BooleanClause(classFieldQuery, BooleanClause.Occur.MUST));
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java b/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java
index 8ea3933eec..aff24fda23 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis.java
@@ -32,7 +32,6 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
@@ -109,7 +108,7 @@ import org.apache.lucene.util.PriorityQueue;
  * <br>
  * <h3>More Advanced Usage</h3>
  * <p>
- * You may want to use {@link #setFieldNames setFieldNames(...)} so you can examine
+ * You may want to use {@link #setFieldNames setFieldNamesRemovingBoost(...)} so you can examine
  * multiple fields (e.g. body and title) for similarity.
  * <p>
  * Depending on the size of your index and the size and makeup of your documents you
@@ -139,141 +138,10 @@ import org.apache.lucene.util.PriorityQueue;
  * </pre>
  */
 public final class MoreLikeThis {
-
-  /**
-   * Default maximum number of tokens to parse in each example doc field that is not stored with TermVector support.
-   *
-   * @see #getMaxNumTokensParsed
-   */
-  public static final int DEFAULT_MAX_NUM_TOKENS_PARSED = 5000;
-
-  /**
-   * Ignore terms with less than this frequency in the source doc.
-   *
-   * @see #getMinTermFreq
-   * @see #setMinTermFreq
-   */
-  public static final int DEFAULT_MIN_TERM_FREQ = 2;
-
-  /**
-   * Ignore words which do not occur in at least this many docs.
-   *
-   * @see #getMinDocFreq
-   * @see #setMinDocFreq
-   */
-  public static final int DEFAULT_MIN_DOC_FREQ = 5;
-
-  /**
-   * Ignore words which occur in more than this many docs.
-   *
-   * @see #getMaxDocFreq
-   * @see #setMaxDocFreq
-   * @see #setMaxDocFreqPct
-   */
-  public static final int DEFAULT_MAX_DOC_FREQ = Integer.MAX_VALUE;
-
-  /**
-   * Boost terms in query based on score.
-   *
-   * @see #isBoost
-   * @see #setBoost
-   */
-  public static final boolean DEFAULT_BOOST = false;
-
-  /**
-   * Default field names. Null is used to specify that the field names should be looked
-   * up at runtime from the provided reader.
-   */
-  public static final String[] DEFAULT_FIELD_NAMES = new String[]{"contents"};
-
-  /**
-   * Ignore words less than this length or if 0 then this has no effect.
-   *
-   * @see #getMinWordLen
-   * @see #setMinWordLen
-   */
-  public static final int DEFAULT_MIN_WORD_LENGTH = 0;
-
-  /**
-   * Ignore words greater than this length or if 0 then this has no effect.
-   *
-   * @see #getMaxWordLen
-   * @see #setMaxWordLen
-   */
-  public static final int DEFAULT_MAX_WORD_LENGTH = 0;
-
-  /**
-   * Default set of stopwords.
-   * If null means to allow stop words.
-   *
-   * @see #setStopWords
-   * @see #getStopWords
-   */
-  public static final Set<?> DEFAULT_STOP_WORDS = null;
-
-  /**
-   * Current set of stop words.
-   */
-  private Set<?> stopWords = DEFAULT_STOP_WORDS;
-
-  /**
-   * Return a Query with no more than this many terms.
-   *
-   * @see BooleanQuery#getMaxClauseCount
-   * @see #getMaxQueryTerms
-   * @see #setMaxQueryTerms
-   */
-  public static final int DEFAULT_MAX_QUERY_TERMS = 25;
-
-  /**
-   * Analyzer that will be used to parse the doc.
-   */
-  private Analyzer analyzer = null;
-
-  /**
-   * Ignore words less frequent that this.
-   */
-  private int minTermFreq = DEFAULT_MIN_TERM_FREQ;
-
-  /**
-   * Ignore words which do not occur in at least this many docs.
-   */
-  private int minDocFreq = DEFAULT_MIN_DOC_FREQ;
-
-  /**
-   * Ignore words which occur in more than this many docs.
-   */
-  private int maxDocFreq = DEFAULT_MAX_DOC_FREQ;
-
-  /**
-   * Should we apply a boost to the Query based on the scores?
-   */
-  private boolean boost = DEFAULT_BOOST;
-
-  /**
-   * Field name we'll analyze.
-   */
-  private String[] fieldNames = DEFAULT_FIELD_NAMES;
-
-  /**
-   * The maximum number of tokens to parse in each example doc field that is not stored with TermVector support
-   */
-  private int maxNumTokensParsed = DEFAULT_MAX_NUM_TOKENS_PARSED;
-
-  /**
-   * Ignore words if less than this len.
-   */
-  private int minWordLen = DEFAULT_MIN_WORD_LENGTH;
-
-  /**
-   * Ignore words if greater than this len.
-   */
-  private int maxWordLen = DEFAULT_MAX_WORD_LENGTH;
-
   /**
-   * Don't return a query longer than this.
+   * All tunable parameters that regulates the query building
    */
-  private int maxQueryTerms = DEFAULT_MAX_QUERY_TERMS;
+  private MoreLikeThisParameters parameters;
 
   /**
    * For idf() calculations.
@@ -285,30 +153,6 @@ public final class MoreLikeThis {
    */
   private final IndexReader ir;
 
-  /**
-   * Boost factor to use when boosting the terms
-   */
-  private float boostFactor = 1;
-
-  /**
-   * Returns the boost factor used when boosting terms
-   *
-   * @return the boost factor used when boosting terms
-   * @see #setBoostFactor(float)
-   */
-  public float getBoostFactor() {
-    return boostFactor;
-  }
-
-  /**
-   * Sets the boost factor to use when boosting terms
-   *
-   * @see #getBoostFactor()
-   */
-  public void setBoostFactor(float boostFactor) {
-    this.boostFactor = boostFactor;
-  }
-
   /**
    * Constructor requiring an IndexReader.
    */
@@ -317,6 +161,7 @@ public final class MoreLikeThis {
   }
 
   public MoreLikeThis(IndexReader ir, TFIDFSimilarity sim) {
+    this.parameters = new MoreLikeThisParameters();
     this.ir = ir;
     this.similarity = sim;
   }
@@ -337,7 +182,7 @@ public final class MoreLikeThis {
    * @return the analyzer that will be used to parse source doc with.
    */
   public Analyzer getAnalyzer() {
-    return analyzer;
+    return parameters.analyzer;
   }
 
   /**
@@ -347,17 +192,17 @@ public final class MoreLikeThis {
    * @param analyzer the analyzer to use to tokenize text.
    */
   public void setAnalyzer(Analyzer analyzer) {
-    this.analyzer = analyzer;
+    parameters.analyzer = analyzer;
   }
 
   /**
    * Returns the frequency below which terms will be ignored in the source doc. The default
-   * frequency is the {@link #DEFAULT_MIN_TERM_FREQ}.
+   * frequency is the {@link MoreLikeThisParameters#DEFAULT_MIN_TERM_FREQ}.
    *
    * @return the frequency below which terms will be ignored in the source doc.
    */
   public int getMinTermFreq() {
-    return minTermFreq;
+    return parameters.minTermFreq;
   }
 
   /**
@@ -366,18 +211,18 @@ public final class MoreLikeThis {
    * @param minTermFreq the frequency below which terms will be ignored in the source doc.
    */
   public void setMinTermFreq(int minTermFreq) {
-    this.minTermFreq = minTermFreq;
+    parameters.minTermFreq = minTermFreq;
   }
 
   /**
    * Returns the frequency at which words will be ignored which do not occur in at least this
-   * many docs. The default frequency is {@link #DEFAULT_MIN_DOC_FREQ}.
+   * many docs. The default frequency is {@link MoreLikeThisParameters#DEFAULT_MIN_DOC_FREQ}.
    *
    * @return the frequency at which words will be ignored which do not occur in at least this
-   *         many docs.
+   * many docs.
    */
   public int getMinDocFreq() {
-    return minDocFreq;
+    return parameters.minDocFreq;
   }
 
   /**
@@ -388,19 +233,19 @@ public final class MoreLikeThis {
    * least this many docs.
    */
   public void setMinDocFreq(int minDocFreq) {
-    this.minDocFreq = minDocFreq;
+    parameters.minDocFreq = minDocFreq;
   }
 
   /**
    * Returns the maximum frequency in which words may still appear.
    * Words that appear in more than this many docs will be ignored. The default frequency is
-   * {@link #DEFAULT_MAX_DOC_FREQ}.
+   * {@link MoreLikeThisParameters#DEFAULT_MAX_DOC_FREQ}.
    *
    * @return get the maximum frequency at which words are still allowed,
-   *         words which occur in more docs than this are ignored.
+   * words which occur in more docs than this are ignored.
    */
   public int getMaxDocFreq() {
-    return maxDocFreq;
+    return parameters.maxDocFreq;
   }
 
   /**
@@ -411,7 +256,7 @@ public final class MoreLikeThis {
    * in to be still considered relevant
    */
   public void setMaxDocFreq(int maxFreq) {
-    this.maxDocFreq = maxFreq;
+    parameters.maxDocFreq = maxFreq;
   }
 
   /**
@@ -429,34 +274,23 @@ public final class MoreLikeThis {
   }
 
   /**
-   * Returns whether to boost terms in query based on "score" or not. The default is
-   * {@link #DEFAULT_BOOST}.
-   *
-   * @return whether to boost terms in query based on "score" or not.
-   * @see #setBoost
-   */
-  public boolean isBoost() {
-    return boost;
-  }
-
-  /**
-   * Sets whether to boost terms in query based on "score" or not.
+   * Returns all the configurations that affect how boost is applied to the
+   * More Like This query
    *
-   * @param boost true to boost terms in query based on "score", false otherwise.
-   * @see #isBoost
+   * @return the boost properties
    */
-  public void setBoost(boolean boost) {
-    this.boost = boost;
+  public MoreLikeThisParameters.BoostProperties getBoostConfiguration() {
+    return parameters.boostConfiguration;
   }
 
   /**
    * Returns the field names that will be used when generating the 'More Like This' query.
-   * The default field names that will be used is {@link #DEFAULT_FIELD_NAMES}.
+   * The default field names that will be used is {@link MoreLikeThisParameters#DEFAULT_FIELD_NAMES}.
    *
    * @return the field names that will be used when generating the 'More Like This' query.
    */
   public String[] getFieldNames() {
-    return fieldNames;
+    return parameters.fieldNames;
   }
 
   /**
@@ -468,17 +302,17 @@ public final class MoreLikeThis {
    * query.
    */
   public void setFieldNames(String[] fieldNames) {
-    this.fieldNames = fieldNames;
+    parameters.setFieldNamesRemovingBoost(fieldNames);
   }
 
   /**
    * Returns the minimum word length below which words will be ignored. Set this to 0 for no
-   * minimum word length. The default is {@link #DEFAULT_MIN_WORD_LENGTH}.
+   * minimum word length. The default is {@link MoreLikeThisParameters#DEFAULT_MIN_WORD_LENGTH}.
    *
    * @return the minimum word length below which words will be ignored.
    */
   public int getMinWordLen() {
-    return minWordLen;
+    return parameters.minWordLen;
   }
 
   /**
@@ -487,17 +321,17 @@ public final class MoreLikeThis {
    * @param minWordLen the minimum word length below which words will be ignored.
    */
   public void setMinWordLen(int minWordLen) {
-    this.minWordLen = minWordLen;
+    parameters.minWordLen = minWordLen;
   }
 
   /**
    * Returns the maximum word length above which words will be ignored. Set this to 0 for no
-   * maximum word length. The default is {@link #DEFAULT_MAX_WORD_LENGTH}.
+   * maximum word length. The default is {@link MoreLikeThisParameters#DEFAULT_MAX_WORD_LENGTH}.
    *
    * @return the maximum word length above which words will be ignored.
    */
   public int getMaxWordLen() {
-    return maxWordLen;
+    return parameters.maxWordLen;
   }
 
   /**
@@ -506,7 +340,7 @@ public final class MoreLikeThis {
    * @param maxWordLen the maximum word length above which words will be ignored.
    */
   public void setMaxWordLen(int maxWordLen) {
-    this.maxWordLen = maxWordLen;
+    parameters.maxWordLen = maxWordLen;
   }
 
   /**
@@ -519,7 +353,7 @@ public final class MoreLikeThis {
    * @see #getStopWords
    */
   public void setStopWords(Set<?> stopWords) {
-    this.stopWords = stopWords;
+    parameters.stopWords = stopWords;
   }
 
   /**
@@ -528,18 +362,18 @@ public final class MoreLikeThis {
    * @see #setStopWords
    */
   public Set<?> getStopWords() {
-    return stopWords;
+    return parameters.stopWords;
   }
 
 
   /**
    * Returns the maximum number of query terms that will be included in any generated query.
-   * The default is {@link #DEFAULT_MAX_QUERY_TERMS}.
+   * The default is {@link MoreLikeThisParameters#DEFAULT_MAX_QUERY_TERMS}.
    *
    * @return the maximum number of query terms that will be included in any generated query.
    */
   public int getMaxQueryTerms() {
-    return maxQueryTerms;
+    return parameters.maxQueryTerms;
   }
 
   /**
@@ -549,22 +383,22 @@ public final class MoreLikeThis {
    * generated query.
    */
   public void setMaxQueryTerms(int maxQueryTerms) {
-    this.maxQueryTerms = maxQueryTerms;
+    parameters.maxQueryTerms = maxQueryTerms;
   }
 
   /**
    * @return The maximum number of tokens to parse in each example doc field that is not stored with TermVector support
-   * @see #DEFAULT_MAX_NUM_TOKENS_PARSED
+   * @see MoreLikeThisParameters#DEFAULT_MAX_NUM_TOKENS_PARSED
    */
   public int getMaxNumTokensParsed() {
-    return maxNumTokensParsed;
+    return parameters.maxNumTokensParsed;
   }
 
   /**
    * @param i The maximum number of tokens to parse in each example doc field that is not stored with TermVector support
    */
   public void setMaxNumTokensParsed(int i) {
-    maxNumTokensParsed = i;
+    parameters.maxNumTokensParsed = i;
   }
 
 
@@ -575,12 +409,6 @@ public final class MoreLikeThis {
    * @return a query that will return docs like the passed lucene document ID.
    */
   public Query like(int docNum) throws IOException {
-    if (fieldNames == null) {
-      // gather list of valid fields from lucene
-      Collection<String> fields = MultiFields.getIndexedFields(ir);
-      fieldNames = fields.toArray(new String[fields.size()]);
-    }
-
     return createQuery(retrieveTerms(docNum));
   }
 
@@ -590,11 +418,6 @@ public final class MoreLikeThis {
    * @return More Like This query for the passed document.
    */
   public Query like(Map<String, Collection<Object>> filteredDocument) throws IOException {
-    if (fieldNames == null) {
-      // gather list of valid fields from lucene
-      Collection<String> fields = MultiFields.getIndexedFields(ir);
-      fieldNames = fields.toArray(new String[fields.size()]);
-    }
     return createQuery(retrieveTerms(filteredDocument));
   }
 
@@ -623,12 +446,13 @@ public final class MoreLikeThis {
     while ((scoreTerm = q.pop()) != null) {
       Query tq = new TermQuery(new Term(scoreTerm.topField, scoreTerm.word));
 
-      if (boost) {
+      if (parameters.boostConfiguration.isBoostByTermScore()) {
         if (bestScore == -1) {
           bestScore = (scoreTerm.score);
         }
         float myScore = (scoreTerm.score);
-        tq = new BoostQuery(tq, boostFactor * myScore / bestScore);
+        float fieldBoost = parameters.boostConfiguration.getFieldBoost(scoreTerm.topField);
+        tq = new BoostQuery(tq, fieldBoost * myScore / bestScore);
       }
 
       try {
@@ -649,7 +473,7 @@ public final class MoreLikeThis {
   private PriorityQueue<ScoreTerm> createQueue(Map<String, Map<String, Int>> perFieldTermFrequencies) throws IOException {
     // have collected all words in doc and their freqs
     int numDocs = ir.numDocs();
-    final int limit = Math.min(maxQueryTerms, this.getTermsCount(perFieldTermFrequencies));
+    final int limit = Math.min(parameters.maxQueryTerms, this.getTermsCount(perFieldTermFrequencies));
     FreqQ queue = new FreqQ(limit); // will order words by score
     for (Map.Entry<String, Map<String, Int>> entry : perFieldTermFrequencies.entrySet()) {
       Map<String, Int> perWordTermFrequencies = entry.getValue();
@@ -658,17 +482,17 @@ public final class MoreLikeThis {
       for (Map.Entry<String, Int> tfEntry : perWordTermFrequencies.entrySet()) { // for every word
         String word = tfEntry.getKey();
         int tf = tfEntry.getValue().x; // term freq in the source doc
-        if (minTermFreq > 0 && tf < minTermFreq) {
+        if (parameters.minTermFreq > 0 && tf < parameters.minTermFreq) {
           continue; // filter out words that don't occur enough times in the source
         }
 
         int docFreq = ir.docFreq(new Term(fieldName, word));
 
-        if (minDocFreq > 0 && docFreq < minDocFreq) {
+        if (parameters.minDocFreq > 0 && docFreq < parameters.minDocFreq) {
           continue; // filter out words that don't occur in enough docs
         }
 
-        if (docFreq > maxDocFreq) {
+        if (docFreq > parameters.maxDocFreq) {
           continue; // filter out words that occur in too many docs
         }
 
@@ -707,21 +531,7 @@ public final class MoreLikeThis {
    * Describe the parameters that control how the "more like this" query is formed.
    */
   public String describeParams() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("\t").append("maxQueryTerms  : ").append(maxQueryTerms).append("\n");
-    sb.append("\t").append("minWordLen     : ").append(minWordLen).append("\n");
-    sb.append("\t").append("maxWordLen     : ").append(maxWordLen).append("\n");
-    sb.append("\t").append("fieldNames     : ");
-    String delim = "";
-    for (String fieldName : fieldNames) {
-      sb.append(delim).append(fieldName);
-      delim = ", ";
-    }
-    sb.append("\n");
-    sb.append("\t").append("boost          : ").append(boost).append("\n");
-    sb.append("\t").append("minTermFreq    : ").append(minTermFreq).append("\n");
-    sb.append("\t").append("minDocFreq     : ").append(minDocFreq).append("\n");
-    return sb.toString();
+    return parameters.describeParams();
   }
 
   /**
@@ -731,7 +541,7 @@ public final class MoreLikeThis {
    */
   private PriorityQueue<ScoreTerm> retrieveTerms(int docNum) throws IOException {
     Map<String, Map<String, Int>> field2termFreqMap = new HashMap<>();
-    for (String fieldName : fieldNames) {
+    for (String fieldName : parameters.getFieldNamesOrInit(ir)) {
       final Fields vectors = ir.getTermVectors(docNum);
       final Terms vector;
       if (vectors != null) {
@@ -762,7 +572,7 @@ public final class MoreLikeThis {
   private PriorityQueue<ScoreTerm> retrieveTerms(Map<String, Collection<Object>> field2fieldValues) throws
       IOException {
     Map<String, Map<String, Int>> field2termFreqMap = new HashMap<>();
-    for (String fieldName : fieldNames) {
+    for (String fieldName : parameters.getFieldNamesOrInit(ir)) {
       for (String field : field2fieldValues.keySet()) {
         Collection<Object> fieldValues = field2fieldValues.get(field);
         if(fieldValues == null)
@@ -817,12 +627,12 @@ public final class MoreLikeThis {
    */
   private void addTermFrequencies(Reader r, Map<String, Map<String, Int>> perFieldTermFrequencies, String fieldName)
       throws IOException {
-    if (analyzer == null) {
+    if (parameters.analyzer == null) {
       throw new UnsupportedOperationException("To use MoreLikeThis without " +
           "term vectors, you must provide an Analyzer");
     }
     Map<String, Int> termFreqMap = perFieldTermFrequencies.computeIfAbsent(fieldName, k -> new HashMap<>());
-    try (TokenStream ts = analyzer.tokenStream(fieldName, r)) {
+    try (TokenStream ts = parameters.analyzer.tokenStream(fieldName, r)) {
       int tokenCount = 0;
       // for every token
       CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
@@ -830,7 +640,7 @@ public final class MoreLikeThis {
       while (ts.incrementToken()) {
         String word = termAtt.toString();
         tokenCount++;
-        if (tokenCount > maxNumTokensParsed) {
+        if (tokenCount > parameters.maxNumTokensParsed) {
           break;
         }
         if (isNoiseWord(word)) {
@@ -858,13 +668,13 @@ public final class MoreLikeThis {
    */
   private boolean isNoiseWord(String term) {
     int len = term.length();
-    if (minWordLen > 0 && len < minWordLen) {
+    if (parameters.minWordLen > 0 && len < parameters.minWordLen) {
       return true;
     }
-    if (maxWordLen > 0 && len > maxWordLen) {
+    if (parameters.maxWordLen > 0 && len > parameters.maxWordLen) {
       return true;
     }
-    return stopWords != null && stopWords.contains(term);
+    return parameters.stopWords != null && parameters.stopWords.contains(term);
   }
 
 
@@ -900,10 +710,10 @@ public final class MoreLikeThis {
    * @see #retrieveInterestingTerms(java.io.Reader, String)
    */
   public String[] retrieveInterestingTerms(int docNum) throws IOException {
-    ArrayList<String> al = new ArrayList<>(maxQueryTerms);
+    ArrayList<String> al = new ArrayList<>(parameters.maxQueryTerms);
     PriorityQueue<ScoreTerm> pq = retrieveTerms(docNum);
     ScoreTerm scoreTerm;
-    int lim = maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
+    int lim = parameters.maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
     // we just want to return the top words
     while (((scoreTerm = pq.pop()) != null) && lim-- > 0) {
       al.add(scoreTerm.word); // the 1st entry is the interesting word
@@ -923,10 +733,10 @@ public final class MoreLikeThis {
    * @see #setMaxQueryTerms
    */
   public String[] retrieveInterestingTerms(Reader r, String fieldName) throws IOException {
-    ArrayList<String> al = new ArrayList<>(maxQueryTerms);
+    ArrayList<String> al = new ArrayList<>(parameters.maxQueryTerms);
     PriorityQueue<ScoreTerm> pq = retrieveTerms(r, fieldName);
     ScoreTerm scoreTerm;
-    int lim = maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
+    int lim = parameters.maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
     // we just want to return the top words
     while (((scoreTerm = pq.pop()) != null) && lim-- > 0) {
       al.add(scoreTerm.word); // the 1st entry is the interesting word
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThisParameters.java b/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThisParameters.java
new file mode 100644
index 0000000000..a33d0d87cf
--- /dev/null
+++ b/lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThisParameters.java
@@ -0,0 +1,297 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.lucene.queries.mlt;
+
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.search.BooleanQuery;
+
+/**
+ * This class models all the parameters that affect how to generate a More Like This Query:
+ */
+public final class MoreLikeThisParameters {
+  /**
+   * Default maximum number of tokens to parse in each example doc field that is not stored with TermVector support.
+   */
+  public static final int DEFAULT_MAX_NUM_TOKENS_PARSED = 5000;
+
+  /**
+   * Ignore terms with less than this frequency in the source doc.
+   *
+   */
+  public static final int DEFAULT_MIN_TERM_FREQ = 2;
+
+  /**
+   * Ignore words which do not occur in at least this many docs.
+   *
+   */
+  public static final int DEFAULT_MIN_DOC_FREQ = 5;
+
+  /**
+   * Ignore words which occur in more than this many docs.
+   *
+   */
+  public static final int DEFAULT_MAX_DOC_FREQ = Integer.MAX_VALUE;
+
+  /**
+   * Default field names. Null is used to specify that the field names should be looked
+   * up at runtime from the provided reader.
+   */
+  public static final String[] DEFAULT_FIELD_NAMES = null;
+
+  /**
+   * Ignore words less than this length or if 0 then this has no effect.
+   *
+   */
+  public static final int DEFAULT_MIN_WORD_LENGTH = 0;
+
+  /**
+   * Ignore words greater than this length or if 0 then this has no effect.
+   *
+   */
+  public static final int DEFAULT_MAX_WORD_LENGTH = 0;
+
+  /**
+   * Default set of stopwords.
+   * If null means to allow stop words.
+   *
+   */
+  public static final Set<?> DEFAULT_STOP_WORDS = null;
+
+  /**
+   * Return a Query with no more than this many terms.
+   *
+   * @see BooleanQuery#getMaxClauseCount
+   */
+  public static final int DEFAULT_MAX_QUERY_TERMS = 25;
+
+  /**
+   * Analyzer that will be used to parse the doc.
+   * This analyzer will be used for all the fields in the document.
+   */
+  Analyzer analyzer = null;
+
+  /**
+   * Ignore words less frequent that this.
+   */
+  int minTermFreq = DEFAULT_MIN_TERM_FREQ;
+
+  /**
+   * Ignore words which do not occur in at least this many docs.
+   */
+  int minDocFreq = DEFAULT_MIN_DOC_FREQ;
+
+  /**
+   * Ignore words which occur in more than this many docs.
+   */
+  int maxDocFreq = DEFAULT_MAX_DOC_FREQ;
+
+  /**
+   * Field name we'll analyze.
+   */
+  String[] fieldNames = DEFAULT_FIELD_NAMES;
+
+  /**
+   * The maximum number of tokens to parse in each example doc field that is not stored with TermVector support
+   */
+  int maxNumTokensParsed = DEFAULT_MAX_NUM_TOKENS_PARSED;
+
+  /**
+   * Ignore words if less than this len.
+   */
+  int minWordLen = DEFAULT_MIN_WORD_LENGTH;
+
+  /**
+   * Ignore words if greater than this len.
+   */
+  int maxWordLen = DEFAULT_MAX_WORD_LENGTH;
+
+  /**
+   * Don't return a query longer than this.
+   */
+  int maxQueryTerms = DEFAULT_MAX_QUERY_TERMS;
+
+  /**
+   * Current set of stop words.
+   */
+  Set<?> stopWords = DEFAULT_STOP_WORDS;
+
+  /**
+   * The boost configuration will be used to manage how :
+   * - terms are boosted in the MLT query
+   * - fields are boosted in the MLT query
+   */
+  BoostProperties boostConfiguration = new BoostProperties();
+
+  /**
+   * Returns an analyzer that will be used to parse source doc with. The default analyzer
+   * is not set.
+   *
+   * @return the analyzer that will be used to parse source doc with.
+   */
+  Analyzer getAnalyzer() {
+    return analyzer;
+  }
+
+  /**
+   * Returns the field names that will be used when generating the 'More Like This' query.
+   * If current field names are null, fetch them from the index reader.
+   * The default field names that will be used is {@link #DEFAULT_FIELD_NAMES}.
+   *
+   * @return the field names that will be used when generating the 'More Like This' query.
+   */
+  public String[] getFieldNamesOrInit(IndexReader ir) {
+    if (fieldNames == null) {
+      // gather list of valid fields from lucene
+      Collection<String> fields = MultiFields.getIndexedFields(ir);
+      fieldNames = fields.toArray(new String[fields.size()]);
+    }
+    return fieldNames;
+  }
+
+  /**
+   * Sets the field names that will be used when generating the 'More Like This' query.
+   * Set this to null for the field names to be determined at runtime from the IndexReader
+   * provided in the constructor.
+   *
+   * @param fieldNames the field names that will be used when generating the 'More Like This'
+   *                   query.
+   */
+  public void setFieldNamesRemovingBoost(String[] fieldNames) {
+    this.fieldNames = Arrays.stream(fieldNames).map(fieldName -> fieldName.split("\\^")[0]).toArray(String[]::new);
+  }
+
+  /**
+   * Describe the parameters that control how the "more like this" query is formed.
+   */
+  public String describeParams() {
+    StringBuilder sb = new StringBuilder();
+    sb.append("\t").append("maxQueryTerms  : ").append(this.maxQueryTerms).append("\n");
+    sb.append("\t").append("minWordLen     : ").append(this.minWordLen).append("\n");
+    sb.append("\t").append("maxWordLen     : ").append(this.maxWordLen).append("\n");
+    sb.append("\t").append("fieldNames     : ");
+    String delim = "";
+    for (String fieldName : fieldNames) {
+      sb.append(delim).append(fieldName);
+      delim = ", ";
+    }
+    sb.append("\n");
+    sb.append("\t").append("boost          : ").append(this.boostConfiguration.isBoostByTermScore()).append("\n");
+    sb.append("\t").append("minTermFreq    : ").append(this.minTermFreq).append("\n");
+    sb.append("\t").append("minDocFreq     : ").append(this.minDocFreq).append("\n");
+    return sb.toString();
+  }
+
+  public class BoostProperties {
+    /**
+     * By default the query time boost factor is not applied
+     */
+    public static final boolean DEFAULT_BOOST = false;
+
+    /**
+     * By default the query time boost factor is equal to 1.0
+     */
+    private static final float DEFAULT_BOOST_FACTOR = 1.0f;
+    
+    /**
+     * If enabled a query time boost factor will applied to each query term.
+     * This boost factor is the term score ( calculated by the similarity function).
+     * More the term is considered interesting, stronger the query time boost
+     */
+    private boolean boostByTermScore = DEFAULT_BOOST;
+
+    /**
+     * This is an additional multiplicative factor that may affect how strongly
+     * the query terms will be boosted.
+     * If a query time boost factor > 1 is specified, each query term boost
+     * is equal the term score multiplied by this factor.
+     */
+    private float boostFactor = DEFAULT_BOOST_FACTOR;
+
+    /**
+     * This is an alternative to the generic boost factor.
+     * This map allows to boost each field differently. 
+     */
+    private Map<String, Float> fieldToBoostFactor = new HashMap<>();
+
+    public BoostProperties() {
+    }
+
+    public void addFieldWithBoost(String boostedField) {
+      String fieldName;
+      String boost;
+      if (boostedField.contains("^")) {
+        String[] field2boost = boostedField.split("\\^");
+        fieldName = field2boost[0];
+        boost = field2boost[1];
+        if (boost != null) {
+          fieldToBoostFactor.put(fieldName, Float.parseFloat(boost));
+        }
+      } else {
+        fieldToBoostFactor.put(boostedField, boostFactor);
+      }
+    }
+
+    public void setBoostFactor(float boostFactor) {
+      this.boostFactor = boostFactor;
+    }
+
+    public float getFieldBoost(String fieldName) {
+      float queryTimeBoost = boostFactor;
+      if (fieldToBoostFactor != null) {
+        Float currentFieldQueryTimeBoost = fieldToBoostFactor.get(fieldName);
+        if (currentFieldQueryTimeBoost != null) {
+          queryTimeBoost = currentFieldQueryTimeBoost;
+        }
+      }
+      return queryTimeBoost;
+    }
+
+    public void setFieldToBoostFactor(Map<String, Float> fieldToBoostFactor) {
+      this.fieldToBoostFactor = fieldToBoostFactor;
+    }
+
+    /**
+     * Returns whether a query time boost for each term based on its score is enabled or not. 
+     * The default is false.
+     *
+     * @return whether to boostByTermScore terms in query based on "score" or not.
+     * @see #setBoost
+     */
+    public boolean isBoostByTermScore() {
+      return boostByTermScore;
+    }
+
+    /**
+     * Sets whether to set a query time boost for each term based on its score or not.
+     *
+     * @param boostEnabled true to boost each term based on its score, false otherwise.
+     * @see #isBoostByTermScore
+     */
+    public void setBoost(boolean boostEnabled) {
+      this.boostByTermScore = boostEnabled;
+    }
+  }
+
+}
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/mlt/MoreLikeThisParametersTest.java b/lucene/queries/src/test/org/apache/lucene/queries/mlt/MoreLikeThisParametersTest.java
new file mode 100644
index 0000000000..a790c83b84
--- /dev/null
+++ b/lucene/queries/src/test/org/apache/lucene/queries/mlt/MoreLikeThisParametersTest.java
@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.queries.mlt;
+
+import java.io.IOException;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+import static org.hamcrest.core.Is.is;
+
+public class MoreLikeThisParametersTest extends LuceneTestCase {
+  private MoreLikeThisParameters toTest = new MoreLikeThisParameters();
+
+  public void testMLTParameters_setFieldNames_shouldRemoveBoosts() {
+    String[] fieldNames = new String[]{"field1", "field2^5.0", "field3^1.0", "field4"};
+
+    toTest.setFieldNamesRemovingBoost(fieldNames);
+
+    assertThat(toTest.fieldNames, is(new String[]{"field1", "field2", "field3", "field4"}));
+  }
+
+  public void testMLTParameters_fieldNamesNotInitialised_shouldFetchThemFromIndex() throws IOException {
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), directory);
+
+    Document doc = new Document();
+    doc.add(newTextField("field1", "lucene", Field.Store.YES));
+    doc.add(newTextField("field2", "more like this", Field.Store.YES));
+    writer.addDocument(doc);
+    
+    IndexReader reader = writer.getReader();
+    writer.close();
+
+    toTest.getFieldNamesOrInit(reader);
+
+    assertThat(toTest.fieldNames, is(new String[]{"field1", "field2"}));
+
+    reader.close();
+    directory.close();
+  }
+
+  public void testMLTParameters_describeParams_shouldReturnParamsDescriptionString() {
+    String[] fieldNames = new String[]{"field1", "field2^5.0", "field3^1.0", "field4"};
+    toTest.setFieldNamesRemovingBoost(fieldNames);
+
+    String paramsDescription = toTest.describeParams();
+
+    assertThat(paramsDescription,
+        is("\tmaxQueryTerms  : 25\n" +
+            "\tminWordLen     : 0\n" +
+            "\tmaxWordLen     : 0\n" +
+            "\tfieldNames     : field1, field2, field3, field4\n" +
+            "\tboost          : false\n" +
+            "\tminTermFreq    : 2\n" +
+            "\tminDocFreq     : 5\n"));
+  }
+
+  public void testMLTParameters_setBoostFields_shouldParseBoosts() {
+    String[] fieldNames = new String[]{"field1", "field2^2.0", "field3^3.0", "field4"};
+
+    for (String fieldWithBoost : fieldNames) {
+      toTest.boostConfiguration.addFieldWithBoost(fieldWithBoost);
+    }
+
+    assertThat(toTest.boostConfiguration.getFieldBoost("field1"), is(1.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field2"), is(2.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field3"), is(3.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field4"), is(1.0F));
+  }
+
+  public void testMLTParameters_noBoostConfiguration_shouldReturnDefaultBoost() {
+    assertThat(toTest.boostConfiguration.getFieldBoost("field1"), is(1.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field2"), is(1.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field3"), is(1.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field4"), is(1.0F));
+
+    toTest.boostConfiguration.setBoostFactor(5.0f);
+
+    assertThat(toTest.boostConfiguration.getFieldBoost("field1"), is(5.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field2"), is(5.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field3"), is(5.0F));
+    assertThat(toTest.boostConfiguration.getFieldBoost("field4"), is(5.0F));
+  }
+}
diff --git a/lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis.java b/lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis.java
index 32a610bf8a..339188aec9 100644
--- a/lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis.java
+++ b/lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis.java
@@ -94,18 +94,19 @@ public class TestMoreLikeThis extends LuceneTestCase {
     Map<String,Float> originalValues = getOriginalValues();
     
     MoreLikeThis mlt = new MoreLikeThis(reader);
+    MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
     Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     mlt.setAnalyzer(analyzer);
     mlt.setMinDocFreq(1);
     mlt.setMinTermFreq(1);
     mlt.setMinWordLen(1);
-    mlt.setFieldNames(new String[] {"text"});
-    mlt.setBoost(true);
+    mlt.setFieldNames(new String[]{"text"});
+    boostConfiguration.setBoost(true);
     
     // this mean that every term boost factor will be multiplied by this
     // number
     float boostFactor = 5;
-    mlt.setBoostFactor(boostFactor);
+    boostConfiguration.setBoostFactor(boostFactor);
     
     BooleanQuery query = (BooleanQuery) mlt.like("text", new StringReader(
         "lucene release"));
@@ -131,13 +132,14 @@ public class TestMoreLikeThis extends LuceneTestCase {
   private Map<String,Float> getOriginalValues() throws IOException {
     Map<String,Float> originalValues = new HashMap<>();
     MoreLikeThis mlt = new MoreLikeThis(reader);
+    MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
     Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);
     mlt.setAnalyzer(analyzer);
     mlt.setMinDocFreq(1);
     mlt.setMinTermFreq(1);
     mlt.setMinWordLen(1);
-    mlt.setFieldNames(new String[] {"text"});
-    mlt.setBoost(true);
+    mlt.setFieldNames(new String[]{"text"});
+    boostConfiguration.setBoost(true);
     BooleanQuery query = (BooleanQuery) mlt.like("text", new StringReader(
         "lucene release"));
     Collection<BooleanClause> clauses = query.clauses();
@@ -159,7 +161,7 @@ public class TestMoreLikeThis extends LuceneTestCase {
     mlt.setMinDocFreq(1);
     mlt.setMinTermFreq(1);
     mlt.setMinWordLen(1);
-    mlt.setFieldNames(new String[] {"text", "foobar"});
+    mlt.setFieldNames(new String[]{"text", "foobar"});
     mlt.like("foobar", new StringReader("this is a test"));
     analyzer.close();
   }
@@ -172,7 +174,7 @@ public class TestMoreLikeThis extends LuceneTestCase {
     mlt.setMinDocFreq(1);
     mlt.setMinTermFreq(1);
     mlt.setMinWordLen(1);
-    mlt.setFieldNames(new String[] {"text"});
+    mlt.setFieldNames(new String[]{"text"});
 
     BooleanQuery query = (BooleanQuery) mlt.like("text",
         new StringReader("lucene"), new StringReader("lucene release"),
diff --git a/solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java b/solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java
index cce2939c58..3b7d8051db 100644
--- a/solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/MoreLikeThisHandler.java
@@ -33,6 +33,7 @@ import org.apache.lucene.index.ExitableDirectoryReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
+import org.apache.lucene.queries.mlt.MoreLikeThisParameters;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BoostQuery;
@@ -43,8 +44,8 @@ import org.apache.solr.common.SolrException;
 import org.apache.solr.common.StringUtils;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.FacetParams;
-import org.apache.solr.common.params.MoreLikeThisParams.TermStyle;
 import org.apache.solr.common.params.MoreLikeThisParams;
+import org.apache.solr.common.params.MoreLikeThisParams.TermStyle;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.ContentStream;
 import org.apache.solr.common.util.NamedList;
@@ -143,12 +144,12 @@ public class MoreLikeThisHandler extends RequestHandlerBase
 
         SolrIndexSearcher searcher = req.getSearcher();
 
-        MoreLikeThisHelper mlt = new MoreLikeThisHelper(params, searcher);
+        MoreLikeThisHelper mltHelper = new MoreLikeThisHelper(params, searcher);
 
         // Hold on to the interesting terms if relevant
         TermStyle termStyle = TermStyle.get(params.get(MoreLikeThisParams.INTERESTING_TERMS));
         List<InterestingTerm> interesting = (termStyle == TermStyle.NONE)
-            ? null : new ArrayList<>(mlt.mlt.getMaxQueryTerms());
+            ? null : new ArrayList<>(mltHelper.mlt.getMaxQueryTerms());
 
         DocListAndSet mltDocs = null;
 
@@ -176,7 +177,7 @@ public class MoreLikeThisHandler extends RequestHandlerBase
           // Find documents MoreLikeThis - either with a reader or a query
           // --------------------------------------------------------------------------------
           if (reader != null) {
-            mltDocs = mlt.getMoreLikeThis(reader, start, rows, filters,
+            mltDocs = mltHelper.getMoreLikeThis(reader, start, rows, filters,
                 interesting, flags);
           } else if (q != null) {
             // Matching options
@@ -195,7 +196,7 @@ public class MoreLikeThisHandler extends RequestHandlerBase
             if (iterator.hasNext()) {
               // do a MoreLikeThis query for each document in results
               int id = iterator.nextDoc();
-              mltDocs = mlt.getMoreLikeThis(id, start, rows, filters, interesting,
+              mltDocs = mltHelper.getMoreLikeThis(id, start, rows, filters, interesting,
                   flags);
             }
           } else {
@@ -261,7 +262,7 @@ public class MoreLikeThisHandler extends RequestHandlerBase
         // TODO resolve duplicated code with DebugComponent.  Perhaps it should be added to doStandardDebug?
         if (dbg == true) {
           try {
-            NamedList<Object> dbgInfo = SolrPluginUtils.doStandardDebug(req, q, mlt.getRawMLTQuery(), mltDocs.docList, dbgQuery, dbgResults);
+            NamedList<Object> dbgInfo = SolrPluginUtils.doStandardDebug(req, q, mltHelper.getBoostedMLTQuery(), mltDocs.docList, dbgQuery, dbgResults);
             if (null != dbgInfo) {
               if (null != filters) {
                 dbgInfo.add("filter_queries", req.getParams().getParams(CommonParams.FQ));
@@ -302,7 +303,6 @@ public class MoreLikeThisHandler extends RequestHandlerBase
     final IndexReader reader;
     final SchemaField uniqueKeyField;
     final boolean needDocSet;
-    Map<String,Float> boostFields;
     
     public MoreLikeThisHelper( SolrParams params, SolrIndexSearcher searcher )
     {
@@ -331,19 +331,20 @@ public class MoreLikeThisHandler extends RequestHandlerBase
       }
       
       this.mlt = new MoreLikeThis( reader ); // TODO -- after LUCENE-896, we can use , searcher.getSimilarity() );
+      MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
       mlt.setFieldNames(fields);
-      mlt.setAnalyzer( searcher.getSchema().getIndexAnalyzer() );
+      mlt.setAnalyzer(searcher.getSchema().getIndexAnalyzer());
       
       // configurable params
-      
-      mlt.setMinTermFreq(       params.getInt(MoreLikeThisParams.MIN_TERM_FREQ,         MoreLikeThis.DEFAULT_MIN_TERM_FREQ));
-      mlt.setMinDocFreq(        params.getInt(MoreLikeThisParams.MIN_DOC_FREQ,          MoreLikeThis.DEFAULT_MIN_DOC_FREQ));
-      mlt.setMaxDocFreq(        params.getInt(MoreLikeThisParams.MAX_DOC_FREQ,          MoreLikeThis.DEFAULT_MAX_DOC_FREQ));
-      mlt.setMinWordLen(        params.getInt(MoreLikeThisParams.MIN_WORD_LEN,          MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));
-      mlt.setMaxWordLen(        params.getInt(MoreLikeThisParams.MAX_WORD_LEN,          MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));
-      mlt.setMaxQueryTerms(     params.getInt(MoreLikeThisParams.MAX_QUERY_TERMS,       MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));
-      mlt.setMaxNumTokensParsed(params.getInt(MoreLikeThisParams.MAX_NUM_TOKENS_PARSED, MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));
-      mlt.setBoost(            params.getBool(MoreLikeThisParams.BOOST, false ) );
+
+      mlt.setMinTermFreq(params.getInt(MoreLikeThisParams.MIN_TERM_FREQ, MoreLikeThisParameters.DEFAULT_MIN_TERM_FREQ));
+      mlt.setMinDocFreq(params.getInt(MoreLikeThisParams.MIN_DOC_FREQ, MoreLikeThisParameters.DEFAULT_MIN_DOC_FREQ));
+      mlt.setMaxDocFreq(params.getInt(MoreLikeThisParams.MAX_DOC_FREQ, MoreLikeThisParameters.DEFAULT_MAX_DOC_FREQ));
+      mlt.setMinWordLen(params.getInt(MoreLikeThisParams.MIN_WORD_LEN, MoreLikeThisParameters.DEFAULT_MIN_WORD_LENGTH));
+      mlt.setMaxWordLen(params.getInt(MoreLikeThisParams.MAX_WORD_LEN, MoreLikeThisParameters.DEFAULT_MAX_WORD_LENGTH));
+      mlt.setMaxQueryTerms(params.getInt(MoreLikeThisParams.MAX_QUERY_TERMS, MoreLikeThisParameters.DEFAULT_MAX_QUERY_TERMS));
+      mlt.setMaxNumTokensParsed(params.getInt(MoreLikeThisParams.MAX_NUM_TOKENS_PARSED, MoreLikeThisParameters.DEFAULT_MAX_NUM_TOKENS_PARSED));
+      boostConfiguration.setBoost(params.getBool(MoreLikeThisParams.BOOST, MoreLikeThisParameters.BoostProperties.DEFAULT_BOOST));
       
       // There is no default for maxDocFreqPct. Also, it's a bit oddly expressed as an integer value 
       // (percentage of the collection's documents count). We keep Lucene's convention here. 
@@ -351,17 +352,13 @@ public class MoreLikeThisHandler extends RequestHandlerBase
         mlt.setMaxDocFreqPct(params.getInt(MoreLikeThisParams.MAX_DOC_FREQ_PCT));
       }
 
-      boostFields = SolrPluginUtils.parseFieldBoosts(params.getParams(MoreLikeThisParams.QF));
+      String[] fieldsWithBoost = params.getParams(MoreLikeThisParams.QF);
+      boostConfiguration.setFieldToBoostFactor(SolrPluginUtils.parseFieldBoosts(fieldsWithBoost));
     }
     
-    private Query rawMLTQuery;
     private Query boostedMLTQuery;
     private BooleanQuery realMLTQuery;
     
-    public Query getRawMLTQuery(){
-      return rawMLTQuery;
-    }
-    
     public Query getBoostedMLTQuery(){
       return boostedMLTQuery;
     }
@@ -370,35 +367,12 @@ public class MoreLikeThisHandler extends RequestHandlerBase
       return realMLTQuery;
     }
     
-    private Query getBoostedQuery(Query mltquery) {
-      BooleanQuery boostedQuery = (BooleanQuery)mltquery;
-      if (boostFields.size() > 0) {
-        BooleanQuery.Builder newQ = new BooleanQuery.Builder();
-        newQ.setMinimumNumberShouldMatch(boostedQuery.getMinimumNumberShouldMatch());
-        for (BooleanClause clause : boostedQuery) {
-          Query q = clause.getQuery();
-          float originalBoost = 1f;
-          if (q instanceof BoostQuery) {
-            BoostQuery bq = (BoostQuery) q;
-            q = bq.getQuery();
-            originalBoost = bq.getBoost();
-          }
-          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());
-          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());
-          newQ.add(q, clause.getOccur());
-        }
-        boostedQuery = newQ.build();
-      }
-      return boostedQuery;
-    }
-    
     public DocListAndSet getMoreLikeThis( int id, int start, int rows, List<Query> filters, List<InterestingTerm> terms, int flags ) throws IOException
     {
       Document doc = reader.document(id);
-      rawMLTQuery = mlt.like(id);
-      boostedMLTQuery = getBoostedQuery( rawMLTQuery );
+      boostedMLTQuery = mlt.like(id);
       if( terms != null ) {
-        fillInterestingTermsFromMLTQuery( rawMLTQuery, terms );
+        fillInterestingTermsFromMLTQuery( boostedMLTQuery, terms );
       }
 
       // exclude current document from results
@@ -423,9 +397,9 @@ public class MoreLikeThisHandler extends RequestHandlerBase
       // SOLR-5351: if only check against a single field, use the reader directly. Otherwise we
       // repeat the stream's content for multiple fields so that query terms can be pulled from any
       // of those fields.
-      String [] fields = mlt.getFieldNames();
+      String[] fields = mlt.getFieldNames();
       if (fields.length == 1) {
-        rawMLTQuery = mlt.like(fields[0], reader);
+        boostedMLTQuery = mlt.like(fields[0], reader);
       } else {
         CharsRefBuilder buffered = new CharsRefBuilder();
         char [] chunk = new char [1024];
@@ -440,10 +414,9 @@ public class MoreLikeThisHandler extends RequestHandlerBase
           multifieldDoc.put(field, streamValue);
         }
 
-        rawMLTQuery = mlt.like(multifieldDoc);
+        boostedMLTQuery = mlt.like(multifieldDoc);
       }
-
-      boostedMLTQuery = getBoostedQuery( rawMLTQuery );
+      
       if (terms != null) {
         fillInterestingTermsFromMLTQuery( boostedMLTQuery, terms );
       }
@@ -469,12 +442,10 @@ public class MoreLikeThisHandler extends RequestHandlerBase
         if (mltquery.clauses().size() == 0) {
           return result;
         }
-        mltquery = (BooleanQuery) getBoostedQuery(mltquery);
-        
         // exclude current document from results
         BooleanQuery.Builder mltQuery = new BooleanQuery.Builder();
         mltQuery.add(mltquery, BooleanClause.Occur.MUST);
-        
+
         mltQuery.add(
             new TermQuery(new Term(uniqueKeyField.getName(), uniqueId)), BooleanClause.Occur.MUST_NOT);
         result.add(uniqueId, mltQuery.build());
diff --git a/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java b/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java
index fd9d37d4aa..876566a8f3 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java
@@ -191,11 +191,6 @@ public class MoreLikeThisComponent extends SearchComponent {
  
             log.info("MLT: results added for key: " + key + " documents: "
                 + shardDocList.toString());
-//            if (log.isDebugEnabled()) {
-//              for (SolrDocument doc : shardDocList) {
-//                doc.addField("shard", "=" + r.getShard());
-//              }
-//            }
             SolrDocumentList mergedDocList = tempResults.get(key);
  
             if (mergedDocList == null) {
@@ -370,25 +365,34 @@ public class MoreLikeThisComponent extends SearchComponent {
     IndexSchema schema = searcher.getSchema();
     MoreLikeThisHandler.MoreLikeThisHelper mltHelper = new MoreLikeThisHandler.MoreLikeThisHelper(
         p, searcher);
-    NamedList<DocList> mlt = new SimpleOrderedMap<>();
+    NamedList<DocList> mltResponse = new SimpleOrderedMap<>();
     DocIterator iterator = docs.iterator();
     
     SimpleOrderedMap<Object> dbg = null;
     if (rb.isDebug()) {
       dbg = new SimpleOrderedMap<>();
     }
+
+    SimpleOrderedMap<Object> interestingTermsResponse = null;
+    MoreLikeThisParams.TermStyle termStyle = MoreLikeThisParams.TermStyle.get(p.get(MoreLikeThisParams.INTERESTING_TERMS));
+    List<MoreLikeThisHandler.InterestingTerm> interestingTerms = (termStyle == MoreLikeThisParams.TermStyle.NONE)
+        ? null : new ArrayList<>(mltHelper.getMoreLikeThis().getMaxQueryTerms());
+    
+    if (interestingTerms!=null) {
+      interestingTermsResponse = new SimpleOrderedMap<>();
+    }
     
     while (iterator.hasNext()) {
       int id = iterator.nextDoc();
       int rows = p.getInt(MoreLikeThisParams.DOC_COUNT, 5);
-      DocListAndSet sim = mltHelper.getMoreLikeThis(id, 0, rows, null, null,
+      
+      DocListAndSet sim = mltHelper.getMoreLikeThis(id, 0, rows, null, interestingTerms,
           flags);
       String name = schema.printableUniqueKey(searcher.doc(id));
-      mlt.add(name, sim.docList);
+      mltResponse.add(name, sim.docList);
       
       if (dbg != null) {
         SimpleOrderedMap<Object> docDbg = new SimpleOrderedMap<>();
-        docDbg.add("rawMLTQuery", mltHelper.getRawMLTQuery().toString());
         docDbg
             .add("boostedMLTQuery", mltHelper.getBoostedMLTQuery().toString());
         docDbg.add("realMLTQuery", mltHelper.getRealMLTQuery().toString());
@@ -403,13 +407,32 @@ public class MoreLikeThisComponent extends SearchComponent {
         docDbg.add("explain", explains);
         dbg.add(name, docDbg);
       }
+
+      if (interestingTermsResponse != null) {
+        if (termStyle == MoreLikeThisParams.TermStyle.DETAILS) {
+          NamedList<Float> interestingTermsWithScore = new NamedList<>();
+          for (MoreLikeThisHandler.InterestingTerm interestingTerm : interestingTerms) {
+            interestingTermsWithScore.add(interestingTerm.term.toString(), interestingTerm.boost);
+          }
+          interestingTermsResponse.add(name, interestingTermsWithScore);
+        } else {
+          List<String> interestingTermsString = new ArrayList<>(interestingTerms.size());
+          for(MoreLikeThisHandler.InterestingTerm interestingTerm : interestingTerms){
+            interestingTermsString.add(interestingTerm.term.toString());
+          }
+          interestingTermsResponse.add(name, interestingTermsString);
+        }
+      }
     }
-    
     // add debug information
     if (dbg != null) {
       rb.addDebugInfo("moreLikeThis", dbg);
     }
-    return mlt;
+    // add Interesting Terms
+    if (interestingTermsResponse != null) {
+      rb.rsp.add("interestingTerms", interestingTermsResponse);
+    }
+    return mltResponse;
   }
   
   // ///////////////////////////////////////////
diff --git a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java b/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
index 7669db8634..c13d6c1ba0 100644
--- a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java
@@ -25,11 +25,10 @@ import java.util.regex.Pattern;
 
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.Term;
-import org.apache.solr.legacy.LegacyNumericUtils;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
+import org.apache.lucene.queries.mlt.MoreLikeThisParameters;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -40,13 +39,13 @@ import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrCore;
+import org.apache.solr.legacy.LegacyNumericUtils;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.request.SolrQueryRequestBase;
 import org.apache.solr.response.SolrQueryResponse;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.QParser;
 import org.apache.solr.search.QueryParsing;
-import org.apache.solr.search.QueryUtils;
 import org.apache.solr.util.SolrPluginUtils;
 
 import static org.apache.solr.common.params.CommonParams.ID;
@@ -73,17 +72,16 @@ public class CloudMLTQParser extends QParser {
     String[] qf = localParams.getParams("qf");
     Map<String,Float> boostFields = new HashMap<>();
     MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());
+    MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
 
-    mlt.setMinTermFreq(localParams.getInt("mintf", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));
+    mlt.setMinTermFreq(localParams.getInt("mintf", MoreLikeThisParameters.DEFAULT_MIN_TERM_FREQ));
     mlt.setMinDocFreq(localParams.getInt("mindf", 0));
-    mlt.setMinWordLen(localParams.getInt("minwl", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));
-    mlt.setMaxWordLen(localParams.getInt("maxwl", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));
-    mlt.setMaxQueryTerms(localParams.getInt("maxqt", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));
-    mlt.setMaxNumTokensParsed(localParams.getInt("maxntp", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));
-    mlt.setMaxDocFreq(localParams.getInt("maxdf", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));
-
-    Boolean boost = localParams.getBool("boost", MoreLikeThis.DEFAULT_BOOST);
-    mlt.setBoost(boost);
+    mlt.setMinWordLen(localParams.getInt("minwl", MoreLikeThisParameters.DEFAULT_MIN_WORD_LENGTH));
+    mlt.setMaxWordLen(localParams.getInt("maxwl", MoreLikeThisParameters.DEFAULT_MAX_WORD_LENGTH));
+    mlt.setMaxQueryTerms(localParams.getInt("maxqt", MoreLikeThisParameters.DEFAULT_MAX_QUERY_TERMS));
+    mlt.setMaxNumTokensParsed(localParams.getInt("maxntp", MoreLikeThisParameters.DEFAULT_MAX_NUM_TOKENS_PARSED));
+    mlt.setMaxDocFreq(localParams.getInt("maxdf", MoreLikeThisParameters.DEFAULT_MAX_DOC_FREQ));
+    boostConfiguration.setBoost(localParams.getBool("boost", MoreLikeThisParameters.BoostProperties.DEFAULT_BOOST));
 
     mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());
 
@@ -104,6 +102,7 @@ public class CloudMLTQParser extends QParser {
       }
       // Parse field names and boosts from the fields
       boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));
+      boostConfiguration.setFieldToBoostFactor(boostFields);
       fieldNames = boostFields.keySet().toArray(new String[0]);
     } else {
       ArrayList<String> fields = new ArrayList();
@@ -142,29 +141,7 @@ public class CloudMLTQParser extends QParser {
     }
 
     try {
-      Query rawMLTQuery = mlt.like(filteredDocument);
-      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;
-
-      if (boost && boostFields.size() > 0) {
-        BooleanQuery.Builder newQ = new BooleanQuery.Builder();
-        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());
-
-        for (BooleanClause clause : boostedMLTQuery) {
-          Query q = clause.getQuery();
-          float originalBoost = 1f;
-          if (q instanceof BoostQuery) {
-            BoostQuery bq = (BoostQuery) q;
-            q = bq.getQuery();
-            originalBoost = bq.getBoost();
-          }
-          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());
-          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());
-          newQ.add(q, clause.getOccur());
-        }
-
-        boostedMLTQuery = QueryUtils.build(newQ, this);
-      }
-
+      Query boostedMLTQuery = mlt.like(filteredDocument);
       // exclude current document from results
       BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();
       realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);
diff --git a/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java b/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
index 4a3400b70f..da14072aff 100644
--- a/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java
@@ -18,9 +18,9 @@ package org.apache.solr.search.mlt;
 import org.apache.lucene.index.Term;
 import org.apache.solr.legacy.LegacyNumericUtils;
 import org.apache.lucene.queries.mlt.MoreLikeThis;
+import org.apache.lucene.queries.mlt.MoreLikeThisParameters;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TermQuery;
@@ -33,7 +33,6 @@ import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.QParser;
 import org.apache.solr.search.QueryParsing;
-import org.apache.solr.search.QueryUtils;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.SolrPluginUtils;
 
@@ -69,16 +68,16 @@ public class SimpleMLTQParser extends QParser {
           "document with id [" + uniqueValue + "]");
       ScoreDoc[] scoreDocs = td.scoreDocs;
       MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());
-      
-      mlt.setMinTermFreq(localParams.getInt("mintf", MoreLikeThis.DEFAULT_MIN_TERM_FREQ));
-      mlt.setMinDocFreq(localParams.getInt("mindf", MoreLikeThis.DEFAULT_MIN_DOC_FREQ));
-      mlt.setMinWordLen(localParams.getInt("minwl", MoreLikeThis.DEFAULT_MIN_WORD_LENGTH));
-      mlt.setMaxWordLen(localParams.getInt("maxwl", MoreLikeThis.DEFAULT_MAX_WORD_LENGTH));
-      mlt.setMaxQueryTerms(localParams.getInt("maxqt", MoreLikeThis.DEFAULT_MAX_QUERY_TERMS));
-      mlt.setMaxNumTokensParsed(localParams.getInt("maxntp", MoreLikeThis.DEFAULT_MAX_NUM_TOKENS_PARSED));
-      mlt.setMaxDocFreq(localParams.getInt("maxdf", MoreLikeThis.DEFAULT_MAX_DOC_FREQ));
-      Boolean boost = localParams.getBool("boost", false);
-      mlt.setBoost(boost);
+      MoreLikeThisParameters.BoostProperties boostConfiguration = mlt.getBoostConfiguration();
+
+      mlt.setMinTermFreq(localParams.getInt("mintf", MoreLikeThisParameters.DEFAULT_MIN_TERM_FREQ));
+      mlt.setMinDocFreq(localParams.getInt("mindf", MoreLikeThisParameters.DEFAULT_MIN_DOC_FREQ));
+      mlt.setMinWordLen(localParams.getInt("minwl", MoreLikeThisParameters.DEFAULT_MIN_WORD_LENGTH));
+      mlt.setMaxWordLen(localParams.getInt("maxwl", MoreLikeThisParameters.DEFAULT_MAX_WORD_LENGTH));
+      mlt.setMaxQueryTerms(localParams.getInt("maxqt", MoreLikeThisParameters.DEFAULT_MAX_QUERY_TERMS));
+      mlt.setMaxNumTokensParsed(localParams.getInt("maxntp", MoreLikeThisParameters.DEFAULT_MAX_NUM_TOKENS_PARSED));
+      mlt.setMaxDocFreq(localParams.getInt("maxdf", MoreLikeThisParameters.DEFAULT_MAX_DOC_FREQ));
+      boostConfiguration.setBoost(localParams.getBool("boost", MoreLikeThisParameters.BoostProperties.DEFAULT_BOOST));
 
       String[] fieldNames;
       
@@ -96,6 +95,7 @@ public class SimpleMLTQParser extends QParser {
         }
         // Parse field names and boosts from the fields
         boostFields = SolrPluginUtils.parseFieldBoosts(fields.toArray(new String[0]));
+        boostConfiguration.setFieldToBoostFactor(boostFields);
         fieldNames = boostFields.keySet().toArray(new String[0]);
       } else {
         Map<String, SchemaField> fieldDefinitions = req.getSearcher().getSchema().getFields();
@@ -115,29 +115,7 @@ public class SimpleMLTQParser extends QParser {
       mlt.setFieldNames(fieldNames);
       mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());
 
-      Query rawMLTQuery = mlt.like(scoreDocs[0].doc);
-      BooleanQuery boostedMLTQuery = (BooleanQuery) rawMLTQuery;
-
-      if (boost && boostFields.size() > 0) {
-        BooleanQuery.Builder newQ = new BooleanQuery.Builder();
-        newQ.setMinimumNumberShouldMatch(boostedMLTQuery.getMinimumNumberShouldMatch());
-
-        for (BooleanClause clause : boostedMLTQuery) {
-          Query q = clause.getQuery();
-          float originalBoost = 1f;
-          if (q instanceof BoostQuery) {
-            BoostQuery bq = (BoostQuery) q;
-            q = bq.getQuery();
-            originalBoost = bq.getBoost();
-          }
-          Float fieldBoost = boostFields.get(((TermQuery) q).getTerm().field());
-          q = ((fieldBoost != null) ? new BoostQuery(q, fieldBoost * originalBoost) : clause.getQuery());
-          newQ.add(q, clause.getOccur());
-        }
-
-        boostedMLTQuery = QueryUtils.build(newQ, this);
-      }
-
+      Query boostedMLTQuery = mlt.like(scoreDocs[0].doc);
       // exclude current document from results
       BooleanQuery.Builder realMLTQuery = new BooleanQuery.Builder();
       realMLTQuery.add(boostedMLTQuery, BooleanClause.Occur.MUST);
diff --git a/solr/core/src/test/org/apache/solr/handler/MoreLikeThisHandlerTest.java b/solr/core/src/test/org/apache/solr/handler/MoreLikeThisHandlerTest.java
index 6b80014c0f..a256a061f5 100644
--- a/solr/core/src/test/org/apache/solr/handler/MoreLikeThisHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/MoreLikeThisHandlerTest.java
@@ -109,7 +109,6 @@ public class MoreLikeThisHandlerTest extends SolrTestCaseJ4 {
     params.set(CommonParams.DEBUG_QUERY, "true");
     try (SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params)) {
       assertQ("morelike this - harrison ford", mltreq,
-          "//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='rawMLTQuery']",
           "//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='boostedMLTQuery']",
           "//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='realMLTQuery']",
           "//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/lst[@name='explain']/str[@name='45']"
diff --git a/solr/core/src/test/org/apache/solr/handler/component/MoreLikeThisComponentTest.java b/solr/core/src/test/org/apache/solr/handler/component/MoreLikeThisComponentTest.java
new file mode 100644
index 0000000000..326b6b95d8
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/handler/component/MoreLikeThisComponentTest.java
@@ -0,0 +1,283 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.handler.component;
+
+import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.MoreLikeThisParams;
+import org.apache.solr.core.SolrCore;
+import org.apache.solr.request.LocalSolrQueryRequest;
+import org.apache.solr.request.SolrQueryRequest;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+/**
+ * Test for MoreLikeThisComponent
+ *
+ *
+ * @see MoreLikeThisComponent
+ */
+@Slow
+public class MoreLikeThisComponentTest extends SolrTestCaseJ4 {
+
+  @BeforeClass
+  public static void moreLikeThisBeforeClass() throws Exception {
+    initCore("solrconfig.xml", "schema.xml");
+    assertU(adoc("id","42","name","Tom Cruise","subword","Top Gun","subword","Risky Business","subword","The Color of Money","subword","Minority Report","subword", "Days of Thunder","subword", "Eyes Wide Shut","subword", "Far and Away", "foo_ti","10"));
+    assertU(adoc("id","43","name","Tom Hanks","subword","The Green Mile","subword","Forest Gump","subword","Philadelphia Story","subword","Big","subword","Cast Away", "foo_ti","10"));
+    assertU(adoc("id","44","name","Harrison Ford","subword","Star Wars","subword","Indiana Jones","subword","Patriot Games","subword","Regarding Henry"));
+    assertU(adoc("id","45","name","George Harrison","subword","Yellow Submarine","subword","Help","subword","Magical Mystery Tour","subword","Sgt. Peppers Lonley Hearts Club Band"));
+    assertU(adoc("id","46","name","Nicole Kidman","subword","Batman","subword","Days of Thunder","subword","Eyes Wide Shut","subword","Far and Away"));
+    assertU(commit());
+  }
+  
+  private void initCommonMoreLikeThisParams(ModifiableSolrParams params) {
+    params.set(MoreLikeThisParams.MLT, "true");
+    params.set(MoreLikeThisParams.SIMILARITY_FIELDS, "name,subword");
+    params.set(MoreLikeThisParams.MIN_TERM_FREQ,"1");
+    params.set(MoreLikeThisParams.MIN_DOC_FREQ,"1");
+    params.set("indent","true");
+  }
+
+  @Test
+  public void testMLT_baseParams_shouldReturnSimilarDocuments()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']");
+
+    params.set(CommonParams.Q, "id:44");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelike this - harrison ford",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='45']");
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_baseParamsInterestingTermsDetails_shouldReturnSimilarDocumentsAndInterestingTermsDetails()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "details");
+    
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']",
+        "//lst[@name='interestingTerms']/lst[1][count(*)>0]",
+        "//lst[@name='interestingTerms']/lst[1]/float[.=1.0]");
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_baseParamsInterestingTermsList_shouldReturnSimilarDocumentsAndInterestingTermsList()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "list");
+
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']",
+        "//lst[@name='interestingTerms']/arr[@name='42'][count(*)>0]",
+        "//lst[@name='interestingTerms']/arr[@name='42']/str[.='name:Cruise']");
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_boostEnabled_shouldReturnSimilarDocumentsConsideringBoost()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']");
+
+    params.set(CommonParams.Q, "id:42");
+    params.set(MoreLikeThisParams.QF,"name^5.0 subword^0.1");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelikethis with weights",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='43']"
+        ,"//result/doc[2]/str[@name='id'][.='46']");
+
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_boostEnabledInterestingTermsDetails_shouldReturnSimilarDocumentsConsideringBoostAndInterestingTermsDetails()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "details");
+    
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']",
+        "//lst[@name='interestingTerms']/lst[1][count(*)>0]",
+        "//lst[@name='interestingTerms']/lst[1]/float[.>1.0]");
+    
+    params.set(MoreLikeThisParams.QF,"name^5.0 subword^0.1");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelikethis with weights",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='43']"
+        ,"//result/doc[2]/str[@name='id'][.='46']",
+        "//lst[@name='interestingTerms']/lst[1][count(*)>0]",
+        "//lst[@name='interestingTerms']/lst[1]/float[.>5.0]");
+
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_boostEnabledInterestingTermsList_shouldReturnSimilarDocumentsConsideringBoostAndInterestingTermsList()
+  {
+    SolrCore core = h.getCore();
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "list");
+
+    params.set(CommonParams.Q, "id:42");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest( core, params);
+    assertQ("morelikethis - tom cruise",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='46']"
+        ,"//result/doc[2]/str[@name='id'][.='43']",
+        "//lst[@name='interestingTerms']/arr[@name='42'][count(*)>0]",
+        "//lst[@name='interestingTerms']/arr[@name='42']/str[.='name:Cruise']");
+
+    params.set(MoreLikeThisParams.QF,"name^5.0 subword^0.1");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelikethis with weights",mltreq
+        ,"//result/doc[1]/str[@name='id'][.='43']"
+        ,"//result/doc[2]/str[@name='id'][.='46']",
+        "//lst[@name='interestingTerms']/arr[@name='42'][count(*)>0]",
+        "//lst[@name='interestingTerms']/arr[@name='42']/str[.='name:Cruise']");
+
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_debugEnabled_shouldReturnSimilarDocumentsWithDebug()
+  {
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+
+    params.set(CommonParams.Q, "id:44");
+    params.set(CommonParams.DEBUG_QUERY, "true");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelike this - harrison ford",mltreq
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='boostedMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='realMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/lst[@name='explain']/str[@name='45']"
+    );
+    
+    params.remove(CommonParams.DEBUG_QUERY);
+    params.set(CommonParams.Q, "{!field f=id}44");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ(mltreq
+        ,"//result/doc[1]/str[@name='id'][.='45']");
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_debugEnabledInterestingTermsDetails_shouldReturnSimilarDocumentsWithDebugAndInterestingTermsDetails()
+  {
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "details");
+
+    params.set(CommonParams.Q, "id:44");
+    params.set(CommonParams.DEBUG_QUERY, "true");
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelike this - harrison ford",mltreq
+        , "//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='boostedMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='realMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/lst[@name='explain']/str[@name='45']",
+        "//lst[@name='interestingTerms']/lst[1][count(*)>0]",
+        "//lst[@name='interestingTerms']/lst[1]/float[.>1.0]");
+
+    params.remove(CommonParams.DEBUG_QUERY);
+    params.set(CommonParams.Q, "{!field f=id}44");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ(mltreq
+        ,"//result/doc[1]/str[@name='id'][.='45']",
+        "//lst[@name='interestingTerms']/lst[1][count(*)>0]",
+        "//lst[@name='interestingTerms']/lst[1]/float[.>1.0]");
+    mltreq.close();
+  }
+
+  @Test
+  public void testMLT_debugEnabledInterestingTermsList_shouldReturnSimilarDocumentsWithDebugAndInterestingTermsList()
+  {
+    ModifiableSolrParams params = new ModifiableSolrParams();
+
+    initCommonMoreLikeThisParams(params);
+    params.set(MoreLikeThisParams.BOOST, "true");
+    params.set(MoreLikeThisParams.INTERESTING_TERMS, "list");
+
+    params.set(CommonParams.Q, "id:44");
+    params.set(CommonParams.DEBUG_QUERY, "true");
+    
+    SolrQueryRequest mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ("morelike this - harrison ford",mltreq
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='boostedMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/str[@name='realMLTQuery']"
+        ,"//lst[@name='debug']/lst[@name='moreLikeThis']/lst[@name='44']/lst[@name='explain']/str[@name='45']",
+        "//lst[@name='interestingTerms']/arr[@name='44'][count(*)>0]",
+        "//lst[@name='interestingTerms']/arr[@name='44']/str[.='name:Harrison']");
+
+    params.remove(CommonParams.DEBUG_QUERY);
+    params.set(CommonParams.Q, "{!field f=id}44");
+    mltreq.close(); mltreq = new LocalSolrQueryRequest(h.getCore(), params);
+    assertQ(mltreq
+        ,"//result/doc[1]/str[@name='id'][.='45']",
+        "//lst[@name='interestingTerms']/arr[@name='44'][count(*)>0]",
+        "//lst[@name='interestingTerms']/arr[@name='44']/str[.='name:Harrison']");
+    mltreq.close();
+  }
+}
