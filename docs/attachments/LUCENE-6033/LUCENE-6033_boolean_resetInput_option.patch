Index: lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(revision 1645984)
+++ lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(revision )
@@ -19,14 +19,15 @@
 
 
 import java.io.IOException;
+import java.util.concurrent.atomic.AtomicInteger;
 
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.store.Directory;
@@ -39,12 +40,19 @@
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
     Document doc = new Document();
+    AtomicInteger resetCount = new AtomicInteger(0);
     TokenStream stream = new TokenStream() {
       private int index = 0;
       private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-      
+
       @Override
+      public void reset() throws IOException {
+        super.reset();
+        resetCount.incrementAndGet();
+      }
+
+      @Override
       public boolean incrementToken() {
         if (index == tokens.length) {
           return false;
@@ -57,11 +65,14 @@
       }
       
     };
+    final boolean passReset = random().nextBoolean();
+    stream = new CachingTokenFilter(stream, passReset);
     
-    stream = new CachingTokenFilter(stream);
-    
     doc.add(new TextField("preanalyzed", stream));
-    
+
+    stream.reset();//does nothing
+    assertFalse(((CachingTokenFilter)stream).isCached());
+
     // 1) we consume all tokens twice before we add the doc to the index
     checkTokens(stream);
     stream.reset();  
@@ -101,6 +112,15 @@
     // 3) reset stream and consume tokens again
     stream.reset();
     checkTokens(stream);
+
+    if (passReset) {
+      assertEquals(1, resetCount.get());
+    } else {
+      assertEquals(0, resetCount.get());
+    }
+
+    assertTrue(((CachingTokenFilter)stream).isCached());
+
     dir.close();
   }
   
Index: lucene/core/src/java/org/apache/lucene/analysis/CachingTokenFilter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/CachingTokenFilter.java	(revision 1645984)
+++ lucene/core/src/java/org/apache/lucene/analysis/CachingTokenFilter.java	(revision )
@@ -35,17 +35,27 @@
  * stream to the first Token. 
  */
 public final class CachingTokenFilter extends TokenFilter {
+  private boolean resetInput;
   private List<AttributeSource.State> cache = null;
   private Iterator<AttributeSource.State> iterator = null; 
   private AttributeSource.State finalState;
   
   /**
-   * Create a new CachingTokenFilter around <code>input</code>,
-   * caching its token attributes, which can be replayed again
-   * after a call to {@link #reset()}.
+   * Create a new CachingTokenFilter around <code>input</code>, which is
+   * assumed to have already been reset.
    */
   public CachingTokenFilter(TokenStream input) {
+    this(input, false);
+  }
+
+  /**
+   * Allows specifying whether whether the <em>first</em> call to
+   * {@link #incrementToken()} should invoke {@link #reset()} on {@code input}.
+   * It won't happen otherwise.
+   */
+  public CachingTokenFilter(TokenStream input, boolean resetInput) {
     super(input);
+    this.resetInput = resetInput;
   }
   
   @Override
@@ -74,11 +84,9 @@
   }
 
   /**
-   * Rewinds the iterator to the beginning of the cached list.
-   * <p>
-   * Note that this does not call reset() on the wrapped tokenstream ever, even
-   * the first time. You should reset() the inner tokenstream before wrapping
-   * it with CachingTokenFilter.
+   * Rewinds the iterator to the beginning of the cached list.  This method
+   * won't propagate reset to the input but the first call to incrementToken
+   * will if this class was constructed with {@code inputWasReset}=false.
    */
   @Override
   public void reset() {
@@ -88,6 +96,9 @@
   }
   
   private void fillCache() throws IOException {
+    if (resetInput) {
+      input.reset();
+    }
     while (input.incrementToken()) {
       cache.add(captureState());
     }
