Index: src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 825165)
+++ src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -231,96 +231,83 @@
   }
   
   public void testPayloadsPos0() throws Exception {
-    for(int x=0;x<2;x++) {
-      Directory dir = new MockRAMDirectory();
-      IndexWriter writer = new IndexWriter(dir,
-                                           new TestPayloadAnalyzer(), true,
-                                           IndexWriter.MaxFieldLength.LIMITED);
-      if (x == 1) {
-        writer.setAllowMinus1Position();
-      }
-      Document doc = new Document();
-      doc.add(new Field("content",
-                        new StringReader("a a b c d e a f g h i j a b k k")));
-      writer.addDocument(doc);
+    Directory dir = new MockRAMDirectory();
+    IndexWriter writer = new IndexWriter(dir,
+                                         new TestPayloadAnalyzer(), true,
+                                         IndexWriter.MaxFieldLength.LIMITED);
+    Document doc = new Document();
+    doc.add(new Field("content",
+                      new StringReader("a a b c d e a f g h i j a b k k")));
+    writer.addDocument(doc);
 
-      IndexReader r = writer.getReader();
+    IndexReader r = writer.getReader();
 
-      TermPositions tp = r.termPositions(new Term("content", "a"));
-      int count = 0;
-      assertTrue(tp.next());
-      // "a" occurs 4 times
-      assertEquals(4, tp.freq());
-      int expected;
-      if (x == 1) {
-        expected = Integer.MAX_VALUE;
-      } else {
-        expected = 0;
-      }
-      assertEquals(expected, tp.nextPosition());
-      if (x == 1) {
-        continue;
-      }
-      assertEquals(1, tp.nextPosition());
-      assertEquals(3, tp.nextPosition());
-      assertEquals(6, tp.nextPosition());
+    TermPositions tp = r.termPositions(new Term("content", "a"));
+    int count = 0;
+    assertTrue(tp.next());
+    // "a" occurs 4 times
+    assertEquals(4, tp.freq());
+    int expected = 0;
+    assertEquals(expected, tp.nextPosition());
+    assertEquals(1, tp.nextPosition());
+    assertEquals(3, tp.nextPosition());
+    assertEquals(6, tp.nextPosition());
 
-      // only one doc has "a"
-      assertFalse(tp.next());
+    // only one doc has "a"
+    assertFalse(tp.next());
 
-      IndexSearcher is = new IndexSearcher(r);
-    
-      SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
-      SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
-      SpanQuery[] sqs = { stq1, stq2 };
-      SpanNearQuery snq = new SpanNearQuery(sqs, 30, false);
+    IndexSearcher is = new IndexSearcher(r);
+  
+    SpanTermQuery stq1 = new SpanTermQuery(new Term("content", "a"));
+    SpanTermQuery stq2 = new SpanTermQuery(new Term("content", "k"));
+    SpanQuery[] sqs = { stq1, stq2 };
+    SpanNearQuery snq = new SpanNearQuery(sqs, 30, false);
 
-      count = 0;
-      boolean sawZero = false;
-      //System.out.println("\ngetPayloadSpans test");
-      Spans pspans = snq.getSpans(is.getIndexReader());
-      while (pspans.next()) {
-        //System.out.println(pspans.doc() + " - " + pspans.start() + " - "+ pspans.end());
-        Collection payloads = pspans.getPayload();
-        sawZero |= pspans.start() == 0;
-        for (Iterator it = payloads.iterator(); it.hasNext();) {
-          count++;
-          it.next();
-          //System.out.println(new String((byte[]) it.next()));
-        }
-      }
-      assertEquals(5, count);
-      assertTrue(sawZero);
-
-      //System.out.println("\ngetSpans test");
-      Spans spans = snq.getSpans(is.getIndexReader());
-      count = 0;
-      sawZero = false;
-      while (spans.next()) {
+    count = 0;
+    boolean sawZero = false;
+    //System.out.println("\ngetPayloadSpans test");
+    Spans pspans = snq.getSpans(is.getIndexReader());
+    while (pspans.next()) {
+      //System.out.println(pspans.doc() + " - " + pspans.start() + " - "+ pspans.end());
+      Collection payloads = pspans.getPayload();
+      sawZero |= pspans.start() == 0;
+      for (Iterator it = payloads.iterator(); it.hasNext();) {
         count++;
-        sawZero |= spans.start() == 0;
-        //System.out.println(spans.doc() + " - " + spans.start() + " - " + spans.end());
+        it.next();
+        //System.out.println(new String((byte[]) it.next()));
       }
-      assertEquals(4, count);
-      assertTrue(sawZero);
-		
-      //System.out.println("\nPayloadSpanUtil test");
+    }
+    assertEquals(5, count);
+    assertTrue(sawZero);
 
-      sawZero = false;
-      PayloadSpanUtil psu = new PayloadSpanUtil(is.getIndexReader());
-      Collection pls = psu.getPayloadsForQuery(snq);
-      count = pls.size();
-      for (Iterator it = pls.iterator(); it.hasNext();) {
-        String s = new String((byte[]) it.next());
-        //System.out.println(s);
-        sawZero |= s.equals("pos: 0");
-      }
-      assertEquals(5, count);
-      assertTrue(sawZero);
-      writer.close();
-      is.getIndexReader().close();
-      dir.close();
+    //System.out.println("\ngetSpans test");
+    Spans spans = snq.getSpans(is.getIndexReader());
+    count = 0;
+    sawZero = false;
+    while (spans.next()) {
+      count++;
+      sawZero |= spans.start() == 0;
+      //System.out.println(spans.doc() + " - " + spans.start() + " - " + spans.end());
     }
+    assertEquals(4, count);
+    assertTrue(sawZero);
+  
+    //System.out.println("\nPayloadSpanUtil test");
+
+    sawZero = false;
+    PayloadSpanUtil psu = new PayloadSpanUtil(is.getIndexReader());
+    Collection pls = psu.getPayloadsForQuery(snq);
+    count = pls.size();
+    for (Iterator it = pls.iterator(); it.hasNext();) {
+      String s = new String((byte[]) it.next());
+      //System.out.println(s);
+      sawZero |= s.equals("pos: 0");
+    }
+    assertEquals(5, count);
+    assertTrue(sawZero);
+    writer.close();
+    is.getIndexReader().close();
+    dir.close();
   }
 }
 
Index: src/test/org/apache/lucene/index/TestIndexReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReader.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexReader.java	(working copy)
@@ -1762,7 +1762,7 @@
     }
     assertFalse(((SegmentReader) r.getSequentialSubReaders()[0]).termsIndexLoaded());
 
-    assertEquals(-1, r.getTermInfosIndexDivisor());
+    assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
     writer = new IndexWriter(dir, new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
     writer.addDocument(doc);
     writer.close();
Index: src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -100,7 +100,7 @@
         for (i = 0; i < 100; i++) {
             addDoc(writer);
         }
-        assertEquals(100, writer.docCount());
+        assertEquals(100, writer.maxDoc());
         writer.close();
 
         // delete 40 documents
@@ -112,7 +112,7 @@
 
         // test doc count before segments are merged/index is optimized
         writer = new IndexWriter(dir, new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
-        assertEquals(100, writer.docCount());
+        assertEquals(100, writer.maxDoc());
         writer.close();
 
         reader = IndexReader.open(dir, true);
@@ -160,7 +160,7 @@
 
     /*
       Test: make sure when we run out of disk space or hit
-      random IOExceptions in any of the addIndexes(*) calls
+      random IOExceptions in any of the addIndexesNoOptimize(*) calls
       that 1) index is not corrupt (searcher can open/search
       it) and 2) transactional semantics are followed:
       either all or none of the incoming documents were in
@@ -175,7 +175,7 @@
       boolean debug = false;
 
       // Build up a bunch of dirs that have indexes which we
-      // will then merge together by calling addIndexes(*):
+      // will then merge together by calling addIndexesNoOptimize(*):
       Directory[] dirs = new Directory[NUM_DIR];
       long inputDiskUsage = 0;
       for(int i=0;i<NUM_DIR;i++) {
@@ -192,7 +192,7 @@
       }
 
       // Now, build a starting index that has START_COUNT docs.  We
-      // will then try to addIndexes into a copy of this:
+      // will then try to addIndexesNoOptimize into a copy of this:
       RAMDirectory startDir = new RAMDirectory();
       IndexWriter writer = new IndexWriter(startDir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
       for(int j=0;j<START_COUNT;j++) {
@@ -213,12 +213,12 @@
 
       // Iterate with larger and larger amounts of free
       // disk space.  With little free disk space,
-      // addIndexes will certainly run out of space &
+      // addIndexesNoOptimize will certainly run out of space &
       // fail.  Verify that when this happens, index is
       // not corrupt and index in fact has added no
       // documents.  Then, we increase disk space by 2000
       // bytes each iteration.  At some point there is
-      // enough free disk space and addIndexes should
+      // enough free disk space and addIndexesNoOptimize should
       // succeed and index should show all documents were
       // added.
 
@@ -246,7 +246,7 @@
 
         String methodName;
         if (0 == method) {
-          methodName = "addIndexes(Directory[])";
+          methodName = "addIndexes(Directory[]) + optimize()";
         } else if (1 == method) {
           methodName = "addIndexes(IndexReader[])";
         } else {
@@ -310,7 +310,8 @@
             try {
 
               if (0 == method) {
-                writer.addIndexes(dirs);
+                writer.addIndexesNoOptimize(dirs);
+                writer.optimize();
               } else if (1 == method) {
                 IndexReader readers[] = new IndexReader[dirs.length];
                 for(int i=0;i<dirs.length;i++) {
@@ -492,7 +493,7 @@
 
           if (hitError) {
             if (doAbort) {
-              writer.abort();
+              writer.rollback();
             } else {
               try {
                 writer.close();
@@ -743,7 +744,7 @@
 
           // now open index for create:
           writer = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
-          assertEquals("should be zero documents", writer.docCount(), 0);
+          assertEquals("should be zero documents", writer.maxDoc(), 0);
           addDoc(writer);
           writer.close();
 
@@ -1005,9 +1006,9 @@
       searcher.close();
 
       // Now, close the writer:
-      writer.abort();
+      writer.rollback();
 
-      assertNoUnreferencedFiles(dir, "unreferenced files remain after abort()");
+      assertNoUnreferencedFiles(dir, "unreferenced files remain after rollback()");
 
       searcher = new IndexSearcher(dir, false);
       hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;
@@ -1089,7 +1090,7 @@
 
     /*
      * Verify that calling optimize when writer is open for
-     * "commit on close" works correctly both for abort()
+     * "commit on close" works correctly both for rollback()
      * and close().
      */
     public void testCommitOnCloseOptimize() throws IOException {
@@ -1113,7 +1114,7 @@
       reader.close();
 
       // Abort the writer:
-      writer.abort();
+      writer.rollback();
       assertNoUnreferencedFiles(dir, "aborted writer after optimize");
 
       // Open a reader after aborting writer:
@@ -2478,25 +2479,25 @@
   }
 
   // LUCENE-1130: make sure initial IOException, and then 2nd
-  // IOException during abort(), is OK:
+  // IOException during rollback(), is OK:
   public void testIOExceptionDuringAbort() throws IOException {
     _testSingleThreadFailure(new FailOnlyOnAbortOrFlush(false));
   }
 
   // LUCENE-1130: make sure initial IOException, and then 2nd
-  // IOException during abort(), is OK:
+  // IOException during rollback(), is OK:
   public void testIOExceptionDuringAbortOnlyOnce() throws IOException {
     _testSingleThreadFailure(new FailOnlyOnAbortOrFlush(true));
   }
 
   // LUCENE-1130: make sure initial IOException, and then 2nd
-  // IOException during abort(), with multiple threads, is OK:
+  // IOException during rollback(), with multiple threads, is OK:
   public void testIOExceptionDuringAbortWithThreads() throws Exception {
     _testMultipleThreadsFailure(new FailOnlyOnAbortOrFlush(false));
   }
 
   // LUCENE-1130: make sure initial IOException, and then 2nd
-  // IOException during abort(), with multiple threads, is OK:
+  // IOException during rollback(), with multiple threads, is OK:
   public void testIOExceptionDuringAbortWithThreadsOnlyOnce() throws Exception {
     _testMultipleThreadsFailure(new FailOnlyOnAbortOrFlush(true));
   }
@@ -2776,7 +2777,8 @@
       writer.setMergePolicy(new LogDocMergePolicy(writer));
 
       Directory[] indexDirs = {new MockRAMDirectory(dir)};
-      writer.addIndexes(indexDirs);
+      writer.addIndexesNoOptimize(indexDirs);
+      writer.optimize();
       writer.close();
     }
     dir.close();
@@ -3229,7 +3231,7 @@
       // Expected
     }
     assertTrue(failure.fail1 && failure.fail2);
-    w.abort();
+    w.rollback();
     dir.close();
   }
   
@@ -3718,7 +3720,8 @@
     void doBody(int j, Directory[] dirs) throws Throwable {
       switch(j%4) {
       case 0:
-        writer2.addIndexes(dirs);
+        writer2.addIndexesNoOptimize(dirs);
+        writer2.optimize();
         break;
       case 1:
         writer2.addIndexesNoOptimize(dirs);
@@ -3804,7 +3807,8 @@
     void doBody(int j, Directory[] dirs) throws Throwable {
       switch(j%5) {
       case 0:
-        writer2.addIndexes(dirs);
+        writer2.addIndexesNoOptimize(dirs);
+        writer2.optimize();
         break;
       case 1:
         writer2.addIndexesNoOptimize(dirs);
Index: src/test/org/apache/lucene/index/TestAddIndexesNoOptimize.java
===================================================================
--- src/test/org/apache/lucene/index/TestAddIndexesNoOptimize.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestAddIndexesNoOptimize.java	(working copy)
@@ -43,27 +43,27 @@
     writer = newWriter(dir, true);
     // add 100 documents
     addDocs(writer, 100);
-    assertEquals(100, writer.docCount());
+    assertEquals(100, writer.maxDoc());
     writer.close();
 
     writer = newWriter(aux, true);
     writer.setUseCompoundFile(false); // use one without a compound file
     // add 40 documents in separate files
     addDocs(writer, 40);
-    assertEquals(40, writer.docCount());
+    assertEquals(40, writer.maxDoc());
     writer.close();
 
     writer = newWriter(aux2, true);
     // add 40 documents in compound files
     addDocs2(writer, 50);
-    assertEquals(50, writer.docCount());
+    assertEquals(50, writer.maxDoc());
     writer.close();
 
     // test doc count before segments are merged
     writer = newWriter(dir, false);
-    assertEquals(100, writer.docCount());
+    assertEquals(100, writer.maxDoc());
     writer.addIndexesNoOptimize(new Directory[] { aux, aux2 });
-    assertEquals(190, writer.docCount());
+    assertEquals(190, writer.maxDoc());
     writer.close();
 
     // make sure the old index is correct
@@ -77,14 +77,14 @@
     writer = newWriter(aux3, true);
     // add 40 documents
     addDocs(writer, 40);
-    assertEquals(40, writer.docCount());
+    assertEquals(40, writer.maxDoc());
     writer.close();
 
     // test doc count before segments are merged/index is optimized
     writer = newWriter(dir, false);
-    assertEquals(190, writer.docCount());
+    assertEquals(190, writer.maxDoc());
     writer.addIndexesNoOptimize(new Directory[] { aux3 });
-    assertEquals(230, writer.docCount());
+    assertEquals(230, writer.maxDoc());
     writer.close();
 
     // make sure the new index is correct
@@ -113,9 +113,9 @@
     writer.close();
 
     writer = newWriter(dir, false);
-    assertEquals(230, writer.docCount());
+    assertEquals(230, writer.maxDoc());
     writer.addIndexesNoOptimize(new Directory[] { aux4 });
-    assertEquals(231, writer.docCount());
+    assertEquals(231, writer.maxDoc());
     writer.close();
 
     verifyNumDocs(dir, 231);
@@ -250,7 +250,7 @@
     writer = newWriter(dir, true);
     // add 100 documents
     addDocs(writer, 100);
-    assertEquals(100, writer.docCount());
+    assertEquals(100, writer.maxDoc());
     writer.close();
 
     writer = newWriter(aux, true);
@@ -272,7 +272,7 @@
       assertTrue(false);
     }
     catch (IllegalArgumentException e) {
-      assertEquals(100, writer.docCount());
+      assertEquals(100, writer.maxDoc());
     }
     writer.close();
 
@@ -297,7 +297,7 @@
     addDocs(writer, 10);
 
     writer.addIndexesNoOptimize(new Directory[] { aux });
-    assertEquals(1040, writer.docCount());
+    assertEquals(1040, writer.maxDoc());
     assertEquals(2, writer.getSegmentCount());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -321,7 +321,7 @@
     addDocs(writer, 2);
 
     writer.addIndexesNoOptimize(new Directory[] { aux });
-    assertEquals(1032, writer.docCount());
+    assertEquals(1032, writer.maxDoc());
     assertEquals(2, writer.getSegmentCount());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -344,7 +344,7 @@
     writer.setMergeFactor(4);
 
     writer.addIndexesNoOptimize(new Directory[] { aux, new RAMDirectory(aux) });
-    assertEquals(1060, writer.docCount());
+    assertEquals(1060, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
 
@@ -373,7 +373,7 @@
     writer.setMergeFactor(4);
 
     writer.addIndexesNoOptimize(new Directory[] { aux, new RAMDirectory(aux) });
-    assertEquals(1020, writer.docCount());
+    assertEquals(1020, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
 
@@ -395,7 +395,7 @@
     writer.setMaxBufferedDocs(100);
     writer.setMergeFactor(10);
     writer.addIndexesNoOptimize(new Directory[] { aux });
-    assertEquals(30, writer.docCount());
+    assertEquals(30, writer.maxDoc());
     assertEquals(3, writer.getSegmentCount());
     writer.close();
 
@@ -418,7 +418,7 @@
     writer.setMergeFactor(4);
 
     writer.addIndexesNoOptimize(new Directory[] { aux, aux2 });
-    assertEquals(1025, writer.docCount());
+    assertEquals(1025, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
 
@@ -476,7 +476,7 @@
     writer.setMaxBufferedDocs(1000);
     // add 1000 documents in 1 segment
     addDocs(writer, 1000);
-    assertEquals(1000, writer.docCount());
+    assertEquals(1000, writer.maxDoc());
     assertEquals(1, writer.getSegmentCount());
     writer.close();
 
@@ -493,7 +493,7 @@
       writer.setMaxBufferedDocs(100);
       writer.setMergeFactor(10);
     }
-    assertEquals(30, writer.docCount());
+    assertEquals(30, writer.maxDoc());
     assertEquals(3, writer.getSegmentCount());
     writer.close();
   }
Index: src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(working copy)
@@ -119,7 +119,8 @@
         IndexWriter.MaxFieldLength.LIMITED);
     iw.setMaxBufferedDocs(5);
     iw.setMergeFactor(3);
-    iw.addIndexes(new Directory[] { dir1, dir2 });
+    iw.addIndexesNoOptimize(new Directory[] { dir1, dir2 });
+    iw.optimize();
     iw.close();
 
     norms1.addAll(norms);
Index: src/test/org/apache/lucene/index/TestCrash.java
===================================================================
--- src/test/org/apache/lucene/index/TestCrash.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestCrash.java	(working copy)
@@ -82,7 +82,7 @@
     MockRAMDirectory dir = (MockRAMDirectory) writer.getDirectory();
     writer.close();
     writer = initIndex(dir);
-    assertEquals(314, writer.docCount());
+    assertEquals(314, writer.maxDoc());
     crash(writer);
 
     /*
Index: src/test/org/apache/lucene/index/TestThreadedOptimize.java
===================================================================
--- src/test/org/apache/lucene/index/TestThreadedOptimize.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestThreadedOptimize.java	(working copy)
@@ -73,8 +73,6 @@
       writer.setMergeFactor(4);
       //writer.setInfoStream(System.out);
 
-      final int docCount = writer.docCount();
-
       Thread[] threads = new Thread[NUM_THREADS];
       
       for(int i=0;i<NUM_THREADS;i++) {
@@ -116,7 +114,7 @@
 
       // System.out.println("TEST: now index=" + writer.segString());
 
-      assertEquals(expectedDocCount, writer.docCount());
+      assertEquals(expectedDocCount, writer.maxDoc());
 
       writer.close();
       writer = new IndexWriter(directory, ANALYZER, false, IndexWriter.MaxFieldLength.UNLIMITED);
Index: src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(working copy)
@@ -198,7 +198,7 @@
     ((ConcurrentMergeScheduler) writer.getMergeScheduler()).sync();
     writer.commit();
     checkInvariants(writer);
-    assertEquals(10, writer.docCount());
+    assertEquals(10, writer.maxDoc());
 
     writer.close();
   }
Index: src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -428,7 +428,8 @@
     void doBody(int j, Directory[] dirs) throws Throwable {
       switch (j % 4) {
         case 0:
-          mainWriter.addIndexes(dirs);
+          mainWriter.addIndexesNoOptimize(dirs);
+          mainWriter.optimize();
           break;
         case 1:
           mainWriter.addIndexesNoOptimize(dirs);
Index: src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -29,7 +29,7 @@
 {
 
   /**
-   * Tests that index merging (specifically addIndexes()) doesn't
+   * Tests that index merging (specifically addIndexesNoOptimize()) doesn't
    * change the index order of documents.
    */
   public void testLucene() throws IOException
@@ -59,7 +59,8 @@
     IndexWriter writer = new IndexWriter(merged, new StandardAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);
     writer.setMergeFactor(2);
 
-    writer.addIndexes(new Directory[]{indexA, indexB});
+    writer.addIndexesNoOptimize(new Directory[]{indexA, indexB});
+    writer.optimize();
     writer.close();
 
     fail = verifyIndex(merged, 0);
Index: src/test/org/apache/lucene/index/TestNorms.java
===================================================================
--- src/test/org/apache/lucene/index/TestNorms.java	(revision 825165)
+++ src/test/org/apache/lucene/index/TestNorms.java	(working copy)
@@ -36,7 +36,7 @@
 
 /**
  * Test that norms info is preserved during index life - including
- * separate norms, addDocument, addIndexes, optimize.
+ * separate norms, addDocument, addIndexesNoOptimize, optimize.
  */
 public class TestNorms extends LuceneTestCase {
 
@@ -112,7 +112,8 @@
     IndexWriter iw = new IndexWriter(dir3,anlzr,false, IndexWriter.MaxFieldLength.LIMITED);
     iw.setMaxBufferedDocs(5);
     iw.setMergeFactor(3);
-    iw.addIndexes(new Directory[]{dir1,dir2});
+    iw.addIndexesNoOptimize(new Directory[]{dir1,dir2});
+    iw.optimize();
     iw.close();
     
     norms1.addAll(norms);
Index: src/test/org/apache/lucene/store/TestRAMDirectory.java
===================================================================
--- src/test/org/apache/lucene/store/TestRAMDirectory.java	(revision 825165)
+++ src/test/org/apache/lucene/store/TestRAMDirectory.java	(working copy)
@@ -65,7 +65,7 @@
       doc.add(new Field("content", English.intToEnglish(i).trim(), Field.Store.YES, Field.Index.NOT_ANALYZED));
       writer.addDocument(doc);
     }
-    assertEquals(docsToAdd, writer.docCount());
+    assertEquals(docsToAdd, writer.maxDoc());
     writer.close();
     dir.close();
   }
