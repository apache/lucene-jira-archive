Index: src/java/org/apache/lucene/analysis/Token.java
===================================================================
--- src/java/org/apache/lucene/analysis/Token.java	(revision 924661)
+++ src/java/org/apache/lucene/analysis/Token.java	(working copy)
@@ -64,14 +64,14 @@
   implementing the {@link TokenStream#incrementToken()} API.
   Failing that, to create a new Token you should first use
   one of the constructors that starts with null text.  To load
-  the token from a char[] use {@link #setTermBuffer(char[], int, int)}.
-  To load from a String use {@link #setTermBuffer(String)} or {@link #setTermBuffer(String, int, int)}.
-  Alternatively you can get the Token's termBuffer by calling either {@link #termBuffer()},
+  the token from a char[] use {@link #copyBuffer(char[], int, int)}.
+  To load from a String use {@link #setEmpty} followed by {@link #append(CharSequence)} or {@link #append(CharSequence, int, int)}.
+  Alternatively you can get the Token's termBuffer by calling either {@link #buffer()},
   if you know that your text is shorter than the capacity of the termBuffer
-  or {@link #resizeTermBuffer(int)}, if there is any possibility
+  or {@link #resizeBuffer(int)}, if there is any possibility
   that you may need to grow the buffer. Fill in the characters of your term into this
   buffer, with {@link String#getChars(int, int, char[], int)} if loading from a string,
-  or with {@link System#arraycopy(Object, int, Object, int, int)}, and finally call {@link #setTermLength(int)} to
+  or with {@link System#arraycopy(Object, int, Object, int, int)}, and finally call {@link #setLength(int)} to
   set the length of the term text.  See <a target="_top"
   href="https://issues.apache.org/jira/browse/LUCENE-969">LUCENE-969</a>
   for details.</p>
@@ -100,7 +100,7 @@
   </li>
   <li> Copying from one one Token to another (type is reset to {@link #DEFAULT_TYPE} if not specified):<br/>
   <pre>
-    return reusableToken.reinit(source.termBuffer(), 0, source.termLength(), source.startOffset(), source.endOffset()[, source.type()]);
+    return reusableToken.reinit(source.buffer(), 0, source.length(), source.startOffset(), source.endOffset()[, source.type()]);
   </pre>
   </li>
   </ul>
@@ -172,7 +172,7 @@
    *  @param end end offset
    */
   public Token(String text, int start, int end) {
-    setTermBuffer(text);
+    append(text);
     startOffset = start;
     endOffset = end;
   }
@@ -187,7 +187,7 @@
    *  @param typ token type
    */
   public Token(String text, int start, int end, String typ) {
-    setTermBuffer(text);
+    append(text);
     startOffset = start;
     endOffset = end;
     type = typ;
@@ -204,7 +204,7 @@
    * @param flags token type bits
    */
   public Token(String text, int start, int end, int flags) {
-    setTermBuffer(text);
+    append(text);
     startOffset = start;
     endOffset = end;
     this.flags = flags;
@@ -221,7 +221,7 @@
    * @param end
    */
   public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {
-    setTermBuffer(startTermBuffer, termBufferOffset, termBufferLength);
+    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);
     startOffset = start;
     endOffset = end;
   }
@@ -270,7 +270,7 @@
     corresponding to this token in the source text.
 
     Note that the difference between endOffset() and startOffset() may not be
-    equal to {@link #termLength}, as the term text may have been altered by a
+    equal to {@link #length}, as the term text may have been altered by a
     stemmer or some other filter. */
   public final int startOffset() {
     return startOffset;
@@ -351,7 +351,7 @@
   @Override
   public String toString() {
     final StringBuilder sb = new StringBuilder();
-    sb.append('(').append(term()).append(',')
+    sb.append('(').append(super.toString()).append(',')
       .append(startOffset).append(',').append(endOffset);
     if (!"word".equals(type))
       sb.append(",type=").append(type);
@@ -387,7 +387,7 @@
   /** Makes a clone, but replaces the term buffer &
    * start/end offset in the process.  This is more
    * efficient than doing a full clone (and then calling
-   * setTermBuffer) because it saves a wasted copy of the old
+   * {@link #copyBuffer}) because it saves a wasted copy of the old
    * termBuffer. */
   public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {
     final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);
@@ -442,16 +442,16 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(char[], int, int)},
+   *  {@link #copyBuffer(char[], int, int)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset},
    *  {@link #setType}
    *  @return this Token instance */
   public Token reinit(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset, String newType) {
     clearNoTermBuffer();
+    copyBuffer(newTermBuffer, newTermOffset, newTermLength);
     payload = null;
     positionIncrement = 1;
-    setTermBuffer(newTermBuffer, newTermOffset, newTermLength);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = newType;
@@ -459,14 +459,14 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(char[], int, int)},
+   *  {@link #copyBuffer(char[], int, int)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset}
    *  {@link #setType} on Token.DEFAULT_TYPE
    *  @return this Token instance */
   public Token reinit(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {
     clearNoTermBuffer();
-    setTermBuffer(newTermBuffer, newTermOffset, newTermLength);
+    copyBuffer(newTermBuffer, newTermOffset, newTermLength);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = DEFAULT_TYPE;
@@ -474,14 +474,14 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(String)},
+   *  {@link #append(CharSequence)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset}
    *  {@link #setType}
    *  @return this Token instance */
   public Token reinit(String newTerm, int newStartOffset, int newEndOffset, String newType) {
-    clearNoTermBuffer();
-    setTermBuffer(newTerm);
+    clear();
+    append(newTerm);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = newType;
@@ -489,14 +489,14 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(String, int, int)},
+   *  {@link #append(CharSequence, int, int)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset}
    *  {@link #setType}
    *  @return this Token instance */
   public Token reinit(String newTerm, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset, String newType) {
-    clearNoTermBuffer();
-    setTermBuffer(newTerm, newTermOffset, newTermLength);
+    clear();
+    append(newTerm, newTermOffset, newTermOffset + newTermLength);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = newType;
@@ -504,14 +504,14 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(String)},
+   *  {@link #append(CharSequence)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset}
    *  {@link #setType} on Token.DEFAULT_TYPE
    *  @return this Token instance */
   public Token reinit(String newTerm, int newStartOffset, int newEndOffset) {
-    clearNoTermBuffer();
-    setTermBuffer(newTerm);
+    clear();
+    append(newTerm);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = DEFAULT_TYPE;
@@ -519,14 +519,14 @@
   }
 
   /** Shorthand for calling {@link #clear},
-   *  {@link #setTermBuffer(String, int, int)},
+   *  {@link #append(CharSequence, int, int)},
    *  {@link #setStartOffset},
    *  {@link #setEndOffset}
    *  {@link #setType} on Token.DEFAULT_TYPE
    *  @return this Token instance */
   public Token reinit(String newTerm, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {
-    clearNoTermBuffer();
-    setTermBuffer(newTerm, newTermOffset, newTermLength);
+    clear();
+    append(newTerm, newTermOffset, newTermOffset + newTermLength);
     startOffset = newStartOffset;
     endOffset = newEndOffset;
     type = DEFAULT_TYPE;
@@ -538,7 +538,7 @@
    * @param prototype
    */
   public void reinit(Token prototype) {
-    setTermBuffer(prototype.termBuffer(), 0, prototype.termLength());
+    copyBuffer(prototype.buffer(), 0, prototype.length());
     positionIncrement = prototype.positionIncrement;
     flags = prototype.flags;
     startOffset = prototype.startOffset;
@@ -553,7 +553,7 @@
    * @param newTerm
    */
   public void reinit(Token prototype, String newTerm) {
-    setTermBuffer(newTerm);
+    setEmpty().append(newTerm);
     positionIncrement = prototype.positionIncrement;
     flags = prototype.flags;
     startOffset = prototype.startOffset;
@@ -570,7 +570,7 @@
    * @param length
    */
   public void reinit(Token prototype, char[] newTermBuffer, int offset, int length) {
-    setTermBuffer(newTermBuffer, offset, length);
+    copyBuffer(newTermBuffer, offset, length);
     positionIncrement = prototype.positionIncrement;
     flags = prototype.flags;
     startOffset = prototype.startOffset;
Index: src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java	(revision 0)
+++ src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java	(revision 0)
@@ -0,0 +1,71 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.Attribute;
+
+/**
+ * The term text of a Token.
+ */
+public interface CharTermAttribute extends Attribute, CharSequence, Appendable {
+  
+  /** Copies the contents of buffer, starting at offset for
+   *  length characters, into the termBuffer array.
+   *  @param buffer the buffer to copy
+   *  @param offset the index in the buffer of the first character to copy
+   *  @param length the number of characters to copy
+   */
+  public void copyBuffer(char[] buffer, int offset, int length);
+  
+  /** Returns the internal termBuffer character array which
+   *  you can then directly alter.  If the array is too
+   *  small for your token, use {@link
+   *  #resizeBuffer(int)} to increase it.  After
+   *  altering the buffer be sure to call {@link
+   *  #setLength} to record the number of valid
+   *  characters that were placed into the termBuffer. */
+  public char[] buffer();
+
+  /** Grows the termBuffer to at least size newSize, preserving the
+   *  existing content.
+   *  @param newSize minimum size of the new termBuffer
+   *  @return newly created termBuffer with length >= newSize
+   */
+  public char[] resizeBuffer(int newSize);
+
+  /** Set number of valid characters (length of the term) in
+   *  the termBuffer array. Use this to truncate the termBuffer
+   *  or to synchronize with external manipulation of the termBuffer.
+   *  Note: to grow the size of the array,
+   *  use {@link #resizeBuffer(int)} first.
+   *  @param length the truncated length
+   */
+  public CharTermAttribute setLength(int length);
+  
+  /** Sets the length of the termBuffer to zero.
+   * Use this method before appending contents
+   * using the {@link Appendable} interface.
+   */
+  public CharTermAttribute setEmpty();
+  
+  // the following methods are redefined to get rid of IOException declaration:
+  public CharTermAttribute append(CharSequence csq);
+  public CharTermAttribute append(CharSequence csq, int start, int end);
+  public CharTermAttribute append(char c);
+
+}

Property changes on: src\java\org\apache\lucene\analysis\tokenattributes\CharTermAttribute.java
___________________________________________________________________
Added: svn:keywords
   + Date Author Id Revision HeadURL
Added: svn:eol-style
   + native

Index: src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java	(revision 0)
+++ src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttributeImpl.java	(revision 0)
@@ -0,0 +1,256 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Serializable;
+import java.nio.CharBuffer;
+
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.RamUsageEstimator;
+import org.apache.lucene.util.UnicodeUtil;
+
+/**
+ * The term text of a Token.
+ */
+public class CharTermAttributeImpl extends AttributeImpl implements CharTermAttribute, TermAttribute, TermToBytesRefAttribute, Cloneable, Serializable {
+  private static int MIN_BUFFER_SIZE = 10;
+  
+  private char[] termBuffer = new char[ArrayUtil.oversize(MIN_BUFFER_SIZE, RamUsageEstimator.NUM_BYTES_CHAR)];
+  private int termLength = 0;
+  
+  @Deprecated
+  public String term() {
+    // don't delegate to toString() here!
+    return new String(termBuffer, 0, termLength);
+  }
+
+  public void copyBuffer(char[] buffer, int offset, int length) {
+    growTermBuffer(length);
+    System.arraycopy(buffer, offset, termBuffer, 0, length);
+    termLength = length;
+  }
+
+  @Deprecated
+  public void setTermBuffer(char[] buffer, int offset, int length) {
+    copyBuffer(buffer, offset, length);
+  }
+
+  @Deprecated
+  public void setTermBuffer(String buffer) {
+    int length = buffer.length();
+    growTermBuffer(length);
+    buffer.getChars(0, length, termBuffer, 0);
+    termLength = length;
+  }
+
+  @Deprecated
+  public void setTermBuffer(String buffer, int offset, int length) {
+    assert offset <= buffer.length();
+    assert offset + length <= buffer.length();
+    growTermBuffer(length);
+    buffer.getChars(offset, offset + length, termBuffer, 0);
+    termLength = length;
+  }
+
+  public char[] buffer() {
+    return termBuffer;
+  }
+
+  @Deprecated
+  public char[] termBuffer() {
+    return termBuffer;
+  }
+  
+  public char[] resizeBuffer(int newSize) {
+    if (termBuffer == null) {
+      // The buffer is always at least MIN_BUFFER_SIZE
+      termBuffer = new char[ArrayUtil.oversize(newSize < MIN_BUFFER_SIZE ? MIN_BUFFER_SIZE : newSize, RamUsageEstimator.NUM_BYTES_CHAR)]; 
+    } else {
+      if(termBuffer.length < newSize){
+        // Not big enough; create a new array with slight
+        // over allocation and preserve content
+        final char[] newCharBuffer = new char[ArrayUtil.oversize(newSize, RamUsageEstimator.NUM_BYTES_CHAR)];
+        System.arraycopy(termBuffer, 0, newCharBuffer, 0, termBuffer.length);
+        termBuffer = newCharBuffer;
+      }
+    } 
+    return termBuffer;   
+  }
+
+  @Deprecated
+  public char[] resizeTermBuffer(int newSize) {
+    return resizeBuffer(newSize);
+  }
+  
+  private void growTermBuffer(int newSize) {
+    if (termBuffer == null) {
+      // The buffer is always at least MIN_BUFFER_SIZE
+      termBuffer = new char[ArrayUtil.oversize(newSize < MIN_BUFFER_SIZE ? MIN_BUFFER_SIZE : newSize, RamUsageEstimator.NUM_BYTES_CHAR)];   
+    } else {
+      if(termBuffer.length < newSize){
+        // Not big enough; create a new array with slight
+        // over allocation:
+        termBuffer = new char[ArrayUtil.oversize(newSize, RamUsageEstimator.NUM_BYTES_CHAR)];
+      }
+    } 
+  }
+  
+  @Deprecated
+  public int termLength() {
+    return termLength;
+  }
+
+  public CharTermAttribute setLength(int length) {
+    if (length > termBuffer.length)
+      throw new IllegalArgumentException("length " + length + " exceeds the size of the termBuffer (" + termBuffer.length + ")");
+    termLength = length;
+    return this;
+  }
+  
+  public CharTermAttribute setEmpty() {
+    termLength = 0;
+    return this;
+  }
+  
+  @Deprecated
+  public void setTermLength(int length) {
+    setLength(length);
+  }
+  
+  // *** TermToBytesRefAttribute interface ***
+  public int toBytesRef(BytesRef target) {
+    // nocommit: Maybe assume that bytes is already initialized? TermsHashPerField ensures this.
+    if (target.bytes == null) {
+      target.bytes = new byte[termLength * 4];
+    }
+    return UnicodeUtil.UTF16toUTF8WithHash(termBuffer, 0, termLength, target);
+  }
+  
+  // *** CharSequence interface ***
+  public int length() {
+    return termLength;
+  }
+  
+  public char charAt(int index) {
+    if (index >= termLength)
+      throw new IndexOutOfBoundsException();
+    return termBuffer[index];
+  }
+  
+  public CharSequence subSequence(final int start, final int end) {
+    if (start > termLength || end > termLength)
+      throw new IndexOutOfBoundsException();
+    return new String(termBuffer, start, end - start);
+  }
+  
+  // *** Appendable interface ***
+  public CharTermAttribute append(CharSequence csq) {
+    return append(csq, 0, csq.length());
+  }
+  
+  public CharTermAttribute append(CharSequence csq, int start, int end) {
+    resizeBuffer(termLength + end - start);
+    if (csq instanceof String) {
+      ((String) csq).getChars(start, end, termBuffer, termLength);
+    } else if (csq instanceof StringBuilder) {
+      ((StringBuilder) csq).getChars(start, end, termBuffer, termLength);
+    } else if (csq instanceof StringBuffer) {
+      ((StringBuffer) csq).getChars(start, end, termBuffer, termLength);
+    } else if (csq instanceof CharBuffer && ((CharBuffer) csq).hasArray()) {
+      final CharBuffer cb = (CharBuffer) csq;
+      System.arraycopy(cb.array(), cb.arrayOffset() + cb.position() + start, termBuffer, termLength, end - start);
+    } else {
+      while (start < end)
+        termBuffer[termLength++] = csq.charAt(start++);
+      // no fall-through here, as termLength is updated!
+      return this;
+    }
+    termLength += end - start;
+    return this;
+  }
+  
+  public CharTermAttribute append(char c) {
+    resizeBuffer(termLength + 1)[termLength++] = c;
+    return this;
+  }
+  
+  // *** AttributeImpl ***
+
+  @Override
+  public int hashCode() {
+    int code = termLength;
+    code = code * 31 + ArrayUtil.hashCode(termBuffer, 0, termLength);
+    return code;
+  }
+
+  @Override
+  public void clear() {
+    termLength = 0;    
+  }
+
+  @Override
+  public Object clone() {
+    CharTermAttributeImpl t = (CharTermAttributeImpl)super.clone();
+    // Do a deep clone
+    if (termBuffer != null) {
+      t.termBuffer = termBuffer.clone();
+    }
+    return t;
+  }
+  
+  @Override
+  public boolean equals(Object other) {
+    if (other == this) {
+      return true;
+    }
+    
+    if (other instanceof CharTermAttributeImpl) {
+      final CharTermAttributeImpl o = ((CharTermAttributeImpl) other);
+      if (termLength != o.termLength)
+        return false;
+      for(int i=0;i<termLength;i++) {
+        if (termBuffer[i] != o.termBuffer[i]) {
+          return false;
+        }
+      }
+      return true;
+    }
+    
+    return false;
+  }
+
+  @Override
+  public String toString() {
+    // nocommit: CharSequence requires that only the contents are returned, but this is orginal code: "term=" + new String(termBuffer, 0, termLength)
+    return new String(termBuffer, 0, termLength);
+  }
+  
+  @Override
+  public void copyTo(AttributeImpl target) {
+    if (target instanceof CharTermAttribute) {
+      CharTermAttribute t = (CharTermAttribute) target;
+      t.copyBuffer(termBuffer, 0, termLength);
+    } else {
+      TermAttribute t = (TermAttribute) target;
+      t.setTermBuffer(termBuffer, 0, termLength);
+    }
+  }
+
+}

Property changes on: src\java\org\apache\lucene\analysis\tokenattributes\CharTermAttributeImpl.java
___________________________________________________________________
Added: svn:keywords
   + Date Author Id Revision HeadURL
Added: svn:eol-style
   + native

Index: src/java/org/apache/lucene/analysis/tokenattributes/TermAttribute.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/TermAttribute.java	(revision 924661)
+++ src/java/org/apache/lucene/analysis/tokenattributes/TermAttribute.java	(working copy)
@@ -21,7 +21,9 @@
 
 /**
  * The term text of a Token.
+ * @deprecated Use {@link CharTermAttribute} instead.
  */
+@Deprecated
 public interface TermAttribute extends Attribute {
   /** Returns the Token's term text.
    * 
Index: src/java/org/apache/lucene/analysis/tokenattributes/TermAttributeImpl.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/TermAttributeImpl.java	(revision 924661)
+++ src/java/org/apache/lucene/analysis/tokenattributes/TermAttributeImpl.java	(working copy)
@@ -17,211 +17,11 @@
  * limitations under the License.
  */
 
-import java.io.Serializable;
-
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.RamUsageEstimator;
-
 /**
  * The term text of a Token.
+ * @deprecated This class is only available for AttributeSource
+ * to be able to load an old TermAttribute implementation class.
  */
-public class TermAttributeImpl extends AttributeImpl implements TermAttribute, Cloneable, Serializable {
-  private static int MIN_BUFFER_SIZE = 10;
-  
-  private char[] termBuffer;
-  private int termLength;
-  
-  /** Returns the Token's term text.
-   * 
-   * This method has a performance penalty
-   * because the text is stored internally in a char[].  If
-   * possible, use {@link #termBuffer()} and {@link
-   * #termLength()} directly instead.  If you really need a
-   * String, use this method, which is nothing more than
-   * a convenience call to <b>new String(token.termBuffer(), 0, token.termLength())</b>
-   */
-  public String term() {
-    initTermBuffer();
-    return new String(termBuffer, 0, termLength);
-  }
-
-  /** Copies the contents of buffer, starting at offset for
-   *  length characters, into the termBuffer array.
-   *  @param buffer the buffer to copy
-   *  @param offset the index in the buffer of the first character to copy
-   *  @param length the number of characters to copy
-   */
-  public void setTermBuffer(char[] buffer, int offset, int length) {
-    growTermBuffer(length);
-    System.arraycopy(buffer, offset, termBuffer, 0, length);
-    termLength = length;
-  }
-
-  /** Copies the contents of buffer into the termBuffer array.
-   *  @param buffer the buffer to copy
-   */
-  public void setTermBuffer(String buffer) {
-    int length = buffer.length();
-    growTermBuffer(length);
-    buffer.getChars(0, length, termBuffer, 0);
-    termLength = length;
-  }
-
-  /** Copies the contents of buffer, starting at offset and continuing
-   *  for length characters, into the termBuffer array.
-   *  @param buffer the buffer to copy
-   *  @param offset the index in the buffer of the first character to copy
-   *  @param length the number of characters to copy
-   */
-  public void setTermBuffer(String buffer, int offset, int length) {
-    assert offset <= buffer.length();
-    assert offset + length <= buffer.length();
-    growTermBuffer(length);
-    buffer.getChars(offset, offset + length, termBuffer, 0);
-    termLength = length;
-  }
-
-  /** Returns the internal termBuffer character array which
-   *  you can then directly alter.  If the array is too
-   *  small for your token, use {@link
-   *  #resizeTermBuffer(int)} to increase it.  After
-   *  altering the buffer be sure to call {@link
-   *  #setTermLength} to record the number of valid
-   *  characters that were placed into the termBuffer. */
-  public char[] termBuffer() {
-    initTermBuffer();
-    return termBuffer;
-  }
-
-  /** Grows the termBuffer to at least size newSize, preserving the
-   *  existing content. Note: If the next operation is to change
-   *  the contents of the term buffer use
-   *  {@link #setTermBuffer(char[], int, int)},
-   *  {@link #setTermBuffer(String)}, or
-   *  {@link #setTermBuffer(String, int, int)}
-   *  to optimally combine the resize with the setting of the termBuffer.
-   *  @param newSize minimum size of the new termBuffer
-   *  @return newly created termBuffer with length >= newSize
-   */
-  public char[] resizeTermBuffer(int newSize) {
-    if (termBuffer == null) {
-      // The buffer is always at least MIN_BUFFER_SIZE
-      termBuffer = new char[ArrayUtil.oversize(newSize < MIN_BUFFER_SIZE ? MIN_BUFFER_SIZE : newSize, RamUsageEstimator.NUM_BYTES_CHAR)]; 
-    } else {
-      if(termBuffer.length < newSize){
-        // Not big enough; create a new array with slight
-        // over allocation and preserve content
-        final char[] newCharBuffer = new char[ArrayUtil.oversize(newSize, RamUsageEstimator.NUM_BYTES_CHAR)];
-        System.arraycopy(termBuffer, 0, newCharBuffer, 0, termBuffer.length);
-        termBuffer = newCharBuffer;
-      }
-    } 
-    return termBuffer;   
-  }
-
-
-  /** Allocates a buffer char[] of at least newSize, without preserving the existing content.
-   * its always used in places that set the content 
-   *  @param newSize minimum size of the buffer
-   */
-  private void growTermBuffer(int newSize) {
-    if (termBuffer == null) {
-      // The buffer is always at least MIN_BUFFER_SIZE
-      termBuffer = new char[ArrayUtil.oversize(newSize < MIN_BUFFER_SIZE ? MIN_BUFFER_SIZE : newSize, RamUsageEstimator.NUM_BYTES_CHAR)];   
-    } else {
-      if(termBuffer.length < newSize){
-        // Not big enough; create a new array with slight
-        // over allocation:
-        termBuffer = new char[ArrayUtil.oversize(newSize, RamUsageEstimator.NUM_BYTES_CHAR)];
-      }
-    } 
-  }
-  
-  private void initTermBuffer() {
-    if (termBuffer == null) {
-      termBuffer = new char[ArrayUtil.oversize(MIN_BUFFER_SIZE, RamUsageEstimator.NUM_BYTES_CHAR)];
-      termLength = 0;
-    }
-  }
-
-  /** Return number of valid characters (length of the term)
-   *  in the termBuffer array. */
-  public int termLength() {
-    return termLength;
-  }
-
-  /** Set number of valid characters (length of the term) in
-   *  the termBuffer array. Use this to truncate the termBuffer
-   *  or to synchronize with external manipulation of the termBuffer.
-   *  Note: to grow the size of the array,
-   *  use {@link #resizeTermBuffer(int)} first.
-   *  @param length the truncated length
-   */
-  public void setTermLength(int length) {
-    initTermBuffer();
-    if (length > termBuffer.length)
-      throw new IllegalArgumentException("length " + length + " exceeds the size of the termBuffer (" + termBuffer.length + ")");
-    termLength = length;
-  }
-
-  @Override
-  public int hashCode() {
-    initTermBuffer();
-    int code = termLength;
-    code = code * 31 + ArrayUtil.hashCode(termBuffer, 0, termLength);
-    return code;
-  }
-
-  @Override
-  public void clear() {
-    termLength = 0;    
-  }
-
-  @Override
-  public Object clone() {
-    TermAttributeImpl t = (TermAttributeImpl)super.clone();
-    // Do a deep clone
-    if (termBuffer != null) {
-      t.termBuffer = termBuffer.clone();
-    }
-    return t;
-  }
-  
-  @Override
-  public boolean equals(Object other) {
-    if (other == this) {
-      return true;
-    }
-    
-    if (other instanceof TermAttributeImpl) {
-      initTermBuffer();
-      TermAttributeImpl o = ((TermAttributeImpl) other);
-      o.initTermBuffer();
-      
-      if (termLength != o.termLength)
-        return false;
-      for(int i=0;i<termLength;i++) {
-        if (termBuffer[i] != o.termBuffer[i]) {
-          return false;
-        }
-      }
-      return true;
-    }
-    
-    return false;
-  }
-
-  @Override
-  public String toString() {
-    initTermBuffer();
-    return "term=" + new String(termBuffer, 0, termLength);
-  }
-  
-  @Override
-  public void copyTo(AttributeImpl target) {
-    initTermBuffer();
-    TermAttribute t = (TermAttribute) target;
-    t.setTermBuffer(termBuffer, 0, termLength);
-  }
+@Deprecated
+public class TermAttributeImpl extends CharTermAttributeImpl {
 }
Index: src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java	(revision 0)
+++ src/java/org/apache/lucene/analysis/tokenattributes/TermToBytesRefAttribute.java	(revision 0)
@@ -0,0 +1,32 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * This attribute is requested by TermsHashPerField to index the contents.
+ * This attribute has no real state, it should be implemented in addition to
+ * {@link CharTermAttribute}, to support indexing the term text as
+ * UTF-8 bytes.
+ */
+public interface TermToBytesRefAttribute extends Attribute {
+  /** Copies the token's term text into the given {@link BytesRef}. It returns the hashCode for TermsHash */
+  public int toBytesRef(BytesRef bytes);
+}

Property changes on: src\java\org\apache\lucene\analysis\tokenattributes\TermToBytesRefAttribute.java
___________________________________________________________________
Added: svn:keywords
   + Date Author Id Revision HeadURL
Added: svn:eol-style
   + native

Index: src/java/org/apache/lucene/index/DocInverterPerThread.java
===================================================================
--- src/java/org/apache/lucene/index/DocInverterPerThread.java	(revision 924661)
+++ src/java/org/apache/lucene/index/DocInverterPerThread.java	(working copy)
@@ -21,7 +21,7 @@
 
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 
 /** This is a DocFieldConsumer that inverts each field,
  *  separately, from a Document, and accepts a
@@ -34,16 +34,16 @@
   final SingleTokenAttributeSource singleToken = new SingleTokenAttributeSource();
   
   static class SingleTokenAttributeSource extends AttributeSource {
-    final TermAttribute termAttribute;
+    final CharTermAttribute termAttribute;
     final OffsetAttribute offsetAttribute;
     
     private SingleTokenAttributeSource() {
-      termAttribute = addAttribute(TermAttribute.class);
+      termAttribute = addAttribute(CharTermAttribute.class);
       offsetAttribute = addAttribute(OffsetAttribute.class);
     }
     
     public void reinit(String stringValue, int startOffset,  int endOffset) {
-      termAttribute.setTermBuffer(stringValue);
+      termAttribute.setEmpty().append(stringValue);
       offsetAttribute.setOffset(startOffset, endOffset);
     }
   }
Index: src/java/org/apache/lucene/index/TermsHashPerField.java
===================================================================
--- src/java/org/apache/lucene/index/TermsHashPerField.java	(revision 924661)
+++ src/java/org/apache/lucene/index/TermsHashPerField.java	(working copy)
@@ -22,6 +22,7 @@
 import java.util.Comparator;
 
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 import org.apache.lucene.document.Fieldable;
 import org.apache.lucene.util.UnicodeUtil;
 import org.apache.lucene.util.BytesRef;
@@ -33,7 +34,7 @@
   final TermsHashPerThread perThread;
   final DocumentsWriter.DocState docState;
   final FieldInvertState fieldState;
-  TermAttribute termAtt;
+  TermToBytesRefAttribute termAtt;
 
   // Copied from our perThread
   final IntBlockPool intPool;
@@ -259,7 +260,14 @@
 
   @Override
   void start(Fieldable f) {
-    termAtt = fieldState.attributeSource.addAttribute(TermAttribute.class);
+    if (fieldState.attributeSource.hasAttribute(TermToBytesRefAttribute.class)) {
+      termAtt = fieldState.attributeSource.getAttribute(TermToBytesRefAttribute.class);
+    } else if (fieldState.attributeSource.hasAttribute(TermAttribute.class)) {
+      perThread.legacyTermAttributeWrapper.setTermAttribute(fieldState.attributeSource.getAttribute(TermAttribute.class));
+      termAtt = perThread.legacyTermAttributeWrapper;
+    } else {
+      throw new IllegalArgumentException("Could not find a term attribute (that implements TermToBytesRefAttribute) in the TokenStream");
+    }
     consumer.start(f);
     if (nextPerField != null) {
       nextPerField.start(f);
@@ -358,13 +366,8 @@
     // We are first in the chain so we must "intern" the
     // term text into textStart address
 
-    // Get the text of this term.
-    final char[] tokenText = termAtt.termBuffer();
-    final int tokenTextLen = termAtt.termLength();
-    
-    //System.out.println("\nfield=" + fieldInfo.name + " add text=" + new String(tokenText, 0, tokenTextLen) + " len=" + tokenTextLen);
-    
-    int code = UnicodeUtil.UTF16toUTF8WithHash(tokenText, 0, tokenTextLen, utf8);
+    // Get the text & hash of this term.
+    int code = termAtt.toBytesRef(utf8);
 
     int hashPos = code & postingsHashMask;
 
@@ -399,7 +402,13 @@
           // other behavior is wanted (pruning the term
           // to a prefix, throwing an exception, etc).
           if (docState.maxTermPrefix == null) {
-            docState.maxTermPrefix = new String(tokenText, 0, 30);
+            final int saved = utf8.length;
+            try {
+              utf8.length = Math.min(30, DocumentsWriter.MAX_TERM_LENGTH_UTF8);
+              docState.maxTermPrefix = utf8.toString();
+            } finally {
+              utf8.length = saved;
+            }
           }
 
           consumer.skippingLongTerm();
Index: src/java/org/apache/lucene/index/TermsHashPerThread.java
===================================================================
--- src/java/org/apache/lucene/index/TermsHashPerThread.java	(revision 924661)
+++ src/java/org/apache/lucene/index/TermsHashPerThread.java	(working copy)
@@ -18,6 +18,9 @@
  */
 
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
 
 import java.io.IOException;
 
@@ -42,6 +45,23 @@
 
   // Used by perField:
   final BytesRef utf8 = new BytesRef(10);
+  
+  final LegacyTermAttributeWrapper legacyTermAttributeWrapper = new LegacyTermAttributeWrapper();
+  
+  /** This class is used to wrap a legacy TermAttribute without support for {@link TermToBytesRefAttribute}. */
+  @Deprecated
+  static class LegacyTermAttributeWrapper implements TermToBytesRefAttribute {
+    private TermAttribute termAtt = null;
+  
+    void setTermAttribute(TermAttribute termAtt) {
+      this.termAtt = termAtt;
+    }
+  
+    public int toBytesRef(BytesRef target) {
+      assert target.bytes != null : "target byteref must be != null, because utf8 is used here";
+      return UnicodeUtil.UTF16toUTF8WithHash(termAtt.termBuffer(), 0, termAtt.termLength(), target);
+    }
+  }
 
   public TermsHashPerThread(DocInverterPerThread docInverterPerThread, final TermsHash termsHash, final TermsHash nextTermsHash, final TermsHashPerThread primaryPerThread) {
     docState = docInverterPerThread.docState;
Index: src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
===================================================================
--- src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java	(revision 0)
+++ src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java	(revision 0)
@@ -0,0 +1,177 @@
+package org.apache.lucene.analysis.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+import java.nio.CharBuffer;
+import java.util.Formatter;
+import java.util.Locale;
+import java.util.regex.Pattern;
+
+public class TestCharTermAttributeImpl extends LuceneTestCase {
+
+  public TestCharTermAttributeImpl(String name) {
+    super(name);
+  }
+
+  public void testResize() {
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    char[] content = "hello".toCharArray();
+    t.copyBuffer(content, 0, content.length);
+    for (int i = 0; i < 2000; i++)
+    {
+      t.resizeBuffer(i);
+      assertTrue(i <= t.buffer().length);
+      assertEquals("hello", t.toString());
+    }
+  }
+
+  public void testGrow() {
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    StringBuilder buf = new StringBuilder("ab");
+    for (int i = 0; i < 20; i++)
+    {
+      char[] content = buf.toString().toCharArray();
+      t.copyBuffer(content, 0, content.length);
+      assertEquals(buf.length(), t.length());
+      assertEquals(buf.toString(), t.toString());
+      buf.append(buf.toString());
+    }
+    assertEquals(1048576, t.length());
+
+    // now as a StringBuilder, first variant
+    t = new CharTermAttributeImpl();
+    buf = new StringBuilder("ab");
+    for (int i = 0; i < 20; i++)
+    {
+      t.setEmpty().append(buf);
+      assertEquals(buf.length(), t.length());
+      assertEquals(buf.toString(), t.toString());
+      buf.append(t);
+    }
+    assertEquals(1048576, t.length());
+
+    // Test for slow growth to a long term
+    t = new CharTermAttributeImpl();
+    buf = new StringBuilder("a");
+    for (int i = 0; i < 20000; i++)
+    {
+      t.setEmpty().append(buf);
+      assertEquals(buf.length(), t.length());
+      assertEquals(buf.toString(), t.toString());
+      buf.append("a");
+    }
+    assertEquals(20000, t.length());
+  }
+
+  public void testToString() throws Exception {
+    char[] b = {'a', 'l', 'o', 'h', 'a'};
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    t.copyBuffer(b, 0, 5);
+    assertEquals("aloha", t.toString());
+
+    t.setEmpty().append("hi there");
+    assertEquals("hi there", t.toString());
+  }
+
+  public void testClone() throws Exception {
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    char[] content = "hello".toCharArray();
+    t.copyBuffer(content, 0, 5);
+    char[] buf = t.buffer();
+    CharTermAttributeImpl copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCloneIsEqual(t);
+    assertEquals(t.toString(), copy.toString());
+    assertNotSame(buf, copy.buffer());
+  }
+  
+  public void testEquals() throws Exception {
+    CharTermAttributeImpl t1a = new CharTermAttributeImpl();
+    char[] content1a = "hello".toCharArray();
+    t1a.copyBuffer(content1a, 0, 5);
+    CharTermAttributeImpl t1b = new CharTermAttributeImpl();
+    char[] content1b = "hello".toCharArray();
+    t1b.copyBuffer(content1b, 0, 5);
+    CharTermAttributeImpl t2 = new CharTermAttributeImpl();
+    char[] content2 = "hello2".toCharArray();
+    t2.copyBuffer(content2, 0, 6);
+    assertTrue(t1a.equals(t1b));
+    assertFalse(t1a.equals(t2));
+    assertFalse(t2.equals(t1b));
+  }
+  
+  public void testCopyTo() throws Exception {
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    CharTermAttributeImpl copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    assertEquals("", t.toString());
+    assertEquals("", copy.toString());
+
+    t = new CharTermAttributeImpl();
+    char[] content = "hello".toCharArray();
+    t.copyBuffer(content, 0, 5);
+    char[] buf = t.buffer();
+    copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    assertEquals(t.toString(), copy.toString());
+    assertNotSame(buf, copy.buffer());
+  }
+  
+  public void testCharSequenceInterface() {
+    final String s = "0123456789"; 
+    final CharTermAttributeImpl t = new CharTermAttributeImpl();
+    t.append(s);
+    
+    assertEquals(s.length(), t.length());
+    assertEquals("12", t.subSequence(1,3).toString());
+    assertEquals(s, t.subSequence(0,s.length()).toString());
+    
+    assertTrue(Pattern.matches("01\\d+", t));
+    assertTrue(Pattern.matches("34", t.subSequence(3,5)));
+    
+    assertEquals(s.subSequence(3,7).toString(), t.subSequence(3,7).toString());
+    
+    for (int i = 0; i < s.length(); i++) {
+      assertTrue(t.charAt(i) == s.charAt(i));
+    }
+  }
+
+  public void testAppendableInterface() {
+    CharTermAttributeImpl t = new CharTermAttributeImpl();
+    Formatter formatter = new Formatter(t, Locale.US);
+    formatter.format("%d", 1234);
+    assertEquals("1234", t.toString());
+    formatter.format("%d", 5678);
+    assertEquals("12345678", t.toString());
+    t.append('9');
+    assertEquals("123456789", t.toString());
+    t.append("0");
+    assertEquals("1234567890", t.toString());
+    t.append("0123456789", 1, 3);
+    assertEquals("123456789012", t.toString());
+    t.append(CharBuffer.wrap("0123456789".toCharArray()), 3, 5);
+    assertEquals("12345678901234", t.toString());
+    t.append(t);
+    assertEquals("1234567890123412345678901234", t.toString());
+    t.append(new StringBuilder("0123456789"), 5, 7);
+    assertEquals("123456789012341234567890123456", t.toString());
+    t.append(new StringBuffer(t));
+    assertEquals("123456789012341234567890123456123456789012341234567890123456", t.toString());
+    // very wierd, to test if a subSlice is wrapped correct :)
+    t.setEmpty().append(CharBuffer.wrap("0123456789".toCharArray(), 3, 5) /* "34" */, 1, 2);
+    assertEquals("4", t.toString());
+  }
+  
+}

Property changes on: src\test\org\apache\lucene\analysis\tokenattributes\TestCharTermAttributeImpl.java
___________________________________________________________________
Added: svn:keywords
   + Date Author Id Revision HeadURL
Added: svn:eol-style
   + native

Index: src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java
===================================================================
--- src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java	(revision 924661)
+++ src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java	(working copy)
@@ -22,6 +22,7 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.AttributeSource.AttributeFactory;
 
+@Deprecated
 public class TestSimpleAttributeImpls extends LuceneTestCase {
 
   public TestSimpleAttributeImpls(String name) {
Index: src/test/org/apache/lucene/analysis/tokenattributes/TestTermAttributeImpl.java
===================================================================
--- src/test/org/apache/lucene/analysis/tokenattributes/TestTermAttributeImpl.java	(revision 924661)
+++ src/test/org/apache/lucene/analysis/tokenattributes/TestTermAttributeImpl.java	(working copy)
@@ -107,10 +107,10 @@
     char[] b = {'a', 'l', 'o', 'h', 'a'};
     TermAttributeImpl t = new TermAttributeImpl();
     t.setTermBuffer(b, 0, 5);
-    assertEquals("term=aloha", t.toString());
+    assertEquals("aloha", t.toString());
 
     t.setTermBuffer("hi there");
-    assertEquals("term=hi there", t.toString());
+    assertEquals("hi there", t.toString());
   }
 
   public void testMixedStringArray() throws Exception {
Index: src/test/org/apache/lucene/util/TestAttributeSource.java
===================================================================
--- src/test/org/apache/lucene/util/TestAttributeSource.java	(revision 924661)
+++ src/test/org/apache/lucene/util/TestAttributeSource.java	(working copy)
@@ -27,27 +27,27 @@
   public void testCaptureState() {
     // init a first instance
     AttributeSource src = new AttributeSource();
-    TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    CharTermAttribute termAtt = src.addAttribute(CharTermAttribute.class);
     TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
-    termAtt.setTermBuffer("TestTerm");
+    termAtt.append("TestTerm");
     typeAtt.setType("TestType");
     final int hashCode = src.hashCode();
     
     AttributeSource.State state = src.captureState();
     
     // modify the attributes
-    termAtt.setTermBuffer("AnotherTestTerm");
+    termAtt.setEmpty().append("AnotherTestTerm");
     typeAtt.setType("AnotherTestType");
     assertTrue("Hash code should be different", hashCode != src.hashCode());
     
     src.restoreState(state);
-    assertEquals("TestTerm", termAtt.term());
+    assertEquals("TestTerm", termAtt.toString());
     assertEquals("TestType", typeAtt.type());
     assertEquals("Hash code should be equal after restore", hashCode, src.hashCode());
 
     // restore into an exact configured copy
     AttributeSource copy = new AttributeSource();
-    copy.addAttribute(TermAttribute.class);
+    copy.addAttribute(CharTermAttribute.class);
     copy.addAttribute(TypeAttribute.class);
     copy.restoreState(state);
     assertEquals("Both AttributeSources should have same hashCode after restore", src.hashCode(), copy.hashCode());
@@ -57,17 +57,17 @@
     AttributeSource src2 = new AttributeSource();
     typeAtt = src2.addAttribute(TypeAttribute.class);
     FlagsAttribute flagsAtt = src2.addAttribute(FlagsAttribute.class);
-    termAtt = src2.addAttribute(TermAttribute.class);
+    termAtt = src2.addAttribute(CharTermAttribute.class);
     flagsAtt.setFlags(12345);
 
     src2.restoreState(state);
-    assertEquals("TestTerm", termAtt.term());
+    assertEquals("TestTerm", termAtt.toString());
     assertEquals("TestType", typeAtt.type());
     assertEquals("FlagsAttribute should not be touched", 12345, flagsAtt.getFlags());
 
     // init a third instance missing one Attribute
     AttributeSource src3 = new AttributeSource();
-    termAtt = src3.addAttribute(TermAttribute.class);
+    termAtt = src3.addAttribute(CharTermAttribute.class);
     try {
       src3.restoreState(state);
       fail("The third instance is missing the TypeAttribute, so restoreState() should throw IllegalArgumentException");
@@ -78,42 +78,42 @@
   
   public void testCloneAttributes() {
     final AttributeSource src = new AttributeSource();
-    final TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    final FlagsAttribute flagsAtt = src.addAttribute(FlagsAttribute.class);
     final TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
-    termAtt.setTermBuffer("TestTerm");
+    flagsAtt.setFlags(1234);
     typeAtt.setType("TestType");
     
     final AttributeSource clone = src.cloneAttributes();
     final Iterator<Class<? extends Attribute>> it = clone.getAttributeClassesIterator();
-    assertEquals("TermAttribute must be the first attribute", TermAttribute.class, it.next());
+    assertEquals("FlagsAttribute must be the first attribute", FlagsAttribute.class, it.next());
     assertEquals("TypeAttribute must be the second attribute", TypeAttribute.class, it.next());
     assertFalse("No more attributes", it.hasNext());
     
-    final TermAttribute termAtt2 = clone.getAttribute(TermAttribute.class);
+    final FlagsAttribute flagsAtt2 = clone.getAttribute(FlagsAttribute.class);
     final TypeAttribute typeAtt2 = clone.getAttribute(TypeAttribute.class);
-    assertNotSame("TermAttribute of original and clone must be different instances", termAtt2, termAtt);
+    assertNotSame("FlagsAttribute of original and clone must be different instances", flagsAtt2, flagsAtt);
     assertNotSame("TypeAttribute of original and clone must be different instances", typeAtt2, typeAtt);
-    assertEquals("TermAttribute of original and clone must be equal", termAtt2, termAtt);
+    assertEquals("FlagsAttribute of original and clone must be equal", flagsAtt2, flagsAtt);
     assertEquals("TypeAttribute of original and clone must be equal", typeAtt2, typeAtt);
     
     // test copy back
-    termAtt2.setTermBuffer("OtherTerm");
+    flagsAtt2.setFlags(4711);
     typeAtt2.setType("OtherType");
     clone.copyTo(src);
-    assertEquals("TermAttribute of original must now contain updated term", "OtherTerm", termAtt.term());
+    assertEquals("FlagsAttribute of original must now contain updated term", 4711, flagsAtt.getFlags());
     assertEquals("TypeAttribute of original must now contain updated type", "OtherType", typeAtt.type());
     // verify again:
-    assertNotSame("TermAttribute of original and clone must be different instances", termAtt2, termAtt);
+    assertNotSame("FlagsAttribute of original and clone must be different instances", flagsAtt2, flagsAtt);
     assertNotSame("TypeAttribute of original and clone must be different instances", typeAtt2, typeAtt);
-    assertEquals("TermAttribute of original and clone must be equal", termAtt2, termAtt);
+    assertEquals("FlagsAttribute of original and clone must be equal", flagsAtt2, flagsAtt);
     assertEquals("TypeAttribute of original and clone must be equal", typeAtt2, typeAtt);
   }
   
   public void testToStringAndMultiAttributeImplementations() {
     AttributeSource src = new AttributeSource();
-    TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    CharTermAttribute termAtt = src.addAttribute(CharTermAttribute.class);
     TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
-    termAtt.setTermBuffer("TestTerm");
+    termAtt.append("TestTerm");
     typeAtt.setType("TestType");    
     assertEquals("Attributes should appear in original order", "("+termAtt.toString()+","+typeAtt.toString()+")", src.toString());
     Iterator<AttributeImpl> it = src.getAttributeImplsIterator();
@@ -125,23 +125,23 @@
 
     src = new AttributeSource();
     src.addAttributeImpl(new Token());
-    // this should not add a new attribute as Token implements TermAttribute, too
-    termAtt = src.addAttribute(TermAttribute.class);
-    assertTrue("TermAttribute should be implemented by Token", termAtt instanceof Token);
+    // this should not add a new attribute as Token implements CharTermAttribute, too
+    termAtt = src.addAttribute(CharTermAttribute.class);
+    assertTrue("CharTermAttribute should be implemented by Token", termAtt instanceof Token);
     // get the Token attribute and check, that it is the only one
     it = src.getAttributeImplsIterator();
     Token tok = (Token) it.next();
     assertFalse("There should be only one attribute implementation instance", it.hasNext());
     
-    termAtt.setTermBuffer("TestTerm");
+    termAtt.setEmpty().append("TestTerm");
     assertEquals("Token should only printed once", "("+tok.toString()+")", src.toString());
   }
   
   public void testDefaultAttributeFactory() throws Exception {
     AttributeSource src = new AttributeSource();
     
-    assertTrue("TermAttribute is not implemented by TermAttributeImpl",
-      src.addAttribute(TermAttribute.class) instanceof TermAttributeImpl);
+    assertTrue("CharTermAttribute is not implemented by CharTermAttributeImpl",
+      src.addAttribute(CharTermAttribute.class) instanceof CharTermAttributeImpl);
     assertTrue("OffsetAttribute is not implemented by OffsetAttributeImpl",
       src.addAttribute(OffsetAttribute.class) instanceof OffsetAttributeImpl);
     assertTrue("FlagsAttribute is not implemented by FlagsAttributeImpl",
