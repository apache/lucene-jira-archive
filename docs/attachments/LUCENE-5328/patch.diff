diff --git a/lucene/core/src/java/org/apache/lucene/index/CompositeIterator.java b/lucene/core/src/java/org/apache/lucene/index/CompositeIterator.java
new file mode 100644
index 0000000..05943bd
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/CompositeIterator.java
@@ -0,0 +1,62 @@
+package org.apache.lucene.index;
+
+import java.util.Iterator;
+import java.util.NoSuchElementException;
+
+public class CompositeIterator<V> implements Iterator<V> {
+  private Iterator<V>[] iters;
+  private int currIter;
+
+  public CompositeIterator(Iterator<V>[] iters) {
+    this.iters = iters;
+    currIter = 0;
+  }
+
+  public CompositeIterator(Iterator<V> iters1, Iterator<V> iters2) {
+    this(new Iterator[] {iters1, iters2});
+  }
+
+  /**
+   * Not supported.
+   *
+   * @see java.util.Iterator#remove()
+   */
+  @Override
+  public final void remove() {
+    throw new UnsupportedOperationException();
+  }
+
+  /**
+   * @see java.util.Iterator#next()
+   */
+  @Override
+  public final V next() {
+    if (hasNext()) {
+      return iters[currIter].next();
+    } else {
+      throw new NoSuchElementException();
+    }
+  }
+
+  /**
+   * @see java.util.Iterator#hasNext()
+   */
+  @Override
+  public final boolean hasNext() {
+    if (iters == null)
+      return false;
+    while (true) {
+      if (currIter >= iters.length) {
+        iters = null;
+        return false;
+      }
+      if (iters[currIter] == null) {
+        ++currIter;
+      } else if (iters[currIter].hasNext()) {
+        return true;
+      } else {
+        ++currIter;
+      }
+    }
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/index/InjectTermFilterAtomicReader.java b/lucene/core/src/java/org/apache/lucene/index/InjectTermFilterAtomicReader.java
new file mode 100644
index 0000000..4d5ed32
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/InjectTermFilterAtomicReader.java
@@ -0,0 +1,113 @@
+package org.apache.lucene.index;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+
+import org.apache.lucene.index.FieldInfo.DocValuesType;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Allow extra indexed parts to be injected into the reader.
+ * Calling injectTerm and injectNumericDocValues are not thread-safe.
+ */
+public class InjectTermFilterAtomicReader extends FilterAtomicReader {
+
+  private final Map<String, Terms> injectedFieldMap;
+  private final Map<String, NumericDocValues> injectedNumericDocValuesMap;
+  private Fields fields;
+
+  public InjectTermFilterAtomicReader(AtomicReader in) throws IOException {
+    super(in);
+    in.incRef();
+    injectedFieldMap = new HashMap<String, Terms>();
+    injectedNumericDocValuesMap = new HashMap<String, NumericDocValues>();
+    fields = in.fields();
+  }
+
+  @Override
+  public Fields fields() throws IOException {
+    if (injectedFieldMap.size() == 0) {
+      return fields;
+    }
+    else {
+      return new AggregatedFields(fields, injectedFieldMap);
+    }
+  }
+
+  @Override
+  public NumericDocValues getNumericDocValues(String field) throws IOException {
+    NumericDocValues docVals = injectedNumericDocValuesMap.get(field);
+    if (docVals == null) {
+      return in.getNumericDocValues(field);
+    } else {
+      return docVals;
+    }
+  }
+
+  public void injectTerm(String field, Terms terms) throws IOException {
+    FieldInfo finfo;
+    if ((finfo = in.getFieldInfos().fieldInfo(field)) != null) {
+      if (finfo.isIndexed()) {
+        throw new IOException("indexed field: " + field + "already exists.");
+      }
+    }
+    injectedFieldMap.put(field, terms);
+  }
+
+  public void injectNumericDocValues(String field, NumericDocValues numericDocValues) throws IOException {
+    FieldInfo finfo;
+    if ((finfo = in.getFieldInfos().fieldInfo(field)) != null) {
+      if (finfo.hasDocValues() && finfo.getDocValuesType() == DocValuesType.NUMERIC) {
+        throw new IOException("numeric docvalues: " + field + "already exists.");
+      }
+    }
+    injectedNumericDocValuesMap.put(field, numericDocValues);
+  }
+
+  private static class AggregatedFields extends Fields {
+
+    private Map<String, Terms> additional;
+    private final Fields in;
+    public AggregatedFields(Fields in, Map<String, Terms> additional) {
+      this.in = in;
+      this.additional = additional;
+    }
+
+    @Override
+    public Iterator<String> iterator() {
+      return new CompositeIterator<String>(in.iterator(), additional.keySet().iterator());
+    }
+
+    @Override
+    public Terms terms(String field) throws IOException {
+      if (additional.containsKey(field)) {
+        return additional.get(field);
+      }
+      return in.terms(field);
+    }
+
+    @Override
+    public int size() {
+      return in.size() + additional.size();
+    }
+
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/index/IntListTerms.java b/lucene/core/src/java/org/apache/lucene/index/IntListTerms.java
new file mode 100644
index 0000000..6d20647
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/index/IntListTerms.java
@@ -0,0 +1,234 @@
+package org.apache.lucene.index;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Comparator;
+import java.util.Map.Entry;
+import java.util.SortedMap;
+import java.util.TreeMap;
+
+import org.apache.lucene.search.IntArrayDocIdSetIterator;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+public class IntListTerms extends Terms{
+
+  private final BytesRef[] terms;
+  private final int[][] postings;
+
+  private final long totalDf;
+
+  public static IntListTerms fromTerms(Terms terms) throws IOException {
+    TreeMap<BytesRef, int[]> termMap = new TreeMap<BytesRef,int[]>();
+    TermsEnum te = terms.iterator(null);
+    BytesRef term;
+    DocsEnum de = null;
+    while ((term = te.next()) != null) {
+      String termString = term.utf8ToString();
+      de = te.docs(null, de);
+      int df = te.docFreq();
+      int docs[] = new int[df];
+      for (int i = 0; i < df; ++i) {
+        docs[i] = de.nextDoc();
+      }
+      termMap.put(new BytesRef(termString), docs);
+    }
+    return new IntListTerms(termMap);
+  }
+
+  public IntListTerms(SortedMap<BytesRef, int[]> termMap) {
+    long sum = 0L;
+    terms = new BytesRef[termMap.size()];
+    postings = new int[termMap.size()][];
+    int i = 0;
+    for (Entry<BytesRef, int[]> entry : termMap.entrySet()) {
+      int[] docs = entry.getValue();
+      terms[i] = entry.getKey();
+      postings[i] = entry.getValue();
+      i++;
+      sum += docs.length;
+    }
+    totalDf = sum;
+  }
+
+  @Override
+  public TermsEnum iterator(TermsEnum reuse) throws IOException {
+    PostingTermsEnum te;
+    if (reuse == null) {
+      te = new PostingTermsEnum(terms, postings);
+    } else {
+      te = (PostingTermsEnum)reuse;
+      te.index = -1;
+    }
+    return te;
+  }
+
+  @Override
+  public Comparator<BytesRef> getComparator() {
+    return BytesRef.getUTF8SortedAsUnicodeComparator();
+  }
+
+  @Override
+  public long size() throws IOException {
+    return terms.length;
+  }
+
+  @Override
+  public long getSumTotalTermFreq() throws IOException {
+    return getSumDocFreq();
+  }
+
+  @Override
+  public long getSumDocFreq() throws IOException {
+    return totalDf;
+  }
+
+  @Override
+  public int getDocCount() throws IOException {
+    return -1;
+  }
+
+  @Override
+  public boolean hasOffsets() {
+    return false;
+  }
+
+  @Override
+  public boolean hasPositions() {
+    return false;
+  }
+
+  @Override
+  public boolean hasPayloads() {
+    return false;
+  }
+
+  private static class PostingTermsEnum extends TermsEnum {
+
+    private final BytesRef[] terms;
+    private final int[][] postings;
+    private int index;
+
+    PostingTermsEnum(BytesRef[] terms, int[][] postings) {
+      this.terms = terms;
+      this.postings = postings;
+      this.index = -1;
+    }
+
+    @Override
+    public BytesRef next() throws IOException {
+      index++;
+      if (index < 0 || index >= terms.length) {
+        return null;
+      }
+      return term();
+    }
+
+    @Override
+    public Comparator<BytesRef> getComparator() {
+      return BytesRef.getUTF8SortedAsUnicodeComparator();
+    }
+
+    @Override
+    public SeekStatus seekCeil(BytesRef text)
+        throws IOException {
+      int i = Arrays.binarySearch(terms, 0, terms.length, text, getComparator());
+      if (i >= 0) {
+        index = i;
+        return SeekStatus.FOUND;
+      }
+      i = -(i + 1);
+      index = i;
+      if (i == terms.length) {
+        return SeekStatus.END;
+      }
+      return SeekStatus.NOT_FOUND;
+    }
+
+    @Override
+    public void seekExact(long ord) throws IOException {
+      if (index < 0 || index >= terms.length) {
+        throw new IOException("ord out of range: " + ord);
+      }
+      index = (int)ord;
+    }
+
+    @Override
+    public BytesRef term() throws IOException {
+      return terms[index];
+    }
+
+    @Override
+    public long ord() throws IOException {
+      return index;
+    }
+
+    @Override
+    public int docFreq() throws IOException {
+      return postings[index].length;
+    }
+
+    @Override
+    public long totalTermFreq() throws IOException {
+      return docFreq();
+    }
+
+    @Override
+    public DocsEnum docs(Bits liveDocs, DocsEnum reuse, int flags)
+        throws IOException {
+      final IntArrayDocIdSetIterator iterator = new IntArrayDocIdSetIterator(postings[index]);
+      return new DocsEnum() {
+
+        @Override
+        public int freq() throws IOException {
+          return 1;
+        }
+
+        @Override
+        public int docID() {
+          return iterator.docID();
+        }
+
+        @Override
+        public int nextDoc() throws IOException {
+          return iterator.nextDoc();
+        }
+
+        @Override
+        public int advance(int target) throws IOException {
+          return iterator.advance(target);
+        }
+
+        @Override
+        public long cost() {
+          return iterator.cost();
+        }
+
+      };
+    }
+
+    @Override
+    public DocsAndPositionsEnum docsAndPositions(Bits liveDocs,
+        DocsAndPositionsEnum reuse, int flags) throws IOException {
+      return null;
+    }
+
+  }
+
+}
diff --git a/lucene/core/src/java/org/apache/lucene/search/IntArrayDocIdSetIterator.java b/lucene/core/src/java/org/apache/lucene/search/IntArrayDocIdSetIterator.java
new file mode 100644
index 0000000..4072ed2
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/search/IntArrayDocIdSetIterator.java
@@ -0,0 +1,123 @@
+package org.apache.lucene.search;
+
+import java.io.IOException;
+
+import org.apache.lucene.search.DocIdSetIterator;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * DocIdSetIterator implementation from a sorted list of integers
+ */
+public class IntArrayDocIdSetIterator extends DocIdSetIterator{
+
+  private final int[] docids;
+  private int docid;
+  private int cursor;
+  public IntArrayDocIdSetIterator(int[] ids){
+    docids = ids;
+    reset();
+  }
+
+  // used for testing
+  public void reset(){
+    docid = -1;
+    for (cursor = 0;cursor < docids.length;++cursor){
+      if (docids[cursor]>=0) {
+        break;
+      }
+    }
+    cursor--;
+    if (docids.length == 0) {
+      docid = NO_MORE_DOCS;
+    }
+  }
+
+  private final static int binarySearchForNearest(int[] arr,int val, int begin, int end) {
+    int mid = (begin + end) >> 1;
+    int midval = arr[mid];
+
+    if(mid == end)
+      return midval>=val? mid : -1;
+
+    if (midval < val) {
+      // Find number equal or greater than the target.
+      if (arr[mid + 1] >= val) return mid + 1;
+
+      return binarySearchForNearest(arr,val, mid + 1, end);
+    }
+    else {
+      // Find number equal or greater than the target.
+      if (midval == val) return mid;
+
+      return binarySearchForNearest(arr,val, begin, mid);
+    }
+  }
+
+  @Override
+  public int docID() {
+    return docid;
+  }
+
+  @Override
+  public int nextDoc() throws IOException {
+    if (cursor < docids.length-1){
+      cursor++;
+      docid = docids[cursor];
+    }
+    else{
+      docid = NO_MORE_DOCS;
+    }
+    return docid;
+  }
+
+  @Override
+  public int advance(int target) throws IOException {
+    if (docid != NO_MORE_DOCS){
+      if (target < docid) return docid;
+      if (target == docid) target = docid+1;
+      int end = Math.min(cursor + (target - docid), docids.length-1);
+      int idx = binarySearchForNearest(docids,target, cursor + 1, end);
+      if (idx!=-1){
+        if (cursor < idx){
+          cursor = idx;
+        }
+        else if (cursor == idx){
+          cursor++;
+        }
+
+        if (cursor>=docids.length){
+          return docid = NO_MORE_DOCS;
+        }
+        return (docid = docids[cursor]);
+      }
+      else{
+        cursor = docids.length-1;
+        return (docid = NO_MORE_DOCS);
+      }
+    }
+    else{
+      return NO_MORE_DOCS;
+    }
+  }
+
+  @Override
+  public long cost() {
+    return docids == null ? 0 : docids.length;
+  }
+}
diff --git a/lucene/core/src/test/org/apache/lucene/index/IndexTestUtils.java b/lucene/core/src/test/org/apache/lucene/index/IndexTestUtils.java
new file mode 100644
index 0000000..b6d40af
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/index/IndexTestUtils.java
@@ -0,0 +1,114 @@
+package org.apache.lucene.index;
+
+import java.io.IOException;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.Set;
+
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.util.BytesRef;
+
+public final class IndexTestUtils {
+
+  private IndexTestUtils() {
+  }
+
+  public static boolean compareDocIdSetIterator(DocIdSetIterator d1, DocIdSetIterator d2) throws IOException {
+    int doc;
+    while ((doc = d1.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+      int doc2 = d2.nextDoc();
+      if (doc != doc2) {
+        System.out.println("comparison failed, docs: "+doc+" != " + doc2);
+        return false;
+      }
+    }
+    return true;
+  }
+
+  public static boolean compareTerms(Terms t1, Terms t2) throws IOException {
+    TermsEnum te1 = t1.iterator(null);
+    TermsEnum te2 = t2.iterator(null);
+
+    Comparator<BytesRef> comp1 = t1.getComparator();
+    Comparator<BytesRef> comp2 = t2.getComparator();
+
+    if (!comp1.equals(comp2)) {
+      System.out.println("different term comparators");
+      return false;
+    }
+
+    BytesRef term;
+    while ((term = te1.next()) != null) {
+      BytesRef term2 = te2.next();
+
+      if (comp1.compare(term, term2) != 0) {
+        System.out.println("term comparison failed: ["+term.utf8ToString()+"] != [" +term2.utf8ToString()+"]");
+        return false;
+      }
+
+      DocsEnum d1 = te1.docs(null, null);
+      DocsEnum d2 = te2.docs(null, null);
+
+      if (!compareDocIdSetIterator(d1, d2)) {
+        System.out.println("comparison failed for term: " + term.utf8ToString());
+        return false;
+      }
+    }
+    return true;
+  }
+
+  public static boolean compareReaders(AtomicReader r1, AtomicReader r2) throws IOException{
+    Fields f1 = r1.fields();
+    Fields f2 = r2.fields();
+
+    boolean success = true;
+    Iterator<String> fnames = f1.iterator();
+
+    while(fnames.hasNext()) {
+      String fname = fnames.next();
+      Terms t1 = f1.terms(fname);
+      Terms t2 = f2.terms(fname);
+
+      if (!compareTerms(t1, t2)) return false;
+    }
+
+    return success;
+  }
+
+  public static <V> boolean testEquals(Set<V> s1, Set<V> s2) {
+    boolean success = true;
+    if (s1.size() == s2.size()) {
+      for (V v : s1) {
+        if (!s2.contains(v)) {
+          success = false;
+          break;
+        }
+      }
+    }
+    else {
+      success = false;
+    }
+    return success;
+  }
+
+  public static <V> boolean testEquals(Set<V> s, Iterator<V> iter) {
+    boolean success = true;
+    int count = 0;
+
+    V v;
+    while (iter.hasNext()) {
+      v = iter.next();
+      count ++;
+      if (!s.contains(v)) {
+        success = false;
+        break;
+      }
+    }
+
+    if (success) {
+      success = count == s.size();
+    }
+
+    return success;
+  }
+}
diff --git a/lucene/core/src/test/org/apache/lucene/index/InjectSegmentReaderTest.java b/lucene/core/src/test/org/apache/lucene/index/InjectSegmentReaderTest.java
new file mode 100644
index 0000000..ace2782
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/index/InjectSegmentReaderTest.java
@@ -0,0 +1,139 @@
+package org.apache.lucene.index;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Random;
+import java.util.Set;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+public class InjectSegmentReaderTest extends LuceneTestCase {
+  static final int NUMDOCS = 100;
+  static final String FIELD_NAME = "num";
+  static final String FIELD_DOC_VAL_NAME = "numDocVals";
+
+  RAMDirectory dir;
+  IndexReader reader;
+  AtomicReader atomicReader;
+  
+  public InjectSegmentReaderTest() {
+  }
+
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = new RAMDirectory();
+    IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_45, new MockAnalyzer(new Random()));
+    IndexWriter writer = new IndexWriter(dir, conf);
+
+    for (int i = 0; i < NUMDOCS; ++i) {
+      Document doc = new Document();
+      Field f = new TextField(FIELD_NAME, String.valueOf(i), Store.NO);
+      Field docVals = new NumericDocValuesField(FIELD_DOC_VAL_NAME, i);
+      doc.add(f);
+      doc.add(docVals);
+      writer.addDocument(doc);
+    }
+
+    writer.commit();
+    writer.forceMerge(1);
+    writer.close();
+
+    reader = DirectoryReader.open(dir);
+    atomicReader = reader.leaves().get(0).reader();
+  }
+
+  @Test
+  public void testCompositeIterators() throws IOException {
+    Integer[] l1 = new Integer[] {0,1,2,3,4};
+    Integer[] l2 = new Integer[] {5,6,7,8,9};
+
+    Iterator<Integer> i1 = Arrays.asList(l1).iterator();
+    Iterator<Integer> i2 = Arrays.asList(l2).iterator();
+
+    CompositeIterator<Integer> ci = new CompositeIterator<Integer>(i1, i2);
+    int c = 0;
+    while (ci.hasNext()) {
+      int v = ci.next();
+      assertEquals(c, v);
+      c++;
+    }
+    assertEquals(10, c);
+  }
+
+  @Test
+  public void testIntListTerms() throws IOException {
+    Terms indexedTerms = atomicReader.terms(FIELD_NAME);
+    IntListTerms memTerms = IntListTerms.fromTerms(indexedTerms);
+    assertTrue(IndexTestUtils.compareTerms(memTerms, indexedTerms));
+  }
+
+  @Test
+  public void testInjectedTerms() throws IOException {
+    String injectedField = "injected";
+    Terms indexedTerms = atomicReader.terms(FIELD_NAME);
+    IntListTerms memTerms = IntListTerms.fromTerms(indexedTerms);
+    InjectTermFilterAtomicReader injectedReader = new InjectTermFilterAtomicReader(atomicReader);
+    injectedReader.injectTerm(injectedField, memTerms);
+
+    Fields fields = injectedReader.fields();
+    Iterator<String> fieldNames = fields.iterator();
+
+    Set<String> names = new HashSet<String>(Arrays.asList(injectedField, FIELD_NAME));
+
+    assertTrue(IndexTestUtils.testEquals(names, fieldNames));
+
+    Terms t1 = injectedReader.terms(FIELD_NAME);
+    assertTrue(IndexTestUtils.compareTerms(t1, indexedTerms));
+
+    Terms t2 = injectedReader.terms(injectedField);
+    assertTrue(IndexTestUtils.compareTerms(t1, t2));
+
+    injectedReader.close();
+  }
+
+  @Test
+  public void testInjectedNumericDocValues() throws IOException {
+    String injectedField = "injectedDoc";
+
+    int maxDoc = atomicReader.maxDoc();
+
+    NumericDocValues indexedDV = atomicReader.getNumericDocValues(FIELD_DOC_VAL_NAME);
+    InjectTermFilterAtomicReader injectedReader = new InjectTermFilterAtomicReader(atomicReader);
+    injectedReader.injectNumericDocValues(injectedField, new NumericDocValues() {
+
+      @Override
+      public long get(int docID) {
+        return docID * 2;
+      }
+    });
+
+    NumericDocValues injectedDV = injectedReader.getNumericDocValues(injectedField);
+
+    for (int i = 0 ; i < maxDoc; ++i) {
+      long v1 = indexedDV.get(i);
+      long v2 = injectedDV.get(i);
+      assertEquals(v1*2, v2);
+    }
+    injectedReader.close();
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+    reader.close();
+  }
+}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestIntArrayDISI.java b/lucene/core/src/test/org/apache/lucene/search/TestIntArrayDISI.java
new file mode 100644
index 0000000..151ac14
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/search/TestIntArrayDISI.java
@@ -0,0 +1,80 @@
+package org.apache.lucene.search;
+
+import junit.framework.TestCase;
+
+import org.junit.Test;
+
+import org.apache.lucene.search.IntArrayDocIdSetIterator;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestIntArrayDISI {
+  
+  public TestIntArrayDISI() {}
+  
+  @Test
+  public void testIntArrayDSI() throws Exception{
+    int[] arr = new int[]{-1,-1,1,3,5,7,9};
+    IntArrayDocIdSetIterator iter = new IntArrayDocIdSetIterator(arr);
+    int doc = iter.nextDoc();
+    TestCase.assertEquals(1,doc);
+    doc = iter.nextDoc();
+    TestCase.assertEquals(3,doc);
+
+    iter.reset();
+    for (int i=0;i<5;++i){
+      doc = iter.nextDoc();
+    }
+    TestCase.assertEquals(9,doc);
+    doc = iter.nextDoc();
+    TestCase.assertEquals(DocIdSetIterator.NO_MORE_DOCS,doc);
+
+    iter.reset();
+    doc = iter.advance(6);
+    TestCase.assertEquals(7,doc);
+
+    doc = iter.advance(7);
+    TestCase.assertEquals(9,doc);
+
+    iter.reset();
+    doc = iter.advance(9);
+    TestCase.assertEquals(9,doc);
+    doc = iter.nextDoc();
+    TestCase.assertEquals(DocIdSetIterator.NO_MORE_DOCS,doc);
+
+    iter.reset();
+    doc = iter.advance(10);
+    TestCase.assertEquals(DocIdSetIterator.NO_MORE_DOCS,doc);
+
+
+    arr = new int[]{1,3,5,7,9};
+    iter = new IntArrayDocIdSetIterator(arr);
+    doc = iter.nextDoc();
+    doc = iter.nextDoc();
+    doc = iter.nextDoc();
+    doc = iter.advance(1);
+    TestCase.assertEquals(5,doc);
+    arr = new int[]{1,3,5,7,9};
+    iter = new IntArrayDocIdSetIterator(arr);
+    doc = iter.advance(1);
+    TestCase.assertEquals(1,doc);
+    doc = iter.advance(1);
+    TestCase.assertEquals(3,doc);
+  }
+  
+}
