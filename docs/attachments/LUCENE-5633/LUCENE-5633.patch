Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1591297)
+++ lucene/CHANGES.txt	(working copy)
@@ -107,6 +107,9 @@
   longer receives the number of fields that will be added (Robert
   Muir, Mike McCandless)
 
+* LUCENE-5633: Make NoMergePolicy a singleton with no distinction between
+  compound and non-compound types. (Shai Erera)
+
 Optimizations
 
 * LUCENE-5603: hunspell stemmer more efficiently strips prefixes
Index: lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
===================================================================
--- lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java	(revision 1591297)
+++ lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java	(working copy)
@@ -138,8 +138,9 @@
     final String mergePolicy = config.get("merge.policy",
                                           "org.apache.lucene.index.LogByteSizeMergePolicy");
     boolean isCompound = config.get("compound", true);
+    iwConf.setUseCompoundFile(isCompound);
     if (mergePolicy.equals(NoMergePolicy.class.getName())) {
-      iwConf.setMergePolicy(isCompound ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES);
+      iwConf.setMergePolicy(NoMergePolicy.INSTANCE);
     } else {
       try {
         iwConf.setMergePolicy(Class.forName(mergePolicy).asSubclass(MergePolicy.class).newInstance());
@@ -147,7 +148,7 @@
         throw new RuntimeException("unable to instantiate class '" + mergePolicy + "' as merge policy", e);
       }
       iwConf.getMergePolicy().setNoCFSRatio(isCompound ? 1.0 : 0.0);
-      if(iwConf.getMergePolicy() instanceof LogMergePolicy) {
+      if (iwConf.getMergePolicy() instanceof LogMergePolicy) {
         LogMergePolicy logMergePolicy = (LogMergePolicy) iwConf.getMergePolicy();
         logMergePolicy.setMergeFactor(config.get("merge.factor",OpenIndexTask.DEFAULT_MERGE_PFACTOR));
       }
Index: lucene/core/src/java/org/apache/lucene/index/NoMergePolicy.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/NoMergePolicy.java	(revision 1591297)
+++ lucene/core/src/java/org/apache/lucene/index/NoMergePolicy.java	(working copy)
@@ -22,34 +22,16 @@
 
 
 /**
- * A {@link MergePolicy} which never returns merges to execute (hence it's
- * name). It is also a singleton and can be accessed through
- * {@link NoMergePolicy#NO_COMPOUND_FILES} if you want to indicate the index
- * does not use compound files, or through {@link NoMergePolicy#COMPOUND_FILES}
- * otherwise. Use it if you want to prevent an {@link IndexWriter} from ever
- * executing merges, without going through the hassle of tweaking a merge
- * policy's settings to achieve that, such as changing its merge factor.
+ * A {@link MergePolicy} which never returns merges to execute. Use it if you
+ * want to prevent segment merges.
  */
 public final class NoMergePolicy extends MergePolicy {
 
-  /**
-   * A singleton {@link NoMergePolicy} which indicates the index does not use
-   * compound files.
-   */
-  public static final MergePolicy NO_COMPOUND_FILES = new NoMergePolicy(false);
+  /** Singleton instance. */
+  public static final MergePolicy INSTANCE = new NoMergePolicy();
 
-  /**
-   * A singleton {@link NoMergePolicy} which indicates the index uses compound
-   * files.
-   */
-  public static final MergePolicy COMPOUND_FILES = new NoMergePolicy(true);
-
-  private final boolean useCompoundFile;
-  
-  private NoMergePolicy(boolean useCompoundFile) {
-    super(useCompoundFile ? 1.0 : 0.0, 0);
-    // prevent instantiation
-    this.useCompoundFile = useCompoundFile;
+  private NoMergePolicy() {
+    super();
   }
 
   @Override
@@ -66,7 +48,9 @@
   public MergeSpecification findForcedDeletesMerges(SegmentInfos segmentInfos) { return null; }
 
   @Override
-  public boolean useCompoundFile(SegmentInfos segments, SegmentCommitInfo newSegment) { return useCompoundFile; }
+  public boolean useCompoundFile(SegmentInfos segments, SegmentCommitInfo newSegment) {
+    return newSegment.info.getUseCompoundFile();
+  }
 
   @Override
   public void setIndexWriter(IndexWriter writer) {}
@@ -73,7 +57,7 @@
   
   @Override
   protected long size(SegmentCommitInfo info) throws IOException {
-      return Long.MAX_VALUE;
+    return Long.MAX_VALUE;
   }
 
   @Override
Index: lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -417,7 +417,7 @@
     setUpDirs(dir, aux, true);
 
     IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      .setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(aux, dontMergeConfig);
     for (int i = 0; i < 20; i++) {
       writer.deleteDocuments(new Term("id", "" + i));
@@ -469,7 +469,7 @@
     writer.shutdown();
 
     IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      .setMergePolicy(NoMergePolicy.INSTANCE);
     writer = new IndexWriter(aux, dontMergeConfig);
     for (int i = 0; i < 27; i++) {
       writer.deleteDocuments(new Term("id", "" + i));
@@ -480,7 +480,7 @@
     reader.close();
 
     dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-    .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    .setMergePolicy(NoMergePolicy.INSTANCE);
     writer = new IndexWriter(aux2, dontMergeConfig);
     for (int i = 0; i < 8; i++) {
       writer.deleteDocuments(new Term("id", "" + i));
Index: lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -629,9 +629,7 @@
       addNoProxDoc(writer);
       writer.shutdown();
 
-      writer = new IndexWriter(dir,
-        conf.setMergePolicy(doCFS ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES)
-      );
+      writer = new IndexWriter(dir, conf.setMergePolicy(NoMergePolicy.INSTANCE));
       Term searchTerm = new Term("id", "7");
       writer.deleteDocuments(searchTerm);
       writer.shutdown();
Index: lucene/core/src/test/org/apache/lucene/index/TestBinaryDocValuesUpdates.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestBinaryDocValuesUpdates.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestBinaryDocValuesUpdates.java	(working copy)
@@ -148,7 +148,7 @@
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     conf.setMaxBufferedDocs(2); // generate few segments
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges for this test
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges for this test
     IndexWriter writer = new IndexWriter(dir, conf);
     int numDocs = 10;
     long[] expectedValues = new long[numDocs];
@@ -235,7 +235,7 @@
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     conf.setMaxBufferedDocs(10); // control segment flushing
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges for this test
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges for this test
     IndexWriter writer = new IndexWriter(dir, conf);
     
     for (int i = 0; i < 6; i++) {
@@ -851,7 +851,7 @@
     // prevent merges, otherwise by the time updates are applied
     // (writer.shutdown()), the segments might have merged and that update becomes
     // legit.
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(dir, conf);
     
     // first segment with BDV
@@ -906,7 +906,7 @@
     // prevent merges, otherwise by the time updates are applied
     // (writer.shutdown()), the segments might have merged and that update becomes
     // legit.
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(dir, conf);
     
     // first segment with BDV
@@ -1172,7 +1172,7 @@
   public void testChangeCodec() throws Exception {
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // disable merges to simplify test assertions.
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // disable merges to simplify test assertions.
     conf.setCodec(new Lucene46Codec() {
       @Override
       public DocValuesFormat getDocValuesFormatForField(String field) {
Index: lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers.java	(working copy)
@@ -37,7 +37,7 @@
   public void testSameFieldNumbersAcrossSegments() throws Exception {
     for (int i = 0; i < 2; i++) {
       Directory dir = newDirectory();
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
 
       Document d1 = new Document();
       d1.add(new StringField("f1", "first field", Field.Store.YES));
@@ -46,7 +46,7 @@
 
       if (i == 1) {
         writer.shutdown();
-        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
       } else {
         writer.commit();
       }
@@ -100,7 +100,7 @@
   public void testAddIndexes() throws Exception {
     Directory dir1 = newDirectory();
     Directory dir2 = newDirectory();
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
 
     Document d1 = new Document();
     d1.add(new TextField("f1", "first field", Field.Store.YES));
@@ -108,7 +108,7 @@
     writer.addDocument(d1);
 
     writer.shutdown();
-    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
 
     Document d2 = new Document();
     FieldType customType2 = new FieldType(TextField.TYPE_STORED);
@@ -121,7 +121,7 @@
 
     writer.shutdown();
 
-    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
     writer.addIndexes(dir2);
     writer.shutdown();
 
@@ -151,7 +151,7 @@
       {
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(
-            NoMergePolicy.NO_COMPOUND_FILES));
+            NoMergePolicy.INSTANCE));
         Document d = new Document();
         d.add(new TextField("f1", "d1 first field", Field.Store.YES));
         d.add(new TextField("f2", "d1 second field", Field.Store.YES));
@@ -168,9 +168,7 @@
 
       {
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(
-            random().nextBoolean() ? NoMergePolicy.NO_COMPOUND_FILES
-                : NoMergePolicy.COMPOUND_FILES));
+            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
         Document d = new Document();
         d.add(new TextField("f1", "d2 first field", Field.Store.YES));
         d.add(new StoredField("f3", new byte[] { 1, 2, 3 }));
@@ -190,9 +188,7 @@
 
       {
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(
-            random().nextBoolean() ? NoMergePolicy.NO_COMPOUND_FILES
-                : NoMergePolicy.COMPOUND_FILES));
+            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
         Document d = new Document();
         d.add(new TextField("f1", "d3 first field", Field.Store.YES));
         d.add(new TextField("f2", "d3 second field", Field.Store.YES));
@@ -217,9 +213,7 @@
 
       {
         IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(
-            random().nextBoolean() ? NoMergePolicy.NO_COMPOUND_FILES
-                : NoMergePolicy.COMPOUND_FILES));
+            TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
         writer.deleteDocuments(new Term("f1", "d1"));
         // nuke the first segment entirely so that the segment with gaps is
         // loaded first!
Index: lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(working copy)
@@ -652,7 +652,7 @@
         writer.shutdown();
         conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
           .setIndexDeletionPolicy(policy)
-          .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+          .setMergePolicy(NoMergePolicy.INSTANCE);
         writer = new IndexWriter(dir, conf);
         policy = (KeepLastNDeletionPolicy) writer.getConfig().getIndexDeletionPolicy();
         writer.deleteDocuments(new Term("id", "" + (i*(N+1)+3)));
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexFileDeleter.java	(working copy)
@@ -72,7 +72,7 @@
     writer = new IndexWriter(
         dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).
-            setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setUseCompoundFile(true)
+            setMergePolicy(NoMergePolicy.INSTANCE).setUseCompoundFile(true)
     );
     Term searchTerm = new Term("id", "7");
     writer.deleteDocuments(searchTerm);
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -21,7 +21,6 @@
 import java.io.IOException;
 import java.io.PrintStream;
 import java.io.StringReader;
-import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
@@ -32,7 +31,12 @@
 import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 
-import org.apache.lucene.analysis.*;
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.MockTokenFilter;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.codecs.Codec;
@@ -112,7 +116,7 @@
         writer.shutdown();
 
         // delete 40 documents
-        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES));
+        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
         for (i = 0; i < 40; i++) {
             writer.deleteDocuments(new Term("id", ""+i));
         }
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.PrintStream;
-import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
@@ -1025,7 +1024,7 @@
     // note: tiny rambuffer used, as with a 1MB buffer the test is too slow (flush @ 128,999)
     IndexWriter w = new IndexWriter(dir,
                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-                                    .setRAMBufferSizeMB(0.1f).setMaxBufferedDocs(1000).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false));
+                                    .setRAMBufferSizeMB(0.1f).setMaxBufferedDocs(1000).setMergePolicy(NoMergePolicy.INSTANCE).setReaderPooling(false));
     int count = 0;
     while(true) {
       Document doc = new Document();
@@ -1071,7 +1070,7 @@
     final int flushAtDelCount = atLeast(1020);
     IndexWriter w = new IndexWriter(dir,
                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).
-                                    setMaxBufferedDeleteTerms(flushAtDelCount).setMaxBufferedDocs(1000).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false));
+                                    setMaxBufferedDeleteTerms(flushAtDelCount).setMaxBufferedDocs(1000).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergePolicy(NoMergePolicy.INSTANCE).setReaderPooling(false));
     int count = 0;
     while(true) {
       Document doc = new Document();
@@ -1112,7 +1111,7 @@
     final AtomicBoolean sawAfterFlush = new AtomicBoolean();
     IndexWriter w = new IndexWriter(dir,
                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).
-                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {
+                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.INSTANCE).setReaderPooling(false)) {
         @Override
         public void doAfterFlush() {
           assertTrue("only " + docsInSegment.get() + " in segment", closing.get() || docsInSegment.get() >= 7);
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -54,8 +54,8 @@
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.MockDirectoryWrapper.FakeIOException;
-import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -708,9 +708,7 @@
       {
         final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(-1)
-            .setMergePolicy(
-                random().nextBoolean() ? NoMergePolicy.COMPOUND_FILES
-                    : NoMergePolicy.NO_COMPOUND_FILES));
+            .setMergePolicy(NoMergePolicy.INSTANCE));
         // don't use a merge policy here they depend on the DWPThreadPool and its max thread states etc.
         final int finalI = i;
 
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(working copy)
@@ -196,7 +196,7 @@
     writer = new IndexWriter(
         dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).
-            setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)
+            setMergePolicy(NoMergePolicy.INSTANCE)
     );
     writer.deleteDocuments(new Term("content", "aaa"));
     writer.shutdown();
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -16,7 +16,6 @@
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Random;
 import java.util.concurrent.atomic.AtomicReference;
 
@@ -156,7 +155,7 @@
     ir.close();
 
     IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      .setMergePolicy(NoMergePolicy.INSTANCE);
     writer = new IndexWriter(dir, dontMergeConfig);
     writer.deleteDocuments(new Term("id", "0"));
     writer.deleteDocuments(new Term("id", "7"));
@@ -219,7 +218,7 @@
     ir.close();
     
     IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      .setMergePolicy(NoMergePolicy.INSTANCE);
     writer = new IndexWriter(dir, dontMergeConfig);
     for(int i=0;i<98;i+=2) {
       writer.deleteDocuments(new Term("id", "" + i));
@@ -285,7 +284,7 @@
     ir.close();
     
     IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-      .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+      .setMergePolicy(NoMergePolicy.INSTANCE);
     writer = new IndexWriter(dir, dontMergeConfig);
     for(int i=0;i<98;i+=2) {
       writer.deleteDocuments(new Term("id", "" + i));
Index: lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -124,11 +124,7 @@
       iwc.setMaxBufferedDocs(20);
     }
     // no merging
-    if (random().nextBoolean()) {
-      iwc.setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES);
-    } else {
-      iwc.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
-    }
+    iwc.setMergePolicy(NoMergePolicy.INSTANCE);
     if (VERBOSE) {
       System.out.println("TEST: make index");
     }
@@ -238,11 +234,7 @@
       iwc.setMaxBufferedDocs(20);
     }
     // no merging
-    if (random().nextBoolean()) {
-      iwc.setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES);
-    } else {
-      iwc.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
-    }
+    iwc.setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(dir1, iwc);
 
     // create the index
@@ -1084,7 +1076,7 @@
     });
     
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges from getting in the way
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges from getting in the way
     IndexWriter writer = new IndexWriter(dir, conf);
     
     // create a segment and open an NRT reader
Index: lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java	(working copy)
@@ -36,7 +36,7 @@
 
       Directory dir = newDirectory();
 
-      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
       // we can do this because we use NoMergePolicy (and dont merge to "nothing")
       w.setKeepFullyDeletedSegments(true);
 
Index: lucene/core/src/test/org/apache/lucene/index/TestNoMergePolicy.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestNoMergePolicy.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestNoMergePolicy.java	(working copy)
@@ -29,21 +29,14 @@
 
   @Test
   public void testNoMergePolicy() throws Exception {
-    MergePolicy mp = NoMergePolicy.NO_COMPOUND_FILES;
+    MergePolicy mp = NoMergePolicy.INSTANCE;
     assertNull(mp.findMerges(null, (SegmentInfos)null));
     assertNull(mp.findForcedMerges(null, 0, null));
     assertNull(mp.findForcedDeletesMerges(null));
-    assertFalse(mp.useCompoundFile(null, null));
     mp.close();
   }
 
   @Test
-  public void testCompoundFiles() throws Exception {
-    assertFalse(NoMergePolicy.NO_COMPOUND_FILES.useCompoundFile(null, null));
-    assertTrue(NoMergePolicy.COMPOUND_FILES.useCompoundFile(null, null));
-  }
-
-  @Test
   public void testFinalSingleton() throws Exception {
     assertTrue(Modifier.isFinal(NoMergePolicy.class.getModifiers()));
     Constructor<?>[] ctors = NoMergePolicy.class.getDeclaredConstructors();
Index: lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates.java	(working copy)
@@ -127,7 +127,7 @@
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     conf.setMaxBufferedDocs(2); // generate few segments
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges for this test
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges for this test
     IndexWriter writer = new IndexWriter(dir, conf);
     int numDocs = 10;
     long[] expectedValues = new long[numDocs];
@@ -212,7 +212,7 @@
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
     conf.setMaxBufferedDocs(10); // control segment flushing
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges for this test
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges for this test
     IndexWriter writer = new IndexWriter(dir, conf);
     
     for (int i = 0; i < 6; i++) {
@@ -830,7 +830,7 @@
     // prevent merges, otherwise by the time updates are applied
     // (writer.shutdown()), the segments might have merged and that update becomes
     // legit.
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(dir, conf);
     
     // first segment with NDV
@@ -884,7 +884,7 @@
     // prevent merges, otherwise by the time updates are applied
     // (writer.shutdown()), the segments might have merged and that update becomes
     // legit.
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     IndexWriter writer = new IndexWriter(dir, conf);
     
     // first segment with NDV
@@ -1152,7 +1152,7 @@
   public void testChangeCodec() throws Exception {
     Directory dir = newDirectory();
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // disable merges to simplify test assertions.
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // disable merges to simplify test assertions.
     conf.setCodec(new Lucene46Codec() {
       @Override
       public DocValuesFormat getDocValuesFormatForField(String field) {
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelCompositeReader.java	(working copy)
@@ -479,7 +479,7 @@
   private Directory getDir1(Random random) throws IOException {
     Directory dir1 = newDirectory();
     IndexWriter w1 = new IndexWriter(dir1, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES));
+        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.INSTANCE));
     Document d1 = new Document();
     d1.add(newTextField("f1", "v1", Field.Store.YES));
     d1.add(newTextField("f2", "v1", Field.Store.YES));
@@ -506,7 +506,7 @@
   private Directory getDir2(Random random) throws IOException {
     Directory dir2 = newDirectory();
     IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES));
+        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.INSTANCE));
     Document d1 = new Document();
     d1.add(newTextField("f3", "v1", Field.Store.YES));
     d1.add(newTextField("f4", "v1", Field.Store.YES));
@@ -533,7 +533,7 @@
   private Directory getInvalidStructuredDir2(Random random) throws IOException {
     Directory dir2 = newDirectory();
     IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES));
+        new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.INSTANCE));
     Document d1 = new Document();
     d1.add(newTextField("f3", "v1", Field.Store.YES));
     d1.add(newTextField("f4", "v1", Field.Store.YES));
Index: lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(working copy)
@@ -104,7 +104,7 @@
       iw.shutdown();
 
       IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))
-        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+        .setMergePolicy(NoMergePolicy.INSTANCE);
       if (VERBOSE) {
         System.out.println("\nTEST: make 2nd writer");
       }
Index: lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java	(working copy)
@@ -48,7 +48,7 @@
     conf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);
     conf.setRAMBufferSizeMB(IndexWriterConfig.DEFAULT_RAM_BUFFER_SIZE_MB);
     // prevent any merges by default.
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     return conf;
   }
   
Index: lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java	(revision 1591297)
+++ lucene/core/src/test/org/apache/lucene/search/TestControlledRealTimeReopenThread.java	(working copy)
@@ -45,9 +45,8 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.NRTCachingDirectory;
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
 import org.apache.lucene.util.Version;
 
@@ -304,7 +303,7 @@
    */
   public void testThreadStarvationNoDeleteNRTReader() throws IOException, InterruptedException {
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    conf.setMergePolicy(random().nextBoolean() ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES);
+    conf.setMergePolicy(NoMergePolicy.INSTANCE);
     Directory d = newDirectory();
     final CountDownLatch latch = new CountDownLatch(1);
     final CountDownLatch signal = new CountDownLatch(1);
Index: lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java
===================================================================
--- lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java	(revision 1591297)
+++ lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts.java	(working copy)
@@ -651,7 +651,7 @@
     Directory taxoDir = newDirectory();
     
     IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    iwc.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges
+    iwc.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges
     IndexWriter indexWriter = new IndexWriter(indexDir, iwc);
 
     TaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);
Index: lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts2.java
===================================================================
--- lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts2.java	(revision 1591297)
+++ lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts2.java	(working copy)
@@ -242,7 +242,7 @@
     // 4. Segment w/ categories, but only some results
     
     IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    conf.setMergePolicy(NoMergePolicy.COMPOUND_FILES); // prevent merges, so we can control the index segments
+    conf.setMergePolicy(NoMergePolicy.INSTANCE); // prevent merges, so we can control the index segments
     IndexWriter indexWriter = new IndexWriter(indexDir, conf);
     TaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);
 
Index: lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java
===================================================================
--- lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java	(revision 1591297)
+++ lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupFacetCollectorTest.java	(working copy)
@@ -286,7 +286,7 @@
         random(),
         dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT,
-            new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+            new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
     boolean useDv = false;
 
     // Cannot assert this since we use NoMergePolicy:
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(revision 1591297)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoin.java	(working copy)
@@ -65,7 +65,7 @@
   public void testEmptyChildFilter() throws Exception {
     final Directory dir = newDirectory();
     final IndexWriterConfig config = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));
-    config.setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES);
+    config.setMergePolicy(NoMergePolicy.INSTANCE);
     // we don't want to merge - since we rely on certain segment setup
     final IndexWriter w = new IndexWriter(dir, config);
 
@@ -387,7 +387,7 @@
         random(),
         dir,
         newIndexWriterConfig(TEST_VERSION_CURRENT,
-            new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+            new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
 
     // Cannot assert this since we use NoMergePolicy:
     w.setDoRandomForceMergeAssert(false);
Index: lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinSorting.java
===================================================================
--- lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinSorting.java	(revision 1591297)
+++ lucene/join/src/test/org/apache/lucene/search/join/TestBlockJoinSorting.java	(working copy)
@@ -53,7 +53,7 @@
   public void testNestedSorting() throws Exception {
     final Directory dir = newDirectory();
     final RandomIndexWriter w = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+        new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
 
     List<Document> docs = new ArrayList<>();
     Document document = new Document();
Index: lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(revision 1591297)
+++ lucene/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(working copy)
@@ -1,4 +1,5 @@
 package org.apache.lucene.index;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -22,7 +23,6 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.LuceneTestCase.SuppressSysoutChecks;
 
 public class TestMultiPassIndexSplitter extends LuceneTestCase {
   IndexReader input;
@@ -33,7 +33,7 @@
   public void setUp() throws Exception {
     super.setUp();
     dir = newDirectory();
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
     Document doc;
     for (int i = 0; i < NUM_DOCS; i++) {
       doc = new Document();
Index: lucene/misc/src/test/org/apache/lucene/index/TestPKIndexSplitter.java
===================================================================
--- lucene/misc/src/test/org/apache/lucene/index/TestPKIndexSplitter.java	(revision 1591297)
+++ lucene/misc/src/test/org/apache/lucene/index/TestPKIndexSplitter.java	(working copy)
@@ -38,7 +38,7 @@
     Directory dir = newDirectory();
     IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))
-        .setOpenMode(OpenMode.CREATE).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+        .setOpenMode(OpenMode.CREATE).setMergePolicy(NoMergePolicy.INSTANCE));
     for (int x = 0; x < 11; x++) {
       Document doc = createDocument(x, "1", 3, format);
       w.addDocument(doc);
@@ -58,7 +58,7 @@
     // delete some documents
     w = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))
-        .setOpenMode(OpenMode.APPEND).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+        .setOpenMode(OpenMode.APPEND).setMergePolicy(NoMergePolicy.INSTANCE));
     w.deleteDocuments(midTerm);
     w.deleteDocuments(new Term("id", format.format(2)));
     w.shutdown();
Index: lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java	(revision 1591297)
+++ lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase.java	(working copy)
@@ -651,7 +651,7 @@
   public void testBulkMergeWithDeletes() throws IOException {
     final int numDocs = atLeast(200);
     Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+    RandomIndexWriter w = new RandomIndexWriter(random(), dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));
     for (int i = 0; i < numDocs; ++i) {
       Document doc = new Document();
       doc.add(new StringField("id", Integer.toString(i), Store.YES));
