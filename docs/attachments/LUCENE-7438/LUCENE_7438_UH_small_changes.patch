Index: lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java	(date 1475337564000)
+++ lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/visibility/TestUnifiedHighlighterExtensibility.java	(revision )
@@ -22,14 +22,11 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 import java.util.SortedSet;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
@@ -44,13 +41,12 @@
 import org.apache.lucene.search.uhighlight.PhraseHelper;
 import org.apache.lucene.search.uhighlight.UnifiedHighlighter;
 import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
 import org.junit.Test;
 
-import static org.junit.Assert.assertEquals;
+public class TestUnifiedHighlighterExtensibility extends LuceneTestCase {
 
-public class TestUnifiedHighlighterExtensibility {
-
   /**
    * This test is for maintaining the extensibility of the FieldOffsetStrategy
    * for customizations out of package.
@@ -72,21 +68,6 @@
         return Collections.emptyList();
       }
 
-      @Override
-      protected List<OffsetsEnum> createOffsetsEnums(LeafReader leafReader, int doc, TokenStream tokenStream) throws IOException {
-        return super.createOffsetsEnums(leafReader, doc, tokenStream);
-      }
-
-      @Override
-      protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader atomicReader, int doc) throws IOException {
-        return super.createOffsetsEnumsFromReader(atomicReader, doc);
-      }
-
-      @Override
-      protected OffsetsEnum createOffsetsEnumFromTokenStream(int doc, TokenStream tokenStream) throws IOException {
-        return super.createOffsetsEnumFromTokenStream(doc, tokenStream);
-      }
-
     };
     assertEquals(offsetSource, strategy.getOffsetSource());
   }
@@ -98,7 +79,7 @@
   @Test
   public void testUnifiedHighlighterExtensibility() {
     final int maxLength = 1000;
-    UnifiedHighlighter uh = new UnifiedHighlighter(null, new MockAnalyzer(new Random())){
+    UnifiedHighlighter uh = new UnifiedHighlighter(null, new MockAnalyzer(random())){
 
       @Override
       protected Map<String, Object[]> highlightFieldsAsObjects(String[] fieldsIn, Query query, int[] docIdsIn, int[] maxPassagesIn) throws IOException {
@@ -161,8 +142,8 @@
       }
 
       @Override
-      protected FieldOffsetStrategy getOffsetStrategy(OffsetSource offsetSource, String field, BytesRef[] terms, PhraseHelper phraseHelper, CharacterRunAutomaton[] automata) {
-        return super.getOffsetStrategy(offsetSource, field, terms, phraseHelper, automata);
+      protected FieldOffsetStrategy getOffsetStrategy(String field, Query query, SortedSet<Term> allTerms) {
+        return super.getOffsetStrategy(field, query, allTerms);
       }
 
       @Override
Index: lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java	(date 1475337564000)
+++ lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/UnifiedHighlighter.java	(revision )
@@ -715,13 +715,8 @@
   }
 
   protected FieldHighlighter getFieldHighlighter(String field, Query query, SortedSet<Term> allTerms, int maxPassages) {
-    BytesRef[] terms = filterExtractedTerms(field, allTerms);
-    EnumSet<HighlightFlag> highlightFlags = getFlags(field);
-    PhraseHelper phraseHelper = getPhraseHelper(field, query, highlightFlags);
-    CharacterRunAutomaton[] automata = getAutomata(field, query, highlightFlags);
-    OffsetSource offsetSource = getOptimizedOffsetSource(field, terms, phraseHelper, automata);
     return new FieldHighlighter(field,
-        getOffsetStrategy(offsetSource, field, terms, phraseHelper, automata),
+        getOffsetStrategy(field, query, allTerms),
         new SplittingBreakIterator(getBreakIterator(field), UnifiedHighlighter.MULTIVAL_SEP_CHAR),
         getScorer(field),
         maxPassages,
@@ -729,19 +724,26 @@
         getFormatter(field));
   }
 
-  protected static BytesRef[] filterExtractedTerms(String field, SortedSet<Term> queryTerms) {
-    // TODO consider requireFieldMatch
-    Term floor = new Term(field, "");
-    Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);
-    SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);
-
-    // Strip off the redundant field:
-    BytesRef[] terms = new BytesRef[fieldTerms.size()];
-    int termUpto = 0;
-    for (Term term : fieldTerms) {
-      terms[termUpto++] = term.bytes();
+  protected FieldOffsetStrategy getOffsetStrategy(String field, Query query, SortedSet<Term> allTerms) {
+    EnumSet<HighlightFlag> highlightFlags = getFlags(field);
+    BytesRef[] terms = filterExtractedTerms(field, allTerms);
+    PhraseHelper phraseHelper = getPhraseHelper(field, query, highlightFlags);
+    CharacterRunAutomaton[] automata = getAutomata(field, query, highlightFlags);
+    OffsetSource offsetSource = getOptimizedOffsetSource(field, terms, phraseHelper, automata);
+    switch (offsetSource) {
+      case ANALYSIS:
+        return new AnalysisOffsetStrategy(field, terms, phraseHelper, automata, getIndexAnalyzer());
+      case NONE_NEEDED:
+        return NoOpOffsetStrategy.INSTANCE;
+      case TERM_VECTORS:
+        return new TermVectorOffsetStrategy(field, terms, phraseHelper, automata);
+      case POSTINGS:
+        return new PostingsOffsetStrategy(field, terms, phraseHelper, automata);
+      case POSTINGS_WITH_TERM_VECTORS:
+        return new PostingsWithTermVectorsOffsetStrategy(field, terms, phraseHelper, automata);
+      default:
+        throw new IllegalArgumentException("Unrecognized offset source " + offsetSource);
     }
-    return terms;
   }
 
   protected EnumSet<HighlightFlag> getFlags(String field) {
@@ -755,6 +757,21 @@
     return highlightFlags;
   }
 
+  protected BytesRef[] filterExtractedTerms(String field, SortedSet<Term> queryTerms) {
+    // TODO consider requireFieldMatch
+    Term floor = new Term(field, "");
+    Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);
+    SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);
+
+    // Strip off the redundant field:
+    BytesRef[] terms = new BytesRef[fieldTerms.size()];
+    int termUpto = 0;
+    for (Term term : fieldTerms) {
+      terms[termUpto++] = term.bytes();
+    }
+    return terms;
+  }
+
   protected PhraseHelper getPhraseHelper(String field, Query query, EnumSet<HighlightFlag> highlightFlags) {
     boolean highlightPhrasesStrictly = highlightFlags.contains(HighlightFlag.PHRASES);
     boolean handleMultiTermQuery = highlightFlags.contains(HighlightFlag.MULTI_TERM_QUERY);
@@ -770,12 +787,11 @@
   }
 
   protected OffsetSource getOptimizedOffsetSource(String field, BytesRef[] terms, PhraseHelper phraseHelper, CharacterRunAutomaton[] automata) {
-    OffsetSource offsetSource = getOffsetSource(field);
-
     if (terms.length == 0 && automata.length == 0 && !phraseHelper.willRewrite()) {
       return OffsetSource.NONE_NEEDED; //nothing to highlight
     }
 
+    OffsetSource offsetSource = getOffsetSource(field);
     switch (offsetSource) {
       case POSTINGS:
         if (phraseHelper.willRewrite()) {
@@ -801,24 +817,6 @@
     }
 
     return offsetSource;
-  }
-
-  protected FieldOffsetStrategy getOffsetStrategy(OffsetSource offsetSource, String field, BytesRef[] terms,
-                                                  PhraseHelper phraseHelper, CharacterRunAutomaton[] automata) {
-    switch (offsetSource) {
-      case ANALYSIS:
-        return new AnalysisOffsetStrategy(field, terms, phraseHelper, automata, getIndexAnalyzer());
-      case NONE_NEEDED:
-        return NoOpOffsetStrategy.INSTANCE;
-      case TERM_VECTORS:
-        return new TermVectorOffsetStrategy(field, terms, phraseHelper, automata);
-      case POSTINGS:
-        return new PostingsOffsetStrategy(field, terms, phraseHelper, automata);
-      case POSTINGS_WITH_TERM_VECTORS:
-        return new PostingsWithTermVectorsOffsetStrategy(field, terms, phraseHelper, automata);
-      default:
-        throw new IllegalArgumentException("Unrecognized offset source " + offsetSource);
-    }
   }
 
   /**
