Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/PrefillTokenStream.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/PrefillTokenStream.java	(revision 0)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/PrefillTokenStream.java	(working copy)
@@ -0,0 +1,105 @@
+package org.apache.lucene.analysis.sinks;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.AttributeImpl;
+
+/**
+ * A {@link TokenStream} that is prefilled by adding token attribute states.
+ * This can be used to split an input token stream into multiple {@link PrefillTokenStream}s.
+ * To cache a complete input token stream,
+ * a {@link org.apache.lucene.analysis.CachingTokenFilter} can be used.
+ */
+public class PrefillTokenStream extends TokenStream {
+
+  private final List<AttributeSource.State> cachedStates = new ArrayList<>();
+  private AttributeSource.State finalState;
+  private Iterator<AttributeSource.State> it = null;
+
+  /** A prefilled TokenStream.
+   * This stream can filled by {@link #addState} and {@link #setFinalState}.
+   * This stream can be (re)started by {@link #reset} and reused after {@link #close}.
+   * @param source See {@link TokenStream#TokenStream(AttributeSource)}.
+   */
+  public PrefillTokenStream(AttributeSource source) {
+    super(source);
+  }
+
+  /** Add a token state to be used later at a single invocation of {@link #incrementToken}. */
+  public void addState(AttributeSource.State state) {
+    if (it != null) {
+      throw new IllegalStateException("State can only be added before the stream is consumed.");
+    }
+    cachedStates.add(state);
+  }
+
+  /** Add the token state to be used later at invocation of {@link #end}. */
+  public void setFinalState(AttributeSource.State finalState) {
+    this.finalState = finalState;
+  }
+
+  /** Prepare the token stream so a next {@link #incrementToken} will use the earliest added state. */
+  @Override
+  public final void reset() {
+    it = cachedStates.iterator();
+  }
+
+  /** Restore the earliest token state added by {@link #addState} that was not restored yet.
+   * {@link #addState} should not be used after this.
+   * @return true iff such a token state was available.
+   */
+  @Override
+  public final boolean incrementToken() {
+    // lazy init the iterator
+    if (it == null) {
+      it = cachedStates.iterator();
+    }
+
+    if (!it.hasNext()) {
+      return false;
+    }
+
+    AttributeSource.State state = it.next();
+    restoreState(state);
+    return true;
+  }
+
+  /** When a {@link #setFinalState} was done, restore that token state. */
+  @Override
+  public final void end() {
+    if (finalState != null) {
+      restoreState(finalState);
+    }
+  }
+
+  /** Release resources and prepare reuse by releasing all token states. */
+  @Override
+  public void close() throws IOException {
+    super.close();
+    cachedStates.clear();
+    finalState = null;
+  }
+}
+
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TeeSinkTokenFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TeeSinkTokenFilter.java	(revision 1681580)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TeeSinkTokenFilter.java	(working copy)
@@ -76,7 +76,7 @@
  */
 public final class TeeSinkTokenFilter extends TokenFilter {
   private final List<WeakReference<SinkTokenStream>> sinks = new LinkedList<>();
-  
+
   /**
    * Instantiates a new TeeSinkTokenFilter.
    */
@@ -90,7 +90,7 @@
   public SinkTokenStream newSinkTokenStream() {
     return newSinkTokenStream(ACCEPT_ALL_FILTER);
   }
-  
+
   /**
    * Returns a new {@link SinkTokenStream} that receives all tokens consumed by this stream
    * that pass the supplied filter.
@@ -101,7 +101,7 @@
     this.sinks.add(new WeakReference<>(sink));
     return sink;
   }
-  
+
   /**
    * Adds a {@link SinkTokenStream} created by another <code>TeeSinkTokenFilter</code>
    * to this one. The supplied stream will also receive all consumed tokens.
@@ -118,7 +118,7 @@
     }
     this.sinks.add(new WeakReference<>(sink));
   }
-  
+
   /**
    * <code>TeeSinkTokenFilter</code> passes all tokens to the added sinks
    * when itself is consumed. To be sure, that all tokens from the input
@@ -128,7 +128,7 @@
   public void consumeAllTokens() throws IOException {
     while (incrementToken()) {}
   }
-  
+
   @Override
   public boolean incrementToken() throws IOException {
     if (input.incrementToken()) {
@@ -147,10 +147,10 @@
       }
       return true;
     }
-    
+
     return false;
   }
-  
+
   @Override
   public final void end() throws IOException {
     super.end();
@@ -162,7 +162,7 @@
       }
     }
   }
-  
+
   /**
    * A filter that decides which {@link AttributeSource} states to store in the sink.
    */
@@ -169,10 +169,10 @@
   public static abstract class SinkFilter {
     /**
      * Returns true, iff the current state of the passed-in {@link AttributeSource} shall be stored
-     * in the sink. 
+     * in the sink.
      */
     public abstract boolean accept(AttributeSource source);
-    
+
     /**
      * Called by {@link SinkTokenStream#reset()}. This method does nothing by default
      * and can optionally be overridden.
@@ -181,65 +181,23 @@
       // nothing to do; can be overridden
     }
   }
-  
+
   /**
    * TokenStream output from a tee with optional filtering.
    */
-  public static final class SinkTokenStream extends TokenStream {
-    private final List<AttributeSource.State> cachedStates = new LinkedList<>();
-    private AttributeSource.State finalState;
-    private Iterator<AttributeSource.State> it = null;
+  public static final class SinkTokenStream extends PrefillTokenStream {
     private SinkFilter filter;
-    
+
     private SinkTokenStream(AttributeSource source, SinkFilter filter) {
       super(source);
       this.filter = filter;
     }
-    
+
     private boolean accept(AttributeSource source) {
       return filter.accept(source);
     }
-    
-    private void addState(AttributeSource.State state) {
-      if (it != null) {
-        throw new IllegalStateException("The tee must be consumed before sinks are consumed.");
-      }
-      cachedStates.add(state);
-    }
-    
-    private void setFinalState(AttributeSource.State finalState) {
-      this.finalState = finalState;
-    }
-    
-    @Override
-    public final boolean incrementToken() {
-      // lazy init the iterator
-      if (it == null) {
-        it = cachedStates.iterator();
-      }
-    
-      if (!it.hasNext()) {
-        return false;
-      }
-      
-      AttributeSource.State state = it.next();
-      restoreState(state);
-      return true;
-    }
-  
-    @Override
-    public final void end() {
-      if (finalState != null) {
-        restoreState(finalState);
-      }
-    }
-    
-    @Override
-    public final void reset() {
-      it = cachedStates.iterator();
-    }
   }
-    
+
   private static final SinkFilter ACCEPT_ALL_FILTER = new SinkFilter() {
     @Override
     public boolean accept(AttributeSource source) {
@@ -246,5 +204,5 @@
       return true;
     }
   };
-  
+
 }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(revision 1681580)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(working copy)
@@ -76,7 +76,7 @@
   }
 
   @Override
-  protected void extractTerms(Set<Term> terms) {
+  public void extractTerms(Set<Term> terms) {
     throw new IllegalStateException("Rewrite first");
   }
 
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java	(revision 1681580)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java	(working copy)
@@ -31,7 +31,7 @@
 
 /** Base class for span-based queries. */
 public abstract class SpanQuery extends Query {
-  /** Expert: Returns the matches for this query in an index.  
+  /** Expert: Returns the matches for this query in an index.
    *  Used internally to search for spans.
    *  This may return null to indicate that the SpanQuery has no results.
    */
@@ -42,7 +42,7 @@
    * @lucene.internal
    * @see Weight#extractTerms
    */
-  protected abstract void extractTerms(Set<Term> terms);
+  public abstract void extractTerms(Set<Term> terms);
 
   /**
    * Returns the name of the field matched by this query.
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/BitSelect.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/BitSelect.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/BitSelect.java	(working copy)
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+/**  Select a 1-bit from a long. See also LUCENE-6040 and LUCENE-6484.
+ */
+public final class BitSelect {
+
+  private BitSelect() {} // no instance
+
+  /** Select a 1-bit from a long.
+   * @return The index of the r-th 1 bit in x. This bit must exist.
+   */
+  public static int select(long x, int r) {
+    long s = x - ((x & 0xAAAAAAAAAAAAAAAAL) >>> 1); // pairwise bitsums
+    s = (s & 0x3333333333333333L) + ((s >>> 2) & 0x3333333333333333L); // nibblewise bitsums
+    s = ((s + (s >>> 4)) & 0x0F0F0F0F0F0F0F0FL) * L8_L; // bytewise bitsums, cumulative
+
+    int b = (Long.numberOfTrailingZeros((s + psOverflow[r-1]) & (L8_L << 7)) >> 3) << 3; // bit position of byte with r-th 1 bit.
+    long l = r - (((s << 8) >>> b) & 0xFFL); // bit rank in byte at b
+
+    // Select bit l from byte (x >>> b):
+    int selectIndex = (int) (((x >>> b) & 0xFFL) | ((l-1) << 8));
+    int res = b + select256[selectIndex];
+    return res;
+  }
+
+  private final static long L8_L = 0x0101010101010101L;
+
+  private static final long[] psOverflow = new long[64];
+  static {
+    for (int s = 1; s <= 64; s++) {
+      psOverflow[s-1] = (128-s) * L8_L;
+    }
+  }
+
+  private static final byte[] select256 = new byte[8 * 256];
+  static {
+    for (int b = 0; b <= 0xFF; b++) {
+      for (int s = 1; s <= 8; s++) {
+        int byteIndex = b | ((s-1) << 8);
+        int bitIndex = selectNaive(b, s);
+        if (bitIndex < 0) {
+          bitIndex = 127; // positive as byte
+        }
+        assert bitIndex >= 0;
+        assert ((byte) bitIndex) >= 0; // non negative as byte, no need to mask the sign
+        select256[byteIndex] = (byte) bitIndex;
+      }
+    }
+  }
+
+  /**
+   * Naive implementation of {@link #select(long,int)}, using {@link Long#numberOfTrailingZeros} repetitively.
+   * Works relatively fast for low ranks.
+   * @return The index of the r-th 1 bit in x, or -1 if no such bit exists.
+   */
+  public static int selectNaive(long x, int r) {
+    assert r >= 1;
+    int s = -1;
+    while ((x != 0L) && (r > 0)) {
+      int ntz = Long.numberOfTrailingZeros(x);
+      x >>>= (ntz + 1);
+      s += (ntz + 1);
+      r -= 1;
+    }
+    int res = (r > 0) ? -1 : s;
+    return res;
+  }
+}
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoBytes.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoBytes.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoBytes.java	(working copy)
@@ -0,0 +1,289 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+import java.io.IOException;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.store.ByteArrayDataInput;
+import org.apache.lucene.store.ByteArrayDataOutput;
+
+/** An EliasFanoSequence implemented on a {@link BytesRef}.
+ * The following format is used in a byte[] bytesRef.bytes from bytesRef.offset:
+ * <ol>
+ * <li>the actual numValues of the sequence as a VLong in bytes,
+ * <li>the actual maxValue of the sequence encoded value as a VLong in bytes,
+ * <li>lb bytes for the low bits,
+ * <li>vib bytes for the value index bits,
+ * <li>hb bytes for the high bits.
+ * </ol>
+ * The low bits, the value index bits and the high bits are encoded in little endian byte order,
+ * i.e. the bytes of a multibyte value are ordered from least significant to most significant.
+ * <br>lb, vib and hb depend on <code>numValues</code> and <code>maxValue</code>, and may be zero.
+ * <br>The number of value index bytes vib also depends on {@link EliasFanoSequence#DEFAULT_VALUE_INDEX_INTERVAL}.
+ * <br>In each of the last bytes of the low bits, the value index bits and the high bits,
+ *     the highest up to 7 unused bits are ignored and should be zero.
+ */
+public class EliasFanoBytes extends EliasFanoSequence {
+  BytesRef bytesRef;
+  int numHeaderBytes;
+  int startLowBitsByte;
+  int startValueIndexByte;
+  int startHighBitsByte;
+  static final int LOG2_BYTE_SIZE = Integer.numberOfTrailingZeros(Byte.SIZE);
+  static final long LONG_BYTE_MASK = 0xFFL;
+  private static final int MAX_HEADER_SIZE = 18;
+
+
+  /** Initialize to encode a sequence into a new BytesRef using {@link EliasFanoSequence#DEFAULT_VALUE_INDEX_INTERVAL}. */
+  public EliasFanoBytes(long maxNumValues, long upperBound) {
+    super(maxNumValues, upperBound);
+    BytesRef bytesRef = initialBytesRef();
+    this.numHeaderBytes = encodeHeader(bytesRef);
+    reInit(bytesRef);
+  }
+
+  /** Create a new EliasFanoBytes using the given BytesRef and {@link EliasFanoSequence#DEFAULT_VALUE_INDEX_INTERVAL} */
+  public static EliasFanoBytes createFromBytesRef(BytesRef bytesRef) {
+    ByteArrayDataInput badi = new ByteArrayDataInput(bytesRef.bytes, bytesRef.offset, bytesRef.length);
+    long maxNumValues = badi.readVLong(); // decode header
+    long upperBound = badi.readVLong();
+    EliasFanoBytes res = new EliasFanoBytes(maxNumValues, upperBound);
+    res.numHeaderBytes = badi.getPosition() - bytesRef.offset;
+    res.reInitSizes(bytesRef);
+    return res;
+  }
+
+  /** Reinitialize to decode a sequence encoded in a given BytesRef. */
+  public void reInit(BytesRef bytesRef) {
+    ByteArrayDataInput badi = new ByteArrayDataInput(bytesRef.bytes, bytesRef.offset, bytesRef.length);
+    maxNumValues = badi.readVLong(); // decode header
+    upperBound = badi.readVLong();
+    numHeaderBytes = badi.getPosition() - bytesRef.offset;
+    valueIndexInterval = DEFAULT_VALUE_INDEX_INTERVAL;
+    reInitSizes(bytesRef);
+  }
+
+  /** Create a new EliasFanoBytes, using {@link EliasFanoSequence#DEFAULT_VALUE_INDEX_INTERVAL} instead of the given valueIndexInterval */
+  @Override
+  EliasFanoBytes newSequence(long maxNumValues, long upperBound, long valueIndexInterval) {
+    return new EliasFanoBytes(maxNumValues, upperBound);
+  }
+
+  private BytesRef initialBytesRef() {
+    BytesRef tempHeader = new BytesRef(MAX_HEADER_SIZE);
+    int tempHeaderOffset = tempHeader.offset;
+    tempHeader.length = tempHeader.bytes.length;
+    numHeaderBytes = encodeHeader(tempHeader);
+
+    BytesRef bytesRef = new BytesRef(numHeaderBytes + numLowBytes() + numValueIndexBytes() + numHighBytes() );
+    System.arraycopy(tempHeader.bytes, tempHeaderOffset, bytesRef.bytes, 0, numHeaderBytes);
+    bytesRef.offset = 0;
+    bytesRef.length = bytesRef.bytes.length;
+    return bytesRef;
+  }
+
+  private int encodeHeader(BytesRef bytesRef) {
+    ByteArrayDataOutput bado = new ByteArrayDataOutput(bytesRef.bytes, bytesRef.offset, bytesRef.length);
+    try {
+      bado.writeVLong(maxNumValues);
+      bado.writeVLong((upperBound < 0) ? 0 : upperBound);
+    } catch (IOException ioe) { // unlikely from byte[]
+      throw new Error(ioe);
+    }
+    int headerBytes = bado.getPosition() - bytesRef.offset;
+    return headerBytes;
+  }
+
+  private void reInitSizes(BytesRef bytesRef) {
+    // bytesRef.offset is directly before the header with maxNumValues and upperBound, numHeaderBytes has been initialized.
+    checkBounds(maxNumValues, upperBound, valueIndexInterval);
+    this.numLowBits = numLowBits(maxNumValues, upperBound);
+    this.lowerBitsMask = lowerBitsMask(numLowBits);
+    this.numValueIndexEntryBits = numValueIndexEntryBits(maxNumValues, upperBound);
+    this.valueIndexBitsMask = (1L << numValueIndexEntryBits) - 1;
+    this.bytesRef = bytesRef;
+    this.startLowBitsByte = bytesRef.offset + numHeaderBytes;
+    this.startValueIndexByte = startLowBitsByte + numLowBytes();
+    this.startHighBitsByte = startValueIndexByte + numValueIndexBytes();
+    long numBytesForHighBits = numHighBytes();
+    if ((startHighBitsByte + numBytesForHighBits) > (bytesRef.offset + bytesRef.length)) {
+      throw new IllegalArgumentException("bytesRef should have at least "
+         + (startHighBitsByte + numBytesForHighBits - bytesRef.offset) + " bytes, but it has only "
+         + bytesRef.length);
+    }
+  }
+
+
+  /** Return the BytesRef that is encoded and/or decoded. */
+  public BytesRef getBytesRef() {
+    return bytesRef;
+  }
+
+  private int numLowBytes() {
+    int res = (int) numBytesForBits(maxNumValues * numLowBits);
+    return res;
+  }
+
+  private int numValueIndexBytes() {
+    int res =  (int) numBytesForBits(maxNumValueIndexEntries() * numValueIndexEntryBits(maxNumValues, upperBound));
+    return res;
+  }
+
+  private int numHighBytes() {
+    int res = (int) numBytesForBits(maxNumValues + maxHighValue());
+    return res;
+  }
+
+  private static long numBytesForBits(long numBits) {
+    assert numBits >= 0 : numBits;
+    return (numBits + (Byte.SIZE-1)) >>> LOG2_BYTE_SIZE;
+  }
+
+  private void packValue(long value, int numBits, long packIndex, int startByte) {
+    if (numBits != 0) {
+      byte[] bytes = bytesRef.bytes;
+      long bitPos = numBits * packIndex;
+      int byteIndex = startByte + (int) (bitPos >>> LOG2_BYTE_SIZE); // little endian
+      int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+      bytes[byteIndex] |= (byte) (value << bitPosAtIndex); 
+      int rightShift = (Byte.SIZE - bitPosAtIndex);
+      int remainingBits = numBits - rightShift;
+      while (remainingBits > 0) {
+        bytes[++byteIndex] = (byte) (value >>> rightShift);
+        rightShift += Byte.SIZE;
+        remainingBits -= Byte.SIZE;
+      }
+    }
+  }
+
+  private long unPackValue(int numBits, long packIndex, long bitsMask, int startByte) {
+    if (numBits == 0) {
+      return 0;
+    }
+    byte[] bytes = bytesRef.bytes;
+    long bitPos = packIndex * numBits;
+    int byteIndex = startByte + (int) (bitPos >>> LOG2_BYTE_SIZE); // little endian
+    int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+    long value = (bytes[byteIndex] & LONG_BYTE_MASK) >>> bitPosAtIndex;
+    int leftShift = Byte.SIZE - bitPosAtIndex;
+    int remainingBits = numBits - leftShift;
+    while (remainingBits > 0) {
+      value |= ((bytes[++byteIndex] & LONG_BYTE_MASK) << leftShift);
+      leftShift += Byte.SIZE;
+      remainingBits -= Byte.SIZE;
+    }
+    value &= bitsMask;
+    return value;
+  }
+
+
+  @Override
+  public EliasFanoEncoder<EliasFanoBytes> getEncoder() {
+    return new EliasFanoEncoder<>(this);
+  }
+
+  @Override
+  void setHighBit(long highBitNum) { 
+    int b = startHighBitsByte + (int)(highBitNum >>> LOG2_BYTE_SIZE); // little endian
+    bytesRef.bytes[b] |= (byte) (1 << (highBitNum & (Byte.SIZE-1)));
+  }
+
+  @Override
+  void setLowValue(long efPosition, long value) {
+    packValue(value & lowerBitsMask, numLowBits, efPosition, startLowBitsByte);
+  }
+
+  @Override
+  void setValueIndexEntry(long afterZeroBitPosition, long entryIndex) {
+    packValue(afterZeroBitPosition & valueIndexBitsMask, numValueIndexEntryBits, entryIndex, startValueIndexByte);
+    numValueIndexEntries = entryIndex + 1;
+  }
+
+  @Override
+  public EliasFanoDecoder<EliasFanoBytes> getDecoder() {
+    return new EliasFanoDecoder<>(this, maxNumValues);
+  }
+
+  @Override
+  long getHighLong(int highIndex) { 
+    int b = 8 * highIndex + startHighBitsByte;
+    final int e = bytesRef.offset + bytesRef.length;
+    final byte[] bytes = bytesRef.bytes;
+    if ((b + 7) < e) {
+      return ( (bytes[b] & LONG_BYTE_MASK) // little endian
+            + ((bytes[b+1] & LONG_BYTE_MASK) << 8)
+            + ((bytes[b+2] & LONG_BYTE_MASK) << 16)
+            + ((bytes[b+3] & LONG_BYTE_MASK) << 24))
+            +(((bytes[b+4] & LONG_BYTE_MASK) << 32) // extra bracket: allow parallel evaluation
+            + ((bytes[b+5] & LONG_BYTE_MASK) << 40)
+            + ((bytes[b+6] & LONG_BYTE_MASK) << 48)
+            + ((bytes[b+7] & LONG_BYTE_MASK) << 56));
+    }
+    else { // must have at least 1 byte, does not have all 8 bytes
+      long r = (bytes[b] & LONG_BYTE_MASK);
+      int s = 8;
+      while (++b < e) {
+        r += (bytes[b] & LONG_BYTE_MASK) << s;
+        s += 8;
+      }
+      return r;
+    }
+  }
+
+  @Override
+  long getLowValue(long efPosition) {
+    return unPackValue(numLowBits, efPosition, lowerBitsMask, startLowBitsByte);
+  }
+
+  @Override
+  long getValueIndexEntry(long entryIndex) {
+    long res = unPackValue(numValueIndexEntryBits, entryIndex, valueIndexBitsMask, startValueIndexByte);
+    return res;
+  }
+
+
+  @Override
+  public String toString() {
+    StringBuilder s = new StringBuilder("EliasFanoBytes: ");
+    s.append(super.toString());
+
+    s.append("\nstartLowBitsByte " + startLowBitsByte);
+    s.append(" startValueIndexByte " + startValueIndexByte);
+    s.append(" startHighBitsByte " + startHighBitsByte);
+
+    s.append("\nbytesRef.offset " + bytesRef.offset);
+    s.append(" bytesRef.length " + bytesRef.length);
+    s.append("\nbytesRef " + bytesRef.toString()); // [hex encoded bytes]
+    s.append("\n");
+    return s.toString();
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    return super.equals(other)
+        && bytesRef.equals(((EliasFanoBytes)other).bytesRef);
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode()
+          ^ bytesRef.hashCode();
+  }
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDecoder.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDecoder.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDecoder.java	(working copy)
@@ -0,0 +1,489 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+import org.apache.lucene.util.eliasfano.BitSelect;
+
+
+/** A decoder for an {@link EliasFanoSequence}.
+ * @lucene.internal
+ */
+public class EliasFanoDecoder<EFSeq extends EliasFanoSequence> {
+  private static final int LOG2_LONG_SIZE = Integer.numberOfTrailingZeros(Long.SIZE);
+
+  private final long numEncoded;
+  private final long numValueIndexEntries;
+  private final long numLowBits;
+  final EFSeq efSeq;
+
+  private long efPosition = -1; // the decoding position.
+  private long setHighBitForPos = -1; // the index of the high bit at the decoding position.
+
+  public final static long NO_MORE_VALUES = -1L;
+
+
+
+  /** Construct a decoder for a given {@link EliasFanoSequence}.
+   * The decoding position is set to just before the first encoded value.
+   */
+  public EliasFanoDecoder(EFSeq efSeq, long numEncoded) {
+    this.efSeq = efSeq;
+    this.numEncoded = numEncoded;
+    this.numValueIndexEntries = this.efSeq.numValueIndexEntries;
+    this.numLowBits = this.efSeq.numLowBits;
+  }
+
+  /** Return the Elias-Fano sequence that is decoded. */
+  public EFSeq getEliasFanoSequence() {
+    return efSeq;
+  }
+  
+  @Override
+  public String toString() {
+    return "EliasFanoDecoder(efIndex=" + efPosition + ", setHighBitForPos=" + setHighBitForPos + "\nefSeq=" + efSeq + ")";
+  }
+  
+  @Override
+  public boolean equals(Object other) {
+    if (other instanceof EliasFanoDecoder) {
+      EliasFanoDecoder<?> oefd = (EliasFanoDecoder<?>) other;
+      return this.efSeq.equals(oefd.efSeq)
+          && (this.efPosition == oefd.efPosition)
+          && (this.setHighBitForPos == oefd.setHighBitForPos);
+    } else {
+      return false;
+    }
+  }
+
+  @Override
+  public int hashCode() {
+    return efSeq.hashCode() ^ (int) (efPosition ^ setHighBitForPos);
+  }
+
+
+  /** Return the number of values in the decoded sequence. */
+  public long numEncoded() { 
+    return numEncoded;
+  }
+
+
+  /** The current decoding position in the sequence.
+   * The first value encoded by {@link EliasFanoEncoder#encodeNext} has position 0.
+   * Only valid directly after
+   * {@link #nextValue}, {@link #advanceToValue},
+   * {@link #previousValue}, or {@link #backToValue}
+   * returned another value than {@link #NO_MORE_VALUES},
+   * or {@link #advanceToPosition} returned true.
+   * @return The decoding position of the last decoded value, or as last set by {@link #advanceToPosition}.
+   */
+  public long currentPosition() {
+    if (efPosition < 0) {
+      throw new IllegalStateException("position before sequence");
+    }
+    if (efPosition >= numEncoded) {
+      throw new IllegalStateException("position after sequence");
+    }
+    return efPosition;
+  }
+
+  /** The value at the current decoding position.
+   * Only valid when {@link #currentPosition} would return a valid result.
+   * <br>This is only intended for use after {@link #advanceToPosition} returned true.
+   * @return The value encoded at {@link #currentPosition}.
+   */
+  public long currentValue() {
+    return combineHighLowValues(currentHighValue(), currentLowValue());
+  }
+
+  /**  @return The high value for the current decoding position. */
+  private long currentHighValue() {
+    return setHighBitForPos - efPosition; // sequence of unary gaps
+  }
+
+  /**  @return The low value for the current decoding position. */
+  private long currentLowValue() {
+    assert ((efPosition >= 0) && (efPosition < numEncoded)) : "efPosition " + efPosition;
+    long res = efSeq.getLowValue(efPosition);
+    return res;
+  }
+
+  /**  @return The given highValue shifted left by the number of low bits from by the EliasFanoSequence,
+   *           logically OR-ed with the given lowValue.
+   */
+  private long combineHighLowValues(long highValue, long lowValue) {
+    return (highValue << numLowBits) | lowValue;
+  }
+
+  private long highLongShifted;
+
+
+  /* The implementation of forward decoding and backward decoding is done by the following method pairs.
+   *
+   * toBeforeSequence - toAfterSequence
+   * getCurrentRightShift - getCurrentLeftShift
+   * toAfterCurrentHighBit - toBeforeCurrentHighBit
+   * toNextHighLong - toPreviousHighLong
+   * nextHighValue - previousHighValue
+   * nextValue - previousValue
+   * advanceToValue - backToValue
+   *
+   */
+
+  /* Forward decoding section */
+
+
+  /** Set the decoding position to just before the first encoded value.
+   */
+  public void toBeforeSequence() {
+    efPosition = -1;
+    setHighBitForPos = -1;
+  }
+
+  /** @return the number of bits in a long after (setHighBitForPos modulo Long.SIZE) */
+  private int getCurrentRightShift() {
+    int s = (int) (setHighBitForPos & (Long.SIZE-1));
+    return s;
+  }
+
+  /** Increment efPosition and setHighBitForPos and
+   * set highLongShifted so that it does not contain the high bits before setHighBitForPos.
+   * @return true iff efPosition still smaller than numEncoded.
+   */
+  private boolean toAfterCurrentHighBit() {
+    efPosition += 1;
+    if (efPosition >= numEncoded) {
+      return false;
+    }
+    setHighBitForPos += 1;
+    int highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+    highLongShifted = efSeq.getHighLong(highIndex) >>> getCurrentRightShift();
+    return true;
+  }
+
+  /** The current high long has been determined to not contain the set bit that is needed.
+   *  Increment setHighBitForPos to the next high long and set highLongShifted accordingly.
+   */
+  private void toNextHighLong() {
+    setHighBitForPos += Long.SIZE - (setHighBitForPos & (Long.SIZE-1));
+    //assert getCurrentRightShift() == 0;
+    int highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+    highLongShifted = efSeq.getHighLong(highIndex);
+  }
+
+  /** setHighBitForPos and efPosition have just been incremented, scan to the next high set bit
+   *  by incrementing setHighBitForPos, and by setting highLongShifted accordingly.
+   */
+  private void toNextHighValue() {
+    while (highLongShifted == 0L) {
+      toNextHighLong(); // inlining and unrolling would simplify somewhat
+    }
+    setHighBitForPos += Long.numberOfTrailingZeros(highLongShifted);
+  }
+
+  /** setHighBitForPos and efPosition have just been incremented, scan to the next high set bit
+   *  by incrementing setHighBitForPos, and by setting highLongShifted accordingly.
+   *  @return the next encoded high value.
+   */
+  private long nextHighValue() {
+    toNextHighValue();
+    return currentHighValue();
+  }
+
+  /** If another value is available after the current decoding position, return this value and
+   * and increase the decoding position by 1. Otherwise return {@link #NO_MORE_VALUES}.
+   */
+  public long nextValue() {
+    if (! toAfterCurrentHighBit()) {
+      return NO_MORE_VALUES;
+    }
+    long highValue = nextHighValue();
+    return combineHighLowValues(highValue, currentLowValue());
+  }
+
+  /** Advance the decoding position to a given position.
+   * and return <code>true</code> iff this position is in the sequence.
+   * <br>See also {@link #currentValue}.
+   * <br>The current implementation does not use the value index on the high bit zero bit positions.
+   * <br>Note: there is currently no implementation of <code>backToPosition</code>.
+   */
+  public boolean advanceToPosition(long newPosition) {
+    assert newPosition > efPosition;
+    if (newPosition >= numEncoded) {
+      toAfterSequence();
+      return false;
+    }
+    if (! toAfterCurrentHighBit()) {
+      throw new IllegalStateException();
+    }
+    /* CHECKME: Add a (binary) search in the value index here. */
+    int curSetBits = Long.bitCount(highLongShifted);
+    while ((efPosition + curSetBits) < newPosition) { // highLongShifted has not enough set bits to reach index
+      efPosition += curSetBits;
+      toNextHighLong();
+      curSetBits = Long.bitCount(highLongShifted);
+    }
+    // highLongShifted has enough set bits to reach newPosition
+    while (efPosition < newPosition) {
+      /* CHECKME: Instead of the linear search here, use (forward) broadword selection from
+       * "Broadword Implementation of Rank/Select Queries", Sebastiano Vigna, January 30, 2012.
+       */
+      toNextHighValue();
+      if (! toAfterCurrentHighBit()) {
+        throw new IllegalStateException();
+      }
+    }
+    toNextHighValue();
+    return true;
+  }
+
+
+
+  /** Given a target value, advance the decoding position to the first bigger or equal value
+   * and return that if it is available. Otherwise return {@link #NO_MORE_VALUES}.
+   * <br>The current implementation uses the value index on the high zero bit positions.
+   */
+  public long advanceToValue(long target) {
+    efPosition += 1;
+    if (efPosition >= numEncoded) {
+      return NO_MORE_VALUES;
+    }
+    setHighBitForPos += 1; // the high bit at setHighBitForPos belongs to the unary code for efPosition
+
+    int highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+    long highLong = efSeq.getHighLong(highIndex);
+    highLongShifted = highLong >>> ((int) (setHighBitForPos & (Long.SIZE-1))); // may contain the unary 1 bit for efPosition
+
+    // determine value index entry to advance to
+    long highTarget = target >>> numLowBits;
+
+    long indexEntryIndex = (highTarget / efSeq.valueIndexInterval) - 1;
+    if (indexEntryIndex >= 0) { // not before first value index entry
+      if (indexEntryIndex >= numValueIndexEntries) {
+        indexEntryIndex = numValueIndexEntries - 1; // no further than last value index entry, if any
+      }
+      long indexHighValue = (indexEntryIndex + 1) * efSeq.valueIndexInterval;
+      assert indexHighValue <= highTarget;
+      if (indexHighValue > (setHighBitForPos - efPosition)) { // advance to just after zero bit position of value index entry.
+        setHighBitForPos = efSeq.getValueIndexEntry(indexEntryIndex);
+        efPosition = setHighBitForPos - indexHighValue; // the high bit at setHighBitForPos belongs to the unary code for efPosition
+        highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+        highLong = efSeq.getHighLong(highIndex);
+        highLongShifted = highLong >>> ((int) (setHighBitForPos & (Long.SIZE-1))); // may contain the unary 1 bit for efPosition
+      }
+      assert efPosition < numEncoded; // there is a high value to be found.
+    }
+
+    int curSetBits = Long.bitCount(highLongShifted); // shifted right.
+    int curClearBits = Long.SIZE - curSetBits - ((int) (setHighBitForPos & (Long.SIZE-1))); // subtract right shift, may be more than encoded
+
+    while (((setHighBitForPos - efPosition) + curClearBits) < highTarget) {
+      // highLongShifted has not enough clear bits to reach highTarget
+      efPosition += curSetBits;
+      if (efPosition >= numEncoded) {
+        return NO_MORE_VALUES;
+      }
+      setHighBitForPos += Long.SIZE - (setHighBitForPos & (Long.SIZE-1));
+      assert (highIndex + 1) == (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+      highIndex += 1;
+      highLong = efSeq.getHighLong(highIndex);
+      highLongShifted = highLong;
+      curSetBits = Long.bitCount(highLongShifted);
+      curClearBits = Long.SIZE - curSetBits;
+    }
+    // highLongShifted has enough clear bits to reach highTarget, and may not have enough set bits.
+    while (highLongShifted == 0L) {
+      setHighBitForPos += Long.SIZE - (setHighBitForPos & (Long.SIZE-1));
+      assert (highIndex + 1) == (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+      highIndex += 1;
+      highLong = efSeq.getHighLong(highIndex);
+      highLongShifted = highLong;
+    }
+
+    // highLongShifted has enough clear bits to reach highTarget, has at least 1 set bit, and may not have enough set bits.
+    int rank = (int) (highTarget - (setHighBitForPos - efPosition)); // the rank of the zero bit for highValue.
+    assert (rank <= Long.SIZE) : ("rank " + rank);
+    if (rank >= 1) {
+      long invCurHighLong = ~highLongShifted;
+      int clearBitForValue = (rank <= 8)
+                              ? BitSelect.selectNaive(invCurHighLong, rank)
+                              : BitSelect.select(invCurHighLong, rank);
+      assert clearBitForValue <= (Long.SIZE-1);
+      setHighBitForPos += clearBitForValue + 1; // the high bit just before setHighBitForPos is zero
+      int oneBitsBeforeClearBit = clearBitForValue - rank + 1;
+      efPosition += oneBitsBeforeClearBit; // the high bit at setHighBitForPos and belongs to the unary code for efPosition
+      if (efPosition >= numEncoded) {
+        return NO_MORE_VALUES;
+      }
+
+      if ((setHighBitForPos & (Long.SIZE - 1)) == 0L) { // exhausted highLongShifted
+        assert (highIndex + 1) == (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+        highIndex += 1;
+        highLong = efSeq.getHighLong(highIndex);
+        highLongShifted = highLong;
+      }
+      else {
+        assert highIndex == (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+        highLongShifted = highLong >>> ((int) (setHighBitForPos & (Long.SIZE-1)));
+      }
+      // highLongShifted has enough clear bits to reach highTarget, and may not have enough set bits.
+ 
+      while (highLongShifted == 0L) {
+        setHighBitForPos += Long.SIZE - (setHighBitForPos & (Long.SIZE-1));
+        assert (highIndex + 1) == (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+        highIndex += 1;
+        highLong = efSeq.getHighLong(highIndex);
+        highLongShifted = highLong;
+      }
+    }
+    setHighBitForPos += Long.numberOfTrailingZeros(highLongShifted);
+    assert (setHighBitForPos - efPosition) >= highTarget; // highTarget reached
+
+    // Linear search also with low values
+    long currentValue = combineHighLowValues((setHighBitForPos - efPosition), currentLowValue());
+    while (currentValue < target) {
+      currentValue = nextValue();
+      if (currentValue == NO_MORE_VALUES) {
+        return NO_MORE_VALUES;
+      }
+    }
+    return currentValue;
+  }
+
+
+  /* Backward decoding section */
+
+  /** Set the decoding position to just after the last encoded value.
+   */
+  public void toAfterSequence() {
+    efPosition = numEncoded; // just after last position
+    setHighBitForPos = efSeq.maxHighValue() + numEncoded;
+  }
+
+  /** @return the number of bits in a long before (setHighBitForPos modulo Long.SIZE) */
+  private int getCurrentLeftShift() {
+    int s = Long.SIZE - 1 - (int) (setHighBitForPos & (Long.SIZE-1));
+    return s;
+  }
+
+  /** Decrement efPosition and setHighBitForPos and
+   * shift highLongShifted so that it does not contain the high bits after setHighBitForPos.
+   * @return true iff efPosition still >= 0
+   */
+  private boolean toBeforeCurrentHighBit() {
+    efPosition -= 1;
+    if (efPosition < 0) {
+      return false;
+    }
+    setHighBitForPos -= 1;
+    int highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+    highLongShifted = efSeq.getHighLong(highIndex) << getCurrentLeftShift();
+    return true;
+  }
+
+  /** The current high long has been determined to not contain the set bit that is needed.
+   *  Decrement setHighBitForPos to the previous high long and set highLongShifted accordingly.
+   */
+  private void toPreviousHighLong() {
+    setHighBitForPos -= (setHighBitForPos & (Long.SIZE-1)) + 1;
+    //assert getCurrentLeftShift() == 0;
+    int highIndex = (int)(setHighBitForPos >>> LOG2_LONG_SIZE);
+    highLongShifted = efSeq.getHighLong(highIndex);
+  }
+
+  /** setHighBitForPos and efPosition have just been decremented, scan to the previous high set bit
+   *  by decrementing setHighBitForPos and by setting highLongShifted accordingly.
+   *  @return the previous encoded high value.
+   */
+  private long previousHighValue() {
+    while (highLongShifted == 0L) {
+      toPreviousHighLong(); // inlining and unrolling would simplify somewhat
+    }
+    setHighBitForPos -= Long.numberOfLeadingZeros(highLongShifted);
+    return currentHighValue();
+  }
+
+  /** If another value is available right before the current decoding position, return this value
+   * and decrease the decoding position by 1. Otherwise return {@link #NO_MORE_VALUES}.
+   */
+  public long previousValue() {
+    if (! toBeforeCurrentHighBit()) {
+      return NO_MORE_VALUES;
+    }
+    long highValue = previousHighValue();
+    return combineHighLowValues(highValue, currentLowValue());
+  }
+
+
+  /** setHighBitForPos and efPosition have just been decremented, scan backward to the high set bit
+   *  of at most a given high value
+   *  by decrementing setHighBitForPos and by setting highLongShifted accordingly.
+   * <br>The current implementation does not use the value index on the high zero bit positions.
+   *  @return the largest encoded high value that is at most the given one.
+   */
+  private long backToHighValue(long highTarget) {
+    /* CHECKME: Add using the value index as in advanceToHighValue */
+    int curSetBits = Long.bitCount(highLongShifted); // is shifted by getCurrentLeftShift()
+    int curClearBits = Long.SIZE - curSetBits - getCurrentLeftShift();
+    while ((currentHighValue() - curClearBits) > highTarget) {
+      // highLongShifted has not enough clear bits to reach highTarget
+      efPosition -= curSetBits;
+      if (efPosition < 0) {
+        return NO_MORE_VALUES;
+      }
+      toPreviousHighLong();
+      //assert getCurrentLeftShift() == 0;
+      curSetBits = Long.bitCount(highLongShifted);
+      curClearBits = Long.SIZE - curSetBits;
+    }
+    // highLongShifted has enough clear bits to reach highTarget, but may not have enough set bits.
+    long highValue = previousHighValue();
+    while (highValue > highTarget) {
+      /* CHECKME: See at advanceToHighValue on using broadword bit selection. */
+      if (! toBeforeCurrentHighBit()) {
+        return NO_MORE_VALUES;
+      }
+      highValue = previousHighValue();
+    }
+    return highValue;
+  }
+
+  /** Given a target value, move the decoding position to the first smaller or equal value
+   * and return that value if it is available. Otherwise return {@link #NO_MORE_VALUES}.
+   * <br>The current implementation does not use the value index on the high zero bit positions.
+   */
+  public long backToValue(long target) {
+    if (! toBeforeCurrentHighBit()) {
+      return NO_MORE_VALUES;
+    }
+    long highTarget = target >>> numLowBits;
+    long highValue = backToHighValue(highTarget);
+    if (highValue == NO_MORE_VALUES) {
+      return NO_MORE_VALUES;
+    }
+    // Linear search with low values:
+    long currentValue = combineHighLowValues(highValue, currentLowValue());
+    while (currentValue > target) {
+      currentValue = previousValue();
+      if (currentValue == NO_MORE_VALUES) {
+        return NO_MORE_VALUES;
+      }
+    }
+    return currentValue;
+  }
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDocIdSet.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDocIdSet.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoDocIdSet.java	(working copy)
@@ -0,0 +1,235 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.ArrayList;
+
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.BitSetIterator;
+
+import org.apache.lucene.util.RamUsageEstimator;
+
+
+/** A DocIdSet that chooses Elias-Fano encoding or bit set encoding.
+ * <br> CHECKME: name ok?
+ * @lucene.internal
+ */
+public class EliasFanoDocIdSet extends DocIdSet {
+
+  private static final long BASE_RAM_BYTES_USED = RamUsageEstimator.shallowSizeOfInstance(EliasFanoDocIdSet.class);
+
+  private final int maxNumDocIds; // given
+  private final int upperBound; // given
+  private int numDocIds; // actual
+  private FixedBitSet fbs = null;
+  private EliasFanoLongs efLongs = null;
+  private EliasFanoEncoderUpperBound efEncoderUb = null;
+
+  /**
+   * Construct an EliasFanoDocIdSet.
+   * @param maxNumDocIds When non negative, at least the number of document ids that will be encoded.
+   *                  When the number of doc ids not known in advance, use a negative value.
+   *                  For efficient encoding this should be chosen non negative,
+   *                  and as little as possible bigger than the number of docs.
+   * @param upperBound  At least the highest document id that will be encoded.
+   *                    Should be chosen as low as possible for efficient encoding.
+   */
+  public EliasFanoDocIdSet(int maxNumDocIds, int upperBound) {
+    this.upperBound = (upperBound < 0) ? 0 : upperBound;
+    this.maxNumDocIds = maxNumDocIds;
+    if (maxNumDocIds >= 0) {
+      if (maxNumDocIds <= EliasFanoSequence.preferredMaxNumValues(upperBound)) {
+        this.efLongs = new EliasFanoLongs(maxNumDocIds, upperBound);
+      }
+      else {
+        this.fbs = newFixedBitSet();
+      }
+    }
+    else { // maxNumDocIds not known in advance, start with upper bound encoder, may be change to fixed bit set later.
+      this.efEncoderUb = new EliasFanoEncoderUpperBound(upperBound);
+    }
+    this.numDocIds = 0;
+  }
+
+  private FixedBitSet newFixedBitSet() {
+    return new FixedBitSet(upperBound + 1);
+  }
+
+  /** Encode the document ids from a DocIdSetIterator. Call this method only once.
+   *  @param disi This DocIdSetIterator should provide document ids that are consistent
+   *              with <code>numValues</code> (when non negative) and <code>upperBound</code> as provided to the constructor.
+   */
+  public void encodeFromDisi(DocIdSetIterator disi) throws IOException {
+    if (fbs != null) { // encode directly into fixed bit set
+      encodeFromDisi(fbs, disi);
+    }
+    else if (efLongs != null) { // given num doc ids at most EliasFanoSequence.preferredMaxNumValues(upperBound)
+      EliasFanoEncoder<EliasFanoLongs> encodeNextNdUb = new EliasFanoEncoder<>(efLongs);
+      encodeFromDisi(encodeNextNdUb, disi);
+      efLongs.freeze(numDocIds);
+    }
+    else if (efEncoderUb != null) { // start with upper bound encoder, may be change to fixed bit set later.
+      long maxNumDocIdsEF = EliasFanoSequence.preferredMaxNumValues(upperBound);
+      int docId = disi.nextDoc();
+      while ((docId != DocIdSetIterator.NO_MORE_DOCS) && (numDocIds < maxNumDocIdsEF)) {
+        efEncoderUb.encodeNext(docId);
+        numDocIds++;
+        docId = disi.nextDoc();
+      }
+      if (docId != DocIdSetIterator.NO_MORE_DOCS) { // more than preferred number of values, change to FixedBitSet
+        assert numDocIds == maxNumDocIdsEF;
+        fbs = newFixedBitSet();
+        encodeFromEfDecoder(fbs, efEncoderUb.getEliasFanoSequence().getDecoder(numDocIds));
+        efEncoderUb = null;
+        fbs.set(docId);
+        numDocIds++;
+        encodeFromDisi(fbs, disi);
+      } else {
+        efEncoderUb.freeze();
+        efLongs = efEncoderUb.getEliasFanoSequence();
+      }
+    }
+    else throw new IllegalStateException("no encoder for encoding");
+  }
+
+  private void encodeFromDisi(EliasFanoEncoder<?> efEncoder, DocIdSetIterator disi) throws IOException {
+    int docId = disi.nextDoc();
+    while (docId != DocIdSetIterator.NO_MORE_DOCS) {
+      efEncoder.encodeNext(docId);
+      numDocIds++;
+      docId = disi.nextDoc();
+    }
+  }
+
+  private void encodeFromDisi(FixedBitSet fbs, DocIdSetIterator disi) throws IOException {
+    int docId = disi.nextDoc();
+    while (docId != DocIdSetIterator.NO_MORE_DOCS) {
+      if (docId > upperBound) {
+        throw new IllegalArgumentException("docId " + docId + " higher than upperBound " + upperBound);
+      }
+      fbs.set(docId);
+      numDocIds++;
+      docId = disi.nextDoc();
+    }
+  }
+
+  private void encodeFromEfDecoder(FixedBitSet fbs, EliasFanoDecoder<?> efDecoder) {
+    long docId = efDecoder.nextValue();
+    while (docId != EliasFanoDecoder.NO_MORE_VALUES) {
+      assert docId <= upperBound;
+      fbs.set((int) docId); // do not increase numDocIds, already counted
+      docId = efDecoder.nextValue();
+    }
+  }
+
+  /**
+   * Provides a {@link DocIdSetIterator} to access encoded document ids.
+   */
+  @Override
+  public DocIdSetIterator iterator() {
+    if (fbs != null) {
+      return new BitSetIterator(fbs, numDocIds);
+    }
+
+    final EliasFanoDecoder<EliasFanoLongs> efDecoder;
+    if (efLongs == null) {
+      throw new IllegalStateException("no encoded data available");
+    }
+
+    efDecoder = efLongs.getDecoder(numDocIds);
+
+    return new DocIdSetIterator() {
+      private int curDocId = -1;
+
+      @Override
+      public int docID() {
+        return curDocId;
+      }
+
+      private int setCurDocID(long value) {
+        curDocId = (value == EliasFanoDecoder.NO_MORE_VALUES)
+                  ?  NO_MORE_DOCS
+                  : (int) value;
+        return curDocId;
+      }
+
+      @Override
+      public int nextDoc() {
+        return setCurDocID(efDecoder.nextValue());
+      }
+
+      @Override
+      public int advance(int target) {
+        return setCurDocID(efDecoder.advanceToValue(target));
+      }
+
+      @Override
+      public long cost() {
+        return efDecoder.numEncoded();
+      }
+    };
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    return (other instanceof EliasFanoDocIdSet)
+        && ( ((efLongs != null) && efLongs.equals(((EliasFanoDocIdSet) other).efLongs))
+            || ((fbs != null) && fbs.equals(((EliasFanoDocIdSet) other).fbs))
+           );
+  }
+
+  @Override
+  public int hashCode() {
+    return getClass().hashCode()
+            ^ ( (efLongs != null) ? efLongs.hashCode()
+             : (fbs != null) ? fbs.hashCode()
+             : 0 );
+  }
+
+  public String toString() {
+    StringBuilder sb = new StringBuilder("EliasFanoDocIdSet(");
+    sb.append(", efLongs = " + ((efLongs != null) ? efLongs.getClass() : efLongs) );
+    sb.append(", fbs = " + ((fbs != null) ? fbs.getClass() : fbs) );
+    sb.append(", upperBound = " + upperBound);
+    sb.append(")");
+    return sb.toString();
+  }
+
+  @Override
+  public long ramBytesUsed() {
+    return BASE_RAM_BYTES_USED;
+  }
+
+  @Override
+  public Collection<Accountable> getChildResources() {
+    ArrayList<Accountable> resources = new ArrayList<>();
+    if (fbs != null) {
+      resources.add(fbs);
+    } else if (efLongs != null) {
+      resources.add(efLongs);
+    }
+    return resources;
+  }
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoder.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoder.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoder.java	(working copy)
@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+import java.util.Arrays;
+
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.FixedBitSet; // for javadocs
+import org.apache.lucene.util.RamUsageEstimator;
+import org.apache.lucene.util.ToStringUtils;
+
+
+/** Encode an {@link EliasFanoSequence}.
+ *
+ * @lucene.internal
+ */
+
+public class EliasFanoEncoder<EFSeq extends EliasFanoSequence> { 
+
+  long numEncoded = 0L;
+  long lastEncoded = 0L; // initially x[-1]
+
+  long currentEntryIndex; // also indicates how many entries in the index are valid.
+  final long valueIndexInterval;
+  
+  EFSeq efSeq; // holds the actual encoded values.
+
+  /**
+   * Construct an Elias-Fano encoder for an EliasFanoSequence.
+   * @param efSeq The storage for the sequence that is to be encoded.
+   *        This also provides:
+   *        <ul>
+   *        <li><code>maxNumValues</code>, after construction, call {@link #encodeNext} <code>maxNumValues</code> times to encode
+   *            a non decreasing sequence of non negative numbers.
+   *        <li><code>upperBound</code> at least the highest value that will be encoded.
+   *        <li><code>valueIndexInterval</code> the number of high zero bits for which a single value index entry is built.
+   *            The value index will have at most <code>2 * maxNumValues / valueIndexInterval</code> entries
+   *            and each value index entry will use at most <code>ceil(log2(3 * maxNumValues))</code> bits,
+   *            see also {@link EliasFanoSequence}.
+   *        </ul>
+   * @throws IllegalArgumentException when:
+   *        <ul>
+   *        <li><code>maxNumValues</code> is negative, or
+   *        <li><code>maxNumValues</code> is non negative and <code>upperBound</code> is negative, or
+   *        <li>constructing the <code>EliasFanoSequence</code> throws this exception.
+   *        </ul>
+   */
+  
+  public EliasFanoEncoder(EFSeq efSeq) {
+    this.efSeq = efSeq;
+    this.currentEntryIndex = 0;
+    this.valueIndexInterval = efSeq.valueIndexInterval;
+  }
+
+
+  /** Call at most <code>maxNumValues</code> times to encode a non decreasing sequence of non negative numbers.
+   * @param x The next number to be encoded.
+   * @throws IllegalStateException when called more than <code>maxNumValues</code> times.
+   * @throws IllegalArgumentException when:
+   *         <ul>
+   *         <li><code>x</code> is smaller than an earlier encoded value, or
+   *         <li><code>x</code> is larger than <code>upperBound</code>.
+   *         </ul>
+   */
+  public void encodeNext(long x) {
+    if (numEncoded >= efSeq.maxNumValues) {
+      throw new IllegalStateException("encodeNext called more than " + efSeq.maxNumValues + " times.");
+    }
+    if (lastEncoded > x) {
+      throw new IllegalArgumentException(x + " smaller than previous " + lastEncoded);
+    }
+    if (x > efSeq.upperBound) {
+      throw new IllegalArgumentException(x + " larger than upperBound " + efSeq.upperBound);
+    }
+    long highValue = x >>> efSeq.numLowBits;
+    long nextHighBitNum = numEncoded + highValue; // sequence of unary gaps
+    efSeq.setHighBit(nextHighBitNum);
+    efSeq.setLowValue(numEncoded, x);
+    lastEncoded = x;
+
+    // Add value index entries:
+    long indexValue = (currentEntryIndex + 1) * valueIndexInterval;
+    while (indexValue <= highValue) { 
+      long afterZeroBitPosition = indexValue + numEncoded;
+      efSeq.setValueIndexEntry(afterZeroBitPosition, currentEntryIndex);
+      currentEntryIndex += 1;
+      indexValue += valueIndexInterval;
+    }
+    numEncoded++;
+  }
+
+  /**
+   * Returns the number of encoded values.
+   */
+  public long numEncoded() {
+    return numEncoded;
+  }
+  
+  /**
+   * Returns the last encoded value.
+   */
+  public long lastEncoded() {
+    return lastEncoded;
+  }
+
+  /**
+   * Returns the encoded sequence.
+   */
+  public EFSeq getEFSequence() {
+    return efSeq;
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder s = new StringBuilder("EliasFanoEncoder");
+    s.append(" numEncoded " + numEncoded);
+    s.append(" lastEncoded " + lastEncoded);
+    s.append(" valueIndexInterval " + valueIndexInterval);
+    s.append(" currentEntryIndex " + currentEntryIndex);
+    s.append("\nefSeq "); s.append(efSeq.toString());
+    return s.toString();
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    if (! (other instanceof EliasFanoEncoder<?>)) {
+      return false;
+    }
+    EliasFanoEncoder<?> oefs = (EliasFanoEncoder<?>) other;
+    // no equality needed for upperBound
+    return (this.numEncoded == oefs.numEncoded)
+        && (this.valueIndexInterval == oefs.valueIndexInterval)
+        && this.efSeq.equals(oefs.efSeq);
+  }
+
+  @Override
+  public int hashCode() {
+    int h = ((int) (7*(numEncoded + 5*valueIndexInterval))) ^ efSeq.hashCode();
+    return h;
+  }
+
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoderUpperBound.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoderUpperBound.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoEncoderUpperBound.java	(working copy)
@@ -0,0 +1,129 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+/** An EliasFanoEncoder that only needs a given upperbound for the values to be encoded.
+ *  <br>The current implementation delegates to one ore more {@link EliasFanoEncoder}s,
+ *  each encoding an {@link EliasFanoLongs},
+ *  by choosing maximum numbers of encoded values appropriately.
+ *  When compared to {@link EliasFanoLongs} this uses at most twice the memory
+ *  and has a slightly reduced performance for {@link EliasFanoDecoder#nextValue}
+ *  and {@link EliasFanoDecoder#advanceToValue}.
+ * @lucene.internal
+ */
+public class EliasFanoEncoderUpperBound {
+
+  static final long MAX_UPPER_INITIAL_SIZE = 1L << 8; // 256, power of 2, see also oversize comment at end of constructor.
+  EliasFanoLongs efSeq;
+  EliasFanoEncoder<EliasFanoLongs> efEncoder;
+  long currentNumValues;
+  final long upperBound;
+
+  /**
+   * Construct an Elias-Fano encoder that only needs an upperbound.
+   * After construction, call {@link #encodeNext} to encode
+   * a non decreasing sequence of non negative numbers.
+   * @param upperBound  At least the highest value that will be encoded.
+   */
+  public EliasFanoEncoderUpperBound(long upperBound) {
+    if (upperBound <= 0) {
+      upperBound = 0;
+    }
+    this.upperBound = upperBound;
+    // Choose initial currentNumValues so that when repeatedly multiplied by 2
+    // it will be just bigger than the max preferred size for Elias-Fano.
+    // This minimizes the reEncoding memory allocation before a bit set is preferable.
+    if (this.upperBound <= MAX_UPPER_INITIAL_SIZE) { // Small upperBound, may prefer a bit set, but anyway
+      this.currentNumValues = this.upperBound;
+    }
+    else { // this.upperBound > MAX_UPPER_INITIAL_SIZE
+      long workNumValues = EliasFanoSequence.preferredMaxNumValues(this.upperBound);
+      if (workNumValues <= 1) { // not likely
+        workNumValues = 1;
+      }
+      int rightShift = Long.numberOfLeadingZeros(MAX_UPPER_INITIAL_SIZE) - Long.numberOfLeadingZeros(workNumValues) + 1;
+      if (rightShift > 0) {
+        workNumValues >>>= rightShift; // divide by 2 until smaller than MAX_UPPER_INITIAL_SIZE (power of 2)
+      }
+      assert workNumValues < MAX_UPPER_INITIAL_SIZE;
+      assert workNumValues >= 1;
+      this.currentNumValues = workNumValues + 1;
+      // Add 1 so repeated multiplication by 2 will oversize this to just bigger than the preferred maximum,
+      // but normally by no more than a factor 2/MAX_UPPER_INITIAL_SIZE, i.e. at most 1/128 bigger for 256.
+      // The normal case is when the preferred maximum value is at least MAX_UPPER_INITIAL_SIZE.
+      assert this.currentNumValues < this.upperBound; // because this.upperBound > MAX_UPPER_INITIAL_SIZE
+    }
+    efSeq = new EliasFanoLongs(this.currentNumValues, this.upperBound);
+    efEncoder = efSeq.getEncoder();
+  }
+
+  private void reEncode() {
+    EliasFanoLongs nextEfSeq = new EliasFanoLongs(currentNumValues, upperBound);
+    EliasFanoEncoder<EliasFanoLongs> nextEfEncoder = nextEfSeq.getEncoder();
+    efSeq.reEncode(nextEfEncoder);
+    efSeq = nextEfSeq;
+    efEncoder = nextEfEncoder;
+  }
+
+  /** Call to encode a non decreasing sequence of non negative numbers.
+   * @param x The next number to be encoded, this should not exceed <code>upperBound</code>.
+   */
+  public void encodeNext(long x) {
+    if (efEncoder.numEncoded() == currentNumValues) {
+      currentNumValues *= 2;
+      reEncode();
+    }
+    efEncoder.encodeNext(x);
+  }
+
+  /**
+   * Returns the number of encoded values.
+   */
+  public long numEncoded() {
+    return efEncoder.numEncoded();
+  }
+
+  /** Reallocate as small as possible to fit the last encoded value.
+   * Do not call {@link #encodeNext} afterwards.
+   */
+  public void freeze() {
+    efSeq.freeze(efEncoder.numEncoded());
+  }
+
+  /**
+   * Returns an {@link EliasFanoLongs} with the encoded values.
+   * Do not call {@link #encodeNext} afterwards.
+   */
+  public EliasFanoLongs getEliasFanoSequence() {
+    return efEncoder.getEFSequence();
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    if (! (other instanceof EliasFanoEncoderUpperBound)) {
+      return false;
+    }
+    return efEncoder.equals(((EliasFanoEncoderUpperBound)other).efEncoder);
+  }
+
+  @Override
+  public int hashCode() {
+    return getClass().hashCode() ^ efEncoder.hashCode();
+  }
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoLongs.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoLongs.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoLongs.java	(working copy)
@@ -0,0 +1,301 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+
+import org.apache.lucene.util.ToStringUtils;
+
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/** An EliasFanoSequence implemented on long arrays */
+public class EliasFanoLongs extends EliasFanoSequence implements Accountable {
+
+  private static final long BASE_RAM_BYTES_USED = RamUsageEstimator.shallowSizeOfInstance(EliasFanoDocIdSet.class);
+
+  long[] highLongs;
+
+  long[] lowLongs;
+  static final int LOG2_LONG_SIZE = Integer.numberOfTrailingZeros(Long.SIZE);
+
+  /** highZeroBitPositionIndex[i] (filled using packValue) will contain the bit position
+   *  just after the zero bit ((i+1) * valueIndexInterval) in the high bits.
+   */
+  long[] highZeroBitPositionIndex;
+  
+  boolean frozen;
+  long numEncoded; // only set at freezing.
+
+  /**
+   * Construct an <code>EliasFanoLongs</code> for given bounds and value index interval.
+   * @throws IllegalArgumentException when:
+   * <ul>
+   * <li>the high bits do not fit in a <code>long[]</code>:
+   *     {@code >(2 * maxNumValues / 64) > Integer.MAX_VALUE}, or
+   * <li>the low bits do not fit in a <code>long[]</code>:
+   *     {@code (numLowBits * maxNumValues / 64) > Integer.MAX_VALUE}, or
+   * <li><code>valueIndexInterval &lt; 2</code>, or
+   * <li>the index bits do not fit in a <code>long[]</code>:
+   *     {@code (maxNumValues / valueIndexInterval * ceil(2log(3 * maxNumValues)) / 64) > Integer.MAX_VALUE}.
+   * </ul>
+   */
+  public EliasFanoLongs(long maxNumValues, long upperBound, long valueIndexInterval) {
+    super(maxNumValues, upperBound, valueIndexInterval);
+
+    long numLongsForHighBits = numLongsForBits( maxNumHighBits());
+    if (numLongsForHighBits > Integer.MAX_VALUE) {
+      throw new IllegalArgumentException("numLongsForHighBits too large to index a long array: " + numLongsForHighBits);
+    }
+    this.highLongs = new long[(int) numLongsForHighBits];
+
+    if (numLowBits >= Long.SIZE) { // getLowValue inspects at most two longs:
+      throw new IllegalArgumentException("numLowBits larger than 63: " + numLowBits);
+    }
+
+    long numLongsForLowBits = numLongsForBits(maxNumValues * numLowBits);
+    if (numLongsForLowBits > Integer.MAX_VALUE) {
+      throw new IllegalArgumentException("numLongsForLowBits too large to index a long array: " + numLongsForLowBits);
+    }
+    this.lowLongs = new long[(int) numLongsForLowBits];
+
+    long numValueIndexBits = maxNumValueIndexEntries() * numValueIndexEntryBits;
+    long numLongsForValueIndexBits = numLongsForBits(numValueIndexBits);
+    if (numLongsForValueIndexBits > Integer.MAX_VALUE) {
+      throw new IllegalArgumentException("numLongsForValueIndexBits too large to index a long array: " + numLongsForValueIndexBits);
+    }
+    this.highZeroBitPositionIndex = new long[(int) numLongsForValueIndexBits];
+    this.frozen = false;
+    this.numEncoded = 0; 
+  }
+
+  /** Call {@link #EliasFanoLongs(long, long, long)} using {@link #DEFAULT_VALUE_INDEX_INTERVAL}. */
+  public EliasFanoLongs(long maxNumValues, long upperBound) {
+    this(maxNumValues, upperBound, DEFAULT_VALUE_INDEX_INTERVAL);
+  }
+
+  @Override
+  EliasFanoLongs newSequence(long maxNumValues, long upperBound, long valueIndexInterval) {
+    return new EliasFanoLongs(maxNumValues, upperBound, valueIndexInterval);
+  }
+
+
+  /** Expert. The low bits. */
+  public long[] getLowBits() {
+    return lowLongs;
+  }
+
+  /** Expert. The high bits. */
+  public long[] getHighBits() {
+    return highLongs;
+  }
+
+  /** Expert. The value index bits. */
+  public long[] getValueIndexBits() {
+    return highZeroBitPositionIndex;
+  }
+
+  private static long numLongsForBits(long numBits) { // Note: int version in FixedBitSet.bits2words()
+    assert numBits >= 0 : numBits;
+    return (numBits + (Long.SIZE-1)) >>> LOG2_LONG_SIZE;
+  }
+
+  private static void packValue(long value, long[] longArray, int numBits, long packIndex) {
+    if (numBits != 0) {
+      long bitPos = numBits * packIndex;
+      int longIndex = (int) (bitPos >>> LOG2_LONG_SIZE);
+      int bitPosAtIndex = (int) (bitPos & (Long.SIZE-1));
+      longArray[longIndex] |= (value << bitPosAtIndex);
+      if ((bitPosAtIndex + numBits) > Long.SIZE) {
+        longArray[longIndex+1] = (value >>> (Long.SIZE - bitPosAtIndex));
+      }
+    }
+  }
+
+  private static long unPackValue(long[] longArray, int numBits, long packIndex, long bitsMask) {
+    if (numBits == 0) {
+      return 0;
+    }
+    long bitPos = packIndex * numBits;
+    int longIndex = (int) (bitPos >>> LOG2_LONG_SIZE);
+    int bitPosAtIndex = (int) (bitPos & (Long.SIZE-1));
+    long value = longArray[longIndex] >>> bitPosAtIndex;
+    if ((bitPosAtIndex + numBits) > Long.SIZE) {
+      value |= (longArray[longIndex + 1] << (Long.SIZE - bitPosAtIndex));
+    }
+    value &= bitsMask;
+    return value;
+  }
+
+  private static void unPackValues(long[] longArray, int numBits, long packIndex, long bitsMask, int numValues, int offset, long[] values) {
+    /* NOCOMMIT: reimplement using org.apache.lucene.util.packed.BulkOperation.Decoder */
+    while (numValues-- > 0) {
+      values[offset++] = unPackValue(longArray, numBits, packIndex++, bitsMask);
+    }
+  }
+
+
+  @Override
+  public EliasFanoEncoder<EliasFanoLongs> getEncoder() {
+    return new EliasFanoEncoder<>(this);
+  }
+
+  @Override
+  void setHighBit(long highBitNum) {
+    highLongs[(int)(highBitNum >>> LOG2_LONG_SIZE)] |= (1L << (highBitNum & (Long.SIZE-1)));
+  }
+
+  @Override
+  void setLowValue(long efPosition, long value) {
+    packValue(value & lowerBitsMask, lowLongs, numLowBits, efPosition);
+  }
+
+  @Override
+  void setValueIndexEntry(long afterZeroBitPosition, long entryIndex) {
+    assert afterZeroBitPosition > 0;
+    assert afterZeroBitPosition <= valueIndexBitsMask;
+    packValue(afterZeroBitPosition, highZeroBitPositionIndex, numValueIndexEntryBits, entryIndex);
+    numValueIndexEntries = entryIndex + 1;
+  }
+
+
+  /**
+   * Reduce the allocated size to the minimal size needed for the given number of encoded values.
+   * Only use this method once after encoding.
+   * <br>This method does not change the number of low bits per encoded value <code>L</code>.
+   */
+  public void freeze(long numEncoded) {
+    if (frozen) {
+      return;
+    }
+    if (numEncoded < 0) {
+      throw new IllegalArgumentException("numEncoded must not be negative");
+    }
+    if (numEncoded > maxNumValues) {
+      throw new IllegalArgumentException("numEncoded=" + numEncoded + " is larger than maxNumValues=" + maxNumValues);
+    }
+    if (numEncoded == maxNumValues) {
+      frozen = true;
+      return;
+    }
+    this.numEncoded = numEncoded;
+    highLongs = reallocSmaller(highLongs, (int) numLongsForBits(numEncoded + maxHighValue())); // might use last encoded to determine maxHighValue()
+    lowLongs = reallocSmaller(lowLongs, (int) numLongsForBits(numEncoded * numLowBits));
+    // do not realloc highZeroBitPositionIndex, it's size depends on maxHighValue(), might use last encoded value for this.
+    frozen = true;
+  }
+
+  private static long[] reallocSmaller(long[] ar, int newLength) {
+    if (newLength > ar.length) {
+      throw new IllegalArgumentException("newLength " + newLength + " should be at most " + ar.length);
+    }
+    return (newLength < ar.length) ? Arrays.copyOf(ar, newLength) : /* newLength == ar.length */ ar;
+  }
+
+  /**
+   * Returns an {@link EliasFanoDecoder} to access the sequence.
+   * Only use this method after encoding and freezing.
+   * <p>
+   * When the actual last encoded value divided by the actual number of encoded values
+   * differs from the given <code>upperBound</code> divided by the given <code>maxNumValues</code>
+   * by at least a factor of 2, a better compression would have been possible and the decoding speed may be reduced.
+   */
+  @Override
+  public EliasFanoDecoder<EliasFanoLongs> getDecoder() {
+    return getDecoder(maxNumValues);
+  }
+
+  /** Decoder when encoded but not frozen. */
+  public EliasFanoDecoder<EliasFanoLongs> getDecoder(long numEncoded) {
+    return new EliasFanoDecoder<>(this, numEncoded);
+  }
+
+  @Override
+  long getHighLong(int highIndex) {
+    return highLongs[highIndex];
+  }
+
+  @Override
+  long getLowValue(long efPosition) {
+    return unPackValue(lowLongs, numLowBits, efPosition, lowerBitsMask);
+  }
+
+  @Override
+  long getValueIndexEntry(long entryIndex) {
+    return unPackValue(highZeroBitPositionIndex, numValueIndexEntryBits, entryIndex, valueIndexBitsMask);
+  }
+
+
+  private static void dumpLongArray(String name, long[] la, StringBuilder s) {
+    s.append(name);
+    if (la != null) {
+      s.append("[");
+      s.append(la.length);
+      s.append("]");
+      for (int i = 0; i < la.length; i++) {
+        s.append(" ");
+        s.append(ToStringUtils.longHex(la[i]));
+      }
+    } else {
+      s.append("(null)");
+    }
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder s = new StringBuilder("EliasFanoLongs\n");
+    s.append(super.toString()); s.append("\n");
+    dumpLongArray("highLongs", highLongs, s); s.append("\n");
+    dumpLongArray("lowLongs", lowLongs, s); s.append("\n");
+    dumpLongArray("highZeroBitPositionIndex", highZeroBitPositionIndex, s); s.append("\n");
+    return s.toString();
+  }
+
+  @Override
+  public boolean equals(Object other) {
+    return super.equals(other)
+      && (this.numValueIndexEntries == ((EliasFanoLongs)other).numValueIndexEntries) // no need to check index content
+      && Arrays.equals(this.highLongs, ((EliasFanoLongs)other).highLongs)
+      && Arrays.equals(this.lowLongs, ((EliasFanoLongs)other).lowLongs);
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode()
+      ^ Arrays.hashCode(highLongs)
+      ^ Arrays.hashCode(lowLongs)
+      ^ (3 * (int) numValueIndexEntries);
+  }
+
+  @Override
+  public long ramBytesUsed() {
+    return BASE_RAM_BYTES_USED
+        + RamUsageEstimator.sizeOf(lowLongs)
+        + RamUsageEstimator.sizeOf(highLongs)
+        + RamUsageEstimator.sizeOf(highZeroBitPositionIndex);
+  }
+
+  @Override
+  public Collection<Accountable> getChildResources() {
+    return Collections.emptyList();
+  }
+}
+
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoSequence.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoSequence.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/EliasFanoSequence.java	(working copy)
@@ -0,0 +1,263 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.eliasfano;
+
+/** Store the encoding and index(es) for an Elias-Fano encoded sequence of non decreasing and non negative whole numbers.
+ * This encoding was introduced in the 1970's by Peter Elias and Robert Fano.
+ * <p>
+ * The Elias-Fano encoding is a high bits / low bits representation of
+ * a monotonically increasing sequence of {@code numValues > 0} natural numbers <code>x[i]</code>
+ * <p>
+ * {@code 0 <= x[0] <= x[1] <= ... <= x[numValues-2] <= x[numValues-1] <= upperBound}
+ * <p>
+ * where {@code upperBound > 0} is an upper bound on the last value.
+ * <br>
+ * The Elias-Fano encoding uses less than half a bit per encoded number more
+ * than the smallest representation
+ * that can encode any monotone sequence with the same bounds.
+ * <p>
+ * The lower <code>L</code> bits of each <code>x[i]</code> are stored explicitly and contiguously
+ * in the lower-bits array, with <code>L</code> chosen as (<code>log()</code> base 2):
+ * <p>
+ * <code>L = max(0, floor(log(upperBound/numValues)))</code>
+ * <p>
+ * The upper bits are stored in the upper-bits array as a sequence of unary-coded gaps (<code>x[-1] = 0</code>):
+ * <p>
+ * <code>(x[i]/2**L) - (x[i-1]/2**L)</code>
+ * <p>
+ * The unary code encodes a natural number <code>n</code> by <code>n</code> 0 bits followed by a 1 bit:
+ * <code>0...01</code>. <br>
+ * In the upper bits the total the number of 1 bits is <code>numValues</code>
+ * and the total number of 0 bits is:<p>
+ * {@code floor(x[numValues-1]/2**L) <= upperBound/(2**max(0, floor(log(upperBound/numValues)))) <= 2*numValues}
+ * <p>
+ * The Elias-Fano encoding uses at most
+ * <p>
+ * <code>2 + ceil(log(upperBound/numValues))</code>
+ * <p>
+ * bits per encoded number. With <code>upperBound</code> in these bounds (<code>p</code> is an integer):
+ * <p>
+ * {@code 2**p < x[numValues-1] <= upperBound <= 2**(p+1)}
+ * <p>
+ * the number of bits per encoded number is minimized.
+ * <p>
+ * In this implementation the values in the sequence can be given as <code>long</code>,
+ * <code>numValues = 0</code> and <code>upperBound = 0</code> are allowed,
+ * and each of the upper and lower bit arrays should fit in a <code>long[]</code>.
+ * <br>
+ * An index of positions of zero's in the upper bits is also built.
+ * <p>
+ * This implementation is based on this article:
+ * <br>
+ * Sebastiano Vigna, "Quasi Succinct Indices", June 19, 2012, sections 3, 4 and 9.
+ * Retrieved from http://arxiv.org/pdf/1206.4300 .
+ *
+ * <p>The articles originally describing the Elias-Fano representation are:
+ * <br>Peter Elias, "Efficient storage and retrieval by content and address of static files",
+ * J. Assoc. Comput. Mach., 21(2):246260, 1974.
+ * <br>Robert M. Fano, "On the number of bits required to implement an associative memory",
+ *  Memorandum 61, Computer Structures Group, Project MAC, MIT, Cambridge, Mass., 1971.
+ *
+ * @lucene.internal
+ */
+public abstract class EliasFanoSequence {
+  long maxNumValues;
+  long upperBound;
+  long valueIndexInterval;
+  int numLowBits;
+  long lowerBitsMask;
+
+  /** The default value index interval for zero high bits. */
+  public static final long DEFAULT_VALUE_INDEX_INTERVAL = 256;
+
+  long numValueIndexEntries;
+  int numValueIndexEntryBits;
+  long valueIndexBitsMask;
+
+  /**
+   * @throws IllegalArgumentException when:
+   *         <ul>
+   *         <li><code>maxNumValues</code> is negative, or
+   *         <li><code>upperBound</code> is non negative, or
+   *         <li><code>valueIndexInterval</code> is smaller than 2.
+   *         </ul>
+   */
+  public EliasFanoSequence(long maxNumValues, long upperBound, long valueIndexInterval) {
+    this.numLowBits = numLowBits(maxNumValues, upperBound);
+    checkBounds(maxNumValues, upperBound, valueIndexInterval);
+    this.maxNumValues = maxNumValues;
+    this.upperBound = (maxNumValues == 0) ? 0 : (upperBound > 0) ? upperBound : 0;
+    this.valueIndexInterval = valueIndexInterval;
+    this.lowerBitsMask = Long.MAX_VALUE >>> (Long.SIZE - 1 - this.numLowBits);
+    // For the index:
+    this.numValueIndexEntryBits = numValueIndexEntryBits(maxNumValues, upperBound);
+    this.valueIndexBitsMask = (1L << numValueIndexEntryBits) - 1;
+  }
+  
+  public EliasFanoSequence(long maxNumValues, long upperBound) {
+    this(maxNumValues, upperBound, DEFAULT_VALUE_INDEX_INTERVAL);
+  }
+  
+  static void checkBounds(long maxNumValues, long upperBound, long valueIndexInterval) {
+    if (maxNumValues < 0) {
+      throw new IllegalArgumentException("maxNumValues should be non negative: " + maxNumValues);
+    }
+    if ((maxNumValues > 0) && (upperBound < 0)) {
+      throw new IllegalArgumentException("upperBound should be non negative for non empty sequence: " + upperBound);
+    }
+    if (valueIndexInterval < 2) {
+      throw new IllegalArgumentException("valueIndexInterval should be at least 2: " + valueIndexInterval);
+    }
+  }
+
+  static int numLowBits(long maxNumValues, long upperBound) {
+    int nLowBits = 0;
+    if (maxNumValues > 0) { // nLowBits = max(0; floor(2log(upperBound/maxNumValues)))
+      long lowBitsFac = upperBound / maxNumValues;
+      if (lowBitsFac > 0) {
+        nLowBits = 63 - Long.numberOfLeadingZeros(lowBitsFac); // see Long.numberOfLeadingZeros javadocs
+      }
+    }
+    return nLowBits;
+  }
+  
+  static long lowerBitsMask(int numLowBits) {
+    return Long.MAX_VALUE >>> (Long.SIZE - 1 - numLowBits);
+  }
+
+  static int numValueIndexEntryBits(long maxNumValues, long upperBound) {
+    int numLowBits = numLowBits(maxNumValues, upperBound);
+    long maxHighValue = upperBound >>> numLowBits;
+    long maxValueIndexEntry = maxHighValue + maxNumValues - 1; // 0 high bits plus 1 high bits, start at zero
+    // ceil(2log(maxValueIndexEntry+1)) :
+    int res = (maxValueIndexEntry <= 0) ? 0 : (Long.SIZE - Long.numberOfLeadingZeros(maxValueIndexEntry));
+    return res;
+  }
+
+  long maxHighValue() {
+    long maxH = upperBound >>> numLowBits;
+    //assert maxH <= (2 * maxNumValues); // Can fail when freezing with too low maxNumValues
+    return maxH;
+  }
+
+  long maxNumHighBits() {
+    long numHighBitsClear = maxHighValue();
+    long numHighBitsSet = this.maxNumValues;  
+    return numHighBitsClear + numHighBitsSet;
+  }
+
+  long maxNumValueIndexEntries() {
+    long maxNum = maxHighValue() / valueIndexInterval; // no zero value index entry
+    return (maxNum >= 0) ? maxNum : 0;
+  }
+  
+
+  /** Return a new EliasFanoSequence of the same type */
+  abstract EliasFanoSequence newSequence(long maxNumValues, long upperBound, long valueIndexInterval);
+
+  /** Reencode the values encoded in this sequence into an EliasFanoEncoder */
+  void reEncode(EliasFanoEncoder<?> efEncoder) {
+    EliasFanoDecoder<?> efDecoder = getDecoder();
+    while (true) {
+      long value = efDecoder.nextValue();
+      if (value == EliasFanoDecoder.NO_MORE_VALUES)
+        break;
+      efEncoder.encodeNext(value);
+    }
+  }
+
+  abstract public EliasFanoEncoder<? extends EliasFanoSequence> getEncoder();
+
+  abstract void setHighBit(long highBitNum); // encode unary by bit
+
+  abstract void setLowValue(long efIndex, long value);
+
+  /** Should be called with increasing values for entryIndex, starting at 0 */
+  abstract void setValueIndexEntry(long afterZeroBitPosition, long entryIndex);
+
+
+  /** Provide a maximum number of values above which it is better to use a {@link org.apache.lucene.util.FixedBitSet}
+   *  than an {@link EliasFanoSequence} to encode and decode a strictly monotone sequence with a given upperBound.
+   *  This indication is not precise and may change in the future.
+   *  <br>It is assumed the value index uses {@link #DEFAULT_VALUE_INDEX_INTERVAL}.
+   *  <br>A bit set is always preferred when <code>upperbound &lt; 256</code>.
+   *  <br>Note that when <code>numValues &gt;= (upperBound/3)</code> a {@link org.apache.lucene.util.FixedBitSet}
+   *  will take less space however this is not the only criterion used here.
+   *  Normally a value smaller than <code>(upperBound/3)</code> is returned.
+   *  @param upperBound The maximum possible value in the sequence.
+   */
+   public static long preferredMaxNumValues(long upperBound) {
+    /* When (upperBound / 6) == maxNumValues,
+     * the number of bits per entry for the EliasFanoEncoder is 2 + ceil(2log(upperBound/maxNumValues)) == 5.
+     * For intersecting two bit sets upperBound bits are accessed, roughly half of one, half of the other.
+     * For intersecting two EliasFano sequences without value index on the high bits,
+     * all (2 * 3 * maxNumValues) high bits are accessed.
+     */
+    return (upperBound < (4 * Long.SIZE))
+          ? 0 // prefer a bitset when it takes no more than 4 longs.
+          : (upperBound / 7); // 6 for intersection as above, + 1 to allow room for the index.
+  }
+
+  /**
+   * Returns an {@link EliasFanoDecoder} to access the sequence.
+   * Only use this method after encoding.
+   */
+  public abstract EliasFanoDecoder<? extends EliasFanoSequence> getDecoder();
+
+  abstract long getHighLong(int highIndex); // decoder always uses high long for broadword efficiency
+
+  abstract long getLowValue(long efPosition);
+
+  abstract long getValueIndexEntry(long entryIndex);
+
+
+  @Override
+  public String toString() {
+    StringBuilder s = new StringBuilder("EliasFanoSequence(");
+    s.append("maxNumValues=" + maxNumValues);
+    s.append(", upperBound=" + upperBound);
+    s.append(", numLowBits=" + numLowBits);
+    s.append(", valueIndexInterval=" + valueIndexInterval);
+    s.append(", numValueIndexEntryBits=" + numValueIndexEntryBits);
+    s.append(")");
+    return s.toString();
+  }
+  
+  @Override
+  public boolean equals(Object other) {
+    if (other == null) {
+      return false;
+    }
+    if (getClass() != other.getClass()) {
+      return false;
+    }
+    EliasFanoSequence oefs = (EliasFanoSequence) other;
+    return (this.numLowBits == oefs.numLowBits)
+        && (this.maxNumValues == oefs.maxNumValues)
+        && (this.upperBound == oefs.upperBound)
+        && (this.valueIndexInterval == oefs.valueIndexInterval);
+  }
+
+  @Override
+  public int hashCode() {
+    return getClass().hashCode() 
+          ^ (3 * numLowBits + (int) (maxNumValues ^ upperBound ^ valueIndexInterval));
+  }
+  
+}
+
Index: lucene/core/src/java/org/apache/lucene/util/eliasfano/package.html
===================================================================
--- lucene/core/src/java/org/apache/lucene/util/eliasfano/package.html	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/util/eliasfano/package.html	(working copy)
@@ -0,0 +1,30 @@
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head></head>
+<body bgcolor="white">
+
+<h2>Package for Elias Fano code</h2>
+
+These classes were taken from a development version of package org.apache.lucene.util.packed in July 2014.
+<br>
+When the Elias Fano classes here are acceptable, they may be moved back into package org.apache.lucene.util.packed
+or the versions there may be deleted.
+
+</body>
+</html>
Index: lucene/core/src/test/org/apache/lucene/search/spans/TestFilterSpans.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/TestFilterSpans.java	(revision 1681580)
+++ lucene/core/src/test/org/apache/lucene/search/spans/TestFilterSpans.java	(working copy)
@@ -31,6 +31,7 @@
     // verify that all methods of Spans are overridden by FilterSpans,
     // except those under the 'exclude' list
     Set<Method> exclude = new HashSet<>();
+    exclude.add(FilterSpans.class.getMethod("asTwoPhaseIterator"));
     for (Method m : FilterSpans.class.getMethods()) {
       if (m.getDeclaringClass() == Spans.class) {
         assertTrue("method " + m.getName() + " not overridden!", exclude.contains(m));
Index: lucene/core/src/test/org/apache/lucene/util/eliasfano/BaseEliasFanoSequenceTestCase.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/eliasfano/BaseEliasFanoSequenceTestCase.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/util/eliasfano/BaseEliasFanoSequenceTestCase.java	(working copy)
@@ -0,0 +1,212 @@
+package org.apache.lucene.util.eliasfano;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+/** Base test class for {@link EliasFanoSequence}s. */
+public abstract class BaseEliasFanoSequenceTestCase<EFSeq extends EliasFanoSequence> extends LuceneTestCase {
+
+  abstract EliasFanoSequence makeSequence(long[] values, long valueIndexInterval);
+
+  static void encodeSequence(long[] values, EliasFanoSequence efSeq) {
+    long upperBound = 0L;
+    for (long value: values) {
+      assertTrue(value >= upperBound); // test data ok
+      upperBound = value;
+    }
+    EliasFanoEncoder<?> efEncoder = efSeq.getEncoder();
+    for (long value: values) {
+      efEncoder.encodeNext(value);
+    }
+  }
+
+  static void tstDecodeAllNext(long[] values, EliasFanoDecoder<?> efd) {
+    efd.toBeforeSequence();
+    long nextValue = efd.nextValue();
+    for (long expValue: values) {
+      assertFalse("nextValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == nextValue);
+      assertEquals(expValue, nextValue);
+      nextValue = efd.nextValue();
+    }
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, nextValue);
+  }
+
+  static void tstDecodeAllPrev(long[] values, EliasFanoDecoder<?> efd) {
+    efd.toAfterSequence();
+    for (int i = values.length - 1; i >= 0; i--) {
+      long previousValue = efd.previousValue();
+      assertFalse("previousValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == previousValue);
+      assertEquals(values[i], previousValue);
+    }
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, efd.previousValue());
+  }
+
+  static void tstDecodeAllAdvanceToExpected(long[] values, EliasFanoDecoder<?> efd) {
+    efd.toBeforeSequence();
+    long previousValue = -1L;
+    long position = 0;
+    for (long expValue: values) {
+      if (expValue > previousValue) {
+        long advanceValue = efd.advanceToValue(expValue);
+        assertFalse("advanceValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == advanceValue);
+        assertEquals(expValue, advanceValue);
+        assertEquals(position, efd.currentPosition());
+        previousValue = expValue;
+      }
+      position++;
+    }
+    long advanceValue = efd.advanceToValue(previousValue+1);
+    assertEquals("at end", EliasFanoDecoder.NO_MORE_VALUES, advanceValue);
+  }
+
+  static void tstDecodeAdvanceToMultiples(long[] values, EliasFanoDecoder<?> efd, final long m) {
+    // test advancing to multiples of m
+    assert m > 0;
+    long previousValue = -1L;
+    long position = 0;
+    long mm = m;
+    efd.toBeforeSequence();
+    for (long expValue: values) {
+      // mm > previousValue
+      if (expValue >= mm) {
+        long advanceValue = efd.advanceToValue(mm);
+        assertFalse("advanceValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == advanceValue);
+        assertEquals(expValue, advanceValue);
+        assertEquals(position, efd.currentPosition());
+        previousValue = expValue;
+        do {
+          mm += m;
+        } while (mm <= previousValue);
+      }
+      position++;
+    }
+    long advanceValue = efd.advanceToValue(mm);
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, advanceValue);
+  }
+
+  static void tstDecodeBackToMultiples(long[] values, EliasFanoDecoder<?> efd, final long m) {
+    // test backing to multiples of m
+    assert m > 0;
+    efd.toAfterSequence();
+    int position = values.length - 1;
+    if (position < 0) {
+      long advanceValue = efd.backToValue(0);
+      assertEquals(EliasFanoDecoder.NO_MORE_VALUES, advanceValue);
+      return; // empty values, nothing to go back to/from
+    }
+    long expValue = values[position];
+    long previousValue = expValue + 1;
+    long mm = (expValue / m) * m;
+    while (position >= 0) {
+      expValue = values[position];
+      assert mm < previousValue;
+      if (expValue <= mm) {
+        long backValue = efd.backToValue(mm);
+        assertFalse("backToValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == backValue);
+        assertEquals(expValue, backValue);
+        assertEquals(position, efd.currentPosition());
+        previousValue = expValue;
+        do {
+          mm -= m;
+        } while (mm >= previousValue);
+      }
+      position--;
+    }
+    long backValue = efd.backToValue(mm);
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, backValue);
+  }
+
+  static void tstDecodeAll(EliasFanoSequence efSeq, long[] values) {
+    tstDecodeAllNext(values, efSeq.getDecoder());
+    tstDecodeAllPrev(values, efSeq.getDecoder());
+    tstDecodeAllAdvanceToExpected(values, efSeq.getDecoder());
+  }
+
+  void tstEFS2(long[] values) {
+    EliasFanoSequence efSeqB = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    tstDecodeAll(efSeqB, values);
+  }
+
+
+  public void testHashCodeEquals() {
+    long[] values = new long[] {5,8,8,15,32};
+    EliasFanoSequence efSeq1 = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    EliasFanoSequence efSeq2 = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    assertEquals(efSeq1, efSeq2);
+    assertEquals(efSeq1.hashCode(), efSeq2.hashCode());
+
+    long[] values3 = new long[] {1,2,3};
+    EliasFanoSequence efSeq3 = makeSequence(values3, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    assertFalse(efSeq1.equals(efSeq3));
+    assertFalse(efSeq3.equals(efSeq1));
+    assertFalse(efSeq1.hashCode() == efSeq3.hashCode()); // Might fail, passes for test data.
+  }
+
+  public void testMonotoneSequences() {
+    for (int s = 2; s < 4422; s++) {
+      long[] values = new long[s];
+      for (int i = 0; i < s; i++) {
+        values[i] = (i/2); // upperbound smaller than number of values, only upper bits encoded
+      }
+      tstEFS2(values);
+    }
+  }
+
+  public void testStrictMonotoneSequences() {
+    for (int s = 2; s < 4422; s++) {
+      long[] values = new long[s];
+      for (int i = 0; i < s; i++) {
+        values[i] = i * ((long) i - 1) / 2; // Add a gap of (s-1) to previous
+        // s = (s*(s+1) - (s-1)*s)/2
+      }
+      tstEFS2(values);
+    }
+  }
+
+  public void testAdvanceToAndBackToMultiples() {
+    for (int s = 2; s < 130; s++) {
+      long[] values = new long[s];
+      for (int i = 0; i < s; i++) {
+        values[i] = i * ((long) i + 1) / 2; // Add a gap of s to previous
+        // s = (s*(s+1) - (s-1)*s)/2
+      }
+      EliasFanoSequence efSeq = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+      long maxValue = values[s-1];
+      long minAdvanceMultiple = 10;
+      for (long m = minAdvanceMultiple; m <= maxValue; m += 1) {
+        tstDecodeAdvanceToMultiples(values, efSeq.getDecoder(), m);
+        tstDecodeBackToMultiples(values, efSeq.getDecoder(), m);
+      }
+    }
+  }
+
+  public void testAdvanceToPosition1() {
+    long[] values = new long[] {0,2};
+    EliasFanoSequence efSeq1 = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    EliasFanoDecoder<?> efd = efSeq1.getDecoder();
+    assertTrue(efd.advanceToPosition(0));
+    assertEquals("position", 0, efd.currentPosition());
+    assertEquals("value", 0, efd.currentValue());
+    assertTrue(efd.advanceToPosition(1));
+    assertEquals("position", 1, efd.currentPosition());
+    assertEquals("value", 2, efd.currentValue());
+    assertFalse(efd.advanceToPosition(2));
+  }
+
+}
Index: lucene/core/src/test/org/apache/lucene/util/eliasfano/TestBitSelect.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/eliasfano/TestBitSelect.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/util/eliasfano/TestBitSelect.java	(working copy)
@@ -0,0 +1,88 @@
+package org.apache.lucene.util.eliasfano;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestBitSelect extends LuceneTestCase {
+
+  private void tstSelect(long x, int r, int exp) {
+    if ((0 <= exp) && (exp <= 63)) {
+      assertEquals("selectNaive(" + x + "," + r + ")", exp, BitSelect.selectNaive(x, r));
+      assertEquals("select(" + x + "," + r + ")", exp, BitSelect.select(x, r));
+    } else {
+      int act = BitSelect.selectNaive(x, r);
+      assertTrue("selectNaive(" + x + "," + r + ")", act < 0 || act > 63);
+      act = BitSelect.select(x, r);
+      assertTrue("select(" + x + "," + r + ")", act < 0 || act > 63);
+    }
+  }
+
+  public void testSelectFromZero() {
+    tstSelect(0L,1,72);
+  }
+  public void testSelectSingleBit() {
+    for (int i = 0; i < 64; i++) {
+      tstSelect((1L << i),1,i);
+    }
+  }
+  public void testSelectTwoBits() {
+    for (int i = 0; i < 64; i++) {
+      for (int j = i+1; j < 64; j++) {
+        long x = (1L << i) | (1L << j);
+        //System.out.println(getName() + " i: " + i + " j: " + j);
+        tstSelect(x,1,i);
+        tstSelect(x,2,j);
+        tstSelect(x,3,72);
+      }
+    }
+  }
+  public void testSelectThreeBits() {
+    for (int i = 0; i < 64; i++) {
+      for (int j = i+1; j < 64; j++) {
+        for (int k = j+1; k < 64; k++) {
+          long x = (1L << i) | (1L << j) | (1L << k);
+          tstSelect(x,1,i);
+          tstSelect(x,2,j);
+          tstSelect(x,3,k);
+          tstSelect(x,4,72);
+        }
+      }
+    }
+  }
+  public void testSelectAllBits() {
+    for (int i = 0; i < 64; i++) {
+      tstSelect(0xFFFFFFFFFFFFFFFFL,i+1,i);
+    }
+  }
+  public void testPerfSelectAllBits() {
+    for (int j = 0; j < 100000; j++) { // 1000000 for real perf test
+      for (int i = 0; i < 64; i++) {
+        assertEquals(i, BitSelect.select(0xFFFFFFFFFFFFFFFFL, i+1));
+      }
+    }
+  }
+  public void testPerfSelectAllBitsNaive() {
+    for (int j = 0; j < 10000; j++) { // real perftest: 1000000
+      for (int i = 0; i < 64; i++) {
+        assertEquals(i, BitSelect.selectNaive(0xFFFFFFFFFFFFFFFFL, i+1));
+      }
+    }
+  }
+}
+
Index: lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoBytes.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoBytes.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoBytes.java	(working copy)
@@ -0,0 +1,140 @@
+package org.apache.lucene.util.eliasfano;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.BytesRef;
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestEliasFanoBytes extends BaseEliasFanoSequenceTestCase<EliasFanoBytes> {
+
+  EliasFanoBytes makeSequence(long[] values, long valueIndexInterval) {
+    assert valueIndexInterval == EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL;
+    long upperBound = values.length > 0 ? values[values.length-1] : -1;
+    EliasFanoBytes efSeq = new EliasFanoBytes(values.length, upperBound);
+    encodeSequence(values, efSeq);
+    return efSeq;
+  }
+
+  private void checkEquals(String mes, byte[] exp, byte[] act) {
+    assertEquals(mes + ".length", exp.length, act.length);
+    for (int i = 0; i < exp.length; i++) {
+      assertEquals(mes + " at " + i, (exp[i] & 0xFF), (act[i] & 0xFF));
+    }
+  }
+  
+  private void tstEFS(long[] values, BytesRef expBytes) {
+    EliasFanoBytes efSeqB = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    tstDecodeAll(efSeqB, values);
+    BytesRef actBytes = efSeqB.getBytesRef();
+    if (! actBytes.bytesEquals(expBytes)) {
+      System.out.println("expected BytesRef: " + expBytes);
+      System.out.println("  actual BytesRef: " + actBytes);
+      checkEquals("bytes", expBytes.bytes, actBytes.bytes);
+    }
+    assertEquals("offset", expBytes.offset, actBytes.offset);
+    assertEquals("length", expBytes.length, actBytes.length);
+
+    EliasFanoBytes efSeqB2 = EliasFanoBytes.createFromBytesRef(expBytes);
+    tstDecodeAll(efSeqB2, values);
+
+    EliasFanoBytes efSeqB3 = new EliasFanoBytes(7, 9);
+    efSeqB3.reInit(expBytes);
+    tstDecodeAll(efSeqB3, values);
+  }
+
+  private BytesRef newBytesRef(byte[] bytes) {
+    return new BytesRef(bytes, 0, bytes.length);
+  }
+
+  public void testEmptySequence() {
+    long[] values = new long[0];
+    byte[] bytes = new byte[] {0,0};
+    tstEFS(values, newBytesRef(bytes));
+  }
+
+  public void testOneValue1() {
+    long[] values = new long[] {0};
+    tstEFS(values, newBytesRef(new byte[] {1,0,1}));
+  }
+
+  public void testTwoValues1() {
+    long[] values = new long[] {0,0};
+    tstEFS(values, newBytesRef(new byte[] {2,0,3}));
+  }
+
+  public void testOneValue2() {
+    long[] values = new long[] {63};
+    tstEFS(values, newBytesRef(new byte[] {1, 63, 31, 2}));
+  }
+
+  public void testOneMaxValue() {
+    long[] values = new long[] {Long.MAX_VALUE};
+    tstEFS(values, newBytesRef(new byte[] {1, -1,-1,-1,-1,-1,-1,-1,-1,127, -1,-1,-1,-1,-1,-1,-1,63, 2}));
+  }
+
+  public void testTwoMinMaxValues() {
+    long[] values = new long[] {0, Long.MAX_VALUE};
+    tstEFS(values, newBytesRef(new byte[] {2, -1,-1,-1,-1,-1,-1,-1,-1,127, 0,0,0,0,0,0,0,-32,-1,-1,-1,-1,-1,-1,-1, 0x03, 0x11}));
+  }
+
+
+  public void testMaxContentEmptyValueIndex() {
+    long[] values = new long[256];
+    for (int i = 0; i < values.length; i++) {
+      values[i] = i;
+    }
+    tstEFS(values, newBytesRef(new byte[]
+                        {-128, 2, // header 256 numValues
+                         -1, 1, // header 255 maxValue
+                         // no low bits, no index
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55 // 64 bytes for high bits, no low bits, no index bits
+                        }));
+  }
+
+
+  public void testMinContentNonEmptyValueIndex() {
+    long[] values = new long[257];
+    for (int i = 0; i < values.length; i++) { // Note: there may be smaller content, starting at value 127 or so.
+      values[i] = i;
+    }
+    tstEFS(values, newBytesRef(new byte[]
+                        {-127, 2, // header 257 numValues
+                         -128, 2, // header 256 maxValue
+                         // no low bits.
+                         0, 2, // index entry 512
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 
+                         0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 0x55, 1 // 65 bytes for high bits
+                        }));
+  }
+
+}
+
Index: lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoDocIdSet.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoDocIdSet.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoDocIdSet.java	(working copy)
@@ -0,0 +1,85 @@
+package org.apache.lucene.util.eliasfano;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.BitSet;
+
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.util.BaseDocIdSetTestCase;
+
+public class TestEliasFanoDocIdSet extends BaseDocIdSetTestCase<EliasFanoDocIdSet> {
+
+  @Override
+  public EliasFanoDocIdSet copyOf(final BitSet bs, final int numBits) throws IOException {
+    int numDocIds = random().nextBoolean() ? bs.cardinality() : -1;
+    final EliasFanoDocIdSet set = new EliasFanoDocIdSet(numDocIds, numBits - 1);
+
+    set.encodeFromDisi(new DocIdSetIterator() {
+      int doc = -1;
+
+      @Override
+      public int nextDoc() throws IOException {
+        doc = bs.nextSetBit(doc + 1);
+        if (doc == -1) {
+          doc = NO_MORE_DOCS;
+        }
+        else {
+          assert doc < numBits;
+        }
+        return doc;
+      }
+
+      @Override
+      public int docID() {
+        return doc;
+      }
+
+      @Override
+      public long cost() {
+        return bs.cardinality();
+      }
+
+      @Override
+      public int advance(int target) throws IOException {
+        throw new UnsupportedOperationException();
+      }
+    });
+    return set;
+  }
+
+  @Override
+  /** Test ram usage estimation. */
+  public void testRamBytesUsed() throws IOException {
+    // NOCOMMIT: what is the good way to implement Accountable on EliasFanoDocIdSet?
+/*  // code from BaseDocIdSetTestCase:
+    final int iters = 100;
+    for (int i = 0; i < iters; ++i) {
+      final int pow = random().nextInt(20);
+      final int maxDoc = TestUtil.nextInt(random(), 1, 1 << pow);
+      final int numDocs = TestUtil.nextInt(random(), 0, Math.min(maxDoc, 1 << TestUtil.nextInt(random(), 0, pow)));
+      final BitSet set = randomSet(maxDoc, numDocs);
+      final DocIdSet copy = copyOf(set, maxDoc);
+      final long actualBytes = ramBytesUsed(copy, maxDoc);
+      final long expectedBytes = copy.ramBytesUsed();
+      assertEquals(expectedBytes, actualBytes);
+    }
+ */
+  }
+
+}
\ No newline at end of file
Index: lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoLongs.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoLongs.java	(revision 0)
+++ lucene/core/src/test/org/apache/lucene/util/eliasfano/TestEliasFanoLongs.java	(working copy)
@@ -0,0 +1,217 @@
+package org.apache.lucene.util.eliasfano;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestEliasFanoLongs extends BaseEliasFanoSequenceTestCase<EliasFanoLongs> {
+
+  EliasFanoLongs makeSequence(long[] values, long indexInterval) {
+    long upperBound = values.length > 0 ? values[values.length-1] : -1;
+    EliasFanoLongs efSeq = new EliasFanoLongs(values.length, upperBound, indexInterval);
+    encodeSequence(values, efSeq);
+    efSeq.freeze(values.length);
+    return efSeq;
+  }
+
+  private static void tstEqual(String mes, long[] exp, long[] act) {
+    assertEquals(mes + ".length", exp.length, act.length);
+    for (int i = 0; i < exp.length; i++) {
+      if (exp[i] != act[i]) {
+        fail(mes + "[" + i + "] " + exp[i] + " != " + act[i]);
+      }
+    }
+  }
+
+  private void tstEFS(long[] values, long[] expHighLongs, long[] expLowLongs) {
+    EliasFanoLongs efSeqL = makeSequence(values, EliasFanoSequence.DEFAULT_VALUE_INDEX_INTERVAL);
+    tstEqual("high bits", expHighLongs, efSeqL.getHighBits());
+    tstEqual("low bits", expLowLongs, efSeqL.getLowBits());
+    tstDecodeAll(efSeqL, values);
+  }
+
+
+  private EliasFanoLongs tstEFVI(long[] values, long indexInterval, long[] expIndexBits) {
+    EliasFanoLongs efSeq = makeSequence(values, indexInterval);
+    tstEqual("index bits", expIndexBits, efSeq.getValueIndexBits());
+    return efSeq;
+  }
+
+  public void testEmptySequence() {
+    long[] values = new long[0];
+    long[] expHighBits = new long[0];
+    long[] expLowBits = new long[0];
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testOneValue1() {
+    long[] values = new long[] {0};
+    long[] expHighBits = new long[] {0x1L};
+    long[] expLowBits = new long[] {};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testTwoValues1() {
+    long[] values = new long[] {0,0};
+    long[] expHighBits = new long[] {0x3L};
+    long[] expLowBits = new long[] {};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testOneValue2() {
+    long[] values = new long[] {63};
+    long[] expHighBits = new long[] {2};
+    long[] expLowBits = new long[] {31};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testOneMaxValue() {
+    long[] values = new long[] {Long.MAX_VALUE};
+    long[] expHighBits = new long[] {2};
+    long[] expLowBits = new long[] {Long.MAX_VALUE/2};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testTwoMinMaxValues() {
+    long[] values = new long[] {0, Long.MAX_VALUE};
+    long[] expHighBits = new long[] {0x11};
+    long[] expLowBits = new long[] {0xE000000000000000L, 0x03FFFFFFFFFFFFFFL};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testTwoMaxValues() {
+    long[] values = new long[] {Long.MAX_VALUE, Long.MAX_VALUE};
+    long[] expHighBits = new long[] {0x18};
+    long[] expLowBits = new long[] {-1L, 0x03FFFFFFFFFFFFFFL};
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testExample1() { // Figure 1 from Vigna 2012 paper
+    long[] values = new long[] {5,8,8,15,32};
+    long[] expLowBits = new long[] {Long.parseLong("0011000001", 2)}; // reverse block and bit order
+    long[] expHighBits = new long[] {Long.parseLong("1000001011010", 2)}; // reverse block and bit order
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+  public void testEmptyValueIndex() {
+    long indexInterval = 2;
+    long[] emptyLongs = new long[0];
+    tstEFVI(emptyLongs, indexInterval, emptyLongs);
+  }
+
+  public void testMaxContentEmptyValueIndex() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,1};
+    long[] emptyLongs = new long[0];
+    tstEFVI(twoLongs, indexInterval, emptyLongs);
+  }
+
+  public void testMinContentNonEmptyValueIndex() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,2};
+    long[] indexLongs = new long[] {3}; // high bits 1001, index position after zero bit.
+    tstEFVI(twoLongs, indexInterval, indexLongs);
+  }
+
+  public void testIndexAdvanceToLast() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,2};
+    long[] indexLongs = new long[] {3}; // high bits 1001
+    EliasFanoSequence efSeqVI = tstEFVI(twoLongs, indexInterval, indexLongs);
+    assertEquals(2, efSeqVI.getDecoder().advanceToValue(2));
+  }
+
+  public void testIndexAdvanceToAfterLast() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,2};
+    long[] indexLongs = new long[] {3}; // high bits 1001
+    EliasFanoSequence efSeqVI = tstEFVI(twoLongs, indexInterval, indexLongs);
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, efSeqVI.getDecoder().advanceToValue(3));
+  }
+
+  public void testIndexAdvanceToFirst() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,2};
+    long[] indexLongs = new long[] {3}; // high bits 1001
+    EliasFanoSequence efSeqVI = tstEFVI(twoLongs, indexInterval, indexLongs);
+    assertEquals(0, efSeqVI.getDecoder().advanceToValue(0));
+  }
+  
+  public void testTwoIndexEntries() {
+    long indexInterval = 2;
+    long[] twoLongs = new long[] {0,1,2,3,4,5};
+    long[] indexLongs = new long[] {4 + 8*16}; // high bits 0b10101010101
+    EliasFanoSequence efSeqVI = tstEFVI(twoLongs, indexInterval, indexLongs);
+    EliasFanoDecoder<?> efDecVI = efSeqVI.getDecoder();
+    assertEquals("advance 0", 0, efDecVI.advanceToValue(0));
+    assertEquals("advance 5", 5, efDecVI.advanceToValue(5));
+    assertEquals("advance 6", EliasFanoDecoder.NO_MORE_VALUES, efDecVI.advanceToValue(5));
+  }
+
+  public void testExample2a() { // Figure 2 from Vigna 2012 paper
+    long indexInterval = 4;
+    long[] values = new long[] {5,8,8,15,32}; // two low bits, high values 1,2,2,3,8.
+    long[] indexLongs = new long[] {8 + 12*16}; // high bits 0b 0001 0000 0101 1010
+    EliasFanoSequence efSeqVI = tstEFVI(values, indexInterval, indexLongs);
+    EliasFanoDecoder<?> efDecVI = efSeqVI.getDecoder();
+    assertEquals("advance 22", 32, efDecVI.advanceToValue(22));
+  }
+
+  public void testExample2b() { // Figure 2 from Vigna 2012 paper
+    long indexInterval = 4;
+    long[] values = new long[] {5,8,8,15,32}; // two low bits, high values 1,2,2,3,8.
+    long[] indexLongs = new long[] {8 + 12*16}; // high bits 0b 0001 0000 0101 1010
+    EliasFanoSequence efSeqVI = tstEFVI(values, indexInterval, indexLongs);
+    EliasFanoDecoder<?> efDecVI = efSeqVI.getDecoder();
+    assertEquals("initial next", 5, efDecVI.nextValue());
+    assertEquals("advance 22", 32, efDecVI.advanceToValue(22));
+  }
+
+  public void testExample2NoIndex1() { // Figure 2 from Vigna 2012 paper, no index, test broadword selection.
+    long indexInterval = 16;
+    long[] values = new long[] {5,8,8,15,32}; // two low bits, high values 1,2,2,3,8.
+    long[] indexLongs = new long[0]; // high bits 0b 0001 0000 0101 1010
+    EliasFanoSequence efSeqVI = tstEFVI(values, indexInterval, indexLongs);
+    EliasFanoDecoder<?> efDecVI = efSeqVI.getDecoder();
+    assertEquals("advance 22", 32, efDecVI.advanceToValue(22));
+  }
+
+  public void testExample2NoIndex2() { // Figure 2 from Vigna 2012 paper, no index, test broadword selection.
+    long indexInterval = 16;
+    long[] values = new long[] {5,8,8,15,32}; // two low bits, high values 1,2,2,3,8.
+    long[] indexLongs = new long[0]; // high bits 0b 0001 0000 0101 1010
+    EliasFanoSequence efSeqVI = tstEFVI(values, indexInterval, indexLongs);
+    EliasFanoDecoder<?> efDecVI = efSeqVI.getDecoder();
+    assertEquals("initial next", 5, efDecVI.nextValue());
+    assertEquals("advance 22", 32, efDecVI.advanceToValue(22));
+  }
+
+  public void testHighBitLongZero() {
+    final int s = 65;
+    long[] values = new long[s];
+    for (int i = 0; i < s-1; i++) {
+      values[i] = 0;
+    }
+    values[s-1] = 128;
+    long[] expHighBits = new long[] {-1,0,0,1};
+    long[] expLowBits = new long[0];
+    tstEFS(values, expHighBits, expLowBits);
+  }
+
+}
+
Index: lucene/join/build.xml
===================================================================
--- lucene/join/build.xml	(revision 1681580)
+++ lucene/join/build.xml	(working copy)
@@ -19,7 +19,7 @@
 -->
 <project name="join" default="default">
   <description>
-    Index-time and Query-time joins for normalized content
+    Index-time and Query-time document joins for normalized content
   </description>
 
   <import file="../module-build.xml"/>
Index: lucene/join/src/java/org/apache/lucene/search/join/package-info.java
===================================================================
--- lucene/join/src/java/org/apache/lucene/search/join/package-info.java	(revision 1681580)
+++ lucene/join/src/java/org/apache/lucene/search/join/package-info.java	(working copy)
@@ -16,10 +16,10 @@
  */
 
 /**
- * Support for index-time and query-time joins.
+ * Support for index-time and query-time document joins.
  * <h2>Index-time joins</h2>
  *
- * <p>The index-time joining support joins while searching, where joined
+ * <p>The index-time joining support document joins while searching, where joined
  *   documents are indexed as a single document block using
  *   {@link org.apache.lucene.index.IndexWriter#addDocuments IndexWriter.addDocuments()}.  
  *   This is useful for any normalized content (XML documents or database tables).  In database terms, all rows for all
@@ -54,10 +54,10 @@
  *   any query matching parent documents, creating the joined query
  *   matching only child documents.
  * 
- * <h2>Query-time joins</h2>
+ * <h2>Query-time document joins</h2>
  * 
  * <p>
- *   The query time joining is index term based and implemented as two pass search. The first pass collects all the terms from a fromField
+ *   The query time document joining is index term based and implemented as two pass search. The first pass collects all the terms from a fromField
  *   that match the fromQuery. The second pass returns all documents that have matching terms in a toField to the terms
  *   collected in the first pass.
  * </p>
Index: lucene/label/build.xml
===================================================================
--- lucene/label/build.xml	(revision 0)
+++ lucene/label/build.xml	(working copy)
@@ -0,0 +1,34 @@
+<?xml version="1.0"?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one
+   or more contributor license agreements.  See the NOTICE file
+   distributed with this work for additional information
+   regarding copyright ownership.  The ASF licenses this file
+   to you under the Apache License, Version 2.0 (the
+   "License"); you may not use this file except in compliance
+   with the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing,
+   software distributed under the License is distributed on an
+   "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+   KIND, either express or implied.  See the License for the
+   specific language governing permissions and limitations
+   under the License.
+-->
+<project name="label" default="default">
+  <description>
+    Index-time and Query-time positional joins
+  </description>
+
+  <import file="../module-build.xml"/>
+
+  <path id="classpath">
+    <pathelement path="${analyzers-common.jar}"/>
+    <path refid="base.classpath"/>
+  </path>
+
+  <target name="init" depends="module-build.init,jar-analyzers-common"/>
+
+</project>
Index: lucene/label/ivy.xml
===================================================================
--- lucene/label/ivy.xml	(revision 0)
+++ lucene/label/ivy.xml	(working copy)
@@ -0,0 +1,21 @@
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one
+   or more contributor license agreements.  See the NOTICE file
+   distributed with this work for additional information
+   regarding copyright ownership.  The ASF licenses this file
+   to you under the Apache License, Version 2.0 (the
+   "License"); you may not use this file except in compliance
+   with the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing,
+   software distributed under the License is distributed on an
+   "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+   KIND, either express or implied.  See the License for the
+   specific language governing permissions and limitations
+   under the License.
+-->
+<ivy-module version="2.0">
+    <info organisation="org.apache.lucene" module="label"/>
+</ivy-module>
Index: lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/FragmentPositionsStreamBuilder.java	(working copy)
@@ -0,0 +1,131 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+import java.util.Objects;
+
+import org.apache.lucene.analysis.TokenStream;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+
+import org.apache.lucene.analysis.sinks.PrefillTokenStream;
+
+import org.apache.lucene.util.Attribute;
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoEncoder;
+
+class FragmentPositionsStreamBuilder {
+  private ArrayList<Integer> fragmentPositions;
+  private AttributeSource attributeSource;
+  private PrefillTokenStream fragmentStream;
+  private int fragmentsSize;
+
+  FragmentPositionsStreamBuilder(AttributeSource attributeSource) {
+    this.attributeSource = Objects.requireNonNull(attributeSource);
+    this.fragmentStream = new PrefillTokenStream(attributeSource);
+    this.fragmentPositions = new ArrayList<>();
+    this.fragmentsSize = 0;
+  }
+
+  void addTokenState(AttributeSource attributeSource) {
+    fragmentStream.addState(attributeSource.captureState());
+  }
+
+  void incrementFragmentsSize() {
+    fragmentsSize++;
+  }
+
+  void incrementFragmentsSize(int incr) {
+    fragmentsSize += incr;
+  }
+
+  void addSizeAsPosition() {
+    fragmentPositions.add(fragmentsSize);
+  }
+
+  TokenStream fragmentsTokenStream() {
+    return fragmentStream;
+  }
+
+  BytesRef fragmentPositionsBytesRef() {
+    int numValues = fragmentPositions.size();
+    if (numValues <= 1) { // no labels: do not index.
+      return null; // avoid creating an EliasFanoBytes
+    } else {
+      int upperBound = fragmentPositions.get(numValues - 1); // non empty
+      if (upperBound == 0) { // only empty fragments
+        return null;
+      } else {
+        /* Corner case not checked here: all labels after first and only non empty fragment.
+         * In this case the first labeled fragment start position is non zero, and
+         * equal to the last fragment end position.
+         * A query for a first non labeled non empty fragment is not unthinkable, so index this.
+         */
+        EliasFanoBytes efBytes = new EliasFanoBytes(numValues, upperBound);
+        EliasFanoEncoder<?> efEncoder = efBytes.getEncoder();
+        for (int fragmentPos: fragmentPositions) {
+          // The Elias-Fano sequence position is the label position,
+          // the sequence value is the fragment start position:
+          efEncoder.encodeNext(fragmentPos);
+        }
+        return efBytes.getBytesRef();
+      }
+    }
+  }
+
+  public TokenStream fragmentPositionsTokenStream(final String termText) {
+    final BytesRef payload = fragmentPositionsBytesRef();
+
+    return new TokenStream() { // single term at position 0 with payload, if any.
+      CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+      PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
+      boolean atFirstTerm;
+
+      @Override
+      public void reset() {
+        atFirstTerm = true;
+      }
+
+      @Override
+      public boolean incrementToken() {
+        if (! atFirstTerm) {
+          return false;
+        }
+        atFirstTerm = false;
+        if (payload == null) {
+          return false;
+        }
+        termAtt.setEmpty();
+        termAtt.append(termText);
+        payloadAtt.setPayload(payload);
+        return true;
+      }
+    };
+  }
+
+  public void clear() {
+    fragmentStream = new PrefillTokenStream(attributeSource); // replace, do not close, may still be indexed.
+    fragmentPositions.clear();
+    fragmentsSize = 0;
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/LabelTreeInfoBuilder.java	(working copy)
@@ -0,0 +1,105 @@
+package org.apache.lucene.analysis.label;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.packed.label.LongsInBytes;
+
+/*
+  Number of bits needed for label tree info: 2*n*ceil(2log(n-1)), for example:
+   100  labels: 2*100*7     =    1.4 Kbits =   0.175 KB
+   500  labels: 2*500*9     =    9   Kbits =   1.125 KB
+     1k labels: 2*1000*10   =   20   Kbits =   2.5   KB
+     5k labels: 2*5000*13   =  130   Kbits =  16.25  KB
+    10k labels: 2*10000*14  =  280   Kbits =  35     KB
+    50k labels: 2*50000*16  = 1600   Kbits = 200     KB
+   100k labels: 2*100000*17 = 3400   Kbits = 425     KB
+  that is about 1-3 times what is needed for the positions of the labels.
+
+  The number of bits might be reduced to about 2.4*n bits,
+  see also Arroyuelo et al., 2010, Succinct Trees in Practice.
+  That requires more complex code (balanced parentheses), and it will probably be slower.
+*/
+
+class LabelTreeInfoBuilder {
+  private ArrayList<Integer> labelParentPositions;
+  private ArrayList<Integer> labelSubTreeSizes;
+  private ArrayList<Integer> labelPositionsStack;
+
+  LabelTreeInfoBuilder() {
+    labelParentPositions = new ArrayList<>(0);
+    labelSubTreeSizes = new ArrayList<>(0);
+    labelPositionsStack = new ArrayList<>(0);
+  }
+
+  void reInit() {
+    labelParentPositions.clear();
+    labelSubTreeSizes.clear();
+    labelPositionsStack.clear();
+  }
+
+  void pushLabel() {
+    int currentLabelPosition = labelParentPositions.size();
+    int parentPosition = (currentLabelPosition == 0)
+                          ? 0 // root is its own parent
+                          : labelPositionsStack.get(labelPositionsStack.size()-1); // top of labelPositionsStack
+    labelParentPositions.add(parentPosition);
+    labelPositionsStack.add(currentLabelPosition);
+    labelSubTreeSizes.add(0); // sub tree size to be filled in by popLabel
+  }
+
+  void popLabel() {
+    int currentLabelPosition = labelParentPositions.size() - 1;
+    int stackTop = labelPositionsStack.size()-1;
+    int parentPosition = labelPositionsStack.get(stackTop);
+    labelSubTreeSizes.set(parentPosition, currentLabelPosition - parentPosition);
+    labelPositionsStack.remove(stackTop);
+  }
+
+  boolean isEmptyStack() {
+    return labelPositionsStack.isEmpty();
+  }
+
+  BytesRef treeInfoBytesRef() {
+    // This takes 2 * ceil(2log(numLabels-1)) bits per label,
+    // An alternative implementation takes 2.3 bits per label ("fully functional") but takes more time to decode.
+    assert labelParentPositions.size() == labelSubTreeSizes.size();
+    assert labelParentPositions.size() > 0;
+    int numBits = Integer.SIZE - Integer.numberOfLeadingZeros(labelParentPositions.size() - 1);
+    if (numBits == 0) {
+      assert labelParentPositions.size() == 1;
+      return null; // no payload needed, only a root
+    }
+    int numBytes = (2 * numBits * labelParentPositions.size() + (Byte.SIZE-1)) >>> LongsInBytes.LOG2_BYTE_SIZE;
+    BytesRef bytesRef = new BytesRef(numBytes);
+    byte[] bytes = bytesRef.bytes;
+    for (int nodeNum = 0; nodeNum < labelParentPositions.size(); nodeNum++) {
+      LongsInBytes.packValue(labelParentPositions.get(nodeNum), numBits, 2 * nodeNum,     bytes); // parent position
+      LongsInBytes.packValue(labelSubTreeSizes.get(nodeNum),    numBits, 2 * nodeNum + 1, bytes); // subtree size
+    }
+    bytesRef.offset = 0;
+    bytesRef.length = bytesRef.bytes.length;
+    return bytesRef;
+  }
+
+  public void close() {
+    reInit();
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/LabeledFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,377 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Objects;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+import org.apache.lucene.analysis.sinks.PrefillTokenStream;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes; // for javadocs only
+
+/**
+ * Split a {@link TokenStream} with labeled fragments into Tokenstreams
+ * for labels, fragments and fragment positions,
+ * to be searched by subclasses of {@link org.apache.lucene.search.spans.label.LabeledFragmentsQuery} after indexing.
+ * Labels and fragments are indicated by methods from {@link LabeledFragmentsAnalyzer.InputSplitter}.
+ * <br>
+ * Each input stream is split into token streams for:
+ * <ul>
+ * <li>a label stream, and
+ * <li>one or more pairs of a fragment stream and a stream with a fragment start/end positions payload.
+ * </ul>
+ * A document can be indexed with these output streams and a field for the label tokens, field(s) for the fragment tokens
+ * and field(s) for the fragment start/end positions.
+ * Subclasses of {@link org.apache.lucene.search.spans.label.LabeledFragmentsQuery}
+ * can use these associations between labels and fragments.
+ * <p>
+ * In a labeled fragment stream each label preceeds its associated fragments.
+ * The label tokens in this stream are distinguished from the fragment tokens by
+ * {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+ * <p>
+ * Each label is associated with the start/end positions of one fragment in each fragment stream.
+ * A fragment is a possibly empty series of tokens in a fragment stream.
+ * In each fragment stream the fragments are contiguous and in the same order as the labels in the label stream.
+ * <p>
+ * For one document, the fragment start/end positions for one fragment stream
+ * are compressed into a single payload that is provided with a dedicated term in another stream at position zero.
+ * <p>
+ * The example below associates the label <code>A:</code> with the fragment <code>a1 a2</code>,
+ * the label <code>B:</code> with the fragment <code>b1 b2 b3</code>, and
+ * the label <code>C:</code> with the fragment <code>c1</code>.
+ * <br>In the output streams, the label stream and the fragment streams are provided
+ * with tokens at the shown positions. In this example an ending colon indicates the labels:
+ * <p>
+ * Input stream with labels for a single fragments stream:
+ * <pre>
+ *
+ *                                A: a1 a2  B: b1 b2 b3  C: c1
+ *
+ * Labels output stream:
+ *
+ *                  label terms:  A:        B:           C:
+ *              label positions:  0         1            2
+ *
+ * Fragments output stream:
+ *
+ *              fragments/terms:     a1 a2     b1 b2 b3     c1
+ *           fragment positions:     0  1      2  3  4      5
+ *
+ * Payload term output stream:
+ *
+ * fragment start/end positions:     0         2            5  6
+ *
+ * </pre>
+ * <p>
+ * Fragments in two streams for a single label stream can for example be separated by a double colon || .
+ * <p>
+ * This is an example input stream with labels for two fragments streams:
+ * <pre>
+ *
+ *                                A:    a1   ||  a2
+ *                                B:    b1
+ *                                C:    c1   ||  c2
+ *                                               c3
+ * </pre>
+ * Presented in this way the columns show the output streams, one for the labels, and two for the fragments.
+ * In this example the labels output stream is the same as above.
+ * <br>The same input stream on a single line:
+ * <pre>
+ *
+ *                                A: a1 || a2  B: b1  C: c1 || c2 c3
+ *
+ * First fragments output stream:
+ *
+ *              fragments/terms:     a1           b1     c1
+ *           fragment positions:     0            1      2
+ *
+ * First payload term output stream:
+ *
+ * fragment start/end positions:     0            1      2  3
+ *
+ *
+ * Second fragments output stream:
+ *
+ *              fragments/terms:           a2                  c2 c3
+ *           fragment positions:           0                   1  2
+ *
+ * Second payload term output stream:
+ *
+ * fragment start/end positions:           0      1            1     3
+ *
+ * </pre>
+ * <p>
+ * The fragment streams and fragment start/end position streams are separate
+ * to allow various associations between fragment streams and label streams.
+ * <p>
+ * For a <code>1 : 1</code> relationship between tokens in the same positions in different fields there is no need
+ * to index the start/end positions. For example:
+ * <pre>
+ *                                A: a1   B: b1   C: c1
+ * </pre>
+ * See {@link org.apache.lucene.search.spans.FieldMaskingSpanQuery} for searching this case.
+ * <p>
+ * This implementation uses {@link EliasFanoBytes} to compress a payload with start/end positions.
+ * These have a value index, which allows for fast fragment to label associations.
+ * Currently these have no position index, so label to fragment associations will be somewhat slower.
+ * Since payloads need to be loaded completely during searches, this is not expected to have a big impact.
+ *
+ * @lucene.experimental
+ */
+public class LabeledFragmentsAnalyzer {
+  PrefillTokenStream labelStream;
+  TokenStream labeledFragments;
+
+  private final int numFragmentStreams;
+  private final ArrayList<FragmentPositionsStreamBuilder> fpsBuilders;
+
+  private int currentFragmentStream;
+  private FragmentPositionsStreamBuilder currentFPSB;
+
+  private InputSplitter inputSplitter;
+
+  /** Token types for splitting an input stream */
+  public static enum TokenType {
+     /** The token is a label, a later label will be its child when labels can be nested. */
+    LABEL,
+
+    /** The token is part of a text fragment associated with the last label. */
+    FRAGMENT,
+
+    /** Indicates that the next fragment token will be part of another fragment associated with the last label. */
+    NEXT_FRAGMENT,
+
+    /** Ends the last label, a later label will be a child of the last label that was not ended. */
+    END_LABEL
+  }
+
+
+  /** Indicates how tokens should be used to split the stream into (a tree of) labels and fragments. */
+  public interface InputSplitter {
+    /** Returns the {@link TokenType} for an input token. */
+    public TokenType tokenType(String term);
+  }
+
+  /** A splitter to split labeled fragment streams into labels and fragments for fragment fields.
+   * @param labeledFragments The labeled fragments input stream. This is used by {@link #consumeInputStream}.
+   * @param inputSplitter   The split will be based on {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+   * @param numFragmentStreams     The number of fragment streams. When no tokens occur for a fragment stream
+   *                               no fragment positions will be provided for that stream.
+   */
+  public LabeledFragmentsAnalyzer(TokenStream labeledFragments, InputSplitter inputSplitter, int numFragmentStreams) {
+    this.labeledFragments = Objects.requireNonNull(labeledFragments, "labeledFragments"); // for subclass
+    if (numFragmentStreams < 1) {
+      throw new IllegalArgumentException("numFragmentStreams should be at least one");
+    }
+    this.numFragmentStreams = numFragmentStreams;
+    this.inputSplitter = Objects.requireNonNull(inputSplitter, "inputSplitter");
+
+    this.labelStream = new PrefillTokenStream(labeledFragments);
+    this.fpsBuilders = new ArrayList<>();
+    for (int i = 0; i < numFragmentStreams; i++) {
+      FragmentPositionsStreamBuilder fpsb = new FragmentPositionsStreamBuilder(labeledFragments);
+      this.fpsBuilders.add(fpsb);
+    }
+  }
+
+
+  /**
+   * Consume the labeled fragments input stream once.
+   * <br>This performs <code> {@link TokenStream#reset}; while ({@link TokenStream#incrementToken}) ... ; {@link TokenStream#end}; </code>
+   * on the input stream.
+   * <br>When the input stream has a {@link PositionIncrementAttribute} it is used as expected for fragments.
+   * <br>Fragment tokens ({@link TokenType#FRAGMENT}) that immediately follow a label token or a next fragment stream token
+   * must have a positive position increment.
+   * <br>A label token ({@link TokenType#LABEL}) must have a position increment 1.
+   * <br>The position increments of next fragment stream tokens ({@link TokenType#NEXT_FRAGMENT}) are ignored.
+   * @throws IllegalArgumentException when:
+   *    <ul>
+   *    <li>the input stream does not have a {@link CharTermAttribute}, or
+   *    <li>there is a fragment token ({@link TokenType#FRAGMENT}) without an associated label ({@link TokenType#LABEL}), or
+   *    <li>there are more than {@link #numFragmentStreams}-1 next fragment tokens ({@link TokenType#NEXT_FRAGMENT}) for any label, or
+   *    <li>there is any label end token ({@link TokenType#END_LABEL} (for this use a {@link LabeledTreeFragmentsAnalyzer}.)
+   *    </ul>
+   */
+  public void consumeInputStream() throws IOException {
+    clear(); // any pending output
+
+    // split the stream into labels and fragment streams and build the fragment start/end positions in the fragment streams
+    labeledFragments.reset(); // start TokenStream consumption
+
+    boolean someLabelsEnded = false;
+    int numOpenLabels = 0;
+
+    // for checking input syntax:
+    boolean allLabelsEnded = false;
+    boolean lastTokenEndLabel = true;
+
+    CharTermAttribute labeledFragmentsTermAttr = null;
+    if (! labeledFragments.hasAttribute(CharTermAttribute.class)) {
+      throw new IllegalArgumentException("labeledFragments must have CharTermAttribute");
+    }
+    labeledFragmentsTermAttr = labeledFragments.getAttribute(CharTermAttribute.class);
+
+    PositionIncrementAttribute labeledFragmentsPosIncrAttr = null;
+    if (labeledFragments.hasAttribute(PositionIncrementAttribute.class)) {
+      labeledFragmentsPosIncrAttr = labeledFragments.getAttribute(PositionIncrementAttribute.class);
+    }
+
+    currentFragmentStream = 0;
+    currentFPSB = fpsBuilders.get(currentFragmentStream);
+
+    while (labeledFragments.incrementToken()) { // do the split.
+      // CHECKME: the implementation for a position increment attribute on labeledFragments could be separated.
+      String termText = labeledFragmentsTermAttr.toString();
+
+      switch (inputSplitter.tokenType(termText)) {
+
+      case LABEL:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("label token after all labels ended: " + termText);
+        }
+        numOpenLabels++;
+        lastTokenEndLabel = false;
+        buildLabel(termText);
+        labelStream.addState(labeledFragments.captureState());
+        break;
+
+      case FRAGMENT:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("fragment token after all labels ended: " + termText);
+        }
+        if (lastTokenEndLabel) { // this might be allowed, but it would require a special query to retrieve
+          throw new IllegalArgumentException("fragment token without open label: " + termText);
+        }
+        if (labeledFragmentsPosIncrAttr == null) {
+          currentFPSB.incrementFragmentsSize(); // default position increment
+        } else {
+          int posIncr = labeledFragmentsPosIncrAttr.getPositionIncrement();
+          currentFPSB.incrementFragmentsSize(posIncr);
+        }
+        currentFPSB.addTokenState(labeledFragments);
+        break;
+
+      case NEXT_FRAGMENT:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("next fragment token after all labels ended: " + termText);
+        }
+        if (lastTokenEndLabel) { // this might be allowed, but it would require a special query to retrieve
+          throw new IllegalArgumentException("next fragment token without open label: " + termText);
+        }
+        currentFragmentStream++; // continue for next stream
+        if (currentFragmentStream >= fpsBuilders.size()) {
+          throw new IllegalArgumentException("too many next fragment stream tokens for a single label");
+        }
+        currentFPSB = fpsBuilders.get(currentFragmentStream);
+        break;
+
+      case END_LABEL:
+        if (allLabelsEnded) {
+          throw new IllegalArgumentException("end label token after all labels ended: " + termText);
+        }
+        numOpenLabels--;
+        if (numOpenLabels == 0) {
+          allLabelsEnded = true;
+        }
+        lastTokenEndLabel = true;
+        someLabelsEnded = true;
+        buildEndLabel();
+        break;
+
+      default:
+        throw new IllegalStateException("unknown token type: " + termText);
+      }
+    }
+
+    if (someLabelsEnded && (numOpenLabels > 0)) {
+      throw new IllegalArgumentException("labels not ended: " + numOpenLabels);
+    }
+    for (FragmentPositionsStreamBuilder fpsb: fpsBuilders) {
+      fpsb.addSizeAsPosition(); // final end positions
+    }
+
+    labeledFragments.end();
+    labeledFragments.close();
+  }
+
+
+  void buildLabel(String termText) {
+    for (FragmentPositionsStreamBuilder fpsb: fpsBuilders) {
+      fpsb.addSizeAsPosition(); // start positions of all fragments for new label
+    }
+    currentFragmentStream = 0; // first fragment stream
+    currentFPSB = fpsBuilders.get(currentFragmentStream);
+  }
+
+  void buildEndLabel() {
+    throw new IllegalArgumentException(getClass().getName() + " input should not contain end label token");
+  }
+
+  private void clear() {
+    labelStream = new PrefillTokenStream(labeledFragments); // replace, do not close, may still be indexed.
+    for (int i = 0; i < numFragmentStreams; i++) {
+      fpsBuilders.get(i).clear();
+    }
+  }
+
+  /** Provide the label stream from the last input stream */
+  public TokenStream labelTokenStream() {
+    if (labelStream == null) {
+      throw new IllegalStateException("no input stream given");
+    }
+    return labelStream;
+  }
+
+  /** The number of fragment streams that can be provided. */
+  public int numFragmentStreams() {
+    return numFragmentStreams;
+  }
+
+  /** Provide the fragment stream from the last input stream as indicated by the given number.
+   * Fragment streams are numbered from 0.
+   */
+  public TokenStream fragmentsTokenStream(int streamNum) {
+    return checkFpsbAvailable(streamNum).fragmentsTokenStream();
+  }
+
+  /** Provide the fragment positions stream from the last input stream as indicated by the given output stream number.
+   * Fragment streams are numbered from 0.
+   * The returned stream will have a single term with a payload for the fragment positions
+   * when the corresponding fragment stream contains at least one non empty fragment.
+   */
+  public TokenStream fragmentPositionsTokenStream(int streamNum, String termText) {
+    return checkFpsbAvailable(streamNum).fragmentPositionsTokenStream(termText);
+  }
+
+  private FragmentPositionsStreamBuilder checkFpsbAvailable(int streamNum) {
+    FragmentPositionsStreamBuilder res = fpsBuilders.get(streamNum);
+    if (res == null) {
+      throw new IllegalStateException("no input stream given or streamNum not available: " + streamNum);
+    }
+    return res;
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/LabeledTreeFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,146 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.AttributeSource;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType; // for javadocs
+import org.apache.lucene.search.spans.label.LabeledTreeQuery; // for javadocs
+
+
+/** A subclass of {@link LabeledFragmentsAnalyzer} that also provides labels in a tree stream,
+ * to be searched by subclasses of {@link LabeledTreeQuery} after indexing.
+ * For example, using an ending colon to denote a label token, and a double semicolon ;; to denote an end label token,
+ * this input stream:
+ * <pre>
+ *
+ * A:  B: ;;  C: ;;  ;;
+ * </pre>
+ * will produce this label tree stream:
+ * <pre>
+ *
+ *      A:
+ *      | \
+ *      B: C:
+ * </pre>
+ * with root A: at position 0, children B: and C: at positions 1 and 2,
+ * and a token with a payload containing information about the tree structure.
+ * Subclasses of {@link org.apache.lucene.search.spans.label.LabeledTreeQuery} can use this label tree.
+ * <p>
+ * Text fragment streams can be embedded directly after each label.
+ * For example, using a double bar || as the next fragment
+ * stream token and showing the label end tokens ;; below their corresponding labels:
+ * <pre>
+ * A:     a1 || a2
+ *    B:  b1 ||
+ *    ;;
+ *    C:     || c1
+ *    ;;
+ * ;;
+ * </pre>
+ * See {@link LabeledFragmentsAnalyzer} for such fragments.
+ * <p>
+ * In the current implementation the payload with the label tree information
+ * consists of an array that is indexed by the (preorder) label positions.
+ * Each array element consist of a pair <code>(parentPosition, numberOfDescendants)</code>
+ * that is encoded in <code>2*(ceil(2log(#labels-1))</code> bits.
+ * <br>For each document, the number of labels is the position of the tree information payload term in the label field.
+ * When there is only one label, no payload is stored.
+ *
+ * @lucene.experimental
+ */
+public class LabeledTreeFragmentsAnalyzer extends LabeledFragmentsAnalyzer {
+
+  private final String treeInfoPayloadTerm;
+  private LabelTreeInfoBuilder labelTreeInfoBuilder;
+
+  /** A splitter to split labeled fragment streams into nested labels and into fragments for fragment fields.
+   * @param inputSplitter   The split will be based on {@link LabeledFragmentsAnalyzer.InputSplitter#tokenType}.
+   * @param numFragmentStreams     The number of fragment streams. When no tokens occur for a fragment stream
+   *                               no fragment positions will be provided for that stream.
+   * @param treeInfoPayloadTerm    The term added in the {@link #labelTokenStream()} after the last label wich will contain
+   *                               the payload with the label tree info.
+   */
+  public LabeledTreeFragmentsAnalyzer(TokenStream labeledFragments, InputSplitter inputSplitter, int numFragmentStreams, String treeInfoPayloadTerm) {
+    super(labeledFragments, inputSplitter, numFragmentStreams);
+    this.treeInfoPayloadTerm = Objects.requireNonNull(treeInfoPayloadTerm, "treeInfoPayloadTerm");
+    this.labelTreeInfoBuilder = new LabelTreeInfoBuilder();
+  }
+
+  /** Start an input stream.
+   * In addition to {@link LabeledFragmentsAnalyzer#consumeInputStream} this builds the label tree info and adds it to the
+   * {@link LabeledFragmentsAnalyzer#labelStream}.
+   * <br>The position increments of end label tokens ({@link TokenType#END_LABEL}) are ignored.
+   * @throws IllegalArgumentException when:
+   * <ul>
+   * <li>the input stream does not have a {@link CharTermAttribute}, or
+   * <li>there is a fragment token ({@link TokenType#FRAGMENT}) without an associated label ({@link TokenType#LABEL}), or
+   * <li>there are more than <code>numFragmentStreams-1</code> next fragment tokens ({@link TokenType#NEXT_FRAGMENT}) for any label, or
+   * <li>any label equals the <code>treeInfoPayloadTerm</code>, or
+   * <li>not all label tokens have a corresponding end label token ({@link TokenType#END_LABEL}), or
+   * <li>there is any token after the end label token of the first label.
+   * </ul>
+   */
+  @Override
+  public void consumeInputStream() throws IOException {
+    labelTreeInfoBuilder.reInit();
+    super.consumeInputStream();
+  }
+
+  @Override
+  void buildLabel(String termText) {
+    if (termText.equals(treeInfoPayloadTerm)) {
+      throw new IllegalArgumentException("label term is tree info payload term: " + termText);
+    }
+    super.buildLabel(termText);
+    labelTreeInfoBuilder.pushLabel();
+  }
+
+
+  @Override
+  void buildEndLabel() {
+    labelTreeInfoBuilder.popLabel();
+    if (! labelTreeInfoBuilder.isEmptyStack()) {
+      return; // not all labels seen, no output token
+    }
+
+    CharTermAttribute termAtt = labeledFragments.getAttribute(CharTermAttribute.class); // IAE when not there, must be there.
+    termAtt.setEmpty();
+    termAtt.append(treeInfoPayloadTerm); // change char attribute to treeInfoPayloadTerm
+
+    BytesRef payload = labelTreeInfoBuilder.treeInfoBytesRef();
+    labelTreeInfoBuilder.close();
+    if (payload != null) {
+      PayloadAttribute payloadAtt = labeledFragments.addAttribute(PayloadAttribute.class); // might not be there on input
+      payloadAtt.setPayload(payload);
+    } // else only a root, put the treeInfoPayloadTerm in the label stream without payload.
+    labelStream.addState(labeledFragments.captureState());
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/analysis/label/XmlLabeledTreeFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/XmlLabeledTreeFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/XmlLabeledTreeFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,649 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.TreeMap;
+import java.util.HashMap;
+import java.util.Objects;
+
+import javax.xml.namespace.QName;
+import javax.xml.stream.XMLInputFactory;
+import javax.xml.stream.XMLEventReader;
+import javax.xml.stream.XMLStreamException;
+import javax.xml.stream.XMLStreamConstants;
+import javax.xml.stream.Location;
+import javax.xml.stream.events.XMLEvent;
+import javax.xml.stream.events.StartElement;
+import javax.xml.stream.events.Characters;
+
+//use complete name of javax.xml.stream.events.Attribute
+//use complete name of org.apache.lucene.util.Attribute
+
+import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.BytesRef;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+
+import org.apache.lucene.analysis.sinks.PrefillTokenStream;
+
+/** Transform an {@link XMLEventReader} into
+ * one {@link TokenStream} for the XML tags with the hierarchical element structure,
+ * two {@code TokenStream}s for the XML attribute names and values, and
+ * one ore more {@code TokenStream}s for the XML element texts, and
+ * transform the XML structure into fragment positions between the streams.
+ * A fragment is a possibly empty series of tokens in a fragment stream.
+ * <p>
+ * The output {@code TokenStream}s can be used for indexing in the same way as the output streams of
+ * a {@link LabeledTreeFragmentsAnalyzer}.
+ * <br>After indexing, the XML tags that are used as labels, their attributes names and values,
+ * and their text tokens can be searched by
+ * subclasses of {@link org.apache.lucene.search.spans.label.LabeledTreeQuery}.
+ * <p>
+ * The XML element tags are used either as fragment labels or as text stream redirectors.
+ * The text stream redirecting tags can be provided by the user, the first given one will be used by default.
+ * For each of these redirecting tags a fragment {@code TokenStream} is provided.
+ * This text stream redirection allows to put the XML element texts into a separate field for each redirecting tag.
+ * <p>
+ * When text redirecting tags are provided, each XML element text is tokenized into
+ * a fragment stream associated with the latest enclosing redirecting tag,
+ * or into the default text fragment stream.
+ * The tokenizers for these element texts need to be provided.
+ * <br>The XML attributes of XML elements with text stream redirecting tags are ignored.
+ * XML element tags that are not text stream redicting tags are used as label tags.
+ * <p>
+ * For each XML element with a label tag, the tag is used as a label in a label tree stream, and
+ * the tree structure of the XML elements with label tags is provided in a label tree info payload.
+ * <p>
+ * For each XML element with a label tag, the specified attributes are sorted by their qualified names.
+ * The attribute names are added to a dedicated fragment stream as single tokens,
+ * and the attribute values are added to another dedicated fragment stream as single tokens.
+ * <br>The attribute names and values have the same fragment position because they are both used as single tokens.
+ * The attribute fragment position is added to the positions encoded in a payload in a dedicated fragment positions stream.
+ * The attributes names and values can be searched by {@link org.apache.lucene.search.spans.FieldMaskingSpanQuery}.
+ * <p>
+ * All element texts occurring after a nested XML element with a label tag are given a special label.
+ * <p>
+ * Some limitations to be considered before using this class:
+ * <br>- The first XML element must have not a have a text redirecting tag.
+ * <br>- Tokenizing XML attribute values is not supported.
+ *       XML attribute values consisting of multiple tokens may be transformed into element texts
+ *       with the element tag as the original attribute name.
+ * <br>- For the underlying XML parser, the attributes of an XML element are fundamentally unordered.
+ * Therefore in the parsed XML the specified attributes may not be in the same order as in the input XML.
+ * To improve consistency the specified attributes are sorted at each XML element before generating the output streams.
+ * <br>- Repetitive XML elements with text that consists of a single token may be transformed into attributes.
+ * <br>- When an attribute name without an attribute value is needed at a label,
+ *       a token stream with a single token per label tag can be used instead.
+ * <br>- XML markup inside a single {@link Token} is not supported.
+ * <p>
+ * The following example illustrates
+ * <br>- attribute parsing for the label tags <code>kiosk</code> and <code>newspaper</code>,
+ * <br>- text redirection for the <code>editor</code> and <code>title</code> tags,
+ * <br>- the default text token stream for <code>some more text</code>, and
+ * <br>- a special label inserted for <code>more text</code> after a nested XML element.
+ * <pre>
+ * &lt;kiosk&gt;
+ *   some
+ *   &lt;newspaper counter="42"&gt;
+ *     &lt;editor&gt;J. More&lt;/editor&gt;
+ *     &lt;title&gt;Greatest&lt;/title&gt;
+ *   &lt;/newspaper&gt;
+ *   more text
+ *   &lt;newspaper counter="43"&gt;
+ *     &lt;editor&gt;C. Less&lt;/editor&gt;
+ *     &lt;title&gt;Early Morning&lt;/title&gt;
+ *   &lt;/newspaper&gt;
+ * &lt;/kiosk&gt;
+ * </pre>
+ * When the parser is provided with:
+ * <br>- text stream tags <code>["txt", "editor", "title"]</code>, <code>"txt"</code> is the default as the first one,
+ * <br>- white space text tokenizers for the text stream tags,
+ * <br>- <code>"after"</code> as the label to be used for text after a nested XML element
+ *       (just before "more text" above),
+ * <br>- <code>"treeInfo"</code> as the token for the tree info payload, and
+ * <br>- <code>"fragPos"</code> as the token for each fragment positions payload,
+ * <br>the following streams will be available after parsing by <code>consumeXmlEventReader()</code>:
+ *
+ * <table border="1" summary="Token streams from XMLAnalyzer">
+ * <tr>
+ *   <td>made by</td>
+ *   <td>tokens (payload)</td>
+ * </tr>
+ * <tr>
+ *     <td> <code>labelTokenStream()</code></td>
+ *     <td> <code>"kiosk" "newspaper" "after" "newspaper" "treeInfo"(0,3, 0,0, 0,0, 0,0)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrNameFragmentsTokenStream()</code>
+ *     <td> <code>"counter" "counter"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrValueFragmentsTokenStream()</code>
+ *     <td> <code>"42" "43"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>attrFragmentPositionsTokenStream("fragPos")</code>
+ *     <td> <code>"fragPos"(0, 0, 1, 1, 2)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("txt")</code>
+ *     <td> <code>"some" "more" "text"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("txt", "fragPos")</code></td>
+ *     <td> <code>"fragPos"(0, 1, 1, 3, 3)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("editor")</code>
+ *     <td> <code>"J." "More" "C." "Less"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("editor", "fragPos")</code></td>
+ *     <td> <code>"fragPos"(0, 0, 2, 2, 4)</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentsStream("title")</code></td>
+ *     <td> <code>"Greatest" "Early" "Morning"</code></td>
+ * </tr>
+ * <tr>
+ *     <td> <code>textFragmentPositionsStream("title", "fragPos")</code></td>
+ *     <td> <code>"fragPos"(0, 0, 1, 1, 3)</code></td>
+ * </tr>
+ * </table>
+ * <p>For the tree info payload see {@link LabeledTreeFragmentsAnalyzer}.
+ * <br>For fragment positions payload see {@link LabeledFragmentsAnalyzer}.
+ *
+ * @lucene.experimental
+ */
+public class XmlLabeledTreeFragmentsAnalyzer {
+
+  public interface TextTokenizers {
+    /** Tokenizer to provide fragment tokens from XML element text. */
+    public Tokenizer textTokenizer(String textStreamTag);
+  }
+
+  private TextTokenizers textTokenizers;
+  private String fragmentLabelAfterNestedElement;
+
+  private LabelTreeInfoBuilder labelTreeInfoBuilder;
+  private PrefillTokenStream labelStream;
+  private AttributeSource labelAttributes;
+  private CharTermAttribute labelCharTermAttribute;
+  private PayloadAttribute labelPayloadAttribute;
+  private OffsetAttribute labelOffsetAttribute;
+  private final String labelTreeInfoPayloadTerm;
+
+  private FragmentPositionsStreamBuilder attrNameFPSB;
+  private PrefillTokenStream attrValueStream;
+
+  // for xml attribute name and value streams:
+  private AttributeSource xmlAttributeStreamsTokenAttributes;
+  private CharTermAttribute xmlAttributeStreamsCharTermAttribute;
+  private OffsetAttribute xmlAttributeStreamsOffsetAttribute;
+  // for text streams:
+  private List<String> textStreamTags;
+  private HashMap<String,TextFragmentsBuilder> textFragmentsBuilderByTag;
+  private TextFragmentsBuilder defaultTextFragmentsBuilder;
+  /** Construct an XmlAnalyzer.
+   * @param textStreamTags The tags of XML elements to be used for redirecting text to fragment streams.
+   *                       These tags should all be different. The first one is used as the default.
+   *                       The top level XML element should have a different tag.
+   *                       <br>When this is empty or null, no XML text elements will be tokenized.
+   * @param textTokenizers Provides the text tokenizers.
+   * @param labelTreeInfoPayloadTerm The term to contain the label tree info as payload.
+   */
+  public XmlLabeledTreeFragmentsAnalyzer(
+        List<String> textStreamTags,
+        TextTokenizers textTokenizers,
+        String fragmentLabelAfterNestedElement,
+        String labelTreeInfoPayloadTerm) {
+    this.textStreamTags = Objects.requireNonNull(textStreamTags, "textStreamTags");
+    this.textTokenizers = Objects.requireNonNull(textTokenizers, "textTokenizers");
+    this.fragmentLabelAfterNestedElement = Objects.requireNonNull(fragmentLabelAfterNestedElement, "fragmentLabelAfterNestedElement");
+    this.labelTreeInfoPayloadTerm = Objects.requireNonNull(labelTreeInfoPayloadTerm, "labelTreeInfoPayloadTerm");
+
+    this.labelAttributes = new AttributeSource(Token.TOKEN_ATTRIBUTE_FACTORY);
+    this.labelCharTermAttribute = labelAttributes.addAttribute(CharTermAttribute.class);
+    this.labelOffsetAttribute = labelAttributes.addAttribute(OffsetAttribute.class);
+    this.labelPayloadAttribute = labelAttributes.addAttribute(PayloadAttribute.class);
+    this.labelStream = new PrefillTokenStream(labelAttributes);
+
+    this.labelTreeInfoBuilder = new LabelTreeInfoBuilder();
+
+    this.xmlAttributeStreamsTokenAttributes = new AttributeSource(Token.TOKEN_ATTRIBUTE_FACTORY);
+    this.xmlAttributeStreamsCharTermAttribute = xmlAttributeStreamsTokenAttributes.addAttribute(CharTermAttribute.class);
+    this.xmlAttributeStreamsOffsetAttribute = xmlAttributeStreamsTokenAttributes.addAttribute(OffsetAttribute.class);
+
+    this.attrNameFPSB = new FragmentPositionsStreamBuilder(xmlAttributeStreamsTokenAttributes);
+    this.attrValueStream = new PrefillTokenStream(xmlAttributeStreamsTokenAttributes); // same positions as attribute names
+
+    this.textFragmentsBuilderByTag = new HashMap<>();
+    this.defaultTextFragmentsBuilder = null;
+    if (this.textStreamTags != null) {
+      for (String tag: this.textStreamTags) {
+        if (this.textFragmentsBuilderByTag.get(tag) != null) {
+          throw new IllegalArgumentException("text stream redirecting tag occurs more than once: " + tag);
+        }
+        this.textFragmentsBuilderByTag.put(tag, new TextFragmentsBuilder(textTokenizers.textTokenizer(tag)));
+      }
+      if (! textStreamTags.isEmpty()) {
+        this.defaultTextFragmentsBuilder = textFragmentsBuilderByTag.get(textStreamTags.get(0));
+      }
+    }
+  }
+
+  /** Consume an XMLEventReader as input.
+   * After this, when no exception is thrown,
+   * {@link #labelTokenStream},
+   * {@link #attrNameFragmentsTokenStream},
+   * {@link #attrValueFragmentsTokenStream},
+   * {@link #attrFragmentPositionsTokenStream},
+   * {@link #textFragmentsStream} and
+   * {@link #textFragmentPositionsStream}
+   * will provide token streams for the parsed XML.
+   * @param xmlEventReader    Provides XML as parsing events. All available events are read.
+   *                          <br>The {@link XMLStreamConstants#START_ELEMENT}
+   *                          and {@link XMLStreamConstants#END_ELEMENT} events are used to provide the labels
+   *                          from the tag names, except for tags present in <code>textStreamTags</code>
+   *                          passed to the constructor.
+   *                          <br>The attributes specified at the element are taken from the XML start element events,
+   *                          {@link XMLStreamConstants#ATTRIBUTE} events should not occur.
+   *                          <br>{@link XMLStreamConstants#CHARACTERS} events should be coalesced.
+   *                          When some of these characters are non white space they are tokenized into text fragments.
+   *                          <br>The following events the are ignored:
+   *                           {@link XMLStreamConstants#COMMENT},
+   *                           {@link XMLStreamConstants#PROCESSING_INSTRUCTION},
+   *                           {@link XMLStreamConstants#START_DOCUMENT},
+   *                           {@link XMLStreamConstants#END_DOCUMENT},
+   *                           {@link XMLStreamConstants#NAMESPACE},
+   *                           {@link XMLStreamConstants#DTD}.
+   * @param initialOffset     The initial character offset. This is added to the XML location and set in the
+   *                          provided token streams where possible, except in the fragment positions streams.
+   * @throws IOException from a provided text tokenizer.
+   * @throws XMLStreamException from the <code>xmlEventReader</code>.
+   * @throws IllegalArgumentException when the <code>xmlEventReader</code> does not coalesce its elements texts.
+   */
+  public void consumeXmlEventReader(XMLEventReader xmlEventReader, int initialOffset)
+  throws IOException, XMLStreamException {
+    if (! Boolean.TRUE.equals(xmlEventReader.getProperty(XMLInputFactory.IS_COALESCING))) {
+      throw new IllegalArgumentException("xmlEventReader should be coalescing its element texts");
+    }
+    clear(); // any pending output.
+    iterateXmlEvents(xmlEventReader, initialOffset);
+  }
+
+  /** Consume an XMLEventReader as input.
+   * Works as {@link #consumeXmlEventReader(XMLEventReader,int)} with 0 initial offset.
+   */
+  public void consumeXmlEventReader(XMLEventReader xmlEventReader)
+  throws IOException, XMLStreamException {
+    consumeXmlEventReader(xmlEventReader, 0);
+  }
+
+  /** Release all resources built for the consumed input. */
+  private void clear() {
+    labelStream = new PrefillTokenStream(labelAttributes); // replace, do not close, may still be indexed.
+    labelTreeInfoBuilder.reInit();
+    attrNameFPSB.clear();
+    attrValueStream = new PrefillTokenStream(xmlAttributeStreamsTokenAttributes); // replace, do not close, may still be indexed.
+    if (textStreamTags != null) {
+      for (String tag: textStreamTags) {
+        TextFragmentsBuilder tfb = textFragmentsBuilderByTag.get(tag);
+        if (tfb != null) {
+          tfb.clear();
+        }
+      }
+    }
+  }
+
+
+  /** Make the label token stream from the tags of the XML elements that are not used to redirect text to fragment streams.
+   * This stream also contains the label tree info payload for the tree structure of these XML elements.
+   */
+  public TokenStream labelTokenStream() {
+    return labelStream;
+  }
+
+  /** Make the token stream for the XML attribute names. */
+  public TokenStream attrNameFragmentsTokenStream() {
+    return attrNameFPSB.fragmentsTokenStream();
+  }
+
+  /** Make the token stream for the XML attribute values. */
+  public TokenStream attrValueFragmentsTokenStream() {
+    return attrValueStream;
+  }
+
+  /** Make the token stream containing the XML attribute fragment positions payload. */
+  public TokenStream attrFragmentPositionsTokenStream(String fragmentPositionsTerm) {
+    return attrNameFPSB.fragmentPositionsTokenStream(fragmentPositionsTerm);
+  }
+
+  /** Make the token stream containing the tokenized XML element texts for the given text stream tag. */
+  public TokenStream textFragmentsStream(String textStreamTag) {
+    return textFragmentsBuilderByTag.get(textStreamTag).fragmentsTokenStream();
+  }
+
+  /** Make the token stream containing the payload for the fragment positions of the XML element text tokens
+   * for the given text stream tag.
+   */
+  public TokenStream textFragmentPositionsStream(String textStreamTag, String fragmentPositionsTerm) {
+    return textFragmentsBuilderByTag.get(textStreamTag).fragmentPositionsTokenStream(fragmentPositionsTerm);
+  }
+
+  private void iterateXmlEvents(XMLEventReader xmlEventReader, int initialOffset) throws IOException, XMLStreamException {
+    labelPayloadAttribute.setPayload(null); // only needed at end of label stream
+
+    elementAttrValueByName = new TreeMap<>(); // avoid reallocation for each tag.
+
+    class LevelInfo {
+      String tag;
+      boolean tagIsLabel; // otherwise the tag redirects text.
+      int previousLabelLevel;
+      boolean tagIsOpenAsLabel;
+      boolean labelAfterNestedElementOpen;
+      TextFragmentsBuilder tfb;
+    }
+    ArrayList<LevelInfo> levelInfos = new ArrayList<>();
+    int currentLevel = -1;
+    LevelInfo currentLevelInfo = null;
+
+    Location xmlLocation = null;
+    int lastCharacterOffset = initialOffset;
+    int prevCharacterOffset = initialOffset;
+    while (xmlEventReader.hasNext()) {
+      XMLEvent xmlEvent = xmlEventReader.nextEvent();
+      int eventType = xmlEvent.getEventType();
+
+      xmlLocation = xmlEvent.getLocation();
+      int curOffset = xmlLocation.getCharacterOffset(); // end position of last XML event, but -1 for ENDDOCUMENT event
+      if (curOffset >= 0) {
+        prevCharacterOffset = lastCharacterOffset;
+        lastCharacterOffset = curOffset + initialOffset;
+      }
+
+      switch (eventType) {
+
+      case XMLStreamConstants.START_ELEMENT:
+
+        StartElement startElement = xmlEvent.asStartElement();
+        QName qualifiedTagName = startElement.getName();
+        String tag = qualifiedTagName.getLocalPart();
+        TextFragmentsBuilder nextTextFragmentsBuilder = textFragmentsBuilderByTag.get(tag);
+
+        if (nextTextFragmentsBuilder == null) { // use the tag as a label
+          if (currentLevelInfo != null) {
+            if (currentLevelInfo.labelAfterNestedElementOpen) {
+              popLabel();
+              currentLevelInfo.labelAfterNestedElementOpen = false; // may be opened again.
+            }
+          }
+        }
+
+        int prevLabelLevel = (currentLevel < 0) ? -1
+                            : currentLevelInfo.tagIsLabel ? currentLevel
+                            : currentLevelInfo.previousLabelLevel;
+
+        TextFragmentsBuilder prevTextFragmentsBuilder = (currentLevel < 0) ? defaultTextFragmentsBuilder : currentLevelInfo.tfb;
+
+        currentLevel++;
+        if (levelInfos.size() <= currentLevel) {
+          levelInfos.add(new LevelInfo());
+        }
+        currentLevelInfo = levelInfos.get(currentLevel);
+        currentLevelInfo.tag = tag;
+
+        if (nextTextFragmentsBuilder == null) { // use the tag as a label
+          pushLabel(tag, prevCharacterOffset, lastCharacterOffset);
+          currentLevelInfo.tagIsLabel = true;
+          currentLevelInfo.previousLabelLevel = prevLabelLevel;
+          currentLevelInfo.tagIsOpenAsLabel = true;
+          currentLevelInfo.labelAfterNestedElementOpen = false;
+          currentLevelInfo.tfb = prevTextFragmentsBuilder;
+          if (currentLevelInfo.previousLabelLevel >= 0) {
+            levelInfos.get(currentLevelInfo.previousLabelLevel).tagIsOpenAsLabel = false;
+          }
+          addAttributes(startElement, prevCharacterOffset, lastCharacterOffset);
+        }
+        else if (currentLevelInfo == null) {
+          throw new IllegalArgumentException("text stream redirecting tag at top level: " + tag);
+        }
+        else { // tag redirects text, ignore attributes.
+          currentLevelInfo.tagIsLabel = false;
+          currentLevelInfo.previousLabelLevel = prevLabelLevel;
+          assert levelInfos.get(currentLevelInfo.previousLabelLevel).tagIsLabel;
+          // new level shares open extra text label:
+          currentLevelInfo.labelAfterNestedElementOpen = levelInfos.get(currentLevel-1).labelAfterNestedElementOpen;
+          currentLevelInfo.tfb = nextTextFragmentsBuilder;
+        }
+        break;
+
+      case XMLStreamConstants.END_ELEMENT:
+
+        if (currentLevelInfo.tagIsLabel) {
+          if (currentLevelInfo.labelAfterNestedElementOpen) {
+            popLabel();
+            currentLevelInfo.labelAfterNestedElementOpen = false;
+          }
+          popLabel();
+          currentLevelInfo.tagIsOpenAsLabel = false;
+        }
+        else { // current tag redirects text
+          if (currentLevelInfo.labelAfterNestedElementOpen) {  // next lower level shares open extra text label
+            levelInfos.get(currentLevel-1).labelAfterNestedElementOpen = true;
+          }
+        }
+
+        currentLevel--;
+        if (currentLevel < 0) {
+          currentLevelInfo = null;
+        }
+        else {
+          currentLevelInfo = levelInfos.get(currentLevel);
+        }
+        break;
+
+      case XMLStreamConstants.CHARACTERS:
+
+        if (currentLevelInfo.tfb == null) { // no text needs to be tokenized
+          break;
+        }
+        Characters characters = xmlEvent.asCharacters(); // coalesced
+        if (characters.isWhiteSpace()) {
+          break;
+        }
+        int labelLevel = currentLevelInfo.tagIsLabel ? currentLevel : currentLevelInfo.previousLabelLevel;
+        if (! levelInfos.get(labelLevel).tagIsOpenAsLabel) {
+          if (! currentLevelInfo.labelAfterNestedElementOpen) {
+            pushLabel(fragmentLabelAfterNestedElement, prevCharacterOffset, prevCharacterOffset);
+            currentLevelInfo.labelAfterNestedElementOpen = true;
+          }
+        }
+        String elementText = characters.getData();
+        currentLevelInfo.tfb.tokenizeToFragmentStream(elementText, prevCharacterOffset);
+        break;
+
+      case XMLStreamConstants.COMMENT:
+      case XMLStreamConstants.PROCESSING_INSTRUCTION:
+      case XMLStreamConstants.START_DOCUMENT:
+      case XMLStreamConstants.END_DOCUMENT:
+      case XMLStreamConstants.NAMESPACE:
+      case XMLStreamConstants.DTD:
+        // ignore
+        break;
+
+      case XMLStreamConstants.ATTRIBUTE: // not used in XML input
+        throw new IllegalArgumentException("Unexpected attribute eventType=" + eventType);
+
+      default:
+        throw new IllegalStateException("Unknown eventType=" + eventType);
+      }
+    }
+
+    if (! labelTreeInfoBuilder.isEmptyStack()) {
+      throw new IllegalArgumentException("not all XML elements ended");
+    }
+
+    // final end positions:
+    attrNameFPSB.addSizeAsPosition();
+    for (TextFragmentsBuilder tfb: textFragmentsBuilderByTag.values()) {
+      tfb.addSizeAsPosition();
+    }
+
+    // final term in label stream with tree info payload
+    labelCharTermAttribute.setEmpty();
+    labelCharTermAttribute.append(labelTreeInfoPayloadTerm);
+    BytesRef payload = labelTreeInfoBuilder.treeInfoBytesRef();
+    labelTreeInfoBuilder.close();
+    if (payload != null) {
+      labelPayloadAttribute.setPayload(payload);
+    } // else only a root, no payload.
+    if (xmlLocation != null) {
+      labelOffsetAttribute.setOffset(lastCharacterOffset, lastCharacterOffset + labelTreeInfoPayloadTerm.length());
+    }
+    labelStream.addState(labelAttributes.captureState());
+  }
+
+  private void pushLabel(String label, int prevCharacterOffset, int lastCharacterOffset) {
+    if (label.equals(labelTreeInfoPayloadTerm)) {
+      throw new IllegalArgumentException("label tree info payload term should not occur as XML tag name " + label);
+    }
+
+    labelCharTermAttribute.setEmpty();
+    labelCharTermAttribute.append(label);
+
+    labelOffsetAttribute.setOffset(prevCharacterOffset, lastCharacterOffset);
+
+    labelStream.addState(labelAttributes.captureState());
+
+    labelTreeInfoBuilder.pushLabel();
+
+    // start positions for new label of attribute name fragment and all text fragments:
+    attrNameFPSB.addSizeAsPosition();
+    for (TextFragmentsBuilder tfb: textFragmentsBuilderByTag.values()) {
+      tfb.addSizeAsPosition();
+    }
+  }
+
+  private void popLabel() {
+    labelTreeInfoBuilder.popLabel();
+  }
+
+  private TreeMap<String,String> elementAttrValueByName;
+
+  private void addAttributes(StartElement startElement, int tagStartOffset, int tagEndOffset) {
+    elementAttrValueByName.clear();
+    Iterator<?> attributes = startElement.getAttributes();
+    while (attributes.hasNext()) {
+      javax.xml.stream.events.Attribute attribute = (javax.xml.stream.events.Attribute) attributes.next();
+      if (attribute.isSpecified()) {
+        QName qualifiedAttrName = attribute.getName();
+        String attrName = qualifiedAttrName.toString();
+        String attrValue = attribute.getValue();
+        elementAttrValueByName.put(attrName, attrValue);
+        // Location attrLocation = attribute.getLocation(); // attrLocation.getCharacterOffset() returns -1, ignore
+      }
+    }
+    if (! elementAttrValueByName.isEmpty()) {
+      xmlAttributeStreamsOffsetAttribute.setOffset(tagStartOffset, tagEndOffset); // best effort, see attrLocation above.
+    }
+    for (String attrName: elementAttrValueByName.keySet()) { // TreeMap sorted by attrName
+      xmlAttributeStreamsCharTermAttribute.setEmpty();
+      xmlAttributeStreamsCharTermAttribute.append(attrName);
+      attrNameFPSB.addTokenState(xmlAttributeStreamsTokenAttributes);
+      attrNameFPSB.incrementFragmentsSize();
+
+      String attrValue = elementAttrValueByName.get(attrName);
+      xmlAttributeStreamsCharTermAttribute.setEmpty();
+      xmlAttributeStreamsCharTermAttribute.append(attrValue);
+      attrValueStream.addState(xmlAttributeStreamsTokenAttributes.captureState());
+    }
+    elementAttrValueByName.clear();
+  }
+
+  private static class TextFragmentsBuilder {
+    final Tokenizer tokenizer;
+    final PositionIncrementAttribute posIncrAttr;
+    final OffsetAttribute offsetAttr;
+
+    FragmentPositionsStreamBuilder fpsb;
+
+    TextFragmentsBuilder(Tokenizer tokenizer) {
+      this.tokenizer = tokenizer;
+      this.fpsb = new FragmentPositionsStreamBuilder(tokenizer);
+
+      if (tokenizer.hasAttribute(PositionIncrementAttribute.class)) {
+        posIncrAttr = tokenizer.getAttribute(PositionIncrementAttribute.class);
+      } else {
+        posIncrAttr = null;
+      }
+      if (tokenizer.hasAttribute(OffsetAttribute.class)) {
+        offsetAttr = tokenizer.getAttribute(OffsetAttribute.class);
+      } else {
+        offsetAttr = null;
+      }
+    }
+
+    TokenStream fragmentsTokenStream() {
+      return fpsb.fragmentsTokenStream();
+    }
+
+    TokenStream fragmentPositionsTokenStream(String fragmentPositionsTerm) {
+      return fpsb.fragmentPositionsTokenStream(fragmentPositionsTerm);
+    }
+
+    void addSizeAsPosition() {
+      fpsb.addSizeAsPosition();
+    }
+
+    void tokenizeToFragmentStream(String elementText, int initialOffset) throws IOException {
+      tokenizer.setReader(new StringReader(elementText));
+      tokenizer.reset();
+      while (tokenizer.incrementToken()) {
+        if (offsetAttr != null) {
+          offsetAttr.setOffset(offsetAttr.startOffset() + initialOffset, offsetAttr.endOffset() + initialOffset);
+        }
+        fpsb.addTokenState(tokenizer);
+        if (posIncrAttr != null) {
+          int posIncr = posIncrAttr.getPositionIncrement();
+          fpsb.incrementFragmentsSize(posIncr);
+        } else {
+          fpsb.incrementFragmentsSize();
+        }
+      }
+      tokenizer.end();
+      tokenizer.close();
+    }
+
+    void clear() {
+      fpsb.clear();
+    }
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/analysis/label/package-info.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/analysis/label/package-info.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/analysis/label/package-info.java	(working copy)
@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Split a labeled fragments stream into token streams for (nested) labels, fragments, and fragment start/end positions.
+ * <p>
+ * For labeled streams with <code>1 : 0..n</code> relationships between label token positions and fragment token positions this is done
+ * by {@link org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer}.
+ * <p>
+ * For labels nested in a tree, with fragments as leafs, this is done by {@link org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer}.
+ * <br>
+ * {@link org.apache.lucene.analysis.label.XmlLabeledTreeFragmentsAnalyzer}
+ * splits an XML parsing event stream consisting of tags, attributes and element texts
+ * into a label tree and various fragment token streams with fragment start/end positions.
+*/
+package org.apache.lucene.analysis.label;
+
Index: lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/document/label/LabelFieldSchema.java	(working copy)
@@ -0,0 +1,107 @@
+package org.apache.lucene.document.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Objects;
+
+import org.apache.lucene.index.Term;
+
+/** A field schema for a Lucene document with a single label field and some fragment fields labeled by the label field.
+ * The labels may form a hierarchy within a document.
+ */
+public class LabelFieldSchema {
+  private String labelFieldName;
+  private String treeInfoPayloadTermText;
+  private ArrayList<String> fragmentFieldNames = new ArrayList<>(0); // in input order.
+  private HashMap<String,Term> positionsPayloadTermByFragmentFieldName = new HashMap<>();
+
+  /** Create a LabelFieldSchema for a label field where the labels do not form a hierarchy within a document.
+   * @param labelFieldName The label field name.
+   */
+  public LabelFieldSchema(String labelFieldName) {
+    this.labelFieldName = Objects.requireNonNull(labelFieldName, "labelFieldName");
+    this.treeInfoPayloadTermText = null;
+  }
+
+  /** Create a LabelFieldSchema for a label field where the labels form a hierarchy within a document.
+   * @param labelFieldName The label field name.
+   * @param treeInfoPayloadTermText The term text for the term in the label field that has a tree info payload.
+   */
+  public LabelFieldSchema(String labelFieldName, String treeInfoPayloadTermText) {
+    this(labelFieldName);
+    this.treeInfoPayloadTermText = Objects.requireNonNull(treeInfoPayloadTermText,"treeInfoPayloadTermText");
+  }
+
+  /** Add a fragment field labeled by the labels in the label field of the same document.
+   * @param fragmentFieldName The fragment field name. Each name can only be added once, should be non null, and should not be equal the label field name.
+   * @param fragmentPositionsPayloadTerm The term that has a payload with the fragment positions for the labels.
+   *                                     This term may be shared between different fragment fields. This should be non null.
+   * @return The unique non negative schema index of the added fragment field.
+   */
+  public int addLabeledFragmentField(String fragmentFieldName, Term fragmentPositionsPayloadTerm) {
+    if (fragmentFieldName == null) {
+      throw new IllegalArgumentException("fragmentFieldName should not be null");
+    }
+    if (fragmentPositionsPayloadTerm == null) {
+      throw new IllegalArgumentException("fragmentPositionsPayloadTerm should not be null");
+    }
+    if (fragmentFieldName.equals(labelFieldName)) {
+      throw new IllegalArgumentException("fragment field should not be same as the label field: " + fragmentFieldName);
+    }
+    if (positionsPayloadTermByFragmentFieldName.containsKey(fragmentFieldName)) {
+      throw new IllegalArgumentException(fragmentFieldName + " can only be labeled once by " + labelFieldName);
+    }
+    int ffi = fragmentFieldNames.size();
+    fragmentFieldNames.add(fragmentFieldName);
+    positionsPayloadTermByFragmentFieldName.put(fragmentFieldName, fragmentPositionsPayloadTerm);
+    return ffi;
+  }
+
+  /** The label field name. */
+  public String getLabelFieldName() {
+    return labelFieldName;
+  }
+
+  /** The term text of the term with the tree info payload, or null. */
+  public String getTreeInfoPayloadTermText() {
+    return treeInfoPayloadTermText;
+  }
+
+  /** The fragment field name for the fragment field at the given schema index. */
+  public String getFragmentFieldName(int ffi) {
+    return fragmentFieldNames.get(ffi);
+  }
+
+  /** The fragment positions payload term for the fragment field at the given schema index. */
+  public Term getFragmentPositionsPayloadTerm(int ffi) {
+    return positionsPayloadTermByFragmentFieldName.get(fragmentFieldNames.get(ffi));
+  }
+
+  /** Returns the non negative fragment field schema index of the given field name when the given field is a fragment field in the schema, otherwise -1. */
+  public int fragmentFieldIndex(String fieldName) {
+    if (! positionsPayloadTermByFragmentFieldName.containsKey(fieldName)) {
+      return -1;
+    }
+    int ffi = fragmentFieldNames.indexOf(fieldName);
+    assert ffi >= 0;
+    return ffi;
+  }
+}
+
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/ChildLabelQuery.java	(working copy)
@@ -0,0 +1,128 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to a child label.
+ *
+ * @lucene.experimental
+ */
+public class ChildLabelQuery extends LabeledTreeQuery {
+  private final int childNum;
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the label Spans of a child label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param childNum            The child number, starting from 0.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed.
+   */
+  public ChildLabelQuery(
+        SpanQuery labelQuery,
+        int childNum,
+        String treeInfoPayloadTerm) {
+    super(labelQuery, treeInfoPayloadTerm);
+    this.childNum = childNum;
+  }
+
+
+  /** The label Spans transformed to a Spans of a child of the labels.
+   * <br>The input start position is transformed the start position of the child.
+   * <br>The end position of the child is 1 after the start position of the child, i.e. the label end is ignored.
+   */
+  @Override
+  Spans makeSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+    return new ChildLabelSpans(payLoadTermEnum, labelSpans);
+  }
+
+  private class ChildLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    ChildLabelSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+      super(payLoadTermEnum, labelSpans);
+    }
+
+    int childNode = TreeInfo.NO_SUCH_NODE;
+    boolean atFirstInCurrentDoc = true;
+
+    @Override
+    boolean twoPhaseCurrentDocMatches() throws IOException {
+      setTreeInfoPayloadForDoc();
+      if (toChildSpan()) {
+        atFirstInCurrentDoc = true;
+        return true;
+      }
+      return false;
+    }
+
+    boolean toChildSpan() throws IOException {
+      int node = spans.nextStartPosition();
+      while (node != NO_MORE_POSITIONS) {
+        childNode = treeInfo.childNode(node, childNum);
+        if (childNode != TreeInfo.NO_SUCH_NODE) {
+          return true;
+        }
+        node = spans.nextStartPosition();
+      }
+      return false;
+    }
+
+    @Override
+    public int nextStartPosition() throws IOException {
+      if (atFirstInCurrentDoc) {
+        atFirstInCurrentDoc = false;
+        return childNode;
+      }
+      if (toChildSpan()) {
+        return childNode;
+      }
+      childNode = NO_MORE_POSITIONS;
+      return NO_MORE_POSITIONS;
+    }
+
+    @Override
+    public int startPosition() {
+      assert (childNode != TreeInfo.NO_SUCH_NODE);
+      return atFirstInCurrentDoc ? -1 : childNode;
+    }
+
+    @Override
+    public int endPosition() {
+      assert (childNode != TreeInfo.NO_SUCH_NODE);
+      return atFirstInCurrentDoc ? -1
+            : childNode == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : childNode + 1;
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (! super.equals(obj)) {
+      return false;
+    }
+    ChildLabelQuery other = (ChildLabelQuery) obj;
+    return childNum == other.childNum;
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode() ^ childNum;
+  }
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/DescendantsLabelQuery.java	(working copy)
@@ -0,0 +1,137 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to a Spans for all descendant labels.
+ *
+ * @lucene.experimental
+ */
+public class DescendantsLabelQuery extends LabeledTreeQuery {
+
+  private final boolean includeLabel;
+
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to a spans for all descendant labels.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   * @param includeLabel        Indicates whether the label itself should be included in the result.
+   *                            In any case the result will only contain spans for which at least one child is available.
+   */
+  public DescendantsLabelQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm,
+        boolean includeLabel) {
+    super(labelQuery, treeInfoPayloadTerm);
+    this.includeLabel = includeLabel;
+  }
+
+
+  /** The label Spans transformed to a Spans a spans for all descendant labels.
+   * <br>The input start position is transformed its first child.
+   * <br>The output end position is taken from the last descendant of the input start position, the input end position is ignored.
+   */
+  @Override
+  Spans makeSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+    return new DescendantsLabelSpans(payLoadTermEnum, labelSpans);
+  }
+
+  private class DescendantsLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    DescendantsLabelSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+      super(payLoadTermEnum, labelSpans);
+    }
+
+    int currentStartNode = TreeInfo.NO_SUCH_NODE;
+    int firstChildNode = TreeInfo.NO_SUCH_NODE;
+    int lastDescendantNode = TreeInfo.NO_SUCH_NODE;
+    boolean atFirstInCurrentDoc = true;
+
+    @Override
+    boolean twoPhaseCurrentDocMatches() throws IOException {
+      setTreeInfoPayloadForDoc();
+      if (toDescendantSpan()) {
+        atFirstInCurrentDoc = true;
+        return true;
+      }
+      return false;
+    }
+
+    boolean toDescendantSpan() throws IOException {
+      currentStartNode = spans.nextStartPosition();
+      while (currentStartNode != NO_MORE_POSITIONS) {
+        int numDesc = treeInfo.numDescendants(currentStartNode);
+        if (numDesc > 0) {
+          firstChildNode = currentStartNode + 1;
+          lastDescendantNode = currentStartNode + numDesc;
+          return true;
+        }
+        currentStartNode = spans.nextStartPosition();
+      }
+      return false;
+    }
+
+    @Override
+    public int nextStartPosition() throws IOException {
+      if (atFirstInCurrentDoc) {
+        atFirstInCurrentDoc = false;
+        return includeLabel ? currentStartNode : firstChildNode;
+      }
+      if (toDescendantSpan()) {
+        return includeLabel ? currentStartNode : firstChildNode;
+      }
+      firstChildNode = NO_MORE_POSITIONS;
+      return NO_MORE_POSITIONS;
+    }
+
+    @Override
+    public int startPosition() {
+      assert (firstChildNode != TreeInfo.NO_SUCH_NODE);
+      return atFirstInCurrentDoc ? -1
+            : includeLabel ? currentStartNode : firstChildNode;
+    }
+
+    @Override
+    public int endPosition() {
+      assert (lastDescendantNode != TreeInfo.NO_SUCH_NODE);
+      return atFirstInCurrentDoc ? -1
+            : currentStartNode == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : lastDescendantNode + 1;
+    }
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (! super.equals(obj)) {
+      return false;
+    }
+    DescendantsLabelQuery other = (DescendantsLabelQuery) obj;
+    return includeLabel == other.includeLabel;
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode() ^ (includeLabel ? Boolean.TRUE.hashCode() : Boolean.FALSE.hashCode());
+  }
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/FragmentToLabelQuery.java	(working copy)
@@ -0,0 +1,111 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.ToStringUtils;
+
+/**
+ * Transform the Spans of a SpanQuery from a fragment field to a label field.
+ * <br>See also {@link LabeledFragmentsQuery}.
+ *
+ * @lucene.experimental
+ */
+public class FragmentToLabelQuery extends LabeledFragmentsQuery {
+  /** Transforms the Spans of a {@link SpanQuery} from a fragment field to a label field.
+   * @param fragmentQuery                Provides the Spans in the fragment field.
+   * @param fragmentPositionsPayloadTerm The term at which the fragment start/end positions are indexed.
+   * @param labelField                   The field to which the fragment spans are transformed.
+   */
+  public FragmentToLabelQuery(
+        SpanQuery fragmentQuery,
+        Term fragmentPositionsPayloadTerm,
+        String labelField) {
+    super(fragmentQuery, fragmentPositionsPayloadTerm, labelField);
+  }
+
+  public SpanQuery getFragmentQuery() {
+    return getSourceQuery();
+  }
+
+
+  /** The fragments Spans transformed to labels.
+   * <br>The start position of each fragment Span is changed to the start position of the associated label.
+   * <br>The end position of each fragment Span is changed to the end position of the associated label.
+   *     For an end position that is within an indexed fragment, the end position of the associated label is used.
+   */
+  @Override
+  Spans makeSpans(PostingsEnum fPosEnum, Spans sourceSpans) throws IOException {
+    return new FragmentToLabelSpans(fPosEnum, sourceSpans);
+  }
+
+  private class FragmentToLabelSpans extends LabeledFragmentsSpans {
+    FragmentToLabelSpans(PostingsEnum fPosEnum, Spans fragmentSpans) throws IOException {
+      super(fPosEnum, fragmentSpans);
+    }
+
+    boolean twoPhaseCurrentDocMatches() throws IOException {
+      getFragmentPositionsPayload();
+      return true;
+    }
+
+    @Override
+    public int nextStartPosition() throws IOException {
+      return labelStartPos(spans.nextStartPosition());
+    }
+
+    @Override
+    public int startPosition() {
+      return labelStartPos(spans.startPosition());
+    }
+
+    private int labelStartPos(int fragStartPos) {
+      return fragStartPos == -1 ? -1
+            : fragStartPos == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : getLabelPosition(fragStartPos);
+    }
+
+    @Override
+    public int endPosition() {
+      int fragEndPos = spans.endPosition();
+      return fragEndPos == -1 ? -1
+            : fragEndPos == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : getLabelPosition(fragEndPos - 1) + 1; // end position of corresponding label.
+    }
+
+  }
+
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("FragmentToLabelQuery( fragmentQuery="); buffer.append(getSourceQuery().toString(field));
+    buffer.append(", labelField="); buffer.append(getTargetField());
+    buffer.append(", fragmentPositionsPayloadTerm="); buffer.append(getFragmentPositionsPayloadTerm().toString());
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/LabelQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/LabelQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/LabelQuery.java	(working copy)
@@ -0,0 +1,202 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Map;
+import java.util.Collection;
+import java.util.Set;
+import java.util.Objects;
+import java.util.ArrayList;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.TermContext;
+
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ConjunctionDISI;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.TwoPhaseIterator;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanWeight;
+
+import org.apache.lucene.util.Bits;
+
+
+/**
+ * Common superclass for queries on labeled fragments or trees
+ * @lucene.experimental
+ */
+abstract class LabelQuery extends SpanQuery {
+  SpanQuery spanQuery;
+  Term payloadTerm;
+
+  LabelQuery(SpanQuery spanQuery, Term payloadTerm) {
+    this.spanQuery = Objects.requireNonNull(spanQuery, "spanQuery");
+    this.payloadTerm = Objects.requireNonNull(payloadTerm, "payloadTerm");
+  }
+
+  @Override
+  public String getField() {
+    return spanQuery.getField();
+  }
+
+  @Override
+  public void extractTerms(Set<Term> terms) {
+    spanQuery.extractTerms(terms);
+    terms.add(payloadTerm);
+  }
+
+  @Override
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    return spanQuery.createWeight(searcher, needsScores);
+  }
+
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    SpanQuery rewrittenSpanQuery = (SpanQuery) spanQuery.rewrite(reader);
+    if (rewrittenSpanQuery == spanQuery) {
+      return this;
+    }
+    LabelQuery clone = (LabelQuery) this.clone();
+    clone.spanQuery = rewrittenSpanQuery;
+    return clone;
+  }
+
+  @Override
+  public Spans getSpans(
+      LeafReaderContext context,
+      Bits acceptDocs, Map<Term,
+      TermContext> termContexts)
+  throws IOException {
+    PostingsEnum payloadTermEnum = context.reader().postings(payloadTerm, PostingsEnum.PAYLOADS);
+    if (payloadTermEnum == null) {
+      return null;
+    }
+    Spans spans = spanQuery.getSpans(context, acceptDocs, termContexts);
+    if (spans == null) {
+      return null;
+    }
+    return makeSpans(payloadTermEnum, spans);
+  }
+
+  abstract Spans makeSpans(PostingsEnum payLoadTermEnum, Spans spans) throws IOException;
+
+  abstract class LabelSpans extends Spans {
+    PostingsEnum payLoadTermEnum;
+    Spans spans;
+    ConjunctionDISI conjunction;
+
+    LabelSpans(PostingsEnum payLoadTermEnum, Spans spans) throws IOException {
+      this.payLoadTermEnum = Objects.requireNonNull(payLoadTermEnum, "payLoadTermEnum");
+      this.spans = Objects.requireNonNull(spans, "spans");
+      ArrayList<DocIdSetIterator> disis = new ArrayList<>();
+      disis.add(payLoadTermEnum);
+      disis.add(spans);
+      this.conjunction = ConjunctionDISI.intersect(disis);
+    }
+
+    @Override
+    public int docID() {
+      return conjunction.docID();
+    }
+
+    @Override
+    public long cost() {
+      return conjunction.cost();
+    }
+
+    @Override
+    public int nextDoc() throws IOException {
+      return (conjunction.nextDoc() == NO_MORE_DOCS)
+              ? NO_MORE_DOCS
+              : toMatchDoc();
+    }
+
+    @Override
+    public int advance(int target) throws IOException {
+      return (conjunction.advance(target) == NO_MORE_DOCS)
+              ? NO_MORE_DOCS
+              : toMatchDoc();
+    }
+
+    private int toMatchDoc() throws IOException {
+      while (true) {
+        if (twoPhaseCurrentDocMatches()) {
+          return docID();
+        }
+        if (conjunction.nextDoc() == NO_MORE_DOCS) {
+          return NO_MORE_DOCS;
+        }
+      }
+    }
+
+    abstract boolean twoPhaseCurrentDocMatches() throws IOException;
+
+    /**
+     * Return a {@link TwoPhaseIterator} view of this LabeledFragmentsSpans.
+     */
+    @Override
+    public TwoPhaseIterator asTwoPhaseIterator() {
+      TwoPhaseIterator res = new TwoPhaseIterator(conjunction) {
+
+        @Override
+        public boolean matches() throws IOException {
+          return twoPhaseCurrentDocMatches();
+        }
+      };
+      return res;
+    }
+
+    @Override
+    public boolean isPayloadAvailable() throws IOException {
+      return spans.isPayloadAvailable();
+    }
+
+    @Override
+    public Collection<byte[]> getPayload() throws IOException {
+      return spans.getPayload();
+    }
+  }
+
+  @Override
+  public String toString(String field) {
+    return "LabelQuery payloadTerm=" + payloadTerm +" spanQuery=" + spanQuery;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (! super.equals(obj)) {
+      return false;
+    }
+    LabelQuery other = (LabelQuery) obj;
+    return payloadTerm.equals(other.payloadTerm)
+        && spanQuery.equals(other.spanQuery);
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode()
+        ^ payloadTerm.hashCode()
+        ^ spanQuery.hashCode();
+  }
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/LabelToFragmentQuery.java	(working copy)
@@ -0,0 +1,138 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.ToStringUtils;
+
+/**
+ * Transform the Spans of a SpanQuery from a label field to a fragment field.
+ * <br>See also {@link LabeledFragmentsQuery}.
+ *
+ * @lucene.experimental
+ */
+public class LabelToFragmentQuery extends LabeledFragmentsQuery {
+
+  /** Transforms the Spans of a {@link SpanQuery} from a label field to a fragment field.
+   * @param labelQuery                   Provides the Spans in the label field.
+   * @param fragmentPositionsPayloadTerm The term at which the fragment start/end positions are indexed.
+   * @param fragmentField                The field to which the label spans are transformed, only non empty fragments are provided.
+   */
+  public LabelToFragmentQuery(
+        SpanQuery labelQuery,
+        Term fragmentPositionsPayloadTerm,
+        String fragmentField) {
+    super(labelQuery, fragmentPositionsPayloadTerm, fragmentField);
+  }
+
+  public SpanQuery getLabelQuery() {
+    return getSourceQuery();
+  }
+
+  /** The label Spans transformed to fragments.
+   * <br>The start position of each label Span is changed to the start position of the associated non empty fragment.
+   * <br>The end position of each label Span is changed to the end position of the associated non empty fragment.
+   */
+  @Override
+  Spans makeSpans(PostingsEnum fPosEnum, Spans sourceSpans) throws IOException {
+    return new LabelToFragmentSpans(fPosEnum, sourceSpans);
+  }
+
+  private class LabelToFragmentSpans extends LabeledFragmentsSpans {
+
+    LabelToFragmentSpans(PostingsEnum fPosEnum, Spans labelSpans) throws IOException {
+      super(fPosEnum, labelSpans);
+    }
+
+    int currentStart = -1;
+    int currentEnd = -1;
+    boolean atFirstInCurrentDoc = true;
+
+    @Override
+    boolean twoPhaseCurrentDocMatches() throws IOException {
+      getFragmentPositionsPayload();
+      return toNonEmptyFragment();
+    }
+
+    private boolean toNonEmptyFragment() throws IOException {
+      assert spans.startPosition() == -1;
+      spans.nextStartPosition();
+      assert spans.startPosition() != NO_MORE_POSITIONS;
+      do {
+        currentStart = getFragmentPosition(spans.startPosition());
+        currentEnd = getFragmentPosition(spans.endPosition()); // This requires that the last fragment end position is available.
+        if (currentStart < currentEnd) {
+          atFirstInCurrentDoc = true;
+          return true;
+        }
+        if (spans.nextStartPosition() == NO_MORE_POSITIONS) {
+          return false;
+        }
+      } while (true);
+    }
+
+    @Override
+    public int nextStartPosition() throws IOException {
+      if (atFirstInCurrentDoc) {
+        atFirstInCurrentDoc = false;
+        return currentStart;
+      }
+      do {
+        if (spans.nextStartPosition() == NO_MORE_POSITIONS) {
+          currentStart = NO_MORE_POSITIONS;
+          currentEnd = NO_MORE_POSITIONS;
+          return NO_MORE_POSITIONS;
+        }
+        currentStart = getFragmentPosition(spans.startPosition());
+        currentEnd = getFragmentPosition(spans.endPosition()); // This requires that the last fragment end position is available.
+        if (currentStart < currentEnd) {
+          return currentStart;
+        }
+      } while (true);
+    }
+
+    @Override
+    public int startPosition() {
+      return atFirstInCurrentDoc ? -1 : currentStart;
+    }
+
+    @Override
+    public int endPosition() {
+      return atFirstInCurrentDoc ? -1 : currentEnd;
+    }
+  }
+
+
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("LabelToFragmentSpanQuery( labelQuery="); buffer.append(getSourceQuery().toString(field));
+    buffer.append(", fragmentField="); buffer.append(getTargetField());
+    buffer.append(", fragmentPositionsPayloadTerm="); buffer.append(getFragmentPositionsPayloadTerm().toString());
+    buffer.append(")");
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledFragmentsQuery.java	(working copy)
@@ -0,0 +1,159 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoDecoder;
+
+/**
+ * Common superclass for queries on labeled fragments
+ * from streams provided by {@link org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer}.
+ * It is assumed that the output fragment token streams for a single labeled fragments input stream
+ * are indexed in one document in different fields.
+ *
+ * @lucene.experimental
+ */
+public abstract class LabeledFragmentsQuery extends LabelQuery { // Public mostly for javadocs
+  private String targetField;
+
+  LabeledFragmentsQuery(
+        SpanQuery sourceQuery,
+        Term fpsPayloadTerm,
+        String targetField) {
+    super(sourceQuery, fpsPayloadTerm);
+    this.targetField = Objects.requireNonNull(targetField, "targetField");
+  }
+
+  SpanQuery getSourceQuery() {
+    return spanQuery;
+  }
+
+  String getTargetField() {
+    return targetField;
+  }
+
+  Term getFragmentPositionsPayloadTerm() {
+    return payloadTerm;
+  }
+
+  /** Return the field in which the spans are made available. */
+  @Override
+  public String getField() {
+    return targetField;
+  }
+
+  abstract Spans makeSpans(PostingsEnum fPosEnum, Spans sourceSpans) throws IOException;
+
+  abstract class LabeledFragmentsSpans extends LabelSpans {
+
+    EliasFanoBytes efBytes = null;
+    EliasFanoDecoder<EliasFanoBytes> efDecoder = null;
+
+    LabeledFragmentsSpans(PostingsEnum fPosEnum, Spans sourceSpans) throws IOException {
+      super(fPosEnum, sourceSpans);
+    }
+
+    private EliasFanoDecoder<EliasFanoBytes> efDecoderForDoc() throws IOException {
+      // get the fragment positions payload for doc
+      int pos = payLoadTermEnum.nextPosition();
+      if (pos != 0) {
+        throw new IOException("fragment positions term at non zero pos=" + pos + " at doc=" + conjunction.docID() + " for term " + payloadTerm);
+      }
+      BytesRef payload = payLoadTermEnum.getPayload();
+      if (payload == null) {
+        throw new IOException("missing fragment positions payload at doc=" + conjunction.docID() +  " for term " + payloadTerm);
+      }
+      // make an Elias-Fano sequence from the payload
+      if (efBytes == null) {
+        efBytes = EliasFanoBytes.createFromBytesRef(payload);
+      } else {
+        efBytes.reInit(payload);
+      }
+      return efBytes.getDecoder(); // initialized to just before the sequence. CHECKME: implement and use efDecoder.reInit(efBytes)
+    }
+
+    void getFragmentPositionsPayload() throws IOException {
+      efDecoder = efDecoderForDoc();
+      long firstValue = efDecoder.nextValue();
+      if (firstValue == EliasFanoDecoder.NO_MORE_VALUES) { // only non empty sequences should be indexed
+        throw new IOException("empty Elias-Fano sequence at docId()=" + docID() +  " for term " + payloadTerm);
+      }
+    }
+
+    int getLabelPosition(int fragmentPosition) {
+      assert fragmentPosition >= 0;
+      assert fragmentPosition != NO_MORE_POSITIONS;
+      long decodingValue = efDecoder.currentValue();
+      if (decodingValue > fragmentPosition) {
+        decodingValue = efDecoder.backToValue(fragmentPosition); // to smaller or equal encoded fragment position
+        assert decodingValue != EliasFanoDecoder.NO_MORE_VALUES : "earlier fragmentPosition " + fragmentPosition + " not available, docID()=" + docID();
+      }
+      if (decodingValue < fragmentPosition) {
+        decodingValue = efDecoder.advanceToValue(fragmentPosition); // to bigger or equal encoded fragment position
+        assert decodingValue != EliasFanoDecoder.NO_MORE_VALUES : "later fragmentPosition " + fragmentPosition + " not available, docID()=" + docID();
+      }
+      long labelPos = efDecoder.currentPosition();
+      assert labelPos != EliasFanoDecoder.NO_MORE_VALUES;
+      return (int) ((decodingValue > fragmentPosition)
+                ? (labelPos-1) // decoder is at next fragment label
+                : labelPos); // decoder is at this fragment label
+    }
+
+    int getFragmentPosition(int labelPosition) {
+      assert labelPosition >= 0;
+      assert labelPosition != NO_MORE_POSITIONS;
+      long decodingPos = efDecoder.currentPosition();
+      if (decodingPos > labelPosition) {
+        efDecoder.toBeforeSequence();
+        boolean ok = efDecoder.advanceToPosition(labelPosition);
+        //CHECKME: instead of toBeforeSequence/advanceToPosition do:  efDecoder.backToPosition(labelPosition);
+        assert ok : "earlier labelPosition " + labelPosition + " not available, docID()=" + docID();
+      } else if (decodingPos < labelPosition) {
+        boolean ok = efDecoder.advanceToPosition(labelPosition);
+        assert ok : "later labelPosition " + labelPosition + " not available, docID()=" + docID();
+      }
+      long fragmentPos = efDecoder.currentValue();
+      assert fragmentPos != EliasFanoDecoder.NO_MORE_VALUES;
+      return (int) fragmentPos;
+    }
+
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (!super.equals(obj)) {
+      return false;
+    }
+    LabeledFragmentsQuery other = (LabeledFragmentsQuery) obj;
+    return targetField.equals(other.targetField);
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode()^ targetField.hashCode();
+  }
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/LabeledTreeQuery.java	(working copy)
@@ -0,0 +1,172 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+import org.apache.lucene.util.BytesRef;
+
+import org.apache.lucene.util.packed.label.LongsInBytes;
+
+/**
+ * Common superclass for queries on labeled trees
+ * as provided by {@link org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer}.
+ * @lucene.experimental
+ */
+public abstract class LabeledTreeQuery extends LabelQuery { // public only for javadocs
+
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the parent label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed
+   *                            as an array of (parent,#descendants) pairs indexable by the label position.
+   */
+  public LabeledTreeQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm) {
+    super(labelQuery, new Term(labelQuery.getField(), treeInfoPayloadTerm));
+  }
+
+  public SpanQuery getLabelQuery() {
+    return spanQuery;
+  }
+
+  abstract class LabeledTreeSpans extends LabelSpans {
+    TreeInfo treeInfo;
+
+    LabeledTreeSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+      super(payLoadTermEnum, labelSpans);
+    }
+
+    void setTreeInfoPayloadForDoc() throws IOException {
+      int numLabels = payLoadTermEnum.nextPosition();
+      BytesRef payload = payLoadTermEnum.getPayload();
+      if (payload == null) {
+        if (numLabels != 1) {
+          throw new IOException("missing tree info payload at docID()=" + docID() +  " for term " + payloadTerm + " numLabels=" + numLabels);
+        } else {
+          treeInfo = ROOT_ONLY;
+        }
+      } else {
+        if ((treeInfo == null) || (treeInfo == ROOT_ONLY)) {
+          treeInfo = new TreeInfo(numLabels, payload); // In case this gets costly, reuse an earlier non ROOT_ONLY treeInfo
+        } else {
+          treeInfo.reInit(numLabels, payload);
+        }
+      }
+    }
+
+  }
+
+  @Override
+  public String toString(String field) {
+    return "LabeledTreeQuery treeInfo payloadTerm=" + payloadTerm +" labelQuery=" + spanQuery;
+  }
+
+  static class TreeInfo {
+    BytesRef bytesRef;
+    int numNodes;
+    int numBits;
+    static final int NO_SUCH_NODE = -1;
+
+    TreeInfo() { // single root constructor
+      numNodes = 1;
+      numBits = 1;
+      bytesRef = null;
+    }
+
+    TreeInfo(int numNodes, BytesRef payload) {
+      reInit(numNodes, payload);
+    }
+
+    void reInit(int numNodes, BytesRef payload) {
+      assert numNodes >= 2;
+      this.numNodes = numNodes;
+      this.bytesRef = payload;
+      this.numBits = Integer.SIZE - Integer.numberOfLeadingZeros(numNodes - 1);
+      assert (bytesRef.offset + (((2*numBits*numNodes + 7)) >> 3)) <= bytesRef.bytes.length : numNodes;
+    }
+
+    int numNodes() {
+      return numNodes;
+    }
+
+    boolean checkNode(int node) {
+      if ((node < 0) || (node >= numNodes)) {
+        throw new ArrayIndexOutOfBoundsException(node);
+      }
+      return true;
+    }
+
+    int parentNode(int node) {
+      assert checkNode(node);
+      return (int) LongsInBytes.unPackValue(numBits, 2*node, bytesRef.bytes, bytesRef.offset);
+    }
+
+    int numDescendants(int node) {
+      assert checkNode(node);
+      return (int) LongsInBytes.unPackValue(numBits, 2*node+1, bytesRef.bytes, bytesRef.offset);
+    }
+
+    int childNode(int node, int childNum) {
+      assert childNum >= 0;
+      int numDesc = numDescendants(node);
+      if (childNum >= numDesc) {
+        return -1;
+      }
+      int childNode = node+1; // first child.
+      assert checkNode(childNode);
+      while (--childNum >= 0) {
+        childNode = nextSibling(childNode);
+        if (childNode == NO_SUCH_NODE) {
+          return NO_SUCH_NODE;
+        }
+      }
+      return childNode;
+    }
+
+    int nextSibling(int node) {
+      int parent = parentNode(node);
+      int nextSib = node + 1 + numDescendants(node);
+      if (nextSib <= parent + numDescendants(parent)) {
+        return nextSib;
+      }
+      return NO_SUCH_NODE;
+    }
+  }
+
+  static final TreeInfo ROOT_ONLY = new TreeInfo() {
+
+    @Override
+    int parentNode(int node) {
+      assert node == 0 : "root only: " + node;
+      return 0;
+    }
+
+    @Override
+    int numDescendants(int node) {
+      assert node == 0 : "root only: " + node;
+      return 0;
+    }
+  };
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/ParentLabelQuery.java	(working copy)
@@ -0,0 +1,89 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanQuery;
+
+/**
+ * Transform the Spans of a SpanQuery in a label field to the parent label.
+ *
+ * @lucene.experimental
+ */
+public class ParentLabelQuery extends LabeledTreeQuery {
+  /** Transforms the Spans of a {@link SpanQuery} in a label field to the parent label.
+   * @param labelQuery          Provides the Spans in the label field.
+   * @param treeInfoPayloadTerm The term in the label field at which the tree nodes info is indexed.
+   */
+  public ParentLabelQuery(
+        SpanQuery labelQuery,
+        String treeInfoPayloadTerm) {
+    super(labelQuery, treeInfoPayloadTerm);
+  }
+
+
+  /** The label Spans transformed to a Spans for the parents of the labels.
+   * <br>The input start position is transformed to its parent.
+   * <br>When the input end position-1 is a descendant of the parent of the start position, it is transformed to the start parent+1.
+   * <br>Otherwise, the input end position is transformed to its parent.
+   */
+  @Override
+  Spans makeSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+    return new ParentLabelSpans(payLoadTermEnum, labelSpans);
+  }
+
+  private class ParentLabelSpans extends LabeledTreeQuery.LabeledTreeSpans {
+    ParentLabelSpans(PostingsEnum payLoadTermEnum, Spans labelSpans) throws IOException {
+      super(payLoadTermEnum, labelSpans);
+    }
+
+    @Override
+    boolean twoPhaseCurrentDocMatches() throws IOException {
+      setTreeInfoPayloadForDoc();
+      return true;
+    }
+
+    private int parentStartPos(int labelStartPos) {
+      return labelStartPos == -1 ? -1
+            : labelStartPos == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : treeInfo.parentNode(labelStartPos);
+    }
+
+    @Override
+    public int nextStartPosition() throws IOException {
+      return parentStartPos(spans.nextStartPosition());
+    }
+
+    @Override
+    public int startPosition() {
+      return parentStartPos(spans.startPosition());
+    }
+
+    @Override
+    public int endPosition() {
+      int labelEndPos = spans.endPosition();
+      return labelEndPos == -1 ? -1
+            : labelEndPos == NO_MORE_POSITIONS ? NO_MORE_POSITIONS
+            : treeInfo.parentNode(labelEndPos-1)+1; // Could check that given end-1 is in descendants of parent start.
+    }
+  }
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/PositionalJoinQueryFactory.java	(working copy)
@@ -0,0 +1,145 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Objects;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+/**
+ * Factory for positional join queries.
+ * This provides queries for positional joins between fragment and label fields, and queries for label tree operations.
+ *
+ * @lucene.experimental
+ */
+public class PositionalJoinQueryFactory {
+  private final LabelFieldSchema fieldSchema;
+
+  /** Create a position join query factory based on a label field schema. */
+  public PositionalJoinQueryFactory(LabelFieldSchema fieldSchema) {
+    this.fieldSchema = Objects.requireNonNull(fieldSchema, "fieldSchema");
+  }
+
+  /** The field schema provided to the constructor. */
+  public LabelFieldSchema getFieldSchema() {
+    return fieldSchema;
+  }
+
+  private String checkTreeInfo(SpanQuery spanQuery) {
+    if (fieldSchema.getTreeInfoPayloadTermText() == null) {
+      throw new IllegalStateException("fieldSchema has no tree info payload term");
+    }
+    if (! fieldSchema.getLabelFieldName().equals(spanQuery.getField())) {
+      throw new IllegalArgumentException("spanQuery field: " + spanQuery.getField() + " is not the label field of the schema: "
+                                          + fieldSchema.getLabelFieldName());
+    }
+    return fieldSchema.getTreeInfoPayloadTermText();
+  }
+
+  /** Transform the spans of a given SpanQuery in the label field of the schema
+   * to the parent label.
+   */
+  public ParentLabelQuery parentLabelQuery(SpanQuery labelQuery) {
+    return new ParentLabelQuery(labelQuery, checkTreeInfo(labelQuery));
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema
+   * to the label of the child with the given number.
+   */
+  public ChildLabelQuery childLabelQuery(SpanQuery labelQuery, int childNum) {
+    return new ChildLabelQuery(labelQuery, childNum, checkTreeInfo(labelQuery));
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema to
+   * a spans containing all descendants of the given label. 
+   */
+  public DescendantsLabelQuery descendantsLabelQuery(SpanQuery labelQuery) {
+    return new DescendantsLabelQuery(labelQuery, checkTreeInfo(labelQuery), false /* not including self */);
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery in the label field of the schema to
+   * a spans containing the given label and all its descendants.
+   */
+  public DescendantsLabelQuery descendantsOrSelfLabelQuery(SpanQuery labelQuery) {
+    return new DescendantsLabelQuery(labelQuery, checkTreeInfo(labelQuery), true /* including self */);
+  }
+
+  /** Provide a query that transforms the spans of a given SpanQuery to a target field with a labeled fragment positions join.
+   * The source field for the join is taken from the given query. The source field and the target field must be in the schema. 
+   * @return The given query is wrapped, when:
+   * <ul>
+   * <li>the source field is the label field of the schema: in a {@link LabelToFragmentQuery},
+   * <li>the target field is the label field of the schema: in a {@link FragmentToLabelQuery},
+   * <li>the source and target fields share their labeled fragment positions: in a {@link FieldMaskingSpanQuery},
+   * <li>the source and target fields do not share their labeled fragment positions: in a {@link FragmentToLabelQuery} wrapping a {@link LabelToFragmentQuery}.
+   * </ul>
+   */
+  public SpanQuery positionalJoin(SpanQuery query, String targetField) {
+    if (query == null) {
+      throw new IllegalArgumentException("query should be non null");
+    }
+    if (targetField == null) {
+      throw new IllegalArgumentException("targetField should be non null");
+    }
+    String sourceField = query.getField();
+    int sourceFFI = -1;
+    int targetFFI = -1;
+    if (! sourceField.equals(fieldSchema.getLabelFieldName())) {
+      sourceFFI = fieldSchema.fragmentFieldIndex(sourceField);
+      if (sourceFFI < 0) {
+        throw new IllegalArgumentException("source field: " + sourceField + " is not a field of the schema");
+      }
+    }
+    if (! targetField.equals(fieldSchema.getLabelFieldName())) {
+      targetFFI = fieldSchema.fragmentFieldIndex(targetField);
+      if (targetFFI < 0) {
+        throw new IllegalArgumentException("targetField: " + targetField + " is not a field of the schema");
+      }
+    }
+    //  sourceField and targetField in fieldSchema, sourceFFI and targetFFI initialized for fragment fields.
+    if (sourceField.equals(targetField)) { // no join needed
+      return query;
+    }
+    if (targetField.equals(fieldSchema.getLabelFieldName())) { // fragment to label
+      assert sourceFFI >= 0;
+      Term sourceFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(sourceFFI);
+      return new FragmentToLabelQuery(query, sourceFpsTerm, targetField);
+    }
+    if (sourceField.equals(fieldSchema.getLabelFieldName())) { // label to fragment
+      assert targetFFI >= 0;
+      Term targetFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(targetFFI);
+      return new LabelToFragmentQuery(query, targetFpsTerm, targetField);
+    }
+    // fragment to fragment
+    assert sourceFFI >= 0;
+    assert targetFFI >= 0;
+    Term sourceFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(sourceFFI);
+    Term targetFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(targetFFI);
+    if (sourceFpsTerm.equals(targetFpsTerm)) { // labeled fragment positions shared
+      return new FieldMaskingSpanQuery(query, targetField);
+    }
+    // fragment to fragment via label:
+    FragmentToLabelQuery ftlq = new FragmentToLabelQuery(query, sourceFpsTerm, fieldSchema.getLabelFieldName());
+    return new LabelToFragmentQuery(ftlq, targetFpsTerm, targetField);
+  }
+
+}
Index: lucene/label/src/java/org/apache/lucene/search/spans/label/package-info.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/search/spans/label/package-info.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/search/spans/label/package-info.java	(working copy)
@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Querying labeled fragments.
+ * <p>
+ * This package provides <code>1 : 0..n</code> positional joins between text fields.
+ * For a <code>1 : 1</code> positional join see
+ * {@link org.apache.lucene.search.spans.FieldMaskingSpanQuery}.
+ * <p>
+ * Some labels can be highly repetitive, even within a single document.
+ * These will suffer from the same problems as other highly repetitive terms.
+ */
+package org.apache.lucene.search.spans.label;
+
Index: lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java
===================================================================
--- lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java	(revision 0)
+++ lucene/label/src/java/org/apache/lucene/util/packed/label/LongsInBytes.java	(working copy)
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.util.packed.label;
+
+/** Pack/unpack Longs in/from a byte array with offset, for a given number of bits per number.
+ *  @lucene.internal
+ */
+public class LongsInBytes {
+  public static final int LOG2_BYTE_SIZE = Integer.numberOfTrailingZeros(Byte.SIZE);
+  public static final long LONG_BYTE_MASK = 0xFFL;
+
+  /** Pack the lower numBits bits of value into array bytes at bit position packIndex*numBytes + 8 * offset.
+   * The value must not have any other bits set, and numBits should be non negative and at most 64.
+   */
+  public static void packValue(long value, int numBits, long packIndex, byte[] bytes, int offset) {
+    assert numBits >= 0;
+    assert numBits <= Long.SIZE;
+    assert ((-1L << numBits) & value) == 0; // no more than numBits in value
+    long bitPos = numBits * packIndex;
+    int byteIndex = offset + (int) (bitPos >>> LOG2_BYTE_SIZE);
+    int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+    bytes[byteIndex] |= (byte) (value << bitPosAtIndex);
+    int rightShift = (Byte.SIZE - bitPosAtIndex);
+    int remainingBits = numBits - rightShift;
+    while (remainingBits > 0) {
+      bytes[++byteIndex] = (byte) (value >>> rightShift);
+      rightShift += Byte.SIZE;
+      remainingBits -= Byte.SIZE;
+    }
+  }
+
+  /** Pack the lower numBits bits of value into array bytes at bit position packIndex*numBytes.
+   * The value must not have any other bits set, and numBits should be non negative and at most 64.
+   */
+  public static void packValue(long value, int numBits, long packIndex, byte[] bytes) {
+    packValue(value, numBits, packIndex, bytes, 0); // zero offset
+  }
+
+  /** Return the lower numBits bits from array bytes at bit position packIndex*numBytes + 8 * offset.
+   * numBits should be non negative and at most 64.
+   */
+  public static long unPackValue(int numBits, long packIndex, byte[] bytes, int offset) {
+    assert numBits >= 0;
+    assert numBits <= Long.SIZE;
+    long bitPos = packIndex * numBits;
+    int byteIndex = offset + (int) (bitPos >>> LOG2_BYTE_SIZE);
+    int bitPosAtIndex = (int) (bitPos & (Byte.SIZE-1));
+    long value = (bytes[byteIndex] & LONG_BYTE_MASK) >>> bitPosAtIndex;
+    int leftShift = Byte.SIZE - bitPosAtIndex;
+    int remainingBits = numBits - leftShift;
+    while (remainingBits > 0) {
+      value |= ((bytes[++byteIndex] & LONG_BYTE_MASK) << leftShift);
+      leftShift += Byte.SIZE;
+      remainingBits -= Byte.SIZE;
+    }
+    value &= ~(-1L << numBits); // mask numBits
+    return value;
+  }
+
+  /** Return the lower numBits bits from array bytes at bit position packIndex*numBytes.
+   * numBits should be non negative and at most 64.
+   */
+  public static long unPackValue(int numBits, long packIndex, byte[] bytes) {
+    return unPackValue(numBits, packIndex, bytes, 0);
+  }
+
+}
+
Index: lucene/label/src/java/overview.html
===================================================================
--- lucene/label/src/java/overview.html	(revision 0)
+++ lucene/label/src/java/overview.html	(working copy)
@@ -0,0 +1,115 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<body>
+Lucene's label module
+
+<h2>Positional joins for labeled text fragments</h2>
+
+At index time labeled text fragments for a document are analyzed from a {@link org.apache.lucene.analysis.TokenStream}.
+<br>
+In package {@link org.apache.lucene.analysis.label} such a labeled fragments stream is split into
+a label stream, and into pairs of streams for fragments and fragment positions.
+<br>The fragments in each fragment stream will be contiguous,
+the labels and the other fragment streams have no influence on their positions.
+This provides some backward compability because an existing text can be reindexed as it is,
+while adding labels and extra text streams.
+<p>
+The labels may be nested in a tree, in that case the label output stream will also contain label tree information.
+<br>
+As a special case of a nested label tree, an {@link javax.xml.stream.XMLEventReader} can also be provided.
+<p>
+The output streams can be used to provide documents with a different {@link org.apache.lucene.index.Field} per stream.
+It is up to the user to associate the output streams with fields in documents to be indexed for search.
+<p>
+Labels and fragments are represented at query time by {@link org.apache.lucene.search.spans.Spans}.
+Querying labeled fragments with positional joins and with navigation of the label tree
+is supported in package {@link org.apache.lucene.search.spans.label}.
+
+
+<h3>Implementation, variations, limitations</h3>
+
+The current implementation is a prototype.
+<p>
+For querying it is assumed that all the output token streams for a single labeled fragments input stream are indexed
+in one document in different fields.
+<br>More query implementations may be considered, for example the fragment streams may be concatenated with position gaps,
+or each output stream may be put in different documents of a document block of the join module.
+<p>
+The fragment positions and the label tree information are each implemented as one payload per stream.
+Even though some compression is done, for documents with many labels these payloads will grow large,
+and loading larger payloads during searches will not scale well.
+<br>Docvalues might be used instead of payloads, but these have the same limitations.
+<br>For up to some hundreds of labels per document this implementation is expected to be usable to explore its possibilities.
+<p>
+Instead of payloads for the fragment positions and for the label tree information,
+special fields could allow more random access for searches, and that would probably scale much better.
+<p>
+There is no support for changes in the data formats of these payloads in the index,
+and it is recommended to add a data format version to the payload term names.
+
+<h3>Some literature</h3>
+
+With comments on what was used here.
+<p>
+<dl>
+<dt>
+Quanzyong Li, Bongki Moon, "Indexing and Querying XML Data for Regular Path Expressions", VLDB 2001.
+<dd>
+Describes a structure index and an element/attribute index for XML.
+The structure index there corresponds to the label tree information here.
+The element/attribute index there is mostly provided by Lucene's term positions index,
+except for the element/attribute positions per label.
+<br>
+Paragraph 2.1 mentions the positional join provided here:
+"Both elements and attributes use the order of the order/size pair as their unique identifier in the document tree."
+This order is the label preorder position.
+<p>
+<dt>
+Taro L. Saito, Shinichi Morishita, "Amoeba Join: Overcoming Structural Fluctuations in XML Data", WebDB 2006.
+<dd>
+Interval representation for XML nodes. An amoeba join is much like a proximity query in the element tree.
+<p>
+<dt>
+Guiseppe Ottaviano, Roberto Grossi, "Semi-Indexing Semi-Structured data in Tiny Space", CIKM 2011.
+<dd>
+Balanced Parentheses for JSON tree structure. Elias-Fano sequence for offsets.
+<p>
+<dt>
+Sebastiano Vigna, "Quasi Succinct Indices", 2012.
+<dd>
+Elias-Fano sequence for term positions.
+<p>
+<dt>
+Diego Arroyuelo, Rodrigo C'novas, Gonzalo Navarro, Kunihiko Sadakane, "Succinct Trees in practice", 2010.
+<dd>
+Recommends a "Fully Functional" representation for trees represented by Balanced Parentheses.
+This requires about 2.4 bits per tree node instead of the 2*2log(#nodes) bits per tree node here,
+and it is less easy to implement.
+<p>
+<dt>
+Paolo Ferragina, Fabrizio Luccio, Giovanni Manzini, S. Muthukrishnan,
+"Compressing and indexing labeled trees, with applications", 2009.
+<dd>Discusses the XBW transform that linearizes the labeled tree into two coordinated arrays,
+one capturing the structure and the other the labels.
+Here such coordinated arrays are represented by the label tree info payload and by the label token stream.
+</dl>
+
+@lucene.experimental
+
+</body>
+</html>
Index: lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/analysis/label/TPS.java	(working copy)
@@ -0,0 +1,61 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.util.LuceneTestCase;
+
+class TPS { // for testing indexed term positions
+  Term term;
+  int[] expPosns;
+
+  TPS(String fieldName, String termText, int[] expPosns) { // at doc zero
+    this.term = new Term(fieldName, termText);
+    this.expPosns = expPosns;
+  }
+
+  void tstTermPositions(LeafReader lr) throws IOException {
+    int expDoc = 0;
+    PostingsEnum actDPE = lr.postings(term, PostingsEnum.POSITIONS);
+    String mes = term.toString() + " at doc " + expDoc;
+    if (actDPE == null) {
+      LuceneTestCase.assertEquals("#positions available for " + mes, expPosns.length, 0);
+    }
+    else {
+      LuceneTestCase.assertEquals(mes, expDoc, actDPE.nextDoc());
+      LuceneTestCase.assertEquals(mes, expPosns.length, actDPE.freq());
+      for (int expPos: expPosns) {
+        LuceneTestCase.assertEquals(mes, expPos, actDPE.nextPosition());
+      }
+      LuceneTestCase.assertEquals(PostingsEnum.NO_MORE_DOCS, actDPE.nextDoc());
+    }
+  }
+
+  static void tstTermPositions(LeafReader lr, TPS[] expTPSs) throws IOException {
+    for (TPS expTPS: expTPSs) {
+      expTPS.tstTermPositions(lr);
+    }
+  }
+}
+
+
Index: lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,342 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.LinkedHashSet;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+
+import org.apache.lucene.analysis.TokenStream;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.store.RAMDirectory;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+import org.apache.lucene.util.eliasfano.EliasFanoDecoder;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.junit.Test;
+
+
+public class TestLabeledFragmentsAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels");
+  final int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments1", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+  final int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  final String FragFieldName1 = fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex);
+  final String FragFieldName2 = fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex);
+
+  final LabeledFragmentsAnalyzer.InputSplitter ENDING_COLON_DOUBLE_BAR =
+  new LabeledFragmentsAnalyzer.InputSplitter() {
+    @Override
+    public LabeledFragmentsAnalyzer.TokenType tokenType(String term) {
+      if (term.equals("||")) {
+        return LabeledFragmentsAnalyzer.TokenType.NEXT_FRAGMENT;
+      }
+      if (term.endsWith(":")) {
+        return LabeledFragmentsAnalyzer.TokenType.LABEL;
+      }
+      return LabeledFragmentsAnalyzer.TokenType.FRAGMENT;
+    }
+  };
+
+  Field makeLabelField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), lfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledFragmentsAnalyzer lfAnalyzer, int fragmentStreamNum) {
+    String ffName = fieldSchema.getFragmentFieldName(fragmentStreamNum);
+    return new TextField(ffName, lfAnalyzer.fragmentsTokenStream(fragmentStreamNum));
+  }
+
+  Field makeFragmentPositionsField(LabeledFragmentsAnalyzer lfAnalyzer, int fragmentStreamNum) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(fragmentStreamNum, fpsTerm.text()));
+  }
+
+  Document makeDocument(String labeledFragmentsStr, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(lfTokenizer, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+    lfAnalyzer.consumeInputStream();
+    Document doc = new Document();
+    Field labelField = makeLabelField(lfAnalyzer);
+    doc.add(labelField);
+    for (int i = 0; i < lfAnalyzer.numFragmentStreams(); i++) {
+      Field fragmentField = makeFragmentField(lfAnalyzer, i);
+      doc.add(fragmentField);
+      Field fragmentPositionsField = makeFragmentPositionsField(lfAnalyzer, i);
+      doc.add(fragmentPositionsField);
+    }
+    return doc;
+  }
+
+  void tstExpectedFieldsIndex(String labeledFragmentsStr, int numFragmentStreams, String[] expectedFieldNames)
+  throws IOException {
+    Document doc = makeDocument(labeledFragmentsStr, numFragmentStreams);
+    // index the document
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    IndexReader r = DirectoryReader.open(dir);
+    // test that the field names are the expected ones:
+    Fields fields = MultiFields.getFields(r);
+    if (fields != null) {
+      LinkedHashSet<String> names = new LinkedHashSet<>();
+      for (String fieldName: expectedFieldNames) {
+        names.add(fieldName);
+      }
+      Iterator<String> fieldNames = fields.iterator();
+      while (fieldNames.hasNext()) {
+        String fieldName = fieldNames.next();
+        assertTrue("field name not in expected set: " + fieldName, names.contains(fieldName));
+        names.remove(fieldName);
+      }
+      for (String fieldName: names) {
+        assertTrue("non present field name: " + fieldName, false);
+      }
+    } else {
+      assertEquals("no fields found, but some expected", 0, expectedFieldNames.length);
+    }
+    r.close();
+    dir.close();
+  }
+
+  static void tstDecodeAllNext(int[] expValues, EliasFanoBytes efSeq) {
+    EliasFanoDecoder<EliasFanoBytes> efd = efSeq.getDecoder();
+    long nextValue = efd.nextValue();
+    for (int expValue: expValues) {
+      assertFalse("nextValue at end too early", EliasFanoDecoder.NO_MORE_VALUES == nextValue);
+      assertEquals(expValue, nextValue);
+      nextValue = efd.nextValue();
+    }
+    assertEquals(EliasFanoDecoder.NO_MORE_VALUES, nextValue);
+  }
+
+  static void tstFragmentPositions(int[] expFragmentPositions, LeafReader lr, Term fpsTerm)
+  throws IOException {
+    PostingsEnum dpfe = lr.postings(fpsTerm, PostingsEnum.PAYLOADS);
+    if (dpfe == null) {
+      assertEquals("number of fragment positions", 0, expFragmentPositions.length);
+    } else {
+      assertEquals("first doc", 0, dpfe.nextDoc());
+      assertEquals("frequency", 1, dpfe.freq());
+      assertEquals("position", 0, dpfe.nextPosition());
+      BytesRef payload = dpfe.getPayload();
+      assertTrue(payload != null);
+      EliasFanoBytes efSeq = EliasFanoBytes.createFromBytesRef(payload);
+      tstDecodeAllNext(expFragmentPositions, efSeq);
+      assertEquals(PostingsEnum.NO_MORE_DOCS, dpfe.nextDoc());
+    }
+  }
+
+  void tstFragments(String[] labeledFragmentsStrs, int numFragmentStreams, int[][] expFragmentPositionsByField, TPS[] expTPSs)
+  throws IOException {
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    for (String lfStr: labeledFragmentsStrs) {
+      Document doc = makeDocument(lfStr, numFragmentStreams);
+      w.addDocument(doc);
+    }
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+    for (int fragmentStreamNum = 0; fragmentStreamNum < numFragmentStreams; fragmentStreamNum++) {
+      int[] expFragmentPositions = expFragmentPositionsByField[fragmentStreamNum];
+      Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+      tstFragmentPositions(expFragmentPositions, lr, fpsTerm);
+    }
+
+    TPS.tstTermPositions(lr, expTPSs);
+    lr.close();
+    dir.close();
+  }
+
+  void tstFragments(String labeledFragmentsStr, int numFragmentStreams, int[][] expFragmentPositionsByField, TPS[] expTPSs)
+  throws IOException {
+    tstFragments(new String[]{labeledFragmentsStr}, numFragmentStreams, expFragmentPositionsByField, expTPSs);
+  }
+
+  public void testFieldsEmpty1() throws IOException {
+    tstExpectedFieldsIndex("", 1, new String[0]);
+  }
+
+  public void testFieldsEmpty2() throws IOException {
+    tstExpectedFieldsIndex("", 2, new String[0]);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelOneFragmentField1() throws IOException {
+    // one fragment, no labels, no payload
+    tstExpectedFieldsIndex("a b", 1, new String[] {FragFieldName1});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelOneFragmentField2() throws IOException {
+    // one fragment, no labels, no payload
+    tstExpectedFieldsIndex("a b", 2, new String[] {FragFieldName1});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsNoLabelTwoFragmentFields() throws IOException {
+    // two fragments fields, no labels, no payload
+    tstExpectedFieldsIndex("a b || c d", 2, new String[] {FragFieldName1,FragFieldName2});
+  }
+
+  public void testFieldsNoFragments() throws IOException {
+    tstExpectedFieldsIndex("A: B:", 1, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+    tstExpectedFieldsIndex("A: B:", 2, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+    tstExpectedFieldsIndex("A: B: ||", 2, new String[] {fieldSchema.getLabelFieldName()}); // only labels, no fragments, no payload
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsInitialUnlabeledFragment1() throws IOException {
+    tstExpectedFieldsIndex("a B:", 1, new String[] {
+                                        fieldSchema.getLabelFieldName(),
+                                        FragFieldName1,
+                                        fieldSchema.getFragmentPositionsPayloadTerm(0).field()});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testFieldsInitialUnlabeledFragment2() throws IOException {
+    tstExpectedFieldsIndex("a B:", 2, new String[] {
+                                        fieldSchema.getLabelFieldName(),
+                                        FragFieldName1,
+                                        fieldSchema.getFragmentPositionsPayloadTerm(0).field()});
+  }
+
+  public void testOneFragmentOneFragmentField() throws IOException {
+    tstFragments("A: a1", 1,
+                  new int[][]{{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0})
+                  });
+  }
+
+  public void testOneFragmentTwoFragmentFields() throws IOException {
+    tstFragments("A: a1 || a2", 2,
+                  new int[][] {{0,1},{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testTooManyFragmentsPerLabel() throws IOException {
+    tstFragments("A: a1 || a2 || a3", 2,
+                  new int[][] {{0,1},{0,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testInitialUnlabeledFragmentOneFragmentField() throws IOException {
+    tstFragments("a1 B:", 1,
+                  new int[][]{{1,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0})
+                  });
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testInitialUnlabeledFragmentTwoFragmentFields() throws IOException {
+    tstFragments("a1 || a2 B:", 2,
+                  new int[][]{{1,1},{1,1}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{0}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName2, "a2", new int[]{0})
+                  });
+  }
+
+  public void testMoreFragmentsOneFragmentField() throws IOException {
+    tstFragments("A: a1 a2 z1 B: C: c1 c2 D: d1 z1 E:", 1,
+                  new int[][]{{0,3,3,5,7,7}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "C:", new int[]{2}),
+                    new TPS(fieldSchema.getLabelFieldName(), "D:", new int[]{3}),
+                    new TPS(fieldSchema.getLabelFieldName(), "E:", new int[]{4}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{1}),
+                    new TPS(FragFieldName1, "z1", new int[]{2,6}),
+                    new TPS(FragFieldName1, "c1", new int[]{3}),
+                    new TPS(FragFieldName1, "c2", new int[]{4}),
+                    new TPS(FragFieldName1, "d1", new int[]{5})
+                  });
+  }
+
+  public void testMoreFragmentsTwoFragmentFields() throws IOException {
+    tstFragments("A: a1 a2 z1 || aa1 B: C: c1 c2 D: d1 z1 E: || ee1", 2,
+                  new int[][]{{0,3,3,5,7,7},{0,1,1,1,1,2}},
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "A:", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "B:", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "C:", new int[]{2}),
+                    new TPS(fieldSchema.getLabelFieldName(), "D:", new int[]{3}),
+                    new TPS(fieldSchema.getLabelFieldName(), "E:", new int[]{4}),
+                    new TPS(FragFieldName1, "a1", new int[]{0}),
+                    new TPS(FragFieldName1, "a2", new int[]{1}),
+                    new TPS(FragFieldName1, "z1", new int[]{2,6}),
+                    new TPS(FragFieldName1, "c1", new int[]{3}),
+                    new TPS(FragFieldName1, "c2", new int[]{4}),
+                    new TPS(FragFieldName1, "d1", new int[]{5}),
+                    new TPS(FragFieldName2, "aa1", new int[]{0}),
+                    new TPS(FragFieldName2, "ee1", new int[]{1})
+                  });
+  }
+}
Index: lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/analysis/label/TestLabeledTreeFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,226 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.LinkedHashSet;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.store.RAMDirectory;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.PostingsEnum;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.packed.label.LongsInBytes;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.InputSplitter;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.junit.Test;
+
+public class TestLabeledTreeFragmentsAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels", "treeInfo-" + Version.LATEST); // add version until there is a real field for this
+  {
+    fieldSchema.addLabeledFragmentField("fragments", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+    fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+  }
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      return term.endsWith(":") ? TokenType.LABEL
+            : term.equals("||") ? TokenType.NEXT_FRAGMENT
+            : term.equals(";;") ? TokenType.END_LABEL
+                                : TokenType.FRAGMENT;
+    }
+  };
+
+  Field makeLabelField(LabeledTreeFragmentsAnalyzer ltfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), ltfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledTreeFragmentsAnalyzer ltfAnalyzer, int fragmentStreamNum) {
+    String ffName = fieldSchema.getFragmentFieldName(fragmentStreamNum);
+    return new TextField(ffName, ltfAnalyzer.fragmentsTokenStream(fragmentStreamNum));
+  }
+
+  Field makeFragmentPositionsField(LabeledTreeFragmentsAnalyzer ltfAnalyzer, int fragmentStreamNum) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(fragmentStreamNum);
+    return new TextField(fpsTerm.field(), ltfAnalyzer.fragmentPositionsTokenStream(fragmentStreamNum, fpsTerm.text()));
+  }
+
+  Document makeDocument(String labeledFragmentsStr, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledTreeFragmentsAnalyzer ltfAnalyzer = new LabeledTreeFragmentsAnalyzer(lfTokenizer,
+                                                      ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI,
+                                                      numFragmentStreams,
+                                                      fieldSchema.getTreeInfoPayloadTermText());
+    lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+    ltfAnalyzer.consumeInputStream();
+    Document doc = new Document();
+    Field labelField = makeLabelField(ltfAnalyzer);
+    doc.add(labelField);
+    for (int i = 0; i < ltfAnalyzer.numFragmentStreams(); i++) {
+      Field fragmentField = makeFragmentField(ltfAnalyzer, i);
+      doc.add(fragmentField);
+      Field fragmentPositionsField = makeFragmentPositionsField(ltfAnalyzer, i);
+      doc.add(fragmentPositionsField);
+    }
+    return doc;
+  }
+
+  static void tstIntsInBytesRef(int[] expLabelNodeInfo, BytesRef bytesRef) {
+    int numBits = Integer.SIZE - Integer.numberOfLeadingZeros(expLabelNodeInfo.length/2 - 1);
+    int numBytes = (expLabelNodeInfo.length * numBits + 7) >> 3;
+    byte[] bytes = bytesRef.bytes;
+    assertEquals("bytes.length", numBytes, bytesRef.length);
+    for (int i = 0; i < expLabelNodeInfo.length; i++) {
+      long actValue = LongsInBytes.unPackValue(numBits, i, bytes, bytesRef.offset);
+      assertEquals("at index " + i, expLabelNodeInfo[i], actValue);
+    }
+  }
+
+  static void tstLabelNodeInfo(int[] expLabelNodeInfo, LeafReader lr, Term labelTreeTerm)
+  throws IOException {
+    PostingsEnum actDPE = lr.postings(labelTreeTerm, PostingsEnum.PAYLOADS);
+    if (actDPE == null) {
+      assertTrue("actual PostingsEnum for tree info payload term should not be null", expLabelNodeInfo == null);
+    } else {
+      assertEquals("labelInfoTerm first doc", 0, actDPE.nextDoc());
+      assertEquals("labelInfoTerm freq", 1, actDPE.freq());
+      int numLabels = actDPE.nextPosition();
+      if (numLabels == 1) { // root only
+        assertEquals("root only label info at pos 1", null, expLabelNodeInfo);
+        assertEquals("no payload for root only", null, actDPE.getPayload());
+      } else {
+        assertEquals("two ints per node expected", 0, expLabelNodeInfo.length % 2);
+        assertEquals("labelInfoTerm pos", expLabelNodeInfo.length/2, numLabels);
+        // get the payload
+        BytesRef payload = actDPE.getPayload();
+        assertTrue(payload != null);
+        tstIntsInBytesRef(expLabelNodeInfo, payload);
+        assertEquals("labelInfoTerm no next doc", PostingsEnum.NO_MORE_DOCS, actDPE.nextDoc());
+      }
+    }
+  }
+
+  void tstLabelNodeInfo(String labeledFragmentsStr, int[] expLabelNodeInfo) throws IOException {
+    final int numFragmentStreams = 1;
+    Document doc = makeDocument(labeledFragmentsStr, numFragmentStreams);
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+    Term labelTreeTerm = new Term(fieldSchema.getLabelFieldName(), fieldSchema.getTreeInfoPayloadTermText());
+    tstLabelNodeInfo(expLabelNodeInfo, lr, labelTreeTerm);
+    lr.close();
+    dir.close();
+  }
+
+  public void testEmpty() throws IOException {
+    tstLabelNodeInfo("", null);
+  }
+
+  public void testRootOnly() throws IOException {
+    tstLabelNodeInfo("A: ;;", null);
+  }
+
+  public void testOneChild() throws IOException {
+    tstLabelNodeInfo("A: B: ;; ;;", new int[]{0,1, 0,0}); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  public void testTwoChildren() throws IOException {
+    tstLabelNodeInfo("A: B: ;; C: ;; ;;", new int[]{0,2, 0,0, 0,0});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; ;; ;;", new int[]{0,2, 0,1, 1,0});
+  }
+
+  public void testGrandChildren() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; D: ;; ;; ;;", new int[]{0,3, 0,2, 1,0, 1,0});
+  }
+
+  public void testLarger() throws IOException {
+    tstLabelNodeInfo("A: B: C: ;; D: ;; ;; B: C: ;; D: ;; ;; ;;", new int[]{0,6, 0,2, 1,0, 1,0, 0,2, 4,0, 4,0});
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxFragmentWithoutOpenLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;; c1 ;;", null); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxNextFragmentWithoutOpenLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;; || c1 ;;", null); // A: parent, A: #descendants, B: parent, B: #descendants
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxLabelAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; B: ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxFragmentAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxNextFragmentAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; || b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxEndLabelAfterLastLabel() throws IOException {
+    tstLabelNodeInfo("A: ;; ;; b1 ", null);
+  }
+
+  @Test(expected=IllegalArgumentException.class)
+  public void testSyntaxMissingEndLabel() throws IOException {
+    tstLabelNodeInfo("A: B: ;;", null);
+  }
+}
Index: lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlLabeledTreeFragmentsAnalyzer.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlLabeledTreeFragmentsAnalyzer.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/analysis/label/TestXmlLabeledTreeFragmentsAnalyzer.java	(working copy)
@@ -0,0 +1,546 @@
+package org.apache.lucene.analysis.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Iterator;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+import org.junit.Test;
+import org.junit.Ignore;
+
+import javax.xml.stream.XMLEventReader;
+import javax.xml.stream.XMLInputFactory;
+import javax.xml.stream.XMLStreamException;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.eliasfano.EliasFanoBytes;
+
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+
+import org.apache.lucene.analysis.label.XmlLabeledTreeFragmentsAnalyzer.TextTokenizers;
+
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+
+public class TestXmlLabeledTreeFragmentsAnalyzer extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labelsField", "treeInfoTerm-" + Version.LATEST); // add version until there is a real field for this
+  Term attrFragmentPosnsPayloadTerm = new Term("attrFragmentPosnsField", "attrFragmentPosnsTerm-" + Version.LATEST);
+  final int ATTR_NAME_FFI = fieldSchema.addLabeledFragmentField("attrNamesField", attrFragmentPosnsPayloadTerm);
+  final int ATTR_VALUE_FFI = fieldSchema.addLabeledFragmentField("attrValuesField", attrFragmentPosnsPayloadTerm);
+  final int TEXT_FFI = fieldSchema.addLabeledFragmentField("textField", new Term("textFragmentPosnsField", "textFragmentPosnsTerm-" + Version.LATEST)); // default xml text
+  final int NFS_FFI = fieldSchema.addLabeledFragmentField("nfs", new Term("nfsFragmentPosnsField", "textFragmentPosnsTerm-" + Version.LATEST)); // nfs is also xml tag name
+
+  final static TextTokenizers TEXT_TOKENIZERS = new TextTokenizers() {
+    @Override
+    public Tokenizer textTokenizer(String tag) {
+      WhitespaceTokenizer whitespaceTokenizer = new WhitespaceTokenizer();
+      return whitespaceTokenizer;
+    }
+  };
+  
+  final String FRAGMENT_LABEL_AFTER_NESTED_ELEMENT = "after";
+
+  Field makeLabelField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), xmlLTFAnalyzer.labelTokenStream());
+  }
+
+  Field makeAttributeNameField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(ATTR_NAME_FFI), xmlLTFAnalyzer.attrNameFragmentsTokenStream());
+  }
+
+  Field makeAttributeValueField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI), xmlLTFAnalyzer.attrValueFragmentsTokenStream());
+  }
+
+  Field makeAttributeFragmentPositionsField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    Term attrFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(ATTR_NAME_FFI); // fragment positions shared with attr values
+    return new TextField(attrFpsTerm.field(), xmlLTFAnalyzer.attrFragmentPositionsTokenStream(attrFpsTerm.text()));
+  }
+
+  Field makeTextField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    return new TextField(textFieldName, xmlLTFAnalyzer.textFragmentsStream(textFieldName));
+  }
+
+  Field makeTextFragmentPositionsField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(TEXT_FFI);
+    return new TextField(textFpsTerm.field(), xmlLTFAnalyzer.textFragmentPositionsStream(textFieldName, textFpsTerm.text()));
+  }
+
+  Field makeNextTextField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    return new TextField(textFieldName, xmlLTFAnalyzer.textFragmentsStream(textFieldName));
+  }
+
+  Field makeNextTextFragmentPositionsField(XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) {
+    String textFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(NFS_FFI);
+    return new TextField(textFpsTerm.field(), xmlLTFAnalyzer.textFragmentPositionsStream(textFieldName, textFpsTerm.text()));
+  }
+
+
+  XMLInputFactory xmlInputFactory;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    xmlInputFactory = XMLInputFactory.newInstance();
+    xmlInputFactory.setProperty(XMLInputFactory.IS_COALESCING, Boolean.TRUE);
+  }
+
+  XMLEventReader xmlEventReaderFromString(String xml) throws IOException {
+    try {
+      XMLEventReader r = xmlInputFactory.createXMLEventReader(new StringReader(xml));
+      return r;
+    } catch (XMLStreamException xse) {
+      throw new IOException(xse);
+    }
+  }
+
+  Document makeDocument(String xml, XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer) throws IOException, XMLStreamException {
+    XMLEventReader xmlEventReader = xmlEventReaderFromString(xml);
+    int initialOffset = 0;
+    xmlLTFAnalyzer.consumeXmlEventReader(xmlEventReader, initialOffset);
+
+    Document doc = new Document();
+    doc.add(makeLabelField(xmlLTFAnalyzer));
+
+    doc.add(makeAttributeNameField(xmlLTFAnalyzer));
+    doc.add(makeAttributeValueField(xmlLTFAnalyzer));
+    doc.add(makeAttributeFragmentPositionsField(xmlLTFAnalyzer));
+
+    doc.add(makeTextField(xmlLTFAnalyzer));
+    doc.add(makeTextFragmentPositionsField(xmlLTFAnalyzer));
+
+    doc.add(makeNextTextField(xmlLTFAnalyzer));
+    doc.add(makeNextTextFragmentPositionsField(xmlLTFAnalyzer));
+
+    return doc;
+  }
+
+  void tstXmlDocument(String xml,
+                      int[] expLabelNodeInfo,
+                      int[] expAttrFragmentPosns,
+                      int[] expTextFragmentPosns,
+                      int[] expNextTextFragmentPosns,
+                      TPS[] expTPSs)
+  throws IOException, XMLStreamException {
+    List<String> textStreamTags = new ArrayList<>(0);
+    textStreamTags.add(fieldSchema.getFragmentFieldName(TEXT_FFI));
+    textStreamTags.add(fieldSchema.getFragmentFieldName(NFS_FFI));
+    XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer = new XmlLabeledTreeFragmentsAnalyzer(textStreamTags, 
+                                                                                      TEXT_TOKENIZERS,
+                                                                                      FRAGMENT_LABEL_AFTER_NESTED_ELEMENT,
+                                                                                      fieldSchema.getTreeInfoPayloadTermText());
+    Document doc = makeDocument(xml, xmlLTFAnalyzer);
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    w.addDocument(doc);
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
+
+    TPS.tstTermPositions(lr, expTPSs);
+
+    Term labelTreeTerm = new Term(fieldSchema.getLabelFieldName(), fieldSchema.getTreeInfoPayloadTermText());
+    TestLabeledTreeFragmentsAnalyzer.tstLabelNodeInfo(expLabelNodeInfo, lr, labelTreeTerm);
+
+    Term attrFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(0);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expAttrFragmentPosns, lr, attrFpsTerm);
+
+    Term textFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(2);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expTextFragmentPosns, lr, textFpsTerm);
+
+    Term nextTextFpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(3);
+    TestLabeledFragmentsAnalyzer.tstFragmentPositions(expNextTextFragmentPosns, lr, nextTextFpsTerm);
+
+    lr.close();
+    dir.close();
+  }
+
+  void tstXmlDocument(String xml,
+                      int[] expLabelNodeInfo,
+                      int[] expAttrFragmentPosns,
+                      int[] expTextFragmentPosns,
+                      TPS[] expTPSs)
+  throws IOException, XMLStreamException {
+    // add empty expNextFragmentPosns
+    tstXmlDocument(xml, expLabelNodeInfo, expAttrFragmentPosns, expTextFragmentPosns, new int[0], expTPSs);
+  }
+
+  @Test(expected=XMLStreamException.class) // unexpected end of file for empty xml stream
+  public void testEmpty() throws IOException, XMLStreamException {
+    String xml = "";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, null);
+  }
+
+  public void testEmptyElement() throws IOException, XMLStreamException {
+    String xml = "<tag1></tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0})
+                  });
+  }
+
+  @Test(expected=XMLStreamException.class) // attribute value missing quotes
+  public void testXmlSyntaxError1() throws IOException, XMLStreamException {
+    String xml = "<tag1 a1=v1/>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, null);
+  }
+
+  public void testSingleAttribute() throws IOException, XMLStreamException {
+    String xml = "<tag1 attr1=\"val1\"/>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {0,1};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(ATTR_NAME_FFI), "attr1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI), "val1", new int[]{0})
+                  });
+  }
+
+  public void testSingleTextToken() throws IOException, XMLStreamException {
+    String xml = "<tag1> token1 </tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {0,1};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getFragmentFieldName(TEXT_FFI), "token1", new int[]{0})
+                  });
+  }
+
+  public void testThreeEmptyElements() throws IOException, XMLStreamException {
+    String xml = "<tag1> <tag2> </tag2> <tag3> </tag3> </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag3", new int[]{2})
+                  });
+  }
+
+  public void testThreeElements1() throws IOException, XMLStreamException {
+    String xml =   "<tag1 attr12=\"v12\" attr11=\"v11\">" // attributes descending by name
+                 + "  <tag2> some text </tag2>"
+                 + "  <tag3 attr31=\"v31\"> </tag3>"
+                 + "</tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,2,2,3};
+    int[] textPosns = {0,0,2,2};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag3", new int[]{2}),
+                    new TPS(attrNameFieldName, "attr11", new int[]{0}), // attributes ascending by name
+                    new TPS(attrValueFieldName, "v11", new int[]{0}),
+                    new TPS(attrNameFieldName, "attr12", new int[]{1}),
+                    new TPS(attrValueFieldName, "v12", new int[]{1}),
+                    new TPS(attrNameFieldName, "attr31", new int[]{2}),
+                    new TPS(attrValueFieldName, "v31", new int[]{2}),
+                    new TPS(textFieldName, "some", new int[]{0}),
+                    new TPS(textFieldName, "text", new int[]{1})
+                  });
+  }
+
+  public void testTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> before <tag2> inside </tag2> after </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,1,2,3};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), FRAGMENT_LABEL_AFTER_NESTED_ELEMENT, new int[]{2}),
+                    new TPS(textFieldName, "before", new int[]{0}),
+                    new TPS(textFieldName, "inside", new int[]{1}),
+                    new TPS(textFieldName, "after", new int[]{2}),
+                  });
+  }
+
+  public void testTwoStreamsSingleTextToken() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs> token2 </nfs> </tag1>";
+    int[] labelNodeInfo = null;
+    int[] attrPosns = {};
+    int[] textPosns = {};
+    int[] nextTextPosns = {0,1};
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(nfsFieldName, "token2", new int[]{0}),
+                  });
+  }
+
+  public void testTwoStreamsTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> default1 default2 <nfs> before <tag2> inside </tag2> after </nfs> default3 </tag1>"; // txt label after </tag2>
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,2,2,3};
+    int[] nextTextPosns = {0,1,2,3};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), FRAGMENT_LABEL_AFTER_NESTED_ELEMENT, new int[]{2}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(nfsFieldName, "inside", new int[]{1}),
+                    new TPS(nfsFieldName, "after", new int[]{2}),
+                    new TPS(textFieldName, "default3", new int[]{2}),
+                  });
+  }
+
+  public void testTwoStreamsNoTextAfterNestedElement() throws IOException, XMLStreamException {
+    String xml = "<tag1> default1 default2 <nfs> before </nfs> <tag2 a21=\"v21\"/> </tag1>"; // no txt label, attribute in < /> syntax
+    int[] labelNodeInfo = {0,1, 0,0};
+    int[] attrPosns = {0,0,1};
+    int[] textPosns = {0,2,2};
+    int[] nextTextPosns = {0,1,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(attrNameFieldName, "a21", new int[]{0}),
+                    new TPS(attrValueFieldName, "v21", new int[]{0}),
+                  });
+  }
+
+  public void testTwoStreamsTextAfterNestedElementWithAttribute() throws IOException, XMLStreamException {
+    String xml = "<tag1> <tag2 a21=\"v21\"/> default1 default2 <nfs> after </nfs> default3 </tag1>"; // txt label after tag with attribute <tag2 ... />
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,0,1,1};
+    int[] textPosns = {0,0,0,3};
+    int[] nextTextPosns = {0,0,0,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), FRAGMENT_LABEL_AFTER_NESTED_ELEMENT, new int[]{2}),
+                    new TPS(attrNameFieldName, "a21", new int[]{0}),
+                    new TPS(attrValueFieldName, "v21", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(nfsFieldName, "after", new int[]{0}),
+                    new TPS(textFieldName, "default3", new int[]{2}),
+                  });
+  }
+
+  public void testIgnoreAttrsAtTextRedirectingTag() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs a21=\"v21\"> inside </nfs> default1 default2 <tag2 a22=\"v22\"> after </tag2> default3 </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {0,0,1,1};
+    int[] textPosns = {0,2,3,4};
+    int[] nextTextPosns = {0,1,1,1};
+    String attrNameFieldName = fieldSchema.getFragmentFieldName(ATTR_NAME_FFI);
+    String attrValueFieldName = fieldSchema.getFragmentFieldName(ATTR_VALUE_FFI);
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), FRAGMENT_LABEL_AFTER_NESTED_ELEMENT, new int[]{2}),
+                    new TPS(attrNameFieldName, "a21", new int[]{}), // ignored
+                    new TPS(attrValueFieldName, "v21", new int[]{}), // ignored
+                    new TPS(nfsFieldName, "inside", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                    new TPS(attrNameFieldName, "a22", new int[]{0}), // present
+                    new TPS(attrValueFieldName, "v22", new int[]{0}), // present
+                    new TPS(textFieldName, "after", new int[]{2}),
+                    new TPS(textFieldName, "default3", new int[]{3}),
+                  });
+  }
+
+  public void testRedirectTextToDefaultStream() throws IOException, XMLStreamException {
+    String xml = "<tag1> <nfs> before <tag2> <textField> default1 </textField> </tag2> </nfs> default2 </tag1>";
+    int[] labelNodeInfo = {0,2, 0,0, 0,0};
+    int[] attrPosns = {};
+    int[] textPosns = {0,0,1,2};
+    int[] nextTextPosns = {0,1,1,1};
+    String textFieldName = fieldSchema.getFragmentFieldName(TEXT_FFI);
+    String nfsFieldName = fieldSchema.getFragmentFieldName(NFS_FFI);
+    tstXmlDocument(xml, labelNodeInfo, attrPosns, textPosns, nextTextPosns,
+                  new TPS[]{
+                    new TPS(fieldSchema.getLabelFieldName(), "tag1", new int[]{0}),
+                    new TPS(fieldSchema.getLabelFieldName(), "tag2", new int[]{1}),
+                    new TPS(fieldSchema.getLabelFieldName(), FRAGMENT_LABEL_AFTER_NESTED_ELEMENT, new int[]{2}),
+                    new TPS(nfsFieldName, "before", new int[]{0}),
+                    new TPS(textFieldName, "default1", new int[]{0}),
+                    new TPS(textFieldName, "default2", new int[]{1}),
+                  });
+  }
+
+  public void testJavadocExample() throws IOException, XMLStreamException {
+    String xml =
+      "<kiosk> " +
+        "some" +
+        "<newspaper counter=\"42\"> " +
+          " <editor>J. More </editor> " +
+          "<title>Greatest</title> " +
+        "</newspaper> " +
+        " more text" +
+        "<newspaper counter=\"43\"> " +
+          "<editor>C. Less</editor> " +
+          "<title> Early Morning</title> " +
+        "</newspaper>" +
+      "</kiosk>";
+
+    List<String> textStreamTags = new ArrayList<>(0);
+    textStreamTags.add("txt");
+    textStreamTags.add("editor");
+    textStreamTags.add("title");
+
+    XmlLabeledTreeFragmentsAnalyzer xmlLTFAnalyzer = new XmlLabeledTreeFragmentsAnalyzer(textStreamTags,
+                                                        TEXT_TOKENIZERS,
+                                                        FRAGMENT_LABEL_AFTER_NESTED_ELEMENT,
+                                                        "treeInfo");
+
+    XMLEventReader xmlEventReader = xmlEventReaderFromString(xml);
+    int initialOffset = 0;
+    xmlLTFAnalyzer.consumeXmlEventReader(xmlEventReader, initialOffset);
+
+    tstTokenStreamWithPayload(xmlLTFAnalyzer.labelTokenStream(),
+                              new String[] {"kiosk", "newspaper", "after", "newspaper", "treeInfo"},
+                              4, true /* tree info payload */,
+                              new int[] {0,3, 0,0, 0,0, 0,0});
+
+    tstTokenStream(xmlLTFAnalyzer.attrNameFragmentsTokenStream(), new String[] {"counter", "counter"});
+    tstTokenStream(xmlLTFAnalyzer.attrValueFragmentsTokenStream(), new String[] {"42", "43"});
+    tstTokenStreamWithPayload(xmlLTFAnalyzer.attrFragmentPositionsTokenStream("fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 1, 1, 2});
+
+    tstTokenStream(xmlLTFAnalyzer.textFragmentsStream("txt"), new String[] {"some", "more", "text"});
+    tstTokenStreamWithPayload(xmlLTFAnalyzer.textFragmentPositionsStream("txt", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 1, 1, 3, 3});
+
+    tstTokenStream(xmlLTFAnalyzer.textFragmentsStream("editor"), new String[] {"J.", "More", "C.", "Less"});
+    tstTokenStreamWithPayload(xmlLTFAnalyzer.textFragmentPositionsStream("editor", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 2, 2, 4});
+
+    tstTokenStream(xmlLTFAnalyzer.textFragmentsStream("title"), new String[] {"Greatest", "Early", "Morning"});
+    tstTokenStreamWithPayload(xmlLTFAnalyzer.textFragmentPositionsStream("title", "fragPos"),
+                              new String[] {"fragPos"},
+                              0, false /* fragment positions payload */,
+                              new int[] {0, 0, 1, 1, 3});
+  }
+
+  static void tstTokenStream(TokenStream ts, String[] expTokenStrings) throws IOException {
+    tstTokenStreamWithPayload(ts, expTokenStrings, -1, false, null);
+  }
+
+  static void tstTokenStreamWithPayload(
+      TokenStream ts,
+      String[] expTokenStrings,
+      int expPayloadIndex,
+      boolean isTreeInfoPayload, // otherwise fragment positions payload
+      int[] expValues) // tree info or fragment positions.
+  throws IOException
+  {
+    int streamIndex = -1;
+    ts.reset();
+    CharTermAttribute cta = ts.getAttribute(CharTermAttribute.class);
+    PayloadAttribute pa = ts.getAttribute(PayloadAttribute.class);
+    while (ts.incrementToken()) {
+      streamIndex++;
+      assertEquals("token string at " + streamIndex, expTokenStrings[streamIndex], cta.toString());
+      if (streamIndex == expPayloadIndex) {
+        BytesRef payload = pa.getPayload();
+        if (isTreeInfoPayload) {
+          TestLabeledTreeFragmentsAnalyzer.tstIntsInBytesRef(expValues, payload);
+        }
+        else { // fragment positions payload
+          TestLabeledFragmentsAnalyzer.tstDecodeAllNext(expValues, EliasFanoBytes.createFromBytesRef(payload));
+        }
+      }
+    }
+    ts.close();
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/LabeledFragmentsTestCase.java	(working copy)
@@ -0,0 +1,219 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.Version;
+import org.apache.lucene.util.Bits;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer;
+import org.apache.lucene.analysis.label.LabeledTreeFragmentsAnalyzer;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.analysis.MockAnalyzer;
+
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.Spans;
+import org.apache.lucene.search.spans.SpanTermQuery;
+
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.InputSplitter;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer.TokenType;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+
+abstract class LabeledFragmentsTestCase extends LuceneTestCase {
+  final LabelFieldSchema fieldSchema = new LabelFieldSchema("labels", "treeInfoTerm-" + Version.LATEST); // add version until there is a real field for this
+  final int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments", new Term("labelsToFragments", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  Field makeLabelField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getLabelFieldName(), lfAnalyzer.labelTokenStream());
+  }
+
+  Field makeFragmentField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex), lfAnalyzer.fragmentsTokenStream(firstFragmentFieldSchemaIndex));
+  }
+
+  Field makeFragmentPositionsField(LabeledFragmentsAnalyzer lfAnalyzer) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(firstFragmentFieldSchemaIndex, fpsTerm.text()));
+  }
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      if (term.equals("||")) {
+        return TokenType.NEXT_FRAGMENT;
+      }
+      if (term.endsWith(":")) {
+        return TokenType.LABEL;
+      }
+      return TokenType.FRAGMENT;
+    }
+  };
+
+  final InputSplitter ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI = new InputSplitter() {
+    @Override
+    public TokenType tokenType(String term) {
+      return term.endsWith(":") ? TokenType.LABEL
+            : term.equals("||") ? TokenType.NEXT_FRAGMENT
+            : term.equals(";;") ? TokenType.END_LABEL
+                                : TokenType.FRAGMENT;
+    }
+  };
+
+  Document makeDocument(LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    Document doc = new Document();
+    Field labelField = makeLabelField(lfAnalyzer);
+    doc.add(labelField);
+    Field fragmentField = makeFragmentField(lfAnalyzer);
+    doc.add(fragmentField);
+    Field fragmentPositionsField = makeFragmentPositionsField(lfAnalyzer);
+    doc.add(fragmentPositionsField);
+    return doc;
+  }
+
+  List<Document> makeDocuments(String[] labeledFragmentsStrs, Tokenizer lfTokenizer, LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    List<Document> docs = new ArrayList<>();
+    for (String labeledFragmentsStr: labeledFragmentsStrs) {
+      lfTokenizer.setReader(new StringReader(labeledFragmentsStr));
+      lfAnalyzer.consumeInputStream();
+      Document doc = makeDocument(lfAnalyzer);
+      docs.add(doc);
+    }
+    return docs;
+  }
+
+  List<Document> makeDocumentsLF(String[] labeledFragmentsStrs, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(lfTokenizer, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    return makeDocuments(labeledFragmentsStrs, lfTokenizer, lfAnalyzer);
+  }
+
+  List<Document> makeDocumentsLTF(String[] labeledFragmentsStrs, int numFragmentStreams) throws IOException {
+    Tokenizer lfTokenizer = new WhitespaceTokenizer();
+    LabeledTreeFragmentsAnalyzer ltfAnalyzer = new LabeledTreeFragmentsAnalyzer(
+                                                      lfTokenizer,
+                                                      ENDING_COLON_DOUBLE_BAR_DOUBLE_SEMI,
+                                                      numFragmentStreams,
+                                                      fieldSchema.getTreeInfoPayloadTermText());
+    return makeDocuments(labeledFragmentsStrs, lfTokenizer, ltfAnalyzer);
+  }
+
+  void tstSpansFromDocs(List<Document> docs, SpanQuery spanQuery, int[][] expSpansByDoc) throws IOException {
+    final Directory dir = new RAMDirectory();
+    final IndexWriterConfig config = new IndexWriterConfig(new MockAnalyzer(random()));
+    final IndexWriter w = new IndexWriter(dir, config);
+    for (Document doc: docs) {
+      w.addDocument(doc);
+    }
+    w.commit();
+    w.close();
+    LeafReader lr = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir)); // slow, but ok for testing
+
+    LeafReaderContext lrContext = lr.getContext();
+
+    SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(lr); // get the term contexts so getSpans can be called directly
+    HashSet<Term> termSet = new HashSet<>();
+    rewrittenQuery.extractTerms(termSet);
+    Map<Term,TermContext> termContexts = new HashMap<>();
+    for (Term term: termSet) {
+      TermContext termContext = TermContext.build(lrContext, term);
+      termContexts.put(term, termContext);
+    }
+
+    Spans actSpans = spanQuery.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()), termContexts);
+
+    assertEquals("expected spans present for each doc", docs.size(), expSpansByDoc.length);
+
+    if (actSpans == null) {
+      for (int[] expSpans : expSpansByDoc) {
+        assertEquals(0, expSpans.length);
+      }
+    } else {
+      int expDoc = 0;
+      while (expDoc < expSpansByDoc.length) {
+        int[] expSpans = expSpansByDoc[expDoc];
+        assertTrue("int[] expSpans should have even length", (expSpans.length % 2) == 0);
+        if (expSpans.length > 0) {
+          assertEquals("next doc", expDoc, actSpans.nextDoc());
+          int i = 0;
+          while (i < expSpans.length) {
+            assertEquals("spans start " + i, expSpans[i], actSpans.nextStartPosition());
+            i++;
+            assertEquals("spans end " + i, expSpans[i], actSpans.endPosition());
+            i++;
+          }
+          assertEquals("spans final start", Spans.NO_MORE_POSITIONS, actSpans.nextStartPosition());
+        }
+        expDoc++;
+      }
+      assertEquals("spans final doc", Spans.NO_MORE_DOCS, actSpans.nextDoc());
+    }
+
+    lr.close();
+    dir.close();
+  }
+
+  void tstSpansFromLabeledFragments(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocumentsLF(labeledFragmentsStrs, 1);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  void tstSpansFromLabeledTree(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocumentsLTF(labeledFragmentsStrs, 1);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  SpanTermQuery labelSTQ(String label) {
+    return new SpanTermQuery(new Term(fieldSchema.getLabelFieldName(), label));
+  }
+
+  SpanTermQuery fragmentSTQ(String fragmentTerm) {
+    return new SpanTermQuery(new Term(fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex), fragmentTerm));
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestChildLabelQuery.java	(working copy)
@@ -0,0 +1,71 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+
+public class TestChildLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstChildSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int childNum, int[][] expSpansByDoc)
+  throws IOException {
+    ChildLabelQuery clq = new ChildLabelQuery(labelSpanQuery, childNum, fieldSchema.getTreeInfoPayloadTermText());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.childLabelQuery(labelSpanQuery, childNum);
+    assertTrue(factoryRes.equals(clq));
+    tstSpansFromLabeledTree(labeledFragmentsStrs, clq, expSpansByDoc);
+  }
+
+  void tstChildSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int childNum, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstChildSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, childNum, new int[][]{expSpans});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), 0, new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstChildSpansFromLabelSpans("A: ;;", labelSTQ("A:"), 0, new int[]{});
+  }
+
+  public void testOneChildNotPresent() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), 0, new int[]{});
+  }
+
+  public void testOneChildPresent() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("A:"), 0, new int[]{1,2});
+  }
+
+  public void testTwoChildren1() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), 0, new int[]{1,2});
+  }
+
+  public void testTwoChildren2() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), 1, new int[]{2,3});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstChildSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("B:"), 0, new int[]{2,3});
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestDescendantsLabelQuery.java	(working copy)
@@ -0,0 +1,71 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+
+public class TestDescendantsLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstDescendantSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    boolean includeLabel = false;
+    DescendantsLabelQuery dlq = new DescendantsLabelQuery(labelSpanQuery, fieldSchema.getTreeInfoPayloadTermText(), includeLabel);
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = includeLabel ? pjqf.descendantsOrSelfLabelQuery(labelSpanQuery) : pjqf.descendantsLabelQuery(labelSpanQuery);
+    assertTrue(factoryRes.equals(dlq));
+    tstSpansFromLabeledTree(labeledFragmentsStrs, dlq, expSpansByDoc);
+  }
+
+  void tstDescendantSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstDescendantSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, new int[][]{expSpans});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: ;;", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testOneChildNotPresent() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), new int[]{});
+  }
+
+  public void testOneChildPresent() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("A:"), new int[]{1,2});
+  }
+
+  public void testOneChildPresent2() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("B:"), new int[]{2,3});
+  }
+
+  public void testTwoChildren() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("A:"), new int[]{1,3});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstDescendantSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("A:"), new int[]{1,3});
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentLabelFragment.java	(working copy)
@@ -0,0 +1,148 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.List;
+import java.util.ArrayList;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.analysis.label.LabeledFragmentsAnalyzer;
+
+import org.apache.lucene.util.Version;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.document.Document;
+
+import org.apache.lucene.search.spans.SpanQuery;
+
+public class TestFragmentLabelFragment extends LabeledFragmentsTestCase {
+  final int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", new Term("labelsToFragments2", "positions-" + Version.LATEST)); // add version until there is a real field for this
+
+  Field makeFragmentField2(LabeledFragmentsAnalyzer lfAnalyzer) {
+    return new TextField(fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex), lfAnalyzer.fragmentsTokenStream(secondFragmentFieldSchemaIndex));
+  }
+
+  Field makeFragmentPositionsField2(LabeledFragmentsAnalyzer lfAnalyzer) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(secondFragmentFieldSchemaIndex);
+    return new TextField(fpsTerm.field(), lfAnalyzer.fragmentPositionsTokenStream(secondFragmentFieldSchemaIndex, fpsTerm.text()));
+  }
+
+  Document makeDocument2(LabeledFragmentsAnalyzer lfAnalyzer) throws IOException {
+    Document doc = makeDocument(lfAnalyzer);
+    Field fragmentField2 = makeFragmentField2(lfAnalyzer);
+    doc.add(fragmentField2);
+    Field fragmentPositionsField2 = makeFragmentPositionsField2(lfAnalyzer);
+    doc.add(fragmentPositionsField2);
+    return doc;
+  }
+
+  List<Document> makeDocuments2(String[] labeledFragmentsStrs) throws IOException {
+    Tokenizer labeledFragments = new WhitespaceTokenizer();
+    int numFragmentStreams = 2;
+    LabeledFragmentsAnalyzer lfAnalyzer = new LabeledFragmentsAnalyzer(labeledFragments, ENDING_COLON_DOUBLE_BAR, numFragmentStreams);
+    List<Document> docs = new ArrayList<>();
+    for (String labeledFragmentsStr: labeledFragmentsStrs) {
+      labeledFragments.setReader(new StringReader(labeledFragmentsStr));
+      lfAnalyzer.consumeInputStream();
+      Document doc = makeDocument2(lfAnalyzer);
+      docs.add(doc);
+    }
+    return docs;
+  }
+
+  void tstSpansFromLabeledFragments2(String[] labeledFragmentsStrs, SpanQuery spanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    List<Document> docs = makeDocuments2(labeledFragmentsStrs);
+    tstSpansFromDocs(docs, spanQuery, expSpansByDoc);
+  }
+
+  FragmentToLabelQuery fragmentToLabelQuery(SpanQuery fragmentQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    FragmentToLabelQuery res = new FragmentToLabelQuery(fragmentQuery, fpsTerm, fieldSchema.getLabelFieldName());
+    return res;
+  }
+
+  LabelToFragmentQuery labelToFragment2Query(SpanQuery labelQuery) {
+    Term fpsTerm2 = fieldSchema.getFragmentPositionsPayloadTerm(secondFragmentFieldSchemaIndex);
+    return new LabelToFragmentQuery(labelQuery, fpsTerm2, fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex));
+  }
+
+  void tstFragment2SpansFromFragmentSpans(String[] labeledFragmentsStrs, SpanQuery fragmentSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    FragmentToLabelQuery ftlq = fragmentToLabelQuery(fragmentSpanQuery);
+    LabelToFragmentQuery ltf2q = labelToFragment2Query(ftlq);
+
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(fragmentSpanQuery, fieldSchema.getFragmentFieldName(secondFragmentFieldSchemaIndex));
+    assertTrue(factoryRes.equals(ltf2q));
+
+    tstSpansFromLabeledFragments2(labeledFragmentsStrs, ltf2q, expSpansByDoc);
+  }
+
+  void tstFragment2SpansFromFragmentSpans(String labeledFragmentsStr, SpanQuery fragmentSpanQuery, int[] expLabelSpans)
+  throws IOException {
+    // single doc
+    tstFragment2SpansFromFragmentSpans(new String[]{labeledFragmentsStr}, fragmentSpanQuery, new int[][]{expLabelSpans});
+  }
+
+  public void testTooManyFragments() throws IOException {
+    boolean ok = false;
+    try {
+      tstFragment2SpansFromFragmentSpans("A: || ||", fragmentSTQ("x"), new int[]{});
+    } catch (IllegalArgumentException iae) {
+      ok = true;
+    }
+    assertTrue("no IllegalArgumentException for too many fragments", ok);
+  }
+
+  public void testFLFNonPresentTerm() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 || a21 a22", fragmentSTQ("a1"), new int[]{});
+  }
+
+  public void testFLFPresentTerm1() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 || a21 a22", fragmentSTQ("a11"), new int[]{0,2});
+  }
+
+  public void testFLFPresentTerm2() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23", fragmentSTQ("a11"), new int[]{0,3});
+  }
+
+  public void testFLFPresentTerm3() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23", fragmentSTQ("a12"), new int[]{0,3});
+  }
+
+  public void testFLFPresentTerm4() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23  B: a12 || ", fragmentSTQ("a12"), new int[]{0,3}); // ignore empty B:
+  }
+
+  public void testFLFPresentTerm5() throws IOException {
+    tstFragment2SpansFromFragmentSpans("A: a11 a12 || a21 a22 a23  B: a13 || ", fragmentSTQ("a13"), new int[]{}); // ignore empty B:
+  }
+
+  public void testFLFPresentTermTwoDocs1() throws IOException {
+    tstFragment2SpansFromFragmentSpans(new String[]{"A: a11 || a21 a22","A: a11 a12 || a21 a22  B: a12 || a23"},
+                                        fragmentSTQ("a12"),
+                                        new int[][]{{},{0,2,2,3}});
+  }
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestFragmentToLabelQuery.java	(working copy)
@@ -0,0 +1,133 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+
+public class TestFragmentToLabelQuery extends LabeledFragmentsTestCase {
+
+  FragmentToLabelQuery fragmentToLabelQuery(SpanQuery fragmentQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    FragmentToLabelQuery res = new FragmentToLabelQuery(fragmentQuery, fpsTerm, fieldSchema.getLabelFieldName());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(fragmentQuery, fieldSchema.getLabelFieldName());
+    assertTrue(factoryRes.equals(res));
+    return res;
+  }
+
+  void tstLabelSpansFromFragmentSpans(String[] labeledFragmentsStrs, SpanQuery fragmentSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    FragmentToLabelQuery ftlq = fragmentToLabelQuery(fragmentSpanQuery);
+    tstSpansFromLabeledFragments(labeledFragmentsStrs, ftlq, expSpansByDoc);
+  }
+
+  void tstLabelSpansFromFragmentSpans(String labeledFragmentsStr, SpanQuery fragmentSpanQuery, int[] expLabelSpans)
+  throws IOException {
+    // single doc
+    tstLabelSpansFromFragmentSpans(new String[]{labeledFragmentsStr}, fragmentSpanQuery, new int[][]{expLabelSpans});
+  }
+
+  public void testEmptyFragment() throws IOException {
+    tstLabelSpansFromFragmentSpans("A:", fragmentSTQ("x"), new int[]{});
+  }
+
+  public void testOneFragmentPresentTerm1() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1", fragmentSTQ("a1"), new int[]{0,1});
+  }
+
+  public void testOneFragmentPresentTerm2() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2", fragmentSTQ("a1"), new int[]{0,1});
+  }
+
+  public void testOneFragmentPresentTerm3() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2", fragmentSTQ("a2"), new int[]{0,1});
+  }
+
+  public void testOneFragmentNonPresentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1", fragmentSTQ("a2"), new int[]{});
+  }
+
+  public void testTwoFragmentsOneLabel() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2", fragmentSTQ("b1"), new int[]{1,2});
+  }
+
+  public void testTwoFragmentsSameFragmentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 a2", fragmentSTQ("a2"), new int[]{0,1,1,2});
+  }
+
+  public void testTwoFragmentsTwoLabels() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2",
+                                  new SpanOrQuery(new SpanQuery[] { fragmentSTQ("a2"), fragmentSTQ("b1")}),
+                                  new int[]{0,1,1,2});
+  }
+
+  public void testLabelsForSpanNearOverFragments() throws IOException {
+    tstLabelSpansFromFragmentSpans("A: a1 a2 B: b1 b2",
+                                    new SpanNearQuery(new SpanQuery[] { fragmentSTQ("a2"), fragmentSTQ("b1")}, 1, false),
+                                    new int[]{0,2}); // "A: B:"
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchFragmentTerm() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[] {"A:","B:"}, fragmentSTQ("x"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsOneFragment1() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, fragmentSTQ("a2"), new int[][]{{0,1},{0,1}});
+  }
+
+  public void testTwoDocsOneFragment2() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, fragmentSTQ("a3"), new int[][]{{},{0,1}});
+  }
+
+  public void testTwoDocsOneFragment3() throws IOException {
+    tstLabelSpansFromFragmentSpans(new String[]{"A: a1 a2 a3", "A: a1 a2"}, fragmentSTQ("a3"), new int[][]{{0,1},{}});
+  }
+
+  public void testWithinLabelFieldBeforeFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentToLabelQuery(fragmentSTQ("a2")), labelSTQ("B:")} , 0, true),
+        new int[][]{{},{0,2}}); // "A: B:", a2 in fragment field of some label, directly followed by label B:
+  }
+
+  public void testWithinLabelFieldInFragment() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanContainingQuery(labelSTQ("B:"), fragmentToLabelQuery(fragmentSTQ("b1"))),
+        new int[][]{{},{1,2}}); // "B:", B: label containing b1 in fragment
+  }
+
+
+  public void testNotWithinLabelFieldInFragment() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanContainingQuery(fragmentToLabelQuery(fragmentSTQ("a2")), labelSTQ("B:")),
+        new int[][]{{},{}}); // label for fragment with a2 nowhere in label field for label B:
+  }
+
+  public void testWithinFragmentFieldAtLabelEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 a2"},
+        new SpanNearQuery(new SpanQuery[] { labelSTQ("A:"), fragmentToLabelQuery(fragmentSTQ("b1")) }, 0, true),
+    new int[][]{{},{0,2}}); // "A: B:" label A: immediately followed by labelof fragment containing b1
+  }
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestLabelToFragmentQuery.java	(working copy)
@@ -0,0 +1,128 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
+
+public class TestLabelToFragmentQuery extends LabeledFragmentsTestCase {
+
+  LabelToFragmentQuery labelToFragmentQuery(SpanQuery labelQuery) {
+    Term fpsTerm = fieldSchema.getFragmentPositionsPayloadTerm(firstFragmentFieldSchemaIndex);
+    LabelToFragmentQuery res = new LabelToFragmentQuery(labelQuery, fpsTerm, fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex));
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.positionalJoin(labelQuery, fieldSchema.getFragmentFieldName(firstFragmentFieldSchemaIndex));
+    assertTrue(factoryRes.equals(res));
+    return res;
+  }
+
+  void tstFragmentSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    LabelToFragmentQuery ltfq = labelToFragmentQuery(labelSpanQuery);
+    tstSpansFromLabeledFragments(labeledFragmentsStrs, ltfq, expSpansByDoc);
+  }
+
+  void tstFragmentSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expFragmentSpans)
+  throws IOException {
+    // single doc
+    tstFragmentSpansFromLabelSpans(new String[]{labeledFragmentsStr}, labelSpanQuery, new int[][]{expFragmentSpans});
+  }
+
+  public void testEmptyFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans("A:", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testOneFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2", labelSTQ("A:"), new int[]{0,2});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2", labelSTQ("B:"), new int[]{});
+  }
+
+  public void testTwoFragmentsOneLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2", labelSTQ("B:"), new int[]{2,4});
+  }
+
+  public void testTwoFragmentsSameLabel() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 A: b1 b2", labelSTQ("A:"), new int[]{0,2,2,4});
+  }
+
+  public void testTwoFragmentsTwoLabels() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2",
+                                  new SpanOrQuery(new SpanQuery[] { labelSTQ("A:"), labelSTQ("B:")}),
+                                  new int[]{0,2,2,4});
+  }
+
+  public void testFragmentsForSpanNearLabels() throws IOException {
+    tstFragmentSpansFromLabelSpans("A: a1 a2 B: b1 b2",
+                                    new SpanNearQuery(new SpanQuery[] { labelSTQ("A:"), labelSTQ("B:")}, 1, false),
+                                    new int[]{0,4}); // "a1 a2 b1 b2"
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchLabel1() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[] {"A:","B:"}, labelSTQ("A:"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsEmptyFragmentNoSuchLabel2() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[] {"A:","B:"}, labelSTQ("B:"), new int[][]{{},{}});
+  }
+
+  public void testTwoDocsOneFragment() throws IOException {
+    tstFragmentSpansFromLabelSpans(new String[]{"A: a1 a2", "A: a1 a2 a3"}, labelSTQ("A:"), new int[][]{{0,2},{0,3}});
+  }
+
+  public void testWithinFragmentFieldBeforeFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanNearQuery(new SpanQuery[] { fragmentSTQ("a2"), labelToFragmentQuery(labelSTQ("B:"))} , 0, true),
+        new int[][]{{},{1,4}}); // "a2 b1 b2", a2 in fragment field directly followed by label B:
+  }
+
+  public void testWithinFragmentFieldInFragmentAtStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanContainingQuery(labelToFragmentQuery(labelSTQ("B:")), fragmentSTQ("b1")),
+        new int[][]{{},{2,4}}); // "b1 b2", b1 in fragment field for label B:
+  }
+
+  public void testWithinFragmentFieldInFragmentAtEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanContainingQuery(labelToFragmentQuery(labelSTQ("B:")), fragmentSTQ("b2")),
+        new int[][]{{},{2,4}}); // "b1 b2", b2 in fragment field for label B:
+  }
+
+  public void testNotWithinFragmentFieldAtFragmentStart() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanWithinQuery(labelToFragmentQuery(labelSTQ("B:")), fragmentSTQ("a2")),
+        new int[][]{{},{}}); // a2 nowhere in fragment field for label B:
+  }
+
+  public void testNoWithinFragmentFieldAtFragmentEnd() throws IOException {
+    tstSpansFromLabeledFragments(new String[]{"A: a1 a2 a3", "A: a1 a2 B: b1 b2"},
+        new SpanWithinQuery(labelToFragmentQuery(labelSTQ("A:")), fragmentSTQ("b1")),
+        new int[][]{{},{}}); // b1 nowhere in fragment field for label A:
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestParentLabelQuery.java	(working copy)
@@ -0,0 +1,78 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+
+public class TestParentLabelQuery extends LabeledFragmentsTestCase {
+
+  void tstParentSpansFromLabelSpans(String[] labeledFragmentsStrs, SpanQuery labelSpanQuery, int[][] expSpansByDoc)
+  throws IOException {
+    ParentLabelQuery plq = new ParentLabelQuery(labelSpanQuery, fieldSchema.getTreeInfoPayloadTermText());
+    // test PositionalJoinQueryFactory:
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+    SpanQuery factoryRes = pjqf.parentLabelQuery(labelSpanQuery);
+    assertTrue(factoryRes.equals(plq));
+
+    tstSpansFromLabeledTree(labeledFragmentsStrs, plq, expSpansByDoc);
+  }
+
+  void tstParentSpansFromLabelSpans(String labeledFragmentsStr, SpanQuery labelSpanQuery, int[] expSpans)
+  throws IOException {
+    // single doc
+    tstParentSpansFromLabelSpans(new String[] {labeledFragmentsStr}, labelSpanQuery, new int[][]{expSpans});
+  }
+
+  public void testUnclosedLabel() throws IOException {
+    tstParentSpansFromLabelSpans("A:", labelSTQ("A:"), new int[]{});
+  }
+
+  public void testNoSuchLabel() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("C:"), new int[]{});
+  }
+
+  public void testRootOnly() throws IOException {
+    tstParentSpansFromLabelSpans("A: ;;", labelSTQ("A:"), new int[]{0,1});
+  }
+
+  public void testOneChild() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; ;;", labelSTQ("B:"), new int[]{0,1});
+  }
+
+  public void testTwoChildren1() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("B:"), new int[]{0,1});
+  }
+
+  public void testTwoChildren2() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: ;; C: ;; ;;", labelSTQ("C:"), new int[]{0,1});
+  }
+
+  public void testGrandChild() throws IOException {
+    tstParentSpansFromLabelSpans("A: B: C: ;; ;; ;;", labelSTQ("C:"), new int[]{1,2});
+  }
+
+  public void testTwoDocsChildGrandChild() throws IOException {
+    // test indexing more than one document.
+    // test TreeInfo.reInit by label present in both docs.
+    tstParentSpansFromLabelSpans(new String[] {"B: A: ;; ;;", "A: C: B: ;; ;; ;;"}, labelSTQ("B:"), new int[][]{{0,1},{1,2}});
+  }
+
+}
Index: lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/search/spans/label/TestPositionalJoinQueryFactory.java	(working copy)
@@ -0,0 +1,44 @@
+package org.apache.lucene.search.spans.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.document.label.LabelFieldSchema;
+
+import org.apache.lucene.index.Term;
+
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+
+public class TestPositionalJoinQueryFactory extends LabeledFragmentsTestCase {
+
+  public void testSharedPositions() { // other normal cases tested elsewhere in this package
+    LabelFieldSchema fieldSchema = new LabelFieldSchema("labelField", "treeInfoPayloadTerm");
+    Term fragmentPositionsPayloadTerm1 = new Term("labelToFragment", "positions");
+    Term fragmentPositionsPayloadTerm2 = new Term("labelToFragment", "positions"); // equal terms
+    int firstFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments1", fragmentPositionsPayloadTerm1);
+    int secondFragmentFieldSchemaIndex = fieldSchema.addLabeledFragmentField("fragments2", fragmentPositionsPayloadTerm2);
+    PositionalJoinQueryFactory pjqf = new PositionalJoinQueryFactory(fieldSchema);
+
+    SpanTermQuery stq = new SpanTermQuery(new Term("fragments1", "value1"));
+    SpanQuery factoryRes = pjqf.positionalJoin(stq, "fragments2");
+    assertTrue(factoryRes instanceof FieldMaskingSpanQuery);
+  }
+}
Index: lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java
===================================================================
--- lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java	(revision 0)
+++ lucene/label/src/test/org/apache/lucene/util/packed/label/TestLongsInBytes.java	(working copy)
@@ -0,0 +1,45 @@
+package org.apache.lucene.util.packed.label;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestLongsInBytes extends LuceneTestCase {
+  public void testSingleOnes() {
+    for (int index = 0; index < Byte.SIZE; index++) {
+      for (int numBits = 1; numBits < Long.SIZE; numBits++) {
+        byte[] bytes = new byte[numBits];
+        long value = 1;
+        int offset = 0;
+        LongsInBytes.packValue(value, numBits, index, bytes, 0);
+        assertEquals(value, LongsInBytes.unPackValue(numBits, index, bytes, 0));
+      }
+    }
+  }
+  public void testAllOnes() {
+    for (int index = 0; index < Byte.SIZE; index++) {
+      for (int numBits = 1; numBits < Long.SIZE; numBits++) {
+        byte[] bytes = new byte[numBits];
+        long value = ~(-1L << numBits);
+        int offset = 0;
+        LongsInBytes.packValue(value, numBits, index, bytes, 0);
+        assertEquals(value, LongsInBytes.unPackValue(numBits, index, bytes, 0));
+      }
+    }
+  }
+}
Index: lucene/module-build.xml
===================================================================
--- lucene/module-build.xml	(revision 1681580)
+++ lucene/module-build.xml	(working copy)
@@ -138,8 +138,19 @@
   <target name="jar-join" unless="join.uptodate" depends="check-join-uptodate">
     <ant dir="${common.dir}/join" target="jar-core" inheritAll="false">
       <propertyset refid="uptodate.and.compiled.properties"/>
-	</ant>
-	<property name="join.uptodate" value="true"/>
+    </ant>
+    <property name="join.uptodate" value="true"/>
+  </target>
+
+  <property name="label.jar" value="${common.dir}/build/join/lucene-label-${version}.jar"/>
+  <target name="check-label-uptodate" unless="label.uptodate">
+    <module-uptodate name="label" jarfile="${label.jar}" property="label.uptodate"/>
+  </target>
+  <target name="jar-label" unless="label.uptodate" depends="check-label-uptodate">
+    <ant dir="${common.dir}/label" target="jar-core" inheritAll="false">
+      <propertyset refid="uptodate.and.compiled.properties"/>
+    </ant>
+    <property name="label.uptodate" value="true"/>
   </target>	
   
   <property name="analyzers-common.jar" value="${common.dir}/build/analysis/common/lucene-analyzers-common-${version}.jar"/>
Index: lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java	(revision 1681580)
+++ lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java	(working copy)
@@ -38,7 +38,7 @@
   }
 
   @Override
-  protected void extractTerms(Set<Term> terms) {
+  public void extractTerms(Set<Term> terms) {
     in.extractTerms(terms);
   }
 
