Index: src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(revision 887482)
+++ src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(working copy)
@@ -256,8 +256,8 @@
     // System.out.println("modifyNormsForF1 maxDoc: "+n);
     for (int i = 0; i < n; i += 3) { // modify for every third doc
       int k = (i * 3) % modifiedNorms.size();
-      float origNorm = ((Float) modifiedNorms.get(i)).floatValue();
-      float newNorm = ((Float) modifiedNorms.get(k)).floatValue();
+      float origNorm =  modifiedNorms.get(i).floatValue();
+      float newNorm =  modifiedNorms.get(k).floatValue();
       // System.out.println("Modifying: for "+i+" from "+origNorm+" to
       // "+newNorm);
       // System.out.println(" and: for "+k+" from "+newNorm+" to "+origNorm);
Index: src/test/org/apache/lucene/store/MockRAMDirectory.java
===================================================================
--- src/test/org/apache/lucene/store/MockRAMDirectory.java	(revision 887482)
+++ src/test/org/apache/lucene/store/MockRAMDirectory.java	(working copy)
@@ -229,7 +229,7 @@
       throw new FileNotFoundException(name);
     else {
       if (openFiles.containsKey(name)) {
-        Integer v = (Integer) openFiles.get(name);
+        Integer v =  openFiles.get(name);
         v = Integer.valueOf(v.intValue()+1);
         openFiles.put(name, v);
       } else {
@@ -331,7 +331,7 @@
   synchronized void maybeThrowDeterministicException() throws IOException {
     if (failures != null) {
       for(int i = 0; i < failures.size(); i++) {
-        ((Failure)failures.get(i)).eval(this);
+        failures.get(i).eval(this);
       }
     }
   }
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java	(revision 887482)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java	(working copy)
@@ -146,7 +146,7 @@
   }
 
   public void testBoostsSimple() throws Exception {
-    Map boosts = new HashMap();
+    Map<CharSequence,Float> boosts = new HashMap<CharSequence,Float>();
     boosts.put("b", Float.valueOf(5));
     boosts.put("t", Float.valueOf(10));
     String[] fields = { "b", "t" };
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(revision 887482)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(working copy)
@@ -89,7 +89,7 @@
 public class TestQPHelper extends LocalizedTestCase {
 
   public TestQPHelper(String name) {
-    super(name, new HashSet(Arrays.asList(new String[]{
+    super(name, new HashSet<String>(Arrays.asList(new String[]{
       "testLegacyDateRange", "testDateRange",
       "testCJK", "testNumber", "testFarsiRangeCollating",
       "testLocalDateFormat"
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java	(revision 887482)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java	(working copy)
@@ -141,7 +141,7 @@
   }
 
   public void testBoostsSimple() throws Exception {
-    Map boosts = new HashMap();
+    Map<CharSequence,Float> boosts = new HashMap<CharSequence,Float>();
     boosts.put("b", Float.valueOf(5));
     boosts.put("t", Float.valueOf(10));
     String[] fields = { "b", "t" };
Index: contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
===================================================================
--- contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(revision 887482)
+++ contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(working copy)
@@ -84,7 +84,7 @@
 public class TestQueryParserWrapper extends LocalizedTestCase {
 
   public TestQueryParserWrapper(String name) {
-    super(name, new HashSet(Arrays.asList(new String[]{
+    super(name, new HashSet<String>(Arrays.asList(new String[]{
       "testLegacyDateRange", "testDateRange",
       "testCJK", "testNumber", "testFarsiRangeCollating",
       "testLocalDateFormat"
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java	(revision 887482)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java	(working copy)
@@ -195,7 +195,7 @@
   }
 
   @Override
-  public Collection getFieldNames(FieldOption fieldOption) {
+  public Collection<String> getFieldNames(FieldOption fieldOption) {
     Set<String> fieldSet = new HashSet<String>();
     for (FieldSetting fi : index.getFieldSettings().values()) {
       if (fieldOption == IndexReader.FieldOption.ALL) {
Index: contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java
===================================================================
--- contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java	(revision 887482)
+++ contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java	(working copy)
@@ -444,12 +444,11 @@
     // Run algo
     Benchmark benchmark = execBenchmark(algLines1);
 
-    List stats = benchmark.getRunData().getPoints().taskStats();
+    List<TaskStats> stats = benchmark.getRunData().getPoints().taskStats();
 
     // Count how many tokens all ReadTokens saw
     int totalTokenCount1 = 0;
-    for (Iterator it = stats.iterator(); it.hasNext();) {
-      TaskStats stat = (TaskStats) it.next();
+    for (final TaskStats stat : stats) {
       if (stat.getTask().getName().equals("ReadTokens")) {
         totalTokenCount1 += stat.getCount();
       }
@@ -809,8 +808,7 @@
     // 3. test counters
     int n = disable ? 0 : 1;
     int nChecked = 0;
-    for (Iterator ts = benchmark.getRunData().getPoints().taskStats().iterator(); ts.hasNext();) {
-      TaskStats stats = (TaskStats) ts.next();
+    for (final TaskStats stats : benchmark.getRunData().getPoints().taskStats()) {
       String taskName = stats.getTask().getName();
       if (taskName.equals("Rounds")) {
         assertEquals("Wrong total count!",20+2*n,stats.getCount());
Index: contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksParse.java
===================================================================
--- contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksParse.java	(revision 887482)
+++ contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksParse.java	(working copy)
@@ -49,10 +49,9 @@
     String parsedTasks = "[ "+taskStr+" ] : 1000";
     Benchmark benchmark = new Benchmark(new StringReader(propPart+parsedTasks));
     Algorithm alg = benchmark.getAlgorithm();
-    ArrayList algTasks = alg.extractTasks();
+    ArrayList<PerfTask> algTasks = alg.extractTasks();
     boolean foundAdd = false;
-    for (Iterator iter = algTasks.iterator(); iter.hasNext();) {
-       PerfTask task = (PerfTask) iter.next();
+    for (final PerfTask task : algTasks) {
        if (task.toString().indexOf(taskStr)>=0) {
           foundAdd = true;
        }
@@ -70,10 +69,9 @@
     String parsedTasks = "{ "+taskStr+" } : 1000";
     Benchmark benchmark = new Benchmark(new StringReader(propPart+parsedTasks));
     Algorithm alg = benchmark.getAlgorithm();
-    ArrayList algTasks = alg.extractTasks();
+    ArrayList<PerfTask> algTasks = alg.extractTasks();
     boolean foundAdd = false;
-    for (Iterator iter = algTasks.iterator(); iter.hasNext();) {
-       PerfTask task = (PerfTask) iter.next();
+    for (final PerfTask task : algTasks) {
        if (task.toString().indexOf(taskStr)>=0) {
           foundAdd = true;
        }
Index: contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java
===================================================================
--- contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java	(revision 887482)
+++ contrib/misc/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java	(working copy)
@@ -90,7 +90,7 @@
 
     Query q = qp.parse(qString);
 
-    HashSet expecteds = new HashSet();
+    HashSet<String> expecteds = new HashSet<String>();
     String[] vals = expectedVals.split(",");
     for (int i = 0; i < vals.length; i++) {
       if (vals[i].length() > 0)
Index: contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
===================================================================
--- contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java	(revision 887482)
+++ contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java	(working copy)
@@ -49,7 +49,7 @@
 public class TestPrecedenceQueryParser extends LocalizedTestCase {
   
   public TestPrecedenceQueryParser(String name) {
-    super(name, new HashSet(Arrays.asList(new String[]{
+    super(name, new HashSet<String>(Arrays.asList(new String[]{
       "testDateRange", "testNumber"
     })));
   }
Index: contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 887482)
+++ contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -978,12 +978,12 @@
         WeightedSpanTerm[] wTerms = new WeightedSpanTerm[2];
         wTerms[0] = new WeightedSpanTerm(10f, "hello");
 
-        List positionSpans = new ArrayList();
+        List<PositionSpan> positionSpans = new ArrayList<PositionSpan>();
         positionSpans.add(new PositionSpan(0, 0));
         wTerms[0].addPositionSpans(positionSpans);
 
         wTerms[1] = new WeightedSpanTerm(1f, "kennedy");
-        positionSpans = new ArrayList();
+        positionSpans = new ArrayList<PositionSpan>();
         positionSpans.add(new PositionSpan(14, 14));
         wTerms[1].addPositionSpans(positionSpans);
 
@@ -1021,7 +1021,7 @@
 
       @Override
       public void run() throws Exception {
-        HashMap synonyms = new HashMap();
+        HashMap<String,String> synonyms = new HashMap<String,String>();
         synonyms.put("football", "soccer,footie");
         Analyzer analyzer = new SynonymAnalyzer(synonyms);
         String srchkey = "football";
@@ -1139,7 +1139,7 @@
       @Override
       public void run() throws Exception {
         String goodWord = "goodtoken";
-        Set stopWords = new HashSet(1);
+        Set<String> stopWords = new HashSet<String>(1);
         stopWords.add("stoppedtoken");
 
         TermQuery query = new TermQuery(new Term("data", goodWord));
@@ -1184,7 +1184,7 @@
     TestHighlightRunner helper = new TestHighlightRunner() {
       @Override
       public void run() throws Exception {
-        Set stopWords = new HashSet();
+        Set<String> stopWords = new HashSet<String>();
         stopWords.add("in");
         stopWords.add("it");
         TermQuery query = new TermQuery(new Term("text", "searchterm"));
@@ -1425,8 +1425,8 @@
   protected TokenStream getTS2() {
     // String s = "Hi-Speed10 foo";
     return new TokenStream() {
-      Iterator iter;
-      List lst;
+      Iterator<Token> iter;
+      List<Token> lst;
       private TermAttribute termAtt;
       private PositionIncrementAttribute posIncrAtt;
       private OffsetAttribute offsetAtt;
@@ -1434,7 +1434,7 @@
         termAtt = addAttribute(TermAttribute.class);
         posIncrAtt = addAttribute(PositionIncrementAttribute.class);
         offsetAtt = addAttribute(OffsetAttribute.class);
-        lst = new ArrayList();
+        lst = new ArrayList<Token>();
         Token t;
         t = createToken("hi", 0, 2);
         t.setPositionIncrement(1);
@@ -1457,7 +1457,7 @@
       @Override
       public boolean incrementToken() throws IOException {
         if(iter.hasNext()) {
-          Token token = (Token) iter.next();
+          Token token =  iter.next();
           termAtt.setTermBuffer(token.term());
           posIncrAtt.setPositionIncrement(token.getPositionIncrement());
           offsetAtt.setOffset(token.startOffset(), token.endOffset());
@@ -1473,8 +1473,8 @@
   protected TokenStream getTS2a() {
     // String s = "Hi-Speed10 foo";
     return new TokenStream() {
-      Iterator iter;
-      List lst;
+      Iterator<Token> iter;
+      List<Token> lst;
       private TermAttribute termAtt;
       private PositionIncrementAttribute posIncrAtt;
       private OffsetAttribute offsetAtt;
@@ -1482,7 +1482,7 @@
         termAtt = addAttribute(TermAttribute.class);
         posIncrAtt = addAttribute(PositionIncrementAttribute.class);
         offsetAtt = addAttribute(OffsetAttribute.class);
-        lst = new ArrayList();
+        lst = new ArrayList<Token>();
         Token t;
         t = createToken("hispeed", 0, 8);
         t.setPositionIncrement(1);
@@ -1505,7 +1505,7 @@
       @Override
       public boolean incrementToken() throws IOException {
         if(iter.hasNext()) {
-          Token token = (Token) iter.next();
+          Token token = iter.next();
           termAtt.setTermBuffer(token.term());
           posIncrAtt.setPositionIncrement(token.getPositionIncrement());
           offsetAtt.setOffset(token.startOffset(), token.endOffset());
@@ -1785,9 +1785,9 @@
 // ===================================================================
 
 class SynonymAnalyzer extends Analyzer {
-  private Map synonyms;
+  private Map<String,String> synonyms;
 
-  public SynonymAnalyzer(Map synonyms) {
+  public SynonymAnalyzer(Map<String,String> synonyms) {
     this.synonyms = synonyms;
   }
 
@@ -1815,7 +1815,7 @@
   private TokenStream realStream;
   private Token currentRealToken = null;
   private org.apache.lucene.analysis.Token cRealToken = null;
-  private Map synonyms;
+  private Map<String,String> synonyms;
   StringTokenizer st = null;
   private TermAttribute realTermAtt;
   private PositionIncrementAttribute realPosIncrAtt;
@@ -1824,7 +1824,7 @@
   private PositionIncrementAttribute posIncrAtt;
   private OffsetAttribute offsetAtt;
 
-  public SynonymTokenizer(TokenStream realStream, Map synonyms) {
+  public SynonymTokenizer(TokenStream realStream, Map<String,String> synonyms) {
     this.realStream = realStream;
     this.synonyms = synonyms;
     realTermAtt = realStream.addAttribute(TermAttribute.class);
@@ -1849,7 +1849,7 @@
       offsetAtt.setOffset(realOffsetAtt.startOffset(), realOffsetAtt.endOffset());
       posIncrAtt.setPositionIncrement(realPosIncrAtt.getPositionIncrement());
 
-      String expansions = (String) synonyms.get(realTermAtt.term());
+      String expansions =  synonyms.get(realTermAtt.term());
       if (expansions == null) {
         return true;
       }
Index: contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
===================================================================
--- contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java	(revision 887482)
+++ contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java	(working copy)
@@ -274,7 +274,7 @@
     boolean toLowerCase = true;
 //    boolean toLowerCase = false;
 //    Set stopWords = null;
-    Set stopWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
+    Set<?> stopWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
     
     Analyzer[] analyzers = new Analyzer[] { 
         new SimpleAnalyzer(),
@@ -380,7 +380,7 @@
   private String[] readLines(File file) throws Exception {
     BufferedReader reader = new BufferedReader(new InputStreamReader(
         new FileInputStream(file))); 
-    List lines = new ArrayList();
+    List<String> lines = new ArrayList<String>();
     String line;  
     while ((line = reader.readLine()) != null) {
       String t = line.trim(); 
@@ -493,7 +493,7 @@
   
   /** returns all files matching the given file name patterns (quick n'dirty) */
   static String[] listFiles(String[] fileNames) {
-    LinkedHashSet allFiles = new LinkedHashSet();
+    LinkedHashSet<String> allFiles = new LinkedHashSet<String>();
     for (int i=0; i < fileNames.length; i++) {
       int k;
       if ((k = fileNames[i].indexOf("*")) < 0) {
Index: contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
===================================================================
--- contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(revision 887482)
+++ contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(working copy)
@@ -197,8 +197,8 @@
    */
   private static final Comparator termComparator = new Comparator() {
     public int compare(Object o1, Object o2) {
-      if (o1 instanceof Map.Entry) o1 = ((Map.Entry) o1).getKey();
-      if (o2 instanceof Map.Entry) o2 = ((Map.Entry) o2).getKey();
+      if (o1 instanceof Map.Entry<?,?>) o1 = ((Map.Entry<?,?>) o1).getKey();
+      if (o2 instanceof Map.Entry<?,?>) o2 = ((Map.Entry<?,?>) o2).getKey();
       if (o1 == o2) return 0;
       return ((String) o1).compareTo((String) o2);
     }
Index: contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
===================================================================
--- contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java	(revision 887482)
+++ contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java	(working copy)
@@ -81,7 +81,7 @@
 	public void testDefaultFilter() throws Throwable
 	{
 		DuplicateFilter df=new DuplicateFilter(KEY_FIELD);		
-		HashSet results=new HashSet();
+		HashSet<String> results=new HashSet<String>();
 		ScoreDoc[] hits = searcher.search(tq,df, 1000).scoreDocs;
 		for(int i=0;i<hits.length;i++)
 		{
@@ -93,7 +93,7 @@
 	}
 	public void testNoFilter() throws Throwable
 	{
-		HashSet results=new HashSet();
+		HashSet<String> results=new HashSet<String>();
 		ScoreDoc[] hits = searcher.search(tq, null, 1000).scoreDocs;
 		assertTrue("Default searching should have found some matches",hits.length>0);
 		boolean dupsFound=false;
@@ -112,7 +112,7 @@
 	{
 		DuplicateFilter df=new DuplicateFilter(KEY_FIELD);
 		df.setProcessingMode(DuplicateFilter.PM_FAST_INVALIDATION);
-		HashSet results=new HashSet();
+		HashSet<String> results=new HashSet<String>();
 		ScoreDoc[] hits = searcher.search(tq,df, 1000).scoreDocs;
 		assertTrue("Filtered searching should have found some matches",hits.length>0);
 		for(int i=0;i<hits.length;i++)
Index: contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
===================================================================
--- contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java	(revision 887482)
+++ contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java	(working copy)
@@ -38,7 +38,7 @@
 		TermsFilter a=new TermsFilter();
 		a.addTerm(new Term("field1","a"));
 		a.addTerm(new Term("field1","b"));
-		HashSet cachedFilters=new HashSet();
+		HashSet<Filter> cachedFilters=new HashSet<Filter>();
 		cachedFilters.add(a);
 		TermsFilter b=new TermsFilter();
 		b.addTerm(new Term("field1","a"));
Index: contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
===================================================================
--- contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java	(revision 887482)
+++ contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java	(working copy)
@@ -71,7 +71,7 @@
     }
 
     public void testBoostFactor() throws Throwable {
-	Map originalValues = getOriginalValues();
+	Map<String,Float> originalValues = getOriginalValues();
 
 	MoreLikeThis mlt = new MoreLikeThis(
 		reader);
@@ -88,13 +88,13 @@
 
 	BooleanQuery query = (BooleanQuery) mlt.like(new StringReader(
 		"lucene release"));
-	List clauses = query.clauses();
+	List<BooleanClause> clauses = query.clauses();
 
 	assertEquals("Expected " + originalValues.size() + " clauses.",
 		originalValues.size(), clauses.size());
 
 	for (int i = 0; i < clauses.size(); i++) {
-	    BooleanClause clause = (BooleanClause) clauses.get(i);
+	    BooleanClause clause =  clauses.get(i);
 	    TermQuery tq = (TermQuery) clause.getQuery();
 	    Float termBoost = (Float) originalValues.get(tq.getTerm().text());
 	    assertNotNull("Expected term " + tq.getTerm().text(), termBoost);
@@ -106,8 +106,8 @@
 	}
     }
 
-    private Map getOriginalValues() throws IOException {
-	Map originalValues = new HashMap();
+    private Map<String,Float> getOriginalValues() throws IOException {
+	Map<String,Float> originalValues = new HashMap<String,Float>();
 	MoreLikeThis mlt = new MoreLikeThis(reader);
 	mlt.setMinDocFreq(1);
 	mlt.setMinTermFreq(1);
@@ -116,10 +116,10 @@
 	mlt.setBoost(true);
 	BooleanQuery query = (BooleanQuery) mlt.like(new StringReader(
 		"lucene release"));
-	List clauses = query.clauses();
+	List<BooleanClause> clauses = query.clauses();
 
 	for (int i = 0; i < clauses.size(); i++) {
-	    BooleanClause clause = (BooleanClause) clauses.get(i);
+	    BooleanClause clause = clauses.get(i);
 	    TermQuery tq = (TermQuery) clause.getQuery();
 	    originalValues.put(tq.getTerm().text(), Float.valueOf(tq.getBoost()));
 	}
Index: contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
===================================================================
--- contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java	(revision 887482)
+++ contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java	(working copy)
@@ -70,7 +70,7 @@
 		FuzzyLikeThisQuery flt=new FuzzyLikeThisQuery(10,analyzer);
 		flt.addTerms("smith", "name", 0.3f, 1);
 		Query q=flt.rewrite(searcher.getIndexReader());
-		HashSet queryTerms=new HashSet();
+		HashSet<Term> queryTerms=new HashSet<Term>();
 		q.extractTerms(queryTerms);
 		assertTrue("Should have variant smythe",queryTerms.contains(new Term("name","smythe")));
 		assertTrue("Should have variant smith",queryTerms.contains(new Term("name","smith")));
@@ -87,7 +87,7 @@
 		FuzzyLikeThisQuery flt=new FuzzyLikeThisQuery(10,analyzer);
 		flt.addTerms("jonathin smoth", "name", 0.3f, 1);
 		Query q=flt.rewrite(searcher.getIndexReader());
-		HashSet queryTerms=new HashSet();
+		HashSet<Term> queryTerms=new HashSet<Term>();
 		q.extractTerms(queryTerms);
 		assertTrue("Should have variant jonathan",queryTerms.contains(new Term("name","jonathan")));
 		assertTrue("Should have variant smith",queryTerms.contains(new Term("name","smith")));
@@ -103,7 +103,7 @@
 		FuzzyLikeThisQuery flt=new FuzzyLikeThisQuery(10,analyzer);
 		flt.addTerms("fernando smith", "name", 0.3f, 1);
 		Query q=flt.rewrite(searcher.getIndexReader());
-		HashSet queryTerms=new HashSet();
+		HashSet<Term> queryTerms=new HashSet<Term>();
 		q.extractTerms(queryTerms);
 		assertTrue("Should have variant smith",queryTerms.contains(new Term("name","smith")));
 		TopDocs topDocs = searcher.search(flt, 1);
