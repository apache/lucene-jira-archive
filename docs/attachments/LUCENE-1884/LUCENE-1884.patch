Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java	(working copy)
@@ -22,9 +22,11 @@
 import org.apache.lucene.util.AttributeSource;
 
 /**
+ * Tokenizer that breaks text into runs of letters and diacritics.
+ * <p>
  * The problem with the standard Letter tokenizer is that it fails on diacritics.
  * Handling similar to this is necessary for Indic Scripts, Hebrew, Thaana, etc.
- * 
+ * </p>
  *
  */
 public class ArabicLetterTokenizer extends LetterTokenizer {
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java	(working copy)
@@ -36,7 +36,7 @@
 	}
 
 	/**
-	 * Stemms the given term to an unique <tt>discriminator</tt>.
+	 * Stems the given term to an unique <tt>discriminator</tt>.
 	 *
 	 * @param term  The term that should be stemmed.
 	 * @return      Discriminator for <tt>term</tt>
@@ -115,7 +115,7 @@
 	/**
 	 * Gets R1
    *
-   * R1 - is the region after the first non-vowel follwing a vowel,
+   * R1 - is the region after the first non-vowel following a vowel,
    *      or is the null region at the end of the word if there is
    *      no such non-vowel.
    *
@@ -159,13 +159,13 @@
 	/**
 	 * Gets RV
    *
-   * RV - IF the second letter is a consoant, RV is the region after
+   * RV - IF the second letter is a consonant, RV is the region after
    *      the next following vowel,
    *
    *      OR if the first two letters are vowels, RV is the region
-   *      after the next consoant,
+   *      after the next consonant,
    *
-   *      AND otherwise (consoant-vowel case) RV is the region after
+   *      AND otherwise (consonant-vowel case) RV is the region after
    *      the third letter.
    *
    *      BUT RV is the end of the word if this positions cannot be
@@ -184,7 +184,7 @@
 
     i = value.length()-1 ;
 
-    // RV - IF the second letter is a consoant, RV is the region after
+    // RV - IF the second letter is a consonant, RV is the region after
     //      the next following vowel,
     if ((i > 0) && !isVowel(value.charAt(1))) {
       // find 1st vowel
@@ -201,7 +201,7 @@
 
 
     // RV - OR if the first two letters are vowels, RV is the region
-    //      after the next consoant,
+    //      after the next consonant,
     if ((i > 1) &&
         isVowel(value.charAt(0)) &&
         isVowel(value.charAt(1))) {
@@ -217,7 +217,7 @@
       }
     }
 
-    // RV - AND otherwise (consoant-vowel case) RV is the region after
+    // RV - AND otherwise (consonant-vowel case) RV is the region after
     //      the third letter.
     if (i > 2) {
       return value.substring(3) ;
@@ -394,7 +394,7 @@
 
 
 	/**
-	 * Standart suffix removal.
+	 * Standard suffix removal.
    * Search for the longest among the following suffixes, and perform
    * the following actions:
    *
@@ -403,12 +403,12 @@
 	private boolean step1() {
     if (CT == null) return false ;
 
-    // suffix lenght = 7
+    // suffix length = 7
     if (suffix(CT,"uciones") && suffix(R2,"uciones")) {
         CT = replaceSuffix(CT,"uciones","u") ; return true;
     }
 
-    // suffix lenght = 6
+    // suffix length = 6
     if (CT.length() >= 6) {
       if (suffix(CT,"imentos") && suffix(R2,"imentos")) {
           CT = removeSuffix(CT,"imentos") ; return true;
@@ -436,7 +436,7 @@
       }
     }
 
-    // suffix lenght = 5
+    // suffix length = 5
     if (CT.length() >= 5) {
       if (suffix(CT,"acoes") && suffix(R2,"acoes")) {
           CT = removeSuffix(CT,"acoes") ; return true;
@@ -473,7 +473,7 @@
       }
     }
 
-    // suffix lenght = 4
+    // suffix length = 4
     if (CT.length() >= 4) {
       if (suffix(CT,"acao") && suffix(R2,"acao")) {
           CT = removeSuffix(CT,"acao") ; return true;
@@ -521,7 +521,7 @@
       }
     }
 
-    // suffix lenght = 3
+    // suffix length = 3
     if (CT.length() >= 3) {
       if (suffix(CT,"eza") && suffix(R2,"eza")) {
           CT = removeSuffix(CT,"eza") ; return true ;
@@ -589,7 +589,7 @@
       }
     }
 
-    // suffix lenght = 6
+    // suffix length = 6
     if (RV.length() >= 6) {
       if (suffix(RV,"iremos")) {
         CT = removeSuffix(CT,"iremos") ; return true;
@@ -633,7 +633,7 @@
     }
 
 
-    // suffix lenght = 5
+    // suffix length = 5
     if (RV.length() >= 5) {
       if (suffix(RV,"irmos")) {
         CT = removeSuffix(CT,"irmos") ; return true;
@@ -718,7 +718,7 @@
       }
     }
 
-    // suffix lenght = 4
+    // suffix length = 4
     if (RV.length() >= 4) {
       if (suffix(RV,"aria")) {
         CT = removeSuffix(CT,"aria") ; return true;
@@ -845,7 +845,7 @@
       }
     }
 
-    // suffix lenght = 3
+    // suffix length = 3
     if (RV.length() >= 3) {
       if (suffix(RV,"ada")) {
         CT = removeSuffix(CT,"ada") ; return true;
@@ -888,7 +888,7 @@
       }
     }
 
-    // suffix lenght = 2
+    // suffix length = 2
     if (RV.length() >= 2) {
       if (suffix(RV,"ia")) {
         CT = removeSuffix(CT,"ia") ; return true;
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java	(working copy)
@@ -150,7 +150,7 @@
   }
 
   protected void decomposeInternal(final Token token) {
-    // get the hpyphenation points
+    // get the hyphenation points
     Hyphenation hyphens = hyphenator.hyphenate(token.termBuffer(), 0, token
         .termLength(), 1, 1);
     // No hyphen points found -> exit
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/package.html	(working copy)
@@ -69,7 +69,7 @@
 filter available:
 <ul>
 	<li><i>HyphenationCompoundWordTokenFilter</i>: it uses a
-	hyphenation grammer based approach to find potential word parts of a
+	hyphenation grammar based approach to find potential word parts of a
 	given word.</li>
 	<li><i>DictionaryCompoundWordTokenFilter</i>: it uses a
 	brute-force dictionary-only based approach to find the word parts of a given
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/TernaryTree.java	(working copy)
@@ -25,7 +25,7 @@
  * <h2>Ternary Search Tree.</h2>
  * 
  * <p>
- * A ternary search tree is a hibrid between a binary tree and a digital search
+ * A ternary search tree is a hybrid between a binary tree and a digital search
  * tree (trie). Keys are limited to strings. A data value of type char is stored
  * in each leaf node. It can be used as an index (or pointer) to the data.
  * Branches that only contain one key are compressed to one node by storing a
@@ -45,7 +45,7 @@
  * requires from 5000 to 15000 hyphenation patterns which will be keys in this
  * tree. The strings patterns are usually small (from 2 to 5 characters), but
  * each char in the tree is stored in a node. Thus memory usage is the main
- * concern. We will sacrify 'elegance' to keep memory requirenments to the
+ * concern. We will sacrifice 'elegance' to keep memory requirements to the
  * minimum. Using java's char type as pointer (yes, I know pointer it is a
  * forbidden word in java) we can keep the size of the node to be just 8 bytes
  * (3 pointers and the data char). This gives room for about 65000 nodes. In my
@@ -100,7 +100,7 @@
    * </ul>
    * <p>
    * This shouldn't be a problem if we give the usual semantics to strings since
-   * 0xFFFF is garanteed not to be an Unicode character.
+   * 0xFFFF is guaranteed not to be an Unicode character.
    * </p>
    */
   protected char[] sc;
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/hyphenation/package.html	(working copy)
@@ -17,7 +17,7 @@
 
 <html>
   <head>
-    <title>Hypenation code for the CompoundWordTokenFilter</title>
+    <title>Hyphenation code for the CompoundWordTokenFilter</title>
   </head>
   <body>
     <p>
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemmer.java	(working copy)
@@ -79,7 +79,7 @@
 
 
     /**
-     * Stemms the given term to a unique <tt>discriminator</tt>.
+     * Stems the given term to a unique <tt>discriminator</tt>.
      *
      * @param term  java.langString The term that should be stemmed
      * @return java.lang.String  Discriminator for <tt>term</tt>
@@ -148,7 +148,7 @@
 	}
 
 	/**
-	 * First step of the Porter Algorithmn<br>
+	 * First step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step1( ) {
@@ -202,7 +202,7 @@
 	}
 
 	/**
-	 * Second step (A) of the Porter Algorithmn<br>
+	 * Second step (A) of the Porter Algorithm<br>
 	 * Will be performed if nothing changed from the first step
 	 * or changed were done in the amment, emment, ments or ment suffixes<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
@@ -219,7 +219,7 @@
 	}
 
 	/**
-	 * Second step (B) of the Porter Algorithmn<br>
+	 * Second step (B) of the Porter Algorithm<br>
 	 * Will be performed if step 2 A was performed unsuccessfully<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
@@ -238,7 +238,7 @@
 	}
 
 	/**
-	 * Third step of the Porter Algorithmn<br>
+	 * Third step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step3() {
@@ -259,7 +259,7 @@
 	}
 
 	/**
-	 * Fourth step of the Porter Algorithmn<br>
+	 * Fourth step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step4() {
@@ -286,7 +286,7 @@
 	}
 
 	/**
-	 * Fifth step of the Porter Algorithmn<br>
+	 * Fifth step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step5() {
@@ -301,7 +301,7 @@
 	}
 
 	/**
-	 * Sixth (and last!) step of the Porter Algorithmn<br>
+	 * Sixth (and last!) step of the Porter Algorithm<br>
 	 * refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
 	 */
 	private void step6() {
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java	(working copy)
@@ -41,7 +41,7 @@
 
   //TODO convert to internal
   /*
-   * Stemms the given term to an unique <tt>discriminator</tt>.
+   * Stems the given term to an unique <tt>discriminator</tt>.
    *
    * @param term The term that should be stemmed.
    * @return Discriminator for <tt>term</tt>
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java	(working copy)
@@ -372,7 +372,7 @@
 
     /**
      * Finds the ending among the given class of endings, then checks if this ending was
-     * preceded by any of given predessors, and if so, removes it from stemming zone.
+     * preceded by any of given predecessors, and if so, removes it from stemming zone.
      * Creation date: (17/03/2002 8:18:34 PM)
      */
     private boolean findAndRemoveEnding(StringBuffer stemmingZone,
Index: contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
===================================================================
--- contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java	(revision 810327)
+++ contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java	(working copy)
@@ -51,10 +51,10 @@
  * be used to replace phrase queries, especially them with 0 slop.
  *
  * <p>Without a spacer character
- * it can be used to handle composition and decomposion of words
+ * it can be used to handle composition and decomposition of words
  * such as searching for "multi dimensional" instead of "multidimensional".
  * It is a rather common human problem at query time
- * in several languages, notebly the northern Germanic branch.
+ * in several languages, notably the northern Germanic branch.
  *
  * <p>Shingles are amongst many things also known to solve problems
  * in spell checking, language detection and document clustering.
@@ -108,7 +108,7 @@
  * so it never created the same shingle more than once in the first place.
  *
  * <p>The filter also has basic support for calculating weights for the shingles
- * based on the weights of the tokens from the input stream, output shingle size, et c.
+ * based on the weights of the tokens from the input stream, output shingle size, etc.
  * See {@link #calculateShingleWeight(org.apache.lucene.analysis.Token, java.util.List, int, java.util.List, java.util.List)}.
  * <p/>
  * <b>NOTE:</b> This filter might not behave correctly if used with custom Attributes, i.e. Attributes other than
@@ -253,7 +253,7 @@
    * @see #ignoringSinglePrefixOrSuffixShingleByDefault
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    */
@@ -268,7 +268,7 @@
    * @see #ignoringSinglePrefixOrSuffixShingleByDefault
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -282,7 +282,7 @@
    *
    * @see #defaultSettingsCodec
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -296,7 +296,7 @@
   /**
    * Creates a shingle filter with ad hoc parameter settings.
    *
-   * @param input stream from wich to construct the matrix
+   * @param input stream from which to construct the matrix
    * @param minimumShingleSize minimum number of tokens in any shingle.
    * @param maximumShingleSize maximum number of tokens in any shingle.
    * @param spacerCharacter character to use between texts of the token parts in a shingle. null for none.
@@ -408,8 +408,8 @@
   private static final Token request_next_token = new Token();
 
   /**
-   * This method exists in order to avoid reursive calls to the method
-   * as the complexity of a fairlt small matrix then easily would require
+   * This method exists in order to avoid recursive calls to the method
+   * as the complexity of a fairly small matrix then easily would require
    * a gigabyte sized stack per thread.
    *
    * @param reusableToken
@@ -490,7 +490,7 @@
             // don't really care, we just read it.
           }
 
-          // get rith of resources
+          // get rid of resources
 
           // delete the first column in the matrix
           Matrix.Column deletedColumn = (Matrix.Column) matrix.columns.remove(0);
Index: contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java
===================================================================
--- contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java	(revision 810327)
+++ contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/BigramDictionary.java	(working copy)
@@ -147,7 +147,7 @@
   /**
    * Load the datafile into this BigramDictionary
    * 
-   * @param dctFilePath path to the Bigramdictionary (bigramdict.mem)
+   * @param dctFilePath path to the Bigramdictionary (bigramdict.dct)
    * @throws FileNotFoundException
    * @throws IOException
    * @throws UnsupportedEncodingException
Index: contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java
===================================================================
--- contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java	(revision 810327)
+++ contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/hhmm/WordDictionary.java	(working copy)
@@ -184,7 +184,7 @@
   /**
    * Load the datafile into this WordDictionary
    * 
-   * @param dctFilePath path to word dictionary (coredict.mem)
+   * @param dctFilePath path to word dictionary (coredict.dct)
    * @return number of words read
    * @throws FileNotFoundException
    * @throws IOException
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/NoMoreDataException.java	(working copy)
@@ -20,7 +20,7 @@
 /**
  * Exception indicating there is no more data.
  * Thrown by Docs Makers if doc.maker.forever is false and docs sources of that maker where exhausted.
- * This is usefull for iterating all document of a source, in case we don't know in advance how many docs there are.
+ * This is useful for iterating all document of a source, in case we don't know in advance how many docs there are.
  */
 public class NoMoreDataException extends Exception {
 
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleQueryMaker.java	(working copy)
@@ -36,9 +36,9 @@
 
   /**
    * Prepare the queries for this test.
-   * Extending classes can overide this method for preparing different queries. 
+   * Extending classes can override this method for preparing different queries. 
    * @return prepared queries.
-   * @throws Exception if canot prepare the queries.
+   * @throws Exception if cannot prepare the queries.
    */
   protected Query[] prepareQueries() throws Exception {
     // analyzer (default is standard analyzer)
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker.java	(working copy)
@@ -33,7 +33,7 @@
    * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()
    */
   protected Query[] prepareQueries() throws Exception {
-    // exatract some 100 words from doc text to an array
+    // extract some 100 words from doc text to an array
     String words[];
     ArrayList w = new ArrayList();
     StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);
@@ -60,7 +60,7 @@
             }
           }
           queries.add(q);
-          // reveresed
+          // reversed
           remainedSlop = slop;
           q = new PhraseQuery();
           q.setSlop(slop+2*qlen);
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/Sample.java	(working copy)
@@ -28,7 +28,7 @@
 import org.apache.lucene.benchmark.byTask.utils.Config;
 
 /**
- * Sample performance test written programatically - no algorithm file is needed here.
+ * Sample performance test written programmatically - no algorithm file is needed here.
  */
 public class Sample {
 
@@ -43,7 +43,7 @@
     PerfRunData runData = new PerfRunData(conf);
     
     // 1. top sequence
-    TaskSequence top = new TaskSequence(runData,null,null,false); // top level, not parralel
+    TaskSequence top = new TaskSequence(runData,null,null,false); // top level, not parallel
     
     // 2. task to create the index
     CreateIndexTask create = new CreateIndexTask(runData);
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/programmatic/package.html	(working copy)
@@ -17,6 +17,6 @@
 -->
 <html>
 <body>
-Sample performance test written programatically - no algorithm file is needed here.
+Sample performance test written programmatically - no algorithm file is needed here.
 </body>
 </html>
\ No newline at end of file
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/Report.java	(working copy)
@@ -42,7 +42,7 @@
   }
 
   /**
-   * Returns number of lines in the reoprt.
+   * Returns number of lines in the report.
    */
   public int getSize() {
     return size;
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/stats/TaskStats.java	(working copy)
@@ -171,7 +171,7 @@
     maxUsedMem += stat2.getMaxUsedMem();
     count += stat2.getCount();
     if (round != stat2.round) {
-      round = -1; // no meaning if agregating tasks of different ruond. 
+      round = -1; // no meaning if aggregating tasks of different round. 
     }
   }
 
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/OpenReaderTask.java	(working copy)
@@ -31,7 +31,7 @@
 
 /**
  * Open an index reader.
- * <br>Other side effects: index redaer object in perfRunData is set.
+ * <br>Other side effects: index reader object in perfRunData is set.
  * <br> Optional params readOnly,commitUserData eg. OpenReader(false,commit1)
  */
 public class OpenReaderTask extends PerfTask {
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/PerfTask.java	(working copy)
@@ -28,8 +28,8 @@
 /**
  * An abstract task to be tested for performance. <br>
  * Every performance task extends this class, and provides its own
- * {@link #doLogic()} method, which performss the actual task. <br>
- * Tasks performing some work that should be measured for the task, can overide
+ * {@link #doLogic()} method, which performs the actual task. <br>
+ * Tasks performing some work that should be measured for the task, can override
  * {@link #setup()} and/or {@link #tearDown()} and place that work there. <br>
  * Relevant properties: <code>task.max.depth.log</code>.<br>
  * Also supports the following logging attributes:
@@ -40,7 +40,7 @@
  * <li>log.step.[class Task Name] - specifies the same as 'log.step', only for a
  * particular task name. For example, log.step.AddDoc will be applied only for
  * {@link AddDocTask}, but not for {@link DeleteDocTask}. It's a way to control
- * per task logging settings. If you want to ommit logging for any other task,
+ * per task logging settings. If you want to omit logging for any other task,
  * include log.step=-1. The syntax is "log.step." together with the Task's
  * 'short' name (i.e., without the 'Task' part).
  * </ul>
@@ -118,8 +118,8 @@
   }
   
   protected Object clone() throws CloneNotSupportedException {
-    // tasks having non primitive data structures should overide this.
-    // otherwise parallel running of a task sequence might not run crrectly. 
+    // tasks having non primitive data structures should override this.
+    // otherwise parallel running of a task sequence might not run correctly. 
     return super.clone();
   }
 
@@ -152,7 +152,7 @@
   }
 
   /**
-   * Perform the task once (ignoring repetions specification)
+   * Perform the task once (ignoring repetitions specification)
    * Return number of work items done by this task.
    * For indexing that can be number of docs added.
    * For warming that can be number of scanned items, etc.
@@ -230,7 +230,7 @@
   }
   
   /**
-   * Tasks that should never log at start can overide this.  
+   * Tasks that should never log at start can override this.  
    * @return true if this task should never log when it start.
    */
   protected boolean shouldNeverLogAtStart () {
@@ -238,7 +238,7 @@
   }
   
   /**
-   * Tasks that should not record statistics can overide this.  
+   * Tasks that should not record statistics can override this.  
    * @return true if this task should never record its statistics.
    */
   protected boolean shouldNotRecordStats () {
@@ -274,7 +274,7 @@
   }
 
   /**
-   * Sub classes that supports parameters must overide this method to return true.
+   * Sub classes that supports parameters must override this method to return true.
    * @return true iff this task supports command line params.
    */
   public boolean supportsParams () {
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java	(working copy)
@@ -250,7 +250,7 @@
   }
 
   /**
-   * @return the maxiumum number of highlighter fragments
+   * @return the maximum number of highlighter fragments
    * @deprecated Please define getBenchmarkHighlighter instead
    */
   final int maxNumFragments(){
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemEraseTask.java	(working copy)
@@ -24,7 +24,7 @@
 /**
  * Reset all index and input data and call gc, erase index and dir, does NOT clear statistics.
  * <br>This contains ResetInputs.
- * <br>Other side effects: writers/readers nulified, deleted, closed.
+ * <br>Other side effects: writers/readers nullified, deleted, closed.
  * Index is erased.
  * Directory is erased.
  */
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ResetSystemSoftTask.java	(working copy)
@@ -24,7 +24,7 @@
 /**
  * Reset all index and input data and call gc, does NOT erase index/dir, does NOT clear statistics.
  * This contains ResetInputs.
- * <br>Other side effects: writers/readers nulified, closed.
+ * <br>Other side effects: writers/readers nullified, closed.
  * Index is NOT erased.
  * Directory is NOT erased.
  */
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SetPropTask.java	(working copy)
@@ -21,7 +21,7 @@
 
 /**
  * Set a performance test configuration property.
- * A property may have a single value, or a sequence of values, seprated by ":". 
+ * A property may have a single value, or a sequence of values, separated by ":". 
  * If a sequence of values is specified, each time a new round starts, 
  * the next (cyclic) value is taken.  
  * <br>Other side effects: none.
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java	(working copy)
@@ -251,7 +251,7 @@
     }
   }
 
-  // run threadsm with rate
+  // run threads with rate
   private void startlThreadsWithRate(Thread[] t) throws InterruptedException {
     long delayStep = (perMin ? 60000 : 1000) /rate;
     long nextStartTime = System.currentTimeMillis();
@@ -261,7 +261,7 @@
         //System.out.println("thread wait: "+waitMore+" for rate: "+ratePerMin+" (delayStep="+delayStep+")");
         Thread.sleep(waitMore);
       }
-      nextStartTime += delayStep; // this aims at avarage rate of starting threads. 
+      nextStartTime += delayStep; // this aims at average rate of starting threads. 
       t[i].start();
     }
   }
@@ -346,7 +346,7 @@
   }
 
   public String getName() {
-    return seqName; // overide to include more info 
+    return seqName; // override to include more info 
   }
 
   /**
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.java	(working copy)
@@ -35,9 +35,9 @@
 /**
  * A task which writes documents, one line per document. Each line is in the
  * following format: title &lt;TAB&gt; date &lt;TAB&gt; body. The output of this
- * taske can be consumed by
+ * task can be consumed by
  * {@link org.apache.lucene.benchmark.byTask.feeds.LineDocMaker} and is intended
- * to save the IO overhead of opening a file per doument to be indexed.<br>
+ * to save the IO overhead of opening a file per document to be indexed.<br>
  * Supports the following parameters:
  * <ul>
  * <li>line.file.out - the name of the file to write the output to. That
@@ -47,7 +47,7 @@
  * false).
  * </ul>
  * <b>NOTE:</b> this class is not thread-safe and if used by multiple threads the
- * output is unspecified (as all will write to the same ouput file in a
+ * output is unspecified (as all will write to the same output file in a
  * non-synchronized way).
  */
 public class WriteLineDocTask extends PerfTask {
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Config.java	(working copy)
@@ -32,7 +32,7 @@
 /**
  * Perf run configuration properties.
  * <p>
- * Numeric peroperty containing ":", e.g. "10:100:5" is interpreted 
+ * Numeric property containing ":", e.g. "10:100:5" is interpreted 
  * as array of numeric values. It is extracted once, on first use, and 
  * maintain a round number to return the appropriate value.
  * <p>
@@ -99,7 +99,7 @@
   }
 
   /**
-   * Create config without algorithm - usefull for a programmatic perf test.
+   * Create config without algorithm - useful for a programmatic perf test.
    * @param props - configuration properties.
    * @throws IOException
    */
@@ -135,7 +135,7 @@
    * Set a property.
    * Note: once a multiple values property is set, it can no longer be modified.
    * @param name name of property.
-   * @param value either single or multiple propery value (multple values are separated by ":")
+   * @param value either single or multiple property value (multiple values are separated by ":")
    * @throws Exception 
    */
   public void set (String name, String value) throws Exception {
@@ -208,7 +208,7 @@
   /**
    * Return a boolean property.
    * If the property contain ":", e.g. "true.true.false", it is interpreted 
-   * as array of boleans. It is extracted once, on first call
+   * as array of booleans. It is extracted once, on first call
    * to get() it, and a by-round-value is returned. 
    * @param name name of property
    * @param dflt default value
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/Format.java	(working copy)
@@ -58,7 +58,7 @@
   }
 
   /**
-   * Padd a number from right.
+   * Pad a number from right.
    * @param numFracDigits number of digits in fraction part - must be 0 or 1 or 2.
    * @param f number to be formatted.
    * @param col column name (used for deciding on length).
@@ -75,7 +75,7 @@
   }
 
   /**
-   * Padd a number from left.
+   * Pad a number from left.
    * @param n number to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
@@ -86,7 +86,7 @@
   }
 
   /**
-   * Padd a string from right.
+   * Pad a string from right.
    * @param s string to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
@@ -97,7 +97,7 @@
   }
 
   /**
-   * Padd a string from left.
+   * Pad a string from left.
    * @param s string to be formatted.
    * @param col column name (used for deciding on length).
    * @return formatted string.
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/utils/StringBufferReader.java	(working copy)
@@ -37,7 +37,7 @@
  * <pre>
  * StringBuffer sb = new StringBuffer("some text");
  * Reader reader = new StringBufferReader(sb);
- * ... read from reader - dont close it ! ...
+ * ... read from reader - don't close it ! ...
  * sb.setLength(0);
  * sb.append("some new text");
  * reader.reset();
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java	(revision 810363)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityBenchmark.java	(working copy)
@@ -63,7 +63,7 @@
    * @param qqs quality queries to run.
    * @param qqParser parser for turning QualityQueries into Lucene Queries. 
    * @param searcher index to be searched.
-   * @param docNameField name of field containg the document name.
+   * @param docNameField name of field containing the document name.
    *        This allows to extract the doc name for search results,
    *        and is important for judging the results.  
    */
@@ -114,7 +114,7 @@
   private QualityStats analyzeQueryResults(QualityQuery qq, Query q, TopDocs td, Judge judge, PrintWriter logger, long searchTime) throws IOException {
     QualityStats stts = new QualityStats(judge.maxRecall(qq),searchTime);
     ScoreDoc sd[] = td.scoreDocs;
-    long t1 = System.currentTimeMillis(); // extraction of first doc name we meassure also construction of doc name extractor, just in case.
+    long t1 = System.currentTimeMillis(); // extraction of first doc name we measure also construction of doc name extractor, just in case.
     DocNameExtractor xt = new DocNameExtractor(docNameField);
     for (int i=0; i<sd.length; i++) {
       String docName = xt.docName(searcher,sd[i].doc);
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java	(revision 810363)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/QualityStats.java	(working copy)
@@ -215,7 +215,7 @@
       }
     }
     assert m>0 : "Fishy: no \"good\" queries!";
-    // take average: times go by all queries, other meassures go by "good" queries noly.
+    // take average: times go by all queries, other measures go by "good" queries only.
     avg.searchTime /= stats.length;
     avg.docNamesExtractTime /= stats.length;
     avg.numGoodPoints /= m;
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java	(revision 810363)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/quality/utils/QualityQueriesFinder.java	(working copy)
@@ -36,7 +36,7 @@
   private Directory dir;
   
   /**
-   * Constrctor over a directory containing the index.
+   * Constructor over a directory containing the index.
    * @param dir directory containing the index we search for the quality test. 
    */
   private QualityQueriesFinder(Directory dir) {
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData.java	(working copy)
@@ -177,7 +177,7 @@
                     }
                     dc.count++;
                     //dc.total += td.getRate();
-                    dc.total += (td.count>0 && td.elapsed<=0 ? 1 : td.elapsed); // assume atleast 1ms for any countable op
+                    dc.total += (td.count>0 && td.elapsed<=0 ? 1 : td.elapsed); // assume at least 1ms for any countable op
                     dc.recordCount += td.count;
                 }
             }
@@ -204,7 +204,7 @@
             }
             ldc.Dcount += dc.count;
             ldc.DrecordCount += dc.recordCount;
-            ldc.Dtotal += (dc.count>0 && dc.total<=0 ? 1 : dc.total); // assume atleast 1ms for any countable op 
+            ldc.Dtotal += (dc.count>0 && dc.total<=0 ? 1 : dc.total); // assume at least 1ms for any countable op 
         }
         it = mapMem.keySet().iterator();
         while (it.hasNext())
@@ -281,20 +281,20 @@
       numFormat[1].setMinimumFractionDigits(1);
     }
 
-    // padd number from left
+    // pad number from left
     // numFracDigits must be 0 or 1.
     static String format(int numFracDigits, float f, String col) {
       String res = padd + numFormat[numFracDigits].format(f);
       return res.substring(res.length() - col.length());
     }
 
-    // padd number from left
+    // pad number from left
     static String format(int n, String col) {
       String res = padd + n;
       return res.substring(res.length() - col.length());
     }
 
-    // padd string from right
+    // pad string from right
     static String format(String s, String col) {
       return (s + padd).substring(0,col.length());
     }
@@ -350,7 +350,7 @@
     /**
      * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses
      * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.
-     * It also only uses compund file and optimize is always true.
+     * It also only uses compound file and optimize is always true.
      *
      * @param sources
      * @param analyzers
Index: contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java
===================================================================
--- contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java	(revision 810327)
+++ contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TimeData.java	(working copy)
@@ -77,7 +77,7 @@
 
   /** Get rate of processing, defined as number of processed records per second. */
   public double getRate() {
-    double rps = (double) count * 1000.0 / (double) (elapsed>0 ? elapsed : 1); // assume atleast 1ms for any countable op
+    double rps = (double) count * 1000.0 / (double) (elapsed>0 ? elapsed : 1); // assume at least 1ms for any countable op
     return rps;
   }
 
@@ -88,7 +88,7 @@
 
   public String toString() { return toString(true); }
   /**
-   * Return a tab-seprated string containing this data.
+   * Return a tab-separated string containing this data.
    * @param withMem if true, append also memory information
    * @return The String
    */
Index: contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java
===================================================================
--- contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java	(revision 810327)
+++ contrib/fast-vector-highlighter/src/java/org/apache/lucene/search/vectorhighlight/ScoreOrderFragmentsBuilder.java	(working copy)
@@ -38,7 +38,7 @@
   /**
    * a constructor.
    * 
-   * @param preTags aray of pre-tags for markup terms.
+   * @param preTags array of pre-tags for markup terms.
    * @param postTags array of post-tags for markup terms.
    */
   public ScoreOrderFragmentsBuilder( String[] preTags, String[] postTags ){
Index: contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java
===================================================================
--- contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java	(revision 810327)
+++ contrib/highlighter/src/java/org/apache/lucene/search/highlight/GradientFormatter.java	(working copy)
@@ -42,7 +42,7 @@
      * 
      * @param maxScore
      *            The score (and above) displayed as maxColor (See QueryScorer.getMaxWeight 
-     * 			  which can be used to callibrate scoring scale)
+     * 			  which can be used to calibrate scoring scale)
      * @param minForegroundColor
      *            The hex color used for representing IDF scores of zero eg
      *            #FFFFFF (white) or null if no foreground color required
@@ -194,7 +194,7 @@
      * input is nonnegative unless there is a preceding minus sign. This method
      * reads the input as twos complement instead, so if the input is 8 bytes
      * long, it will correctly restore a negative int produced by
-     * Integer.toHexString() but not neccesarily one produced by
+     * Integer.toHexString() but not necessarily one produced by
      * Integer.toString(x,16) since that method will produce a string like '-FF'
      * for negative integer values.
      * 
Index: contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
===================================================================
--- contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java	(revision 810327)
+++ contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java	(working copy)
@@ -93,7 +93,7 @@
 	 *
 	 * @param tokenStream   a stream of tokens identified in the text parameter, including offset information.
 	 * This is typically produced by an analyzer re-parsing a document's
-	 * text. Some work may be done on retrieving TokenStreams more efficently
+	 * text. Some work may be done on retrieving TokenStreams more efficiently
 	 * by adding support for storing original text position data in the Lucene
 	 * index but this support is not currently available (as of Lucene 1.4 rc2).
 	 * @param text text to highlight terms in
Index: contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java
===================================================================
--- contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java	(revision 810327)
+++ contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java	(working copy)
@@ -54,7 +54,7 @@
 	 *
 	 * @param query      Query to extract term texts from
 	 * @param reader used to compute IDF which can be used to a) score selected fragments better 
-	 * b) use graded highlights eg chaning intensity of font color
+	 * b) use graded highlights eg changing intensity of font color
 	 * @param fieldName the field on which Inverse Document Frequency (IDF) calculations are based
 	 * @return an array of the terms used in a query, plus their weights.
 	 */
Index: contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
===================================================================
--- contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(revision 810327)
+++ contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(working copy)
@@ -130,7 +130,7 @@
      * 	   stemmer/lowercaser/stopword combo)
      *  2) The  number of other fields (Lucene reads ALL fields off the disk 
      *     when accessing just one document field - can cost dear!)
-     *  3) Use of compression on field storage - could be faster cos of compression (less disk IO)
+     *  3) Use of compression on field storage - could be faster due to compression (less disk IO)
      *     or slower (more CPU burn) depending on the content.
      *
      * @param tpv
Index: contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html
===================================================================
--- contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html	(revision 810327)
+++ contrib/highlighter/src/java/org/apache/lucene/search/highlight/package.html	(working copy)
@@ -87,7 +87,7 @@
 you want to see what the basis of the similarities are).</p>
 
 <p>The QueryScorer class has a new constructor which can use an IndexReader to derive the IDF (inverse document frequency)
-for each term in order to influcence the score. This is useful for helping to extracting the most significant sections
+for each term in order to influence the score. This is useful for helping to extracting the most significant sections
 of a document and in supplying scores used by the new GradientFormatter to color significant words more strongly.
 The QueryScorer.getMaxWeight method is useful when passed to the GradientFormatter constructor to define the top score
 which is associated with the top color.</p>
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/FieldSettings.java	(working copy)
@@ -23,7 +23,7 @@
  */
 
 /**
- * Essetially a Map<FieldName, {@link org.apache.lucene.store.instantiated.FieldSetting}> 
+ * Essentially a Map<FieldName, {@link org.apache.lucene.store.instantiated.FieldSetting}> 
  */
 class FieldSettings implements Serializable {
 
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex.java	(working copy)
@@ -92,7 +92,7 @@
    * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.
    *
    * @param sourceIndexReader the source index this new instantiated index will be copied from.
-   * @throws IOException if the source index is not optimized, or when accesing the source.
+   * @throws IOException if the source index is not optimized, or when accessing the source.
    */
   public InstantiatedIndex(IndexReader sourceIndexReader) throws IOException {
     this(sourceIndexReader, null);
@@ -105,7 +105,7 @@
    *
    * @param sourceIndexReader the source index this new instantiated index will be copied from.
    * @param fields fields to be added, or null for all
-   * @throws IOException if the source index is not optimized, or when accesing the source.
+   * @throws IOException if the source index is not optimized, or when accessing the source.
    */
   public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {
 
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexReader.java	(working copy)
@@ -224,8 +224,8 @@
    * over a {@link org.apache.lucene.store.Directory}.
    * I.e., if you need to touch the document, clone it first!
    * <p>
-   * This can also be seen as a feature for live canges of stored values,
-   * but be carful! Adding a field with an name unknown to the index
+   * This can also be seen as a feature for live changes of stored values,
+   * but be careful! Adding a field with an name unknown to the index
    * or to a field with previously no stored values will make
    * {@link org.apache.lucene.store.instantiated.InstantiatedIndexReader#getFieldNames(org.apache.lucene.index.IndexReader.FieldOption)}
    * out of sync, causing problems for instance when merging the
@@ -259,8 +259,8 @@
    * over a {@link org.apache.lucene.store.Directory}.
    * I.e., if you need to touch the document, clone it first!
    * <p>
-   * This can also be seen as a feature for live canges of stored values,
-   * but be carful! Adding a field with an name unknown to the index
+   * This can also be seen as a feature for live changes of stored values,
+   * but be careful! Adding a field with an name unknown to the index
    * or to a field with previously no stored values will make
    * {@link org.apache.lucene.store.instantiated.InstantiatedIndexReader#getFieldNames(org.apache.lucene.index.IndexReader.FieldOption)}
    * out of sync, causing problems for instance when merging the
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java	(working copy)
@@ -281,7 +281,7 @@
             }
           }
 
-          // create association term document infomation
+          // create association term document information
           //
           // [Term]-- {0..*} | {0..* ordered} --(field)[Document]
           //
@@ -302,7 +302,7 @@
 
           InstantiatedTermDocumentInformation info = new InstantiatedTermDocumentInformation(term, document, /*eTermText_TermDocInfoFactory.getValue().termFrequency,*/ positions, payloads);
 
-          // todo optimize, this should be chached and updated to array in batches rather than appending the array once for every position!
+          // todo optimize, this should be cached and updated to array in batches rather than appending the array once for every position!
           InstantiatedTermDocumentInformation[] associatedDocuments;
           if (term.getAssociatedDocuments() != null) {
             associatedDocuments = new InstantiatedTermDocumentInformation[term.getAssociatedDocuments().length + 1];
@@ -363,7 +363,7 @@
 
     // order document informations in dirty terms
     for (InstantiatedTerm term : dirtyTerms) {
-      // todo optimize, i belive this is useless, that the natural order is document number?
+      // todo optimize, i believe this is useless, that the natural order is document number?
       Arrays.sort(term.getAssociatedDocuments(), InstantiatedTermDocumentInformation.documentNumberComparator);
 
 //      // update association class reference for speedy skipTo()
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTerm.java	(working copy)
@@ -74,10 +74,10 @@
   private InstantiatedTermDocumentInformation[] associatedDocuments;
 
   /**
-   * Meta data per document in wich this term is occuring.
+   * Meta data per document in which this term is occurring.
    * Ordered by document number.
    *
-   * @return Meta data per document in wich this term is occuring.
+   * @return Meta data per document in which this term is occurring.
    */
   public InstantiatedTermDocumentInformation[] getAssociatedDocuments() {
     return associatedDocuments;
@@ -85,10 +85,10 @@
 
 
   /**
-   * Meta data per document in wich this term is occuring.
+   * Meta data per document in which this term is occurring.
    * Ordered by document number.
    *
-   * @param associatedDocuments meta data per document in wich this term is occuring, ordered by document number
+   * @param associatedDocuments meta data per document in which this term is occurring, ordered by document number
    */
   void setAssociatedDocuments(InstantiatedTermDocumentInformation[] associatedDocuments) {
     this.associatedDocuments = associatedDocuments;
@@ -182,7 +182,7 @@
       // A typical binarySearch algorithm uses pivot = (min + max) / 2.
       // The pivot we use here tries to be smarter and to choose a pivot close to the expectable location of the key.
       // This reduces dramatically the number of steps needed to get to the key.
-      // However, it does not work well with a logaritmic distribution of values, for instance.
+      // However, it does not work well with a logarithmic distribution of values, for instance.
       // When the key is not found quickly the smart way, we switch to the standard pivot.
       if (nPreviousSteps > 2) {
         pivot = (min + max) >> 1;
@@ -214,7 +214,7 @@
 
 
   /**
-   * Navigates to the view of this occurances of this term in a specific document. 
+   * Navigates to the view of this occurrences of this term in a specific document. 
    *
    * This method is only used by InstantiatedIndex(IndexReader) and
    * should not be optimized for less CPU at the cost of more RAM.
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermDocumentInformation.java	(working copy)
@@ -23,7 +23,7 @@
 
 /**
  * There is one instance of this class per indexed term in a document
- * and it contains the meta data about each occurance of a term in a docment.
+ * and it contains the meta data about each occurrence of a term in a document.
  *
  * It is the inner glue of the inverted index.
  *
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedTermPositions.java	(working copy)
@@ -62,7 +62,7 @@
   public int nextPosition() {
     currentTermPositionIndex++;
     // if you get an array out of index exception here,
-    // it might be due to currentDocumentInformation.getIndexFromTerm not beeing set!!
+    // it might be due to currentDocumentInformation.getIndexFromTerm not being set!!
     return currentDocumentInformation.getTermPositions()[currentTermPositionIndex];
   }
 
Index: contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html
===================================================================
--- contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html	(revision 810327)
+++ contrib/instantiated/src/java/org/apache/lucene/store/instantiated/package.html	(working copy)
@@ -49,8 +49,8 @@
 
 <p>
   At a few thousand ~160 characters long documents
-  InstantiaedIndex outperforms RAMDirectory some 50x,
-  15x at 100 documents of 2000 charachters length,
+  InstantiatedIndex outperforms RAMDirectory some 50x,
+  15x at 100 documents of 2000 characters length,
   and is linear to RAMDirectory at 10,000 documents of 2000 characters length.
 </p>
 
@@ -84,7 +84,7 @@
   Could replace any small index that could do with greater response time.
   spell check a priori index,
   the index of new documents exposed to user search agent queries,
-  to compile classifiers in machine learning environments, et c.
+  to compile classifiers in machine learning environments, etc.
 </p>
 
 <h2>Class diagram</h2>
Index: contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java	(revision 810327)
+++ contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java	(working copy)
@@ -81,11 +81,11 @@
   private Similarity sim;
   
   /**
-   * Constructor for code that wishes to use this class programatically
+   * Constructor for code that wishes to use this class programmatically
    * If Similarity is null, kill the field norms.
    *
    * @param d the Directory to modify
-   * @param s the Similiary to use (can be null)
+   * @param s the Similarity to use (can be null)
    */
   public FieldNormModifier(Directory d, Similarity s) {
     dir = d;
Index: contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java	(revision 810327)
+++ contrib/misc/src/java/org/apache/lucene/misc/ChainedFilter.java	(working copy)
@@ -85,7 +85,7 @@
     /**
      * Ctor.
      * @param chain The chain of filters
-     * @param logic Logicial operation to apply to ALL filters
+     * @param logic Logical operation to apply to ALL filters
      */
     public ChainedFilter(Filter[] chain, int logic)
     {
Index: contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java	(revision 810327)
+++ contrib/misc/src/java/org/apache/lucene/misc/SweetSpotSimilarity.java	(working copy)
@@ -97,7 +97,7 @@
     
   /**
    * Sets the default function variables used by lengthNorm when no field
-   * specifc variables have been set.
+   * specific variables have been set.
    *
    * @see #lengthNorm
    */
@@ -233,7 +233,7 @@
    * </code>
    *
    * <p>
-   * This code is provided as a convincience for subclasses that want
+   * This code is provided as a convenience for subclasses that want
    * to use a hyperbolic tf function.
    * </p>
    *
Index: contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
===================================================================
--- contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java	(revision 810327)
+++ contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java	(working copy)
@@ -40,9 +40,9 @@
 import org.apache.lucene.search.spans.SpanTermQuery;
 
 /**
- * QueryParser which permits complex phrase query syntax e.g. "(john jon
- * jonathan~) peters*"
- * 
+ * QueryParser which permits complex phrase query syntax eg "(john jon
+ * jonathan~) peters*".
+ * <p>
  * Performs potentially multiple passes over Query text to parse any nested
  * logic in PhraseQueries. - First pass takes any PhraseQuery content between
  * quotes and stores for subsequent pass. All other query content is parsed as
@@ -50,14 +50,15 @@
  * embedded clauses are referring to the same field and therefore can be
  * rewritten as Span queries. All PhraseQuery clauses are expressed as
  * ComplexPhraseQuery objects
- * 
+ * </p>
+ * <p>
  * This could arguably be done in one pass using a new QueryParser but here I am
  * working within the constraints of the existing parser as a base class. This
  * currently simply feeds all phrase content through an analyzer to select
  * phrase terms - any "special" syntax such as * ~ * etc are not given special
  * status
+ * </p>
  * 
- * 
  */
 public class ComplexPhraseQueryParser extends QueryParser {
   private ArrayList/*<ComplexPhraseQuery>*/complexPhrases = null;
Index: contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj
===================================================================
--- contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj	(revision 810327)
+++ contrib/misc/src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj	(working copy)
@@ -232,7 +232,7 @@
    * In default mode (<code>OR_OPERATOR</code>) terms without any modifiers
    * are considered optional: for example <code>capital of Hungary</code> is equal to
    * <code>capital OR of OR Hungary</code>.<br/>
-   * In <code>AND_OPERATOR</code> mode terms are considered to be in conjuction: the
+   * In <code>AND_OPERATOR</code> mode terms are considered to be in conjunction: the
    * above mentioned query is parsed as <code>capital AND of AND Hungary</code>
    */
   public void setDefaultOperator(Operator op) {
Index: contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
===================================================================
--- contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java	(revision 810327)
+++ contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java	(working copy)
@@ -87,7 +87,7 @@
  *
  * This class has lots of options to try to make it efficient and flexible.
  * See the body of {@link #main main()} below in the source for real code, or
- * if you want pseudo code, the simpliest possible usage is as follows. The bold
+ * if you want pseudo code, the simplest possible usage is as follows. The bold
  * fragment is specific to this class.
  *
  * <code><pre>
@@ -109,7 +109,7 @@
  * <ol>
  * <li> do your normal, Lucene setup for searching,
  * <li> create a MoreLikeThis,
- * <li> get the text of the doc you want to find similaries to
+ * <li> get the text of the doc you want to find similarities to
  * <li> then call one of the like() calls to generate a similarity query
  * <li> call the searcher to find the similar docs
  * </ol>
@@ -139,7 +139,7 @@
  * Some bugfixing, some refactoring, some optimisation.
  *  - bugfix: retrieveTerms(int docNum) was not working for indexes without a termvector -added missing code
  *  - bugfix: No significant terms being created for fields with a termvector - because 
- *            was only counting one occurence per term/field pair in calculations(ie not including frequency info from TermVector) 
+ *            was only counting one occurrence per term/field pair in calculations(ie not including frequency info from TermVector) 
  *  - refactor: moved common code into isNoiseWord()
  *  - optimise: when no termvector support available - used maxNumTermsParsed to limit amount of tokenization
  * </pre>
@@ -230,7 +230,7 @@
     private Analyzer analyzer = DEFAULT_ANALYZER;
 
     /**
-     * Ignore words less freqent that this.
+     * Ignore words less frequent that this.
      */
     private int minTermFreq = DEFAULT_MIN_TERM_FREQ;
 
Index: contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
===================================================================
--- contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java	(revision 810327)
+++ contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java	(working copy)
@@ -63,7 +63,7 @@
 	 *
 	 * <p>
 	 * The philosophy behind this method is "two documents are similar if they share lots of words".
-	 * Note that behind the scenes, Lucenes scoring algorithm will tend to give two documents a higher similarity score if the share more uncommon words.
+	 * Note that behind the scenes, Lucene's scoring algorithm will tend to give two documents a higher similarity score if the share more uncommon words.
 	 *
 	 * <P>
 	 * This method is fail-safe in that if a long 'body' is passed in and
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/package.html	(working copy)
@@ -44,7 +44,7 @@
 <p>
 The query processing phase is performed by a query processor, which implements {@link org.apache.lucene.queryParser.core.processors.QueryNodeProcessor}.
 A query processor is responsible to perform any processing on a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree. This phase
-is optional and is used only if an extra processing, validation, query expansion, etc needs to be perfomed in a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree.
+is optional and is used only if an extra processing, validation, query expansion, etc needs to be performed in a {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree.
 The {@link org.apache.lucene.queryParser.core.nodes.QueryNode} tree can be either be generated by a text parser or programmatically created.
 </p>
 
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/ModifierQueryNode.java	(working copy)
@@ -27,11 +27,12 @@
 
 /**
  * A {@link ModifierQueryNode} indicates the modifier value (+,-,?,NONE) for
- * each term on the query string for example "+t1 -t2 t3" will have a tree of
- * <BooleanQueryNode> <ModifierQueryNode modifier="MOD_REQ"> <t1/>
- * </ModifierQueryNode> <ModifierQueryNode modifier="MOD_NOT"> <t2/>
- * </ModifierQueryNode> <t3/> </BooleanQueryNode>
- * 
+ * each term on the query string. For example "+t1 -t2 t3" will have a tree of:
+ * <blockquote>
+ * &lt;BooleanQueryNode&gt; &lt;ModifierQueryNode modifier="MOD_REQ"&gt; &lt;t1/&gt;
+ * &lt;/ModifierQueryNode&gt; &lt;ModifierQueryNode modifier="MOD_NOT"&gt; &lt;t2/&gt;
+ * &lt;/ModifierQueryNode&gt; &lt;t3/&gt; &lt;/BooleanQueryNode&gt;
+ * </blockquote>
  */
 public class ModifierQueryNode extends QueryNodeImpl {
 
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/PathQueryNode.java	(working copy)
@@ -25,17 +25,19 @@
 import org.apache.lucene.queryParser.core.parser.EscapeQuerySyntax.Type;
 
 /**
- * A {@link PathQueryNode} is used for to store queries like
- * /company/USA/California /product/shoes/brown QueryText are objects that
+ * A {@link PathQueryNode} is used to store queries like
+ * /company/USA/California /product/shoes/brown. QueryText are objects that
  * contain the text, begin position and end position in the query.
- * 
+ * <p>
  * Example how the text parser creates these objects:
- * 
- * List values = ArrayList(); values.add(new PathQueryNode.QueryText("company",
- * 1, 7)); values.add(new PathQueryNode.QueryText("USA", 9, 12)); values.add(new
- * PathQueryNode.QueryText("California", 14, 23)); QueryNode q = new
- * PathQueryNode(values);
- * 
+ * </p>
+ * <pre>
+ * List values = ArrayList(); 
+ * values.add(new PathQueryNode.QueryText("company", 1, 7)); 
+ * values.add(new PathQueryNode.QueryText("USA", 9, 12)); 
+ * values.add(new PathQueryNode.QueryText("California", 14, 23)); 
+ * QueryNode q = new PathQueryNode(values);
+ * </pre>
  */
 public class PathQueryNode extends QueryNodeImpl {
 
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/QueryNodeImpl.java	(working copy)
@@ -106,7 +106,7 @@
     // allocate new children list
     allocate();
 
-    // add new childs and set parent
+    // add new children and set parent
     for (QueryNode child : children) {
       add(child);
     }
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TextableQueryNode.java	(working copy)
@@ -17,6 +17,9 @@
  * the License.
  */
 
+/**
+ * 
+ */
 public interface TextableQueryNode {
 
   CharSequence getText();
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/TokenizedPhraseQueryNode.java	(working copy)
@@ -23,7 +23,7 @@
 
 /**
  * A {@link TokenizedPhraseQueryNode} represents a node created by a code that
- * tokenizes/lemmatizes/analizes.
+ * tokenizes/lemmatizes/analyzes.
  */
 public class TokenizedPhraseQueryNode extends QueryNodeImpl implements
     FieldableNode {
Index: contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html
===================================================================
--- contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html	(revision 810327)
+++ contrib/queryparser/src/java/org/apache/lucene/queryParser/core/nodes/package.html	(working copy)
@@ -61,7 +61,7 @@
 <li>FuzzyQueryNode - fuzzy node</li>
 <li>ParametricRangeQueryNode - used for parametric field:[low_value TO high_value]</li>
 <li>ProximityQueryNode - used for proximity search</li>
-<li>TokenizedPhraseQueryNode - used by tokenizers/lemmatizers/analizers for phrases/autophrases</li>
+<li>TokenizedPhraseQueryNode - used by tokenizers/lemmatizers/analyzers for phrases/autophrases</li>
 </ul>
 </p>
 <p>
@@ -82,7 +82,7 @@
 <li>DeletedQueryNode - used by processors on optimizations</li>
 <li>MatchAllDocsQueryNode - used by processors on optimizations</li>
 <li>MatchNoDocsQueryNode - used by processors on optimizations</li>
-<li>NoTokenFoundQueryNode - used by tokenizers/lemmatizers/analizers</li>
+<li>NoTokenFoundQueryNode - used by tokenizers/lemmatizers/analyzers</li>
 </ul>
 </p>
 </body>
Index: contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java
===================================================================
--- contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java	(revision 810327)
+++ contrib/regex/src/java/org/apache/lucene/search/regex/JakartaRegexpCapabilities.java	(working copy)
@@ -29,7 +29,7 @@
   private RE regexp;
   
   // Define the flags that are possible. Redefine them here
-  // to avoid exposign the RE class to the caller.
+  // to avoid exposing the RE class to the caller.
   
   private int flags = RE.MATCH_NORMAL;
 
@@ -44,7 +44,7 @@
   public static final int FLAG_MATCH_CASEINDEPENDENT = RE.MATCH_CASEINDEPENDENT;
  
   /**
-   * Contructs a RegexCapabilities with the default MATCH_NORMAL match style.
+   * Constructs a RegexCapabilities with the default MATCH_NORMAL match style.
    */
   public JakartaRegexpCapabilities() {}
   
Index: contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java
===================================================================
--- contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java	(revision 810327)
+++ contrib/regex/src/java/org/apache/lucene/search/regex/JavaUtilRegexCapabilities.java	(working copy)
@@ -54,7 +54,7 @@
    * Constructor that allows for the modification of the flags that
    * the java.util.regex.Pattern will use to compile the regular expression.
    * This gives the user the ability to fine-tune how the regular expression 
-   * to match the functionlity that they need. 
+   * to match the functionality that they need. 
    * The {@link java.util.regex.Pattern Pattern} class supports specifying 
    * these fields via the regular expression text itself, but this gives the caller
    * another option to modify the behavior. Useful in cases where the regular expression text
Index: contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/geometry/FloatLatLng.java	(working copy)
@@ -23,7 +23,7 @@
   private boolean normalized;
   
   public FloatLatLng(double lat, double lng) {
-    if (lat>90.0 || lat<-90.0) throw new IllegalArgumentException("Illegal lattitude value " + lat);
+    if (lat>90.0 || lat<-90.0) throw new IllegalArgumentException("Illegal latitude value " + lat);
     this.lat=lat;
     this.lng=lng;
   }
Index: contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/geometry/LatLng.java	(working copy)
@@ -105,7 +105,7 @@
    * @param ll2
    *            Second lat,lng position to calculate distance to.
    * @param lUnits
-   *            Units to calculate distace, defaults to miles
+   *            Units to calculate distance, defaults to miles
    * 
    * @return Returns the distance in meters or miles.
    */
@@ -120,7 +120,7 @@
     if (lat1 == lat2 && lng1 == lng2)
       return 0.0;
 
-    // Get the m_dLongitude diffeernce. Don't need to worry about
+    // Get the m_dLongitude difference. Don't need to worry about
     // crossing 180 since cos(x) = cos(-x)
     double dLon = lng2 - lng1;
 
Index: contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/Ellipse.java	(working copy)
@@ -105,7 +105,7 @@
     if (pt1 == null)
       pt1 = new Point2D();
 
-    // Solution is found by paramterizing the line segment and
+    // Solution is found by parameterizing the line segment and
     // substituting those values into the ellipse equation.
     // Results in a quadratic equation.
     double x1 = center.x();
Index: contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/LineSegment.java	(working copy)
@@ -37,7 +37,7 @@
 
   /**
    * Finds the distance of a specified point from the line segment and the
-   * closest point on the segement to the specified point.
+   * closest point on the segment to the specified point.
    * 
    * @param P
    *            Test point.
Index: contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/CartesianTierPlotter.java	(working copy)
@@ -77,7 +77,7 @@
   
   /**
    * TierBoxId is latitude box id + longitude box id
-   * where latitude box id, and longitude box id are transposded in to position
+   * where latitude box id, and longitude box id are transposed in to position
    * coordinates.
    * 
    * @param latitude
Index: contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
===================================================================
--- contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java	(revision 810327)
+++ contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java	(working copy)
@@ -19,7 +19,7 @@
 
 /**
  * Based on Sinusoidal Projections
- * Project a latitude / longitude on a 2D cartisian map
+ * Project a latitude / longitude on a 2D cartesian map
  * 
  */
 public class SinusoidalProjector implements IProjector {
Index: contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java
===================================================================
--- contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java	(revision 810327)
+++ contrib/spellchecker/src/java/org/apache/lucene/search/spell/JaroWinklerDistance.java	(working copy)
@@ -103,7 +103,7 @@
 
   /**
    * Returns the current value of the threshold used for adding the Winkler bonus.
-   * The deafult value is 0.7.
+   * The default value is 0.7.
    * @return the current value of the threshold
    */
   public float getThreshold() {
Index: contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj
===================================================================
--- contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj	(revision 810327)
+++ contrib/surround/src/java/org/apache/lucene/queryParser/surround/parser/QueryParser.jj	(working copy)
@@ -64,7 +64,7 @@
   final char quote = '\"';
   final char fieldOperator = ':';
   final char comma = ','; /* prefix list separator */
-  final char carat = '^'; /* weight oparator */
+  final char carat = '^'; /* weight operator */
  
   static public SrndQuery parse(String query) throws ParseException {
     QueryParser parser = new QueryParser();
Index: contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java
===================================================================
--- contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java	(revision 810327)
+++ contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java	(working copy)
@@ -118,7 +118,7 @@
                 //for each row make a new document
                 Document document = new Document();
                 //add the row number of this row in the decorated list model
-                //this will allow us to retrive the results later
+                //this will allow us to retrieve the results later
                 //and map this list model's row to a row in the decorated
                 //list model
                 document.add(new Field(ROW_NUMBER, "" + row, Field.Store.YES, Field.Index.ANALYZED));
@@ -187,7 +187,7 @@
             //iterate through the hits
             //get the row number stored at the index
             //that number is the row number of the decorated
-            //tabble model row that we are mapping to
+            //table model row that we are mapping to
             for (int t=0; t<hits.length(); t++){
                 Document document = hits.doc(t);
                 Fieldable field = document.getField(ROW_NUMBER);
Index: contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java
===================================================================
--- contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java	(revision 810327)
+++ contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java	(working copy)
@@ -43,7 +43,7 @@
  * a TableModel and provides sorting functionality. The benefit
  * of this architecture is that you can decorate any TableModel
  * implementation with this searching table model -- making it
- * easy to add searching functionaliy to existing JTables -- or
+ * easy to add searching functionality to existing JTables -- or
  * making new search capable table lucene.
  *
  * <p>This decorator works by holding a reference to a decorated ot inner
@@ -169,7 +169,7 @@
                 //for each row make a new document
                 Document document = new Document();
                 //add the row number of this row in the decorated table model
-                //this will allow us to retrive the results later
+                //this will allow us to retrieve the results later
                 //and map this table model's row to a row in the decorated
                 //table model
                 document.add(new Field(ROW_NUMBER, "" + row, Field.Store.YES, Field.Index.ANALYZED));
@@ -268,7 +268,7 @@
             //iterate through the hits
             //get the row number stored at the index
             //that number is the row number of the decorated
-            //tabble model row that we are mapping to
+            //table model row that we are mapping to
             for (int t=0; t<hits.length(); t++){
                 Document document = hits.doc(t);
                 Fieldable field = document.getField(ROW_NUMBER);
Index: contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
===================================================================
--- contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java	(revision 810327)
+++ contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java	(working copy)
@@ -142,8 +142,8 @@
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
@@ -156,8 +156,8 @@
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
@@ -170,8 +170,8 @@
   }
 
   /**
-   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
-   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource}.
+   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the
+   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource}.
    *
    * @param input The input
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java	(revision 810327)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java	(working copy)
@@ -230,7 +230,7 @@
     /**
      * Forms a Lucene index based on the 2 maps.
      *
-     * @param indexDir the direcotry where the index should be created
+     * @param indexDir the directory where the index should be created
      * @param word2Nums
      * @param num2Words
      */
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html	(revision 810327)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/package.html	(working copy)
@@ -33,7 +33,7 @@
 	<ol>
 	    <li> Download the <a href="http://www.cogsci.princeton.edu/2.0/WNprolog-2.0.tar.gz">WordNet prolog database</a> , gunzip, untar etc.
 	<li> Invoke Syn2Index as appropriate to build a synonym index.
-	    It'll take 2 arguments, the path to wn_s.pl from that WordNet downlaod, and the index name.
+	    It'll take 2 arguments, the path to wn_s.pl from that WordNet download, and the index name.
    
 	 <li> Update your UI so that as appropriate you call SynExpand.expand(...) to expand user queries with synonyms.
        </ol>
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/CorePlusExtensionsParser.java	(working copy)
@@ -24,12 +24,16 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class CorePlusExtensionsParser extends CoreParser
 {
 
 	/**
 	 * Construct an XML parser that uses a single instance QueryParser for handling 
-	 * UserQuery tags - all parse operations are synchronised on this parser
+	 * UserQuery tags - all parse operations are synchronized on this parser
 	 * @param analyzer
 	 * @param parser A QueryParser which will be synchronized on during parse calls.
 	 */
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/DOMUtils.java	(working copy)
@@ -24,6 +24,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class DOMUtils
 {
     public static Element getChildByTagOrFail(Element e, String name)	throws ParserException
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilder.java	(working copy)
@@ -22,6 +22,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public interface FilterBuilder {
 	 public Filter getFilter(Element e) throws ParserException;
 }
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java	(working copy)
@@ -24,6 +24,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class FilterBuilderFactory implements FilterBuilder {
 
 	HashMap builders=new HashMap();
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/ParserException.java	(working copy)
@@ -19,6 +19,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class ParserException extends Exception {
 
 	/**
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java	(working copy)
@@ -24,6 +24,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class QueryBuilderFactory implements QueryBuilder {
 
 	HashMap builders=new HashMap();
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanFilterBuilder.java	(working copy)
@@ -31,6 +31,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class BooleanFilterBuilder implements FilterBuilder {
 	
 	private FilterBuilder factory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BooleanQueryBuilder.java	(working copy)
@@ -29,7 +29,9 @@
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class BooleanQueryBuilder implements QueryBuilder {
 	
 	private QueryBuilder factory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingQueryBuilder.java	(working copy)
@@ -23,6 +23,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class BoostingQueryBuilder implements QueryBuilder
 {
 	
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/BoostingTermBuilder.java	(working copy)
@@ -24,6 +24,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class BoostingTermBuilder extends SpanBuilderBase
 {
 
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/ConstantScoreQueryBuilder.java	(working copy)
@@ -23,6 +23,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class ConstantScoreQueryBuilder implements QueryBuilder
 {
 	private FilterBuilderFactory filterFactory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/DuplicateFilterBuilder.java	(working copy)
@@ -32,6 +32,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class DuplicateFilterBuilder implements FilterBuilder {
 	
 
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FilteredQueryBuilder.java	(working copy)
@@ -29,6 +29,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class FilteredQueryBuilder implements QueryBuilder {
 	
 	private FilterBuilder filterFactory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/FuzzyLikeThisQueryBuilder.java	(working copy)
@@ -25,6 +25,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class FuzzyLikeThisQueryBuilder implements QueryBuilder
 {
 	int defaultMaxNumTerms=50;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java	(working copy)
@@ -34,7 +34,9 @@
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class LikeThisQueryBuilder implements QueryBuilder {
 
 	private Analyzer analyzer;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/MatchAllDocsQueryBuilder.java	(working copy)
@@ -21,6 +21,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class MatchAllDocsQueryBuilder implements QueryBuilder
 {
 	public Query getQuery(Element e) throws ParserException
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/RangeFilterBuilder.java	(working copy)
@@ -27,7 +27,9 @@
  */
 
 
-
+/**
+ * 
+ */
 public class RangeFilterBuilder implements FilterBuilder {
 
 
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanBuilderBase.java	(working copy)
@@ -19,6 +19,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public abstract class SpanBuilderBase implements SpanQueryBuilder
 {
 	public Query getQuery(Element e) throws ParserException
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanFirstBuilder.java	(working copy)
@@ -21,6 +21,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanFirstBuilder extends SpanBuilderBase
 {
     SpanQueryBuilder factory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java	(working copy)
@@ -24,6 +24,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanNearBuilder extends SpanBuilderBase
 {
 	SpanQueryBuilder factory;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNotBuilder.java	(working copy)
@@ -21,6 +21,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanNotBuilder extends SpanBuilderBase
 {
     
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java	(working copy)
@@ -24,6 +24,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanOrBuilder extends SpanBuilderBase
 {
     
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java	(working copy)
@@ -30,6 +30,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanOrTermsBuilder extends SpanBuilderBase
 {
     Analyzer analyzer;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java	(working copy)
@@ -23,6 +23,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class SpanQueryBuilderFactory implements SpanQueryBuilder {
 
 	HashMap builders=new HashMap();
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanTermBuilder.java	(working copy)
@@ -22,6 +22,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+/**
+ * 
+ */
 public class SpanTermBuilder extends SpanBuilderBase
 {
 
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermQueryBuilder.java	(working copy)
@@ -24,7 +24,9 @@
  * limitations under the License.
  */
 
-
+/**
+ * 
+ */
 public class TermQueryBuilder implements QueryBuilder {
 
 	public Query getQuery(Element e) throws ParserException {
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java	(revision 810339)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java	(working copy)
@@ -31,6 +31,9 @@
  * limitations under the License.
  */
 
+/**
+ * 
+ */
 public class TermsFilterBuilder implements FilterBuilder
 {
 	Analyzer analyzer;
Index: src/java/org/apache/lucene/analysis/CharReader.java
===================================================================
--- src/java/org/apache/lucene/analysis/CharReader.java	(revision 810327)
+++ src/java/org/apache/lucene/analysis/CharReader.java	(working copy)
@@ -23,7 +23,7 @@
 /**
  * CharReader is a Reader wrapper. It reads chars from
  * Reader and outputs {@link CharStream}, defining an
- * identify fucntion {@link #correctOffset} method that
+ * identify function {@link #correctOffset} method that
  * simply returns the provided offset.
  */
 public final class CharReader extends CharStream {
Index: src/java/org/apache/lucene/analysis/CharacterCache.java
===================================================================
--- src/java/org/apache/lucene/analysis/CharacterCache.java	(revision 810327)
+++ src/java/org/apache/lucene/analysis/CharacterCache.java	(working copy)
@@ -36,7 +36,7 @@
    * 
    * @param c
    *          a char value
-   * @return a Charater representation of the given char value.
+   * @return a Character representation of the given char value.
    */
   public static Character valueOf(char c) {
     if (c < cache.length) {
Index: src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java
===================================================================
--- src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java	(revision 810327)
+++ src/java/org/apache/lucene/analysis/TeeSinkTokenFilter.java	(working copy)
@@ -119,7 +119,7 @@
   
   /**
    * <code>TeeSinkTokenFilter</code> passes all tokens to the added sinks
-   * when itsself is consumed. To be sure, that all tokens from the input
+   * when itself is consumed. To be sure, that all tokens from the input
    * stream are passed to the sinks, you can call this methods.
    * This instance is exhausted after this, but all sinks are instant available.
    */
Index: src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
===================================================================
--- src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java	(revision 810327)
+++ src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java	(working copy)
@@ -86,7 +86,7 @@
    *
    * @param replaceInvalidAcronym Set to true to have new
    * instances of StandardTokenizer replace mischaracterized
-   * acronyms by default.  Set to false to preseve the
+   * acronyms by default.  Set to false to preserve the
    * previous (before 2.4) buggy behavior.  Alternatively,
    * set the system property
    * org.apache.lucene.analysis.standard.StandardAnalyzer.replaceInvalidAcronym
Index: src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex
===================================================================
--- src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex	(revision 810327)
+++ src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex	(working copy)
@@ -86,7 +86,7 @@
 ALPHANUM   = ({LETTER}|{THAI}|[:digit:])+
 
 // internal apostrophes: O'Reilly, you're, O'Reilly's
-// use a post-filter to remove possesives
+// use a post-filter to remove possessives
 APOSTROPHE =  {ALPHA} ("'" {ALPHA})+
 
 // acronyms: U.S.A., I.B.M., etc.
Index: src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java
===================================================================
--- src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java	(revision 810327)
+++ src/java/org/apache/lucene/analysis/tokenattributes/FlagsAttributeImpl.java	(working copy)
@@ -23,7 +23,7 @@
 
 /**
  * This attribute can be used to pass different flags down the tokenizer chain,
- * e. g. from one TokenFilter to another one. 
+ * eg from one TokenFilter to another one. 
  */
 public class FlagsAttributeImpl extends AttributeImpl implements FlagsAttribute, Cloneable, Serializable {
   private int flags = 0;
Index: src/java/org/apache/lucene/document/AbstractField.java
===================================================================
--- src/java/org/apache/lucene/document/AbstractField.java	(revision 810327)
+++ src/java/org/apache/lucene/document/AbstractField.java	(working copy)
@@ -204,7 +204,7 @@
 
   /**
    * True iff terms are stored as term vector together with their offsets 
-   * (start and end positon in source text).
+   * (start and end position in source text).
    */
   public boolean isStoreOffsetWithTermVector(){
     return storeOffsetWithTermVector;
Index: src/java/org/apache/lucene/document/DateTools.java
===================================================================
--- src/java/org/apache/lucene/document/DateTools.java	(revision 810327)
+++ src/java/org/apache/lucene/document/DateTools.java	(working copy)
@@ -84,7 +84,7 @@
    * @param resolution the desired resolution, see
    *  {@link #round(Date, DateTools.Resolution)}
    * @return a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
-   *  depeding on <code>resolution</code>; using GMT as timezone 
+   *  depending on <code>resolution</code>; using GMT as timezone 
    */
   public static synchronized String dateToString(Date date, Resolution resolution) {
     return timeToString(date.getTime(), resolution);
@@ -97,7 +97,7 @@
    * @param resolution the desired resolution, see
    *  {@link #round(long, DateTools.Resolution)}
    * @return a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
-   *  depeding on <code>resolution</code>; using GMT as timezone
+   *  depending on <code>resolution</code>; using GMT as timezone
    */
   public static synchronized String timeToString(long time, Resolution resolution) {
     calInstance.setTimeInMillis(round(time, resolution));
Index: src/java/org/apache/lucene/document/Field.java
===================================================================
--- src/java/org/apache/lucene/document/Field.java	(revision 810327)
+++ src/java/org/apache/lucene/document/Field.java	(working copy)
@@ -46,7 +46,7 @@
      * useful for long documents and for binary valued fields.
      * @deprecated Please use {@link CompressionTools} instead.
      * For string fields that were previously indexed and stored using compression,
-     * the new way to achive this is: First add the field indexed-only (no store)
+     * the new way to achieve this is: First add the field indexed-only (no store)
      * and additionally using the same field name as a binary, stored field
      * with {@link CompressionTools#compressString}.
      */
@@ -132,7 +132,7 @@
     public static final TermVector NO = new TermVector("NO");
     
     /** Store the term vectors of each document. A term vector is a list
-     * of the document's terms and their number of occurences in that document. */
+     * of the document's terms and their number of occurrences in that document. */
     public static final TermVector YES = new TermVector("YES");
     
     /**
Index: src/java/org/apache/lucene/document/FieldSelectorResult.java
===================================================================
--- src/java/org/apache/lucene/document/FieldSelectorResult.java	(revision 810327)
+++ src/java/org/apache/lucene/document/FieldSelectorResult.java	(working copy)
@@ -25,7 +25,7 @@
 public final class FieldSelectorResult implements Serializable {
 
     /**
-     * Load this {@link Field} every time the {@link Document} is loaded, reading in the data as it is encounterd.
+     * Load this {@link Field} every time the {@link Document} is loaded, reading in the data as it is encountered.
      *  {@link Document#getField(String)} and {@link Document#getFieldable(String)} should not return null.
      *<p/>
      * {@link Document#add(Fieldable)} should be called by the Reader.
Index: src/java/org/apache/lucene/document/Fieldable.java
===================================================================
--- src/java/org/apache/lucene/document/Fieldable.java	(revision 810327)
+++ src/java/org/apache/lucene/document/Fieldable.java	(working copy)
@@ -43,7 +43,7 @@
    * used to compute the norm factor for the field.  By
    * default, in the {@link
    * org.apache.lucene.search.Similarity#computeNorm(String,
-   * FieldInvertState)} method, the boost value is multipled
+   * FieldInvertState)} method, the boost value is multiplied
    * by the {@link
    * org.apache.lucene.search.Similarity#lengthNorm(String,
    * int)} and then rounded by {@link org.apache.lucene.search.Similarity#encodeNorm(float)} before it is stored in the
Index: src/java/org/apache/lucene/document/NumberTools.java
===================================================================
--- src/java/org/apache/lucene/document/NumberTools.java	(revision 810327)
+++ src/java/org/apache/lucene/document/NumberTools.java	(working copy)
@@ -77,7 +77,7 @@
     public static String longToString(long l) {
 
         if (l == Long.MIN_VALUE) {
-            // special case, because long is not symetric around zero
+            // special case, because long is not symmetric around zero
             return MIN_STRING_VALUE;
         }
 
Index: src/java/org/apache/lucene/document/NumericField.java
===================================================================
--- src/java/org/apache/lucene/document/NumericField.java	(revision 810327)
+++ src/java/org/apache/lucene/document/NumericField.java	(working copy)
@@ -86,7 +86,7 @@
  * you should separately index a single-valued <code>NumericField</code>.</p>
  *
  * <p>A <code>NumericField</code> will consume somewhat more disk space
- * in the index than an ordindary single-valued field.
+ * in the index than an ordinary single-valued field.
  * However, for a typical index that includes substantial
  * textual content per document, this increase will likely
  * be in the noise. </p>
@@ -146,7 +146,7 @@
    * {@link NumericUtils#PRECISION_STEP_DEFAULT} (4). The instance is not yet initialized with
    * a numeric value, before indexing a document containing this field,
    * set a value using the various set<em>???</em>Value() methods.
-   * This constrcutor creates an indexed, but not stored field.
+   * This constructor creates an indexed, but not stored field.
    * @param name the field name
    */
   public NumericField(String name) {
@@ -172,7 +172,7 @@
    * <code>precisionStep</code>. The instance is not yet initialized with
    * a numeric value, before indexing a document containing this field,
    * set a value using the various set<em>???</em>Value() methods.
-   * This constrcutor creates an indexed, but not stored field.
+   * This constructor creates an indexed, but not stored field.
    * @param name the field name
    * @param precisionStep the used <a href="../search/NumericRangeQuery.html#precisionStepDesc">precision step</a>
    */
@@ -217,7 +217,7 @@
     return null;
   }
     
-  /** Returns the numeric value as a string (how it is stored, when {@link Field.Store#YES} is choosen). */
+  /** Returns the numeric value as a string (how it is stored, when {@link Field.Store#YES} is chosen). */
   public String stringValue()   {
     return (fieldsData == null) ? null : fieldsData.toString();
   }
Index: src/java/org/apache/lucene/index/DirectoryReader.java
===================================================================
--- src/java/org/apache/lucene/index/DirectoryReader.java	(revision 810327)
+++ src/java/org/apache/lucene/index/DirectoryReader.java	(working copy)
@@ -173,7 +173,7 @@
     initialize(readers);
   }
 
-  /** This contructor is only used for {@link #reopen()} */
+  /** This constructor is only used for {@link #reopen()} */
   DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,
                   Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {
     this.directory = directory;
Index: src/java/org/apache/lucene/index/FieldInfos.java
===================================================================
--- src/java/org/apache/lucene/index/FieldInfos.java	(revision 810327)
+++ src/java/org/apache/lucene/index/FieldInfos.java	(working copy)
@@ -137,7 +137,7 @@
    * 
    * @param names The names of the fields
    * @param storeTermVectors Whether the fields store term vectors or not
-   * @param storePositionWithTermVector treu if positions should be stored.
+   * @param storePositionWithTermVector true if positions should be stored.
    * @param storeOffsetWithTermVector true if offsets should be stored
    */
   synchronized public void addIndexed(Collection names, boolean storeTermVectors, boolean storePositionWithTermVector, 
Index: src/java/org/apache/lucene/index/FreqProxTermsWriter.java
===================================================================
--- src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(revision 810327)
+++ src/java/org/apache/lucene/index/FreqProxTermsWriter.java	(working copy)
@@ -61,7 +61,7 @@
   void abort() {}
 
 
-  // TODO: would be nice to factor out morme of this, eg the
+  // TODO: would be nice to factor out more of this, eg the
   // FreqProxFieldMergeState, and code to visit all Fields
   // under the same FieldInfo together, up into TermsHash*.
   // Other writers would presumably share alot of this...
Index: src/java/org/apache/lucene/index/IndexModifier.java
===================================================================
--- src/java/org/apache/lucene/index/IndexModifier.java	(revision 810327)
+++ src/java/org/apache/lucene/index/IndexModifier.java	(working copy)
@@ -450,7 +450,7 @@
    * running out of memory.<p/>
    * Note that this effectively truncates large documents, excluding from the
    * index terms that occur further in the document.  If you know your source
-   * documents are large, be sure to set this value high enough to accomodate
+   * documents are large, be sure to set this value high enough to accommodate
    * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
    * is your memory, but you should anticipate an OutOfMemoryError.<p/>
    * By default, no more than 10,000 terms will be indexed for a field.
Index: src/java/org/apache/lucene/index/IndexReader.java
===================================================================
--- src/java/org/apache/lucene/index/IndexReader.java	(revision 810327)
+++ src/java/org/apache/lucene/index/IndexReader.java	(working copy)
@@ -386,7 +386,7 @@
    *  if you use this reader to perform deletes or to set
    *  norms); see {@link IndexWriter} for details.
    * @param readOnly true if no changes (deletions, norms) will be made with this IndexReader
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -455,7 +455,7 @@
    *  if you use this reader to perform deletes or to set
    *  norms); see {@link IndexWriter} for details.
    * @param readOnly true if no changes (deletions, norms) will be made with this IndexReader
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -1393,7 +1393,7 @@
 
           FileOutputStream f = new FileOutputStream(files[i]);
 
-          // read and write with a small buffer, which is more effectiv than reading byte by byte
+          // read and write with a small buffer, which is more effective than reading byte by byte
           byte[] buffer = new byte[1024];
           int chunk = buffer.length;
           while(len > 0) {
Index: src/java/org/apache/lucene/index/IndexWriter.java
===================================================================
--- src/java/org/apache/lucene/index/IndexWriter.java	(revision 810327)
+++ src/java/org/apache/lucene/index/IndexWriter.java	(working copy)
@@ -399,7 +399,7 @@
    * feature, please report back on your findings so we can
    * learn, improve and iterate.</p>
    *
-   * <p>The resulting reader suppports {@link
+   * <p>The resulting reader supports {@link
    * IndexReader#reopen}, but that call will simply forward
    * back to this method (though this may change in the
    * future).</p>
@@ -440,7 +440,7 @@
   /** Expert: like {@link #getReader}, except you can
    *  specify which termInfosIndexDivisor should be used for
    *  any newly opened readers.
-   * @param termInfosIndexDivisor Subsambles which indexed
+   * @param termInfosIndexDivisor Subsamples which indexed
    *  terms are loaded into RAM. This has the same effect as {@link
    *  IndexWriter#setTermIndexInterval} except that setting
    *  must be done at indexing time while this setting can be
@@ -481,8 +481,8 @@
 
     private final Map readerMap = new HashMap();
 
-    /** Forcefully clear changes for the specifed segments,
-     *  and remove from the pool.   This is called on succesful merge. */
+    /** Forcefully clear changes for the specified segments,
+     *  and remove from the pool.   This is called on successful merge. */
     synchronized void clear(SegmentInfos infos) throws IOException {
       if (infos == null) {
         Iterator iter = readerMap.entrySet().iterator();
@@ -2371,7 +2371,7 @@
    * running out of memory.<p/>
    * Note that this effectively truncates large documents, excluding from the
    * index terms that occur further in the document.  If you know your source
-   * documents are large, be sure to set this value high enough to accomodate
+   * documents are large, be sure to set this value high enough to accommodate
    * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
    * is your memory, but you should anticipate an OutOfMemoryError.<p/>
    * By default, no more than 10,000 terms will be indexed for a field.
@@ -5328,7 +5328,7 @@
     // against thread timing hazards where notifyAll()
     // falls to be called, we wait for at most 1 second
     // and then return so caller can check if wait
-    // conditions are satisified:
+    // conditions are satisfied:
     try {
       wait(1000);
     } catch (InterruptedException ie) {
Index: src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java
===================================================================
--- src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java	(revision 810327)
+++ src/java/org/apache/lucene/index/LogByteSizeMergePolicy.java	(working copy)
@@ -54,7 +54,7 @@
     maxMergeSize = (long) (mb*1024*1024);
   }
 
-  /** Returns the largest segment (meaured by total byte
+  /** Returns the largest segment (measured by total byte
    *  size of the segment's files, in MB) that may be merged
    *  with other segments.
    *  @see #setMaxMergeMB */
Index: src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java
===================================================================
--- src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java	(revision 810327)
+++ src/java/org/apache/lucene/index/MultiLevelSkipListWriter.java	(working copy)
@@ -40,7 +40,7 @@
  * Therefore the number of entries on level i is: floor(df / ((skipInterval ^ (i + 1))).
  * 
  * Each skip entry on a level i>0 contains a pointer to the corresponding skip entry in list i-1.
- * This guarantess a logarithmic amount of skips to find the target document.
+ * This guarantees a logarithmic amount of skips to find the target document.
  * 
  * While this class takes care of writing the different skip levels,
  * subclasses must define the actual format of the skip data.
@@ -89,7 +89,7 @@
   /**
    * Subclasses must implement the actual skip data encoding in this method.
    *  
-   * @param level the level skip data shall be writting for
+   * @param level the level skip data shall be writing for
    * @param skipBuffer the skip buffer to write to
    */
   protected abstract void writeSkipData(int level, IndexOutput skipBuffer) throws IOException;
Index: src/java/org/apache/lucene/index/ParallelReader.java
===================================================================
--- src/java/org/apache/lucene/index/ParallelReader.java	(revision 810327)
+++ src/java/org/apache/lucene/index/ParallelReader.java	(working copy)
@@ -78,7 +78,7 @@
   }
 
  /** Add an IndexReader whose stored fields will not be returned.  This can
-  * accellerate search when stored fields are only needed from a subset of
+  * accelerate search when stored fields are only needed from a subset of
   * the IndexReaders.
   *
   * @throws IllegalArgumentException if not all indexes contain the same number
Index: src/java/org/apache/lucene/index/SegmentInfos.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentInfos.java	(revision 810327)
+++ src/java/org/apache/lucene/index/SegmentInfos.java	(working copy)
@@ -85,7 +85,7 @@
   public static final int FORMAT_USER_DATA = -8;
 
   /** This format adds optional per-segment String
-   *  dianostics storage, and switches userData to Map */
+   *  diagnostics storage, and switches userData to Map */
   public static final int FORMAT_DIAGNOSTICS = -9;
 
   /* This must always point to the most recent file format. */
@@ -756,7 +756,7 @@
   }
 
   /**
-   * Returns a new SegmentInfos containg the SegmentInfo
+   * Returns a new SegmentInfos containing the SegmentInfo
    * instances in the specified range first (inclusive) to
    * last (exclusive), so total number of segments returned
    * is last-first.
Index: src/java/org/apache/lucene/index/SegmentReader.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentReader.java	(revision 810327)
+++ src/java/org/apache/lucene/index/SegmentReader.java	(working copy)
@@ -76,7 +76,7 @@
     // Counts how many other reader share the core objects
     // (freqStream, proxStream, tis, etc.) of this reader;
     // when coreRef drops to 0, these core objects may be
-    // closed.  A given insance of SegmentReader may be
+    // closed.  A given instance of SegmentReader may be
     // closed, even those it shares core objects with other
     // SegmentReaders:
     private final Ref ref = new Ref();
@@ -802,7 +802,7 @@
       success = true;
     } finally {
       if (!success) {
-        // An exception occured during reopen, we have to decRef the norms
+        // An exception occurred during reopen, we have to decRef the norms
         // that we incRef'ed already and close singleNormsStream and FieldsReader
         clone.decRef();
       }
Index: src/java/org/apache/lucene/index/SegmentTermPositions.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentTermPositions.java	(revision 810327)
+++ src/java/org/apache/lucene/index/SegmentTermPositions.java	(working copy)
@@ -29,7 +29,7 @@
   
   // the current payload length
   private int payloadLength;
-  // indicates whether the payload of the currend position has
+  // indicates whether the payload of the current position has
   // been read from the proxStream yet
   private boolean needToLoadPayload;
   
@@ -63,7 +63,7 @@
     if (currentFieldOmitTermFreqAndPositions)
       // This field does not store term freq, positions, payloads
       return 0;
-    // perform lazy skips if neccessary
+    // perform lazy skips if necessary
     lazySkip();
     proxCount--;
     return position += readDeltaPosition();
@@ -133,7 +133,7 @@
     needToLoadPayload = false;
   }
 
-  // It is not always neccessary to move the prox pointer
+  // It is not always necessary to move the prox pointer
   // to a new document after the freq pointer has been moved.
   // Consider for example a phrase query with two terms:
   // the freq pointer for term 1 has to move to document x
Index: src/java/org/apache/lucene/index/Term.java
===================================================================
--- src/java/org/apache/lucene/index/Term.java	(revision 810327)
+++ src/java/org/apache/lucene/index/Term.java	(working copy)
@@ -22,7 +22,7 @@
 /**
   A Term represents a word from text.  This is the unit of search.  It is
   composed of two elements, the text of the word, as a string, and the name of
-  the field that the text occured in, an interned string.
+  the field that the text occurred in, an interned string.
 
   Note that terms may represent more than words from text fields, but also
   things like dates, email addresses, urls, etc.  */
Index: src/java/org/apache/lucene/index/TermFreqVector.java
===================================================================
--- src/java/org/apache/lucene/index/TermFreqVector.java	(revision 810327)
+++ src/java/org/apache/lucene/index/TermFreqVector.java	(working copy)
@@ -18,7 +18,7 @@
  */
 
 /** Provides access to stored term vector of 
- *  a document field.  The vector consists of the name of the field, an array of the terms tha occur in the field of the
+ *  a document field.  The vector consists of the name of the field, an array of the terms that occur in the field of the
  * {@link org.apache.lucene.document.Document} and a parallel array of frequencies.  Thus, getTermFrequencies()[5] corresponds with the
  * frequency of getTerms()[5], assuming there are at least 5 terms in the Document.
  */
Index: src/java/org/apache/lucene/index/TermInfosWriter.java
===================================================================
--- src/java/org/apache/lucene/index/TermInfosWriter.java	(revision 810327)
+++ src/java/org/apache/lucene/index/TermInfosWriter.java	(working copy)
@@ -57,7 +57,7 @@
   int indexInterval = 128;
 
   /** Expert: The fraction of {@link TermDocs} entries stored in skip tables,
-   * used to accellerate {@link TermDocs#skipTo(int)}.  Larger values result in
+   * used to accelerate {@link TermDocs#skipTo(int)}.  Larger values result in
    * smaller indexes, greater acceleration, but fewer accelerable cases, while
    * smaller values result in bigger indexes, less acceleration and more
    * accelerable cases. More detailed experiments would be useful here. */
Index: src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
===================================================================
--- src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java	(revision 810327)
+++ src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java	(working copy)
@@ -113,7 +113,7 @@
 
     final IndexOutput tvf = perThread.doc.tvf;
 
-    // This is called once, after inverting all occurences
+    // This is called once, after inverting all occurrences
     // of a given field in the doc.  At this point we flush
     // our hash into the DocWriter.
 
Index: src/java/org/apache/lucene/queryParser/QueryParser.jj
===================================================================
--- src/java/org/apache/lucene/queryParser/QueryParser.jj	(revision 810327)
+++ src/java/org/apache/lucene/queryParser/QueryParser.jj	(working copy)
@@ -783,7 +783,7 @@
       DateTools.Resolution resolution = getDateResolution(field);
       if (resolution == null) {
         // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibilty with
+        // use deprecated DateField to maintain compatibility with
         // pre-1.9 Lucene versions.
         part1 = DateField.dateToString(d1);
         part2 = DateField.dateToString(d2);
Index: src/java/org/apache/lucene/search/BooleanQuery.java
===================================================================
--- src/java/org/apache/lucene/search/BooleanQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/BooleanQuery.java	(working copy)
@@ -129,7 +129,7 @@
 
   /**
    * Gets the minimum number of the optional BooleanClauses
-   * which must be satisifed.
+   * which must be satisfied.
    */
   public int getMinimumNumberShouldMatch() {
     return minNrShouldMatch;
Index: src/java/org/apache/lucene/search/ComplexExplanation.java
===================================================================
--- src/java/org/apache/lucene/search/ComplexExplanation.java	(revision 810327)
+++ src/java/org/apache/lucene/search/ComplexExplanation.java	(working copy)
@@ -27,7 +27,7 @@
   }
 
   public ComplexExplanation(boolean match, float value, String description) {
-    // NOTE: use of "boolean" instead of "Boolean" in params is concious
+    // NOTE: use of "boolean" instead of "Boolean" in params is conscious
     // choice to encourage clients to be specific.
     super(value, description);
     this.match = Boolean.valueOf(match);
Index: src/java/org/apache/lucene/search/DisjunctionMaxScorer.java
===================================================================
--- src/java/org/apache/lucene/search/DisjunctionMaxScorer.java	(revision 810327)
+++ src/java/org/apache/lucene/search/DisjunctionMaxScorer.java	(working copy)
@@ -19,7 +19,7 @@
 import java.io.IOException;
 
 /**
- * The Scorer for DisjunctionMaxQuery's.  The union of all documents generated by the the subquery scorers
+ * The Scorer for DisjunctionMaxQuery.  The union of all documents generated by the the subquery scorers
  * is generated in document number order.  The score for each document is the maximum of the scores computed
  * by the subquery scorers that generate that document, plus tieBreakerMultiplier times the sum of the scores
  * for the other subqueries that generate the document.
Index: src/java/org/apache/lucene/search/DocIdSetIterator.java
===================================================================
--- src/java/org/apache/lucene/search/DocIdSetIterator.java	(revision 810327)
+++ src/java/org/apache/lucene/search/DocIdSetIterator.java	(working copy)
@@ -125,7 +125,7 @@
    * 
    * Some implementations are considerably more efficient than that.
    * <p>
-   * <b>NOTE:</b> certain implemenations may return a different value (each
+   * <b>NOTE:</b> certain implementations may return a different value (each
    * time) if called several times in a row with the same target.
    * <p>
    * <b>NOTE:</b> this method may be called with {@value #NO_MORE_DOCS} for
Index: src/java/org/apache/lucene/search/FieldCache.java
===================================================================
--- src/java/org/apache/lucene/search/FieldCache.java	(revision 810327)
+++ src/java/org/apache/lucene/search/FieldCache.java	(working copy)
@@ -584,8 +584,8 @@
    * EXPERT: Generates an array of CacheEntry objects representing all items 
    * currently in the FieldCache.
    * <p>
-   * NOTE: These CacheEntry objects maintain a strong refrence to the 
-   * Cached Values.  Maintaining refrences to a CacheEntry the IndexReader 
+   * NOTE: These CacheEntry objects maintain a strong reference to the 
+   * Cached Values.  Maintaining references to a CacheEntry the IndexReader 
    * associated with it has garbage collected will prevent the Value itself
    * from being garbage collected when the Cache drops the WeakRefrence.
    * </p>
Index: src/java/org/apache/lucene/search/FieldComparator.java
===================================================================
--- src/java/org/apache/lucene/search/FieldComparator.java	(revision 810327)
+++ src/java/org/apache/lucene/search/FieldComparator.java	(working copy)
@@ -402,7 +402,7 @@
 
   /** Sorts by descending relevance.  NOTE: if you are
    *  sorting only by descending relevance and then
-   *  secondarily by ascending docID, peformance is faster
+   *  secondarily by ascending docID, performance is faster
    *  using {@link TopScoreDocCollector} directly (which {@link
    *  IndexSearcher#search} uses when no {@link Sort} is
    *  specified). */
Index: src/java/org/apache/lucene/search/FieldSortedHitQueue.java
===================================================================
--- src/java/org/apache/lucene/search/FieldSortedHitQueue.java	(revision 810327)
+++ src/java/org/apache/lucene/search/FieldSortedHitQueue.java	(working copy)
@@ -233,7 +233,7 @@
    /**
    * Returns a comparator for sorting hits according to a field containing bytes.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -264,7 +264,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing shorts.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -295,7 +295,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing integers.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -326,7 +326,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing integers.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg integer values.
+   * @param fieldname  Fieldable containing integer values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -358,7 +358,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing floats.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg float values.
+   * @param fieldname  Fieldable containing float values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -389,7 +389,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing doubles.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg float values.
+   * @param fieldname  Fieldable containing float values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -420,7 +420,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing strings.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg string values.
+   * @param fieldname  Fieldable containing string values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -451,7 +451,7 @@
   /**
    * Returns a comparator for sorting hits according to a field containing strings.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg string values.
+   * @param fieldname  Fieldable containing string values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
@@ -492,7 +492,7 @@
    * floats or strings.  Once the type is determined, one of the other static methods
    * in this class is called to get the comparator.
    * @param reader  Index to use.
-   * @param fieldname  Fieldable containg values.
+   * @param fieldname  Fieldable containing values.
    * @return  Comparator for sorting hits.
    * @throws IOException If an error occurs reading the index.
    */
Index: src/java/org/apache/lucene/search/FilterManager.java
===================================================================
--- src/java/org/apache/lucene/search/FilterManager.java	(revision 810327)
+++ src/java/org/apache/lucene/search/FilterManager.java	(working copy)
@@ -27,8 +27,8 @@
 /**
  * Filter caching singleton.  It can be used 
  * to save filters locally for reuse.
- * This class makes it possble to cache Filters even when using RMI, as it
- * keeps the cache on the seaercher side of the RMI connection.
+ * This class makes it possible to cache Filters even when using RMI, as it
+ * keeps the cache on the searcher side of the RMI connection.
  * 
  * Also could be used as a persistent storage for any filter as long as the
  * filter provides a proper hashCode(), as that is used as the key in the cache.
@@ -42,7 +42,7 @@
   
   /** The default maximum number of Filters in the cache */
   protected static final int  DEFAULT_CACHE_CLEAN_SIZE = 100;
-  /** The default frequency of cache clenup */
+  /** The default frequency of cache cleanup */
   protected static final long DEFAULT_CACHE_SLEEP_TIME = 1000 * 60 * 10;
 
   /** The cache itself */
@@ -71,7 +71,7 @@
 
     filterCleaner   = new FilterCleaner();
     Thread fcThread = new Thread(filterCleaner);
-    // setto be a Daemon so it doesn't have to be stopped
+    // set to be a Daemon so it doesn't have to be stopped
     fcThread.setDaemon(true);
     fcThread.start();
   }
@@ -86,7 +86,7 @@
 
   /**
    * Sets the cache cleaning frequency in milliseconds.
-   * @param cleanSleepTime cleaning frequency in millioseconds
+   * @param cleanSleepTime cleaning frequency in milliseconds
    */
   public void setCleanThreadSleepTime(long cleanSleepTime) {
     this.cleanSleepTime  = cleanSleepTime;
Index: src/java/org/apache/lucene/search/FuzzyTermEnum.java
===================================================================
--- src/java/org/apache/lucene/search/FuzzyTermEnum.java	(revision 810327)
+++ src/java/org/apache/lucene/search/FuzzyTermEnum.java	(working copy)
@@ -22,7 +22,7 @@
 
 import java.io.IOException;
 
-/** Subclass of FilteredTermEnum for enumerating all terms that are similiar
+/** Subclass of FilteredTermEnum for enumerating all terms that are similar
  * to the specified filter term.
  *
  * <p>Term enumerations are always ordered by Term.compareTo().  Each term in
@@ -37,7 +37,7 @@
   private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19;
 
   /* Allows us save time required to create a new array
-   * everytime similarity is called.
+   * every time similarity is called.
    */
   private int[][] d;
 
@@ -181,20 +181,20 @@
    * <p>Embedded within this algorithm is a fail-fast Levenshtein distance
    * algorithm.  The fail-fast algorithm differs from the standard Levenshtein
    * distance algorithm in that it is aborted if it is discovered that the
-   * mimimum distance between the words is greater than some threshold.
+   * minimum distance between the words is greater than some threshold.
    *
    * <p>To calculate the maximum distance threshold we use the following formula:
    * <pre>
    *     (1 - minimumSimilarity) * length</pre>
    * where length is the shortest term including any prefix that is not part of the
-   * similarity comparision.  This formula was derived by solving for what maximum value
+   * similarity comparison.  This formula was derived by solving for what maximum value
    * of distance returns false for the following statements:
    * <pre>
    *   similarity = 1 - ((float)distance / (float) (prefixLength + Math.min(textlen, targetlen)));
    *   return (similarity > minimumSimilarity);</pre>
    * where distance is the Levenshtein distance for the two words.
    * </p>
-   * <p>Levenshtein distance (also known as edit distance) is a measure of similiarity
+   * <p>Levenshtein distance (also known as edit distance) is a measure of similarity
    * between two strings where the distance is measured as the number of character
    * deletions, insertions or substitutions required to transform one string to
    * the other string.
@@ -221,7 +221,7 @@
       //too many edits
       //for example "pre" length is 3 and "prefixes" length is 8.  We can see that
       //given this optimal circumstance, the edit distance cannot be less than 5.
-      //which is 8-3 or more precisesly Math.abs(3-8).
+      //which is 8-3 or more precisely Math.abs(3-8).
       //if our maximum edit distance is 4, then we can discard this word
       //without looking at it.
       return 0.0f;
Index: src/java/org/apache/lucene/search/MultiTermQuery.java
===================================================================
--- src/java/org/apache/lucene/search/MultiTermQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/MultiTermQuery.java	(working copy)
@@ -356,7 +356,7 @@
    * with {@link #clearTotalNumberOfTerms}.
    * <p>On optimized indexes / no MultiReaders, you get the correct number of
    * unique terms for the whole index. Use this number to compare different queries.
-   * For non-optimized indexes this number can also be achived in
+   * For non-optimized indexes this number can also be achieved in
    * non-constant-score mode. In constant-score mode you get the total number of
    * terms seeked for all segments / sub-readers.
    * @see #clearTotalNumberOfTerms
Index: src/java/org/apache/lucene/search/NumericRangeQuery.java
===================================================================
--- src/java/org/apache/lucene/search/NumericRangeQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/NumericRangeQuery.java	(working copy)
@@ -108,7 +108,7 @@
  * <code>7*255*2 + 255 = 3825</code> distinct terms (when there is a term for every distinct value of an
  * 8-byte-number in the index and the range covers almost all of them; a maximum of 255 distinct values is used
  * because it would always be possible to reduce the full 256 values to one term with degraded precision).
- * In practise, we have seen up to 300 terms in most cases (index with 500,000 metadata records
+ * In practice, we have seen up to 300 terms in most cases (index with 500,000 metadata records
  * and a uniform value distribution).</p>
  *
  * <a name="precisionStepDesc"><h3>Precision Step</h3>
@@ -141,7 +141,7 @@
  *  Sorting is also possible with range query optimized fields using one of the above <code>precisionSteps</code>.
  * </ul>
  *
- * <p>Comparisions of the different types of RangeQueries on an index with about 500,000 docs showed
+ * <p>Comparisons of the different types of RangeQueries on an index with about 500,000 docs showed
  * that {@link TermRangeQuery} in boolean rewrite mode (with raised {@link BooleanQuery} clause count)
  * took about 30-40 secs to complete, {@link TermRangeQuery} in constant score filter rewrite mode took 5 secs
  * and executing this class took &lt;100ms to complete (on an Opteron64 machine, Java 1.5, 8 bit
Index: src/java/org/apache/lucene/search/PhraseScorer.java
===================================================================
--- src/java/org/apache/lucene/search/PhraseScorer.java	(revision 810327)
+++ src/java/org/apache/lucene/search/PhraseScorer.java	(working copy)
@@ -23,7 +23,7 @@
 
 /** Expert: Scoring functionality for phrase queries.
  * <br>A document is considered matching if it contains the phrase-query terms  
- * at "valid" positons. What "valid positions" are
+ * at "valid" positions. What "valid positions" are
  * depends on the type of the phrase query: for an exact phrase query terms are required 
  * to appear in adjacent locations, while for a sloppy phrase query some distance between 
  * the terms is allowed. The abstract method {@link #phraseFreq()} of extending classes
@@ -41,7 +41,7 @@
   protected PhraseQueue pq;
   protected PhrasePositions first, last;
 
-  private float freq; //prhase frequency in current doc as computed by phraseFreq().
+  private float freq; //phrase frequency in current doc as computed by phraseFreq().
 
   PhraseScorer(Weight weight, TermPositions[] tps, int[] offsets,
       Similarity similarity, byte[] norms) {
Index: src/java/org/apache/lucene/search/Query.java
===================================================================
--- src/java/org/apache/lucene/search/Query.java	(revision 810327)
+++ src/java/org/apache/lucene/search/Query.java	(working copy)
@@ -160,7 +160,7 @@
   
 
   /**
-   * Expert: adds all terms occuring in this query to the terms set. Only
+   * Expert: adds all terms occurring in this query to the terms set. Only
    * works if this query is in its {@link #rewrite rewritten} form.
    * 
    * @throws UnsupportedOperationException if this query is not yet rewritten
Index: src/java/org/apache/lucene/search/SimilarityDelegator.java
===================================================================
--- src/java/org/apache/lucene/search/SimilarityDelegator.java	(revision 810327)
+++ src/java/org/apache/lucene/search/SimilarityDelegator.java	(working copy)
@@ -21,7 +21,7 @@
 
 /** Expert: Delegating scoring implementation.  Useful in {@link
  * Query#getSimilarity(Searcher)} implementations, to override only certain
- * methods of a Searcher's Similiarty implementation.. */
+ * methods of a Searcher's Similarity implementation.. */
 public class SimilarityDelegator extends Similarity {
 
   private Similarity delegee;
Index: src/java/org/apache/lucene/search/TimeLimitedCollector.java
===================================================================
--- src/java/org/apache/lucene/search/TimeLimitedCollector.java	(revision 810327)
+++ src/java/org/apache/lucene/search/TimeLimitedCollector.java	(working copy)
@@ -53,7 +53,7 @@
     // * use of volatile keyword ensures that it does not reside in
     //   a register, but in main memory (so that changes are visible to
     //   other threads).
-    // * visibility of changes does not need to be instantanous, we can
+    // * visibility of changes does not need to be instantaneous, we can
     //   afford losing a tick or two.
     //
     // See section 17 of the Java Language Specification for details.
Index: src/java/org/apache/lucene/search/TimeLimitingCollector.java
===================================================================
--- src/java/org/apache/lucene/search/TimeLimitingCollector.java	(revision 810327)
+++ src/java/org/apache/lucene/search/TimeLimitingCollector.java	(working copy)
@@ -53,7 +53,7 @@
     // * use of volatile keyword ensures that it does not reside in
     //   a register, but in main memory (so that changes are visible to
     //   other threads).
-    // * visibility of changes does not need to be instantanous, we can
+    // * visibility of changes does not need to be instantaneous, we can
     //   afford losing a tick or two.
     //
     // See section 17 of the Java Language Specification for details.
Index: src/java/org/apache/lucene/search/TopDocsCollector.java
===================================================================
--- src/java/org/apache/lucene/search/TopDocsCollector.java	(revision 810327)
+++ src/java/org/apache/lucene/search/TopDocsCollector.java	(working copy)
@@ -85,7 +85,7 @@
    * Returns the documents in the rage [start .. pq.size()) that were collected
    * by this collector. Note that if start >= pq.size(), an empty TopDocs is
    * returned.<br>
-   * This method is convenient to call if the application allways asks for the
+   * This method is convenient to call if the application always asks for the
    * last results, starting from the last 'page'.<br>
    * <b>NOTE:</b> you cannot call this method more than once for each search
    * execution. If you need to call it more than once, passing each time a
Index: src/java/org/apache/lucene/search/function/CustomScoreQuery.java
===================================================================
--- src/java/org/apache/lucene/search/function/CustomScoreQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/function/CustomScoreQuery.java	(working copy)
@@ -61,9 +61,9 @@
 
   /**
    * Create a CustomScoreQuery over input subQuery and a {@link ValueSourceQuery}.
-   * @param subQuery the sub query whose score is being customed. Must not be null.
+   * @param subQuery the sub query whose score is being customized. Must not be null.
    * @param valSrcQuery a value source query whose scores are used in the custom score
-   * computation. For most simple/convineient use case this would be a 
+   * computation. For most simple/convenient use case this would be a 
    * {@link org.apache.lucene.search.function.FieldScoreQuery FieldScoreQuery}.
    * This parameter is optional - it can be null.
    */
Index: src/java/org/apache/lucene/search/function/DocValues.java
===================================================================
--- src/java/org/apache/lucene/search/function/DocValues.java	(revision 810327)
+++ src/java/org/apache/lucene/search/function/DocValues.java	(working copy)
@@ -86,7 +86,7 @@
   }
   
   /**
-   * Return a string representation of a doc value, as reuired for Explanations.
+   * Return a string representation of a doc value, as required for Explanations.
    */
   public abstract String toString(int doc);
   
Index: src/java/org/apache/lucene/search/function/FieldCacheSource.java
===================================================================
--- src/java/org/apache/lucene/search/function/FieldCacheSource.java	(revision 810327)
+++ src/java/org/apache/lucene/search/function/FieldCacheSource.java	(working copy)
@@ -26,7 +26,7 @@
  * Expert: A base class for ValueSource implementations that retrieve values for
  * a single field from the {@link org.apache.lucene.search.FieldCache FieldCache}.
  * <p>
- * Fields used herein nust be indexed (doesn't matter if these fields are stored or not).
+ * Fields used herein must be indexed (doesn't matter if these fields are stored or not).
  * <p> 
  * It is assumed that each such indexed field is untokenized, or at least has a single token in a document.
  * For documents with multiple tokens of the same field, behavior is undefined (It is likely that current 
Index: src/java/org/apache/lucene/search/function/FieldScoreQuery.java
===================================================================
--- src/java/org/apache/lucene/search/function/FieldScoreQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/function/FieldScoreQuery.java	(working copy)
@@ -28,7 +28,7 @@
  *  <li>The field used here is indexed, and has exactly 
  *      one token in every scored document.</li> 
  *  <li>Best if this field is un_tokenized.</li>
- *  <li>That token is parsable to the selected type.</li>
+ *  <li>That token is parseable to the selected type.</li>
  * </ul>
  * <p>  
  * Combining this query in a FunctionQuery allows much freedom in affecting document scores.
@@ -36,7 +36,7 @@
  * default Lucene scoring is superior in quality to scoring modified as explained here.
  * However, in some cases, and certainly for research experiments, this capability may turn useful.
  * <p>
- * When contructing this query, select the appropriate type. That type should match the data stored in the
+ * When constructing this query, select the appropriate type. That type should match the data stored in the
  * field. So in fact the "right" type should be selected before indexing. Type selection
  * has effect on the RAM usage: 
  * <ul>
Index: src/java/org/apache/lucene/search/function/ValueSourceQuery.java
===================================================================
--- src/java/org/apache/lucene/search/function/ValueSourceQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/function/ValueSourceQuery.java	(working copy)
@@ -105,7 +105,7 @@
 
   /**
    * A scorer that (simply) matches all documents, and scores each document with 
-   * the value of the value soure in effect. As an example, if the value source 
+   * the value of the value source in effect. As an example, if the value source 
    * is a (cached) field source, then value of that field in that document will 
    * be used. (assuming field is indexed for this doc, with a single token.)   
    */
Index: src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
===================================================================
--- src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(working copy)
@@ -139,7 +139,7 @@
       /**
        * Returns the SpanScorer score only.
        * <p/>
-       * Should not be overriden without good cause!
+       * Should not be overridden without good cause!
        * 
        * @return the score for just the Span part w/o the payload
        * @throws IOException
Index: src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java
===================================================================
--- src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java	(working copy)
@@ -88,7 +88,7 @@
   }
 
   // :NOTE: getBoost and setBoost are not proxied to the maskedQuery
-  // ...this is done to be more consistent with thigns like SpanFirstQuery
+  // ...this is done to be more consistent with things like SpanFirstQuery
   
   public Spans getSpans(IndexReader reader) throws IOException {
     return maskedQuery.getSpans(reader);
Index: src/java/org/apache/lucene/search/spans/SpanNotQuery.java
===================================================================
--- src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(revision 810327)
+++ src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(working copy)
@@ -136,7 +136,7 @@
         public int start() { return includeSpans.start(); }
         public int end() { return includeSpans.end(); }
 
-      // TODO: Remove warning after API has been finalizedb
+      // TODO: Remove warning after API has been finalized
       public Collection/*<byte[]>*/ getPayload() throws IOException {
         ArrayList result = null;
         if (includeSpans.isPayloadAvailable()) {
Index: src/java/org/apache/lucene/store/Directory.java
===================================================================
--- src/java/org/apache/lucene/store/Directory.java	(revision 810327)
+++ src/java/org/apache/lucene/store/Directory.java	(working copy)
@@ -60,7 +60,7 @@
    *  filtering of the contents in a directory, and it will
    *  never return null (throws IOException instead).
    *
-   *  Currently this method simply fallsback to {@link
+   *  Currently this method simply falls back to {@link
    *  #list} for Directory impls outside of Lucene's core &
    *  contrib, but in 3.0 that method will be removed and
    *  this method will become abstract. */
Index: src/java/org/apache/lucene/store/FSDirectory.java
===================================================================
--- src/java/org/apache/lucene/store/FSDirectory.java	(revision 810327)
+++ src/java/org/apache/lucene/store/FSDirectory.java	(working copy)
@@ -42,7 +42,7 @@
  *
  * <ul>
  *
- *  <li> {@link SimpleFSDirectory} is a straighforward
+ *  <li> {@link SimpleFSDirectory} is a straightforward
  *       implementation using java.io.RandomAccessFile.
  *       However, it has poor concurrent performance
  *       (multiple threads will bottleneck) as it
Index: src/java/org/apache/lucene/store/FileSwitchDirectory.java
===================================================================
--- src/java/org/apache/lucene/store/FileSwitchDirectory.java	(revision 810327)
+++ src/java/org/apache/lucene/store/FileSwitchDirectory.java	(working copy)
@@ -23,7 +23,7 @@
 import java.util.Set;
 
 /**
- * Expert: A Directory instance that switches files betweeen
+ * Expert: A Directory instance that switches files between
  * two other Directory instances.
 
  * <p>Files with the specified extensions are placed in the
Index: src/java/org/apache/lucene/store/IndexInput.java
===================================================================
--- src/java/org/apache/lucene/store/IndexInput.java	(revision 810327)
+++ src/java/org/apache/lucene/store/IndexInput.java	(working copy)
@@ -190,7 +190,7 @@
   }
   
 
-  /** Closes the stream to futher operations. */
+  /** Closes the stream to further operations. */
   public abstract void close() throws IOException;
 
   /** Returns the current position in this file, where the next read will
Index: src/java/org/apache/lucene/store/MMapDirectory.java
===================================================================
--- src/java/org/apache/lucene/store/MMapDirectory.java	(revision 810327)
+++ src/java/org/apache/lucene/store/MMapDirectory.java	(working copy)
@@ -44,7 +44,7 @@
  * guaranteed to fit within the address space.
  * On 32 bit platforms also consult {@link #setMaxChunkSize}
  * if you have problems with mmap failing because of fragmented
- * address space. If you get an OutOfMemoryException, it is recommened
+ * address space. If you get an OutOfMemoryException, it is recommended
  * to reduce the chunk size, until it works.
  *
  * <p>Due to <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4724038">
@@ -101,7 +101,7 @@
   private int maxBBuf = Constants.JRE_IS_64BIT ? Integer.MAX_VALUE : (256*1024*1024);
   
   /**
-   * <code>true</code>, if this platform supports unmapping mmaped files.
+   * <code>true</code>, if this platform supports unmapping mmapped files.
    */
   public static final boolean UNMAP_SUPPORTED;
   static {
@@ -124,7 +124,7 @@
    * It forcefully unmaps the buffer on close by using
    * an undocumented internal cleanup functionality.
    * <p><b>NOTE:</b> Enabling this is completely unsupported
-   * by Java and may lead to JVM crashs if <code>IndexInput</code>
+   * by Java and may lead to JVM crashes if <code>IndexInput</code>
    * is closed while another thread is still accessing it (SIGSEGV).
    * @throws IllegalArgumentException if {@link #UNMAP_SUPPORTED}
    * is <code>false</code> and the workaround cannot be enabled.
@@ -181,7 +181,7 @@
    * bit slower (as the correct chunk must be resolved on each seek)
    * but the chance is higher that mmap does not fail. On 64 bit
    * Java platforms, this parameter should always be {@link Integer#MAX_VALUE},
-   * as the adress space is big enough.
+   * as the address space is big enough.
    */
   public void setMaxChunkSize(final int maxBBuf) {
     if (maxBBuf<=0)
Index: src/java/org/apache/lucene/store/NativeFSLockFactory.java
===================================================================
--- src/java/org/apache/lucene/store/NativeFSLockFactory.java	(revision 810327)
+++ src/java/org/apache/lucene/store/NativeFSLockFactory.java	(working copy)
@@ -231,7 +231,7 @@
       try {
         f = new RandomAccessFile(path, "rw");
       } catch (IOException e) {
-        // On Windows, we can get intermittant "Access
+        // On Windows, we can get intermittent "Access
         // Denied" here.  So, we treat this as failure to
         // acquire the lock, but, store the reason in case
         // there is in fact a real error case.
@@ -246,7 +246,7 @@
             lock = channel.tryLock();
           } catch (IOException e) {
             // At least on OS X, we will sometimes get an
-            // intermittant "Permission Denied" IOException,
+            // intermittent "Permission Denied" IOException,
             // which seems to simply mean "you failed to get
             // the lock".  But other IOExceptions could be
             // "permanent" (eg, locking is not supported via
Index: src/java/org/apache/lucene/util/ArrayUtil.java
===================================================================
--- src/java/org/apache/lucene/util/ArrayUtil.java	(revision 810327)
+++ src/java/org/apache/lucene/util/ArrayUtil.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+/**
+ * Methods for manipulating arrays.
+ */
 public final class ArrayUtil {
   /*
      Begin Apache Harmony code
Index: src/java/org/apache/lucene/util/BitUtil.java
===================================================================
--- src/java/org/apache/lucene/util/BitUtil.java	(revision 810327)
+++ src/java/org/apache/lucene/util/BitUtil.java	(working copy)
@@ -17,7 +17,7 @@
 
 package org.apache.lucene.util; // from org.apache.solr.util rev 555343
 
-/**  A variety of high efficiencly bit twiddling routines.
+/**  A variety of high efficiency bit twiddling routines.
  *
  * @version $Id$
  */
Index: src/java/org/apache/lucene/util/CloseableThreadLocal.java
===================================================================
--- src/java/org/apache/lucene/util/CloseableThreadLocal.java	(revision 810327)
+++ src/java/org/apache/lucene/util/CloseableThreadLocal.java	(working copy)
@@ -33,7 +33,7 @@
  *  While not technically a memory leak, because eventually
  *  the memory will be reclaimed, it can take a long time
  *  and you can easily hit OutOfMemoryError because from the
- *  GC's standpoint the stale entries are not reclaimaible.
+ *  GC's standpoint the stale entries are not reclaimable.
  * 
  *  This class works around that, by only enrolling
  *  WeakReference values into the ThreadLocal, and
Index: src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
===================================================================
--- src/java/org/apache/lucene/util/FieldCacheSanityChecker.java	(revision 810327)
+++ src/java/org/apache/lucene/util/FieldCacheSanityChecker.java	(working copy)
@@ -154,7 +154,7 @@
    * Internal helper method used by check that iterates over 
    * valMismatchKeys and generates a Collection of Insanity 
    * instances accordingly.  The MapOfSets are used to populate 
-   * the Insantiy objects. 
+   * the Insanity objects. 
    * @see InsanityType#VALUEMISMATCH
    */
   private Collection checkValueMismatch(MapOfSets valIdToItems,
@@ -195,7 +195,7 @@
    * Internal helper method used by check that iterates over 
    * the keys of readerFieldToValIds and generates a Collection 
    * of Insanity instances whenever two (or more) ReaderField instances are 
-   * found that have an ancestery relationships.  
+   * found that have an ancestry relationships.  
    *
    * @see InsanityType#SUBREADER
    */
@@ -327,7 +327,7 @@
 
   /**
    * Simple container for a collection of related CacheEntry objects that 
-   * in conjunction with eachother represent some "insane" usage of the 
+   * in conjunction with each other represent some "insane" usage of the 
    * FieldCache.
    */
   public final static class Insanity {
@@ -384,7 +384,7 @@
   }
 
   /**
-   * An Enumaration of the differnet types of "insane" behavior that 
+   * An Enumeration of the different types of "insane" behavior that 
    * may be detected in a FieldCache.
    *
    * @see InsanityType#SUBREADER
Index: src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
===================================================================
--- src/java/org/apache/lucene/util/IndexableBinaryStringTools.java	(revision 810327)
+++ src/java/org/apache/lucene/util/IndexableBinaryStringTools.java	(working copy)
@@ -43,7 +43,7 @@
  * on the CharBuffers and ByteBuffers it uses, so only wrapped arrays may be
  * used.  This class interprets the arrayOffset() and limit() values returned by
  * its input buffers as beginning and end+1 positions on the wrapped array,
- * resprectively; similarly, on the output buffer, arrayOffset() is the first
+ * respectively; similarly, on the output buffer, arrayOffset() is the first
  * position written to, and limit() is set to one past the final output array
  * position.
  */
Index: src/java/org/apache/lucene/util/MapOfSets.java
===================================================================
--- src/java/org/apache/lucene/util/MapOfSets.java	(revision 810327)
+++ src/java/org/apache/lucene/util/MapOfSets.java	(working copy)
@@ -24,7 +24,7 @@
 import java.util.Map;
 
 /**
- * Helper class for keeping Listss of Objects associated with keys. <b>WARNING: THIS CLASS IS NOT THREAD SAFE</b>
+ * Helper class for keeping Lists of Objects associated with keys. <b>WARNING: THIS CLASS IS NOT THREAD SAFE</b>
  */
 public class MapOfSets {
 
Index: src/java/org/apache/lucene/util/NumericUtils.java
===================================================================
--- src/java/org/apache/lucene/util/NumericUtils.java	(revision 810327)
+++ src/java/org/apache/lucene/util/NumericUtils.java	(working copy)
@@ -31,7 +31,7 @@
  * the lowest possible precision in the trie, while the boundaries are matched
  * more exactly. This reduces the number of terms dramatically.
  *
- * <p>This class generates terms to achive this: First the numerical integer values need to
+ * <p>This class generates terms to achieve this: First the numerical integer values need to
  * be converted to strings. For that integer values (32 bit or 64 bit) are made unsigned
  * and the bits are converted to ASCII chars with each 7 bit. The resulting string is
  * sortable like the original integer value. Each value is also prefixed
Index: src/java/org/apache/lucene/util/ReaderUtil.java
===================================================================
--- src/java/org/apache/lucene/util/ReaderUtil.java	(revision 810327)
+++ src/java/org/apache/lucene/util/ReaderUtil.java	(working copy)
@@ -72,7 +72,7 @@
    * 
    * @param reader parent reader
    * @param subIndex index of desired sub reader
-   * @return the subreader at subINdex
+   * @return the subreader at subIndex
    */
   public static IndexReader subReader(IndexReader reader, int subIndex) {
     List subReadersList = new ArrayList();
Index: src/java/org/apache/lucene/util/ToStringUtils.java
===================================================================
--- src/java/org/apache/lucene/util/ToStringUtils.java	(revision 810327)
+++ src/java/org/apache/lucene/util/ToStringUtils.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+/**
+ * Helper methods to ease implementing {@link Object#toString()}.
+ */
 public class ToStringUtils {
   /** for printing boost only if not 1.0 */ 
   public static String boost(float boost) {
Index: src/java/org/apache/lucene/util/UnicodeUtil.java
===================================================================
--- src/java/org/apache/lucene/util/UnicodeUtil.java	(revision 810327)
+++ src/java/org/apache/lucene/util/UnicodeUtil.java	(working copy)
@@ -410,10 +410,10 @@
           if (nextCH >= UNI_SUR_LOW_START && nextCH <= UNI_SUR_LOW_END) {
             // Valid surrogate pair
           } else
-            // Unmatched hight surrogate
+            // Unmatched high surrogate
             return false;
         } else
-          // Unmatched hight surrogate
+          // Unmatched high surrogate
           return false;
       } else if (ch >= UNI_SUR_LOW_START && ch <= UNI_SUR_LOW_END)
         // Unmatched low surrogate
