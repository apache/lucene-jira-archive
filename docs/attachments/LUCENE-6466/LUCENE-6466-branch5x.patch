Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1685519)
+++ lucene/CHANGES.txt	(working copy)
@@ -67,6 +67,9 @@
 * LUCENE-6525: Deprecate IndexWriterConfig's writeLockTimeout.
   (Robert Muir)
 
+* LUCENE-6466: Moved SpanQuery.getSpans() and .extractTerms() to SpanWeight
+  (Alan Woodward, Robert Muir)
+
 Bug fixes
 
 * LUCENE-6500: ParallelCompositeReader did not always call

Property changes on: lucene/CHANGES.txt
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene/CHANGES.txt:r1680565,1682513
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadNearQuery.java	(working copy)
@@ -18,11 +18,16 @@
  */
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
 import java.util.Objects;
 
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Scorer;
@@ -71,7 +76,11 @@
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    return new PayloadNearSpanWeight(this, searcher, needsScores);
+    List<SpanWeight> subWeights = new ArrayList<>();
+    for (SpanQuery q : clauses) {
+      subWeights.add(q.createWeight(searcher, false));
+    }
+    return new PayloadNearSpanWeight(subWeights, searcher, needsScores ? getTermContexts(subWeights) : null);
   }
 
   @Override
@@ -128,18 +137,20 @@
           && function.equals(other.function);
   }
 
-  public class PayloadNearSpanWeight extends SpanWeight {
-    public PayloadNearSpanWeight(SpanQuery query, IndexSearcher searcher, boolean needsScores)
+  public class PayloadNearSpanWeight extends SpanNearWeight {
+
+    public PayloadNearSpanWeight(List<SpanWeight> subWeights, IndexSearcher searcher, Map<Term, TermContext> terms)
         throws IOException {
-      super(query, searcher, needsScores);
+      super(subWeights, searcher, terms);
     }
 
     @Override
     public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Spans spans = query.getSpans(context, acceptDocs, termContexts);
+      Spans spans = super.getSpans(context, acceptDocs);
+      Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null)
               ? null
-              : new PayloadNearSpanScorer(spans, this, similarity, similarity.simScorer(stats, context));
+              : new PayloadNearSpanScorer(spans, this, simScorer);
     }
     
     @Override
@@ -150,7 +161,7 @@
         if (newDoc == doc) {
           float freq = scorer.freq();
           Explanation freqExplanation = Explanation.match(freq, "phraseFreq=" + freq);
-          SimScorer docScorer = similarity.simScorer(stats, context);
+          SimScorer docScorer = similarity.simScorer(simWeight, context);
           Explanation scoreExplanation = docScorer.explain(doc, freqExplanation);
           Explanation expl = Explanation.match(
               scoreExplanation.getValue(),
@@ -176,8 +187,7 @@
     protected float payloadScore;
     private int payloadsSeen;
 
-    protected PayloadNearSpanScorer(Spans spans, SpanWeight weight,
-        Similarity similarity, Similarity.SimScorer docScorer) throws IOException {
+    protected PayloadNearSpanScorer(Spans spans, SpanWeight weight, Similarity.SimScorer docScorer) throws IOException {
       super(spans, weight, docScorer);
       this.spans = spans;
     }
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil.java	(working copy)
@@ -20,17 +20,13 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Map;
-import java.util.TreeSet;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.DisjunctionMaxQuery;
@@ -44,6 +40,7 @@
 import org.apache.lucene.search.spans.SpanOrQuery;
 import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
 
 /**
@@ -179,16 +176,12 @@
 
   private void getPayloads(Collection<byte []> payloads, SpanQuery query)
       throws IOException {
-    Map<Term,TermContext> termContexts = new HashMap<>();
-    TreeSet<Term> terms = new TreeSet<>();
+
     final IndexSearcher searcher = new IndexSearcher(context);
     searcher.setQueryCache(null);
-    searcher.createNormalizedWeight(query, false).extractTerms(terms);
-    for (Term term : terms) {
-      termContexts.put(term, TermContext.build(context, term));
-    }
+    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);
     for (LeafReaderContext leafReaderContext : context.leaves()) {
-      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);
+      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs());
       if (spans != null) {
         while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
           while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
Index: lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/payloads/PayloadTermQuery.java	(working copy)
@@ -18,11 +18,14 @@
  */
 
 import java.io.IOException;
+import java.util.Collections;
+import java.util.Map;
 import java.util.Objects;
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
@@ -67,22 +70,24 @@
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    return new PayloadTermWeight(this, searcher, needsScores);
+    TermContext context = TermContext.build(searcher.getTopReaderContext(), term);
+    return new PayloadTermWeight(context, searcher, needsScores ? Collections.singletonMap(term, context) : null);
   }
 
-  protected class PayloadTermWeight extends SpanWeight {
+  private class PayloadTermWeight extends SpanTermWeight {
 
-    public PayloadTermWeight(PayloadTermQuery query, IndexSearcher searcher, boolean needsScores)
+    public PayloadTermWeight(TermContext context, IndexSearcher searcher, Map<Term, TermContext> terms)
         throws IOException {
-      super(query, searcher, needsScores);
+      super(context, searcher, terms);
     }
 
     @Override
     public PayloadTermSpanScorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      TermSpans spans = (TermSpans) query.getSpans(context, acceptDocs, termContexts);
+      Spans spans = super.getSpans(context, acceptDocs);
+      Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
       return (spans == null)
               ? null
-              : new PayloadTermSpanScorer(spans, this, similarity.simScorer(stats, context));
+              : new PayloadTermSpanScorer((TermSpans) spans, this, simScorer);
     }
 
     protected class PayloadTermSpanScorer extends SpanScorer {
@@ -178,7 +183,7 @@
         if (newDoc == doc) {
           float freq = scorer.sloppyFreq();
           Explanation freqExplanation = Explanation.match(freq, "phraseFreq=" + freq);
-          SimScorer docScorer = similarity.simScorer(stats, context);
+          SimScorer docScorer = similarity.simScorer(simWeight, context);
           Explanation scoreExplanation = docScorer.explain(doc, freqExplanation);
           Explanation expl = Explanation.match(
               scoreExplanation.getValue(),
Index: lucene/core/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/FieldMaskingSpanQuery.java	(working copy)
@@ -18,18 +18,11 @@
  */
 
 import java.io.IOException;
-import java.util.Map;
-import java.util.Set;
 import java.util.Objects;
 
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 /**
@@ -95,18 +88,8 @@
 
   // :NOTE: getBoost and setBoost are not proxied to the maskedQuery
   // ...this is done to be more consistent with things like SpanFirstQuery
-  
-  @Override
-  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    return maskedQuery.getSpans(context, acceptDocs, termContexts);
-  }
 
   @Override
-  public void extractTerms(Set<Term> terms) {
-    maskedQuery.extractTerms(terms);
-  }  
-
-  @Override
   public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
     return maskedQuery.createWeight(searcher, needsScores);
   }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanContainQuery.java	(working copy)
@@ -20,17 +20,19 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Set;
-import java.util.Objects;
 
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.Bits;
 
 abstract class SpanContainQuery extends SpanQuery implements Cloneable {
+
   SpanQuery big;
   SpanQuery little;
 
@@ -48,26 +50,48 @@
   @Override
   public String getField() { return big.getField(); }
 
-  /** Extract terms from both <code>big</code> and <code>little</code>. */
-  @Override
-  public void extractTerms(Set<Term> terms) {
-    big.extractTerms(terms);
-    little.extractTerms(terms);
-  }
+  public abstract class SpanContainWeight extends SpanWeight {
 
-  ArrayList<Spans> prepareConjunction(final LeafReaderContext context, final Bits acceptDocs, final Map<Term,TermContext> termContexts) throws IOException {
-    Spans bigSpans = big.getSpans(context, acceptDocs, termContexts);
-    if (bigSpans == null) {
-      return null;
+    final SpanWeight bigWeight;
+    final SpanWeight littleWeight;
+
+    public SpanContainWeight(IndexSearcher searcher, Map<Term, TermContext> terms,
+                             SpanWeight bigWeight, SpanWeight littleWeight) throws IOException {
+      super(SpanContainQuery.this, searcher, terms);
+      this.bigWeight = bigWeight;
+      this.littleWeight = littleWeight;
     }
-    Spans littleSpans = little.getSpans(context, acceptDocs, termContexts);
-    if (littleSpans == null) {
-      return null;
+
+    /**
+     * Extract terms from both <code>big</code> and <code>little</code>.
+     */
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      bigWeight.extractTerms(terms);
+      littleWeight.extractTerms(terms);
     }
-    ArrayList<Spans> bigAndLittle = new ArrayList<>();
-    bigAndLittle.add(bigSpans);
-    bigAndLittle.add(littleSpans);
-    return bigAndLittle;
+
+    ArrayList<Spans> prepareConjunction(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
+      Spans bigSpans = bigWeight.getSpans(context, acceptDocs);
+      if (bigSpans == null) {
+        return null;
+      }
+      Spans littleSpans = littleWeight.getSpans(context, acceptDocs);
+      if (littleSpans == null) {
+        return null;
+      }
+      ArrayList<Spans> bigAndLittle = new ArrayList<>();
+      bigAndLittle.add(bigSpans);
+      bigAndLittle.add(littleSpans);
+      return bigAndLittle;
+    }
+
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      bigWeight.extractTermContexts(contexts);
+      littleWeight.extractTermContexts(contexts);
+    }
+
   }
 
   String toString(String field, String name) {
@@ -117,4 +141,4 @@
     h ^= little.hashCode();
     return h;
   }
-}
\ No newline at end of file
+}
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanContainingQuery.java	(working copy)
@@ -18,12 +18,13 @@
  */
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Map;
-import java.util.ArrayList;
 
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.Bits;
 
 /** Keep matches that contain another Spans. */
@@ -48,63 +49,79 @@
           (SpanQuery) big.clone(),
           (SpanQuery) little.clone());
   }
-  
-  /** 
-   * Return spans from <code>big</code> that contain at least one spans from <code>little</code>.
-   * The payload is from the spans of <code>big</code>.
-   */
+
   @Override
-  public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, final Map<Term,TermContext> termContexts) throws IOException {
-    ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, termContexts);
-    if (containerContained == null) {
-      return null;
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    SpanWeight bigWeight = big.createWeight(searcher, false);
+    SpanWeight littleWeight = little.createWeight(searcher, false);
+    return new SpanContainingWeight(searcher, needsScores ? getTermContexts(bigWeight, littleWeight) : null,
+                                      bigWeight, littleWeight);
+  }
+
+  public class SpanContainingWeight extends SpanContainWeight {
+
+    public SpanContainingWeight(IndexSearcher searcher, Map<Term, TermContext> terms,
+                                SpanWeight bigWeight, SpanWeight littleWeight) throws IOException {
+      super(searcher, terms, bigWeight, littleWeight);
     }
-    
-    Spans big = containerContained.get(0);
-    Spans little = containerContained.get(1);
 
-    return new ContainSpans(big, little, big) {
+    /**
+     * Return spans from <code>big</code> that contain at least one spans from <code>little</code>.
+     * The payload is from the spans of <code>big</code>.
+     */
+    @Override
+    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs);
+      if (containerContained == null) {
+        return null;
+      }
 
-      @Override
-      boolean twoPhaseCurrentDocMatches() throws IOException {
-        oneExhaustedInCurrentDoc = false;
-        assert littleSpans.startPosition() == -1;
-        while (bigSpans.nextStartPosition() != NO_MORE_POSITIONS) {
-          while (littleSpans.startPosition() < bigSpans.startPosition()) {
-            if (littleSpans.nextStartPosition() == NO_MORE_POSITIONS) {
-              oneExhaustedInCurrentDoc = true;
-              return false;
+      Spans big = containerContained.get(0);
+      Spans little = containerContained.get(1);
+
+      return new ContainSpans(big, little, big) {
+
+        @Override
+        boolean twoPhaseCurrentDocMatches() throws IOException {
+          oneExhaustedInCurrentDoc = false;
+          assert littleSpans.startPosition() == -1;
+          while (bigSpans.nextStartPosition() != NO_MORE_POSITIONS) {
+            while (littleSpans.startPosition() < bigSpans.startPosition()) {
+              if (littleSpans.nextStartPosition() == NO_MORE_POSITIONS) {
+                oneExhaustedInCurrentDoc = true;
+                return false;
+              }
             }
+            if (bigSpans.endPosition() >= littleSpans.endPosition()) {
+              atFirstInCurrentDoc = true;
+              return true;
+            }
           }
-          if (bigSpans.endPosition() >= littleSpans.endPosition()) {
-            atFirstInCurrentDoc = true;
-            return true;
+          oneExhaustedInCurrentDoc = true;
+          return false;
+        }
+
+        @Override
+        public int nextStartPosition() throws IOException {
+          if (atFirstInCurrentDoc) {
+            atFirstInCurrentDoc = false;
+            return bigSpans.startPosition();
           }
-        } 
-        oneExhaustedInCurrentDoc = true;
-        return false;
-      }
-
-      @Override
-      public int nextStartPosition() throws IOException {
-        if (atFirstInCurrentDoc) {
-          atFirstInCurrentDoc = false;
-          return bigSpans.startPosition();
-        }
-        while (bigSpans.nextStartPosition() != NO_MORE_POSITIONS) {
-          while (littleSpans.startPosition() < bigSpans.startPosition()) {
-            if (littleSpans.nextStartPosition() == NO_MORE_POSITIONS) {
-              oneExhaustedInCurrentDoc = true;
-              return NO_MORE_POSITIONS;
+          while (bigSpans.nextStartPosition() != NO_MORE_POSITIONS) {
+            while (littleSpans.startPosition() < bigSpans.startPosition()) {
+              if (littleSpans.nextStartPosition() == NO_MORE_POSITIONS) {
+                oneExhaustedInCurrentDoc = true;
+                return NO_MORE_POSITIONS;
+              }
             }
+            if (bigSpans.endPosition() >= littleSpans.endPosition()) {
+              return bigSpans.startPosition();
+            }
           }
-          if (bigSpans.endPosition() >= littleSpans.endPosition()) {
-            return bigSpans.startPosition();
-          }
+          oneExhaustedInCurrentDoc = true;
+          return NO_MORE_POSITIONS;
         }
-        oneExhaustedInCurrentDoc = true;
-        return NO_MORE_POSITIONS;
-      }
-    };
+      };
+    }
   }
-}
\ No newline at end of file
+}
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java	(working copy)
@@ -18,20 +18,17 @@
  */
 
 import java.io.IOException;
-import java.util.Map;
-import java.util.Set;
 import java.util.Objects;
 
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoringRewrite;
 import org.apache.lucene.search.TopTermsRewrite;
-import org.apache.lucene.search.ScoringRewrite;
-import org.apache.lucene.search.BooleanClause.Occur; // javadocs only
-import org.apache.lucene.util.Bits;
 
 /**
  * Wraps any {@link MultiTermQuery} as a {@link SpanQuery}, 
@@ -75,11 +72,6 @@
     }
   }
 
-  @Override
-  protected void extractTerms(Set<Term> terms) {
-    throw new IllegalStateException("Rewrite first");
-  }
-
   /**
    * Expert: returns the rewriteMethod
    */
@@ -97,17 +89,17 @@
   public final void setRewriteMethod(SpanRewriteMethod rewriteMethod) {
     query.setRewriteMethod(rewriteMethod);
   }
-  
-  @Override
-  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    throw new UnsupportedOperationException("Query should have been rewritten");
-  }
 
   @Override
   public String getField() {
     return query.getField();
   }
-  
+
+  @Override
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    throw new IllegalArgumentException("Rewrite first!");
+  }
+
   /** Returns the wrapped query */
   public Query getWrappedQuery() {
     return query;
@@ -179,10 +171,7 @@
     
       @Override
       protected void addClause(SpanOrQuery topLevel, Term term, int docCount, float boost, TermContext states) {
-        // TODO: would be nice to not lose term-state here.
-        // we could add a hack option to SpanOrQuery, but the hack would only work if this is the top-level Span
-        // (if you put this thing in another span query, it would extractTerms/double-seek anyway)
-        final SpanTermQuery q = new SpanTermQuery(term);
+        final SpanTermQuery q = new SpanTermQuery(term, states);
         q.setBoost(boost);
         topLevel.addClause(q);
       }
@@ -226,7 +215,7 @@
 
         @Override
         protected void addClause(SpanOrQuery topLevel, Term term, int docFreq, float boost, TermContext states) {
-          final SpanTermQuery q = new SpanTermQuery(term);
+          final SpanTermQuery q = new SpanTermQuery(term, states);
           q.setBoost(boost);
           topLevel.addClause(q);
         }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java	(working copy)
@@ -17,22 +17,23 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.Terms;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
 /** Matches spans which are near one another.  One can specify <i>slop</i>, the
  * maximum number of intervening unmatched positions, as well as whether
  * matches are required to be in-order.
@@ -90,13 +91,6 @@
   public String getField() { return field; }
 
   @Override
-  public void extractTerms(Set<Term> terms) {
-    for (final SpanQuery clause : clauses) {
-      clause.extractTerms(terms);
-    }
-  }
-
-  @Override
   public String toString(String field) {
     StringBuilder buffer = new StringBuilder();
     buffer.append("spanNear([");
@@ -118,25 +112,59 @@
   }
 
   @Override
-  public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    List<SpanWeight> subWeights = new ArrayList<>();
+    for (SpanQuery q : clauses) {
+      subWeights.add(q.createWeight(searcher, false));
+    }
+    return new SpanNearWeight(subWeights, searcher, needsScores ? getTermContexts(subWeights) : null);
+  }
 
-    for (SpanQuery seq : clauses) {
-      Spans subSpan = seq.getSpans(context, acceptDocs, termContexts);
-      if (subSpan != null) {
-        subSpans.add(subSpan);
-      } else {
-        return null; // all required
+  public class SpanNearWeight extends SpanWeight {
+
+    final List<SpanWeight> subWeights;
+
+    public SpanNearWeight(List<SpanWeight> subWeights, IndexSearcher searcher, Map<Term, TermContext> terms) throws IOException {
+      super(SpanNearQuery.this, searcher, terms);
+      this.subWeights = subWeights;
+    }
+
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      for (SpanWeight w : subWeights) {
+        w.extractTermContexts(contexts);
       }
     }
 
-    Terms terms = context.reader().terms(field);
-    if (terms == null)
-      return null; // field does not exist
+    @Override
+    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs) throws IOException {
 
-    // all NearSpans require at least two subSpans
-    return (!inOrder) ? new NearSpansUnordered(this, subSpans) : new NearSpansOrdered(this, subSpans);
+      Terms terms = context.reader().terms(field);
+      if (terms == null) {
+        return null; // field does not exist
+      }
 
+      ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
+      for (SpanWeight w : subWeights) {
+        Spans subSpan = w.getSpans(context, acceptDocs);
+        if (subSpan != null) {
+          subSpans.add(subSpan);
+        } else {
+          return null; // all required
+        }
+      }
+
+      // all NearSpans require at least two subSpans
+      return (!inOrder) ? new NearSpansUnordered(SpanNearQuery.this, subSpans)
+          : new NearSpansOrdered(SpanNearQuery.this, subSpans);
+    }
+
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      for (SpanWeight w : subWeights) {
+        w.extractTerms(terms);
+      }
+    }
   }
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java	(working copy)
@@ -17,21 +17,22 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Set;
+
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
-import java.io.IOException;
-import java.util.Map;
-import java.util.Set;
-import java.util.Objects;
-
 /** Removes matches which overlap with another SpanQuery or which are
  * within x tokens before or y tokens after another SpanQuery.
  */
@@ -78,9 +79,6 @@
   public String getField() { return include.getField(); }
 
   @Override
-  public void extractTerms(Set<Term> terms) { include.extractTerms(terms); }
-
-  @Override
   public String toString(String field) {
     StringBuilder buffer = new StringBuilder();
     buffer.append("spanNot(");
@@ -105,69 +103,101 @@
   }
 
   @Override
-  public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, final Map<Term,TermContext> termContexts) throws IOException {
-    final Spans includeSpans = include.getSpans(context, acceptDocs, termContexts);
-    if (includeSpans == null) {
-      return null;
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    SpanWeight includeWeight = include.createWeight(searcher, false);
+    SpanWeight excludeWeight = exclude.createWeight(searcher, false);
+    return new SpanNotWeight(searcher, needsScores ? getTermContexts(includeWeight, excludeWeight) : null,
+                                   includeWeight, excludeWeight);
+  }
+
+  public class SpanNotWeight extends SpanWeight {
+
+    final SpanWeight includeWeight;
+    final SpanWeight excludeWeight;
+
+    public SpanNotWeight(IndexSearcher searcher, Map<Term, TermContext> terms,
+                         SpanWeight includeWeight, SpanWeight excludeWeight) throws IOException {
+      super(SpanNotQuery.this, searcher, terms);
+      this.includeWeight = includeWeight;
+      this.excludeWeight = excludeWeight;
     }
 
-    final Spans excludeSpans = exclude.getSpans(context, acceptDocs, termContexts);
-    if (excludeSpans == null) {
-      return includeSpans;
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      includeWeight.extractTermContexts(contexts);
     }
-    
-    final TwoPhaseIterator excludeTwoPhase = excludeSpans.asTwoPhaseIterator();
-    final DocIdSetIterator excludeApproximation = excludeTwoPhase == null ? null : excludeTwoPhase.approximation();
-    
-    return new FilterSpans(includeSpans) {
-      // last document we have checked matches() against for the exclusion, and failed
-      // when using approximations, so we don't call it again, and pass thru all inclusions.
-      int lastApproxDoc = -1;
-      boolean lastApproxResult = false;
-      
-      @Override
-      protected AcceptStatus accept(Spans candidate) throws IOException {
-        // TODO: this logic is ugly and sneaky, can we clean it up?
-        int doc = candidate.docID();
-        if (doc > excludeSpans.docID()) {
-          // catch up 'exclude' to the current doc
-          if (excludeTwoPhase != null) {
-            if (excludeApproximation.advance(doc) == doc) {
-              lastApproxDoc = doc;
-              lastApproxResult = excludeTwoPhase.matches();
+
+
+    @Override
+    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
+      Spans includeSpans = includeWeight.getSpans(context, acceptDocs);
+      if (includeSpans == null) {
+        return null;
+      }
+
+      final Spans excludeSpans = excludeWeight.getSpans(context, acceptDocs);
+      if (excludeSpans == null) {
+        return includeSpans;
+      }
+
+      final TwoPhaseIterator excludeTwoPhase = excludeSpans.asTwoPhaseIterator();
+      final DocIdSetIterator excludeApproximation = excludeTwoPhase == null ? null : excludeTwoPhase.approximation();
+
+      return new FilterSpans(includeSpans) {
+        // last document we have checked matches() against for the exclusion, and failed
+        // when using approximations, so we don't call it again, and pass thru all inclusions.
+        int lastApproxDoc = -1;
+        boolean lastApproxResult = false;
+
+        @Override
+        protected AcceptStatus accept(Spans candidate) throws IOException {
+          // TODO: this logic is ugly and sneaky, can we clean it up?
+          int doc = candidate.docID();
+          if (doc > excludeSpans.docID()) {
+            // catch up 'exclude' to the current doc
+            if (excludeTwoPhase != null) {
+              if (excludeApproximation.advance(doc) == doc) {
+                lastApproxDoc = doc;
+                lastApproxResult = excludeTwoPhase.matches();
+              }
+            } else {
+              excludeSpans.advance(doc);
             }
+          } else if (excludeTwoPhase != null && doc == excludeSpans.docID() && doc != lastApproxDoc) {
+            // excludeSpans already sitting on our candidate doc, but matches not called yet.
+            lastApproxDoc = doc;
+            lastApproxResult = excludeTwoPhase.matches();
+          }
+
+          if (doc != excludeSpans.docID() || (doc == lastApproxDoc && lastApproxResult == false)) {
+            return AcceptStatus.YES;
+          }
+
+          if (excludeSpans.startPosition() == -1) { // init exclude start position if needed
+            excludeSpans.nextStartPosition();
+          }
+
+          while (excludeSpans.endPosition() <= candidate.startPosition() - pre) {
+            // exclude end position is before a possible exclusion
+            if (excludeSpans.nextStartPosition() == NO_MORE_POSITIONS) {
+              return AcceptStatus.YES; // no more exclude at current doc.
+            }
+          }
+
+          // exclude end position far enough in current doc, check start position:
+          if (candidate.endPosition() + post <= excludeSpans.startPosition()) {
+            return AcceptStatus.YES;
           } else {
-            excludeSpans.advance(doc);
+            return AcceptStatus.NO;
           }
-        } else if (excludeTwoPhase != null && doc == excludeSpans.docID() && doc != lastApproxDoc) {
-          // excludeSpans already sitting on our candidate doc, but matches not called yet.
-          lastApproxDoc = doc;
-          lastApproxResult = excludeTwoPhase.matches();
         }
-        
-        if (doc != excludeSpans.docID() || (doc == lastApproxDoc && lastApproxResult == false)) {
-          return AcceptStatus.YES;
-        }
-        
-        if (excludeSpans.startPosition() == -1) { // init exclude start position if needed
-          excludeSpans.nextStartPosition();
-        }
-        
-        while (excludeSpans.endPosition() <= candidate.startPosition() - pre) {
-          // exclude end position is before a possible exclusion
-          if (excludeSpans.nextStartPosition() == NO_MORE_POSITIONS) {
-            return AcceptStatus.YES; // no more exclude at current doc.
-          }
-        }
-        
-        // exclude end position far enough in current doc, check start position:
-        if (candidate.endPosition() + post <= excludeSpans.startPosition()) {
-          return AcceptStatus.YES;
-        } else {
-          return AcceptStatus.NO;
-        }
-      }
-    };
+      };
+    }
+
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      includeWeight.extractTerms(terms);
+    }
   }
 
   @Override
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java	(working copy)
@@ -18,25 +18,25 @@
  */
 
 import java.io.IOException;
-
-import java.util.List;
+import java.util.ArrayList;
 import java.util.Collection;
-import java.util.ArrayList;
 import java.util.Iterator;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.ToStringUtils;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.search.DisiPriorityQueue;
 import org.apache.lucene.search.DisiWrapper;
+import org.apache.lucene.search.DisjunctionDISIApproximation;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.search.DisjunctionDISIApproximation;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
 
 
 /** Matches the union of its clauses.
@@ -74,13 +74,6 @@
   public String getField() { return field; }
 
   @Override
-  public void extractTerms(Set<Term> terms) {
-    for(final SpanQuery clause: clauses) {
-      clause.extractTerms(terms);
-    }
-  }
-
-  @Override
   public SpanOrQuery clone() {
     int sz = clauses.size();
     SpanQuery[] newClauses = new SpanQuery[sz];
@@ -145,198 +138,229 @@
     return h;
   }
 
-
   @Override
-  public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, final Map<Term,TermContext> termContexts)
-  throws IOException {
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    List<SpanWeight> subWeights = new ArrayList<>(clauses.size());
+    for (SpanQuery q : clauses) {
+      subWeights.add(q.createWeight(searcher, false));
+    }
+    return new SpanOrWeight(searcher, needsScores ? getTermContexts(subWeights) : null, subWeights);
+  }
 
-    final ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
+  public class SpanOrWeight extends SpanWeight {
+    final List<SpanWeight> subWeights;
 
-    for (SpanQuery sq : clauses) {
-      Spans spans = sq.getSpans(context, acceptDocs, termContexts);
-      if (spans != null) {
-        subSpans.add(spans);
-      }
+    public SpanOrWeight(IndexSearcher searcher, Map<Term, TermContext> terms, List<SpanWeight> subWeights) throws IOException {
+      super(SpanOrQuery.this, searcher, terms);
+      this.subWeights = subWeights;
     }
 
-    if (subSpans.size() == 0) {
-      return null;
-    } else if (subSpans.size() == 1) {
-      return subSpans.get(0);
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      for (final SpanWeight w: subWeights) {
+        w.extractTerms(terms);
+      }
     }
 
-    final DisiPriorityQueue<Spans> byDocQueue = new DisiPriorityQueue<>(subSpans.size());
-    for (Spans spans : subSpans) {
-      byDocQueue.add(new DisiWrapper<>(spans));
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      for (SpanWeight w : subWeights) {
+        w.extractTermContexts(contexts);
+      }
     }
 
-    final SpanPositionQueue byPositionQueue = new SpanPositionQueue(subSpans.size()); // when empty use -1
+    @Override
+    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs)
+        throws IOException {
 
-    return new Spans() {
-      Spans topPositionSpans = null;
+      final ArrayList<Spans> subSpans = new ArrayList<>(clauses.size());
 
-      @Override
-      public int nextDoc() throws IOException {
-        topPositionSpans = null;
-        DisiWrapper<Spans> topDocSpans = byDocQueue.top();
-        int currentDoc = topDocSpans.doc;
-        do {
-          topDocSpans.doc = topDocSpans.iterator.nextDoc();
-          topDocSpans = byDocQueue.updateTop();
-        } while (topDocSpans.doc == currentDoc);
-        return topDocSpans.doc;
+      for (SpanWeight w : subWeights) {
+        Spans spans = w.getSpans(context, acceptDocs);
+        if (spans != null) {
+          subSpans.add(spans);
+        }
       }
 
-      @Override
-      public int advance(int target) throws IOException {
-        topPositionSpans = null;
-        DisiWrapper<Spans> topDocSpans = byDocQueue.top();
-        do {
-          topDocSpans.doc = topDocSpans.iterator.advance(target);
-          topDocSpans = byDocQueue.updateTop();
-        } while (topDocSpans.doc < target);
-        return topDocSpans.doc;
+      if (subSpans.size() == 0) {
+        return null;
+      } else if (subSpans.size() == 1) {
+        return subSpans.get(0);
       }
 
-      @Override
-      public int docID() {
-        DisiWrapper<Spans> topDocSpans = byDocQueue.top();
-        return topDocSpans.doc;
+      final DisiPriorityQueue<Spans> byDocQueue = new DisiPriorityQueue<>(subSpans.size());
+      for (Spans spans : subSpans) {
+        byDocQueue.add(new DisiWrapper<>(spans));
       }
 
-      @Override
-      public TwoPhaseIterator asTwoPhaseIterator() {
-        boolean hasApproximation = false;
-        for (DisiWrapper<Spans> w : byDocQueue) {
-          if (w.twoPhaseView != null) {
-            hasApproximation = true;
-            break;
-          }
+      final SpanPositionQueue byPositionQueue = new SpanPositionQueue(subSpans.size()); // when empty use -1
+
+      return new Spans() {
+        Spans topPositionSpans = null;
+
+        @Override
+        public int nextDoc() throws IOException {
+          topPositionSpans = null;
+          DisiWrapper<Spans> topDocSpans = byDocQueue.top();
+          int currentDoc = topDocSpans.doc;
+          do {
+            topDocSpans.doc = topDocSpans.iterator.nextDoc();
+            topDocSpans = byDocQueue.updateTop();
+          } while (topDocSpans.doc == currentDoc);
+          return topDocSpans.doc;
         }
 
-        if (! hasApproximation) { // none of the sub spans supports approximations
-          return null;
+        @Override
+        public int advance(int target) throws IOException {
+          topPositionSpans = null;
+          DisiWrapper<Spans> topDocSpans = byDocQueue.top();
+          do {
+            topDocSpans.doc = topDocSpans.iterator.advance(target);
+            topDocSpans = byDocQueue.updateTop();
+          } while (topDocSpans.doc < target);
+          return topDocSpans.doc;
         }
 
-        return new TwoPhaseIterator(new DisjunctionDISIApproximation<Spans>(byDocQueue)) {
-          @Override
-          public boolean matches() throws IOException {
-            return twoPhaseCurrentDocMatches();
+        @Override
+        public int docID() {
+          DisiWrapper<Spans> topDocSpans = byDocQueue.top();
+          return topDocSpans.doc;
+        }
+
+        @Override
+        public TwoPhaseIterator asTwoPhaseIterator() {
+          boolean hasApproximation = false;
+          for (DisiWrapper<Spans> w : byDocQueue) {
+            if (w.twoPhaseView != null) {
+              hasApproximation = true;
+              break;
+            }
           }
-        };
-      }
-      
-      int lastDocTwoPhaseMatched = -1;
 
-      boolean twoPhaseCurrentDocMatches() throws IOException {
-        DisiWrapper<Spans> listAtCurrentDoc = byDocQueue.topList();
-        // remove the head of the list as long as it does not match
-        final int currentDoc = listAtCurrentDoc.doc;
-        while (listAtCurrentDoc.twoPhaseView != null) {
-          if (listAtCurrentDoc.twoPhaseView.matches()) {
-            // use this spans for positions at current doc:
-            listAtCurrentDoc.lastApproxMatchDoc = currentDoc;
-            break;
+          if (!hasApproximation) { // none of the sub spans supports approximations
+            return null;
           }
-          // do not use this spans for positions at current doc:
-          listAtCurrentDoc.lastApproxNonMatchDoc = currentDoc;
-          listAtCurrentDoc = listAtCurrentDoc.next;
-          if (listAtCurrentDoc == null) {
-            return false;
+
+          return new TwoPhaseIterator(new DisjunctionDISIApproximation<Spans>(byDocQueue)) {
+            @Override
+            public boolean matches() throws IOException {
+              return twoPhaseCurrentDocMatches();
+            }
+          };
+        }
+
+        int lastDocTwoPhaseMatched = -1;
+
+        boolean twoPhaseCurrentDocMatches() throws IOException {
+          DisiWrapper<Spans> listAtCurrentDoc = byDocQueue.topList();
+          // remove the head of the list as long as it does not match
+          final int currentDoc = listAtCurrentDoc.doc;
+          while (listAtCurrentDoc.twoPhaseView != null) {
+            if (listAtCurrentDoc.twoPhaseView.matches()) {
+              // use this spans for positions at current doc:
+              listAtCurrentDoc.lastApproxMatchDoc = currentDoc;
+              break;
+            }
+            // do not use this spans for positions at current doc:
+            listAtCurrentDoc.lastApproxNonMatchDoc = currentDoc;
+            listAtCurrentDoc = listAtCurrentDoc.next;
+            if (listAtCurrentDoc == null) {
+              return false;
+            }
           }
+          lastDocTwoPhaseMatched = currentDoc;
+          topPositionSpans = null;
+          return true;
         }
-        lastDocTwoPhaseMatched = currentDoc;
-        topPositionSpans = null;
-        return true;
-      }
 
-      void fillPositionQueue() throws IOException { // called at first nextStartPosition
-        assert byPositionQueue.size() == 0;
-        // add all matching Spans at current doc to byPositionQueue
-        DisiWrapper<Spans> listAtCurrentDoc = byDocQueue.topList();
-        while (listAtCurrentDoc != null) {
-          Spans spansAtDoc = listAtCurrentDoc.iterator;
-          if (lastDocTwoPhaseMatched == listAtCurrentDoc.doc) { // matched by DisjunctionDisiApproximation
-            if (listAtCurrentDoc.twoPhaseView != null) { // matched by approximation
-              if (listAtCurrentDoc.lastApproxNonMatchDoc == listAtCurrentDoc.doc) { // matches() returned false
-                spansAtDoc = null;
-              } else {
-                if (listAtCurrentDoc.lastApproxMatchDoc != listAtCurrentDoc.doc) {
-                  if (! listAtCurrentDoc.twoPhaseView.matches()) {
-                    spansAtDoc = null;
+        void fillPositionQueue() throws IOException { // called at first nextStartPosition
+          assert byPositionQueue.size() == 0;
+          // add all matching Spans at current doc to byPositionQueue
+          DisiWrapper<Spans> listAtCurrentDoc = byDocQueue.topList();
+          while (listAtCurrentDoc != null) {
+            Spans spansAtDoc = listAtCurrentDoc.iterator;
+            if (lastDocTwoPhaseMatched == listAtCurrentDoc.doc) { // matched by DisjunctionDisiApproximation
+              if (listAtCurrentDoc.twoPhaseView != null) { // matched by approximation
+                if (listAtCurrentDoc.lastApproxNonMatchDoc == listAtCurrentDoc.doc) { // matches() returned false
+                  spansAtDoc = null;
+                } else {
+                  if (listAtCurrentDoc.lastApproxMatchDoc != listAtCurrentDoc.doc) {
+                    if (!listAtCurrentDoc.twoPhaseView.matches()) {
+                      spansAtDoc = null;
+                    }
                   }
                 }
-              } 
+              }
             }
+
+            if (spansAtDoc != null) {
+              assert spansAtDoc.docID() == listAtCurrentDoc.doc;
+              assert spansAtDoc.startPosition() == -1;
+              spansAtDoc.nextStartPosition();
+              assert spansAtDoc.startPosition() != NO_MORE_POSITIONS;
+              byPositionQueue.add(spansAtDoc);
+            }
+            listAtCurrentDoc = listAtCurrentDoc.next;
           }
+          assert byPositionQueue.size() > 0;
+        }
 
-          if (spansAtDoc != null) {
-            assert spansAtDoc.docID() == listAtCurrentDoc.doc;
-            assert spansAtDoc.startPosition() == -1;
-            spansAtDoc.nextStartPosition();
-            assert spansAtDoc.startPosition() != NO_MORE_POSITIONS;
-            byPositionQueue.add(spansAtDoc);
+        @Override
+        public int nextStartPosition() throws IOException {
+          if (topPositionSpans == null) {
+            byPositionQueue.clear();
+            fillPositionQueue(); // fills byPositionQueue at first position
+            topPositionSpans = byPositionQueue.top();
+          } else {
+            topPositionSpans.nextStartPosition();
+            topPositionSpans = byPositionQueue.updateTop();
           }
-          listAtCurrentDoc = listAtCurrentDoc.next;
+          return topPositionSpans.startPosition();
         }
-        assert byPositionQueue.size() > 0;
-      }
-        
-      @Override
-      public int nextStartPosition() throws IOException {
-        if (topPositionSpans == null) {
-          byPositionQueue.clear();
-          fillPositionQueue(); // fills byPositionQueue at first position
-          topPositionSpans = byPositionQueue.top();
-        } else {
-          topPositionSpans.nextStartPosition();
-          topPositionSpans = byPositionQueue.updateTop();
+
+        @Override
+        public int startPosition() {
+          return topPositionSpans == null ? -1 : topPositionSpans.startPosition();
         }
-        return topPositionSpans.startPosition();
-      }
 
-      @Override
-      public int startPosition() {
-        return topPositionSpans == null ? -1 : topPositionSpans.startPosition();
-      }
+        @Override
+        public int endPosition() {
+          return topPositionSpans == null ? -1 : topPositionSpans.endPosition();
+        }
 
-      @Override
-      public int endPosition() {
-        return topPositionSpans == null ? -1 : topPositionSpans.endPosition();
-      }
+        @Override
+        public Collection<byte[]> getPayload() throws IOException {
+          return topPositionSpans == null
+              ? null
+              : topPositionSpans.isPayloadAvailable()
+              ? new ArrayList<>(topPositionSpans.getPayload())
+              : null;
+        }
 
-      @Override
-      public Collection<byte[]> getPayload() throws IOException {
-        return topPositionSpans == null
-                ? null
-                : topPositionSpans.isPayloadAvailable()
-                ? new ArrayList<>(topPositionSpans.getPayload())
-                : null;
-      }
+        @Override
+        public boolean isPayloadAvailable() throws IOException {
+          return (topPositionSpans != null) && topPositionSpans.isPayloadAvailable();
+        }
 
-      @Override
-      public boolean isPayloadAvailable() throws IOException {
-        return (topPositionSpans != null) && topPositionSpans.isPayloadAvailable();
-      }
+        @Override
+        public String toString() {
+          return "spanOr("+SpanOrQuery.this+")@"+docID()+": "+startPosition()+" - "+endPosition();
+        }
 
-      @Override
-      public String toString() {
-        return "spanOr("+SpanOrQuery.this+")@"+docID()+": "+startPosition()+" - "+endPosition();
-      }
+        long cost = -1;
 
-      long cost = -1;
-
-      @Override
-      public long cost() {
-        if (cost == -1) {
-          cost = 0;
-          for (Spans spans : subSpans) {
-            cost += spans.cost();
+        @Override
+        public long cost() {
+          if (cost == -1) {
+            cost = 0;
+            for (Spans spans : subSpans) {
+              cost += spans.cost();
+            }
           }
+          return cost;
         }
-        return cost;
-      }
-    };
+      };
+    }
   }
 
 }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanPositionCheckQuery.java	(working copy)
@@ -17,20 +17,21 @@
  */
 
 
+import java.io.IOException;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Set;
+
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.spans.FilterSpans.AcceptStatus;
 import org.apache.lucene.util.Bits;
 
-import java.io.IOException;
-import java.util.Map;
-import java.util.Set;
-import java.util.Objects;
 
-
 /**
  * Base class for filtering a SpanQuery based on the position of a match.
  **/
@@ -47,18 +48,9 @@
    * */
   public SpanQuery getMatch() { return match; }
 
-
-
   @Override
   public String getField() { return match.getField(); }
 
-
-
-  @Override
-  public void extractTerms(Set<Term> terms) {
-    match.extractTerms(terms);
-  }
-
   /**
    * Implementing classes are required to return whether the current position is a match for the passed in
    * "match" {@link SpanQuery}.
@@ -66,7 +58,6 @@
    * This is only called if the underlying last {@link Spans#nextStartPosition()} for the
    * match indicated a valid start position.
    *
-   *
    * @param spans The {@link Spans} instance, positioned at the spot to check
    *
    * @return whether the match is accepted, rejected, or rejected and should move to the next doc.
@@ -77,16 +68,44 @@
   protected abstract AcceptStatus acceptPosition(Spans spans) throws IOException;
 
   @Override
-  public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    Spans matchSpans = match.getSpans(context, acceptDocs, termContexts);
-    return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
-      @Override
-      protected AcceptStatus accept(Spans candidate) throws IOException {
-        return acceptPosition(candidate);
-      }
-    };
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    SpanWeight matchWeight = match.createWeight(searcher, false);
+    return new SpanPositionCheckWeight(matchWeight, searcher, needsScores ? getTermContexts(matchWeight) : null);
   }
 
+  public class SpanPositionCheckWeight extends SpanWeight {
+
+    final SpanWeight matchWeight;
+
+    public SpanPositionCheckWeight(SpanWeight matchWeight, IndexSearcher searcher, Map<Term, TermContext> terms)
+        throws IOException {
+      super(SpanPositionCheckQuery.this, searcher, terms);
+      this.matchWeight = matchWeight;
+    }
+
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      matchWeight.extractTerms(terms);
+    }
+
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      matchWeight.extractTermContexts(contexts);
+    }
+
+    @Override
+    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+      Spans matchSpans = matchWeight.getSpans(context, acceptDocs);
+      return (matchSpans == null) ? null : new FilterSpans(matchSpans) {
+        @Override
+        protected AcceptStatus accept(Spans candidate) throws IOException {
+          return acceptPosition(candidate);
+        }
+      };
+    }
+
+  }
+
   @Override
   public Query rewrite(IndexReader reader) throws IOException {
     SpanPositionCheckQuery clone = null;
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java	(working copy)
@@ -18,42 +18,53 @@
  */
 
 import java.io.IOException;
+import java.util.Collection;
 import java.util.Map;
-import java.util.Set;
+import java.util.TreeMap;
 
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
 
 /** Base class for span-based queries. */
 public abstract class SpanQuery extends Query {
-  /** Expert: Returns the matches for this query in an index.  
-   *  Used internally to search for spans.
-   *  This may return null to indicate that the SpanQuery has no results.
+
+  /**
+   * Returns the name of the field matched by this query.
    */
-  public abstract Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException;
+  public abstract String getField();
 
   /**
-   * Extract terms from these spans.
+   * Create a SpanWeight for this query
+   * @param searcher the IndexSearcher to be searched across
+   * @param needsScores if the query needs scores
+   * @return a SpanWeight
+   * @throws IOException on error
+   */
+  public abstract SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException;
+
+  /**
+   * Build a map of terms to termcontexts, for use in constructing SpanWeights
    * @lucene.internal
-   * @see Weight#extractTerms
    */
-  protected abstract void extractTerms(Set<Term> terms);
+  protected static Map<Term, TermContext> getTermContexts(SpanWeight... weights) {
+    Map<Term, TermContext> terms = new TreeMap<>();
+    for (SpanWeight w : weights) {
+      w.extractTermContexts(terms);
+    }
+    return terms;
+  }
 
   /**
-   * Returns the name of the field matched by this query.
-   * <p>
-   * Note that this may return null if the query matches no terms.
+   * Build a map of terms to termcontexts, for use in constructing SpanWeights
+   * @lucene.internal
    */
-  public abstract String getField();
-
-  @Override
-  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    return new SpanWeight(this, searcher, needsScores);
+  protected static Map<Term, TermContext> getTermContexts(Collection<SpanWeight> weights) {
+    Map<Term, TermContext> terms = new TreeMap<>();
+    for (SpanWeight w : weights) {
+      w.extractTermContexts(terms);
+    }
+    return terms;
   }
-
 }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanScorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanScorer.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanScorer.java	(working copy)
@@ -42,7 +42,7 @@
 
   protected SpanScorer(Spans spans, SpanWeight weight, Similarity.SimScorer docScorer) throws IOException {
     super(weight);
-    this.docScorer = Objects.requireNonNull(docScorer);
+    this.docScorer = docScorer;
     this.spans = Objects.requireNonNull(spans);
   }
 
@@ -91,6 +91,10 @@
       // assert (startPos != prevStartPos) || (endPos > prevEndPos) : "non increased endPos="+endPos;
       assert (startPos != prevStartPos) || (endPos >= prevEndPos) : "decreased endPos="+endPos;
       numMatches++;
+      if (docScorer == null) {  // scores not required, break out here
+        freq = 1;
+        return;
+      }
       int matchLength = endPos - startPos;
       freq += docScorer.computeSlopFactor(matchLength);
       prevStartPos = startPos;
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java	(working copy)
@@ -18,17 +18,21 @@
  */
 
 import java.io.IOException;
+import java.util.Collections;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Set;
-import java.util.Objects;
 
+import org.apache.lucene.index.IndexReaderContext;
+import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.TermState;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
@@ -36,13 +40,25 @@
  * This should not be used for terms that are indexed at position Integer.MAX_VALUE.
  */
 public class SpanTermQuery extends SpanQuery {
-  protected Term term;
 
+  protected final Term term;
+  protected final TermContext termContext;
+
   /** Construct a SpanTermQuery matching the named term's spans. */
   public SpanTermQuery(Term term) {
     this.term = Objects.requireNonNull(term);
+    this.termContext = null;
   }
 
+  /**
+   * Expert: Construct a SpanTermQuery matching the named term's spans, using
+   * the provided TermContext
+   */
+  public SpanTermQuery(Term term, TermContext context) {
+    this.term = Objects.requireNonNull(term);
+    this.termContext = context;
+  }
+
   /** Return the term whose spans are matched. */
   public Term getTerm() { return term; }
 
@@ -50,10 +66,63 @@
   public String getField() { return term.field(); }
 
   @Override
-  public void extractTerms(Set<Term> terms) {
-    terms.add(term);
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    final TermContext context;
+    final IndexReaderContext topContext = searcher.getTopReaderContext();
+    if (termContext == null || termContext.topReaderContext != topContext) {
+      context = TermContext.build(topContext, term);
+    }
+    else {
+      context = termContext;
+    }
+    return new SpanTermWeight(context, searcher, needsScores ? Collections.singletonMap(term, context) : null);
   }
 
+  public class SpanTermWeight extends SpanWeight {
+
+    final TermContext termContext;
+
+    public SpanTermWeight(TermContext termContext, IndexSearcher searcher, Map<Term, TermContext> terms) throws IOException {
+      super(SpanTermQuery.this, searcher, terms);
+      this.termContext = termContext;
+      assert termContext != null : "TermContext must not be null";
+    }
+
+    @Override
+    public void extractTerms(Set<Term> terms) {
+      terms.add(term);
+    }
+
+    @Override
+    public void extractTermContexts(Map<Term, TermContext> contexts) {
+      contexts.put(term, termContext);
+    }
+
+    @Override
+    public Spans getSpans(final LeafReaderContext context, Bits acceptDocs) throws IOException {
+
+      assert termContext.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termContext.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
+
+      final TermState state = termContext.get(context.ord);
+      if (state == null) { // term is not present in that reader
+        assert context.reader().docFreq(term) == 0 : "no termstate found but term exists in reader term=" + term;
+        return null;
+      }
+
+      final Terms terms = context.reader().terms(term.field());
+      if (terms == null)
+        return null;
+      if (terms.hasPositions() == false)
+        throw new IllegalStateException("field \"" + term.field() + "\" was indexed without position data; cannot run SpanTermQuery (term=" + term.text() + ")");
+
+      final TermsEnum termsEnum = terms.iterator();
+      termsEnum.seekExact(term.bytes(), state);
+
+      final PostingsEnum postings = termsEnum.postings(acceptDocs, null, PostingsEnum.PAYLOADS);
+      return new TermSpans(postings, term);
+    }
+  }
+
   @Override
   public String toString(String field) {
     StringBuilder buffer = new StringBuilder();
@@ -82,40 +151,4 @@
     return term.equals(other.term);
   }
 
-  @Override
-  public Spans getSpans(final LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    TermContext termContext = termContexts.get(term);
-    final TermState state;
-    if (termContext == null) {
-      // this happens with span-not query, as it doesn't include the NOT side in extractTerms()
-      // so we seek to the term now in this segment..., this sucks because it's ugly mostly!
-      final Terms terms = context.reader().terms(term.field());
-      if (terms != null) {
-        if (terms.hasPositions() == false) {
-          throw new IllegalStateException("field \"" + term.field() + "\" was indexed without position data; cannot run SpanTermQuery (term=" + term.text() + ")");
-        }
-
-        final TermsEnum termsEnum = terms.iterator();
-        if (termsEnum.seekExact(term.bytes())) {
-          state = termsEnum.termState();
-        } else {
-          state = null;
-        }
-      } else {
-        state = null;
-      }
-    } else {
-      state = termContext.get(context.ord);
-    }
-
-    if (state == null) { // term is not present in that reader
-      return null;
-    }
-
-    final TermsEnum termsEnum = context.reader().terms(term.field()).iterator();
-    termsEnum.seekExact(term.bytes(), state);
-
-    final PostingsEnum postings = termsEnum.postings(acceptDocs, null, PostingsEnum.PAYLOADS);
-    return new TermSpans(postings, term);
-  }
 }
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java	(working copy)
@@ -18,16 +18,13 @@
  */
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
-import java.util.Set;
-import java.util.TreeSet;
 
-import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.Terms;
+import org.apache.lucene.search.CollectionStatistics;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Scorer;
@@ -40,65 +37,80 @@
 /**
  * Expert-only.  Public for use by other weight implementations
  */
-public class SpanWeight extends Weight {
+public abstract class SpanWeight extends Weight {
+
   protected final Similarity similarity;
-  protected final Map<Term,TermContext> termContexts;
-  protected final SpanQuery query;
-  protected Similarity.SimWeight stats;
+  protected final Similarity.SimWeight simWeight;
+  protected final String field;
 
-  public SpanWeight(SpanQuery query, IndexSearcher searcher, boolean needsScores) throws IOException {
+  /**
+   * Create a new SpanWeight
+   * @param query the parent query
+   * @param searcher the IndexSearcher to query against
+   * @param termContexts a map of terms to termcontexts for use in building the similarity.  May
+   *                     be null if scores are not required
+   * @throws IOException on error
+   */
+  public SpanWeight(SpanQuery query, IndexSearcher searcher, Map<Term, TermContext> termContexts) throws IOException {
     super(query);
-    this.similarity = searcher.getSimilarity(needsScores);
-    this.query = query;
+    this.field = query.getField();
+    this.similarity = searcher.getSimilarity(termContexts != null);
+    this.simWeight = buildSimWeight(query, searcher, termContexts);
+  }
 
-    termContexts = new HashMap<>();
-    TreeSet<Term> terms = new TreeSet<>();
-    query.extractTerms(terms);
-    final IndexReaderContext context = searcher.getTopReaderContext();
-    final TermStatistics termStats[] = new TermStatistics[terms.size()];
+  private Similarity.SimWeight buildSimWeight(SpanQuery query, IndexSearcher searcher, Map<Term, TermContext> termContexts) throws IOException {
+    if (termContexts == null || termContexts.size() == 0 || query.getField() == null)
+      return null;
+    TermStatistics[] termStats = new TermStatistics[termContexts.size()];
     int i = 0;
-    for (Term term : terms) {
-      TermContext state = TermContext.build(context, term);
-      termStats[i] = searcher.termStatistics(term, state);
-      termContexts.put(term, state);
+    for (Term term : termContexts.keySet()) {
+      termStats[i] = searcher.termStatistics(term, termContexts.get(term));
       i++;
     }
-    final String field = query.getField();
-    if (field != null) {
-      stats = similarity.computeWeight(query.getBoost(),
-                                       searcher.collectionStatistics(query.getField()),
-                                       termStats);
-    }
+    CollectionStatistics collectionStats = searcher.collectionStatistics(query.getField());
+    return this.similarity.computeWeight(query.getBoost(), collectionStats, termStats);
   }
 
-  @Override
-  public void extractTerms(Set<Term> terms) {
-    query.extractTerms(terms);
-  }
+  /**
+   * Collect all TermContexts used by this Weight
+   * @param contexts a map to add the TermContexts to
+   */
+  public abstract void extractTermContexts(Map<Term, TermContext> contexts);
 
+  /**
+   * Expert: Return a Spans object iterating over matches from this Weight
+   * @param ctx a LeafReaderContext for this Spans
+   * @param acceptDocs a bitset of documents to check
+   * @return a Spans
+   * @throws IOException on error
+   */
+  public abstract Spans getSpans(LeafReaderContext ctx, Bits acceptDocs) throws IOException;
+
   @Override
   public float getValueForNormalization() throws IOException {
-    return stats == null ? 1.0f : stats.getValueForNormalization();
+    return simWeight == null ? 1.0f : simWeight.getValueForNormalization();
   }
 
   @Override
   public void normalize(float queryNorm, float topLevelBoost) {
-    if (stats != null) {
-      stats.normalize(queryNorm, topLevelBoost);
+    if (simWeight != null) {
+      simWeight.normalize(queryNorm, topLevelBoost);
     }
   }
 
   @Override
   public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    if (stats == null) {
+    if (field == null) {
       return null;
     }
-    Terms terms = context.reader().terms(query.getField());
+    Terms terms = context.reader().terms(field);
     if (terms != null && terms.hasPositions() == false) {
-      throw new IllegalStateException("field \"" + query.getField() + "\" was indexed without position data; cannot run SpanQuery (query=" + query + ")");
+      throw new IllegalStateException("field \"" + field + "\" was indexed without position data; cannot run SpanQuery (query=" + parentQuery + ")");
     }
-    Spans spans = query.getSpans(context, acceptDocs, termContexts);
-    return (spans == null) ? null : new SpanScorer(spans, this, similarity.simScorer(stats, context));
+
+    Spans spans = getSpans(context, acceptDocs);
+    Similarity.SimScorer simScorer = simWeight == null ? null : similarity.simScorer(simWeight, context);
+    return (spans == null) ? null : new SpanScorer(spans, this, simScorer);
   }
 
   @Override
@@ -108,7 +120,7 @@
       int newDoc = scorer.advance(doc);
       if (newDoc == doc) {
         float freq = scorer.sloppyFreq();
-        SimScorer docScorer = similarity.simScorer(stats, context);
+        SimScorer docScorer = similarity.simScorer(simWeight, context);
         Explanation freqExplanation = Explanation.match(freq, "phraseFreq=" + freq);
         Explanation scoreExplanation = docScorer.explain(doc, freqExplanation);
         return Explanation.match(scoreExplanation.getValue(),
Index: lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java	(revision 1685519)
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanWithinQuery.java	(working copy)
@@ -18,16 +18,18 @@
  */
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Map;
-import java.util.ArrayList;
 
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.Bits;
 
 /** Keep matches that are contained within another Spans. */
 public class SpanWithinQuery extends SpanContainQuery {
+
   /** Construct a SpanWithinQuery matching spans from <code>little</code>
    * that are inside of <code>big</code>.
    * This query has the boost of <code>little</code>.
@@ -49,62 +51,79 @@
           (SpanQuery) little.clone());
   }
 
-  /** 
-   * Return spans from <code>little</code> that are contained in a spans from <code>big</code>.
-   * The payload is from the spans of <code>little</code>.
-   */
   @Override
-  public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs, final Map<Term,TermContext> termContexts) throws IOException {
-    ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs, termContexts);
-    if (containerContained == null) {
-      return null;
+  public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    SpanWeight bigWeight = big.createWeight(searcher, false);
+    SpanWeight littleWeight = little.createWeight(searcher, false);
+    return new SpanWithinWeight(searcher, needsScores ? getTermContexts(bigWeight, littleWeight) : null,
+                                      bigWeight, littleWeight);
+  }
+
+  public class SpanWithinWeight extends SpanContainWeight {
+
+    public SpanWithinWeight(IndexSearcher searcher, Map<Term, TermContext> terms,
+                            SpanWeight bigWeight, SpanWeight littleWeight) throws IOException {
+      super(searcher, terms, bigWeight, littleWeight);
     }
 
-    Spans big = containerContained.get(0);
-    Spans little = containerContained.get(1);
+    /**
+     * Return spans from <code>little</code> that are contained in a spans from <code>big</code>.
+     * The payload is from the spans of <code>little</code>.
+     */
+    @Override
+    public Spans getSpans(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
+      ArrayList<Spans> containerContained = prepareConjunction(context, acceptDocs);
+      if (containerContained == null) {
+        return null;
+      }
 
-    return new ContainSpans(big, little, little) {
+      Spans big = containerContained.get(0);
+      Spans little = containerContained.get(1);
 
-      @Override
-      boolean twoPhaseCurrentDocMatches() throws IOException {
-        oneExhaustedInCurrentDoc = false;
-        assert littleSpans.startPosition() == -1;
-        while (littleSpans.nextStartPosition() != NO_MORE_POSITIONS) {
-          while (bigSpans.endPosition() < littleSpans.endPosition()) {
-            if (bigSpans.nextStartPosition() == NO_MORE_POSITIONS) {
-              oneExhaustedInCurrentDoc = true;
-              return false;
+      return new ContainSpans(big, little, little) {
+
+        @Override
+        boolean twoPhaseCurrentDocMatches() throws IOException {
+          oneExhaustedInCurrentDoc = false;
+          assert littleSpans.startPosition() == -1;
+          while (littleSpans.nextStartPosition() != NO_MORE_POSITIONS) {
+            while (bigSpans.endPosition() < littleSpans.endPosition()) {
+              if (bigSpans.nextStartPosition() == NO_MORE_POSITIONS) {
+                oneExhaustedInCurrentDoc = true;
+                return false;
+              }
             }
+            if (bigSpans.startPosition() <= littleSpans.startPosition()) {
+              atFirstInCurrentDoc = true;
+              return true;
+            }
           }
-          if (bigSpans.startPosition() <= littleSpans.startPosition()) {
-            atFirstInCurrentDoc = true;
-            return true;
+          oneExhaustedInCurrentDoc = true;
+          return false;
+        }
+
+        @Override
+        public int nextStartPosition() throws IOException {
+          if (atFirstInCurrentDoc) {
+            atFirstInCurrentDoc = false;
+            return littleSpans.startPosition();
           }
-        } 
-        oneExhaustedInCurrentDoc = true;
-        return false;
-      }
-
-      @Override
-      public int nextStartPosition() throws IOException {
-        if (atFirstInCurrentDoc) {
-          atFirstInCurrentDoc = false;
-          return littleSpans.startPosition();
-        }
-        while (littleSpans.nextStartPosition() != NO_MORE_POSITIONS) {
-          while (bigSpans.endPosition() < littleSpans.endPosition()) {
-            if (bigSpans.nextStartPosition() == NO_MORE_POSITIONS) {
-              oneExhaustedInCurrentDoc = true;
-              return NO_MORE_POSITIONS;
+          while (littleSpans.nextStartPosition() != NO_MORE_POSITIONS) {
+            while (bigSpans.endPosition() < littleSpans.endPosition()) {
+              if (bigSpans.nextStartPosition() == NO_MORE_POSITIONS) {
+                oneExhaustedInCurrentDoc = true;
+                return NO_MORE_POSITIONS;
+              }
             }
+            if (bigSpans.startPosition() <= littleSpans.startPosition()) {
+              return littleSpans.startPosition();
+            }
           }
-          if (bigSpans.startPosition() <= littleSpans.startPosition()) {
-            return littleSpans.startPosition();
-          }
+          oneExhaustedInCurrentDoc = true;
+          return NO_MORE_POSITIONS;
         }
-        oneExhaustedInCurrentDoc = true;
-        return NO_MORE_POSITIONS;
-      }
-    };
+      };
+    }
   }
-}
\ No newline at end of file
+
+}
Index: lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(revision 1685519)
+++ lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(working copy)
@@ -16,37 +16,41 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.*;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.English;
+import java.io.IOException;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.FieldInvertState;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.CheckHits;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.QueryUtils;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.CheckHits;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.search.spans.MultiSpansWrapper;
 import org.apache.lucene.search.spans.SpanTermQuery;
 import org.apache.lucene.search.spans.Spans;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.FieldInvertState;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.English;
+import org.apache.lucene.util.LuceneTestCase;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
-import java.io.IOException;
 
-
 /**
  *
  *
Index: lucene/core/src/test/org/apache/lucene/search/spans/JustCompileSearchSpans.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/JustCompileSearchSpans.java	(revision 1685519)
+++ lucene/core/src/test/org/apache/lucene/search/spans/JustCompileSearchSpans.java	(working copy)
@@ -19,14 +19,9 @@
 
 import java.io.IOException;
 import java.util.Collection;
-import java.util.Map;
-import java.util.Set;
 
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.Bits;
 
 /**
  * Holds all implementations of classes in the o.a.l.s.spans package as a
@@ -90,17 +85,12 @@
   static final class JustCompileSpanQuery extends SpanQuery {
 
     @Override
-    protected void extractTerms(Set<Term> terms) {
-      throw new UnsupportedOperationException(UNSUPPORTED_MSG);
-    }
-
-    @Override
     public String getField() {
       throw new UnsupportedOperationException(UNSUPPORTED_MSG);
     }
 
     @Override
-    public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) {
+    public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
       throw new UnsupportedOperationException(UNSUPPORTED_MSG);
     }
 
Index: lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java	(revision 1685519)
+++ lucene/core/src/test/org/apache/lucene/search/spans/MultiSpansWrapper.java	(working copy)
@@ -18,16 +18,12 @@
  */
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.Bits;
 
 /**
@@ -40,17 +36,14 @@
 public class MultiSpansWrapper {
 
   public static Spans wrap(IndexReader reader, SpanQuery spanQuery) throws IOException {
+
     LeafReader lr = SlowCompositeReaderWrapper.wrap(reader); // slow, but ok for testing
     LeafReaderContext lrContext = lr.getContext();
-    SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(lr); // get the term contexts so getSpans can be called directly
-    HashSet<Term> termSet = new HashSet<>();
-    rewrittenQuery.extractTerms(termSet);
-    Map<Term,TermContext> termContexts = new HashMap<>();
-    for (Term term: termSet) {
-      TermContext termContext = TermContext.build(lrContext, term);
-      termContexts.put(term, termContext);
-    }
-    Spans actSpans = spanQuery.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()), termContexts);
-    return actSpans;
+    IndexSearcher searcher = new IndexSearcher(lr);
+    searcher.setQueryCache(null);
+
+    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(spanQuery, false);
+
+    return w.getSpans(lrContext, new Bits.MatchAllBits(lr.numDocs()));
   }
 }
Index: lucene/core/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java	(revision 1685519)
+++ lucene/core/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java	(working copy)
@@ -36,7 +36,8 @@
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
-import static org.apache.lucene.search.spans.SpanTestUtil.*;
+import static org.apache.lucene.search.spans.SpanTestUtil.assertFinished;
+import static org.apache.lucene.search.spans.SpanTestUtil.assertNext;
 
 public class TestFieldMaskingSpanQuery extends LuceneTestCase {
 
@@ -141,7 +142,7 @@
     QueryUtils.checkEqual(q, qr);
 
     Set<Term> terms = new HashSet<>();
-    qr.extractTerms(terms);
+    qr.createWeight(searcher, false).extractTerms(terms);
     assertEquals(1, terms.size());
   }
   
@@ -161,7 +162,7 @@
     QueryUtils.checkUnequal(q, qr);
 
     Set<Term> terms = new HashSet<>();
-    qr.extractTerms(terms);
+    qr.createWeight(searcher, false).extractTerms(terms);
     assertEquals(2, terms.size());
   }
   
Index: lucene/core
===================================================================
--- lucene/core	(revision 1685519)
+++ lucene/core	(working copy)

Property changes on: lucene/core
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene/core:r1680565,1680603,1680606,1682513
Index: lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java	(revision 1685519)
+++ lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java	(working copy)
@@ -26,7 +26,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.TreeSet;
 
 import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -40,7 +39,6 @@
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.queries.CommonTermsQuery;
@@ -66,11 +64,11 @@
 import org.apache.lucene.search.spans.SpanOrQuery;
 import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.SpanWeight;
 import org.apache.lucene.search.spans.Spans;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.IOUtils;
 
-
 /**
  * Class used to extract {@link WeightedSpanTerm}s from a {@link Query} based on whether 
  * {@link Term}s from the {@link Query} are contained in a supplied {@link TokenStream}.
@@ -303,14 +301,9 @@
         q = spanQuery;
       }
       LeafReaderContext context = getLeafContext();
-      Map<Term,TermContext> termContexts = new HashMap<>();
-      TreeSet<Term> extractedTerms = new TreeSet<>();
-      searcher.createNormalizedWeight(q, false).extractTerms(extractedTerms);
-      for (Term term : extractedTerms) {
-        termContexts.put(term, TermContext.build(context, term));
-      }
+      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);
       Bits acceptDocs = context.reader().getLiveDocs();
-      final Spans spans = q.getSpans(context, acceptDocs, termContexts);
+      final Spans spans = w.getSpans(context, acceptDocs);
       if (spans == null) {
         return;
       }
Index: lucene/highlighter
===================================================================
--- lucene/highlighter	(revision 1685519)
+++ lucene/highlighter	(working copy)

Property changes on: lucene/highlighter
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene/highlighter:r1680565
Index: lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java	(revision 1685519)
+++ lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanQuery.java	(working copy)
@@ -18,16 +18,10 @@
  */
 
 import java.io.IOException;
-import java.util.Map;
-import java.util.Set;
 
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.util.Bits;
 
 /** Wraps a span query with asserts */
 public class AssertingSpanQuery extends SpanQuery {
@@ -38,21 +32,6 @@
   }
 
   @Override
-  protected void extractTerms(Set<Term> terms) {
-    in.extractTerms(terms);
-  }
-
-  @Override
-  public Spans getSpans(LeafReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException {
-    Spans spans = in.getSpans(context, acceptDocs, termContexts);
-    if (spans == null) {
-      return null;
-    } else {
-      return new AssertingSpans(spans);
-    }
-  }
-
-  @Override
   public String getField() {
     return in.getField();
   }
@@ -64,14 +43,8 @@
 
   @Override
   public SpanWeight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    // TODO: we are wasteful and createWeight twice in this case... use VirtualMethod?
-    // we need to not wrap if the query is e.g. a Payload one that overrides this (it should really be final)
     SpanWeight weight = in.createWeight(searcher, needsScores);
-    if (weight.getClass() == SpanWeight.class) {
-      return super.createWeight(searcher, needsScores);
-    } else {
-      return weight;
-    }
+    return new AssertingSpanWeight(searcher, weight);
   }
 
   @Override
Index: lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java
===================================================================
--- lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java	(revision 1680565)
+++ lucene/test-framework/src/java/org/apache/lucene/search/spans/AssertingSpanWeight.java	(working copy)
@@ -20,6 +20,9 @@
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Scorer;
 import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
@@ -38,8 +41,8 @@
    * @param in the SpanWeight to wrap
    * @throws IOException on error
    */
-  public AssertingSpanWeight(SpanWeight in) throws IOException {
-    super((SpanQuery) in.getQuery(), in.similarity, in.collectorFactory);
+  public AssertingSpanWeight(IndexSearcher searcher, SpanWeight in) throws IOException {
+    super((SpanQuery) in.getQuery(), searcher, null);
     this.in = in;
   }
 
@@ -49,8 +52,8 @@
   }
 
   @Override
-  public Spans getSpans(LeafReaderContext context, Bits liveDocs, SpanCollector collector) throws IOException {
-    Spans spans = in.getSpans(context, liveDocs, collector);
+  public Spans getSpans(LeafReaderContext context, Bits liveDocs) throws IOException {
+    Spans spans = in.getSpans(context, liveDocs);
     if (spans == null)
       return null;
     return new AssertingSpans(spans);
@@ -60,4 +63,24 @@
   public void extractTerms(Set<Term> terms) {
     in.extractTerms(terms);
   }
+
+  @Override
+  public float getValueForNormalization() throws IOException {
+    return in.getValueForNormalization();
+  }
+
+  @Override
+  public void normalize(float queryNorm, float topLevelBoost) {
+    in.normalize(queryNorm, topLevelBoost);
+  }
+
+  @Override
+  public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+    return in.scorer(context, acceptDocs);
+  }
+
+  @Override
+  public Explanation explain(LeafReaderContext context, int doc) throws IOException {
+    return in.explain(context, doc);
+  }
 }
Index: lucene/test-framework
===================================================================
--- lucene/test-framework	(revision 1685519)
+++ lucene/test-framework	(working copy)

Property changes on: lucene/test-framework
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene/test-framework:r1680565,1682513
Index: lucene
===================================================================
--- lucene	(revision 1685519)
+++ lucene	(working copy)

Property changes on: lucene
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk/lucene:r1680565,1680603,1680606,1682513
Index: .
===================================================================
--- .	(revision 1685519)
+++ .	(working copy)

Property changes on: .
___________________________________________________________________
Modified: svn:mergeinfo
   Merged /lucene/dev/trunk:r1680565,1680603,1680606,1682513
