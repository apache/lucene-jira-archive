Index: solr/contrib/clustering/build.xml
===================================================================
--- solr/contrib/clustering/build.xml	(revision 995688)
+++ solr/contrib/clustering/build.xml	(working copy)
@@ -99,7 +99,7 @@
   <target name="test" depends="compileTests">
     <mkdir dir="${junit.output.dir}"/>
 
-    <junit printsummary="on"
+    <junit printsummary="no"
            haltonfailure="no"
            maxmemory="512M"
            errorProperty="tests.failed"
@@ -114,18 +114,19 @@
       <sysproperty key="tests.locale" value="${tests.locale}"/>
       <sysproperty key="tests.timezone" value="${tests.timezone}"/>
       <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
+      <sysproperty key="tests.seed" value="${tests.seed}"/>
       <sysproperty key="tests.iter" value="${tests.iter}"/>
       <sysproperty key="jetty.insecurerandom" value="1"/>
       <sysproperty key="tempDir" file="${junit.output.dir}"/>
       <sysproperty key="testmethod" value="${testmethod}"/>
       <jvmarg line="${args}"/>
-      <formatter type="brief" usefile="false" if="junit.details"/>
+      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
       <classpath refid="test.classpath"/>
       <assertions>
         <enable package="org.apache.lucene"/>
         <enable package="org.apache.solr"/>
       </assertions>
-      <formatter type="xml"/>
+      <formatter type="${junit.formatter}"/>
       <batchtest fork="yes" todir="${junit.output.dir}" unless="testcase">
         <fileset dir="src/test/java" includes="${junit.includes}">
           <exclude name="**/AbstractClusteringTest*"/>
Index: solr/contrib/extraction/build.xml
===================================================================
--- solr/contrib/extraction/build.xml	(revision 995688)
+++ solr/contrib/extraction/build.xml	(working copy)
@@ -100,7 +100,7 @@
       </not>
     </condition>    
     
-  	<junit printsummary="on"
+  	<junit printsummary="no"
            haltonfailure="no"
            maxmemory="512M"
            errorProperty="tests.failed"
@@ -116,17 +116,18 @@
       <sysproperty key="tests.timezone" value="${tests.timezone}"/>
       <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
       <sysproperty key="tests.iter" value="${tests.iter}"/>
+      <sysproperty key="tests.seed" value="${tests.seed}"/>
       <sysproperty key="jetty.insecurerandom" value="1"/>
       <sysproperty key="tempDir" file="${tempDir}"/>
       <sysproperty key="testmethod" value="${testmethod}"/>
       <jvmarg line="${args}"/>
-      <formatter type="brief" usefile="false" if="junit.details"/>
+      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
       <classpath refid="test.classpath"/>
       <assertions>
         <enable package="org.apache.lucene"/>
         <enable package="org.apache.solr"/>
       </assertions>
-      <formatter type="xml"/>
+      <formatter type="${junit.formatter}"/>
       <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
         <fileset dir="src/test/java" includes="${junit.includes}"/>
       </batchtest>
Index: solr/contrib/dataimporthandler/build.xml
===================================================================
--- solr/contrib/dataimporthandler/build.xml	(revision 995688)
+++ solr/contrib/dataimporthandler/build.xml	(working copy)
@@ -151,7 +151,7 @@
       </not>
     </condition>
     
-  	<junit printsummary="on"
+  	<junit printsummary="no"
            haltonfailure="no"
            maxmemory="512M"
            errorProperty="tests.failed"
@@ -167,13 +167,14 @@
       <sysproperty key="tests.timezone" value="${tests.timezone}"/>
       <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
       <sysproperty key="tests.iter" value="${tests.iter}"/>
+      <sysproperty key="tests.seed" value="${tests.seed}"/>
       <sysproperty key="jetty.insecurerandom" value="1"/>
       <sysproperty key="tempDir" file="${tempDir}"/>
       <sysproperty key="testmethod" value="${testmethod}"/>
       <jvmarg line="${args}"/>
-      <formatter type="brief" usefile="false" if="junit.details"/>
+      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
       <classpath refid="test.classpath"/>
-      <formatter type="xml"/>
+      <formatter type="${junit.formatter}"/>
       <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
         <fileset dir="src/test/java" includes="${junit.includes}"/>
       </batchtest>
@@ -208,7 +209,7 @@
       </not>
     </condition>    
     
-  	<junit printsummary="on"
+  	<junit printsummary="no"
            haltonfailure="no"
            maxmemory="512M"
            errorProperty="tests.failed"
@@ -224,17 +225,18 @@
       <sysproperty key="tests.timezone" value="${tests.timezone}"/>
       <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
       <sysproperty key="tests.iter" value="${tests.iter}"/>
+      <sysproperty key="tests.seed" value="${tests.seed}"/>
       <sysproperty key="jetty.insecurerandom" value="1"/>
       <sysproperty key="tempDir" file="${tempDir}"/>
       <sysproperty key="testmethod" value="${testmethod}"/>
       <jvmarg line="${args}"/>
-      <formatter type="brief" usefile="false" if="junit.details"/>
+      <formatter classname="${junit.details.formatter}" usefile="false" if="junit.details"/>
       <classpath refid="test.extras.classpath"/>
       <assertions>
         <enable package="org.apache.lucene"/>
         <enable package="org.apache.solr"/>
       </assertions>
-      <formatter type="xml"/>
+      <formatter type="${junit.formatter}"/>
   	  
       <batchtest fork="yes" todir="${junit.output.dir}" if="runall">
         <fileset dir="src/extras/test/java" includes="${junit.includes}"/>
Index: solr/common-build.xml
===================================================================
--- solr/common-build.xml	(revision 995688)
+++ solr/common-build.xml	(working copy)
@@ -38,6 +38,8 @@
     <format property="dateversion" pattern="yyyy.MM.dd.HH.mm.ss" />
   </tstamp>
 
+  <property name="junit.details" value="1"/>
+
   <!-- default arguments to pass to jvm executing tests -->
   <property name="args" value="" />
 
@@ -55,6 +57,7 @@
   <property name="tests.locale" value="random" />
   <property name="tests.timezone" value="random" />
   <property name="tests.iter" value="1" />
+  <property name="tests.seed" value="random" />
 
   <condition property="dir.prop" value="-Dsolr.directoryFactory=solr.StandardDirectoryFactory">
     <isset property="use.fsdir"/>
Index: solr/src/test/org/apache/solr/search/TestSort.java
===================================================================
--- solr/src/test/org/apache/solr/search/TestSort.java	(revision 995688)
+++ solr/src/test/org/apache/solr/search/TestSort.java	(working copy)
@@ -48,8 +48,7 @@
   }
 
   public void testSort() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Document smallDoc = new Document();
     // Field id = new Field("id","0", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);
     Field f = new Field("f","0", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);
Index: solr/src/test/org/apache/solr/common/util/TestJavaBinCodec.java
===================================================================
--- solr/src/test/org/apache/solr/common/util/TestJavaBinCodec.java	(revision 995688)
+++ solr/src/test/org/apache/solr/common/util/TestJavaBinCodec.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
@@ -27,10 +26,9 @@
 public class TestJavaBinCodec extends LuceneTestCase {
   
  public void testStrings() throws Exception {
-    Random r = newRandom();
     JavaBinCodec javabin = new JavaBinCodec();
     for (int i = 0; i < 10000*RANDOM_MULTIPLIER; i++) {
-      String s = _TestUtil.randomUnicodeString(r);
+      String s = _TestUtil.randomUnicodeString(random);
       ByteArrayOutputStream os = new ByteArrayOutputStream();
       javabin.marshal(s, os);
       ByteArrayInputStream is = new ByteArrayInputStream(os.toByteArray());
Index: solr/src/test/org/apache/solr/util/PrimUtilsTest.java
===================================================================
--- solr/src/test/org/apache/solr/util/PrimUtilsTest.java	(revision 995688)
+++ solr/src/test/org/apache/solr/util/PrimUtilsTest.java	(working copy)
@@ -19,10 +19,8 @@
 import org.apache.lucene.util.LuceneTestCase;
 
 import java.util.Arrays;
-import java.util.Random;
 
 public class PrimUtilsTest extends LuceneTestCase {
-  Random r = newRandom();
 
   public void testSort() {
     int maxSize = 100;
@@ -38,10 +36,10 @@
     };
 
     for (int iter=0; iter<100; iter++) {
-      int start = r.nextInt(maxSize+1);
-      int end = start==maxSize ? maxSize : start + r.nextInt(maxSize-start);
+      int start = random.nextInt(maxSize+1);
+      int end = start==maxSize ? maxSize : start + random.nextInt(maxSize-start);
       for (int i=start; i<end; i++) {
-        a[i] = b[i] = r.nextInt(maxVal);
+        a[i] = b[i] = random.nextInt(maxVal);
       }
       PrimUtils.sort(start, end, a, comparator);
       Arrays.sort(b, start, end);
@@ -58,14 +56,14 @@
 
     for (int iter=0; iter<100; iter++) {
       int discardCount = 0;
-      int startSize = r.nextInt(maxSize) + 1;
-      int endSize = startSize==maxSize ? maxSize : startSize + r.nextInt(maxSize-startSize);
-      int adds = r.nextInt(maxSize+1);
+      int startSize = random.nextInt(maxSize) + 1;
+      int endSize = startSize==maxSize ? maxSize : startSize + random.nextInt(maxSize-startSize);
+      int adds = random.nextInt(maxSize+1);
       // System.out.println("startSize=" + startSize + " endSize=" + endSize + " adds="+adds);
       LongPriorityQueue pq = new LongPriorityQueue(startSize, endSize, Long.MIN_VALUE);
 
       for (int i=0; i<adds; i++) {
-        long v = r.nextLong();
+        long v = random.nextLong();
         a[i] = v;
         long out = pq.insertWithOverflow(v);
         if (i < endSize) {
Index: solr/build.xml
===================================================================
--- solr/build.xml	(revision 995688)
+++ solr/build.xml	(working copy)
@@ -33,8 +33,6 @@
 
   <property name="clover.db.dir" location="${dest}/tests/clover/db"/>
   <property name="clover.report.dir" location="${dest}/tests/clover/reports"/>
-
-  <property name="junit.details" value="1"/>
   
   <!-- change this together with the default and test's solrconfig.xml after starting a new development branch: -->
   <property name="tests.luceneMatchVersion" value="4.0"/>
@@ -436,6 +434,7 @@
       <sysproperty key="tests.timezone" value="${tests.timezone}"/>
       <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
       <sysproperty key="tests.iter" value="${tests.iter}"/>
+      <sysproperty key="tests.seed" value="${tests.seed}"/>
       <sysproperty key="jetty.insecurerandom" value="1"/>
       <sysproperty key="tempDir" file="@{tempDir}/@{threadNum}"/>
       <sysproperty key="testmethod" value="${testmethod}"/>
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(revision 995688)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java	(working copy)
@@ -92,10 +92,9 @@
   // TODO: instead of testing it this way, we can test 
   // with BaseTokenStreamTestCase now...
   public void testEndOffsetPositionWithTeeSinkTokenFilter() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Analyzer analyzer = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
     TeeSinkTokenFilter tee = new TeeSinkTokenFilter(analyzer.tokenStream("field", new StringReader("abcd   ")));
     TokenStream sink = tee.newSinkTokenStream();
Index: modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayMap.java
===================================================================
--- modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayMap.java	(revision 995688)
+++ modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArrayMap.java	(working copy)
@@ -24,23 +24,21 @@
 import org.apache.lucene.util.LuceneTestCase;
 
 public class TestCharArrayMap extends LuceneTestCase {
-  Random r = newRandom();
-
   public void doRandom(int iter, boolean ignoreCase) {
     CharArrayMap<Integer> map = new CharArrayMap<Integer>(TEST_VERSION_CURRENT, 1, ignoreCase);
     HashMap<String,Integer> hmap = new HashMap<String,Integer>();
 
     char[] key;
     for (int i=0; i<iter; i++) {
-      int len = r.nextInt(5);
+      int len = random.nextInt(5);
       key = new char[len];
       for (int j=0; j<key.length; j++) {
-        key[j] = (char)r.nextInt(127);
+        key[j] = (char)random.nextInt(127);
       }
       String keyStr = new String(key);
       String hmapKey = ignoreCase ? keyStr.toLowerCase(Locale.ENGLISH) : keyStr; 
 
-      int val = r.nextInt();
+      int val = random.nextInt();
 
       Object o1 = map.put(key, val);
       Object o2 = hmap.put(hmapKey,val);
Index: lucene/common-build.xml
===================================================================
--- lucene/common-build.xml	(revision 995688)
+++ lucene/common-build.xml	(working copy)
@@ -68,6 +68,7 @@
   <property name="tests.timezone" value="random" />
   <property name="tests.directory" value="random" />
   <property name="tests.iter" value="1" />
+  <property name="tests.seed" value="random" />
     
   <property name="javac.deprecation" value="off"/>
   <property name="javac.debug" value="on"/>
@@ -450,6 +451,8 @@
               <sysproperty key="tests.directory" value="${tests.directory}"/>
               <!-- set the number of times tests should run -->
               <sysproperty key="tests.iter" value="${tests.iter}"/>
+              <!-- set the test seed -->
+              <sysproperty key="tests.seed" value="${tests.seed}"/>
 	
 	      <!-- TODO: create propertyset for test properties, so each project can have its own set -->
               <sysproperty key="tests.multiplier" value="${tests.multiplier}"/>
Index: lucene/src/test/org/apache/lucene/TestMergeSchedulerExternal.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestMergeSchedulerExternal.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/TestMergeSchedulerExternal.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.store.MockDirectoryWrapper;
@@ -83,15 +82,14 @@
   }
 
   public void testSubclassConcurrentMergeScheduler() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     dir.failOn(new FailOnlyOnMerge());
 
     Document doc = new Document();
     Field idField = new Field("id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
     doc.add(idField);
     
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new MyMergeScheduler())
         .setMaxBufferedDocs(2).setRAMBufferSizeMB(
             IndexWriterConfig.DISABLE_AUTO_FLUSH));
Index: lucene/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java
===================================================================
--- lucene/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/queryParser/TestMultiFieldQueryParser.java	(working copy)
@@ -21,7 +21,6 @@
 import java.io.Reader;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
@@ -282,9 +281,8 @@
 
   public void testStopWordSearching() throws Exception {
     Analyzer analyzer = new MockAnalyzer();
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw =  new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    Directory ramDir = newDirectory();
+    IndexWriter iw =  new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
     doc.add(new Field("body", "blah the footest blah", Field.Store.NO, Field.Index.ANALYZED));
     iw.addDocument(doc);
Index: lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java
===================================================================
--- lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java	(working copy)
@@ -27,7 +27,6 @@
 import java.util.GregorianCalendar;
 import java.util.HashSet;
 import java.util.Locale;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -569,9 +568,8 @@
   }
     
   public void testFarsiRangeCollating() throws Exception {
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    Directory ramDir = newDirectory();
+    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     Document doc = new Document();
     doc.add(new Field("content","\u0633\u0627\u0628", 
                       Field.Store.YES, Field.Index.NOT_ANALYZED));
@@ -979,9 +977,8 @@
   }
 
   public void testLocalDateFormat() throws IOException, ParseException {
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    Directory ramDir = newDirectory();
+    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
     addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
     iw.close();
@@ -1154,10 +1151,9 @@
   // enableStopPositionIncr & QueryParser's enablePosIncr
   // "match"
   public void testPositionIncrements() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Analyzer a = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, a));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, a));
     Document doc = new Document();
     doc.add(new Field("f", "the wizard of ozzy", Field.Store.NO, Field.Index.ANALYZED));
     w.addDocument(doc);
Index: lucene/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java	(working copy)
@@ -19,7 +19,6 @@
 
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
@@ -37,8 +36,7 @@
   private String[] tokens = new String[] {"term1", "term2", "term3", "term2"};
   
   public void testCaching() throws IOException {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     Document doc = new Document();
     TokenStream stream = new TokenStream() {
Index: lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java
===================================================================
--- lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java	(working copy)
@@ -20,10 +20,8 @@
 import java.io.IOException;
 import java.io.Reader;
 import java.io.StringReader;
-import java.util.Random;
 
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util._TestUtil;
 
 /**
  * Testcase for {@link CharTokenizer} subclasses
@@ -36,9 +34,8 @@
    */
   public void testReadSupplementaryChars() throws IOException {
     StringBuilder builder = new StringBuilder();
-    Random newRandom = newRandom();
     // create random input
-    int num = 1024 + newRandom.nextInt(1024);
+    int num = 1024 + random.nextInt(1024);
     num *= RANDOM_MULTIPLIER;
     for (int i = 1; i < num; i++) {
       builder.append("\ud801\udc1cabc");
Index: lucene/src/test/org/apache/lucene/TestExternalCodecs.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestExternalCodecs.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/TestExternalCodecs.java	(working copy)
@@ -600,10 +600,9 @@
   public void testPerFieldCodec() throws Exception {
     
     final int NUM_DOCS = 173;
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     IndexWriter w = new IndexWriter(dir,
-                                    newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(new MyCodecs()));
+                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(new MyCodecs()));
 
     w.setMergeFactor(3);
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/TestDemo.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestDemo.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/TestDemo.java	(working copy)
@@ -33,7 +33,6 @@
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -49,7 +48,7 @@
     Analyzer analyzer = new MockAnalyzer();
 
     // Store the index in memory:
-    Directory directory = newDirectory(newRandom());
+    Directory directory = newDirectory();
     // To store an index on disk, use this instead:
     //Directory directory = FSDirectory.open("/tmp/testindex");
     IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(
Index: lucene/src/test/org/apache/lucene/search/TestFuzzyQuery2.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFuzzyQuery2.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFuzzyQuery2.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.BufferedReader;
 import java.io.InputStream;
 import java.io.InputStreamReader;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -57,13 +56,6 @@
 public class TestFuzzyQuery2 extends LuceneTestCase {
   /** epsilon for score comparisons */
   static final float epsilon = 0.00001f;
-  private Random random;
-  
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
 
   public void testFromTestData() throws Exception {
     // TODO: randomize!
@@ -86,7 +78,7 @@
     int bits = Integer.parseInt(reader.readLine());
     int terms = (int) Math.pow(2, bits);
     
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
     
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestNot.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestNot.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestNot.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 
 import org.apache.lucene.index.IndexReader;
@@ -40,8 +38,7 @@
   }
 
   public void testNot() throws Exception {
-    Random random = newRandom();
-    Directory store = newDirectory(random);
+    Directory store = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, store);
 
     Document d1 = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.BitSet;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -76,8 +75,7 @@
         "blueberry strudel",
         "blueberry pizza",
     };
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter iw = new RandomIndexWriter(random, directory);
     
     for (int i=0; i<N_DOCS; i++) {
Index: lucene/src/test/org/apache/lucene/search/TestPrefixFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPrefixFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPrefixFilter.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.index.IndexReader;
@@ -33,8 +31,7 @@
  */
 public class TestPrefixFilter extends LuceneTestCase {
   public void testPrefixFilter() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
 
     String[] categories = new String[] {"/Computers/Linux",
                                         "/Computers/Mac/One",
Index: lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
 import java.io.IOException;
 
 import org.apache.lucene.index.IndexReader;
@@ -34,17 +33,10 @@
 import org.apache.lucene.util.OpenBitSetDISI;
 
 public class TestCachingWrapperFilter extends LuceneTestCase {
-  Random rand;
 
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    rand = newRandom();
-  }
-
   public void testCachingWorks() throws Exception {
-    Directory dir = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -69,8 +61,8 @@
   }
   
   public void testNullDocIdSet() throws Exception {
-    Directory dir = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -91,8 +83,8 @@
   }
   
   public void testNullDocIdSetIterator() throws Exception {
-    Directory dir = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.close();
 
     IndexReader reader = IndexReader.open(dir, true);
@@ -132,8 +124,8 @@
   }
   
   public void testIsCacheAble() throws Exception {
-    Directory dir = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.addDocument(new Document());
     writer.close();
 
@@ -159,9 +151,9 @@
   }
 
   public void testEnforceDeletions() throws Exception {
-    Directory dir = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, dir,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
+                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
 
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
Index: lucene/src/test/org/apache/lucene/search/TestAutomatonQueryUnicode.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestAutomatonQueryUnicode.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestAutomatonQueryUnicode.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -44,8 +43,7 @@
 
   public void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     Document doc = new Document();
     Field titleField = new Field("title", "some title", Field.Store.NO,
Index: lucene/src/test/org/apache/lucene/search/TestBooleanQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBooleanQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBooleanQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.document.Document;
@@ -60,8 +58,7 @@
 
   // LUCENE-1630
   public void testNullOrSubScorer() throws Throwable {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter w = new RandomIndexWriter(random, dir);
     Document doc = new Document();
     doc.add(new Field("field", "a b c d", Field.Store.NO, Field.Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java	(working copy)
@@ -49,13 +49,11 @@
   private IndexReader reader;
   private PhraseQuery query;
   private Directory directory;
-  private Random random;
 
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     Analyzer analyzer = new Analyzer() {
       @Override
       public TokenStream tokenStream(String fieldName, Reader reader) {
@@ -213,10 +211,10 @@
   }
   
   public void testPhraseQueryWithStopAnalyzer() throws Exception {
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     Analyzer stopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, Version.LUCENE_24, stopAnalyzer));
+        newIndexWriterConfig( Version.LUCENE_24, stopAnalyzer));
     Document doc = new Document();
     doc.add(new Field("field", "the stop words are here", Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
@@ -249,7 +247,7 @@
   }
   
   public void testPhraseQueryInConjunctionScorer() throws Exception {
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     
     Document doc = new Document();
@@ -287,7 +285,7 @@
     reader.close();
     
     writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     doc = new Document();
     doc.add(new Field("contents", "map entry woo", Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
@@ -336,7 +334,7 @@
   }
   
   public void testSlopScoring() throws IOException {
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
 
     Document doc = new Document();
@@ -597,7 +595,7 @@
   }
 
   public void testRandomPhrases() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
 
     RandomIndexWriter w  = new RandomIndexWriter(random, dir, analyzer);
Index: lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPositionIncrement.java	(working copy)
@@ -90,8 +90,7 @@
         };
       }
     };
-    Random random = newRandom();
-    Directory store = newDirectory(random);
+    Directory store = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, store, analyzer);
     Document d = new Document();
     d.add(new Field("field", "bogus", Field.Store.YES, Field.Index.ANALYZED));
@@ -241,8 +240,7 @@
     new CharacterRunAutomaton(new RegExp("[sS][tT][oO][pP]").toAutomaton());
   
   public void testPayloadsPos0() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, new TestPayloadAnalyzer());
     Document doc = new Document();
     doc.add(new Field("content", new StringReader(
Index: lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java	(working copy)
@@ -33,7 +33,6 @@
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Locale;
-import java.util.Random;
 import java.util.Set;
 import java.util.HashSet;
 import java.util.Arrays;
@@ -44,13 +43,11 @@
 
   private int docCount = 0;
   private Directory dir;
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
   }
   
   @Override
@@ -341,7 +338,7 @@
   }
 
   private void initializeIndex(String[] values, Analyzer analyzer) throws IOException {
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setOpenMode(OpenMode.CREATE));
     for (int i = 0; i < values.length; i++) {
       insertDoc(writer, values[i]);
@@ -350,7 +347,7 @@
   }
 
   private void addDoc(String content) throws IOException {
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setOpenMode(OpenMode.APPEND));
     insertDoc(writer, content);
     writer.close();
   }
Index: lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBooleanMinShouldMatch.java	(working copy)
@@ -32,7 +32,6 @@
  */
 public class TestBooleanMinShouldMatch extends LuceneTestCase {
 
-    private Random rnd;
     private Directory index;
     private IndexReader r;
     private IndexSearcher s;
@@ -41,8 +40,6 @@
     protected void setUp() throws Exception {
         super.setUp();
 
-        rnd = newRandom();
-        
         String[] data = new String [] {
             "A 1 2 3 4 5 6",
             "Z       4 5 6",
@@ -54,8 +51,8 @@
             "X       4 5 6"
         };
 
-        index = newDirectory(rnd);
-        RandomIndexWriter w = new RandomIndexWriter(rnd, index);
+        index = newDirectory();
+        RandomIndexWriter w = new RandomIndexWriter(random, index);
 
         for (int i = 0; i < data.length; i++) {
             Document doc = new Document();
@@ -308,7 +305,7 @@
           for (int i=0; i<c.length;i++) {
             if (c[i].getOccur() == BooleanClause.Occur.SHOULD) opt++;
           }
-          q.setMinimumNumberShouldMatch(rnd.nextInt(opt+2));
+          q.setMinimumNumberShouldMatch(random.nextInt(opt+2));
         }
       };
 
@@ -317,8 +314,8 @@
       // increase number of iterations for more complete testing      
       int num = 50 * RANDOM_MULTIPLIER;
       for (int i=0; i<num; i++) {
-        int lev = rnd.nextInt(maxLev);
-        final long seed = rnd.nextLong();
+        int lev = random.nextInt(maxLev);
+        final long seed = random.nextLong();
         BooleanQuery q1 = TestBoolean2.randBoolQuery(new Random(seed), true, lev, field, vals, null);
         // BooleanQuery q2 = TestBoolean2.randBoolQuery(new Random(seed), lev, field, vals, minNrCB);
         BooleanQuery q2 = TestBoolean2.randBoolQuery(new Random(seed), true, lev, field, vals, null);
Index: lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -48,14 +46,6 @@
   private static final PhraseQuery QUERY_2 = makePhraseQuery( S_2 );
   private static final PhraseQuery QUERY_4 = makePhraseQuery( "X A A");
 
-  private Random random;
-  
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-
   /**
    * Test DOC_4 and QUERY_4.
    * QUERY_4 has a fuzzy (len=1) match to DOC_4, so all slop values > 0 should succeed.
@@ -125,7 +115,7 @@
   private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {
     query.setSlop(slop);
 
-    Directory ramDir = newDirectory(random);
+    Directory ramDir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
     writer.addDocument(doc);
 
Index: lucene/src/test/org/apache/lucene/search/TestBooleanOr.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBooleanOr.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBooleanOr.java	(working copy)
@@ -16,7 +16,6 @@
  * limitations under the License.
  */
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -136,8 +135,7 @@
     super.setUp();
 
     //
-    Random random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
 
 
     //
Index: lucene/src/test/org/apache/lucene/search/TestDateSort.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestDateSort.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestDateSort.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.util.Arrays;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -51,8 +50,7 @@
   protected void setUp() throws Exception {
     super.setUp();
     // Create an index writer.
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
 
     // oldest doc:
Index: lucene/src/test/org/apache/lucene/search/TestSort.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSort.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSort.java	(working copy)
@@ -24,7 +24,6 @@
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Locale;
-import java.util.Random;
 
 import junit.framework.Test;
 import junit.framework.TestSuite;
@@ -70,8 +69,6 @@
   private Query queryG;
   private Sort sort;
 
-  private Random random = newRandom();
-
   public TestSort (String name) {
     super (name);
   }
@@ -109,7 +106,7 @@
   // create an index of all the documents, or just the x, or just the y documents
   private IndexSearcher getIndex (boolean even, boolean odd)
   throws IOException {
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     dirs.add(indexStore);
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
 
@@ -145,7 +142,7 @@
   }
   
   private IndexSearcher getFullStrings() throws CorruptIndexException, LockObtainFailedException, IOException {
-    Directory indexStore = newDirectory (random);
+    Directory indexStore = newDirectory();
     dirs.add(indexStore);
     IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(4));
@@ -189,11 +186,9 @@
     return sb.toString();
   }
   
-  Random r;
-  
   public int getRandomNumber(final int low, final int high) {
   
-    int randInt = (Math.abs(r.nextInt()) % (high - low)) + low;
+    int randInt = (Math.abs(random.nextInt()) % (high - low)) + low;
 
     return randInt;
   }
@@ -289,7 +284,6 @@
    * Test String sorting: small queue to many matches, multi field sort, reverse sort
    */
   public void testStringSort() throws IOException, ParseException {
-    r = newRandom();
     ScoreDoc[] result = null;
     IndexSearcher searcher = getFullStrings();
     sort.setSort(
@@ -1101,8 +1095,8 @@
   }
 
   public void testEmptyStringVsNullStringSort() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
                         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("f", "", Field.Store.NO, Field.Index.NOT_ANALYZED));
@@ -1126,8 +1120,8 @@
   }
 
   public void testLUCENE2142() throws IOException {
-    Directory indexStore = newDirectory (random);
-    IndexWriter writer = new IndexWriter(indexStore, newIndexWriterConfig(random,
+    Directory indexStore = newDirectory();
+    IndexWriter writer = new IndexWriter(indexStore, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     for (int i=0; i<5; i++) {
         Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiTermConstantScore.java	(working copy)
@@ -54,8 +54,8 @@
         "B   2   4 5 6", "Y     3   5 6", null, "C     3     6",
         "X       4 5 6" };
 
-    small = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, small, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
+    small = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, small, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
 
     for (int i = 0; i < data.length; i++) {
       Document doc = new Document();
@@ -608,8 +608,8 @@
   public void testFarsi() throws Exception {
 
     /* build an index */
-    Directory farsiIndex = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
+    Directory farsiIndex = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, farsiIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
     Document doc = new Document();
     doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
         Field.Index.NOT_ANALYZED));
@@ -648,8 +648,8 @@
   public void testDanish() throws Exception {
 
     /* build an index */
-    Directory danishIndex = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
+    Directory danishIndex = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, danishIndex, new MockAnalyzer(MockTokenizer.SIMPLE, true));
 
     // Danish collation orders the words below in the given order
     // (example taken from TestSort.testInternationalSort() ).
Index: lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestWildcardRandom.java	(working copy)
@@ -21,7 +21,6 @@
 import java.text.DecimalFormatSymbols;
 import java.text.NumberFormat;
 import java.util.Locale;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -39,14 +38,12 @@
 public class TestWildcardRandom extends LuceneTestCase {
   private Searcher searcher;
   private IndexReader reader;
-  private Random random;
   private Directory dir;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java	(working copy)
@@ -18,7 +18,6 @@
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Collection;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -34,7 +33,6 @@
 import org.apache.lucene.search.DefaultSimilarity;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryUtils;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Searcher;
@@ -108,10 +106,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
         .setSimilarity(similarity));
     //writer.infoStream = System.out;
     for (int i = 0; i < 1000; i++) {
Index: lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java	(working copy)
@@ -45,7 +45,6 @@
 
 import java.io.Reader;
 import java.io.IOException;
-import java.util.Random;
 
 
 /**
@@ -112,10 +111,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new PayloadAnalyzer())
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer())
         .setSimilarity(similarity));
     //writer.infoStream = System.out;
     for (int i = 0; i < 1000; i++) {
Index: lucene/src/test/org/apache/lucene/search/TestBooleanScorer.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBooleanScorer.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBooleanScorer.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -40,8 +39,7 @@
   private static final String FIELD = "category";
   
   public void testMethod() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
 
     String[] values = new String[] { "1", "2", "3", "4" };
 
Index: lucene/src/test/org/apache/lucene/search/TestDocIdSet.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestDocIdSet.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestDocIdSet.java	(working copy)
@@ -21,7 +21,6 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Iterator;
-import java.util.Random;
 
 import junit.framework.Assert;
 
@@ -101,8 +100,7 @@
   public void testNullDocIdSet() throws Exception {
     // Tests that if a Filter produces a null DocIdSet, which is given to
     // IndexSearcher, everything works fine. This came up in LUCENE-1754.
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     Document doc = new Document();
     doc.add(new Field("c", "val", Store.NO, Index.NOT_ANALYZED_NO_NORMS));
Index: lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestNearSpansOrdered.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -55,8 +53,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     for (int i = 0; i < docFields.length; i++) {
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestBasics.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestBasics.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -60,8 +59,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
         new MockAnalyzer(MockTokenizer.SIMPLE, true));
     //writer.infoStream = System.out;
Index: lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestSpans.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestSpans.java	(working copy)
@@ -38,21 +38,18 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.util.LuceneTestCase;
 import java.io.IOException;
-import java.util.Random;
 
 public class TestSpans extends LuceneTestCase {
   private IndexSearcher searcher;
   private IndexReader reader;
   private Directory directory;
-  private Random random;
   
   public static final String field = "field";
 
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     for (int i = 0; i < docFields.length; i++) {
       Document doc = new Document();
@@ -463,7 +460,7 @@
 
   // LUCENE-1404
   public void testNPESpanQuery() throws Throwable {
-    final Directory dir = newDirectory(random);
+    final Directory dir = newDirectory();
     final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
 
Index: lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.util.HashSet;
-import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.document.Document;
@@ -55,8 +54,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     
     writer.addDocument(doc(new Field[] { field("id", "0")
Index: lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -44,7 +43,6 @@
   protected Directory mDirectory;
   protected IndexReader reader;
   protected IndexSearcher searcher;
-  protected Random random;
   
   // field names in the index
   private final static String FIELD_ID = "ID";
@@ -56,9 +54,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
     // create test index
-    mDirectory = newDirectory(random);
+    mDirectory = newDirectory();
     final RandomIndexWriter writer = new RandomIndexWriter(random,
         mDirectory, new MockAnalyzer(MockTokenizer.SIMPLE, true,
                 MockTokenFilter.ENGLISH_STOPSET, true));
Index: lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestSpansAdvanced2.java	(working copy)
@@ -46,7 +46,7 @@
     
     // create test index
     final RandomIndexWriter writer = new RandomIndexWriter(random, mDirectory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(
             MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true))
             .setOpenMode(OpenMode.APPEND));
     addDocument(writer, "A", "Should we, could we, would we?");
Index: lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Set;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -55,7 +54,6 @@
   private Similarity similarity = new DefaultSimilarity();
   protected IndexReader indexReader;
   private IndexReader closeIndexReader;
-  private Random rand;
   private Directory directory;
   
   public TestPayloadSpans(String s) {
@@ -65,7 +63,6 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    rand = newRandom();
     PayloadHelper helper = new PayloadHelper();
     searcher = helper.setUp(similarity, 1000);
     indexReader = searcher.getIndexReader();
@@ -116,9 +113,9 @@
 
 
 
-    Directory directory = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
 
     Document doc = new Document();
     doc.add(new Field(PayloadHelper.FIELD, "one two three one four three",
@@ -260,9 +257,9 @@
   
   public void testShrinkToAfterShortestMatch() throws CorruptIndexException,
       LockObtainFailedException, IOException {
-    Directory directory = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
 
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("a b c d e f g h i j a k")));
@@ -298,9 +295,9 @@
   
   public void testShrinkToAfterShortestMatch2() throws CorruptIndexException,
       LockObtainFailedException, IOException {
-    Directory directory = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
 
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("a b a d k f a h i k a k")));
@@ -334,9 +331,9 @@
   
   public void testShrinkToAfterShortestMatch3() throws CorruptIndexException,
       LockObtainFailedException, IOException {
-    Directory directory = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new TestPayloadAnalyzer()));
 
     Document doc = new Document();
     doc.add(new Field("content", new StringReader("j k a l f k k p a t a k l k t a")));
@@ -375,9 +372,9 @@
   }
   
   public void testPayloadSpanUtil() throws Exception {
-    Directory directory = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
 
     Document doc = new Document();
     doc.add(new Field(PayloadHelper.FIELD,"xx rr yy mm  pp", Field.Store.YES, Field.Index.ANALYZED));
@@ -434,10 +431,10 @@
   }
   
   private IndexSearcher getSearcher() throws Exception {
-    directory = newDirectory(rand);
+    directory = newDirectory();
     String[] docs = new String[]{"xx rr yy mm  pp","xx yy mm rr pp", "nopayload qq ss pp np", "one two three four five six seven eight nine ten eleven", "nine one two three four five six seven eight eleven ten"};
-    RandomIndexWriter writer = new RandomIndexWriter(rand, directory,
-                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory,
+                                                     newIndexWriterConfig(TEST_VERSION_CURRENT, new PayloadAnalyzer()).setSimilarity(similarity));
 
     Document doc = null;
     for(int i = 0; i < docs.length; i++) {
Index: lucene/src/test/org/apache/lucene/search/TestMultiSearcher.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiSearcher.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiSearcher.java	(working copy)
@@ -18,6 +18,7 @@
  */
 
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.LuceneTestCaseJ4;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -41,14 +42,7 @@
  */
 public class TestMultiSearcher extends LuceneTestCase
 {
-  private Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
     public TestMultiSearcher(String name)
     {
         super(name);
@@ -64,8 +58,8 @@
 
     public void testEmptyIndex() throws Exception {
         // creating two directories for indices
-        Directory indexStoreA = newDirectory(random);
-        Directory indexStoreB = newDirectory(random);
+        Directory indexStoreA = newDirectory();
+        Directory indexStoreB = newDirectory();
 
         // creating a document to store
         Document lDoc = new Document();
@@ -88,9 +82,9 @@
         lDoc3.add(new Field("handle", "1", Field.Store.YES, Field.Index.NOT_ANALYZED));
 
         // creating an index writer for the first index
-        IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         // creating an index writer for the second index, but writing nothing
-        IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
         //--------------------------------------------------------------------
         // scenario 1
@@ -134,7 +128,7 @@
         //--------------------------------------------------------------------
 
         // adding one document to the empty index
-        writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(random,
+        writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(
             TEST_VERSION_CURRENT, 
                 new MockAnalyzer())
                 .setOpenMode(OpenMode.APPEND));
@@ -227,7 +221,7 @@
         IndexWriter indexWriter=null;
         
         try {
-          indexWriter = new IndexWriter(directory, newIndexWriterConfig(random,
+          indexWriter = new IndexWriter(directory, LuceneTestCaseJ4.newIndexWriterConfig(random,
               TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(
                   create ? OpenMode.CREATE : OpenMode.APPEND));
             
@@ -245,8 +239,8 @@
     Directory ramDirectory1, ramDirectory2;
     IndexSearcher indexSearcher1, indexSearcher2;
 
-    ramDirectory1 = newDirectory(random);
-    ramDirectory2 = newDirectory(random);
+    ramDirectory1 = newDirectory();
+    ramDirectory2 = newDirectory();
     Query query = new TermQuery(new Term("contents", "doc0"));
 
     // Now put the documents in a different index
@@ -307,7 +301,7 @@
         IndexSearcher indexSearcher1;
         ScoreDoc[] hits;
         
-        ramDirectory1=newDirectory(random);
+        ramDirectory1=newDirectory();
         
         // First put the documents in the same index
         initIndex(random, ramDirectory1, nDocs, true, null); // documents with a single token "doc0", "doc1", etc...
@@ -334,8 +328,8 @@
         Directory ramDirectory2;
         IndexSearcher indexSearcher2;
         
-        ramDirectory1=newDirectory(random);
-        ramDirectory2=newDirectory(random);
+        ramDirectory1=newDirectory();
+        ramDirectory2=newDirectory();
         
         // Now put the documents in a different index
         initIndex(random, ramDirectory1, nDocs, true, null); // documents with a single token "doc0", "doc1", etc...
@@ -377,7 +371,7 @@
      * @throws IOException 
      */
     public void testCustomSimilarity () throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
         initIndex(random, dir, 10, true, "x"); // documents with two tokens "doc0" and "x", "doc1" and x, etc...
         IndexSearcher srchr = new IndexSearcher(dir, true);
         MultiSearcher msrchr = getMultiSearcherInstance(new Searcher[]{srchr});
@@ -420,8 +414,8 @@
     }
     
     public void testDocFreq() throws IOException{
-      Directory dir1 = newDirectory(random);
-      Directory dir2 = newDirectory(random);
+      Directory dir1 = newDirectory();
+      Directory dir2 = newDirectory();
 
       initIndex(random, dir1, 10, true, "x"); // documents with two tokens "doc0" and "x", "doc1" and x, etc...
       initIndex(random, dir2, 5, true, "x"); // documents with two tokens "doc0" and "x", "doc1" and x, etc...
@@ -438,8 +432,8 @@
     }
     
     public void testCreateDocFrequencyMap() throws IOException{
-      Directory dir1 = newDirectory(random);
-      Directory dir2 = newDirectory(random);
+      Directory dir1 = newDirectory();
+      Directory dir2 = newDirectory();
       Term template = new Term("contents") ;
       String[] contents  = {"a", "b", "c"};
       HashSet<Term> termsSet = new HashSet<Term>();
Index: lucene/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Index;
@@ -33,8 +31,7 @@
 public class TestQueryWrapperFilter extends LuceneTestCase {
 
   public void testBasic() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     Document doc = new Document();
     doc.add(new Field("field", "value", Store.NO, Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/search/TestTermVectors.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTermVectors.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTermVectors.java	(working copy)
@@ -31,7 +31,6 @@
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.Random;
 import java.util.SortedSet;
 
 public class TestTermVectors extends LuceneTestCase {
@@ -39,8 +38,6 @@
   private IndexReader reader;
   private Directory directory;
 
-  private Random random;
-
   public TestTermVectors(String s) {
     super(s);
   }
@@ -48,8 +45,7 @@
   @Override
   protected void setUp() throws Exception {                  
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.SIMPLE, true));
     //writer.setUseCompoundFile(true);
     //writer.infoStream = System.out;
@@ -115,7 +111,7 @@
   }
   
   public void testTermVectorsFieldOrder() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.SIMPLE, true));
     Document doc = new Document();
     doc.add(new Field("c", "some content here", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
@@ -243,10 +239,10 @@
     Document testDoc4 = new Document();
     setupDoc(testDoc4, test4);
     
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
         .setOpenMode(OpenMode.CREATE));
     writer.addDocument(testDoc1);
     writer.addDocument(testDoc2);
@@ -359,7 +355,7 @@
   // Test only a few docs having vectors
   public void testRareVectors() throws IOException {
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true))
         .setOpenMode(OpenMode.CREATE));
     for (int i = 0; i < 100; i++) {
       Document doc = new Document();
@@ -394,7 +390,7 @@
   // vectors up
   public void testMixedVectrosVectors() throws IOException {
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, 
+        newIndexWriterConfig(TEST_VERSION_CURRENT, 
         new MockAnalyzer(MockTokenizer.SIMPLE, true)).setOpenMode(OpenMode.CREATE));
     Document doc = new Document();
     doc.add(new Field("field", "one",
Index: lucene/src/test/org/apache/lucene/search/TestSimpleExplanations.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSimpleExplanations.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSimpleExplanations.java	(working copy)
@@ -305,8 +305,8 @@
   
   public void testTermQueryMultiSearcherExplain() throws Exception {
     // creating two directories for indices
-    Directory indexStoreA = newDirectory(random);
-    Directory indexStoreB = newDirectory(random);
+    Directory indexStoreA = newDirectory();
+    Directory indexStoreB = newDirectory();
 
     Document lDoc = new Document();
     lDoc.add(new Field("handle", "1 2", Field.Store.YES, Field.Index.ANALYZED));
@@ -315,9 +315,9 @@
     Document lDoc3 = new Document();
     lDoc3.add(new Field("handle", "1 2", Field.Store.YES, Field.Index.ANALYZED));
 
-    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(random,
+    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
-    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(random,
+    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     writerA.addDocument(lDoc);
Index: lucene/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiValuedNumericRangeQuery.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
 import java.util.Locale;
 import java.text.DecimalFormat;
 import java.text.DecimalFormatSymbols;
@@ -38,18 +37,16 @@
    * do not interfere with multiple numeric values.
    */
   public void testMultiValuedNRQ() throws Exception {
-    final Random rnd = newRandom();
-
-    Directory directory = newDirectory(rnd);
-    RandomIndexWriter writer = new RandomIndexWriter(rnd, directory);
+    Directory directory = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     
     DecimalFormat format = new DecimalFormat("00000000000", new DecimalFormatSymbols(Locale.US));
     
     int num = 5000 * RANDOM_MULTIPLIER;
     for (int l = 0; l < num; l++) {
       Document doc = new Document();
-      for (int m=0, c=rnd.nextInt(10); m<=c; m++) {
-        int value = rnd.nextInt(Integer.MAX_VALUE);
+      for (int m=0, c=random.nextInt(10); m<=c; m++) {
+        int value = random.nextInt(Integer.MAX_VALUE);
         doc.add(new Field("asc", format.format(value), Field.Store.NO, Field.Index.NOT_ANALYZED));
         doc.add(new NumericField("trie", Field.Store.NO, true).setIntValue(value));
       }
@@ -61,8 +58,8 @@
     Searcher searcher=new IndexSearcher(reader);
     num = 50 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      int lower=rnd.nextInt(Integer.MAX_VALUE);
-      int upper=rnd.nextInt(Integer.MAX_VALUE);
+      int lower=random.nextInt(Integer.MAX_VALUE);
+      int upper=random.nextInt(Integer.MAX_VALUE);
       if (lower>upper) {
         int a=lower; lower=upper; upper=a;
       }
Index: lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTopDocsCollector.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
@@ -108,8 +107,7 @@
     
     // populate an index with 30 documents, this should be enough for the test.
     // The documents have no content - the test uses MatchAllDocsQuery().
-    Random random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     for (int i = 0; i < 30; i++) {
       writer.addDocument(new Document());
Index: lucene/src/test/org/apache/lucene/search/TestTermScorer.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTermScorer.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTermScorer.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.document.Document;
@@ -47,8 +46,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     for (int i = 0; i < values.length; i++) {
Index: lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery.java	(working copy)
@@ -30,7 +30,6 @@
 
 import java.io.IOException;
 import java.util.LinkedList;
-import java.util.Random;
 
 /**
  * This class tests PhrasePrefixQuery class.
@@ -44,8 +43,7 @@
      *
      */
   public void testPhrasePrefix() throws IOException {
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     Document doc1 = new Document();
     Document doc2 = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestSetNorm.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSetNorm.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSetNorm.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -39,9 +38,8 @@
   }
 
   public void testSetNorm() throws Exception {
-    Random random = newRandom();
-    Directory store = newDirectory(random);
-    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory store = newDirectory();
+    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     // add the same document four times
     Fieldable f1 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
Index: lucene/src/test/org/apache/lucene/search/TestWildcard.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestWildcard.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestWildcard.java	(working copy)
@@ -29,19 +29,16 @@
 import org.apache.lucene.queryParser.QueryParser;
 
 import java.io.IOException;
-import java.util.Random;
 
 /**
  * TestWildcard tests the '*' and '?' wildcard characters.
  */
 public class TestWildcard
     extends LuceneTestCase {
-  private Random random;
   
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
   }
 
   public void testEquals() {
@@ -210,7 +207,7 @@
 
   private Directory getIndexStore(String field, String[] contents)
       throws IOException {
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     for (int i = 0; i < contents.length; ++i) {
       Document doc = new Document();
@@ -266,7 +263,7 @@
     };
 
     // prepare the index
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter iw = new RandomIndexWriter(random, dir);
     for (int i = 0; i < docs.length; i++) {
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestAutomatonQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestAutomatonQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestAutomatonQuery.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -41,8 +40,7 @@
   
   public void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     Document doc = new Document();
     Field titleField = new Field("title", "some title", Field.Store.NO,
Index: lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java	(working copy)
@@ -34,8 +34,6 @@
   public static final boolean F = false;
   public static final boolean T = true;
   
-  protected Random rand = newRandom();
-  
   /**
    * Collation interacts badly with hyphens -- collation produces different
    * ordering than Unicode code-point ordering -- so two indexes are created:
@@ -48,12 +46,12 @@
     boolean allowNegativeRandomInts;
     Directory index;
     
-    TestIndex(int minR, int maxR, boolean allowNegativeRandomInts) {
+    TestIndex(Random random, int minR, int maxR, boolean allowNegativeRandomInts) {
       this.minR = minR;
       this.maxR = maxR;
       this.allowNegativeRandomInts = allowNegativeRandomInts;
       try {
-        index = newDirectory(rand);
+        index = newDirectory();
       } catch (IOException e) { throw new RuntimeException(e); }
     }
   }
@@ -91,10 +89,10 @@
    
   protected void setUp() throws Exception {
     super.setUp();
-    signedIndexDir = new TestIndex(Integer.MAX_VALUE, Integer.MIN_VALUE, true);
-    unsignedIndexDir = new TestIndex(Integer.MAX_VALUE, 0, false);
-    signedIndexReader = build(rand, signedIndexDir);
-    unsignedIndexReader = build(rand, unsignedIndexDir);
+    signedIndexDir = new TestIndex(random, Integer.MAX_VALUE, Integer.MIN_VALUE, true);
+    unsignedIndexDir = new TestIndex(random, Integer.MAX_VALUE, 0, false);
+    signedIndexReader = build(random, signedIndexDir);
+    unsignedIndexReader = build(random, unsignedIndexDir);
   }
   
   protected void tearDown() throws Exception {
@@ -108,14 +106,14 @@
   private IndexReader build(Random random, TestIndex index) throws IOException {
     /* build an index */
     RandomIndexWriter writer = new RandomIndexWriter(random, index.index, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
     .setOpenMode(OpenMode.CREATE));
     
     for (int d = minId; d <= maxId; d++) {
       Document doc = new Document();
       doc.add(new Field("id", pad(d), Field.Store.YES,
           Field.Index.NOT_ANALYZED));
-      int r = index.allowNegativeRandomInts ? rand.nextInt() : rand
+      int r = index.allowNegativeRandomInts ? random.nextInt() : random
           .nextInt(Integer.MAX_VALUE);
       if (index.maxR < r) {
         index.maxR = r;
Index: lucene/src/test/org/apache/lucene/search/TestBoolean2.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBoolean2.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBoolean2.java	(working copy)
@@ -40,7 +40,6 @@
   private IndexSearcher searcher;
   private IndexSearcher bigSearcher;
   private IndexReader reader;
-  private Random rnd;
   private static int NUM_EXTRA_DOCS = 6000;
 
   public static final String field = "field";
@@ -51,9 +50,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    rnd = newRandom();
-    directory = newDirectory(rnd);
-    RandomIndexWriter writer= new RandomIndexWriter(rnd, directory);
+    directory = newDirectory();
+    RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     for (int i = 0; i < docFields.length; i++) {
       Document doc = new Document();
       doc.add(new Field(field, docFields[i], Field.Store.NO, Field.Index.ANALYZED));
@@ -70,14 +68,14 @@
     int docCount = 0;
     do {
       final Directory copy = new MockDirectoryWrapper(new RAMDirectory(dir2));
-      RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
+      RandomIndexWriter w = new RandomIndexWriter(random, dir2);
       w.addIndexes(new Directory[] {copy});
       docCount = w.maxDoc();
       w.close();
       mulFactor *= 2;
     } while(docCount < 3000);
 
-    RandomIndexWriter w = new RandomIndexWriter(rnd, dir2);
+    RandomIndexWriter w = new RandomIndexWriter(random, dir2);
     Document doc = new Document();
     doc.add(new Field("field2", "xxx", Field.Store.NO, Field.Index.ANALYZED));
     for(int i=0;i<NUM_EXTRA_DOCS/2;i++) {
@@ -211,8 +209,8 @@
       // increase number of iterations for more complete testing
       int num = 50 * RANDOM_MULTIPLIER;
       for (int i=0; i<num; i++) {
-        int level = rnd.nextInt(3);
-        q1 = randBoolQuery(new Random(rnd.nextLong()), rnd.nextBoolean(), level, field, vals, null);
+        int level = random.nextInt(3);
+        q1 = randBoolQuery(new Random(random.nextLong()), random.nextBoolean(), level, field, vals, null);
         
         // Can't sort by relevance since floating point numbers may not quite
         // match up.
Index: lucene/src/test/org/apache/lucene/search/TestExplanations.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestExplanations.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestExplanations.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.queryParser.QueryParser;
 import org.apache.lucene.queryParser.ParseException;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -52,7 +50,6 @@
   protected IndexSearcher searcher;
   protected IndexReader reader;
   protected Directory directory;
-  protected Random random;
   
   public static final String KEY = "KEY";
   public static final String FIELD = "field";
@@ -70,8 +67,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     for (int i = 0; i < docFields.length; i++) {
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/function/FunctionTestSetup.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/function/FunctionTestSetup.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/function/FunctionTestSetup.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCaseJ4;
 import org.apache.lucene.util._TestUtil;
-import java.util.Random;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Ignore;
@@ -95,14 +94,13 @@
   public void setUp() throws Exception {
     super.setUp();
     // prepare a small index with just a few documents.  
-    Random r = newRandom();
-    dir = newDirectory(r);
+    dir = newDirectory();
     anlzr = new MockAnalyzer();
-    IndexWriterConfig iwc = newIndexWriterConfig(r, TEST_VERSION_CURRENT, anlzr);
+    IndexWriterConfig iwc = newIndexWriterConfig( TEST_VERSION_CURRENT, anlzr);
     if (doMultiSegment) {
-      iwc.setMaxBufferedDocs(_TestUtil.nextInt(r, 2, 7));
+      iwc.setMaxBufferedDocs(_TestUtil.nextInt(random, 2, 7));
     }
-    RandomIndexWriter iw = new RandomIndexWriter(r, dir, iwc);
+    RandomIndexWriter iw = new RandomIndexWriter(random, dir, iwc);
     // add docs not exactly in natural ID order, to verify we do check the order of docs by scores
     int remaining = N_DOCS;
     boolean done[] = new boolean[N_DOCS];
Index: lucene/src/test/org/apache/lucene/search/function/TestValueSource.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/function/TestValueSource.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/function/TestValueSource.java	(working copy)
@@ -20,7 +20,6 @@
 import org.apache.lucene.util.*;
 import org.apache.lucene.store.*;
 import org.apache.lucene.search.*;
-import org.apache.lucene.search.function.*;
 import org.apache.lucene.analysis.*;
 import org.apache.lucene.index.*;
 import org.apache.lucene.document.*;
@@ -28,7 +27,7 @@
 public class TestValueSource extends LuceneTestCase {
 
   public void testMultiValueSource() throws Exception {
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
     IndexWriter w = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
     Document doc = new Document();
     Field f = new Field("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
Index: lucene/src/test/org/apache/lucene/search/TestThreadSafe.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestThreadSafe.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestThreadSafe.java	(working copy)
@@ -30,7 +30,6 @@
 import java.io.IOException;
 
 public class TestThreadSafe extends LuceneTestCase {
-  Random r;
   Directory dir1;
 
   IndexReader ir1;
@@ -107,11 +106,11 @@
         TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10));
     for (int j=0; j<nDocs; j++) {
       Document d = new Document();
-      int nFields = r.nextInt(maxFields);
+      int nFields = random.nextInt(maxFields);
       for (int i=0; i<nFields; i++) {
-        int flen = r.nextInt(maxFieldLen);
+        int flen = random.nextInt(maxFieldLen);
         StringBuilder sb = new StringBuilder("^ ");
-        while (sb.length() < flen) sb.append(' ').append(words[r.nextInt(words.length)]);
+        while (sb.length() < flen) sb.append(' ').append(words[random.nextInt(words.length)]);
         sb.append(" $");
         Field.Store store = Field.Store.YES;  // make random later
         Field.Index index = Field.Index.ANALYZED;  // make random later
@@ -126,7 +125,7 @@
   void doTest(int iter, int nThreads) throws Exception {
     Thr[] tarr = new Thr[nThreads];
     for (int i=0; i<nThreads; i++) {
-      tarr[i] = new Thr(iter, new Random(r.nextLong()));
+      tarr[i] = new Thr(iter, new Random(random.nextLong()));
       tarr[i].start();
     }
     for (int i=0; i<nThreads; i++) {
@@ -138,8 +137,7 @@
   }
 
   public void testLazyLoadThreadSafety() throws Exception{
-    r = newRandom();
-    dir1 = newDirectory(r);
+    dir1 = newDirectory();
     // test w/ field sizes bigger than the buffer of an index input
     buildDir(dir1, 15, 5, 2000);
 
Index: lucene/src/test/org/apache/lucene/search/TestFieldCache.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFieldCache.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFieldCache.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.BytesRef;
 import java.io.IOException;
-import java.util.Random;
 import java.io.ByteArrayOutputStream;
 import java.io.PrintStream;
 
@@ -36,7 +35,6 @@
   protected IndexReader reader;
   private static final int NUM_DOCS = 1000 * RANDOM_MULTIPLIER;
   private String[] unicodeStrings;
-  private Random random;
   private Directory directory;
   
   public TestFieldCache(String s) {
@@ -46,8 +44,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer= new RandomIndexWriter(random, directory);
     long theLong = Long.MAX_VALUE;
     double theDouble = Double.MAX_VALUE;
@@ -208,8 +205,8 @@
   }
 
   public void testEmptyIndex() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer= new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(500));
+    Directory dir = newDirectory();
+    IndexWriter writer= new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(500));
     IndexReader r = writer.getReader();
     FieldCache.DocTerms terms = FieldCache.DEFAULT.getTerms(r, "foobar");
     FieldCache.DocTermsIndex termsIndex = FieldCache.DEFAULT.getTermsIndex(r, "foobar");
Index: lucene/src/test/org/apache/lucene/search/TestScorerPerf.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestScorerPerf.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestScorerPerf.java	(working copy)
@@ -3,7 +3,6 @@
 import org.apache.lucene.util.DocIdBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 
-import java.util.Random;
 import java.util.BitSet;
 import java.io.IOException;
 
@@ -34,7 +33,6 @@
  */
 
 public class TestScorerPerf extends LuceneTestCase {
-  Random r = newRandom();
   boolean validate = true;  // set to false when doing performance testing
 
   BitSet[] sets;
@@ -45,8 +43,8 @@
   public void createDummySearcher() throws Exception {
       // Create a dummy index with nothing in it.
     // This could possibly fail if Lucene starts checking for docid ranges...
-    d = newDirectory(r);
-    IndexWriter iw = new IndexWriter(d, newIndexWriterConfig(r, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    d = newDirectory();
+    IndexWriter iw = new IndexWriter(d, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     iw.addDocument(new Document());
     iw.close();
     s = new IndexSearcher(d, true);
@@ -61,11 +59,11 @@
       terms[i] = new Term("f",Character.toString((char)('A'+i)));
     }
 
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(r, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     for (int i=0; i<nDocs; i++) {
       Document d = new Document();
       for (int j=0; j<nTerms; j++) {
-        if (r.nextInt(freq[j]) == 0) {
+        if (random.nextInt(freq[j]) == 0) {
           d.add(new Field("f", terms[j].text(), Field.Store.NO, Field.Index.NOT_ANALYZED));
           //System.out.println(d);
         }
@@ -80,7 +78,7 @@
   public BitSet randBitSet(int sz, int numBitsToSet) {
     BitSet set = new BitSet(sz);
     for (int i=0; i<numBitsToSet; i++) {
-      set.set(r.nextInt(sz));
+      set.set(random.nextInt(sz));
     }
     return set;
   }
@@ -88,7 +86,7 @@
   public BitSet[] randBitSets(int numSets, int setSize) {
     BitSet[] sets = new BitSet[numSets];
     for (int i=0; i<sets.length; i++) {
-      sets[i] = randBitSet(setSize, r.nextInt(setSize));
+      sets[i] = randBitSet(setSize, random.nextInt(setSize));
     }
     return sets;
   }
@@ -140,7 +138,7 @@
 
 
   BitSet addClause(BooleanQuery bq, BitSet result) {
-    final BitSet rnd = sets[r.nextInt(sets.length)];
+    final BitSet rnd = sets[random.nextInt(sets.length)];
     Query q = new ConstantScoreQuery(new Filter() {
       @Override
       public DocIdSet getDocIdSet(IndexReader reader) {
@@ -160,7 +158,7 @@
     int ret=0;
 
     for (int i=0; i<iter; i++) {
-      int nClauses = r.nextInt(maxClauses-1)+2; // min 2 clauses
+      int nClauses = random.nextInt(maxClauses-1)+2; // min 2 clauses
       BooleanQuery bq = new BooleanQuery();
       BitSet result=null;
       for (int j=0; j<nClauses; j++) {
@@ -184,13 +182,13 @@
     long nMatches=0;
 
     for (int i=0; i<iter; i++) {
-      int oClauses = r.nextInt(maxOuterClauses-1)+2;
+      int oClauses = random.nextInt(maxOuterClauses-1)+2;
       BooleanQuery oq = new BooleanQuery();
       BitSet result=null;
 
       for (int o=0; o<oClauses; o++) {
 
-      int nClauses = r.nextInt(maxClauses-1)+2; // min 2 clauses
+      int nClauses = random.nextInt(maxClauses-1)+2; // min 2 clauses
       BooleanQuery bq = new BooleanQuery();
       for (int j=0; j<nClauses; j++) {
         result = addClause(bq,result);
@@ -221,13 +219,13 @@
 
     long nMatches=0;
     for (int i=0; i<iter; i++) {
-      int nClauses = r.nextInt(maxClauses-1)+2; // min 2 clauses
+      int nClauses = random.nextInt(maxClauses-1)+2; // min 2 clauses
       BooleanQuery bq = new BooleanQuery();
       BitSet termflag = new BitSet(termsInIndex);
       for (int j=0; j<nClauses; j++) {
         int tnum;
         // don't pick same clause twice
-        tnum = r.nextInt(termsInIndex);
+        tnum = random.nextInt(termsInIndex);
         if (termflag.get(tnum)) tnum=termflag.nextClearBit(tnum);
         if (tnum<0 || tnum>=termsInIndex) tnum=termflag.nextClearBit(0);
         termflag.set(tnum);
@@ -255,17 +253,17 @@
     int ret=0;
     long nMatches=0;
     for (int i=0; i<iter; i++) {
-      int oClauses = r.nextInt(maxOuterClauses-1)+2;
+      int oClauses = random.nextInt(maxOuterClauses-1)+2;
       BooleanQuery oq = new BooleanQuery();
       for (int o=0; o<oClauses; o++) {
 
-      int nClauses = r.nextInt(maxClauses-1)+2; // min 2 clauses
+      int nClauses = random.nextInt(maxClauses-1)+2; // min 2 clauses
       BooleanQuery bq = new BooleanQuery();
       BitSet termflag = new BitSet(termsInIndex);
       for (int j=0; j<nClauses; j++) {
         int tnum;
         // don't pick same clause twice
-        tnum = r.nextInt(termsInIndex);
+        tnum = random.nextInt(termsInIndex);
         if (termflag.get(tnum)) tnum=termflag.nextClearBit(tnum);
         if (tnum<0 || tnum>=25) tnum=termflag.nextClearBit(0);
         termflag.set(tnum);
@@ -295,10 +293,10 @@
     int ret=0;
 
     for (int i=0; i<iter; i++) {
-      int nClauses = r.nextInt(maxClauses-1)+2; // min 2 clauses
+      int nClauses = random.nextInt(maxClauses-1)+2; // min 2 clauses
       PhraseQuery q = new PhraseQuery();
       for (int j=0; j<nClauses; j++) {
-        int tnum = r.nextInt(termsInIndex);
+        int tnum = random.nextInt(termsInIndex);
         q.add(new Term("f",Character.toString((char)(tnum+'A'))), j);
       }
       q.setSlop(termsInIndex);  // this could be random too
Index: lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestRegexpRandom2.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 import java.util.Collections;
 import java.util.List;
 import java.util.ArrayList;
@@ -49,13 +48,11 @@
   private IndexSearcher searcher;
   private IndexReader reader;
   private Directory dir;
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
     
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFuzzyQuery.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.util.List;
 import java.util.Arrays;
-import java.util.Random;
 import java.io.IOException;
 
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -39,8 +38,7 @@
 public class TestFuzzyQuery extends LuceneTestCase {
 
   public void testFuzziness() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     addDoc("aaaaa", writer);
     addDoc("aaaab", writer);
@@ -193,8 +191,7 @@
   }
 
   public void testFuzzinessLong() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     addDoc("aaaaaaa", writer);
     addDoc("segment", writer);
@@ -284,8 +281,7 @@
   }
   
   public void testTokenLengthOpt() throws IOException {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     addDoc("12345678911", writer);
     addDoc("segment", writer);
@@ -322,8 +318,7 @@
   
   /** Test the TopTermsBoostOnlyBooleanQueryRewrite rewrite method. */
   public void testBoostOnlyRewrite() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     addDoc("Lucene", writer);
     addDoc("Lucene", writer);
@@ -349,8 +344,7 @@
   public void testGiga() throws Exception {
 
     MockAnalyzer analyzer = new MockAnalyzer();
-    Random random = newRandom();
-    Directory index = newDirectory(random);
+    Directory index = newDirectory();
     RandomIndexWriter w = new RandomIndexWriter(random, index);
 
     addDoc("Lucene in Action", w);
Index: lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -45,8 +44,7 @@
   
   public void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     Document doc = new Document();
     doc.add(new Field(FN,
Index: lucene/src/test/org/apache/lucene/search/TestMultiThreadTermVectors.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiThreadTermVectors.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiThreadTermVectors.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.util.English;
 
 import java.io.IOException;
-import java.util.Random;
 
 public class TestMultiThreadTermVectors extends LuceneTestCase {
   private Directory directory;
@@ -42,9 +41,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     //writer.setUseCompoundFile(false);
     //writer.infoStream = System.out;
     for (int i = 0; i < numDocs; i++) {
Index: lucene/src/test/org/apache/lucene/search/TestDateFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestDateFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestDateFilter.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.index.Term;
 
 import java.io.IOException;
-import java.util.Random;
 
 /**
  * DateFilter JUnit tests.
@@ -45,8 +44,7 @@
    */
   public void testBefore() throws IOException {
     // create an index
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     
     long now = System.currentTimeMillis();
@@ -112,8 +110,7 @@
    */
   public void testAfter() throws IOException {
     // create an index
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     
     long now = System.currentTimeMillis();
Index: lucene/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMatchAllDocsQuery.java	(working copy)
@@ -17,7 +17,6 @@
 package org.apache.lucene.search;
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -39,9 +38,8 @@
   private Analyzer analyzer = new MockAnalyzer();
   
   public void testQuery() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(2));
     addDoc("one", iw, 1f);
     addDoc("two", iw, 20f);
Index: lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -32,8 +31,7 @@
 public class TestCachingSpanFilter extends LuceneTestCase {
 
   public void testEnforceDeletions() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
Index: lucene/src/test/org/apache/lucene/search/TestFilteredSearch.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFilteredSearch.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFilteredSearch.java	(working copy)
@@ -18,7 +18,6 @@
 package org.apache.lucene.search;
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -47,18 +46,17 @@
   
   public void testFilteredSearch() throws CorruptIndexException, LockObtainFailedException, IOException {
     boolean enforceSingleSegment = true;
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     int[] filterBits = {1, 36};
     SimpleDocIdSetFilter filter = new SimpleDocIdSetFilter(filterBits);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     searchFiltered(writer, directory, filter, enforceSingleSegment);
     // run the test on more than one segment
     enforceSingleSegment = false;
     // reset - it is stateful
     filter.reset();
     writer.close();
-    writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10));
+    writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10));
     // we index 60 docs - this will create 6 segments
     searchFiltered(writer, directory, filter, enforceSingleSegment);
     writer.close();
Index: lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestDisjunctionMaxQuery.java	(working copy)
@@ -28,7 +28,6 @@
 import org.apache.lucene.store.Directory;
 
 import java.text.DecimalFormat;
-import java.util.Random;
 import java.io.IOException;
 
 /**
@@ -79,10 +78,9 @@
   protected void setUp() throws Exception {
     super.setUp();
     
-    Random random = newRandom();
-    index = newDirectory(random);
+    index = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, index,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
             .setSimilarity(sim));
     
     // hed is the most important field, dek is secondary
Index: lucene/src/test/org/apache/lucene/search/TestSimilarity.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSimilarity.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSimilarity.java	(working copy)
@@ -20,7 +20,6 @@
 import org.apache.lucene.util.LuceneTestCase;
 import java.io.IOException;
 import java.util.Collection;
-import java.util.Random;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -63,10 +62,9 @@
   }
 
   public void testSimilarity() throws Exception {
-    Random random = newRandom();
-    Directory store = newDirectory(random);
+    Directory store = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, store, 
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setSimilarity(new SimpleSimilarity()));
     
     Document d1 = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestFieldCacheRangeFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFieldCacheRangeFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFieldCacheRangeFilter.java	(working copy)
@@ -515,8 +515,8 @@
   
   // test using a sparse index (with deleted docs).
   public void testSparseIndex() throws IOException {
-    Directory dir = newDirectory(rand);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     for (int d = -20; d <= 20; d++) {
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestRegexpRandom.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestRegexpRandom.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestRegexpRandom.java	(working copy)
@@ -21,7 +21,6 @@
 import java.text.DecimalFormatSymbols;
 import java.text.NumberFormat;
 import java.util.Locale;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -40,13 +39,11 @@
   private Searcher searcher;
   private IndexReader reader;
   private Directory dir;
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -36,8 +34,7 @@
   }
 
   public void testOutOfOrderCollection() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     for (int i = 0; i < 10; i++) {
       writer.addDocument(new Document());
Index: lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestSpanQueryFilter.java	(working copy)
@@ -17,7 +17,6 @@
  */
 
 import java.util.List;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -38,8 +37,7 @@
   }
 
   public void testFilterWorks() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     for (int i = 0; i < 500; i++) {
       Document document = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPrefixRandom.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -41,13 +40,11 @@
   private IndexSearcher searcher;
   private IndexReader reader;
   private Directory dir;
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir, new MockAnalyzer(MockTokenizer.KEYWORD, false));
     
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java	(working copy)
@@ -48,10 +48,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random rand = newRandom();
-    index = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, index);
-    RandomGen random = new RandomGen(rand);
+    index = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, index);
+    RandomGen random = new RandomGen(this.random);
     for (int i = 0; i < INDEX_SIZE; ++i) { // don't decrease; if to low the
                                            // problem doesn't show up
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPrefixInBooleanQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -47,8 +45,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
 
     for (int i = 0; i < 5137; ++i) {
Index: lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery32.java	(working copy)
@@ -25,7 +25,6 @@
 import org.apache.lucene.document.NumericField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
@@ -281,8 +280,8 @@
   
   @Test
   public void testInfiniteValues() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new NumericField("float").setFloatValue(Float.NEGATIVE_INFINITY));
     doc.add(new NumericField("int").setIntValue(Integer.MIN_VALUE));
@@ -330,13 +329,12 @@
   }
   
   private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="field"+precisionStep;
     int termCountT=0,termCountC=0;
     int num = 10 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
-      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
+      int lower=(int)(random.nextDouble()*noDocs*distance)+startOffset;
+      int upper=(int)(random.nextDouble()*noDocs*distance)+startOffset;
       if (lower>upper) {
         int a=lower; lower=upper; upper=a;
       }
@@ -409,13 +407,12 @@
   }
   
   private void testRangeSplit(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="ascfield"+precisionStep;
     // 10 random tests
     int  num = 10 * RANDOM_MULTIPLIER;
     for (int  i =0;  i< num; i++) {
-      int lower=(int)(rnd.nextDouble()*noDocs - noDocs/2);
-      int upper=(int)(rnd.nextDouble()*noDocs - noDocs/2);
+      int lower=(int)(random.nextDouble()*noDocs - noDocs/2);
+      int upper=(int)(random.nextDouble()*noDocs - noDocs/2);
       if (lower>upper) {
         int a=lower; lower=upper; upper=a;
       }
@@ -485,14 +482,13 @@
   }
   
   private void testSorting(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="field"+precisionStep;
     // 10 random tests, the index order is ascending,
     // so using a reverse sort field should retun descending documents
     int num = 10 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      int lower=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
-      int upper=(int)(rnd.nextDouble()*noDocs*distance)+startOffset;
+      int lower=(int)(random.nextDouble()*noDocs*distance)+startOffset;
+      int upper=(int)(random.nextDouble()*noDocs*distance)+startOffset;
       if (lower>upper) {
         int a=lower; lower=upper; upper=a;
       }
Index: lucene/src/test/org/apache/lucene/search/TestDocBoost.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestDocBoost.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestDocBoost.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.document.*;
@@ -38,8 +37,7 @@
   }
 
   public void testDocBoost() throws Exception {
-    Random random = newRandom();
-    Directory store = newDirectory(random);
+    Directory store = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, store);
 
     Fieldable f1 = new Field("field", "word", Field.Store.YES, Field.Index.ANALYZED);
Index: lucene/src/test/org/apache/lucene/search/TestElevationComparator.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestElevationComparator.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestElevationComparator.java	(working copy)
@@ -28,7 +28,6 @@
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.Random;
 
 public class TestElevationComparator extends LuceneTestCase {
 
@@ -36,9 +35,8 @@
 
   //@Test
   public void testSorting() throws Throwable {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    Directory directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);
     writer.addDocument(adoc(new String[] {"id", "a", "title", "ipod", "str_s", "a"}));
     writer.addDocument(adoc(new String[] {"id", "b", "title", "ipod ipod", "str_s", "b"}));
Index: lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestNumericRangeQuery64.java	(working copy)
@@ -25,7 +25,6 @@
 import org.apache.lucene.document.NumericField;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
@@ -299,8 +298,8 @@
   
   @Test
   public void testInfiniteValues() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new NumericField("double").setDoubleValue(Double.NEGATIVE_INFINITY));
@@ -349,13 +348,12 @@
   }
   
   private void testRandomTrieAndClassicRangeQuery(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="field"+precisionStep;
     int termCountT=0,termCountC=0;
     int num = 10 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
-      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
+      long lower=(long)(random.nextDouble()*noDocs*distance)+startOffset;
+      long upper=(long)(random.nextDouble()*noDocs*distance)+startOffset;
       if (lower>upper) {
         long a=lower; lower=upper; upper=a;
       }
@@ -433,13 +431,12 @@
   }
   
   private void testRangeSplit(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="ascfield"+precisionStep;
     // 10 random tests
     int num = 10 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      long lower=(long)(rnd.nextDouble()*noDocs - noDocs/2);
-      long upper=(long)(rnd.nextDouble()*noDocs - noDocs/2);
+      long lower=(long)(random.nextDouble()*noDocs - noDocs/2);
+      long upper=(long)(random.nextDouble()*noDocs - noDocs/2);
       if (lower>upper) {
         long a=lower; lower=upper; upper=a;
       }
@@ -519,14 +516,13 @@
   }
   
   private void testSorting(int precisionStep) throws Exception {
-    final Random rnd=newRandom();
     String field="field"+precisionStep;
     // 10 random tests, the index order is ascending,
     // so using a reverse sort field should retun descending documents
     int num = 10 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      long lower=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
-      long upper=(long)(rnd.nextDouble()*noDocs*distance)+startOffset;
+      long lower=(long)(random.nextDouble()*noDocs*distance)+startOffset;
+      long upper=(long)(random.nextDouble()*noDocs*distance)+startOffset;
       if (lower>upper) {
         long a=lower; lower=upper; upper=a;
       }
Index: lucene/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiSearcherRanking.java	(working copy)
@@ -26,7 +26,6 @@
 import org.apache.lucene.queryParser.QueryParser;
 import org.apache.lucene.store.Directory;
 import java.io.IOException;
-import java.util.Random;
 
 /**
  * Tests {@link MultiSearcher} ranking, i.e. makes sure this bug is fixed:
@@ -110,14 +109,13 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
     // create MultiSearcher from two seperate searchers
-    d1 = newDirectory(random);
-    IndexWriter iw1 = new IndexWriter(d1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    d1 = newDirectory();
+    IndexWriter iw1 = new IndexWriter(d1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     addCollection1(iw1);
     iw1.close();
-    d2 = newDirectory(random);
-    IndexWriter iw2 = new IndexWriter(d2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    d2 = newDirectory();
+    IndexWriter iw2 = new IndexWriter(d2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     addCollection2(iw2);
     iw2.close();
 
@@ -127,8 +125,8 @@
     multiSearcher = new MultiSearcher(s);
 
     // create IndexSearcher which contains all documents
-    d = newDirectory(random);
-    IndexWriter iw = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    d = newDirectory();
+    IndexWriter iw = new IndexWriter(d, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     addCollection1(iw);
     addCollection2(iw);
     iw.close();
Index: lucene/src/test/org/apache/lucene/search/TestPrefixQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestPrefixQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestPrefixQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.index.IndexReader;
@@ -33,8 +31,7 @@
  */
 public class TestPrefixQuery extends LuceneTestCase {
   public void testPrefixQuery() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
 
     String[] categories = new String[] {"/Computers",
                                         "/Computers/Mac",
Index: lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java	(working copy)
@@ -31,7 +31,6 @@
 
 import java.io.IOException;
 import java.util.LinkedList;
-import java.util.Random;
 
 /**
  * This class tests the MultiPhraseQuery class.
@@ -44,8 +43,7 @@
   }
   
   public void testPhrasePrefix() throws IOException {
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     add("blueberry pie", writer);
     add("blueberry strudel", writer);
@@ -138,8 +136,7 @@
 
   // LUCENE-2580
   public void testTall() throws IOException {
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     add("blueberry chocolate pie", writer);
     add("blueberry chocolate tart", writer);
@@ -168,8 +165,7 @@
     // In order to cause the bug, the outer query must have more than one term
     // and all terms required.
     // The contained PhraseMultiQuery must contain exactly one term array.
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     add("blueberry pie", writer);
     add("blueberry chewing gum", writer);
@@ -201,8 +197,7 @@
   }
   
   public void testPhrasePrefixWithBooleanQuery() throws IOException {
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     add("This is a test", "object", writer);
     add("a note", "note", writer);
@@ -230,8 +225,7 @@
   }
   
   public void testNoDocs() throws Exception {
-    Random random = newRandom();
-    Directory indexStore = newDirectory(random);
+    Directory indexStore = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);
     add("a note", "note", writer);
     
Index: lucene/src/test/org/apache/lucene/search/TestBooleanPrefixQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestBooleanPrefixQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestBooleanPrefixQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 import junit.framework.Test;
 import junit.framework.TestSuite;
@@ -67,8 +65,7 @@
   }
 
   public void testMethod() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
 
     String[] categories = new String[]{"food",
                                        "foodanddrink",
Index: lucene/src/test/org/apache/lucene/search/TestFilteredQuery.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFilteredQuery.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFilteredQuery.java	(working copy)
@@ -27,7 +27,6 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.DocIdBitSet;
 import java.util.BitSet;
-import java.util.Random;
 
 /**
  * FilteredQuery JUnit tests.
@@ -48,8 +47,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter (random, directory);
 
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java	(working copy)
@@ -27,7 +27,6 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Random;
 
 /**
  * A basic unit test for FieldCacheTermsFilter
@@ -37,8 +36,7 @@
 public class TestFieldCacheTermsFilter extends LuceneTestCase {
   public void testMissingTerms() throws Exception {
     String fieldName = "field1";
-    Random random = newRandom();
-    Directory rd = newDirectory(random);
+    Directory rd = newDirectory();
     RandomIndexWriter w = new RandomIndexWriter(random, rd);
     for (int i = 0; i < 100; i++) {
       Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java
===================================================================
--- lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/search/TestTermRangeFilter.java	(working copy)
@@ -398,8 +398,8 @@
   public void testFarsi() throws Exception {
     
     /* build an index */
-    Directory farsiIndex = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, farsiIndex);
+    Directory farsiIndex = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, farsiIndex);
     Document doc = new Document();
     doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
         Field.Index.NOT_ANALYZED));
@@ -438,8 +438,8 @@
   public void testDanish() throws Exception {
     
     /* build an index */
-    Directory danishIndex = newDirectory(rand);
-    RandomIndexWriter writer = new RandomIndexWriter(rand, danishIndex);
+    Directory danishIndex = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random, danishIndex);
     // Danish collation orders the words below in the given order
     // (example taken from TestSort.testInternationalSort() ).
     String[] words = {"H\u00D8T", "H\u00C5T", "MAND"};
Index: lucene/src/test/org/apache/lucene/TestSearch.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestSearch.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/TestSearch.java	(working copy)
@@ -51,7 +51,6 @@
      *        single-file formats, even if the results are wrong.
      */
     public void testSearch() throws Exception {
-      Random random = newRandom();
       StringWriter sw = new StringWriter();
       PrintWriter pw = new PrintWriter(sw, true);
       doTestSearch(random, pw, false);
@@ -73,9 +72,9 @@
 
     private void doTestSearch(Random random, PrintWriter out, boolean useCompoundFile)
     throws Exception {
-      Directory directory = newDirectory(random);
+      Directory directory = newDirectory();
       Analyzer analyzer = new MockAnalyzer();
-      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer);
+      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
       LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
       lmp.setUseCompoundFile(useCompoundFile);
       lmp.setUseCompoundDocStore(useCompoundFile);
Index: lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java	(working copy)
@@ -22,7 +22,6 @@
 import org.apache.lucene.util.LuceneTestCaseJ4;
 import org.apache.lucene.util.ThreadInterruptedException;
 import org.apache.lucene.util._TestUtil;
-import org.junit.Before;
 import org.junit.Test;
 
 //
@@ -31,18 +30,10 @@
 //
 
 public class TestSnapshotDeletionPolicy extends LuceneTestCaseJ4 {
-  protected Random random;
   public static final String INDEX_PATH = "test.snapshots";
-
-  @Before
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
   
   protected IndexWriterConfig getConfig(Random random, IndexDeletionPolicy dp) {
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer());
+    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer());
     if (dp != null) {
       conf.setIndexDeletionPolicy(dp);
     }
@@ -101,7 +92,7 @@
       _TestUtil.rmDir(dir);
     }
 
-    Directory dir2 = newDirectory(random);
+    Directory dir2 = newDirectory();
     runTest(random, dir2);
     dir2.close();
   }
@@ -111,7 +102,7 @@
     final long stopTime = System.currentTimeMillis() + 1000;
 
     SnapshotDeletionPolicy dp = getDeletionPolicy();
-    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(dp)
         .setMaxBufferedDocs(2));
     writer.commit();
@@ -239,7 +230,7 @@
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     
     // Create 3 snapshots: snapshot0, snapshot1, snapshot2
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     prepareIndexAndSnapshots(sdp, writer, numSnapshots, "snapshot");
     writer.close();
@@ -269,7 +260,7 @@
 
   @Test
   public void testMultiThreadedSnapshotting() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     final SnapshotDeletionPolicy sdp = getDeletionPolicy();
     final IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
 
@@ -314,7 +305,7 @@
   @Test
   public void testRollbackToOldSnapshot() throws Exception {
     int numSnapshots = 2;
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     prepareIndexAndSnapshots(sdp, writer, numSnapshots, "snapshot");
@@ -336,7 +327,7 @@
 
   @Test
   public void testReleaseSnapshot() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     prepareIndexAndSnapshots(sdp, writer, 1, "snapshot");
@@ -368,7 +359,7 @@
     // Tests the ability to construct a SDP from existing snapshots, and
     // asserts that those snapshots/commit points are protected.
     int numSnapshots = 3;
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     prepareIndexAndSnapshots(sdp, writer, numSnapshots, "snapshot");
@@ -386,7 +377,7 @@
 
   @Test
   public void testSnapshotLastCommitTwice() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     writer.addDocument(new Document());
@@ -415,7 +406,7 @@
   public void testMissingCommits() throws Exception {
     // Tests the behavior of SDP when commits that are given at ctor are missing
     // on onInit().
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, sdp));
     writer.addDocument(new Document());
Index: lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java	(working copy)
@@ -119,13 +119,13 @@
   private static final int NUM_DOCS = 10;
 
   private IndexWriterConfig getConfig(Random random) {
-    return newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
+    return newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
   }
 
   private void populateDirs(Random random, Directory[] dirs, boolean multipleCommits)
       throws IOException {
     for (int i = 0; i < dirs.length; i++) {
-      dirs[i] = newDirectory(random);
+      dirs[i] = newDirectory();
       populateDocs(random, dirs[i], multipleCommits);
       verifyPayloadExists(dirs[i], "p", new BytesRef("p1"), NUM_DOCS);
       verifyPayloadExists(dirs[i], "p", new BytesRef("p2"), NUM_DOCS);
@@ -178,7 +178,7 @@
     Directory[] dirs = new Directory[2];
     populateDirs(random, dirs, multipleCommits);
 
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     if (!addToEmptyIndex) {
       populateDocs(random, dir, multipleCommits);
       verifyPayloadExists(dir, "p", new BytesRef("p1"), NUM_DOCS);
@@ -218,7 +218,6 @@
 
   @Test
   public void testAddIndexes() throws Exception {
-    Random random = newRandom();
     // addIndexes - single commit in each
     doTest(random, true, 0, false);
 
@@ -228,7 +227,6 @@
 
   @Test
   public void testAddIndexesIntoExisting() throws Exception {
-    Random random = newRandom();
     // addIndexes - single commit in each
     doTest(random, false, NUM_DOCS, false);
 
@@ -238,8 +236,7 @@
 
   @Test
   public void testRegularMerges() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     populateDocs(random, dir, true);
     verifyPayloadExists(dir, "p", new BytesRef("p1"), NUM_DOCS);
     verifyPayloadExists(dir, "p", new BytesRef("p2"), NUM_DOCS);
Index: lucene/src/test/org/apache/lucene/index/TestDoc.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestDoc.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestDoc.java	(working copy)
@@ -110,10 +110,9 @@
     public void testIndexAndMerge() throws Exception {
       StringWriter sw = new StringWriter();
       PrintWriter out = new PrintWriter(sw, true);
-      Random random = newRandom();
       
       Directory directory = FSDirectory.open(indexDir);
-      IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
                                            .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(-1));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -144,7 +143,7 @@
       out = new PrintWriter(sw, true);
 
       directory = FSDirectory.open(indexDir);
-      writer = new IndexWriter(directory, newIndexWriterConfig(random,
+      writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
                                .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(-1));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
Index: lucene/src/test/org/apache/lucene/index/TestParallelTermEnum.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestParallelTermEnum.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -39,9 +38,8 @@
     protected void setUp() throws Exception {
         super.setUp();
         Document doc;
-        Random random = newRandom();
-        rd1 = newDirectory(random);
-        IndexWriter iw1 = new IndexWriter(rd1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        rd1 = newDirectory();
+        IndexWriter iw1 = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
         doc = new Document();
         doc.add(new Field("field1", "the quick brown fox jumps", Store.YES,
@@ -52,8 +50,8 @@
         iw1.addDocument(doc);
 
         iw1.close();
-        rd2 = newDirectory(random);
-        IndexWriter iw2 = new IndexWriter(rd2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        rd2 = newDirectory();
+        IndexWriter iw2 = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
         doc = new Document();
         doc.add(new Field("field0", "", Store.NO, Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.index.SegmentReader.Norm;
 import org.apache.lucene.search.Similarity;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -35,16 +33,9 @@
  * implemented properly
  */
 public class TestIndexReaderClone extends LuceneTestCase {
-  Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   public void testCloneReadOnlySegmentReader() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader reader = IndexReader.open(dir1, false);
@@ -63,7 +54,7 @@
   // open non-readOnly reader1, clone to non-readOnly
   // reader2, make sure we can change reader2
   public void testCloneNoChangesStillReadOnly() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader r1 = IndexReader.open(dir1, false);
@@ -79,7 +70,7 @@
   // open non-readOnly reader1, clone to non-readOnly
   // reader2, make sure we can change reader1
   public void testCloneWriteToOrig() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader r1 = IndexReader.open(dir1, false);
@@ -95,7 +86,7 @@
   // open non-readOnly reader1, clone to non-readOnly
   // reader2, make sure we can change reader2
   public void testCloneWriteToClone() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader r1 = IndexReader.open(dir1, false);
@@ -118,7 +109,7 @@
   // SegmentReader, add docs, reopen to multireader, then do
   // delete
   public void testReopenSegmentReaderToMultiReader() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader reader1 = IndexReader.open(dir1, false);
@@ -136,7 +127,7 @@
 
   // open non-readOnly reader1, clone to readOnly reader2
   public void testCloneWriteableToReadOnly() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader = IndexReader.open(dir1, false);
@@ -158,7 +149,7 @@
 
   // open non-readOnly reader1, reopen to readOnly reader2
   public void testReopenWriteableToReadOnly() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader = IndexReader.open(dir1, false);
@@ -179,7 +170,7 @@
 
   // open readOnly reader1, clone to non-readOnly reader2
   public void testCloneReadOnlyToWriteable() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader1 = IndexReader.open(dir1, true);
@@ -202,11 +193,11 @@
   // open non-readOnly reader1 on multi-segment index, then
   // optimize the index, then clone to readOnly reader2
   public void testReadOnlyCloneAfterOptimize() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader1 = IndexReader.open(dir1, false);
-    IndexWriter w = new IndexWriter(dir1, newIndexWriterConfig(random,
+    IndexWriter w = new IndexWriter(dir1, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     w.optimize();
     w.close();
@@ -229,7 +220,7 @@
   }
   
   public void testCloneReadOnlyDirectoryReader() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
 
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader = IndexReader.open(dir1, false);
@@ -253,9 +244,9 @@
   }
 
   public void testParallelReader() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, true);
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir2, true);
     IndexReader r1 = IndexReader.open(dir1, false);
     IndexReader r2 = IndexReader.open(dir2, false);
@@ -304,9 +295,9 @@
   }
 
   public void testMixedReaders() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, true);
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir2, true);
     IndexReader r1 = IndexReader.open(dir1, false);
     IndexReader r2 = IndexReader.open(dir2, false);
@@ -319,7 +310,7 @@
   }
 
   public void testSegmentReaderUndeleteall() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
     SegmentReader origSegmentReader = SegmentReader.getOnlySegmentReader(dir1);
     origSegmentReader.deleteDocument(10);
@@ -332,7 +323,7 @@
   }
   
   public void testSegmentReaderCloseReferencing() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
     SegmentReader origSegmentReader = SegmentReader.getOnlySegmentReader(dir1);
     origSegmentReader.deleteDocument(1);
@@ -351,7 +342,7 @@
   }
   
   public void testSegmentReaderDelDocsReferenceCounting() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
 
     IndexReader origReader = IndexReader.open(dir1, false);
@@ -415,7 +406,7 @@
 
   // LUCENE-1648
   public void testCloneWithDeletes() throws Throwable {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader origReader = IndexReader.open(dir1, false);
     origReader.deleteDocument(1);
@@ -432,7 +423,7 @@
 
   // LUCENE-1648
   public void testCloneWithSetNorm() throws Throwable {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader orig = IndexReader.open(dir1, false);
     orig.setNorm(1, "field1", 17.0f);
@@ -461,7 +452,7 @@
   }
   
   public void testCloneSubreaders() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
  
     TestIndexReaderReopen.createIndex(random, dir1, true);
     IndexReader reader = IndexReader.open(dir1, false);
@@ -481,7 +472,7 @@
   }
 
   public void testLucene1516Bug() throws Exception {
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader r1 = IndexReader.open(dir1, false);
     r1.incRef();
@@ -498,8 +489,8 @@
   }
 
   public void testCloseStoredFields() throws Exception {
-    final Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random,
+    final Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundFile(false);
     ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
Index: lucene/src/test/org/apache/lucene/index/TestIsCurrent.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIsCurrent.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIsCurrent.java	(working copy)
@@ -22,14 +22,12 @@
 import org.apache.lucene.document.Field.Index;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.util.*;
-import org.apache.lucene.analysis.*;
 import org.apache.lucene.store.*;
 
 import static org.junit.Assert.*;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Random;
 
 public class TestIsCurrent extends LuceneTestCaseJ4 {
 
@@ -37,17 +35,13 @@
 
   private Directory directory;
 
-  private Random rand;
-
   @Override
   public void setUp() throws Exception {
     super.setUp();
 
-    rand = newRandom();
-
     // initialize directory
-    directory = newDirectory(rand);
-    writer = new RandomIndexWriter(rand, directory);
+    directory = newDirectory();
+    writer = new RandomIndexWriter(random, directory);
 
     // write document
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.BytesRef;
@@ -33,13 +32,11 @@
 public class TestSegmentTermEnum extends LuceneTestCase {
   
   Directory dir;
-  Random random;
   
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
   }
   
   @Override
@@ -51,7 +48,7 @@
   public void testTermEnum() throws IOException {
     IndexWriter writer = null;
 
-    writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     // ADD 100 documents with term : aaa
     // add 100 documents with terms: aaa bbb
@@ -67,7 +64,7 @@
     verifyDocFreq();
 
     // merge segments by optimizing the index
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.optimize();
     writer.close();
 
@@ -77,7 +74,7 @@
 
   public void testPrevTermAtEnd() throws IOException
   {
-    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
+    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     addDoc(writer, "aaa bbb");
     writer.close();
     SegmentReader reader = SegmentReader.getOnlySegmentReader(dir);
Index: lucene/src/test/org/apache/lucene/index/TestRollback.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestRollback.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestRollback.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -31,8 +29,7 @@
 
   // LUCENE-2536
   public void testRollbackIntegrityWithBufferFlush() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter rw = new RandomIndexWriter(random, dir);
     for (int i = 0; i < 5; i++) {
       Document doc = new Document();
@@ -42,7 +39,7 @@
     rw.close();
 
     // If buffer size is small enough to cause a flush, errors ensue...
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));
 
     Term pkTerm = new Term("pk", "");
     for (int i = 0; i < 3; i++) {
Index: lucene/src/test/org/apache/lucene/index/TestIndexReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReader.java	(working copy)
@@ -27,7 +27,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.HashMap;
-import java.util.Random;
 import java.util.Set;
 import java.util.SortedSet;
 
@@ -71,26 +70,18 @@
 //        TestRunner.run (new TestIndexReader("testFilesOpenClose"));
     }
     
-    private Random random;
-    
-    @Override
-    public void setUp() throws Exception {
-      super.setUp();
-      random = newRandom();
-    }
-    
     public TestIndexReader(String name) {
         super(name);
     }
     
     public void testCommitUserData() throws Exception {
-      Directory d = newDirectory(random);
+      Directory d = newDirectory();
 
       Map<String,String> commitUserData = new HashMap<String,String>();
       commitUserData.put("foo", "fighters");
       
       // set up writer
-      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
       .setMaxBufferedDocs(2));
       for(int i=0;i<27;i++)
@@ -113,7 +104,7 @@
       assertTrue(c.equals(r.getIndexCommit()));
 
       // Change the index
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
               OpenMode.APPEND).setMaxBufferedDocs(2));
       for(int i=0;i<7;i++)
@@ -125,7 +116,7 @@
       assertFalse(r2.getIndexCommit().isOptimized());
       r3.close();
 
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND));
       writer.optimize();
@@ -139,8 +130,8 @@
     }
     
     public void testIsCurrent() throws Exception {
-      Directory d = newDirectory(random);
-      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random, 
+      Directory d = newDirectory();
+      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       writer.close();
@@ -148,13 +139,13 @@
       IndexReader reader = IndexReader.open(d, false);
       assertTrue(reader.isCurrent());
       // modify index by adding another document:
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       addDocumentWithFields(writer);
       writer.close();
       assertFalse(reader.isCurrent());
       // re-create index:
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
       addDocumentWithFields(writer);
       writer.close();
@@ -168,9 +159,9 @@
      * @throws Exception on error
      */
     public void testGetFieldNames() throws Exception {
-        Directory d = newDirectory(random);
+        Directory d = newDirectory();
         // set up writer
-        IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random, 
+        IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer()));
         addDocumentWithFields(writer);
         writer.close();
@@ -183,7 +174,7 @@
         assertTrue(fieldNames.contains("unstored"));
         reader.close();
         // add more documents
-        writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+        writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
             new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
         // want to get some more segments here
         int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();
@@ -260,9 +251,9 @@
     }
 
   public void testTermVectors() throws Exception {
-    Directory d = newDirectory(random);
+    Directory d = newDirectory();
     // set up writer
-    IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random, 
+    IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     // want to get some more segments here
     // new termvector fields
@@ -314,14 +305,14 @@
     }
 
     public void testBasicDelete() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
         IndexReader reader = null;
         Term searchTerm = new Term("content", "aaa");
 
         //  add 100 documents with term : aaa
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         for (int i = 0; i < 100; i++) {
             addDoc(writer, searchTerm.text());
         }
@@ -358,10 +349,10 @@
     }
     
     public void testBinaryFields() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
         byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};
         
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         
         for (int i = 0; i < 10; i++) {
           addDoc(writer, "document number " + (i + 1));
@@ -370,7 +361,7 @@
           addDocumentWithTermVectorFields(writer);
         }
         writer.close();
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
         Document doc = new Document();
         doc.add(new Field("bin1", bin));
         doc.add(new Field("junk", "junk text", Field.Store.NO, Field.Index.ANALYZED));
@@ -407,7 +398,7 @@
         // force optimize
 
 
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+        writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
         writer.optimize();
         writer.close();
         reader = IndexReader.open(dir, false);
@@ -429,14 +420,14 @@
     // Make sure attempts to make changes after reader is
     // closed throws IOException:
     public void testChangesAfterClose() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
         IndexReader reader = null;
         Term searchTerm = new Term("content", "aaa");
 
         //  add 11 documents with term : aaa
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         for (int i = 0; i < 11; i++) {
             addDoc(writer, searchTerm.text());
         }
@@ -473,12 +464,12 @@
 
     // Make sure we get lock obtain failed exception with 2 writers:
     public void testLockObtainFailed() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         Term searchTerm = new Term("content", "aaa");
 
         //  add 11 documents with term : aaa
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         writer.commit();
         for (int i = 0; i < 11; i++) {
             addDoc(writer, searchTerm.text());
@@ -523,7 +514,7 @@
         Term searchTerm = new Term("content", "aaa");
 
         //  add 1 documents with term : aaa
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         addDoc(writer, searchTerm.text());
         writer.close();
 
@@ -561,13 +552,13 @@
     // Make sure you can set norms & commit, and there are
     // no extra norms files left:
     public void testWritingNormsNoReader() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
         IndexWriter writer = null;
         IndexReader reader = null;
         Term searchTerm = new Term("content", "aaa");
 
         //  add 1 documents with term : aaa
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
         ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
         addDoc(writer, searchTerm.text());
@@ -615,13 +606,13 @@
 
     private void deleteReaderWriterConflict(boolean optimize) throws IOException {
         //Directory dir = new RAMDirectory();
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         Term searchTerm = new Term("content", "aaa");
         Term searchTerm2 = new Term("content", "bbb");
 
         //  add 100 documents with term : aaa
-        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         for (int i = 0; i < 100; i++) {
             addDoc(writer, searchTerm.text());
         }
@@ -636,7 +627,7 @@
         assertTermDocsCount("first reader", reader, searchTerm2, 0);
 
         // add 100 documents with term : bbb
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
         for (int i = 0; i < 100; i++) {
             addDoc(writer, searchTerm2.text());
         }
@@ -698,7 +689,7 @@
         // Create initial data set
         File dirFile = _TestUtil.getTempDir("TestIndexReader.testFilesOpenClose");
         Directory dir = FSDirectory.open(dirFile);
-        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
         addDoc(writer, "test");
         writer.close();
         dir.close();
@@ -708,7 +699,7 @@
         dir = FSDirectory.open(dirFile);
 
         // Now create the data set again, just as before
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         addDoc(writer, "test");
         writer.close();
         dir.close();
@@ -726,9 +717,9 @@
 
     public void testLastModified() throws Exception {
       for(int i=0;i<2;i++) {
-        final Directory dir = newDirectory(random);
+        final Directory dir = newDirectory();
         assertFalse(IndexReader.indexExists(dir));
-        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         addDocumentWithFields(writer);
         assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
         writer.close();
@@ -745,7 +736,7 @@
         // incremented:
         Thread.sleep(1000);
 
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         addDocumentWithFields(writer);
         writer.close();
         reader = IndexReader.open(dir, false);
@@ -756,9 +747,9 @@
     }
 
     public void testVersion() throws IOException {
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
       assertFalse(IndexReader.indexExists(dir));
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       assertTrue(IndexWriter.isLocked(dir));		// writer open, so dir is locked
       writer.close();
@@ -769,7 +760,7 @@
       reader.close();
       // modify index and check version has been
       // incremented:
-      writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+      writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
       addDocumentWithFields(writer);
       writer.close();
       reader = IndexReader.open(dir, false);
@@ -779,11 +770,11 @@
     }
 
     public void testLock() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       writer.close();
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       IndexReader reader = IndexReader.open(dir, false);
       try {
         reader.deleteDocument(0);
@@ -803,8 +794,8 @@
     }
 
     public void testUndeleteAll() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       addDocumentWithFields(writer);
       writer.close();
@@ -820,8 +811,8 @@
     }
 
     public void testUndeleteAllAfterClose() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       addDocumentWithFields(writer);
       writer.close();
@@ -837,8 +828,8 @@
     }
 
     public void testUndeleteAllAfterCloseThenReopen() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       addDocumentWithFields(writer);
       writer.close();
@@ -874,8 +865,8 @@
       int END_COUNT = 144;
       
       // First build up a starting index:
-      MockDirectoryWrapper startDir = newDirectory(random);
-      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      MockDirectoryWrapper startDir = newDirectory();
+      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       for(int i=0;i<157;i++) {
         Document d = new Document();
         d.add(new Field("id", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));
@@ -1048,8 +1039,8 @@
     }
 
     public void testDocsOutOfOrderJIRA140() throws IOException {
-      Directory dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       for(int i=0;i<11;i++) {
         addDoc(writer, "aaa");
       }
@@ -1067,7 +1058,7 @@
       }
       reader.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
 
       // We must add more docs to get a new segment written
       for(int i=0;i<11;i++) {
@@ -1088,8 +1079,8 @@
 
     public void testExceptionReleaseWriteLockJIRA768() throws IOException {
 
-      Directory dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDoc(writer, "aaa");
       writer.close();
 
@@ -1143,7 +1134,7 @@
     }
 
     public void testMultiReaderDeletes() throws Exception {
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
       RandomIndexWriter w = new RandomIndexWriter(random, dir);
       Document doc = new Document();
       doc.add(new Field("f", "doctor", Field.Store.NO, Field.Index.NOT_ANALYZED));
@@ -1173,7 +1164,7 @@
     }
 
     private void deleteReaderReaderConflict(boolean optimize) throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         Term searchTerm1 = new Term("content", "aaa");
         Term searchTerm2 = new Term("content", "bbb");
@@ -1182,7 +1173,7 @@
         //  add 100 documents with term : aaa
         //  add 100 documents with term : bbb
         //  add 100 documents with term : ccc
-        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         for (int i = 0; i < 100; i++) {
             addDoc(writer, searchTerm1.text());
             addDoc(writer, searchTerm2.text());
@@ -1410,10 +1401,10 @@
 
     public void testGetIndexCommit() throws IOException {
 
-      Directory d = newDirectory(random);
+      Directory d = newDirectory();
 
       // set up writer
-      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random, 
+      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig( 
           TEST_VERSION_CURRENT, new MockAnalyzer())
       .setMaxBufferedDocs(2));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -1431,7 +1422,7 @@
       assertTrue(c.equals(r.getIndexCommit()));
 
       // Change the index
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
               OpenMode.APPEND).setMaxBufferedDocs(2));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -1444,7 +1435,7 @@
       assertFalse(r2.getIndexCommit().isOptimized());
       r2.close();
 
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND));
       writer.optimize();
@@ -1459,8 +1450,8 @@
     }      
 
     public void testReadOnly() throws Throwable {
-      Directory d = newDirectory(random);
-      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(random, 
+      Directory d = newDirectory();
+      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
       addDocumentWithFields(writer);
       writer.commit();
@@ -1475,7 +1466,7 @@
         // expected
       }
       
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -1495,7 +1486,7 @@
         // expected
       }
 
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND));
       writer.optimize();
@@ -1516,7 +1507,7 @@
       }
 
       // Make sure write lock isn't held
-      writer = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer())
       .setOpenMode(OpenMode.APPEND));
       writer.close();
@@ -1528,8 +1519,8 @@
 
   // LUCENE-1474
   public void testIndexReader() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.addDocument(createDocument("a"));
     writer.addDocument(createDocument("b"));
@@ -1546,9 +1537,9 @@
 
   // LUCENE-1647
   public void testIndexReaderUnDeleteAll() throws Exception {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     dir.setPreventDoubleWrite(false);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.addDocument(createDocument("a"));
     writer.addDocument(createDocument("b"));
@@ -1588,9 +1579,9 @@
   // LUCENE-1509
   public void testNoDupCommitFileNames() throws Throwable {
 
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2));
     writer.addDocument(createDocument("a"));
@@ -1614,8 +1605,8 @@
   // LUCENE-1579: Ensure that on a cloned reader, segments
   // reuse the doc values arrays in FieldCache
   public void testFieldCacheReuseAfterClone() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("number", "17", Field.Store.NO, Field.Index.NOT_ANALYZED));
     writer.addDocument(doc);
@@ -1645,8 +1636,8 @@
   // shared segments reuse the doc values arrays in
   // FieldCache
   public void testFieldCacheReuseAfterReopen() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("number", "17", Field.Store.NO, Field.Index.NOT_ANALYZED));
     ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -1678,8 +1669,8 @@
   // LUCENE-1579: Make sure all SegmentReaders are new when
   // reopen switches readOnly
   public void testReopenChangeReadonly() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
     Document doc = new Document();
     doc.add(new Field("number", "17", Field.Store.NO, Field.Index.NOT_ANALYZED));
@@ -1720,8 +1711,8 @@
 
   // LUCENE-1586: getUniqueTermCount
   public void testUniqueTermCount() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     Document doc = new Document();
     doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
     doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
@@ -1753,8 +1744,8 @@
 
   // LUCENE-1609: don't load terms index
   public void testNoTermsIndex() throws Throwable {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     Document doc = new Document();
     doc.add(new Field("field", "a b c d e f g h i j k l m n o p q r s t u v w x y z", Field.Store.NO, Field.Index.ANALYZED));
     doc.add(new Field("number", "0 1 2 3 4 5 6 7 8 9", Field.Store.NO, Field.Index.ANALYZED));
@@ -1771,7 +1762,7 @@
     }
 
     assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
     writer.addDocument(doc);
     writer.close();
@@ -1795,8 +1786,8 @@
 
   // LUCENE-2046
   public void testPrepareCommitIsCurrent() throws Throwable {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.commit();
     Document doc = new Document();
Index: lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -44,8 +44,6 @@
   static int maxBufferedDocs=3;
   static int seed=0;
 
-  Random r;
-
   public class MockIndexWriter extends IndexWriter {
 
     public MockIndexWriter(Directory dir, IndexWriterConfig conf) throws IOException {
@@ -55,36 +53,34 @@
     @Override
     boolean testPoint(String name) {
       //      if (name.equals("startCommit")) {
-      if (r.nextInt(4) == 2)
+      if (random.nextInt(4) == 2)
         Thread.yield();
       return true;
     }
   }
   
   public void testRandomIWReader() throws Throwable {
-    r = newRandom();
-    Directory dir = newDirectory(r);
+    Directory dir = newDirectory();
     
     // TODO: verify equals using IW.getReader
     DocsAndWriter dw = indexRandomIWReader(5, 3, 100, dir);
     IndexReader reader = dw.writer.getReader();
     dw.writer.commit();
-    verifyEquals(r, reader, dir, "id");
+    verifyEquals(random, reader, dir, "id");
     reader.close();
     dw.writer.close();
     dir.close();
   }
   
   public void testRandom() throws Throwable {
-    r = newRandom();
-    Directory dir1 = newDirectory(r);
+    Directory dir1 = newDirectory();
     // dir1 = FSDirectory.open("foofoofoo");
-    Directory dir2 = newDirectory(r);
+    Directory dir2 = newDirectory();
     // mergeFactor=2; maxBufferedDocs=2; Map docs = indexRandom(1, 3, 2, dir1);
-    int maxThreadStates = 1+r.nextInt(10);
-    boolean doReaderPooling = r.nextBoolean();
+    int maxThreadStates = 1+random.nextInt(10);
+    boolean doReaderPooling = random.nextBoolean();
     Map<String,Document> docs = indexRandom(5, 3, 100, dir1, maxThreadStates, doReaderPooling);
-    indexSerial(r, docs, dir2);
+    indexSerial(random, docs, dir2);
 
     // verifying verify
     // verifyEquals(dir1, dir1, "id");
@@ -98,25 +94,23 @@
   public void testMultiConfig() throws Throwable {
     // test lots of smaller different params together
 
-    r = newRandom();
-
     int num = 3 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) { // increase iterations for better testing
-      sameFieldOrder=r.nextBoolean();
-      mergeFactor=r.nextInt(3)+2;
-      maxBufferedDocs=r.nextInt(3)+2;
-      int maxThreadStates = 1+r.nextInt(10);
-      boolean doReaderPooling = r.nextBoolean();
+      sameFieldOrder=random.nextBoolean();
+      mergeFactor=random.nextInt(3)+2;
+      maxBufferedDocs=random.nextInt(3)+2;
+      int maxThreadStates = 1+random.nextInt(10);
+      boolean doReaderPooling = random.nextBoolean();
       seed++;
 
-      int nThreads=r.nextInt(5)+1;
-      int iter=r.nextInt(5)+1;
-      int range=r.nextInt(20)+1;
-      Directory dir1 = newDirectory(r);
-      Directory dir2 = newDirectory(r);
+      int nThreads=random.nextInt(5)+1;
+      int iter=random.nextInt(5)+1;
+      int range=random.nextInt(20)+1;
+      Directory dir1 = newDirectory();
+      Directory dir2 = newDirectory();
       Map<String,Document> docs = indexRandom(nThreads, iter, range, dir1, maxThreadStates, doReaderPooling);
       //System.out.println("TEST: index serial");
-      indexSerial(r, docs, dir2);
+      indexSerial(random, docs, dir2);
       //System.out.println("TEST: verify");
       verifyEquals(dir1, dir2, "id");
       dir1.close();
@@ -144,7 +138,7 @@
   
   public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {
     Map<String,Document> docs = new HashMap<String,Document>();
-    IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(r,
+    IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(
         0.1).setMaxBufferedDocs(maxBufferedDocs));
     w.commit();
@@ -197,7 +191,7 @@
                                           boolean doReaderPooling) throws IOException, InterruptedException {
     Map<String,Document> docs = new HashMap<String,Document>();
     for(int iter=0;iter<3;iter++) {
-      IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(r,
+      IndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
                .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates)
                .setReaderPooling(doReaderPooling));
@@ -242,7 +236,7 @@
 
   
   public static void indexSerial(Random random, Map<String,Document> docs, Directory dir) throws IOException {
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter w = new IndexWriter(dir, LuceneTestCaseJ4.newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     // index all docs in a single thread
     Iterator<Document> iter = docs.values().iterator();
Index: lucene/src/test/org/apache/lucene/index/TestFlex.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestFlex.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestFlex.java	(working copy)
@@ -17,12 +17,7 @@
  * limitations under the License.
  */
 
-import java.io.*;
-import java.util.*;
 import org.apache.lucene.store.*;
-import org.apache.lucene.index.codecs.*;
-import org.apache.lucene.index.codecs.standard.*;
-import org.apache.lucene.search.*;
 import org.apache.lucene.analysis.*;
 import org.apache.lucene.document.*;
 import org.apache.lucene.util.*;
@@ -31,7 +26,7 @@
 
   // Test non-flex API emulated on flex index
   public void testNonFlex() throws Exception {
-    Directory d = newDirectory(newRandom());
+    Directory d = newDirectory();
 
     final int DOC_COUNT = 177;
 
@@ -65,9 +60,8 @@
   }
 
   public void testTermOrd() throws Exception {
-    Random random = newRandom();
-    Directory d = newDirectory(random);
-    IndexWriter w = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    Directory d = newDirectory();
+    IndexWriter w = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
                                                              new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     Document doc = new Document();
     doc.add(new Field("f", "a b c", Field.Store.NO, Field.Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.Arrays;
 import java.util.Iterator;
 import java.util.Map;
-import java.util.Random;
 import java.util.SortedSet;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -94,9 +93,8 @@
     }
     Arrays.sort(tokens);
 
-    Random random = newRandom();
-    dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MyAnalyzer()).setMaxBufferedDocs(-1));
+    dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MyAnalyzer()).setMaxBufferedDocs(-1));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
Index: lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestSegmentTermDocs.java	(working copy)
@@ -25,13 +25,11 @@
 import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
-import java.util.Random;
 
 public class TestSegmentTermDocs extends LuceneTestCase {
   private Document testDoc = new Document();
   private Directory dir;
   private SegmentInfo info;
-  private Random random;
 
   public TestSegmentTermDocs(String s) {
     super(s);
@@ -40,8 +38,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     DocHelper.setupDoc(testDoc);
     info = DocHelper.writeDoc(dir, testDoc);
   }
@@ -111,8 +108,8 @@
   }
 
   public void testSkipTo(int indexDivisor) throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     
     Term ta = new Term("content","aaa");
     for(int i = 0; i < 10; i++)
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -79,20 +79,13 @@
 import org.apache.lucene.util.Bits;
 
 public class TestIndexWriter extends LuceneTestCase {
-    Random random;
     
-    @Override
-    public void setUp() throws Exception {
-      super.setUp();
-      random = newRandom();
-    }
-    
     public TestIndexWriter(String name) {
       super(name);
     }
 
     public void testDocCount() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
         IndexReader reader = null;
@@ -102,7 +95,7 @@
         try {
           IndexWriterConfig.setDefaultWriteLockTimeout(2000);
           assertEquals(2000, IndexWriterConfig.getDefaultWriteLockTimeout());
-          writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+          writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         } finally {
           IndexWriterConfig.setDefaultWriteLockTimeout(savedWriteLockTimeout);
         }
@@ -122,7 +115,7 @@
         reader.close();
 
         // test doc count before segments are merged/index is optimized
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         assertEquals(100, writer.maxDoc());
         writer.close();
 
@@ -132,7 +125,7 @@
         reader.close();
 
         // optimize the index and check that the new doc count is correct
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         assertEquals(100, writer.maxDoc());
         assertEquals(60, writer.numDocs());
         writer.optimize();
@@ -148,7 +141,7 @@
 
         // make sure opening a new index for create over
         // this existing one works correctly:
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         assertEquals(0, writer.maxDoc());
         assertEquals(0, writer.numDocs());
         writer.close();
@@ -189,8 +182,8 @@
       Directory[] dirs = new Directory[NUM_DIR];
       long inputDiskUsage = 0;
       for(int i=0;i<NUM_DIR;i++) {
-        dirs[i] = newDirectory(random);
-        IndexWriter writer  = new IndexWriter(dirs[i], newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        dirs[i] = newDirectory();
+        IndexWriter writer  = new IndexWriter(dirs[i], newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         for(int j=0;j<25;j++) {
           addDocWithIndex(writer, 25*i+j);
         }
@@ -203,8 +196,8 @@
 
       // Now, build a starting index that has START_COUNT docs.  We
       // will then try to addIndexesNoOptimize into a copy of this:
-      MockDirectoryWrapper startDir = newDirectory(random);
-      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      MockDirectoryWrapper startDir = newDirectory();
+      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       for(int j=0;j<START_COUNT;j++) {
         addDocWithIndex(writer, j);
       }
@@ -267,7 +260,7 @@
 
           // Make a new dir that will enforce disk usage:
           MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));
-          writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+          writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
           IOException err = null;
 
           MergeScheduler ms = writer.getConfig().getMergeScheduler();
@@ -481,7 +474,7 @@
             System.out.println("TEST: cycle: diskFree=" + diskFree);
           MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());
           dir.setMaxSizeInBytes(diskFree);
-          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
           MergeScheduler ms = writer.getConfig().getMergeScheduler();
           if (ms instanceof ConcurrentMergeScheduler)
             // This test intentionally produces exceptions
@@ -559,7 +552,7 @@
 
     public void testOptimizeMaxNumSegments() throws IOException {
 
-      MockDirectoryWrapper dir = newDirectory(random);
+      MockDirectoryWrapper dir = newDirectory();
 
       final Document doc = new Document();
       doc.add(new Field("content", "aaa", Field.Store.YES, Field.Index.ANALYZED));
@@ -568,7 +561,7 @@
         LogDocMergePolicy ldmp = new LogDocMergePolicy();
         ldmp.setMinMergeDocs(1);
         ldmp.setMergeFactor(5);
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2).setMergePolicy(
               ldmp));
@@ -582,7 +575,7 @@
 
         ldmp = new LogDocMergePolicy();
         ldmp.setMergeFactor(5);
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
           new MockAnalyzer()).setMergePolicy(ldmp));
         writer.optimize(3);
         writer.close();
@@ -600,7 +593,7 @@
     }
 
     public void testOptimizeMaxNumSegments2() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);
+      MockDirectoryWrapper dir = newDirectory();
 
       final Document doc = new Document();
       doc.add(new Field("content", "aaa", Field.Store.YES, Field.Index.ANALYZED));
@@ -608,7 +601,7 @@
       LogDocMergePolicy ldmp = new LogDocMergePolicy();
       ldmp.setMinMergeDocs(1);
       ldmp.setMergeFactor(4);
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setMergePolicy(ldmp).setMergeScheduler(new ConcurrentMergeScheduler()));
 
@@ -648,8 +641,8 @@
      */
     public void testOptimizeTempSpaceUsage() throws IOException {
     
-      MockDirectoryWrapper dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      MockDirectoryWrapper dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
 
       for(int j=0;j<500;j++) {
         addDocWithIndex(writer, j);
@@ -665,7 +658,7 @@
       dir.resetMaxUsedSizeInBytes();
       dir.setTrackDiskUsage(true);
 
-      writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       writer.optimize();
       writer.close();
       long maxDiskUsage = dir.getMaxUsedSizeInBytes();
@@ -696,7 +689,7 @@
           Directory dir = FSDirectory.open(indexDir);
 
           // add one document & close writer
-          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
           addDoc(writer);
           writer.close();
 
@@ -705,7 +698,7 @@
           assertEquals("should be one document", reader.numDocs(), 1);
 
           // now open index for create:
-          writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+          writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
           assertEquals("should be zero documents", writer.maxDoc(), 0);
           addDoc(writer);
           writer.close();
@@ -725,12 +718,12 @@
     // gracefully fallback to the previous segments file),
     // and that we can add to the index:
     public void testSimulatedCrashedWriter() throws IOException {
-        MockDirectoryWrapper dir = newDirectory(random);
+        MockDirectoryWrapper dir = newDirectory();
         dir.setPreventDoubleWrite(false);
 
         IndexWriter writer = null;
 
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
         // add 100 documents
         for (int i = 0; i < 100; i++) {
@@ -768,7 +761,7 @@
         reader.close();
 
         try {
-          writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+          writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
         } catch (Exception e) {
           e.printStackTrace(System.out);
           fail("writer failed to open on a crashed index");
@@ -788,11 +781,11 @@
     // latest segments file and make sure we get an
     // IOException trying to open the index:
     public void testSimulatedCorruptIndex1() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
 
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
         // add 100 documents
         for (int i = 0; i < 100; i++) {
@@ -832,11 +825,11 @@
     }
 
     public void testChangesAfterClose() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
 
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         addDoc(writer);
 
         // close
@@ -855,11 +848,11 @@
     // files and make sure we get an IOException trying to
     // open the index:
     public void testSimulatedCorruptIndex2() throws IOException {
-        Directory dir = newDirectory(random);
+        Directory dir = newDirectory();
 
         IndexWriter writer = null;
 
-        writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);
 
         // add 100 documents
@@ -902,8 +895,8 @@
      * these docs until writer is closed.
      */
     public void testCommitOnClose() throws IOException {
-        Directory dir = newDirectory(random);      
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        Directory dir = newDirectory();      
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         for (int i = 0; i < 14; i++) {
           addDoc(writer);
         }
@@ -917,7 +910,7 @@
 
         IndexReader reader = IndexReader.open(dir, true);
 
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         for(int i=0;i<3;i++) {
           for(int j=0;j<11;j++) {
             addDoc(writer);
@@ -950,8 +943,8 @@
      * and add docs to it.
      */
     public void testCommitOnCloseAbort() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
       for (int i = 0; i < 14; i++) {
         addDoc(writer);
       }
@@ -963,7 +956,7 @@
       assertEquals("first number of hits", 14, hits.length);
       searcher.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
       for(int j=0;j<17;j++) {
         addDoc(writer);
@@ -988,7 +981,7 @@
           
       // Now make sure we can re-open the index, add docs,
       // and all is good:
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
 
       // On abort, writer in fact may write to the same
@@ -1022,8 +1015,8 @@
      * measure max temp disk space used.
      */
     public void testCommitOnCloseDiskUsage() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
       for(int j=0;j<30;j++) {
         addDocWithIndex(writer, j);
@@ -1033,7 +1026,7 @@
 
       dir.setTrackDiskUsage(true);
       long startDiskUsage = dir.getMaxUsedSizeInBytes();
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10).setMergeScheduler(
             new SerialMergeScheduler()));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -1069,19 +1062,19 @@
      * and close().
      */
     public void testCommitOnCloseOptimize() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);  
+      MockDirectoryWrapper dir = newDirectory();  
       // Must disable throwing exc on double-write: this
       // test uses IW.rollback which easily results in
       // writing to same file more than once
       dir.setPreventDoubleWrite(false);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
       ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
       for(int j=0;j<17;j++) {
         addDocWithIndex(writer, j);
       }
       writer.close();
 
-      writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       writer.optimize();
 
       // Open a reader before closing (commiting) the writer:
@@ -1103,7 +1096,7 @@
       assertFalse("Reader incorrectly sees that the index is optimized", reader.isOptimized());
       reader.close();
 
-      writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       writer.optimize();
       writer.close();
       assertNoUnreferencedFiles(dir, "aborted writer after optimize");
@@ -1118,8 +1111,8 @@
     }
 
     public void testIndexNoDocuments() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       writer.commit();
       writer.close();
 
@@ -1128,7 +1121,7 @@
       assertEquals(0, reader.numDocs());
       reader.close();
 
-      writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       writer.commit();
       writer.close();
 
@@ -1140,8 +1133,8 @@
     }
 
     public void testManyFields() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
       for(int j=0;j<100;j++) {
         Document doc = new Document();
         doc.add(new Field("a"+j, "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
@@ -1170,8 +1163,8 @@
     }
 
     public void testSmallRAMBuffer() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.000001));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.000001));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
       int lastNumFile = dir.listAll().length;
       for(int j=0;j<9;j++) {
@@ -1197,8 +1190,8 @@
      *             session won't be possible.
      */
     public void testChangingRAMBuffer() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10).setRAMBufferSizeMB(
         IndexWriterConfig.DISABLE_AUTO_FLUSH));
 
@@ -1255,8 +1248,8 @@
      *             changing those settings on IW won't be possible.
      */
     public void testChangingRAMBuffer2() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10).setMaxBufferedDeleteTerms(
         10).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));
 
@@ -1314,8 +1307,8 @@
     }
 
     public void testDiverseDocs() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
       for(int i=0;i<3;i++) {
         // First, docs where every term is unique (heavy on
         // Posting instances)
@@ -1361,8 +1354,8 @@
     }
 
     public void testEnablingNorms() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
       // Enable norms for only 1 doc, pre flush
       for(int j=0;j<10;j++) {
         Document doc = new Document();
@@ -1382,7 +1375,7 @@
       assertEquals(10, hits.length);
       searcher.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10));
       // Enable norms for only 1 doc, post flush
       for(int j=0;j<27;j++) {
@@ -1407,8 +1400,8 @@
     }
 
     public void testHighFreqTerm() throws IOException {
-      MockDirectoryWrapper dir = newDirectory(random);      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      MockDirectoryWrapper dir = newDirectory();      
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxFieldLength(100000000).setRAMBufferSizeMB(0.01));
       // Massive doc that has 128 K a's
       StringBuilder b = new StringBuilder(1024*1024);
@@ -1459,7 +1452,7 @@
       }
       
       Directory dir = new MyRAMDirectory(new RAMDirectory());
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
       for (int i = 0; i < 100; i++) {
         addDoc(writer);
@@ -1471,7 +1464,7 @@
       assertEquals("did not get right number of hits", 100, hits.length);
       searcher.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE));
       writer.close();
       searcher.close();
@@ -1479,8 +1472,8 @@
     }
 
     public void testFlushWithNoMerging() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+      Directory dir = newDirectory();
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
       Document doc = new Document();
@@ -1500,8 +1493,8 @@
     // Make sure we can flush segment w/ norms, then add
     // empty doc (no norms) and flush
     public void testEmptyDocAfterFlushingRealDoc() throws IOException {
-      Directory dir = newDirectory(random);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       Document doc = new Document();
       doc.add(new Field("field", "aaa", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
       writer.addDocument(doc);
@@ -1520,9 +1513,9 @@
     // writer.close()) does wait
     public void testBackgroundOptimize() throws IOException {
 
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
       for(int pass=0;pass<2;pass++) {
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2));
         ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(101);
@@ -1575,8 +1568,8 @@
    *
    */
   public void testBadSegment() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     
     Document document = new Document();
@@ -1588,8 +1581,8 @@
 
   // LUCENE-1008
   public void testNoTermVectorAfterTermVector() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document document = new Document();
     document.add(new Field("tvtest", "a b c", Field.Store.NO, Field.Index.ANALYZED,
@@ -1615,8 +1608,8 @@
 
   // LUCENE-1010
   public void testNoTermVectorAfterTermVectorMerge() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document document = new Document();
     document.add(new Field("tvtest", "a b c", Field.Store.NO, Field.Index.ANALYZED,
@@ -1648,8 +1641,8 @@
   public void testMaxThreadPriority() throws IOException {
     int pri = Thread.currentThread().getPriority();
     try {
-      Directory dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      Directory dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMaxBufferedDocs(2);
       ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);
@@ -1690,8 +1683,8 @@
 
   // LUCENE-1013
   public void testSetMaxMergeDocs() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriterConfig conf = newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMergeScheduler(new MyMergeScheduler()).setMaxBufferedDocs(2);
     LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -1709,8 +1702,8 @@
 
   // LUCENE-1072
   public void testExceptionFromTokenStream() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new Analyzer() {
+    Directory dir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new Analyzer() {
 
       @Override
       public TokenStream tokenStream(String fieldName, Reader reader) {
@@ -1812,12 +1805,12 @@
   // LUCENE-1072: make sure an errant exception on flushing
   // one segment only takes out those docs in that one flush
   public void testDocumentsWriterAbort() throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     FailOnlyOnFlush failure = new FailOnlyOnFlush();
     failure.setDoFail();
     dir.failOn(failure);
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     Document doc = new Document();
     String contents = "aa bb cc dd ee ff gg hh ii jj kk";
     doc.add(new Field("content", contents, Field.Store.NO,
@@ -1872,8 +1865,8 @@
     };
 
     for(int i=0;i<2;i++) {
-      MockDirectoryWrapper dir = newDirectory(random);
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+      MockDirectoryWrapper dir = newDirectory();
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
       //writer.setInfoStream(System.out);
       Document doc = new Document();
       doc.add(new Field("contents", "here are some contents", Field.Store.YES,
@@ -1918,7 +1911,7 @@
 
       assertEquals(1, numDel);
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
           analyzer).setMaxBufferedDocs(10));
       doc = new Document();
       doc.add(new Field("contents", "here are some contents", Field.Store.YES,
@@ -1957,10 +1950,10 @@
     final int NUM_ITER = 100;
 
     for(int i=0;i<2;i++) {
-      MockDirectoryWrapper dir = newDirectory(random);
+      MockDirectoryWrapper dir = newDirectory();
 
       {
-        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(-1));
+        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(-1));
         ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
         final int finalI = i;
 
@@ -2031,7 +2024,7 @@
 
       assertEquals(NUM_THREAD*NUM_ITER, numDel);
 
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(10));
       Document doc = new Document();
       doc.add(new Field("contents", "here are some contents", Field.Store.YES,
@@ -2057,10 +2050,10 @@
   }
 
   public void testVariableSchema() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     int delID = 0;
     for(int i=0;i<20;i++) {
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
       LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
       lmp.setMergeFactor(2);
       lmp.setUseCompoundFile(false);
@@ -2097,7 +2090,7 @@
       reader.close();
 
       if (0 == i % 4) {
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         LogMergePolicy lmp2 = (LogMergePolicy) writer.getConfig().getMergePolicy();
         lmp2.setUseCompoundFile(false);
         lmp2.setUseCompoundDocStore(false);
@@ -2109,7 +2102,7 @@
   }
 
   public void testNoWaitClose() throws Throwable {
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
 
     final Document doc = new Document();
     Field idField = new Field("id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
@@ -2117,7 +2110,7 @@
 
     for(int pass=0;pass<2;pass++) {
 
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
           .setMaxBufferedDocs(2);
       if (pass == 2) {
@@ -2186,7 +2179,7 @@
         reader.close();
 
         // Reopen
-        writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+        writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       }
       writer.close();
     }
@@ -2265,8 +2258,8 @@
     int NUM_THREADS = 3;
 
     for(int iter=0;iter<7;iter++) {
-      Directory dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      Directory dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());
       // We expect AlreadyClosedException
       ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
@@ -2324,8 +2317,8 @@
   // an IndexWriter (hit during DW.ThreadState.init()) is
   // OK:
   public void testImmediateDiskFull() throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    MockDirectoryWrapper dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
     dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));
     final Document doc = new Document();
@@ -2362,8 +2355,8 @@
     int NUM_THREADS = 3;
 
     for(int iter=0;iter<10;iter++) {
-      MockDirectoryWrapper dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      MockDirectoryWrapper dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler());
       // We expect disk full exceptions in the merge threads
       ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
@@ -2421,9 +2414,9 @@
   // Runs test, with one thread, using the specific failure
   // to trigger an IOException
   public void _testSingleThreadFailure(MockDirectoryWrapper.Failure failure) throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
       .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
     final Document doc = new Document();
     doc.add(new Field("field", "aaa bbb ccc ddd eee fff ggg hhh iii jjj", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
@@ -2453,8 +2446,8 @@
     int NUM_THREADS = 3;
 
     for(int iter=0;iter<2;iter++) {
-      MockDirectoryWrapper dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      MockDirectoryWrapper dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT,
           new MockAnalyzer()).setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler());
       // We expect disk full exceptions in the merge threads
       ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
@@ -2612,9 +2605,9 @@
 
   // LUCENE-1084: test unlimited field length
   public void testUnlimitedMaxFieldLength() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     Document doc = new Document();
     StringBuilder b = new StringBuilder();
@@ -2634,11 +2627,11 @@
 
   // LUCENE-1044: Simulate checksum error in segments_N
   public void testSegmentsChecksumError() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     IndexWriter writer = null;
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     // add 100 documents
     for (int i = 0; i < 100; i++) {
@@ -2673,9 +2666,9 @@
 
   // LUCENE-1044: test writer.commit() when ac=false
   public void testForceCommit() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
@@ -2727,11 +2720,11 @@
 
   // LUCENE-1044: test exception during sync
   public void testExceptionDuringSync() throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     FailOnlyInSync failure = new FailOnlyInSync();
     dir.failOn(failure);
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
     failure.setDoFail();
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
@@ -2761,9 +2754,9 @@
   // LUCENE-1168
   public void testTermVectorCorruption() throws IOException {
 
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     for(int iter=0;iter<2;iter++) {
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMaxBufferedDocs(2).setRAMBufferSizeMB(
               IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(
@@ -2796,7 +2789,7 @@
       }
       reader.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
           new MockAnalyzer()).setMaxBufferedDocs(2)
           .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH)
           .setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(
@@ -2812,9 +2805,9 @@
 
   // LUCENE-1168
   public void testTermVectorCorruption2() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     for(int iter=0;iter<2;iter++) {
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMaxBufferedDocs(2).setRAMBufferSizeMB(
               IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(
@@ -2850,8 +2843,8 @@
 
   // LUCENE-1168
   public void testTermVectorCorruption3() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setRAMBufferSizeMB(
             IndexWriterConfig.DISABLE_AUTO_FLUSH).setMergeScheduler(
@@ -2871,7 +2864,7 @@
       writer.addDocument(document);
     writer.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
         new MockAnalyzer()).setMaxBufferedDocs(2)
         .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH)
         .setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(
@@ -2893,7 +2886,7 @@
 
   // LUCENE-1084: test user-specified field length
   public void testUserSpecifiedMaxFieldLength() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxFieldLength(100000));
@@ -2917,8 +2910,8 @@
   // LUCENE-325: test expungeDeletes, when 2 singular merges
   // are required
   public void testExpungeDeletes() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setRAMBufferSizeMB(
             IndexWriterConfig.DISABLE_AUTO_FLUSH));
@@ -2945,7 +2938,7 @@
     assertEquals(8, ir.numDocs());
     ir.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     assertEquals(8, writer.numDocs());
     assertEquals(10, writer.maxDoc());
     writer.expungeDeletes();
@@ -2960,8 +2953,8 @@
 
   // LUCENE-325: test expungeDeletes, when many adjacent merges are required
   public void testExpungeDeletes2() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setRAMBufferSizeMB(
             IndexWriterConfig.DISABLE_AUTO_FLUSH));
@@ -2989,7 +2982,7 @@
     assertEquals(49, ir.numDocs());
     ir.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
         new MockAnalyzer()));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(3);
     assertEquals(49, writer.numDocs());
@@ -3005,8 +2998,8 @@
   // LUCENE-325: test expungeDeletes without waiting, when
   // many adjacent merges are required
   public void testExpungeDeletes3() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setRAMBufferSizeMB(
             IndexWriterConfig.DISABLE_AUTO_FLUSH));
@@ -3034,7 +3027,7 @@
     assertEquals(49, ir.numDocs());
     ir.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     // Force many merges to happen
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(3);
     writer.expungeDeletes(false);
@@ -3048,8 +3041,8 @@
 
   // LUCENE-1179
   public void testEmptyFieldName() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("", "a b c", Field.Store.NO, Field.Index.ANALYZED));
     writer.addDocument(doc);
@@ -3076,8 +3069,8 @@
   
 
   public void testExceptionDocumentsWriterInit() throws IOException {
-    Directory dir = newDirectory(random);
-    MockIndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    MockIndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a field", Field.Store.YES,
                       Field.Index.ANALYZED));
@@ -3096,8 +3089,8 @@
 
   // LUCENE-1208
   public void testExceptionJustBeforeFlush() throws IOException {
-    Directory dir = newDirectory(random);
-    MockIndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    Directory dir = newDirectory();
+    MockIndexWriter w = new MockIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     Document doc = new Document();
     doc.add(new Field("field", "a field", Field.Store.YES,
                       Field.Index.ANALYZED));
@@ -3146,8 +3139,8 @@
 
   // LUCENE-1210
   public void testExceptionOnMergeInit() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    Directory dir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
       .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler());
     ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);
     MockIndexWriter2 w = new MockIndexWriter2(dir, conf);
@@ -3191,8 +3184,8 @@
 
   // LUCENE-1222
   public void testDoBeforeAfterFlush() throws IOException {
-    Directory dir = newDirectory(random);
-    MockIndexWriter3 w = new MockIndexWriter3(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    MockIndexWriter3 w = new MockIndexWriter3(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a field", Field.Store.YES,
                       Field.Index.ANALYZED));
@@ -3247,9 +3240,9 @@
 
   // LUCENE-1214
   public void testExceptionsDuringCommit() throws Throwable {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     FailOnlyInCommit failure = new FailOnlyInCommit();
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a field", Field.Store.YES,
                       Field.Index.ANALYZED));
@@ -3296,8 +3289,8 @@
 
   // LUCENE-510
   public void testInvalidUTF16() throws Throwable {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
 
     final int count = utf8Data.length/2;
@@ -3506,8 +3499,8 @@
       }
     };
 
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", tokens));
     w.addDocument(doc);
@@ -3542,9 +3535,9 @@
 
   // LUCENE-1274: test writer.prepareCommit()
   public void testPrepareCommit() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
     writer.commit();
     
@@ -3593,10 +3586,10 @@
 
   // LUCENE-1274: test writer.prepareCommit()
   public void testPrepareCommitRollback() throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     dir.setPreventDoubleWrite(false);
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
     writer.commit();
     
@@ -3620,7 +3613,7 @@
     reader.close();
     reader2.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     for (int i = 0; i < 17; i++)
       addDoc(writer);
 
@@ -3646,9 +3639,9 @@
 
   // LUCENE-1274
   public void testPrepareCommitNoChanges() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.prepareCommit();
     writer.commit();
     writer.close();
@@ -3952,8 +3945,8 @@
 
   // LUCENE-1347
   public void testRollbackExceptionHang() throws Throwable {
-    Directory dir = newDirectory(random);
-    MockIndexWriter4 w = new MockIndexWriter4(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    MockIndexWriter4 w = new MockIndexWriter4(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     addDoc(w);
     w.doFail = true;
@@ -3972,8 +3965,8 @@
 
   // LUCENE-1219
   public void testBinaryFieldOffsetLength() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     byte[] b = new byte[50];
     for(int i=0;i<50;i++)
       b[i] = (byte) (i+77);
@@ -4002,8 +3995,8 @@
 
   // LUCENE-1382
   public void testCommitUserData() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     for(int j=0;j<17;j++)
       addDoc(w);
     w.close();
@@ -4015,7 +4008,7 @@
     assertEquals(0, r.getCommitUserData().size());
     r.close();
       
-    w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     for(int j=0;j<17;j++)
       addDoc(w);
     Map<String,String> data = new HashMap<String,String>();
@@ -4029,7 +4022,7 @@
     assertEquals("test1", r.getCommitUserData().get("label"));
     r.close();
 
-    w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     w.optimize();
     w.close();
 
@@ -4039,8 +4032,8 @@
   }
 
   public void testOptimizeExceptions() throws IOException {
-    Directory startDir = newDirectory(random);
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2);
+    Directory startDir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2);
     ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(100);
     IndexWriter w = new IndexWriter(startDir, conf);
     for(int i=0;i<27;i++)
@@ -4049,7 +4042,7 @@
 
     for(int i=0;i<200;i++) {
       MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));
-      conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new ConcurrentMergeScheduler());
+      conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new ConcurrentMergeScheduler());
       ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
       w = new IndexWriter(dir, conf);
       dir.setRandomIOExceptionRate(0.5, 100);
@@ -4070,9 +4063,9 @@
   public void testOutOfMemoryErrorCausesCloseToFail() throws Exception {
 
     final List<Throwable> thrown = new ArrayList<Throwable>();
-    final Directory dir = newDirectory(random);
+    final Directory dir = newDirectory();
     final IndexWriter writer = new IndexWriter(dir,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())) {
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())) {
         @Override
         public void message(final String message) {
           if (message.startsWith("now flush at close") && 0 == thrown.size()) {
@@ -4097,8 +4090,8 @@
 
   // LUCENE-1442
   public void testDoubleOffsetCounting() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = new Field("field", "abcd", Field.Store.NO, Field.Index.NOT_ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
@@ -4133,8 +4126,8 @@
 
   // LUCENE-1442
   public void testDoubleOffsetCounting2() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = new Field("field", "abcd", Field.Store.NO, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
     doc.add(f);
@@ -4155,8 +4148,8 @@
 
   // LUCENE-1448
   public void testEndOffsetPositionCharAnalyzer() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = new Field("field", "abcd   ", Field.Store.NO, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
     doc.add(f);
@@ -4177,9 +4170,9 @@
 
   // LUCENE-1448
   public void testEndOffsetPositionWithCachingTokenFilter() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
     TokenStream stream = new CachingTokenFilter(analyzer.tokenStream("field", new StringReader("abcd   ")));
     Field f = new Field("field", stream, Field.TermVector.WITH_POSITIONS_OFFSETS);
@@ -4201,8 +4194,8 @@
   
   // LUCENE-1448
   public void testEndOffsetPositionStopFilter() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
     Document doc = new Document();
     Field f = new Field("field", "abcd the", Field.Store.NO, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS);
@@ -4224,8 +4217,8 @@
 
   // LUCENE-1448
   public void testEndOffsetPositionStandard() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = new Field("field", "abcd the  ", Field.Store.NO,
@@ -4255,8 +4248,8 @@
 
   // LUCENE-1448
   public void testEndOffsetPositionStandardEmptyField() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = new Field("field", "", Field.Store.NO,
@@ -4283,8 +4276,8 @@
 
   // LUCENE-1448
   public void testEndOffsetPositionStandardEmptyField2() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
 
@@ -4327,7 +4320,7 @@
       out.writeByte((byte) 42);
       out.close();
 
-      new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())).close();
+      new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())).close();
 
       assertTrue(dir.fileExists("myrandomfile"));
     } finally {
@@ -4337,8 +4330,8 @@
   }
 
   public void testDeadlock() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     Document doc = new Document();
     doc.add(new Field("content", "aaa bbb ccc ddd eee fff ggg hhh iii", Field.Store.YES,
                       Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
@@ -4348,8 +4341,8 @@
     writer.commit();
     // index has 2 segments
 
-    Directory dir2 = newDirectory(random);
-    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir2 = newDirectory();
+    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer2.addDocument(doc);
     writer2.close();
 
@@ -4387,7 +4380,7 @@
             if (w != null) {
               w.close();
             }
-            IndexWriterConfig conf = newIndexWriterConfig(random, 
+            IndexWriterConfig conf = newIndexWriterConfig( 
                                                           TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2);
             ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);
             w = new IndexWriter(dir, conf);
@@ -4493,8 +4486,8 @@
 
 
   public void testIndexStoreCombos() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     byte[] b = new byte[50];
     for(int i=0;i<50;i++)
       b[i] = (byte) (i+77);
@@ -4556,8 +4549,8 @@
 
   // LUCENE-1727: make sure doc fields are stored in order
   public void testStoredFieldsOrder() throws Throwable {
-    Directory d = newDirectory(random);
-    IndexWriter w = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory d = newDirectory();
+    IndexWriter w = new IndexWriter(d, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("zzz", "a b c", Field.Store.YES, Field.Index.NO));
     doc.add(new Field("aaa", "a b c", Field.Store.YES, Field.Index.NO));
@@ -4588,8 +4581,8 @@
 
   public void testEmbeddedFFFF() throws Throwable {
 
-    Directory d = newDirectory(random);
-    IndexWriter w = new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory d = newDirectory();
+    IndexWriter w = new IndexWriter(d, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a a\uffffb", Field.Store.NO, Field.Index.ANALYZED));
     w.addDocument(doc);
@@ -4605,8 +4598,8 @@
   }
 
   public void testNoDocsIndex() throws Throwable {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
     lmp.setUseCompoundFile(false);
@@ -4626,8 +4619,8 @@
   public void testCommitThreadSafety() throws Throwable {
     final int NUM_THREADS = 5;
     final double RUN_SEC = 0.5;
-    final Directory dir = newDirectory(random);
-    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+    final Directory dir = newDirectory();
+    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     w.commit();
     final AtomicBoolean failed = new AtomicBoolean();
@@ -4734,7 +4727,7 @@
   // sort in codepoint sort order by default
   public void testTermUTF16SortOrder() throws Throwable {
     Random rnd = random;
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(rnd, dir);
     Document d = new Document();
     // Single segment
@@ -4798,7 +4791,7 @@
   }
 
   public void testIndexDivisor() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     IndexWriter w = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
     StringBuilder s = new StringBuilder();
     // must be > 256
@@ -4827,8 +4820,8 @@
   public void testDeleteUnusedFiles() throws Exception {
 
     for(int iter=0;iter<2;iter++) {
-      Directory dir = newDirectory(random);
-      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      Directory dir = newDirectory();
+      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       ((LogMergePolicy) w.getMergePolicy()).setUseCompoundFile(true);
       Document doc = new Document();
       doc.add(new Field("field", "go", Field.Store.NO, Field.Index.ANALYZED));
@@ -4886,9 +4879,9 @@
   public void testDeleteUnsedFiles2() throws Exception {
     // Validates that iw.deleteUnusedFiles() also deletes unused index commits
     // in case a deletion policy which holds onto commits is used.
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SnapshotDeletionPolicy sdp = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setIndexDeletionPolicy(sdp));
     
@@ -4931,8 +4924,8 @@
   public void testIndexingThenDeleting() throws Exception {
     final Random r = random;
 
-    Directory dir = newDirectory(random);
-    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
+    Directory dir = newDirectory();
+    FlushCountingIndexWriter w = new FlushCountingIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMaxBufferedDeleteTerms(-1));
     //w.setInfoStream(System.out);
     Document doc = new Document();
     doc.add(new Field("field", "go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20", Field.Store.NO, Field.Index.ANALYZED));
@@ -4966,8 +4959,8 @@
     // Tests that if we don't call commit(), the directory has 0 commits. This has
     // changed since LUCENE-2386, where before IW would always commit on a fresh
     // new index.
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     try {
       IndexReader.listCommits(dir);
       fail("listCommits should have thrown an exception over empty index");
@@ -4985,15 +4978,15 @@
     // then IndexWriter ctor succeeds. Previously (LUCENE-2386) it failed 
     // when listAll() was called in IndexFileDeleter.
     FSDirectory dir = FSDirectory.open(new File(TEMP_DIR, "emptyFSDirNoLock"), NoLockFactory.getNoLockFactory());
-    new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())).close();
+    new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())).close();
   }
 
   public void testEmptyDirRollback() throws Exception {
     // Tests that if IW is created over an empty Directory, some documents are
     // indexed, flushed (but not committed) and then IW rolls back, then no 
     // files are left in the Directory.
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2));
     String[] files = dir.listAll();
@@ -5037,14 +5030,14 @@
     try {
       Directory dir = FSDirectory.open(tempDir);
       dir.setLockFactory(NoLockFactory.getNoLockFactory());
-      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, 
+      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
           TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
 
       Document doc = new Document();
       doc.add(new Field("c", "val", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
       w.addDocument(doc);
       w.addDocument(doc);
-      IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig(random, 
+      IndexWriter w2 = new IndexWriter(dir, newIndexWriterConfig( 
           TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2)
           .setOpenMode(OpenMode.CREATE));
 
@@ -5058,9 +5051,9 @@
   }
 
   public void testFutureCommit() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
     Document doc = new Document();
     w.addDocument(doc);
 
@@ -5086,7 +5079,7 @@
 
     assertNotNull(commit);
 
-    w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE).setIndexCommit(commit));
+    w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE).setIndexCommit(commit));
 
     assertEquals(1, w.numDocs());
     
@@ -5134,9 +5127,9 @@
   }
 
   public void testRandomStoredFields() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     Random rand = random;
-    RandomIndexWriter w = new RandomIndexWriter(rand, dir, newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(_TestUtil.nextInt(rand, 5, 20)));
+    RandomIndexWriter w = new RandomIndexWriter(rand, dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(_TestUtil.nextInt(rand, 5, 20)));
     //w.w.setInfoStream(System.out);
     //w.w.setUseCompoundFile(false);
     if (VERBOSE) {
@@ -5247,10 +5240,10 @@
   
   // LUCENE-2593
   public void testCorruptionAfterDiskFullDuringMerge() throws IOException {
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     final Random rand = random;
-    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));
+    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));
 
     ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);
 
Index: lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java	(working copy)
@@ -62,7 +62,7 @@
 
   public void testSimpleSkip() throws IOException {
     Directory dir = new CountingRAMDirectory(new RAMDirectory());
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new PayloadAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new PayloadAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     Term term = new Term("test", "a");
     for (int i = 0; i < 5000; i++) {
       Document d1 = new Document();
Index: lucene/src/test/org/apache/lucene/index/TestCheckIndex.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestCheckIndex.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestCheckIndex.java	(working copy)
@@ -22,7 +22,6 @@
 import java.io.PrintStream;
 import java.util.List;
 import java.util.ArrayList;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.store.Directory;
@@ -34,9 +33,8 @@
 public class TestCheckIndex extends LuceneTestCase {
 
   public void testDeletedDocs() throws IOException {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    Directory dir = newDirectory();
+    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     Document doc = new Document();
     doc.add(new Field("field", "aaa", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
     for(int i=0;i<19;i++) {
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java	(working copy)
@@ -129,10 +129,9 @@
   }
 
   public void testRandomExceptions() throws Throwable {
-    Random random = newRandom();
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
 
-    MockIndexWriter writer  = new MockIndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    MockIndexWriter writer  = new MockIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setRAMBufferSizeMB(0.1).setMergeScheduler(new ConcurrentMergeScheduler()));
     ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
     //writer.setMaxBufferedDocs(10);
@@ -170,9 +169,8 @@
   }
 
   public void testRandomExceptionsThreads() throws Throwable {
-    Random random = newRandom();
-    MockDirectoryWrapper dir = newDirectory(random);
-    MockIndexWriter writer  = new MockIndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    MockDirectoryWrapper dir = newDirectory();
+    MockIndexWriter writer  = new MockIndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
         .setRAMBufferSizeMB(0.2).setMergeScheduler(new ConcurrentMergeScheduler()));
     ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
     //writer.setMaxBufferedDocs(10);
Index: lucene/src/test/org/apache/lucene/index/TestTransactions.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTransactions.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestTransactions.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -28,17 +27,15 @@
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
 
 public class TestTransactions extends LuceneTestCase {
   
-  private Random RANDOM;
   private static volatile boolean doFail;
 
   private class RandomFailure extends MockDirectoryWrapper.Failure {
     @Override
     public void eval(MockDirectoryWrapper dir) throws IOException {
-      if (TestTransactions.doFail && RANDOM.nextInt() % 10 <= 3)
+      if (TestTransactions.doFail && random.nextInt() % 10 <= 3)
         throw new IOException("now failing randomly but on purpose");
     }
   }
@@ -94,14 +91,14 @@
     @Override
     public void doWork() throws Throwable {
 
-      IndexWriter writer1 = new IndexWriter(dir1, newIndexWriterConfig(RANDOM, TEST_VERSION_CURRENT, new MockAnalyzer())
+      IndexWriter writer1 = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMaxBufferedDocs(3).setMergeScheduler(new ConcurrentMergeScheduler()));
       ((LogMergePolicy) writer1.getConfig().getMergePolicy()).setMergeFactor(2);
       ((ConcurrentMergeScheduler) writer1.getConfig().getMergeScheduler()).setSuppressExceptions();
 
       // Intentionally use different params so flush/merge
       // happen @ different times
-      IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig(RANDOM, TEST_VERSION_CURRENT, new MockAnalyzer())
+      IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
       ((LogMergePolicy) writer2.getConfig().getMergePolicy()).setMergeFactor(3);
       ((ConcurrentMergeScheduler) writer2.getConfig().getMergeScheduler()).setSuppressExceptions();
@@ -142,7 +139,7 @@
       // Add 10 docs:
       for(int j=0; j<10; j++) {
         Document d = new Document();
-        int n = RANDOM.nextInt();
+        int n = random.nextInt();
         d.add(new Field("id", Integer.toString(nextID++), Field.Store.YES, Field.Index.NOT_ANALYZED));
         d.add(new Field("contents", English.intToEnglish(n), Field.Store.NO, Field.Index.ANALYZED));
         writer.addDocument(d);
@@ -184,10 +181,10 @@
   }
 
   public void initIndex(Directory dir) throws Throwable {
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(RANDOM, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     for(int j=0; j<7; j++) {
       Document d = new Document();
-      int n = RANDOM.nextInt();
+      int n = random.nextInt();
       d.add(new Field("contents", English.intToEnglish(n), Field.Store.NO, Field.Index.ANALYZED));
       writer.addDocument(d);
     }
@@ -195,7 +192,6 @@
   }
 
   public void testTransactions() throws Throwable {
-    RANDOM = newRandom();
     // we cant use non-ramdir on windows, because this test needs to double-write.
     MockDirectoryWrapper dir1 = new MockDirectoryWrapper(new RAMDirectory());
     MockDirectoryWrapper dir2 = new MockDirectoryWrapper(new RAMDirectory());
Index: lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.io.Reader;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -43,7 +42,6 @@
 
 public class TestDocumentWriter extends LuceneTestCase {
   private Directory dir;
-  private Random random;
   
   public TestDocumentWriter(String s) {
     super(s);
@@ -52,8 +50,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
   }
   
   @Override
@@ -69,7 +66,7 @@
   public void testAddDocument() throws Exception {
     Document testDoc = new Document();
     DocHelper.setupDoc(testDoc);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.addDocument(testDoc);
     writer.commit();
     SegmentInfo info = writer.newestSegment();
@@ -127,7 +124,7 @@
       }
     };
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
 
     Document doc = new Document();
     doc.add(new Field("repeated", "repeated one", Field.Store.YES, Field.Index.ANALYZED));
@@ -192,7 +189,7 @@
       }
     };
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
 
     Document doc = new Document();
     doc.add(new Field("f1", "a 5 a a", Field.Store.YES, Field.Index.ANALYZED));
@@ -218,7 +215,7 @@
 
 
   public void testPreAnalyzedField() throws IOException {
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     
@@ -278,7 +275,7 @@
     doc.add(new Field("f2", "v1", Store.YES, Index.NOT_ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
     doc.add(new Field("f2", "v2", Store.YES, Index.NOT_ANALYZED, TermVector.NO));
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.addDocument(doc);
     writer.close();
@@ -313,7 +310,7 @@
     doc.add(f);
     doc.add(new Field("f2", "v2", Store.YES, Index.NO));
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.addDocument(doc);
     writer.optimize(); // be sure to have a single segment
Index: lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java	(working copy)
@@ -38,10 +38,9 @@
 public class TestIndexFileDeleter extends LuceneTestCase {
   
   public void testDeleteLeftoverFiles() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper dir = newDirectory(random);
+    MockDirectoryWrapper dir = newDirectory();
     dir.setPreventDoubleWrite(false);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10));
     ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -147,7 +146,7 @@
 
     // Open & close a writer: it should delete the above 4
     // files and nothing more:
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.close();
 
     String[] files2 = dir.listAll();
Index: lucene/src/test/org/apache/lucene/index/TestMultiFields.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestMultiFields.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestMultiFields.java	(working copy)
@@ -27,36 +27,34 @@
 
   public void testRandom() throws Exception {
 
-    Random r = newRandom();
-
     int num = 2 * RANDOM_MULTIPLIER;
     for (int iter = 0; iter < num; iter++) {
-      Directory dir = newDirectory(r);
+      Directory dir = newDirectory();
 
-      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(r, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
+      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));
 
       Map<BytesRef,List<Integer>> docs = new HashMap<BytesRef,List<Integer>>();
       Set<Integer> deleted = new HashSet<Integer>();
       List<BytesRef> terms = new ArrayList<BytesRef>();
 
-      int numDocs = _TestUtil.nextInt(r, 1, 100 * RANDOM_MULTIPLIER);
+      int numDocs = _TestUtil.nextInt(random, 1, 100 * RANDOM_MULTIPLIER);
       Document doc = new Document();
       Field f = new Field("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
       doc.add(f);
       Field id = new Field("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
       doc.add(id);
 
-      boolean onlyUniqueTerms = r.nextBoolean();
+      boolean onlyUniqueTerms = random.nextBoolean();
       Set<BytesRef> uniqueTerms = new HashSet<BytesRef>();
       for(int i=0;i<numDocs;i++) {
 
-        if (!onlyUniqueTerms && r.nextBoolean() && terms.size() > 0) {
+        if (!onlyUniqueTerms && random.nextBoolean() && terms.size() > 0) {
           // re-use existing term
-          BytesRef term = terms.get(r.nextInt(terms.size()));
+          BytesRef term = terms.get(random.nextInt(terms.size()));
           docs.get(term).add(i);
           f.setValue(term.utf8ToString());
         } else {
-          String s = _TestUtil.randomUnicodeString(r, 10);
+          String s = _TestUtil.randomUnicodeString(random, 10);
           BytesRef term = new BytesRef(s);
           if (!docs.containsKey(term)) {
             docs.put(term, new ArrayList<Integer>());
@@ -68,11 +66,11 @@
         }
         id.setValue(""+i);
         w.addDocument(doc);
-        if (r.nextInt(4) == 1) {
+        if (random.nextInt(4) == 1) {
           w.commit();
         }
-        if (i > 0 && r.nextInt(20) == 1) {
-          int delID = r.nextInt(i);
+        if (i > 0 && random.nextInt(20) == 1) {
+          int delID = random.nextInt(i);
           deleted.add(delID);
           w.deleteDocuments(new Term("id", ""+delID));
         }
@@ -98,7 +96,7 @@
       Terms terms2 = MultiFields.getTerms(reader, "field");
 
       for(int i=0;i<100;i++) {
-        BytesRef term = terms.get(r.nextInt(terms.size()));
+        BytesRef term = terms.get(random.nextInt(terms.size()));
         
         DocsEnum docsEnum = terms2.docs(delDocs, term, null);
         assertNotNull(docsEnum);
@@ -131,9 +129,8 @@
   */
 
   public void testSeparateEnums() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document d = new Document();
     d.add(new Field("f", "j", Field.Store.NO, Field.Index.NOT_ANALYZED));
     w.addDocument(d);
Index: lucene/src/test/org/apache/lucene/index/TestPersistentSnapshotDeletionPolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestPersistentSnapshotDeletionPolicy.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestPersistentSnapshotDeletionPolicy.java	(working copy)
@@ -39,7 +39,7 @@
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    snapshotDir = newDirectory(random);
+    snapshotDir = newDirectory();
   }
   
   @After
@@ -52,7 +52,7 @@
   @Override
   protected SnapshotDeletionPolicy getDeletionPolicy() throws IOException {
     snapshotDir.close();
-    snapshotDir = newDirectory(random);
+    snapshotDir = newDirectory();
     return new PersistentSnapshotDeletionPolicy(
         new KeepOnlyLastCommitDeletionPolicy(), snapshotDir, OpenMode.CREATE,
         TEST_VERSION_CURRENT);
@@ -73,7 +73,7 @@
   @Test
   public void testExistingSnapshots() throws Exception {
     int numSnapshots = 3;
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     PersistentSnapshotDeletionPolicy psdp = (PersistentSnapshotDeletionPolicy) getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, psdp));
     prepareIndexAndSnapshots(psdp, writer, numSnapshots, "snapshot");
@@ -137,7 +137,7 @@
 
   @Test
   public void testSnapshotRelease() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     PersistentSnapshotDeletionPolicy psdp = (PersistentSnapshotDeletionPolicy) getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, psdp));
     prepareIndexAndSnapshots(psdp, writer, 1, "snapshot");
@@ -160,7 +160,7 @@
     // prevents reading the snapshots information. This test checks that the 
     // static read method works.
     int numSnapshots = 1;
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     PersistentSnapshotDeletionPolicy psdp = (PersistentSnapshotDeletionPolicy) getDeletionPolicy();
     IndexWriter writer = new IndexWriter(dir, getConfig(random, psdp));
     prepareIndexAndSnapshots(psdp, writer, numSnapshots, "snapshot");
Index: lucene/src/test/org/apache/lucene/index/TestNewestSegment.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestNewestSegment.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestNewestSegment.java	(working copy)
@@ -17,19 +17,14 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
-import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.index.IndexWriter.MaxFieldLength;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
 public class TestNewestSegment extends LuceneTestCase {
   public void testNewestSegment() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     assertNull(writer.newestSegment());
     writer.close();
     directory.close();
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java	(working copy)
@@ -263,7 +263,7 @@
     // iw.getConfig().getXYZ(), he'll get the same value he passed to
     // iw.setXYZ().
     IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
     IndexWriter writer = new IndexWriter(dir, conf);
 
     writer.setSimilarity(new MySimilarity());
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java	(working copy)
@@ -83,7 +83,6 @@
    */
   public void testNorms() throws IOException {
     // test with a single index: index1
-    Random random = newRandom();
     File indexDir1 = new File(TEMP_DIR, "lucenetestindex1");
     Directory dir1 = FSDirectory.open(indexDir1);
     IndexWriter.unlock(dir1);
@@ -114,7 +113,7 @@
     Directory dir3 = FSDirectory.open(indexDir3);
 
     createIndex(random, dir3);
-    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(random,
+    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
         .setMaxBufferedDocs(5));
     ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
@@ -133,7 +132,7 @@
     doTestNorms(random, dir3);
 
     // now with optimize
-    iw = new IndexWriter(dir3, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    iw = new IndexWriter(dir3, newIndexWriterConfig( TEST_VERSION_CURRENT,
         anlzr).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(5));
     ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
     iw.optimize();
@@ -165,8 +164,7 @@
   }
   
   public void testNormsClose() throws IOException { 
-    Random random = newRandom();
-    Directory dir1 = newDirectory(random); 
+    Directory dir1 = newDirectory(); 
     TestIndexReaderReopen.createIndex(random, dir1, false);
     SegmentReader reader1 = SegmentReader.getOnlySegmentReader(dir1);
     reader1.norms("field1");
@@ -182,8 +180,7 @@
   }
   
   public void testNormsRefCounting() throws IOException { 
-    Random random = newRandom();
-    Directory dir1 = newDirectory(random); 
+    Directory dir1 = newDirectory(); 
     TestIndexReaderReopen.createIndex(random, dir1, false);
     IndexReader reader1 = IndexReader.open(dir1, false);
         
@@ -236,7 +233,7 @@
   }
   
   private void createIndex(Random random, Directory dir) throws IOException {
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
         .setMaxBufferedDocs(5).setSimilarity(similarityOne));
     LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
@@ -289,7 +286,7 @@
 
   private void addDocs(Random random, Directory dir, int ndocs, boolean compound)
       throws IOException {
-    IndexWriterConfig conf = newIndexWriterConfig(random,
+    IndexWriterConfig conf = newIndexWriterConfig(
             TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
             .setMaxBufferedDocs(5).setSimilarity(similarityOne);
     LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
Index: lucene/src/test/org/apache/lucene/index/TestCodecs.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestCodecs.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestCodecs.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.HashSet;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -62,8 +61,6 @@
 //   - skipTo(doc)
 
 public class TestCodecs extends MultiCodecTestCase {
-
-  private Random RANDOM;
   private static String[] fieldNames = new String[] {"one", "two", "three", "four"};
 
   private final static int NUM_TEST_ITER = 20 * RANDOM_MULTIPLIER;
@@ -75,11 +72,11 @@
 
   // start is inclusive and end is exclusive
   public int nextInt(final int start, final int end) {
-    return start + RANDOM.nextInt(end-start);
+    return start + random.nextInt(end-start);
   }
 
   private int nextInt(final int lim) {
-    return RANDOM.nextInt(lim);
+    return random.nextInt(lim);
   }
 
   char[] getRandomText() {
@@ -260,9 +257,6 @@
   }
 
   public void testFixedPostings() throws Throwable {
-
-    RANDOM = this.newRandom();
-
     final int NUM_TERMS = 100;
     final TermData[] terms = new TermData[NUM_TERMS];
     for(int i=0;i<NUM_TERMS;i++) {
@@ -276,7 +270,7 @@
     final FieldData field = new FieldData("field", fieldInfos, terms, true, false);
     final FieldData[] fields = new FieldData[] {field};
 
-    final Directory dir = newDirectory(RANDOM);
+    final Directory dir = newDirectory();
     this.write(fieldInfos, dir, fields);
     final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));
     si.setHasProx(false);
@@ -314,9 +308,6 @@
   }
 
   public void testRandomPostings() throws Throwable {
-
-    RANDOM = this.newRandom();
-
     final FieldInfos fieldInfos = new FieldInfos();
 
     final FieldData[] fields = new FieldData[NUM_FIELDS];
@@ -326,7 +317,7 @@
       fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);
     }
 
-    final Directory dir = newDirectory(RANDOM);
+    final Directory dir = newDirectory();
 
     this.write(fieldInfos, dir, fields);
     final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));
@@ -352,9 +343,8 @@
   }
 
   public void testSepPositionAfterMerge() throws IOException {
-    Random random = newRandom();
-    final Directory dir = newDirectory(random);
-    final IndexWriterConfig config = newIndexWriterConfig(random, Version.LUCENE_31,
+    final Directory dir = newDirectory();
+    final IndexWriterConfig config = newIndexWriterConfig(Version.LUCENE_31,
       new MockAnalyzer());
     config.setCodecProvider(new MockSepCodecs());
     final IndexWriter writer = new IndexWriter(dir, config);
Index: lucene/src/test/org/apache/lucene/index/TestCrash.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestCrash.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestCrash.java	(working copy)
@@ -30,13 +30,13 @@
 public class TestCrash extends LuceneTestCase {
 
   private IndexWriter initIndex(Random random, boolean initialCommit) throws IOException {
-    return initIndex(random, newDirectory(random), initialCommit);
+    return initIndex(random, newDirectory(), initialCommit);
   }
 
   private IndexWriter initIndex(Random random, MockDirectoryWrapper dir, boolean initialCommit) throws IOException {
     dir.setLockFactory(NoLockFactory.getNoLockFactory());
 
-    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler()));
     ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
     if (initialCommit) {
@@ -65,7 +65,7 @@
     // This test relies on being able to open a reader before any commit
     // happened, so we must create an initial commit just to allow that, but
     // before any documents were added.
-    IndexWriter writer = initIndex(newRandom(), true);
+    IndexWriter writer = initIndex(random, true);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
     crash(writer);
     IndexReader reader = IndexReader.open(dir, false);
@@ -78,7 +78,6 @@
     // This test relies on being able to open a reader before any commit
     // happened, so we must create an initial commit just to allow that, but
     // before any documents were added.
-    Random random = newRandom();
     IndexWriter writer = initIndex(random, true);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
     dir.setPreventDoubleWrite(false);
@@ -93,7 +92,6 @@
   }
 
   public void testCrashAfterReopen() throws IOException {
-    Random random = newRandom();
     IndexWriter writer = initIndex(random, false);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
     writer.close();
@@ -118,7 +116,7 @@
 
   public void testCrashAfterClose() throws IOException {
     
-    IndexWriter writer = initIndex(newRandom(), false);
+    IndexWriter writer = initIndex(random, false);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
 
     writer.close();
@@ -139,7 +137,7 @@
 
   public void testCrashAfterCloseNoWait() throws IOException {
     
-    IndexWriter writer = initIndex(newRandom(), false);
+    IndexWriter writer = initIndex(random, false);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
 
     writer.close(false);
@@ -160,7 +158,7 @@
 
   public void testCrashReaderDeletes() throws IOException {
     
-    IndexWriter writer = initIndex(newRandom(), false);
+    IndexWriter writer = initIndex(random, false);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
 
     writer.close(false);
@@ -183,7 +181,7 @@
 
   public void testCrashReaderDeletesAfterClose() throws IOException {
     
-    IndexWriter writer = initIndex(newRandom(), false);
+    IndexWriter writer = initIndex(random, false);
     MockDirectoryWrapper dir = (MockDirectoryWrapper) writer.getDirectory();
 
     writer.close(false);
Index: lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java	(working copy)
@@ -54,7 +54,7 @@
 
   public void runTest(Random random, Directory directory, MergeScheduler merger) throws Exception {
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, ANALYZER)
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2).setMergeScheduler(
             merger));
@@ -119,7 +119,7 @@
       assertEquals(expectedDocCount, writer.maxDoc());
 
       writer.close();
-      writer = new IndexWriter(directory, newIndexWriterConfig(random,
+      writer = new IndexWriter(directory, newIndexWriterConfig(
           TEST_VERSION_CURRENT, ANALYZER).setOpenMode(
           OpenMode.APPEND).setMaxBufferedDocs(2));
 
@@ -136,8 +136,7 @@
     FSDirectory.
   */
   public void testThreadedOptimize() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
+    Directory directory = newDirectory();
     runTest(random, directory, new SerialMergeScheduler());
     runTest(random, directory, new ConcurrentMergeScheduler());
     directory.close();
Index: lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java	(working copy)
@@ -25,7 +25,6 @@
 
 import org.apache.lucene.util.LuceneTestCase;
 import java.io.IOException;
-import java.util.Random;
 
 public class TestConcurrentMergeScheduler extends LuceneTestCase {
   
@@ -60,12 +59,11 @@
   // Make sure running BG merges still work fine even when
   // we are hitting exceptions during flushing.
   public void testFlushExceptions() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper directory = newDirectory(random);
+    MockDirectoryWrapper directory = newDirectory();
     FailOnlyOnFlush failure = new FailOnlyOnFlush();
     directory.failOn(failure);
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     Document doc = new Document();
     Field idField = new Field("id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
     doc.add(idField);
@@ -106,15 +104,14 @@
   // Test that deletes committed after a merge started and
   // before it finishes, are correctly merged back:
   public void testDeleteMerging() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper directory = newDirectory(random);
+    MockDirectoryWrapper directory = newDirectory();
 
     LogDocMergePolicy mp = new LogDocMergePolicy();
     // Force degenerate merging so we can get a mix of
     // merging of segments with and without deletes at the
     // start:
     mp.setMinMergeDocs(1000);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMergePolicy(mp));
 
@@ -145,9 +142,8 @@
   }
 
   public void testNoExtraFiles() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random,
+    MockDirectoryWrapper directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2));
 
@@ -163,7 +159,7 @@
       TestIndexWriter.assertNoUnreferencedFiles(directory, "testNoExtraFiles");
 
       // Reopen
-      writer = new IndexWriter(directory, newIndexWriterConfig(random,
+      writer = new IndexWriter(directory, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(2));
     }
@@ -174,13 +170,12 @@
   }
 
   public void testNoWaitClose() throws IOException {
-    Random random = newRandom();
-    MockDirectoryWrapper directory = newDirectory(random);
+    MockDirectoryWrapper directory = newDirectory();
     Document doc = new Document();
     Field idField = new Field("id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
     doc.add(idField);
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
 
     for(int iter=0;iter<10;iter++) {
@@ -209,7 +204,7 @@
       reader.close();
 
       // Reopen
-      writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
     }
     writer.close();
Index: lucene/src/test/org/apache/lucene/index/TestOmitTf.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestOmitTf.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestOmitTf.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.Collection;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
@@ -34,14 +33,7 @@
 
 
 public class TestOmitTf extends LuceneTestCase {
-  private Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   public static class SimpleSimilarity extends Similarity {
     @Override public float lengthNorm(String field, int numTerms) { return 1.0f; }
     @Override public float queryNorm(float sumOfSquaredWeights) { return 1.0f; }
@@ -66,9 +58,9 @@
   // Tests whether the DocumentWriter correctly enable the
   // omitTermFreqAndPositions bit in the FieldInfo
   public void testOmitTermFreqAndPositions() throws Exception {
-    Directory ram = newDirectory(random);
+    Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
     Document d = new Document();
         
     // this field will have Tf
@@ -113,9 +105,9 @@
   // Tests whether merging of docs that have different
   // omitTermFreqAndPositions for the same field works
   public void testMixedMerge() throws Exception {
-    Directory ram = newDirectory(random);
+    Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(3));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
     Document d = new Document();
@@ -166,9 +158,9 @@
   // field X, then adding docs that do omitTermFreqAndPositions for that same
   // field, 
   public void testMixedRAM() throws Exception {
-    Directory ram = newDirectory(random);
+    Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(10));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
     Document d = new Document();
@@ -214,9 +206,9 @@
 
   // Verifies no *.prx exists when all fields omit term freq:
   public void testNoPrxFile() throws Throwable {
-    Directory ram = newDirectory(random);
+    Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(3));
     LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
     lmp.setMergeFactor(2);
@@ -247,9 +239,9 @@
  
   // Test scores with one field with Term Freqs and one without, otherwise with equal content 
   public void testBasic() throws Exception {
-    Directory dir = newDirectory(random);  
+    Directory dir = newDirectory();  
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(2)
         .setSimilarity(new SimpleSimilarity()));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -30,19 +29,12 @@
 import org.apache.lucene.util.LuceneTestCase;
 
 public class TestIndexWriterMergePolicy extends LuceneTestCase {
-  private Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   // Test the normal case
   public void testNormalCase() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergePolicy(new LogDocMergePolicy()));
 
@@ -57,9 +49,9 @@
 
   // Test to see if there is over merge
   public void testNoOverMerge() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergePolicy(new LogDocMergePolicy()));
 
@@ -79,12 +71,12 @@
 
   // Test the case where flush is forced after every addDoc
   public void testForceFlush() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     LogDocMergePolicy mp = new LogDocMergePolicy();
     mp.setMinMergeDocs(100);
     mp.setMergeFactor(10);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergePolicy(mp));
 
@@ -94,7 +86,7 @@
 
       mp = new LogDocMergePolicy();
       mp.setMergeFactor(10);
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
           OpenMode.APPEND).setMaxBufferedDocs(10).setMergePolicy(mp));
       mp.setMinMergeDocs(100);
@@ -107,9 +99,9 @@
 
   // Test the case where mergeFactor changes
   public void testMergeFactorChange() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergePolicy(new LogDocMergePolicy()));
 
@@ -133,9 +125,9 @@
 
   // Test the case where both mergeFactor and maxBufferedDocs change
   public void testMaxBufferedDocsChange() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(101).setMergePolicy(new LogDocMergePolicy()));
 
@@ -148,7 +140,7 @@
       }
       writer.close();
 
-      writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
           OpenMode.APPEND).setMaxBufferedDocs(101).setMergePolicy(
           new LogDocMergePolicy()));
@@ -157,7 +149,7 @@
     writer.close();
     LogDocMergePolicy ldmp = new LogDocMergePolicy();
     ldmp.setMergeFactor(10);
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
         new MockAnalyzer()).setOpenMode(
         OpenMode.APPEND).setMaxBufferedDocs(10).setMergePolicy(ldmp).setMergeScheduler(new ConcurrentMergeScheduler()));
 
@@ -182,11 +174,11 @@
 
   // Test the case where a merge results in no doc at all
   public void testMergeDocCount0() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     LogDocMergePolicy ldmp = new LogDocMergePolicy();
     ldmp.setMergeFactor(100);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(10).setMergePolicy(ldmp));
 
@@ -202,7 +194,7 @@
 
     ldmp = new LogDocMergePolicy();
     ldmp.setMergeFactor(5);
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
         new MockAnalyzer()).setOpenMode(
         OpenMode.APPEND).setMaxBufferedDocs(10).setMergePolicy(ldmp).setMergeScheduler(new ConcurrentMergeScheduler()));
 
Index: lucene/src/test/org/apache/lucene/index/TestByteSlices.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestByteSlices.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestByteSlices.java	(working copy)
@@ -14,7 +14,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
 import java.util.ArrayList;
 import java.util.List;
 import org.apache.lucene.util.LuceneTestCase;
@@ -62,8 +61,6 @@
     int[] uptos = new int[NUM_STREAM];
     int[] counters = new int[NUM_STREAM];
 
-    Random r = newRandom();
-
     ByteSliceReader reader = new ByteSliceReader();
 
     for(int ti=0;ti<100;ti++) {
@@ -75,7 +72,7 @@
       
       int num = 10000 * RANDOM_MULTIPLIER;
       for (int iter = 0; iter < num; iter++) {
-        int stream = r.nextInt(NUM_STREAM);
+        int stream = random.nextInt(NUM_STREAM);
         if (VERBOSE)
           System.out.println("write stream=" + stream);
 
@@ -87,12 +84,12 @@
         }
 
         writer.init(uptos[stream]);
-        int numValue = r.nextInt(20);
+        int numValue = random.nextInt(20);
         for(int j=0;j<numValue;j++) {
           if (VERBOSE)
             System.out.println("    write " + (counters[stream]+j));
           // write some large (incl. negative) ints:
-          writer.writeVInt(r.nextInt());
+          writer.writeVInt(random.nextInt());
           writer.writeVInt(counters[stream]+j);
         }
         counters[stream] += numValue;
Index: lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestAtomicUpdate.java	(working copy)
@@ -185,7 +185,7 @@
     FSDirectory.
   */
   public void testAtomicUpdates() throws Exception {
-    MockIndexWriter.RANDOM = newRandom();
+    MockIndexWriter.RANDOM = random;
     Directory directory;
 
     // First in a RAM directory:
Index: lucene/src/test/org/apache/lucene/index/TestIndexCommit.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexCommit.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexCommit.java	(working copy)
@@ -32,7 +32,7 @@
   @Test
   public void testEqualsHashCode() throws Exception {
     // LUCENE-2417: equals and hashCode() impl was inconsistent
-    final Directory dir = newDirectory(newRandom());
+    final Directory dir = newDirectory();
     
     IndexCommit ic1 = new IndexCommit() {
       @Override public String getSegmentsFileName() { return "a"; }
Index: lucene/src/test/org/apache/lucene/index/TestNoDeletionPolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestNoDeletionPolicy.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestNoDeletionPolicy.java	(working copy)
@@ -73,9 +73,8 @@
 
   @Test
   public void testAllCommitsRemain() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setIndexDeletionPolicy(NoDeletionPolicy.INSTANCE));
     for (int i = 0; i < 10; i++) {
Index: lucene/src/test/org/apache/lucene/index/TestFieldInfos.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestFieldInfos.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestFieldInfos.java	(working copy)
@@ -47,7 +47,7 @@
     fieldInfos.add(testDoc);
     //Since the complement is stored as well in the fields map
     assertTrue(fieldInfos.size() == DocHelper.all.size()); //this is all b/c we are using the no-arg constructor
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
     String name = "testFile";
     IndexOutput output = dir.createOutput(name);
     assertTrue(output != null);
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -34,14 +33,7 @@
 import org.apache.lucene.util._TestUtil;
 
 public class TestIndexWriterDelete extends LuceneTestCase {
-  Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   // test the simple case
   public void testSimpleCase() throws IOException {
     String[] keywords = { "1", "2" };
@@ -50,8 +42,8 @@
         "Venice has lots of canals" };
     String[] text = { "Amsterdam", "Venice" };
 
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDeleteTerms(1));
 
     for (int i = 0; i < keywords.length; i++) {
@@ -85,8 +77,8 @@
   // test when delete terms only apply to disk segments
   public void testNonRAMDelete() throws IOException {
 
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(2)
         .setMaxBufferedDeleteTerms(2));
 
@@ -119,8 +111,8 @@
   }
 
   public void testMaxBufferedDeletes() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDeleteTerms(1));
     writer.deleteDocuments(new Term("foobar", "1"));
     writer.deleteDocuments(new Term("foobar", "1"));
@@ -133,8 +125,8 @@
   // test when delete terms only apply to ram segments
   public void testRAMDeletes() throws IOException {
     for(int t=0;t<2;t++) {
-      Directory dir = newDirectory(random);
-      IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+      Directory dir = newDirectory();
+      IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(4)
           .setMaxBufferedDeleteTerms(4));
 
@@ -174,8 +166,8 @@
 
   // test when delete terms apply to both disk and ram segments
   public void testBothDeletes() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(100)
         .setMaxBufferedDeleteTerms(100));
 
@@ -208,8 +200,8 @@
 
   // test that batched delete terms are flushed together
   public void testBatchDeletes() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(2)
         .setMaxBufferedDeleteTerms(2));
 
@@ -251,8 +243,8 @@
 
   // test deleteAll()
   public void testDeleteAll() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(2)
         .setMaxBufferedDeleteTerms(2));
 
@@ -297,8 +289,8 @@
 
   // test rollback of deleteAll()
   public void testDeleteAllRollback() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(2)
         .setMaxBufferedDeleteTerms(2));
     
@@ -334,8 +326,8 @@
 
   // test deleteAll() w/ near real-time reader
   public void testDeleteAllNRT() throws IOException {
-    Directory dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDocs(2)
         .setMaxBufferedDeleteTerms(2));
     
@@ -424,10 +416,10 @@
     int END_COUNT = 144;
 
     // First build up a starting index:
-    MockDirectoryWrapper startDir = newDirectory(random);
+    MockDirectoryWrapper startDir = newDirectory();
     // TODO: find the resource leak that only occurs sometimes here.
     startDir.setNoDeleteOpenFile(false);
-    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     for (int i = 0; i < 157; i++) {
       Document d = new Document();
       d.add(new Field("id", Integer.toString(i), Field.Store.YES,
@@ -450,7 +442,7 @@
       MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));
       dir.setPreventDoubleWrite(false);
       IndexWriter modifier = new IndexWriter(dir,
-                                             newIndexWriterConfig(random,
+                                             newIndexWriterConfig(
                                                                   TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false))
                                              .setMaxBufferedDocs(1000)
                                              .setMaxBufferedDeleteTerms(1000)
@@ -663,8 +655,8 @@
         "Venice has lots of canals" };
     String[] text = { "Amsterdam", "Venice" };
 
-    MockDirectoryWrapper dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random,
+    MockDirectoryWrapper dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(
                                                                      TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).setMaxBufferedDeleteTerms(2).setReaderPooling(false));
     LogMergePolicy lmp = (LogMergePolicy) modifier.getConfig().getMergePolicy();
     lmp.setUseCompoundFile(true);
@@ -773,8 +765,8 @@
         "Venice has lots of canals" };
     String[] text = { "Amsterdam", "Venice" };
 
-    MockDirectoryWrapper dir = newDirectory(random);
-    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    MockDirectoryWrapper dir = newDirectory();
+    IndexWriter modifier = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     modifier.commit();
     dir.failOn(failure.reset());
 
@@ -801,7 +793,7 @@
   }
 
   public void testDeleteNullQuery() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     IndexWriter modifier = new IndexWriter(dir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), IndexWriter.MaxFieldLength.UNLIMITED);
 
     for (int i = 0; i < 5; i++) {
Index: lucene/src/test/org/apache/lucene/index/TestDirectoryReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestDirectoryReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestDirectoryReader.java	(working copy)
@@ -35,9 +35,7 @@
   private Document doc2;
   protected SegmentReader [] readers = new SegmentReader[2];
   protected SegmentInfos sis;
-  private Random random;
   
-  
   public TestDirectoryReader(String s) {
     super(s);
   }
@@ -45,8 +43,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     doc1 = new Document();
     doc2 = new Document();
     DocHelper.setupDoc(doc1);
@@ -136,9 +133,9 @@
   }
         
   public void testIsCurrent() throws IOException {
-    Directory ramDir1=newDirectory(random);
+    Directory ramDir1=newDirectory();
     addDoc(random, ramDir1, "test foo", true);
-    Directory ramDir2=newDirectory(random);
+    Directory ramDir2=newDirectory();
     addDoc(random, ramDir2, "test blah", true);
     IndexReader[] readers = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir2, false)};
     MultiReader mr = new MultiReader(readers);
@@ -159,11 +156,11 @@
   }
 
   public void testMultiTermDocs() throws IOException {
-    Directory ramDir1=newDirectory(random);
+    Directory ramDir1=newDirectory();
     addDoc(random, ramDir1, "test foo", true);
-    Directory ramDir2=newDirectory(random);
+    Directory ramDir2=newDirectory();
     addDoc(random, ramDir2, "test blah", true);
-    Directory ramDir3=newDirectory(random);
+    Directory ramDir3=newDirectory();
     addDoc(random, ramDir3, "test wow", true);
 
     IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1, false), IndexReader.open(ramDir3, false)};
@@ -204,7 +201,7 @@
   }
 
   private void addDoc(Random random, Directory ramDir1, String s, boolean create) throws IOException {
-    IndexWriter iw = new IndexWriter(ramDir1, newIndexWriterConfig(random, 
+    IndexWriter iw = new IndexWriter(ramDir1, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, 
         new MockAnalyzer()).setOpenMode(
         create ? OpenMode.CREATE : OpenMode.APPEND));
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java	(working copy)
@@ -38,6 +38,7 @@
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.LuceneTestCaseJ4;
 import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ThreadInterruptedException;
@@ -45,14 +46,7 @@
 
 public class TestIndexWriterReader extends LuceneTestCase {
   static PrintStream infoStream;
-  private Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   public static int count(Term t, IndexReader r) throws IOException {
     int count = 0;
     DocsEnum td = MultiFields.getTermDocsEnum(r,
@@ -71,8 +65,8 @@
   public void testUpdateDocument() throws Exception {
     boolean optimize = true;
 
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     // create the index
     createIndexNoClose(!optimize, "index1", writer);
@@ -106,7 +100,7 @@
     assertEquals(0, count(new Term("id", id10), r3));
     assertEquals(1, count(new Term("id", Integer.toString(8000)), r3));
 
-    writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a b c", Field.Store.NO, Field.Index.ANALYZED));
     writer.addDocument(doc);
@@ -132,16 +126,16 @@
   public void testAddIndexes() throws Exception {
     boolean optimize = false;
 
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
     // create the index
     createIndexNoClose(!optimize, "index1", writer);
     writer.flush(false, true, true);
 
     // create a 2nd index
-    Directory dir2 = newDirectory(random);
-    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir2 = newDirectory();
+    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer2.setInfoStream(infoStream);
     createIndexNoClose(!optimize, "index2", writer2);
     writer2.close();
@@ -178,13 +172,13 @@
   public void testAddIndexes2() throws Exception {
     boolean optimize = false;
 
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
 
     // create a 2nd index
-    Directory dir2 = newDirectory(random);
-    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir2 = newDirectory();
+    IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer2.setInfoStream(infoStream);
     createIndexNoClose(!optimize, "index2", writer2);
     writer2.close();
@@ -212,8 +206,8 @@
   public void testDeleteFromIndexWriter() throws Exception {
     boolean optimize = true;
 
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderTermsIndexDivisor(2));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderTermsIndexDivisor(2));
     writer.setInfoStream(infoStream);
     // create the index
     createIndexNoClose(!optimize, "index1", writer);
@@ -251,7 +245,7 @@
     writer.close();
         
     // reopen the writer to verify the delete made it to the directory
-    writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
     IndexReader w2r1 = writer.getReader();
     assertEquals(0, count(new Term("id", id10), w2r1));
@@ -264,8 +258,8 @@
     final int numIter = 2;
     int numDirs = 3;
     
-    Directory mainDir = newDirectory(random);
-    IndexWriter mainWriter = new IndexWriter(mainDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory mainDir = newDirectory();
+    IndexWriter mainWriter = new IndexWriter(mainDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     mainWriter.setInfoStream(infoStream);
     AddDirectoriesThreads addDirThreads = new AddDirectoriesThreads(numIter, mainWriter);
     addDirThreads.launchThreads(numDirs);
@@ -307,8 +301,8 @@
     public AddDirectoriesThreads(int numDirs, IndexWriter mainWriter) throws Throwable {
       this.numDirs = numDirs;
       this.mainWriter = mainWriter;
-      addDir = newDirectory(random);
-      IndexWriter writer = new IndexWriter(addDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
+      addDir = newDirectory();
+      IndexWriter writer = new IndexWriter(addDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
       for (int i = 0; i < NUM_INIT_DOCS; i++) {
         Document doc = createDocument(i, "addindex", 4);
         writer.addDocument(doc);
@@ -413,8 +407,8 @@
    * IW.getReader
    */
   public void doTestIndexWriterReopenSegment(boolean optimize) throws Exception {
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
     IndexReader r1 = writer.getReader();
     assertEquals(0, r1.maxDoc());
@@ -451,7 +445,7 @@
     writer.close();
 
     // test whether the changes made it to the directory
-    writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     IndexReader w2r1 = writer.getReader();
     // insure the deletes were actually flushed to the directory
     assertEquals(200, w2r1.maxDoc());
@@ -490,7 +484,7 @@
   
   public static void createIndex(Random random, Directory dir1, String indexName,
       boolean multiSegment) throws IOException {
-    IndexWriter w = new IndexWriter(dir1, newIndexWriterConfig(random,
+    IndexWriter w = new IndexWriter(dir1, LuceneTestCaseJ4.newIndexWriterConfig(random,
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMergePolicy(new LogDocMergePolicy()));
     for (int i = 0; i < 100; i++) {
@@ -524,10 +518,10 @@
 
   public void testMergeWarmer() throws Exception {
 
-    Directory dir1 = newDirectory(random);
+    Directory dir1 = newDirectory();
     // Enroll warmer
     MyWarmer warmer = new MyWarmer();
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(2).setMergedSegmentWarmer(warmer).setMergeScheduler(new ConcurrentMergeScheduler()));
     writer.setInfoStream(infoStream);
@@ -559,8 +553,8 @@
   }
 
   public void testAfterCommit() throws Exception {
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new ConcurrentMergeScheduler()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new ConcurrentMergeScheduler()));
     writer.commit();
     writer.setInfoStream(infoStream);
 
@@ -592,8 +586,8 @@
 
   // Make sure reader remains usable even if IndexWriter closes
   public void testAfterClose() throws Exception {
-    Directory dir1 = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
 
     // create the index
@@ -621,8 +615,8 @@
 
   // Stress test reopen during addIndexes
   public void testDuringAddIndexes() throws Exception {
-    Directory dir1 = newDirectory(random);
-    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
 
@@ -699,8 +693,8 @@
 
   // Stress test reopen during add/delete
   public void testDuringAddDelete() throws Exception {
-    Directory dir1 = newDirectory(random);
-    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     writer.setInfoStream(infoStream);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
 
@@ -779,8 +773,8 @@
   }
 
   public void testExpungeDeletes() throws Throwable {
-    Directory dir = newDirectory(random);
-    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a b c", Field.Store.NO, Field.Index.ANALYZED));
     Field id = new Field("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
@@ -803,8 +797,8 @@
   }
 
   public void testDeletesNumDocs() throws Throwable {
-    Directory dir = newDirectory(random);
-    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "a b c", Field.Store.NO, Field.Index.ANALYZED));
     Field id = new Field("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
@@ -833,8 +827,8 @@
   
   public void testEmptyIndex() throws Exception {
     // Ensures that getReader works on an empty index, which hasn't been committed yet.
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     IndexReader r = w.getReader();
     assertEquals(0, r.numDocs());
     r.close();
@@ -843,8 +837,8 @@
   }
 
   public void testSegmentWarmer() throws Exception {
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
                                     .setMaxBufferedDocs(2).setReaderPooling(true));
     ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);
     w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {
Index: lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestFieldsReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestFieldsReader.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
-import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -47,7 +46,6 @@
   private Directory dir;
   private Document testDoc = new Document();
   private FieldInfos fieldInfos = null;
-  private Random random;
   private final static String TEST_SEGMENT_NAME = "_0";
 
   public TestFieldsReader(String s) {
@@ -60,9 +58,8 @@
     fieldInfos = new FieldInfos();
     DocHelper.setupDoc(testDoc);
     fieldInfos.add(testDoc);
-    random = newRandom();
-    dir = newDirectory(random);
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer());
+    dir = newDirectory();
+    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(false);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(false);
     IndexWriter writer = new IndexWriter(dir, conf);
@@ -302,7 +299,7 @@
     FSDirectory tmpDir = FSDirectory.open(file);
     assertTrue(tmpDir != null);
 
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE);
+    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(false);
     IndexWriter writer = new IndexWriter(tmpDir, conf);
     writer.addDocument(testDoc);
@@ -482,7 +479,7 @@
 
     try {
       Directory dir = new FaultyFSDirectory(indexDir);
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, 
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
           TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
       for(int i=0;i<2;i++)
         writer.addDocument(testDoc);
Index: lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java	(working copy)
@@ -30,8 +30,8 @@
   AtomicInteger seq = new AtomicInteger(1);
 
   public void testIndexing() throws Exception {
-    Directory mainDir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(mainDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+    Directory mainDir = newDirectory();
+    IndexWriter writer = new IndexWriter(mainDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
Index: lucene/src/test/org/apache/lucene/index/TestTransactionRollback.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTransactionRollback.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestTransactionRollback.java	(working copy)
@@ -25,7 +25,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.HashMap;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -45,7 +44,6 @@
 	
   private static final String FIELD_RECORD_ID = "record_id";
   private Directory dir;
-  private Random random;
 	
   //Rolls back index to a chosen ID
   private void rollBackLast(int id) throws Exception {
@@ -65,7 +63,7 @@
     if (last==null)
       throw new RuntimeException("Couldn't find commit point "+id);
 		
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(
         new RollbackDeletionPolicy(id)).setIndexCommit(last));
     Map<String,String> data = new HashMap<String,String>();
@@ -126,11 +124,10 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
+    dir = newDirectory();
     //Build index, of records 1 to 100, committing after each batch of 10
     IndexDeletionPolicy sdp=new KeepAllDeletionPolicy();
-    IndexWriter w=new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(sdp));
+    IndexWriter w=new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(sdp));
     for(int currentRecordId=1;currentRecordId<=100;currentRecordId++) {
       Document doc=new Document();
       doc.add(new Field(FIELD_RECORD_ID,""+currentRecordId,Field.Store.YES,Field.Index.ANALYZED));
@@ -204,7 +201,7 @@
     for(int i=0;i<2;i++) {
       // Unless you specify a prior commit point, rollback
       // should not work:
-      new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
           .setIndexDeletionPolicy(new DeleteLastCommitPolicy())).close();
       IndexReader r = IndexReader.open(dir, true);
       assertEquals(100, r.numDocs());
Index: lucene/src/test/org/apache/lucene/index/TestFilterIndexReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestFilterIndexReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestFilterIndexReader.java	(working copy)
@@ -30,7 +30,6 @@
 import org.apache.lucene.util.Bits;
 
 import java.io.IOException;
-import java.util.Random;
 
 public class TestFilterIndexReader extends LuceneTestCase {
 
@@ -130,9 +129,8 @@
    * @throws Exception on error
    */
   public void testFilterIndexReader() throws Exception {
-    Random random = newRandom();
-    Directory directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     Document d1 = new Document();
     d1.add(new Field("default","one two", Field.Store.YES, Field.Index.ANALYZED));
@@ -149,8 +147,8 @@
     writer.close();
 
     //IndexReader reader = new TestReader(IndexReader.open(directory, true));
-    Directory target = newDirectory(random);
-    writer = new IndexWriter(target, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory target = newDirectory();
+    writer = new IndexWriter(target, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     IndexReader reader = new TestReader(IndexReader.open(directory, true));
     writer.addIndexes(reader);
     writer.close();
Index: lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java	(working copy)
@@ -45,14 +45,14 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.BitVector;
 import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.LuceneTestCaseJ4;
 
 public class TestIndexReaderReopen extends LuceneTestCase {
     
   private File indexDir;
   
   public void testReopen() throws Exception {
-    Random random = newRandom();
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     
     createIndex(random, dir1, false);
     performDefaultTests(new TestReopen() {
@@ -70,7 +70,7 @@
     });
     dir1.close();
     
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     
     createIndex(random, dir2, true);
     performDefaultTests(new TestReopen() {
@@ -90,10 +90,9 @@
   }
   
   public void testParallelReaderReopen() throws Exception {
-    Random random = newRandom();
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     createIndex(random, dir1, true);
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     createIndex(random, dir2, true);
     
     performDefaultTests(new TestReopen() {
@@ -116,9 +115,9 @@
     dir1.close();
     dir2.close();
     
-    final Directory dir3 = newDirectory(random);
+    final Directory dir3 = newDirectory();
     createIndex(random, dir3, true);
-    final Directory dir4 = newDirectory(random);
+    final Directory dir4 = newDirectory();
     createIndex(random, dir4, true);
 
     performTestsWithExceptionInReopen(new TestReopen() {
@@ -152,29 +151,27 @@
   // try this once with reopen once recreate, on both RAMDir and FSDir.
   public void testCommitReopenFS () throws IOException {
     Directory dir = FSDirectory.open(indexDir);
-    doTestReopenWithCommit(newRandom(), dir, true);
+    doTestReopenWithCommit(random, dir, true);
     dir.close();
   }
   public void testCommitRecreateFS () throws IOException {
     Directory dir = FSDirectory.open(indexDir);
-    doTestReopenWithCommit(newRandom(), dir, false);
+    doTestReopenWithCommit(random, dir, false);
     dir.close();
   }
   public void testCommitReopenRAM () throws IOException {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     doTestReopenWithCommit(random, dir, true);
     dir.close();
   }
   public void testCommitRecreateRAM () throws IOException {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     doTestReopenWithCommit(random, dir, false);
     dir.close();
   }
 
   private void doTestReopenWithCommit (Random random, Directory dir, boolean withReopen) throws IOException {
-    IndexWriter iwriter = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter iwriter = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(
         OpenMode.CREATE).setMergeScheduler(new SerialMergeScheduler()));
     iwriter.commit();
@@ -218,11 +215,10 @@
   }
   
   public void testMultiReaderReopen() throws Exception {
-    Random random = newRandom();
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     createIndex(random, dir1, true);
 
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     createIndex(random, dir2, true);
 
     performDefaultTests(new TestReopen() {
@@ -245,10 +241,10 @@
     dir1.close();
     dir2.close();
     
-    final Directory dir3 = newDirectory(random);
+    final Directory dir3 = newDirectory();
     createIndex(random, dir3, true);
 
-    final Directory dir4 = newDirectory(random);
+    final Directory dir4 = newDirectory();
     createIndex(random, dir4, true);
 
     performTestsWithExceptionInReopen(new TestReopen() {
@@ -275,16 +271,15 @@
   }
 
   public void testMixedReaders() throws Exception {
-    Random random = newRandom();
-    final Directory dir1 = newDirectory(random);
+    final Directory dir1 = newDirectory();
     createIndex(random, dir1, true);
-    final Directory dir2 = newDirectory(random);
+    final Directory dir2 = newDirectory();
     createIndex(random, dir2, true);
-    final Directory dir3 = newDirectory(random);
+    final Directory dir3 = newDirectory();
     createIndex(random, dir3, false);
-    final Directory dir4 = newDirectory(random);
+    final Directory dir4 = newDirectory();
     createIndex(random, dir4, true);
-    final Directory dir5 = newDirectory(random);
+    final Directory dir5 = newDirectory();
     createIndex(random, dir5, false);
     
     performDefaultTests(new TestReopen() {
@@ -363,9 +358,8 @@
   }
   
   public void testReferenceCounting() throws IOException {
-    Random random = newRandom();
     for (int mode = 0; mode < 4; mode++) {
-      Directory dir1 = newDirectory(random);
+      Directory dir1 = newDirectory();
       createIndex(random, dir1, true);
      
       IndexReader reader0 = IndexReader.open(dir1, false);
@@ -469,11 +463,10 @@
 
 
   public void testReferenceCountingMultiReader() throws IOException {
-    Random random = newRandom();
     for (int mode = 0; mode <=1; mode++) {
-      Directory dir1 = newDirectory(random);
+      Directory dir1 = newDirectory();
       createIndex(random, dir1, false);
-      Directory dir2 = newDirectory(random);
+      Directory dir2 = newDirectory();
       createIndex(random, dir2, true);
       
       IndexReader reader1 = IndexReader.open(dir1, false);
@@ -541,11 +534,10 @@
   }
 
   public void testReferenceCountingParallelReader() throws IOException {
-    Random random = newRandom();
     for (int mode = 0; mode <=1; mode++) {
-      Directory dir1 = newDirectory(random);
+      Directory dir1 = newDirectory();
       createIndex(random, dir1, false);
-      Directory dir2 = newDirectory(random);
+      Directory dir2 = newDirectory();
       createIndex(random, dir2, true);
       
       IndexReader reader1 = IndexReader.open(dir1, false);
@@ -617,8 +609,7 @@
   }
   
   public void testNormsRefCounting() throws IOException {
-    Random random = newRandom();
-    Directory dir1 = newDirectory(random);
+    Directory dir1 = newDirectory();
     createIndex(random, dir1, false);
     
     IndexReader reader1 = IndexReader.open(dir1, false);
@@ -708,10 +699,9 @@
   }
   
   public void testThreadSafety() throws Exception {
-    Random random = newRandom();
-    final Directory dir = newDirectory(random);
+    final Directory dir = newDirectory();
     final int n = 30 * RANDOM_MULTIPLIER;
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     for (int i = 0; i < n; i++) {
       writer.addDocument(createDocument(i, 3));
@@ -957,7 +947,7 @@
   
   public static void createIndex(Random random, Directory dir, boolean multiSegment) throws IOException {
     IndexWriter.unlock(dir);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter w = new IndexWriter(dir, LuceneTestCaseJ4.newIndexWriterConfig(random,
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMergePolicy(new LogDocMergePolicy()));
     
@@ -1109,8 +1099,7 @@
   }
   
   public void testCloseOrig() throws Throwable {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     createIndex(random, dir, false);
     IndexReader r1 = IndexReader.open(dir, false);
     IndexReader r2 = IndexReader.open(dir, false);
@@ -1131,8 +1120,7 @@
   }
 
   public void testDeletes() throws Throwable {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     createIndex(random, dir, false); // Create an index with a bunch of docs (1 segment)
 
     modifyIndex(0, dir); // Get delete bitVector on 1st segment
@@ -1166,8 +1154,7 @@
   }
 
   public void testDeletes2() throws Throwable {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     createIndex(random, dir, false);
     // Get delete bitVector
     modifyIndex(0, dir);
@@ -1203,9 +1190,8 @@
   }
 
   public void testReopenOnCommit() throws Throwable {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    Directory dir = newDirectory();
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
                                                                    TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(new KeepAllCommits()).setMaxBufferedDocs(-1));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
     for(int i=0;i<4;i++) {
Index: lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java	(working copy)
@@ -26,7 +26,6 @@
 
 import java.io.IOException;
 import java.util.Collection;
-import java.util.Random;
 
 public class TestSegmentMerger extends LuceneTestCase {
   //The variables for the new merged segment
@@ -49,10 +48,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    mergedDir = newDirectory(random);
-    merge1Dir = newDirectory(random);
-    merge2Dir = newDirectory(random);
+    mergedDir = newDirectory();
+    merge1Dir = newDirectory();
+    merge2Dir = newDirectory();
     DocHelper.setupDoc(doc1);
     SegmentInfo info1 = DocHelper.writeDoc(merge1Dir, doc1);
     DocHelper.setupDoc(doc2);
Index: lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestAddIndexes.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -34,24 +33,17 @@
 import org.apache.lucene.search.PhraseQuery;
 
 public class TestAddIndexes extends LuceneTestCase {
-  private Random random;
   
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    random = newRandom();
-  }
-  
   public void testSimpleCase() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // two auxiliary directories
-    Directory aux = newDirectory(random);
-    Directory aux2 = newDirectory(random);
+    Directory aux = newDirectory();
+    Directory aux2 = newDirectory();
 
     IndexWriter writer = null;
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE));
     // add 100 documents
@@ -60,7 +52,7 @@
     writer.close();
     _TestUtil.checkIndex(dir);
 
-    writer = newWriter(aux, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
     // add 40 documents in separate files
@@ -68,14 +60,14 @@
     assertEquals(40, writer.maxDoc());
     writer.close();
 
-    writer = newWriter(aux2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
+    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     // add 40 documents in compound files
     addDocs2(writer, 50);
     assertEquals(50, writer.maxDoc());
     writer.close();
 
     // test doc count before segments are merged
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(100, writer.maxDoc());
     writer.addIndexes(new Directory[] { aux, aux2 });
     assertEquals(190, writer.maxDoc());
@@ -89,15 +81,15 @@
     verifyNumDocs(dir, 190);
 
     // now add another set in.
-    Directory aux3 = newDirectory(random);
-    writer = newWriter(aux3, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory aux3 = newDirectory();
+    writer = newWriter(aux3, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     // add 40 documents
     addDocs(writer, 40);
     assertEquals(40, writer.maxDoc());
     writer.close();
 
     // test doc count before segments are merged/index is optimized
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(190, writer.maxDoc());
     writer.addIndexes(new Directory[] { aux3 });
     assertEquals(230, writer.maxDoc());
@@ -111,7 +103,7 @@
     verifyTermDocs(dir, new Term("content", "bbb"), 50);
 
     // now optimize it.
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.optimize();
     writer.close();
 
@@ -123,12 +115,12 @@
     verifyTermDocs(dir, new Term("content", "bbb"), 50);
 
     // now add a single document
-    Directory aux4 = newDirectory(random);
-    writer = newWriter(aux4, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory aux4 = newDirectory();
+    writer = newWriter(aux4, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     addDocs2(writer, 1);
     writer.close();
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(230, writer.maxDoc());
     writer.addIndexes(new Directory[] { aux4 });
     assertEquals(231, writer.maxDoc());
@@ -146,12 +138,12 @@
 
   public void testWithPendingDeletes() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.addIndexes(new Directory[] {aux});
 
     // Adds 10 docs, then replaces them with another 10
@@ -183,12 +175,12 @@
 
   public void testWithPendingDeletes2() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
 
     // Adds 10 docs, then replaces them with another 10
     // docs, so 10 pending deletes:
@@ -221,12 +213,12 @@
 
   public void testWithPendingDeletes3() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
 
     // Adds 10 docs, then replaces them with another 10
     // docs, so 10 pending deletes:
@@ -261,31 +253,31 @@
   // case 0: add self or exceed maxMergeDocs, expect exception
   public void testAddSelf() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     IndexWriter writer = null;
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     // add 100 documents
     addDocs(writer, 100);
     assertEquals(100, writer.maxDoc());
     writer.close();
 
-    writer = newWriter(aux, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
+    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
     // add 140 documents in separate files
     addDocs(writer, 40);
     writer.close();
-    writer = newWriter(aux, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
+    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
     addDocs(writer, 100);
     writer.close();
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     try {
       // cannot add self
       writer.addIndexes(new Directory[] { aux, dir });
@@ -307,13 +299,13 @@
   // case 1: no tail segments
   public void testNoTailSegments() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, 
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
@@ -333,13 +325,13 @@
   // case 2: tail segments, invariants hold, no copy
   public void testNoCopySegments() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(9));
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(9));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
     addDocs(writer, 2);
 
@@ -357,13 +349,13 @@
   // case 3: tail segments, invariants hold, copy, invariants hold
   public void testNoMergeAfterCopy() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random, 
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
@@ -382,9 +374,9 @@
   // case 4: tail segments, invariants hold, copy, invariants not hold
   public void testMergeAfterCopy() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
+    Directory aux = newDirectory();
 
     setUpDirs(dir, aux);
 
@@ -395,7 +387,7 @@
     assertEquals(10, reader.numDocs());
     reader.close();
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = newWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(4));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
@@ -411,14 +403,14 @@
   // case 5: tail segments, invariants not hold
   public void testMoreMerges() throws IOException {
     // main directory
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     // auxiliary directory
-    Directory aux = newDirectory(random);
-    Directory aux2 = newDirectory(random);
+    Directory aux = newDirectory();
+    Directory aux2 = newDirectory();
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(aux2, newIndexWriterConfig(random,
+    IndexWriter writer = newWriter(aux2, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
@@ -441,7 +433,7 @@
     assertEquals(22, reader.numDocs());
     reader.close();
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(6));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
 
@@ -500,14 +492,14 @@
   private void setUpDirs(Directory dir, Directory aux) throws IOException {
     IndexWriter writer = null;
 
-    writer = newWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
+    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
     // add 1000 documents in 1 segment
     addDocs(writer, 1000);
     assertEquals(1000, writer.maxDoc());
     assertEquals(1, writer.getSegmentCount());
     writer.close();
 
-    writer = newWriter(aux, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
+    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
@@ -515,7 +507,7 @@
     for (int i = 0; i < 3; i++) {
       addDocs(writer, 10);
       writer.close();
-      writer = newWriter(aux, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(100));
+      writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(100));
       ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
       ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
       ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
@@ -528,12 +520,12 @@
   // LUCENE-1270
   public void testHangOnClose() throws IOException {
 
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     LogByteSizeMergePolicy lmp = new LogByteSizeMergePolicy();
     lmp.setUseCompoundFile(false);
     lmp.setUseCompoundDocStore(false);
     lmp.setMergeFactor(100);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setMaxBufferedDocs(5).setMergePolicy(lmp));
 
@@ -556,13 +548,13 @@
       writer.addDocument(doc2);
     writer.close();
 
-    Directory dir2 = newDirectory(random);
+    Directory dir2 = newDirectory();
     lmp = new LogByteSizeMergePolicy();
     lmp.setMinMergeMB(0.0001);
     lmp.setUseCompoundFile(false);
     lmp.setUseCompoundDocStore(false);
     lmp.setMergeFactor(4);
-    writer = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    writer = new IndexWriter(dir2, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(lmp));
     writer.addIndexes(new Directory[] {dir});
Index: lucene/src/test/org/apache/lucene/index/TestStressIndexing.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestStressIndexing.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestStressIndexing.java	(working copy)
@@ -23,12 +23,9 @@
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.*;
 
-import java.util.Random;
 import java.io.File;
 
 public class TestStressIndexing extends MultiCodecTestCase {
-  private Random RANDOM;
-
   private static abstract class TimedThread extends Thread {
     volatile boolean failed;
     int count;
@@ -82,7 +79,7 @@
       // Add 10 docs:
       for(int j=0; j<10; j++) {
         Document d = new Document();
-        int n = RANDOM.nextInt();
+        int n = random.nextInt();
         d.add(new Field("id", Integer.toString(nextID++), Field.Store.YES, Field.Index.NOT_ANALYZED));
         d.add(new Field("contents", English.intToEnglish(n), Field.Store.NO, Field.Index.ANALYZED));
         writer.addDocument(d);
@@ -118,7 +115,7 @@
     stress test.
   */
   public void runStressTest(Directory directory, MergeScheduler mergeScheduler) throws Exception {
-    IndexWriter modifier = new IndexWriter(directory, newIndexWriterConfig(RANDOM,
+    IndexWriter modifier = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(10).setMergeScheduler(
             mergeScheduler));
@@ -166,10 +163,8 @@
     FSDirectory.
   */
   public void testStressIndexAndSearching() throws Exception {
-    RANDOM = newRandom();
-
     // With ConcurrentMergeScheduler, in RAMDir
-    Directory directory = newDirectory(RANDOM);
+    Directory directory = newDirectory();
     runStressTest(directory, new ConcurrentMergeScheduler());
     directory.close();
 
Index: lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java	(working copy)
@@ -70,7 +70,7 @@
 
     Document doc = new Document();
     doc.add(new Field(field,val, Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS));
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, analyzer)
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
@@ -85,8 +85,7 @@
 
 
   public int doTest(int iter, int ndocs, int maxTF, float percentDocs) throws IOException {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     long start = System.currentTimeMillis();
     addDocs(random, dir, ndocs, "foo", "val", maxTF, percentDocs);
Index: lucene/src/test/org/apache/lucene/index/TestPayloads.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestPayloads.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestPayloads.java	(working copy)
@@ -50,7 +50,6 @@
     
     // Simple tests to test the Payload class
     public void testPayload() throws Exception {
-        rnd = newRandom();
         byte[] testData = "This is a test!".getBytes();
         Payload payload = new Payload(testData);
         assertEquals("Wrong payload length.", testData.length, payload.length());
@@ -99,10 +98,9 @@
     // Tests whether the DocumentWriter and SegmentMerger correctly enable the
     // payload bit in the FieldInfo
     public void testPayloadFieldBit() throws Exception {
-        rnd = newRandom();
-        Directory ram = newDirectory(rnd);
+        Directory ram = newDirectory();
         PayloadAnalyzer analyzer = new PayloadAnalyzer();
-        IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(rnd, TEST_VERSION_CURRENT, analyzer));
+        IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer));
         Document d = new Document();
         // this field won't have any payloads
         d.add(new Field("f1", "This field has no payloads", Field.Store.NO, Field.Index.ANALYZED));
@@ -129,7 +127,7 @@
         
         // now we add another document which has payloads for field f3 and verify if the SegmentMerger
         // enabled payloads for that field
-        writer = new IndexWriter(ram, newIndexWriterConfig(rnd, TEST_VERSION_CURRENT,
+        writer = new IndexWriter(ram, newIndexWriterConfig( TEST_VERSION_CURRENT,
             analyzer).setOpenMode(OpenMode.CREATE));
         d = new Document();
         d.add(new Field("f1", "This field has no payloads", Field.Store.NO, Field.Index.ANALYZED));
@@ -157,15 +155,14 @@
 
     // Tests if payloads are correctly stored and loaded using both RamDirectory and FSDirectory
     public void testPayloadsEncoding() throws Exception {
-        rnd = newRandom();
         // first perform the test using a RAMDirectory
-        Directory dir = newDirectory(rnd);
-        performTest(rnd, dir);
+        Directory dir = newDirectory();
+        performTest(random, dir);
         dir.close();
         // now use a FSDirectory and repeat same test
         File dirName = _TestUtil.getTempDir("test_payloads");
         dir = FSDirectory.open(dirName);
-        performTest(rnd, dir);
+        performTest(random, dir);
        _TestUtil.rmDir(dirName);
         dir.close();
     }
@@ -174,7 +171,7 @@
     // different tests to verify the payload encoding
     private void performTest(Random random, Directory dir) throws Exception {
         PayloadAnalyzer analyzer = new PayloadAnalyzer();
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, analyzer)
             .setOpenMode(OpenMode.CREATE));
         
@@ -315,7 +312,7 @@
         
         // test long payload
         analyzer = new PayloadAnalyzer();
-        writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
             analyzer).setOpenMode(OpenMode.CREATE));
         String singleTerm = "lucene";
         
@@ -349,10 +346,8 @@
         
     }
     
-    private Random rnd;
-    
     private void generateRandomData(byte[] data) {
-        rnd.nextBytes(data);
+        random.nextBytes(data);
     }
 
     private byte[] generateRandomData(int n) {
@@ -485,13 +480,12 @@
     }
     
     public void testThreadSafety() throws Exception {
-        rnd = newRandom();
         final int numThreads = 5;
         final int numDocs = 50 * RANDOM_MULTIPLIER;
         final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);
         
-        Directory dir = newDirectory(rnd);
-        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(rnd, 
+        Directory dir = newDirectory();
+        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
             TEST_VERSION_CURRENT, new MockAnalyzer()));
         final String field = "test";
         
Index: lucene/src/test/org/apache/lucene/index/TestLazyBug.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestLazyBug.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestLazyBug.java	(working copy)
@@ -67,10 +67,9 @@
     };
   
   private Directory makeIndex() throws Exception { 
-    Random r = newRandom();
-    Directory dir = newDirectory(r);
+    Directory dir = newDirectory();
     try {
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(r,
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()));
       LogMergePolicy lmp = (LogMergePolicy) writer.getConfig().getMergePolicy();
       lmp.setUseCompoundFile(false);
@@ -81,7 +80,7 @@
         for (int f = 1; f <= NUM_FIELDS; f++ ) {
           doc.add(new Field("f"+f, 
                             data[f % data.length] 
-                            + '#' + data[r.nextInt(data.length)], 
+                            + '#' + data[random.nextInt(data.length)], 
                             Field.Store.YES, 
                             Field.Index.ANALYZED));
         }
Index: lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java	(working copy)
@@ -34,11 +34,10 @@
    * change the index order of documents.
    */
   public void testLucene() throws IOException {
-    Random random = newRandom();
     int num=100;
 
-    Directory indexA = newDirectory(random);
-    Directory indexB = newDirectory(random);
+    Directory indexA = newDirectory();
+    Directory indexB = newDirectory();
 
     fillIndex(random, indexA, 0, num);
     boolean fail = verifyIndex(indexA, 0);
@@ -54,9 +53,9 @@
       fail("Index b is invalid");
     }
 
-    Directory merged = newDirectory(random);
+    Directory merged = newDirectory();
 
-    IndexWriter writer = new IndexWriter(merged, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(merged, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
 
     writer.addIndexes(new Directory[]{indexA, indexB});
@@ -95,7 +94,7 @@
 
   private void fillIndex(Random random, Directory dir, int start, int numDocs) throws IOException {
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, 
         new MockAnalyzer())
         .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2));
Index: lucene/src/test/org/apache/lucene/index/TestParallelReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestParallelReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestParallelReader.java	(working copy)
@@ -39,13 +39,11 @@
 
   private IndexSearcher parallel;
   private IndexSearcher single;
-  private Random random;
   private Directory dir, dir1, dir2;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
     single = single(random);
     parallel = parallel(random);
   }
@@ -122,8 +120,8 @@
     Directory dir1 = getDir1(random);
 
     // one document only:
-    Directory dir2 = newDirectory(random);
-    IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir2 = newDirectory();
+    IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document d3 = new Document();
     d3.add(new Field("f3", "v1", Field.Store.YES, Field.Index.ANALYZED));
     w2.addDocument(d3);
@@ -176,14 +174,14 @@
     Directory dir2 = getDir2(random);
     
     // add another document to ensure that the indexes are not optimized
-    IndexWriter modifier = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter modifier = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     ((LogMergePolicy) modifier.getMergePolicy()).setMergeFactor(10);
     Document d = new Document();
     d.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     modifier.addDocument(d);
     modifier.close();
     
-    modifier = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    modifier = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     ((LogMergePolicy) modifier.getMergePolicy()).setMergeFactor(10);
     d = new Document();
     d.add(new Field("f2", "v2", Field.Store.YES, Field.Index.ANALYZED));
@@ -197,7 +195,7 @@
     assertFalse(pr.isOptimized());
     pr.close();
     
-    modifier = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    modifier = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     modifier.optimize();
     modifier.close();
     
@@ -209,7 +207,7 @@
     pr.close();
 
     
-    modifier = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    modifier = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     modifier.optimize();
     modifier.close();
     
@@ -240,8 +238,8 @@
 
   // Fields 1-4 indexed together:
   private IndexSearcher single(Random random) throws IOException {
-    dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document d1 = new Document();
     d1.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d1.add(new Field("f2", "v1", Field.Store.YES, Field.Index.ANALYZED));
@@ -270,8 +268,8 @@
   }
 
   private Directory getDir1(Random random) throws IOException {
-    Directory dir1 = newDirectory(random);
-    IndexWriter w1 = new IndexWriter(dir1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir1 = newDirectory();
+    IndexWriter w1 = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document d1 = new Document();
     d1.add(new Field("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d1.add(new Field("f2", "v1", Field.Store.YES, Field.Index.ANALYZED));
@@ -285,8 +283,8 @@
   }
 
   private Directory getDir2(Random random) throws IOException {
-    Directory dir2 = newDirectory(random);
-    IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir2 = newDirectory();
+    IndexWriter w2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document d3 = new Document();
     d3.add(new Field("f3", "v1", Field.Store.YES, Field.Index.ANALYZED));
     d3.add(new Field("f4", "v1", Field.Store.YES, Field.Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/index/codecs/intblock/TestIntBlockCodec.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/codecs/intblock/TestIntBlockCodec.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/codecs/intblock/TestIntBlockCodec.java	(working copy)
@@ -25,7 +25,7 @@
 public class TestIntBlockCodec extends LuceneTestCase {
 
   public void testSimpleIntBlocks() throws Exception {
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
 
     IntStreamFactory f = new MockFixedIntBlockCodec(128).getIntFactory();
 
@@ -47,7 +47,7 @@
   }
 
   public void testEmptySimpleIntBlocks() throws Exception {
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
 
     IntStreamFactory f = new MockFixedIntBlockCodec(128).getIntFactory();
     IntIndexOutput out = f.createOutput(dir, "test");
Index: lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates.java	(working copy)
@@ -272,15 +272,13 @@
 
   @Test
   public void testSurrogatesOrder() throws Exception {
-    Random r = newRandom();
-
-    Directory dir = newDirectory(r);
-    RandomIndexWriter w = new RandomIndexWriter(r,
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random,
                                                 dir,
-                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,
+                                                newIndexWriterConfig( TEST_VERSION_CURRENT,
                                                                       new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));
 
-    final int numField = _TestUtil.nextInt(r, 2, 5);
+    final int numField = _TestUtil.nextInt(random, 2, 5);
 
     int uniqueTermCount = 0;
 
@@ -295,7 +293,7 @@
       final Set<String> uniqueTerms = new HashSet<String>();
 
       for(int i=0;i<numTerms;i++) {
-        String term = getRandomString(r) + "_ " + (tc++);
+        String term = getRandomString(random) + "_ " + (tc++);
         uniqueTerms.add(term);
         fieldTerms.add(new Term(field, term));
         Document doc = new Document();
@@ -334,8 +332,8 @@
     //assertNotNull(fields);
 
     doTestStraightEnum(fieldTerms, reader, uniqueTermCount);
-    doTestSeekExists(r, fieldTerms, reader);
-    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);
+    doTestSeekExists(random, fieldTerms, reader);
+    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);
 
     reader.close();
     w.close();
Index: lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.IOException;
 import java.util.HashSet;
 import java.util.List;
-import java.util.Random;
 import java.util.Set;
 import java.util.Collection;
 
@@ -197,11 +196,10 @@
     final double SECONDS = 2.0;
 
     boolean useCompoundFile = true;
-    Random random = newRandom();
     
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     ExpirationTimeDeletionPolicy policy = new ExpirationTimeDeletionPolicy(dir, SECONDS);
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setIndexDeletionPolicy(policy);
     LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -217,7 +215,7 @@
       // Record last time when writer performed deletes of
       // past commits
       lastDeleteTime = System.currentTimeMillis();
-      conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
           OpenMode.APPEND).setIndexDeletionPolicy(policy);
       lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -284,8 +282,6 @@
    * Test a silly deletion policy that keeps all commits around.
    */
   public void testKeepAllDeletionPolicy() throws IOException {
-    Random random = newRandom();
-    
     for(int pass=0;pass<2;pass++) {
 
       boolean useCompoundFile = (pass % 2) != 0;
@@ -293,10 +289,10 @@
       // Never deletes a commit
       KeepAllDeletionPolicy policy = new KeepAllDeletionPolicy();
 
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
       policy.dir = dir;
 
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setIndexDeletionPolicy(policy).setMaxBufferedDocs(10)
           .setMergeScheduler(new SerialMergeScheduler());
@@ -310,7 +306,7 @@
       }
       writer.close();
 
-      conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+      conf = newIndexWriterConfig(TEST_VERSION_CURRENT,
           new MockAnalyzer()).setOpenMode(
           OpenMode.APPEND).setIndexDeletionPolicy(policy);
       lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -353,7 +349,7 @@
           // Open & close a writer and assert that it
           // actually removed something:
           int preCount = dir.listAll().length;
-          writer = new IndexWriter(dir, newIndexWriterConfig(random,
+          writer = new IndexWriter(dir, newIndexWriterConfig(
               TEST_VERSION_CURRENT,
               new MockAnalyzer()).setOpenMode(
               OpenMode.APPEND).setIndexDeletionPolicy(policy));
@@ -371,15 +367,13 @@
    * then, opens a new IndexWriter on a previous commit
    * point. */
   public void testOpenPriorSnapshot() throws IOException {
-    Random random = newRandom();
-    
     // Never deletes a commit
     KeepAllDeletionPolicy policy = new KeepAllDeletionPolicy();
 
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     policy.dir = dir;
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer())
         .setIndexDeletionPolicy(policy).setMaxBufferedDocs(2));
     ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
@@ -400,7 +394,7 @@
     assertTrue(lastCommit != null);
 
     // Now add 1 doc and optimize
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(policy));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(policy));
     addDoc(writer);
     assertEquals(11, writer.numDocs());
     writer.optimize();
@@ -409,7 +403,7 @@
     assertEquals(6, IndexReader.listCommits(dir).size());
 
     // Now open writer on the commit just before optimize:
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
         .setIndexDeletionPolicy(policy).setIndexCommit(lastCommit));
     assertEquals(10, writer.numDocs());
 
@@ -422,7 +416,7 @@
     assertEquals(11, r.numDocs());
     r.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
         .setIndexDeletionPolicy(policy).setIndexCommit(lastCommit));
     assertEquals(10, writer.numDocs());
     // Commits the rollback:
@@ -439,7 +433,7 @@
     r.close();
 
     // Reoptimize
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(policy));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(policy));
     writer.optimize();
     writer.close();
 
@@ -450,7 +444,7 @@
 
     // Now open writer on the commit just before optimize,
     // but this time keeping only the last commit:
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexCommit(lastCommit));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexCommit(lastCommit));
     assertEquals(10, writer.numDocs());
     
     // Reader still sees optimized index, because writer
@@ -477,17 +471,15 @@
    * you know there are no readers.
    */
   public void testKeepNoneOnInitDeletionPolicy() throws IOException {
-    Random random = newRandom();
-    
     for(int pass=0;pass<2;pass++) {
 
       boolean useCompoundFile = (pass % 2) != 0;
 
       KeepNoneOnInitDeletionPolicy policy = new KeepNoneOnInitDeletionPolicy();
 
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
 
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.CREATE).setIndexDeletionPolicy(policy)
           .setMaxBufferedDocs(10);
@@ -500,7 +492,7 @@
       }
       writer.close();
 
-      conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.APPEND).setIndexDeletionPolicy(policy);
       lmp = (LogMergePolicy) conf.getMergePolicy();
       lmp.setUseCompoundFile(useCompoundFile);
@@ -527,19 +519,18 @@
    * Test a deletion policy that keeps last N commits.
    */
   public void testKeepLastNDeletionPolicy() throws IOException {
-    Random random = newRandom();
     final int N = 5;
 
     for(int pass=0;pass<2;pass++) {
 
       boolean useCompoundFile = (pass % 2) != 0;
 
-      Directory dir = newDirectory(random);
+      Directory dir = newDirectory();
 
       KeepLastNDeletionPolicy policy = new KeepLastNDeletionPolicy(N);
 
       for(int j=0;j<N+1;j++) {
-        IndexWriterConfig conf = newIndexWriterConfig(random,
+        IndexWriterConfig conf = newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer())
             .setOpenMode(OpenMode.CREATE).setIndexDeletionPolicy(policy)
             .setMaxBufferedDocs(10);
@@ -589,8 +580,6 @@
    * around, with reader doing deletes.
    */
   public void testKeepLastNDeletionPolicyWithReader() throws IOException {
-    Random random = newRandom();
-    
     final int N = 10;
 
     for(int pass=0;pass<2;pass++) {
@@ -599,8 +588,8 @@
 
       KeepLastNDeletionPolicy policy = new KeepLastNDeletionPolicy(N);
 
-      Directory dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      Directory dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.CREATE).setIndexDeletionPolicy(policy);
       LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -612,7 +601,7 @@
       Query query = new TermQuery(searchTerm);
 
       for(int i=0;i<N+1;i++) {
-        conf = newIndexWriterConfig(random,
+        conf = newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer())
             .setOpenMode(OpenMode.APPEND).setIndexDeletionPolicy(policy);
         lmp = (LogMergePolicy) conf.getMergePolicy();
@@ -634,7 +623,7 @@
         reader.close();
         searcher.close();
       }
-      conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
+      conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.APPEND).setIndexDeletionPolicy(policy);
       lmp = (LogMergePolicy) conf.getMergePolicy();
       lmp.setUseCompoundFile(useCompoundFile);
@@ -698,7 +687,6 @@
    * around, through creates.
    */
   public void testKeepLastNDeletionPolicyWithCreates() throws IOException {
-    Random random = newRandom();
     
     final int N = 10;
 
@@ -708,8 +696,8 @@
 
       KeepLastNDeletionPolicy policy = new KeepLastNDeletionPolicy(N);
 
-      Directory dir = newDirectory(random);
-      IndexWriterConfig conf = newIndexWriterConfig(random,
+      Directory dir = newDirectory();
+      IndexWriterConfig conf = newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setOpenMode(OpenMode.CREATE).setIndexDeletionPolicy(policy)
           .setMaxBufferedDocs(10);
@@ -723,7 +711,7 @@
 
       for(int i=0;i<N+1;i++) {
 
-        conf = newIndexWriterConfig(random,
+        conf = newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer())
             .setOpenMode(OpenMode.APPEND).setIndexDeletionPolicy(policy)
             .setMaxBufferedDocs(10);
@@ -746,7 +734,7 @@
         reader.close();
         searcher.close();
 
-        writer = new IndexWriter(dir, newIndexWriterConfig(random,
+        writer = new IndexWriter(dir, newIndexWriterConfig(
             TEST_VERSION_CURRENT, new MockAnalyzer())
             .setOpenMode(OpenMode.CREATE).setIndexDeletionPolicy(policy));
         // This will not commit: there are no changes
Index: lucene/src/test/org/apache/lucene/index/TestSegmentReader.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestSegmentReader.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestSegmentReader.java	(working copy)
@@ -43,7 +43,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    dir = newDirectory(newRandom());
+    dir = newDirectory();
     DocHelper.setupDoc(testDoc);
     SegmentInfo info = DocHelper.writeDoc(dir, testDoc);
     reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
Index: lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
@@ -46,16 +45,15 @@
    * @throws IOException
    */
   public void testEmptyIndex() throws IOException {
-    Random random = newRandom();
-    Directory rd1 = newDirectory(random);
-    IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory rd1 = newDirectory();
+    IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     iw.close();
 
-    Directory rd2 = newDirectory(random, rd1);
+    Directory rd2 = newDirectory(rd1);
 
-    Directory rdOut = newDirectory(random);
+    Directory rdOut = newDirectory();
 
-    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     ParallelReader pr = new ParallelReader();
     pr.add(IndexReader.open(rd1,true));
     pr.add(IndexReader.open(rd2,true));
@@ -77,10 +75,9 @@
    * any exception.
    */
   public void testEmptyIndexWithVectors() throws IOException {
-    Random random = newRandom();
-    Directory rd1 = newDirectory(random);
+    Directory rd1 = newDirectory();
     {
-      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       Document doc = new Document();
       doc.add(new Field("test", "", Store.NO, Index.ANALYZED,
                         TermVector.YES));
@@ -94,22 +91,22 @@
       ir.deleteDocument(0);
       ir.close();
 
-      iw = new IndexWriter(rd1, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
       iw.optimize();
       iw.close();
     }
 
-    Directory rd2 = newDirectory(random);
+    Directory rd2 = newDirectory();
     {
-      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
       Document doc = new Document();
       iw.addDocument(doc);
       iw.close();
     }
 
-    Directory rdOut = newDirectory(random);
+    Directory rdOut = newDirectory();
 
-    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
     ParallelReader pr = new ParallelReader();
     pr.add(IndexReader.open(rd1,true));
     pr.add(IndexReader.open(rd2,true));
Index: lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java	(working copy)
@@ -148,7 +148,6 @@
   
   /** This test checks that *only* IndexFormatTooOldExceptions are throws when you open and operate on too old indexes! */
   public void testUnsupportedOldIndexes() throws Exception {
-    final Random rnd = newRandom();
     for(int i=0;i<unsupportedNames.length;i++) {
       unzip(getDataFile("unsupported." + unsupportedNames[i] + ".zip"), unsupportedNames[i]);
 
@@ -168,12 +167,12 @@
       }
 
       try {
-        writer = new IndexWriter(dir, newIndexWriterConfig(rnd,
+        writer = new IndexWriter(dir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
           .setMergeScheduler(new SerialMergeScheduler()) // no threads!
         );
         // TODO: Make IndexWriter fail on open!
-        if (rnd.nextBoolean()) {
+        if (random.nextBoolean()) {
           writer.optimize();
         } else {
           reader = writer.getReader();
@@ -220,14 +219,13 @@
   }
 
   public void testAddOldIndexes() throws IOException {
-    Random random = newRandom();
     for (String name : oldNames) {
       unzip(getDataFile("index." + name + ".zip"), name);
       String fullPath = fullDir(name);
       Directory dir = FSDirectory.open(new File(fullPath));
 
-      Directory targetDir = newDirectory(random);
-      IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(random,
+      Directory targetDir = newDirectory();
+      IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()));
       w.addIndexes(new Directory[] { dir });
       w.close();
@@ -241,15 +239,14 @@
   }
 
   public void testAddOldIndexesReader() throws IOException {
-    Random random = newRandom();
     for (String name : oldNames) {
       unzip(getDataFile("index." + name + ".zip"), name);
       String fullPath = fullDir(name);
       Directory dir = FSDirectory.open(new File(fullPath));
       IndexReader reader = IndexReader.open(dir);
       
-      Directory targetDir = newDirectory(random);
-      IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(random,
+      Directory targetDir = newDirectory();
+      IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()));
       w.addIndexes(new IndexReader[] { reader });
       w.close();
@@ -272,7 +269,6 @@
   }
 
   public void testIndexOldIndexNoAdds() throws IOException {
-    Random random = newRandom();
     for(int i=0;i<oldNames.length;i++) {
       unzip(getDataFile("index." + oldNames[i] + ".zip"), oldNames[i]);
       changeIndexNoAdds(random, oldNames[i]);
@@ -281,7 +277,6 @@
   }
 
   public void testIndexOldIndex() throws IOException {
-    Random random = newRandom();
     for(int i=0;i<oldNames.length;i++) {
       unzip(getDataFile("index." + oldNames[i] + ".zip"), oldNames[i]);
       changeIndexWithAdds(random, oldNames[i]);
@@ -371,7 +366,7 @@
 
     Directory dir = FSDirectory.open(new File(dirName));
     // open writer
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     // add 10 docs
     for(int i=0;i<10;i++) {
       addDoc(writer, 35+i);
@@ -415,7 +410,7 @@
     searcher.close();
 
     // optimize
-    writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.optimize();
     writer.close();
 
@@ -462,7 +457,7 @@
     searcher.close();
 
     // optimize
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     writer.optimize();
     writer.close();
 
@@ -484,7 +479,7 @@
     dirName = fullDir(dirName);
 
     Directory dir = FSDirectory.open(new File(dirName));
-    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
+    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);
     IndexWriter writer = new IndexWriter(dir, conf);
@@ -496,7 +491,7 @@
     writer.close();
 
     // open fresh writer so we get no prx file in the added segment
-    conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
+    conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);
     ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);
     writer = new IndexWriter(dir, conf);
@@ -524,7 +519,7 @@
     try {
       Directory dir = FSDirectory.open(new File(fullDir(outputDir)));
 
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));
+      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));
       ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);
       ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
       for(int i=0;i<35;i++) {
Index: lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java	(working copy)
@@ -68,7 +68,7 @@
         int numDocs = 500;
         
         Directory directory = new SeekCountingDirectory(new RAMDirectory());
-        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
+        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
         ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
         ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
         for (int i = 0; i < numDocs; i++) {
@@ -120,15 +120,13 @@
     
     public void testLazySkipping() throws IOException {
         // test whether only the minimum amount of seeks() are performed
-        Random random = newRandom();
         performTest(random, 5);
         performTest(random, 10);
     }
     
     public void testSeek() throws IOException {
-        Random random = newRandom();
-        Directory directory = newDirectory(random);
-        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+        Directory directory = newDirectory();
+        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
         for (int i = 0; i < 10; i++) {
             Document doc = new Document();
             doc.add(new Field(this.field, "a b", Field.Store.YES, Field.Index.ANALYZED));
Index: lucene/src/test/org/apache/lucene/index/TestNorms.java
===================================================================
--- lucene/src/test/org/apache/lucene/index/TestNorms.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/index/TestNorms.java	(working copy)
@@ -74,8 +74,7 @@
    * Including optimize. 
    */
   public void testNorms() throws IOException {
-    Random random = newRandom();
-    Directory dir1 = newDirectory(random);
+    Directory dir1 = newDirectory();
 
     norms = new ArrayList<Float>();
     modifiedNorms = new ArrayList<Float>();
@@ -92,16 +91,16 @@
     modifiedNorms = new ArrayList<Float>();
     numDocNorms = 0;
     
-    Directory dir2 = newDirectory(random);
+    Directory dir2 = newDirectory();
 
     createIndex(random, dir2);
     doTestNorms(random, dir2);
 
     // add index1 and index2 to a third index: index3
-    Directory dir3 = newDirectory(random);
+    Directory dir3 = newDirectory();
 
     createIndex(random, dir3);
-    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(random,
+    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
         .setMaxBufferedDocs(5));
     ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
@@ -120,7 +119,7 @@
     doTestNorms(random, dir3);
     
     // now with optimize
-    iw = new IndexWriter(dir3, newIndexWriterConfig(random, TEST_VERSION_CURRENT,
+    iw = new IndexWriter(dir3, newIndexWriterConfig( TEST_VERSION_CURRENT,
         anlzr).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(5));
     ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
     iw.optimize();
@@ -146,7 +145,7 @@
   }
 
   private void createIndex(Random random, Directory dir) throws IOException {
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.CREATE)
         .setMaxBufferedDocs(5).setSimilarity(similarityOne));
     LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
@@ -191,7 +190,7 @@
   }
 
   private void addDocs(Random random, Directory dir, int ndocs, boolean compound) throws IOException {
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
         .setMaxBufferedDocs(5).setSimilarity(similarityOne));
     LogMergePolicy lmp = (LogMergePolicy) iw.getConfig().getMergePolicy();
Index: lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java
===================================================================
--- lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/TestSearchForDuplicates.java	(working copy)
@@ -59,7 +59,6 @@
   public void testRun() throws Exception {
       StringWriter sw = new StringWriter();
       PrintWriter pw = new PrintWriter(sw, true);
-      Random random = newRandom();
       doTest(random, pw, false);
       pw.close();
       sw.close();
@@ -78,9 +77,9 @@
 
 
   private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {
-      Directory directory = newDirectory(random);
+      Directory directory = newDirectory();
       Analyzer analyzer = new MockAnalyzer();
-      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer);
+      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);
       LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();
       lmp.setUseCompoundFile(useCompoundFiles);
       lmp.setUseCompoundDocStore(useCompoundFiles);
Index: lucene/src/test/org/apache/lucene/store/TestCopyBytes.java
===================================================================
--- lucene/src/test/org/apache/lucene/store/TestCopyBytes.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/store/TestCopyBytes.java	(working copy)
@@ -18,8 +18,6 @@
  */
 
 
-import java.io.IOException;
-import java.util.Random;
 import org.apache.lucene.util.LuceneTestCaseJ4;
 import org.apache.lucene.util._TestUtil;
 
@@ -35,17 +33,16 @@
 
   @Test
   public void testCopyBytes() throws Exception {
-    Random rand = newRandom();
     for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {
-      Directory dir = newDirectory(rand);
+      Directory dir = newDirectory();
       if (VERBOSE) {
         System.out.println("TEST: iter=" + iter + " dir=" + dir);
       }
 
       // make random file
       IndexOutput out = dir.createOutput("test");
-      byte[] bytes = new byte[_TestUtil.nextInt(rand, 1, 77777)];
-      final int size = _TestUtil.nextInt(rand, 1, 1777777);
+      byte[] bytes = new byte[_TestUtil.nextInt(random, 1, 77777)];
+      final int size = _TestUtil.nextInt(random, 1, 1777777);
       int upto = 0;
       int byteUpto = 0;
       while(upto < size) {
@@ -69,11 +66,11 @@
 
       upto = 0;
       while(upto < size) {
-        if (rand.nextBoolean()) {
+        if (random.nextBoolean()) {
           out.writeByte(in.readByte());
           upto++;
         } else {
-          final int chunk = Math.min(_TestUtil.nextInt(rand, 1, bytes.length), size-upto);
+          final int chunk = Math.min(_TestUtil.nextInt(random, 1, bytes.length), size-upto);
           out.copyBytes(in, chunk);
           upto += chunk;
         }
@@ -86,12 +83,12 @@
       IndexInput in2 = dir.openInput("test2");
       upto = 0;
       while(upto < size) {
-        if (rand.nextBoolean()) {
+        if (random.nextBoolean()) {
           final byte v = in2.readByte();
           assertEquals(value(upto), v);
           upto++;
         } else {
-          final int limit = Math.min(_TestUtil.nextInt(rand, 1, bytes.length), size-upto);
+          final int limit = Math.min(_TestUtil.nextInt(random, 1, bytes.length), size-upto);
           in2.readBytes(bytes, 0, limit);
           for(int byteIdx=0;byteIdx<limit;byteIdx++) {
             assertEquals(value(upto), bytes[byteIdx]);
Index: lucene/src/test/org/apache/lucene/store/TestMultiMMap.java
===================================================================
--- lucene/src/test/org/apache/lucene/store/TestMultiMMap.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/store/TestMultiMMap.java	(working copy)
@@ -45,7 +45,6 @@
   }
   
   public void testRandomChunkSizes() throws Exception {
-    Random random = newRandom();
     for (int i = 0; i < 10*RANDOM_MULTIPLIER; i++)
       assertChunking(random, _TestUtil.nextInt(random, 20, 100));
   }
Index: lucene/src/test/org/apache/lucene/store/TestWindowsMMap.java
===================================================================
--- lucene/src/test/org/apache/lucene/store/TestWindowsMMap.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/store/TestWindowsMMap.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
 import java.io.File;
 
 import org.apache.lucene.util.LuceneTestCase;
@@ -33,12 +32,10 @@
 public class TestWindowsMMap extends LuceneTestCase {
   
   private final static String alphabet = "abcdefghijklmnopqrstuvwzyz";
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
   }
   
   private String randomToken() {
Index: lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
===================================================================
--- lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java	(working copy)
@@ -78,10 +78,8 @@
   // Our input comes from a dynamically generated "file" -
   // see MyBufferedIndexInput below.
   public void testReadBytes() throws Exception {
-    final Random r = newRandom();
-
     MyBufferedIndexInput input = new MyBufferedIndexInput();
-    runReadBytes(input, BufferedIndexInput.BUFFER_SIZE, r);
+    runReadBytes(input, BufferedIndexInput.BUFFER_SIZE, random);
 
     // This tests the workaround code for LUCENE-1566 where readBytesInternal
     // provides a workaround for a JVM Bug that incorrectly raises a OOM Error
@@ -95,11 +93,11 @@
 
     // run test with chunk size of 10 bytes
     runReadBytesAndClose(new SimpleFSIndexInput(tmpInputFile,
-                                                inputBufferSize, 10), inputBufferSize, r);
+                                                inputBufferSize, 10), inputBufferSize, random);
 
     // run test with chunk size of 10 bytes
     runReadBytesAndClose(new NIOFSIndexInput(tmpInputFile,
-                                             inputBufferSize, 10), inputBufferSize, r);
+                                             inputBufferSize, 10), inputBufferSize, random);
   }
 
   private void runReadBytesAndClose(IndexInput input, int bufferSize, Random r)
@@ -243,7 +241,7 @@
 
     public void testSetBufferSize() throws IOException {
       File indexDir = new File(TEMP_DIR, "testSetBufferSize");
-      MockFSDirectory dir = new MockFSDirectory(indexDir, newRandom());
+      MockFSDirectory dir = new MockFSDirectory(indexDir, random);
       try {
         IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer())
Index: lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/LuceneTestCaseJ4.java	(working copy)
@@ -156,6 +156,8 @@
   static final String TEST_DIRECTORY = System.getProperty("tests.directory", "random");
   /** Get the number of times to run tests */
   static final int TEST_ITER = Integer.parseInt(System.getProperty("tests.iter", "1"));
+  /** Get the random seed for tests */
+  static final String TEST_SEED = System.getProperty("tests.seed", "random");
   
   private static final Pattern codecWithParam = Pattern.compile("(.*)\\(\\s*(\\d+)\\s*\\)");
 
@@ -349,6 +351,8 @@
   public void setUp() throws Exception {
     Assert.assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
     setup = true;
+    seed = Long.valueOf(TEST_SEED.equals("random") ? seedRnd.nextLong() : Long.parseLong(TEST_SEED));
+    random = new Random(seed);
     savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
     Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
       public void uncaughtException(Thread t, Throwable e) {
@@ -500,37 +504,6 @@
     dumpIterator(label, iter, stream);
   }
 
-  /**
-   * Returns a {@link Random} instance for generating random numbers during the test.
-   * The random seed is logged during test execution and printed to System.out on any failure
-   * for reproducing the test using {@link #newRandom(long)} with the recorded seed
-   * .
-   */
-  public Random newRandom() {
-    if (seed != null) {
-      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
-    }
-    this.seed = Long.valueOf(seedRnd.nextLong());
-    if (VERBOSE) {
-      System.out.println("NOTE: random seed of testcase '" + getName() + "' is: " + this.seed);
-    }
-    return new Random(seed);
-  }
-
-  /**
-   * Returns a {@link Random} instance for generating random numbers during the test.
-   * If an error occurs in the test that is not reproducible, you can use this method to
-   * initialize the number generator with the seed that was printed out during the failing test.
-   */
-  public Random newRandom(long seed) {
-    if (this.seed != null) {
-      throw new IllegalStateException("please call LuceneTestCaseJ4.newRandom only once per test");
-    }
-    System.out.println("WARNING: random seed of testcase '" + getName() + "' is fixed to: " + seed);
-    this.seed = Long.valueOf(seed);
-    return new Random(seed);
-  }
-
   private static final Map<Class<? extends LuceneTestCaseJ4>,Long> staticSeeds =
     Collections.synchronizedMap(new WeakHashMap<Class<? extends LuceneTestCaseJ4>,Long>());
 
@@ -560,6 +533,10 @@
   }
 
   /** create a new index writer config with random defaults */
+  public IndexWriterConfig newIndexWriterConfig(Version v, Analyzer a) {
+    return newIndexWriterConfig(random, v, a);
+  }
+  
   public static IndexWriterConfig newIndexWriterConfig(Random r, Version v, Analyzer a) {
     IndexWriterConfig c = new IndexWriterConfig(v, a);
     if (r.nextBoolean()) {
@@ -601,6 +578,10 @@
    * some features of Windows, such as not allowing open files to be
    * overwritten.
    */
+  public MockDirectoryWrapper newDirectory() throws IOException {
+    return newDirectory(random);
+  }
+  
   public static MockDirectoryWrapper newDirectory(Random r) throws IOException {
     StackTraceElement[] stack = new Exception().getStackTrace();
     Directory impl = newDirectoryImpl(r, TEST_DIRECTORY);
@@ -611,10 +592,14 @@
   
   /**
    * Returns a new Dictionary instance, with contents copied from the
-   * provided directory. See {@link #newDirectory(Random)} for more
+   * provided directory. See {@link #newDirectory()} for more
    * information.
    */
-  public static MockDirectoryWrapper newDirectory(Random r, Directory d) throws IOException {
+  public MockDirectoryWrapper newDirectory(Directory d) throws IOException {
+    return newDirectory(random, d);
+  }
+  
+  private static MockDirectoryWrapper newDirectory(Random r, Directory d) throws IOException {
     StackTraceElement[] stack = new Exception().getStackTrace();
     Directory impl = newDirectoryImpl(r, TEST_DIRECTORY);
     for (String file : d.listAll()) {
@@ -730,7 +715,8 @@
 
   // recorded seed
   protected Long seed = null;
-
+  protected Random random = null;
+  
   // static members
   private static final Random seedRnd = new Random();
 
Index: lucene/src/test/org/apache/lucene/util/packed/TestPackedInts.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/packed/TestPackedInts.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/packed/TestPackedInts.java	(working copy)
@@ -26,9 +26,6 @@
 import java.io.IOException;
 
 public class TestPackedInts extends LuceneTestCase {
-
-  private Random rnd;
-
   public void testBitsRequired() throws Exception {
     assertEquals(61, PackedInts.bitsRequired((long)Math.pow(2, 61)-1));
     assertEquals(61, PackedInts.bitsRequired(0x1FFFFFFFFFFFFFFFL));
@@ -50,13 +47,12 @@
   }
 
   public void testPackedInts() throws IOException {
-    rnd = newRandom();
     int num = 5 * RANDOM_MULTIPLIER;
     for (int iter = 0; iter < num; iter++) {
       long ceil = 2;
       for(int nbits=1;nbits<63;nbits++) {
-        final int valueCount = 100+rnd.nextInt(500);
-        final Directory d = newDirectory(rnd);
+        final int valueCount = 100+random.nextInt(500);
+        final Directory d = newDirectory();
 
         IndexOutput out = d.createOutput("out.bin");
         PackedInts.Writer w = PackedInts.getWriter(
@@ -64,7 +60,7 @@
 
         final long[] values = new long[valueCount];
         for(int i=0;i<valueCount;i++) {
-          long v = rnd.nextLong() % ceil;
+          long v = random.nextLong() % ceil;
           if (v < 0) {
             v = -v;
           }
@@ -119,13 +115,11 @@
     final int MIN_BITS_PER_VALUE = 1;
     final int MAX_BITS_PER_VALUE = 64;
 
-    rnd = newRandom();
-
     for (int valueCount: VALUE_COUNTS) {
       for (int bitsPerValue = MIN_BITS_PER_VALUE ;
            bitsPerValue <= MAX_BITS_PER_VALUE ;
            bitsPerValue++) {
-        assertRandomEquality(valueCount, bitsPerValue, rnd.nextLong());
+        assertRandomEquality(valueCount, bitsPerValue, random.nextLong());
       }
     }
   }
@@ -209,7 +203,7 @@
   }
 
   public void testSingleValue() throws Exception {
-    Directory dir = newDirectory(newRandom());
+    Directory dir = newDirectory();
     IndexOutput out = dir.createOutput("out");
     PackedInts.Writer w = PackedInts.getWriter(out, 1, 8);
     w.add(17);
Index: lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/LuceneTestCase.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/LuceneTestCase.java	(working copy)
@@ -42,9 +42,7 @@
 import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.search.FieldCache.CacheEntry;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.store.MockDirectoryWrapper;
-import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.FieldCacheSanityChecker.Insanity;
 
 /** 
@@ -88,6 +86,8 @@
   static final String TEST_TIMEZONE = LuceneTestCaseJ4.TEST_TIMEZONE;
   /** Gets the directory to run tests with */
   static final String TEST_DIRECTORY = LuceneTestCaseJ4.TEST_DIRECTORY;
+  /** Get the random seed for tests */
+  static final String TEST_SEED = LuceneTestCaseJ4.TEST_SEED;
   
   /**
    * A random multiplier which you should use when writing random tests:
@@ -134,6 +134,8 @@
   protected void setUp() throws Exception {
     super.setUp();
     assertFalse("ensure your tearDown() calls super.tearDown()!!!", setup);
+    seed = Long.valueOf(TEST_SEED.equals("random") ? seedRnd.nextLong() : Long.parseLong(TEST_SEED));
+    random = new Random(seed);
     setup = true;
     stores = new IdentityHashMap<MockDirectoryWrapper,StackTraceElement[]>();
     savedUncaughtExceptionHandler = Thread.getDefaultUncaughtExceptionHandler();
@@ -297,41 +299,10 @@
     Iterator<Object> iter = (null == objs) ? null : Arrays.asList(objs).iterator();
     dumpIterator(label, iter, stream);
   }
-  
-  /**
-   * Returns a {@link Random} instance for generating random numbers during the test.
-   * The random seed is logged during test execution and printed to System.out on any failure
-   * for reproducing the test using {@link #newRandom(long)} with the recorded seed
-   *.
-   */
-  public Random newRandom() {
-    if (seed != null) {
-      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
-    }
-    this.seed = Long.valueOf(seedRnd.nextLong());
-    if (VERBOSE) {
-      System.out.println("NOTE: random seed of testcase '" + getName() + "' is: " + this.seed);
-    }
-    return new Random(seed);
-  }
-  
-  /**
-   * Returns a {@link Random} instance for generating random numbers during the test.
-   * If an error occurs in the test that is not reproducible, you can use this method to
-   * initialize the number generator with the seed that was printed out during the failing test.
-   */
-  public Random newRandom(long seed) {
-    if (this.seed != null) {
-      throw new IllegalStateException("please call LuceneTestCase.newRandom only once per test");
-    }
-    System.out.println("WARNING: random seed of testcase '" + getName() + "' is fixed to: " + seed);
-    this.seed = Long.valueOf(seed);
-    return new Random(seed);
-  }
 
   /** create a new index writer config with random defaults */
-  public static IndexWriterConfig newIndexWriterConfig(Random r, Version v, Analyzer a) {
-    return LuceneTestCaseJ4.newIndexWriterConfig(r, v, a);
+  public IndexWriterConfig newIndexWriterConfig(Version v, Analyzer a) {
+    return LuceneTestCaseJ4.newIndexWriterConfig(random, v, a);
   }
 
   /**
@@ -344,9 +315,9 @@
    * some features of Windows, such as not allowing open files to be
    * overwritten.
    */
-  public MockDirectoryWrapper newDirectory(Random r) throws IOException {
+  public MockDirectoryWrapper newDirectory() throws IOException {
     StackTraceElement[] stack = new Exception().getStackTrace();
-    Directory impl = LuceneTestCaseJ4.newDirectoryImpl(r, TEST_DIRECTORY);
+    Directory impl = LuceneTestCaseJ4.newDirectoryImpl(random, TEST_DIRECTORY);
     MockDirectoryWrapper dir = new MockDirectoryWrapper(impl);
     stores.put(dir, stack);
     return dir;
@@ -354,12 +325,12 @@
   
   /**
    * Returns a new Dictionary instance, with contents copied from the
-   * provided directory. See {@link #newDirectory(Random)} for more
+   * provided directory. See {@link #newDirectory()} for more
    * information.
    */
-  public MockDirectoryWrapper newDirectory(Random r, Directory d) throws IOException {
+  public MockDirectoryWrapper newDirectory(Directory d) throws IOException {
     StackTraceElement[] stack = new Exception().getStackTrace();
-    Directory impl = LuceneTestCaseJ4.newDirectoryImpl(r, TEST_DIRECTORY);
+    Directory impl = LuceneTestCaseJ4.newDirectoryImpl(random, TEST_DIRECTORY);
     for (String file : d.listAll()) {
      d.copy(impl, file, file);
     }
@@ -412,6 +383,7 @@
   
   // recorded seed
   protected Long seed = null;
+  protected Random random = null;
   
   // static members
   private static final Random seedRnd = new Random();
Index: lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
 import java.nio.CharBuffer;
 import java.nio.ByteBuffer;
 
@@ -75,7 +74,6 @@
   /** @deprecated remove this test for Lucene 4.0 */
   @Deprecated
   public void testEncodedSortabilityNIO() {
-    Random random = newRandom();
     byte[] originalArray1 = new byte[MAX_RANDOM_BINARY_LENGTH];
     ByteBuffer originalBuf1 = ByteBuffer.wrap(originalArray1);
     char[] originalString1 = new char[MAX_RANDOM_BINARY_LENGTH];
@@ -132,7 +130,6 @@
   }
 
   public void testEncodedSortability() {
-    Random random = newRandom();
     byte[] originalArray1 = new byte[MAX_RANDOM_BINARY_LENGTH];
     char[] originalString1 = new char[MAX_RANDOM_BINARY_LENGTH];
     char[] encoded1 = new char[MAX_RANDOM_BINARY_LENGTH * 10];
@@ -266,7 +263,6 @@
   /** @deprecated remove this test for Lucene 4.0 */
   @Deprecated
   public void testRandomBinaryRoundTripNIO() {
-    Random random = newRandom();
     byte[] binary = new byte[MAX_RANDOM_BINARY_LENGTH];
     ByteBuffer binaryBuf = ByteBuffer.wrap(binary);
     char[] encoded = new char[IndexableBinaryStringTools.getEncodedLength(binaryBuf)];
@@ -294,7 +290,6 @@
   }
 
   public void testRandomBinaryRoundTrip() {
-    Random random = newRandom();
     byte[] binary = new byte[MAX_RANDOM_BINARY_LENGTH];
     char[] encoded = new char[MAX_RANDOM_BINARY_LENGTH * 10];
     byte[] decoded = new byte[MAX_RANDOM_BINARY_LENGTH];
Index: lucene/src/test/org/apache/lucene/util/TestArrayUtil.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestArrayUtil.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestArrayUtil.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 public class TestArrayUtil extends LuceneTestCase {
 
   // Ensure ArrayUtil.getNextSize gives linear amortized cost of realloc/copy
@@ -48,11 +46,10 @@
   }
 
   public void testInvalidElementSizes() {
-    final Random r = newRandom();
     int num = 10000 * RANDOM_MULTIPLIER;
     for (int iter = 0; iter < num; iter++) {
-      final int minTargetSize = r.nextInt(Integer.MAX_VALUE);
-      final int elemSize = r.nextInt(11);
+      final int minTargetSize = random.nextInt(Integer.MAX_VALUE);
+      final int elemSize = random.nextInt(11);
       final int v = ArrayUtil.oversize(minTargetSize, elemSize);
       assertTrue(v >= minTargetSize);
     }
Index: lucene/src/test/org/apache/lucene/util/TestOpenBitSet.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestOpenBitSet.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestOpenBitSet.java	(working copy)
@@ -17,13 +17,11 @@
 
 package org.apache.lucene.util;
 
-import java.util.Random;
 import java.util.BitSet;
 
 import org.apache.lucene.search.DocIdSetIterator;
 
 public class TestOpenBitSet extends LuceneTestCase {
-  Random rand;
 
   void doGet(BitSet a, OpenBitSet b) {
     int max = a.size();
@@ -54,7 +52,7 @@
     OpenBitSetIterator iterator = new OpenBitSetIterator(b);
     do {
       aa = a.nextSetBit(aa+1);
-      bb = rand.nextBoolean() ? iterator.nextDoc() : iterator.advance(bb + 1);
+      bb = random.nextBoolean() ? iterator.nextDoc() : iterator.advance(bb + 1);
       assertEquals(aa == -1 ? DocIdSetIterator.NO_MORE_DOCS : aa, bb);
     } while (aa>=0);
   }
@@ -64,7 +62,7 @@
     OpenBitSetIterator iterator = new OpenBitSetIterator(b);
     do {
       aa = a.nextSetBit(aa+1);
-      bb = rand.nextBoolean() ? iterator.nextDoc() : iterator.advance(bb + 1);
+      bb = random.nextBoolean() ? iterator.nextDoc() : iterator.advance(bb + 1);
       assertEquals(aa == -1 ? DocIdSetIterator.NO_MORE_DOCS : aa, bb);
     } while (aa>=0);
   }
@@ -74,23 +72,23 @@
     OpenBitSet b0=null;
 
     for (int i=0; i<iter; i++) {
-      int sz = rand.nextInt(maxSize);
+      int sz = random.nextInt(maxSize);
       BitSet a = new BitSet(sz);
       OpenBitSet b = new OpenBitSet(sz);
 
       // test the various ways of setting bits
       if (sz>0) {
-        int nOper = rand.nextInt(sz);
+        int nOper = random.nextInt(sz);
         for (int j=0; j<nOper; j++) {
           int idx;         
 
-          idx = rand.nextInt(sz);
+          idx = random.nextInt(sz);
           a.set(idx);
           b.fastSet(idx);
-          idx = rand.nextInt(sz);
+          idx = random.nextInt(sz);
           a.clear(idx);
           b.fastClear(idx);
-          idx = rand.nextInt(sz);
+          idx = random.nextInt(sz);
           a.flip(idx);
           b.fastFlip(idx);
 
@@ -112,22 +110,22 @@
 
       // test ranges, including possible extension
       int fromIndex, toIndex;
-      fromIndex = rand.nextInt(sz+80);
-      toIndex = fromIndex + rand.nextInt((sz>>1)+1);
+      fromIndex = random.nextInt(sz+80);
+      toIndex = fromIndex + random.nextInt((sz>>1)+1);
       BitSet aa = (BitSet)a.clone(); aa.flip(fromIndex,toIndex);
       OpenBitSet bb = (OpenBitSet)b.clone(); bb.flip(fromIndex,toIndex);
 
       doIterate(aa,bb, mode);   // a problem here is from flip or doIterate
 
-      fromIndex = rand.nextInt(sz+80);
-      toIndex = fromIndex + rand.nextInt((sz>>1)+1);
+      fromIndex = random.nextInt(sz+80);
+      toIndex = fromIndex + random.nextInt((sz>>1)+1);
       aa = (BitSet)a.clone(); aa.clear(fromIndex,toIndex);
       bb = (OpenBitSet)b.clone(); bb.clear(fromIndex,toIndex);
 
       doNextSetBit(aa,bb);  // a problem here is from clear() or nextSetBit
 
-      fromIndex = rand.nextInt(sz+80);
-      toIndex = fromIndex + rand.nextInt((sz>>1)+1);
+      fromIndex = random.nextInt(sz+80);
+      toIndex = fromIndex + random.nextInt((sz>>1)+1);
       aa = (BitSet)a.clone(); aa.set(fromIndex,toIndex);
       bb = (OpenBitSet)b.clone(); bb.set(fromIndex,toIndex);
 
@@ -174,7 +172,6 @@
   // large enough to flush obvious bugs, small enough to run in <.5 sec as part of a
   // larger testsuite.
   public void testSmall() {
-    rand = newRandom();
     doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 1);
     doRandomSets(1200 * RANDOM_MULTIPLIER, 1000 * RANDOM_MULTIPLIER, 2);
   }
@@ -187,7 +184,6 @@
   }
 
   public void testEquals() {
-    rand = newRandom();
     OpenBitSet b1 = new OpenBitSet(1111);
     OpenBitSet b2 = new OpenBitSet(2222);
     assertTrue(b1.equals(b2));
@@ -211,7 +207,6 @@
   
   public void testBitUtils()
   {
-    rand = newRandom();
     long num = 100000;
     assertEquals( 5, BitUtil.ntz(num) );
     assertEquals( 5, BitUtil.ntz2(num) );
Index: lucene/src/test/org/apache/lucene/util/TestNumericUtils.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestNumericUtils.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestNumericUtils.java	(working copy)
@@ -308,7 +308,6 @@
   }
   
   public void testRandomSplit() throws Exception {
-    final Random random = newRandom();
     long num = 100L * RANDOM_MULTIPLIER;
     for (long i=0; i < num; i++) {
       executeOneRandomSplit(random);
Index: lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java	(working copy)
@@ -21,7 +21,6 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.search.FieldCache;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.MultiReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.store.Directory;
@@ -29,7 +28,6 @@
 import org.apache.lucene.util.FieldCacheSanityChecker.InsanityType;
 
 import java.io.IOException;
-import java.util.Random;
 
 public class TestFieldCacheSanityChecker extends LuceneTestCase {
 
@@ -42,12 +40,11 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    dirA = newDirectory(random);
-    dirB = newDirectory(random);
+    dirA = newDirectory();
+    dirB = newDirectory();
 
-    IndexWriter wA = new IndexWriter(dirA, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
-    IndexWriter wB = new IndexWriter(dirB, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter wA = new IndexWriter(dirA, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter wB = new IndexWriter(dirB, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     long theLong = Long.MAX_VALUE;
     double theDouble = Double.MAX_VALUE;
Index: lucene/src/test/org/apache/lucene/util/TestUnicodeUtil.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestUnicodeUtil.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestUnicodeUtil.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 /*
  * Some of this code came from the excellent Unicode
  * conversion examples from:
@@ -120,11 +118,10 @@
   }
 
   public void testCodePointCount() {
-    final Random r = newRandom();
     BytesRef utf8 = new BytesRef(20);
     int num = 50000 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      final String s = _TestUtil.randomUnicodeString(r);
+      final String s = _TestUtil.randomUnicodeString(random);
       UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
       assertEquals(s.codePointCount(0, s.length()),
                    UnicodeUtil.codePointCount(utf8));
@@ -132,13 +129,12 @@
   }
 
   public void testUTF8toUTF32() {
-    final Random r = newRandom();
     BytesRef utf8 = new BytesRef(20);
     IntsRef utf32 = new IntsRef(20);
     int[] codePoints = new int[20];
     int num = 50000 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      final String s = _TestUtil.randomUnicodeString(r);
+      final String s = _TestUtil.randomUnicodeString(random);
       UnicodeUtil.UTF16toUTF8(s, 0, s.length(), utf8);
       UnicodeUtil.UTF8toUTF32(utf8, utf32);
       
Index: lucene/src/test/org/apache/lucene/util/TestPriorityQueue.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestPriorityQueue.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestPriorityQueue.java	(working copy)
@@ -37,7 +37,7 @@
     }
 
     public void testPQ() throws Exception {
-        testPQ(10000 * RANDOM_MULTIPLIER, newRandom());
+        testPQ(10000 * RANDOM_MULTIPLIER, random);
     }
 
     public static void testPQ(int count, Random gen) {
Index: lucene/src/test/org/apache/lucene/util/TestStringIntern.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestStringIntern.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestStringIntern.java	(working copy)
@@ -21,12 +21,11 @@
 public class TestStringIntern extends LuceneTestCase {
   String[] testStrings;
   String[] internedStrings;
-  Random r = newRandom();
 
   private String randStr(int len) {
     char[] arr = new char[len];
     for (int i=0; i<len; i++) {
-      arr[i] = (char)('a' + r.nextInt(26));
+      arr[i] = (char)('a' + random.nextInt(26));
     }
     return new String(arr);
   }
@@ -35,7 +34,7 @@
     testStrings = new String[sz];
     internedStrings = new String[sz];
     for (int i=0; i<sz; i++) {
-      testStrings[i] = randStr(r.nextInt(8)+3);
+      testStrings[i] = randStr(random.nextInt(8)+3);
     }
   }
 
Index: lucene/src/test/org/apache/lucene/util/automaton/TestDeterminism.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/automaton/TestDeterminism.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/automaton/TestDeterminism.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -26,12 +24,10 @@
  * somewhat randomly.
  */
 public class TestDeterminism extends LuceneTestCase {
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
   }
   
   /** test a bunch of random regular expressions */
Index: lucene/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/automaton/TestDeterminizeLexicon.java	(working copy)
@@ -20,7 +20,6 @@
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
-import java.util.Random;
 
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
@@ -32,10 +31,8 @@
 public class TestDeterminizeLexicon extends LuceneTestCase {
   private List<Automaton> automata = new ArrayList<Automaton>();
   private List<String> terms = new ArrayList<String>();
-  private Random random;
   
   public void testLexicon() throws Exception {
-    random = newRandom();
     int num = 3 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
       automata.clear();
Index: lucene/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/automaton/TestBasicOperations.java	(working copy)
@@ -20,8 +20,6 @@
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.UnicodeUtil;
 
-import java.util.Random;
-
 public class TestBasicOperations extends LuceneTestCase { 
   /** Test optimization to concatenate() */
   public void testSingletonConcatenate() {
@@ -85,12 +83,11 @@
   }
 
   public void testGetRandomAcceptedString() throws Throwable {
-    final Random r = newRandom();
     final int ITER1 = 100 * RANDOM_MULTIPLIER;
     final int ITER2 = 100 * RANDOM_MULTIPLIER;
     for(int i=0;i<ITER1;i++) {
 
-      final RegExp re = AutomatonTestUtil.randomRegexp(r);
+      final RegExp re = AutomatonTestUtil.randomRegexp(random);
       final Automaton a = re.toAutomaton();
       assertFalse(BasicOperations.isEmpty(a));
 
@@ -98,7 +95,7 @@
       for(int j=0;j<ITER2;j++) {
         int[] acc = null;
         try {
-          acc = rx.getRandomAcceptedString(r);
+          acc = rx.getRandomAcceptedString(random);
           final String s = UnicodeUtil.newString(acc, 0, acc.length);
           assertTrue(BasicOperations.run(a, s));
         } catch (Throwable t) {
Index: lucene/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/automaton/TestUTF32ToUTF8.java	(working copy)
@@ -25,12 +25,10 @@
 import java.util.Random;
 
 public class TestUTF32ToUTF8 extends LuceneTestCase {
-  private Random random;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
   }
 
   private static final int MAX_UNICODE = 0x10FFFF;
Index: lucene/src/test/org/apache/lucene/util/TestSmallFloat.java
===================================================================
--- lucene/src/test/org/apache/lucene/util/TestSmallFloat.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/util/TestSmallFloat.java	(working copy)
@@ -16,8 +16,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 public class TestSmallFloat extends LuceneTestCase {
 
   // original lucene byteToFloat
@@ -70,11 +68,10 @@
   }
 
   public void testFloatToByte() {
-    Random rand = newRandom();
     // up iterations for more exhaustive test after changing something
     int num = 100000 * RANDOM_MULTIPLIER;
     for (int i = 0; i < num; i++) {
-      float f = Float.intBitsToFloat(rand.nextInt());
+      float f = Float.intBitsToFloat(random.nextInt());
       if (Float.isNaN(f)) continue;    // skip NaN
       byte b1 = orig_floatToByte(f);
       byte b2 = SmallFloat.floatToByte(f,3,15);
Index: lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
===================================================================
--- lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java	(working copy)
@@ -1,7 +1,5 @@
 package org.apache.lucene.document;
 
-import java.util.Random;
-
 import org.apache.lucene.util.LuceneTestCase;
 
 import org.apache.lucene.index.IndexReader;
@@ -57,8 +55,7 @@
     assertEquals(2, doc.fields.size());
     
     /** add the doc to a ram index */
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.addDocument(doc);
     
@@ -97,8 +94,7 @@
     doc.add(stringFldCompressed);
     
     /** add the doc to a ram index */
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.addDocument(doc);
     
Index: lucene/src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- lucene/src/test/org/apache/lucene/document/TestDocument.java	(revision 995688)
+++ lucene/src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -1,7 +1,5 @@
 package org.apache.lucene.document;
 
-import java.util.Random;
-
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
@@ -154,8 +152,7 @@
    * @throws Exception on error
    */
   public void testGetValuesForIndexedDocument() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.addDocument(makeDocumentWithFields());
     IndexReader reader = writer.getReader();
@@ -233,8 +230,7 @@
     doc.add(new Field("keyword", "test", Field.Store.YES,
         Field.Index.NOT_ANALYZED));
     
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     writer.addDocument(doc);
     field.setValue("id2");
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java	(revision 995688)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQPHelper.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.Reader;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
@@ -318,9 +317,8 @@
 
   public void testStopWordSearching() throws Exception {
     Analyzer analyzer = new MockAnalyzer();
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    Directory ramDir = newDirectory();
+    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     Document doc = new Document();
     doc.add(new Field("body", "blah the footest blah", Field.Store.NO,
         Field.Index.ANALYZED));
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(revision 995688)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java	(working copy)
@@ -30,7 +30,6 @@
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -654,9 +653,8 @@
   }
 
   public void testFarsiRangeCollating() throws Exception {
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    Directory ramDir = newDirectory();
+    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     Document doc = new Document();
     doc.add(new Field("content", "\u0633\u0627\u0628", Field.Store.YES,
         Field.Index.NOT_ANALYZED));
@@ -1078,9 +1076,8 @@
   }
 
   public void testLocalDateFormat() throws IOException, QueryNodeException {
-    Random random = newRandom();
-    Directory ramDir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    Directory ramDir = newDirectory();
+    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
     addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
     iw.close();
@@ -1306,9 +1303,8 @@
   }
 
   public void testMultiPhraseQuery() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new CannedAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new CannedAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("field", "", Field.Store.NO, Field.Index.ANALYZED));
     w.addDocument(doc);
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java	(revision 995688)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java	(working copy)
@@ -320,7 +320,7 @@
 
   public void testStopWordSearching() throws Exception {
     Analyzer analyzer = new MockAnalyzer();
-    Directory ramDir = newDirectory(newRandom());
+    Directory ramDir = newDirectory();
     IndexWriter iw = new IndexWriter(ramDir, analyzer, true,
         IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(revision 995688)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java	(working copy)
@@ -654,7 +654,7 @@
 
   public void testFarsiRangeCollating() throws Exception {
 
-    Directory ramDir = newDirectory(newRandom());
+    Directory ramDir = newDirectory();
     IndexWriter iw = new IndexWriter(ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), true,
         IndexWriter.MaxFieldLength.LIMITED);
     Document doc = new Document();
@@ -1063,7 +1063,7 @@
 
   public void testLocalDateFormat() throws IOException, ParseException {
 
-    Directory ramDir = newDirectory(newRandom());
+    Directory ramDir = newDirectory();
     IndexWriter iw = new IndexWriter(ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), true,
         IndexWriter.MaxFieldLength.LIMITED);
     addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
Index: lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java
===================================================================
--- lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java	(revision 995688)
+++ lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/complexPhrase/TestComplexPhraseQuery.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.util.HashSet;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -112,9 +111,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    rd = newDirectory(random);
-    IndexWriter w = new IndexWriter(rd, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+    rd = newDirectory();
+    IndexWriter w = new IndexWriter(rd, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     for (int i = 0; i < docsContent.length; i++) {
       Document doc = new Document();
       doc.add(new Field("name", docsContent[i].name, Field.Store.YES,
Index: lucene/contrib/db/bdb-je/src/test/org/apache/lucene/store/je/JEStoreTest.java
===================================================================
--- lucene/contrib/db/bdb-je/src/test/org/apache/lucene/store/je/JEStoreTest.java	(revision 995688)
+++ lucene/contrib/db/bdb-je/src/test/org/apache/lucene/store/je/JEStoreTest.java	(working copy)
@@ -115,7 +115,7 @@
         final int count = 250;
         final int LENGTH_MASK = 0xffff;
 
-        Random r = newRandom();
+        Random r = random;
         final long seed = r.nextLong();
         Random gen = new Random(seed);
         int totalLength = 0;
@@ -261,7 +261,7 @@
         final int count = 250;
         final int LENGTH_MASK = 0xffff;
 
-        Random r = newRandom();
+        Random r = random;
         final long seed = r.nextLong();
         Random gen = new Random(seed);
         int totalLength = 0;
@@ -493,7 +493,7 @@
         final int count = 250;
         final int LENGTH_MASK = 0xffff;
 
-        Random r = newRandom();
+        Random r = random;
         final long seed = r.nextLong();
         Random gen = new Random(seed);
         int totalLength = 0;
Index: lucene/contrib/db/bdb/src/test/org/apache/lucene/store/db/DbStoreTest.java
===================================================================
--- lucene/contrib/db/bdb/src/test/org/apache/lucene/store/db/DbStoreTest.java	(revision 995688)
+++ lucene/contrib/db/bdb/src/test/org/apache/lucene/store/db/DbStoreTest.java	(working copy)
@@ -116,7 +116,7 @@
         final int count = 250;
         final int LENGTH_MASK = 0xffff;
 
-        Random r = newRandom();
+        Random r = random;
         final long seed = r.nextLong();
 
         Random gen = new Random(seed);
@@ -267,7 +267,7 @@
         final int count = 250;
         final int LENGTH_MASK = 0xffff;
 
-        Random r = newRandom();
+        Random r = random;
         final long seed = r.nextLong();
 
         Random gen = new Random(seed);
Index: lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestEmptyIndex.java
===================================================================
--- lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestEmptyIndex.java	(revision 995688)
+++ lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestEmptyIndex.java	(working copy)
@@ -59,9 +59,8 @@
     ii.close();
 
     // make sure a Directory acts the same
-    Random random = newRandom();
-    Directory d = newDirectory(random);
-    new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())).close();
+    Directory d = newDirectory();
+    new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())).close();
     r = IndexReader.open(d, false);
     testNorms(r);
     r.close();
@@ -92,9 +91,8 @@
     ii.close();
 
     // make sure a Directory acts the same
-    Random random = newRandom();
-    Directory d = newDirectory(random);
-    new IndexWriter(d, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())).close();
+    Directory d = newDirectory();
+    new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())).close();
     r = IndexReader.open(d, false);
     termsEnumTest(r);
     r.close();
Index: lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java
===================================================================
--- lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java	(revision 995688)
+++ lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestIndicesEquals.java	(working copy)
@@ -21,7 +21,6 @@
 import java.util.Comparator;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
@@ -61,11 +60,10 @@
 
 
   public void testLoadIndexReader() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
     // create dir data
-    IndexWriter indexWriter = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter indexWriter = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     for (int i = 0; i < 20; i++) {
       Document document = new Document();
@@ -86,12 +84,11 @@
 
   public void testInstantiatedIndexWriter() throws Exception {
 
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     InstantiatedIndex ii = new InstantiatedIndex();
 
     // create dir data
-    IndexWriter indexWriter = new IndexWriter(dir, newIndexWriterConfig(random,
+    IndexWriter indexWriter = new IndexWriter(dir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     for (int i = 0; i < 500; i++) {
       Document document = new Document();
Index: lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestSerialization.java
===================================================================
--- lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestSerialization.java	(revision 995688)
+++ lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestSerialization.java	(working copy)
@@ -27,15 +27,13 @@
 
 import java.io.ByteArrayOutputStream;
 import java.io.ObjectOutputStream;
-import java.util.Random;
 
 public class TestSerialization extends LuceneTestCase {
 
   public void test() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
 
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     doc.add(new Field("foo", "bar rab abr bra rba", Field.Store.NO, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
     doc.add(new Field("moo", "bar rab abr bra rba", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
Index: lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestUnoptimizedReaderOnConstructor.java
===================================================================
--- lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestUnoptimizedReaderOnConstructor.java	(revision 995688)
+++ lucene/contrib/instantiated/src/test/org/apache/lucene/store/instantiated/TestUnoptimizedReaderOnConstructor.java	(working copy)
@@ -16,7 +16,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
@@ -34,8 +33,7 @@
 public class TestUnoptimizedReaderOnConstructor extends LuceneTestCase {
 
   public void test() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     addDocument(iw, "Hello, world!");
     addDocument(iw, "All work and no play makes jack a dull boy");
Index: lucene/contrib/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(revision 995688)
+++ lucene/contrib/misc/src/test/org/apache/lucene/index/TestMultiPassIndexSplitter.java	(working copy)
@@ -16,8 +16,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -28,15 +26,13 @@
 public class TestMultiPassIndexSplitter extends LuceneTestCase {
   IndexReader input;
   int NUM_DOCS = 11;
-  private Random random;
   Directory dir;
   
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    dir = newDirectory();
+    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc;
     for (int i = 0; i < NUM_DOCS; i++) {
       doc = new Document();
@@ -66,9 +62,9 @@
   public void testSplitRR() throws Exception {
     MultiPassIndexSplitter splitter = new MultiPassIndexSplitter();
     Directory[] dirs = new Directory[]{
-            newDirectory(random),
-            newDirectory(random),
-            newDirectory(random)
+            newDirectory(),
+            newDirectory(),
+            newDirectory()
     };
     splitter.split(input, dirs, false);
     IndexReader ir;
@@ -111,9 +107,9 @@
   public void testSplitSeq() throws Exception {
     MultiPassIndexSplitter splitter = new MultiPassIndexSplitter();
     Directory[] dirs = new Directory[]{
-            newDirectory(random),
-            newDirectory(random),
-            newDirectory(random)
+            newDirectory(),
+            newDirectory(),
+            newDirectory()
     };
     splitter.split(input, dirs, true);
     IndexReader ir;
Index: lucene/contrib/misc/src/test/org/apache/lucene/index/TestTermVectorAccessor.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/index/TestTermVectorAccessor.java	(revision 995688)
+++ lucene/contrib/misc/src/test/org/apache/lucene/index/TestTermVectorAccessor.java	(working copy)
@@ -6,7 +6,6 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
-import java.util.Random;
 /*
  *  Licensed under the Apache License, Version 2.0 (the "License");
  *  you may not use this file except in compliance with the License.
@@ -25,9 +24,8 @@
 public class TestTermVectorAccessor extends LuceneTestCase {
 
   public void test() throws Exception {
-    Random random = newRandom();
-    Directory dir = newDirectory(random);
-    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    Directory dir = newDirectory();
+    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
 
     Document doc;
 
Index: lucene/contrib/misc/src/test/org/apache/lucene/index/TestFieldNormModifier.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/index/TestFieldNormModifier.java	(revision 995688)
+++ lucene/contrib/misc/src/test/org/apache/lucene/index/TestFieldNormModifier.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -57,9 +56,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    store = newDirectory(random);
-    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(random,
+    store = newDirectory();
+    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     
     for (int i = 0; i < NUM_DOCS; i++) {
Index: lucene/contrib/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java	(revision 995688)
+++ lucene/contrib/misc/src/test/org/apache/lucene/misc/TestHighFreqTerms.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.util.BytesRef;
@@ -37,9 +35,8 @@
   
   public void setUp() throws Exception {
   	super.setUp();
-  	Random random = newRandom();
-    dir= newDirectory(random);
-    writer = new IndexWriter(dir, newIndexWriterConfig(random,
+    dir= newDirectory();
+    writer = new IndexWriter(dir, newIndexWriterConfig(
        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false))
        .setMaxBufferedDocs(2));
     indexDocs(writer);
Index: lucene/contrib/misc/src/test/org/apache/lucene/misc/TestLengthNormModifier.java
===================================================================
--- lucene/contrib/misc/src/test/org/apache/lucene/misc/TestLengthNormModifier.java	(revision 995688)
+++ lucene/contrib/misc/src/test/org/apache/lucene/misc/TestLengthNormModifier.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -26,7 +25,6 @@
 import org.apache.lucene.index.FieldNormModifier;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DefaultSimilarity;
@@ -61,9 +59,8 @@
     @Override
     protected void setUp() throws Exception {
       super.setUp();
-      Random random = newRandom();
-      store = newDirectory(random);
-	IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(random,
+      store = newDirectory();
+	IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
 	
 	for (int i = 0; i < NUM_DOCS; i++) {
Index: lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java
===================================================================
--- lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java	(revision 995688)
+++ lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestCartesian.java	(working copy)
@@ -20,7 +20,6 @@
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -70,10 +69,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     
     setUpPlotter( 2, 15);
     
Index: lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java
===================================================================
--- lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java	(revision 995688)
+++ lucene/contrib/spatial/src/test/org/apache/lucene/spatial/tier/TestDistance.java	(working copy)
@@ -17,7 +17,6 @@
 package org.apache.lucene.spatial.tier;
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -44,9 +43,8 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
-    writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));
+    directory = newDirectory();
+    writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     addData(writer);
     
   }
Index: lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java
===================================================================
--- lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java	(revision 995688)
+++ lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java	(working copy)
@@ -20,7 +20,6 @@
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Random;
 
 import javax.xml.parsers.DocumentBuilder;
 import javax.xml.parsers.DocumentBuilderFactory;
@@ -61,9 +60,8 @@
 		String xml = "<NumericRangeFilter fieldName='AGE' type='int' lowerTerm='-1' upperTerm='NaN'/>";
 		Document doc = getDocumentFromString(xml);
 		Filter filter = filterBuilder.getFilter(doc.getDocumentElement());
-		Random random = newRandom();
-		Directory ramDir = newDirectory(random);
-		IndexWriter writer = new IndexWriter(ramDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, null));
+		Directory ramDir = newDirectory();
+		IndexWriter writer = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));
 		writer.commit();
 		try
 		{
Index: lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java
===================================================================
--- lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java	(revision 995688)
+++ lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java	(working copy)
@@ -4,7 +4,6 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -57,10 +56,9 @@
 		//initialize the parser
 		builder=new CorePlusExtensionsParser("contents",analyzer);
 		
-		  Random random = newRandom();
 			BufferedReader d = new BufferedReader(new InputStreamReader(TestParser.class.getResourceAsStream("reuters21578.txt"))); 
-			dir=newDirectory(random);
-			IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, Version.LUCENE_24, analyzer));
+			dir=newDirectory();
+			IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_24, analyzer));
 			String line = d.readLine();		
 			while(line!=null)
 			{
Index: lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestQueryTemplateManager.java
===================================================================
--- lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestQueryTemplateManager.java	(revision 995688)
+++ lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestQueryTemplateManager.java	(working copy)
@@ -2,7 +2,6 @@
 
 import java.io.IOException;
 import java.util.Properties;
-import java.util.Random;
 import java.util.StringTokenizer;
 
 import javax.xml.parsers.ParserConfigurationException;
@@ -142,9 +141,8 @@
 		
 		
 		//Create an index
-		Random random = newRandom();
-		dir=newDirectory(random);
-		IndexWriter w=new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer));
+		dir=newDirectory();
+		IndexWriter w=new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
 		for (int i = 0; i < docFieldValues.length; i++)
 		{
 			w.addDocument(getDocumentFromString(docFieldValues[i]));
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java	(revision 995688)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -53,13 +52,12 @@
 
 public class HighlighterPhraseTest extends LuceneTestCase {
   private static final String FIELD = "text";
-  private Random random = newRandom();
   public void testConcurrentPhrase() throws CorruptIndexException,
       LockObtainFailedException, IOException, InvalidTokenOffsetsException {
     final String TEXT = "the fox jumped";
-    final Directory directory = newDirectory(random);
+    final Directory directory = newDirectory();
     final IndexWriter indexWriter = new IndexWriter(directory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     try {
       final Document document = new Document();
       document.add(new Field(FIELD, new TokenStreamConcurrent(),
@@ -101,9 +99,9 @@
   public void testConcurrentSpan() throws CorruptIndexException,
       LockObtainFailedException, IOException, InvalidTokenOffsetsException {
     final String TEXT = "the fox jumped";
-    final Directory directory = newDirectory(random);
+    final Directory directory = newDirectory();
     final IndexWriter indexWriter = new IndexWriter(directory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     try {
       final Document document = new Document();
       document.add(new Field(FIELD, new TokenStreamConcurrent(),
@@ -171,9 +169,9 @@
   public void testSparsePhrase() throws CorruptIndexException,
       LockObtainFailedException, IOException, InvalidTokenOffsetsException {
     final String TEXT = "the fox did not jump";
-    final Directory directory = newDirectory(random);
+    final Directory directory = newDirectory();
     final IndexWriter indexWriter = new IndexWriter(directory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     try {
       final Document document = new Document();
       document.add(new Field(FIELD, new TokenStreamSparse(),
@@ -214,9 +212,9 @@
   public void testSparsePhraseWithNoPositions() throws CorruptIndexException,
       LockObtainFailedException, IOException, InvalidTokenOffsetsException {
     final String TEXT = "the fox did not jump";
-    final Directory directory = newDirectory(random);
+    final Directory directory = newDirectory();
     final IndexWriter indexWriter = new IndexWriter(directory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     try {
       final Document document = new Document();
       document.add(new Field(FIELD, TEXT, Store.YES, Index.ANALYZED,
@@ -255,9 +253,9 @@
   public void testSparseSpan() throws CorruptIndexException,
       LockObtainFailedException, IOException, InvalidTokenOffsetsException {
     final String TEXT = "the fox did not jump";
-    final Directory directory = newDirectory(random);
+    final Directory directory = newDirectory();
     final IndexWriter indexWriter = new IndexWriter(directory,
-        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     try {
       final Document document = new Document();
       document.add(new Field(FIELD, new TokenStreamSparse(),
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(revision 995688)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java	(working copy)
@@ -26,7 +26,6 @@
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 import java.util.StringTokenizer;
 
 import javax.xml.parsers.DocumentBuilder;
@@ -99,7 +98,6 @@
   int numHighlights = 0;
   final Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true);
   TopDocs hits;
-  private Random random;
 
   String[] texts = {
       "Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot",
@@ -1322,8 +1320,8 @@
 
   public void testMultiSearcher() throws Exception {
     // setup index 1
-    Directory ramDir1 = newDirectory(random);
-    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(random,
+    Directory ramDir1 = newDirectory();
+    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
     Document d = new Document();
     Field f = new Field(FIELD_NAME, "multiOne", Field.Store.YES, Field.Index.ANALYZED);
@@ -1334,8 +1332,8 @@
     IndexReader reader1 = IndexReader.open(ramDir1, true);
 
     // setup index 2
-    Directory ramDir2 = newDirectory(random);
-    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(random,
+    Directory ramDir2 = newDirectory();
+    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
     d = new Document();
     f = new Field(FIELD_NAME, "multiTwo", Field.Store.YES, Field.Index.ANALYZED);
@@ -1723,10 +1721,9 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    dir = newDirectory(random);
-    ramDir = newDirectory(random);
-    IndexWriter writer = new IndexWriter(ramDir, newIndexWriterConfig(random,
+    dir = newDirectory();
+    ramDir = newDirectory();
+    IndexWriter writer = new IndexWriter(ramDir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
     for (int i = 0; i < texts.length; i++) {
       addDoc(writer, texts[i]);
Index: lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java
===================================================================
--- lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java	(revision 995688)
+++ lucene/contrib/highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java	(working copy)
@@ -92,7 +92,7 @@
     analyzerK = new MockAnalyzer(MockTokenizer.KEYWORD, false);
     paW = new QueryParser(TEST_VERSION_CURRENT,  F, analyzerW );
     paB = new QueryParser(TEST_VERSION_CURRENT,  F, analyzerB );
-    dir = newDirectory(newRandom());
+    dir = newDirectory();
   }
   
   @Override
Index: lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestLuceneDictionary.java
===================================================================
--- lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestLuceneDictionary.java	(revision 995688)
+++ lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestLuceneDictionary.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.Iterator;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -40,16 +39,14 @@
   private Directory store;
 
   private IndexReader indexReader = null;
-  private Random random;
   private LuceneDictionary ld;
   private Iterator<String> it;
 
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    store = newDirectory(random);
-    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+    store = newDirectory();
+    IndexWriter writer = new IndexWriter(store, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
 
     Document doc;
 
@@ -195,7 +192,7 @@
   }
   
   public void testSpellchecker() throws IOException {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     SpellChecker sc = new SpellChecker(dir);
     indexReader = IndexReader.open(store, true);
     sc.indexDictionary(new LuceneDictionary(indexReader, "contents"));
Index: lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java
===================================================================
--- lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java	(revision 995688)
+++ lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestSpellChecker.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
-import java.util.Random;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
@@ -46,7 +45,6 @@
 public class TestSpellChecker extends LuceneTestCase {
   private SpellCheckerMock spellChecker;
   private Directory userindex, spellindex;
-  private final Random random = newRandom();
   private List<IndexSearcher> searchers;
 
   @Override
@@ -54,7 +52,7 @@
     super.setUp();
     
     //create a user index
-    userindex = newDirectory(random);
+    userindex = newDirectory();
     IndexWriter writer = new IndexWriter(userindex, new IndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
 
@@ -68,7 +66,7 @@
     writer.close();
     searchers = Collections.synchronizedList(new ArrayList<IndexSearcher>());
     // create the spellChecker
-    spellindex = newDirectory(random);
+    spellindex = newDirectory();
     spellChecker = new SpellCheckerMock(spellindex);
   }
   
@@ -124,7 +122,7 @@
 
   public void testComparator() throws Exception {
     IndexReader r = IndexReader.open(userindex, true);
-    Directory compIdx = newDirectory(random);
+    Directory compIdx = newDirectory();
     SpellChecker compareSP = new SpellCheckerMock(compIdx, new LevensteinDistance(), new SuggestWordFrequencyComparator());
     addwords(r, compareSP, "field3");
 
Index: lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestPlainTextDictionary.java
===================================================================
--- lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestPlainTextDictionary.java	(revision 995688)
+++ lucene/contrib/spellchecker/src/test/org/apache/lucene/search/spell/TestPlainTextDictionary.java	(working copy)
@@ -33,7 +33,7 @@
     final String LF = System.getProperty("line.separator");
     String input = "oneword" + LF + "twoword" + LF + "threeword";
     PlainTextDictionary ptd = new PlainTextDictionary(new StringReader(input));
-    Directory ramDir = newDirectory(newRandom());
+    Directory ramDir = newDirectory();
     SpellChecker spellChecker = new SpellChecker(ramDir);
     spellChecker.indexDictionary(ptd);
     String[] similar = spellChecker.suggestSimilar("treeword", 2);
Index: lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
===================================================================
--- lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java	(revision 995688)
+++ lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java	(working copy)
@@ -22,7 +22,6 @@
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.util.HashSet;
-import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -46,7 +45,6 @@
  */
 public class MemoryIndexTest extends BaseTokenStreamTestCase {
   private Set<String> queries = new HashSet<String>();
-  private Random random;
   
   public static final int ITERATIONS = 100 * RANDOM_MULTIPLIER;
 
@@ -55,7 +53,6 @@
     super.setUp();
     queries.addAll(readQueries("testqueries.txt"));
     queries.addAll(readQueries("testqueries2.txt"));
-    random = newRandom();
   }
   
   /**
@@ -106,7 +103,7 @@
       termField.append(randomTerm());
     }
     
-    Directory ramdir = newDirectory(random);
+    Directory ramdir = newDirectory();
     Analyzer analyzer = randomAnalyzer();
     IndexWriter writer = new IndexWriter(ramdir,
                                          new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/similar/TestMoreLikeThis.java	(working copy)
@@ -22,7 +22,6 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -45,8 +44,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     
     // Add series of docs with specific information for MoreLikeThis
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/DuplicateFilterTest.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.HashSet;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -42,8 +41,7 @@
 	@Override
 	protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-		directory = newDirectory(random);
+		directory = newDirectory();
 		RandomIndexWriter writer = new RandomIndexWriter(random, directory);
 		
 		//Add series of docs with filterable fields : url, text and dates  flags
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/TermsFilterTest.java	(working copy)
@@ -52,8 +52,7 @@
 	
 	public void testMissingTerms() throws Exception {
 		String fieldName="field1";
-		Random random = newRandom();
-		Directory rd=newDirectory(random);
+		Directory rd=newDirectory();
 		RandomIndexWriter w = new RandomIndexWriter(random, rd);
 		for (int i = 0; i < 100; i++) {
 			Document doc=new Document();
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/ChainedFilterTest.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.util.Calendar;
 import java.util.GregorianCalendar;
-import java.util.Random;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -53,13 +52,10 @@
   private QueryWrapperFilter bobFilter;
   private QueryWrapperFilter sueFilter;
 
-  private Random random;
-
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     Calendar cal = new GregorianCalendar();
     cal.clear();
@@ -194,7 +190,7 @@
   */
   
   public void testWithCachingFilter() throws Exception {
-    Directory dir = newDirectory(random);
+    Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir);
     IndexReader reader = writer.getReader();
     writer.close();
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/BooleanFilterTest.java	(working copy)
@@ -18,7 +18,6 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -39,8 +38,7 @@
 	@Override
 	protected void setUp() throws Exception {
 	  super.setUp();
-	  Random random = newRandom();
-		directory = newDirectory(random);
+		directory = newDirectory();
 		RandomIndexWriter writer = new RandomIndexWriter(random, directory, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
 		
 		//Add series of docs with filterable fields : acces rights, prices, dates and "in-stock" flags
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java	(working copy)
@@ -17,8 +17,6 @@
  * limitations under the License.
  */
 
-import java.util.Random;
-
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.RandomIndexWriter;
@@ -42,8 +40,7 @@
   @Override
   protected void setUp() throws Exception {
     super.setUp();
-    Random random = newRandom();
-    directory = newDirectory(random);
+    directory = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, directory);
     Document doc = new Document();
     doc.add(new Field(FN, "the quick brown fox jumps over the lazy dog", Field.Store.NO, Field.Index.ANALYZED));
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java	(working copy)
@@ -18,14 +18,12 @@
  */
 
 import java.io.IOException;
-import java.util.Random;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.search.IndexSearcher;
@@ -41,14 +39,12 @@
   
   Directory indexStoreA;
   Directory indexStoreB;
-  Random random;
   
   @Override
   public void setUp() throws Exception {
     super.setUp();
-    random = newRandom();
-    indexStoreA = newDirectory(random);
-    indexStoreB = newDirectory(random);
+    indexStoreA = newDirectory();
+    indexStoreB = newDirectory();
   }
   
   @Override
@@ -59,8 +55,8 @@
   }
   
   public void testSpanRegex() throws Exception {
-    Directory directory = newDirectory(random);
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random,
+    Directory directory = newDirectory();
+    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     // doc.add(new Field("field", "the quick brown fox jumps over the lazy dog",
@@ -128,14 +124,14 @@
         Field.Index.ANALYZED_NO_NORMS));
 
     // creating first index writer
-    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(random,
+    IndexWriter writerA = new IndexWriter(indexStoreA, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     writerA.addDocument(lDoc);
     writerA.optimize();
     writerA.close();
 
     // creating second index writer
-    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(random,
+    IndexWriter writerB = new IndexWriter(indexStoreB, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
     writerB.addDocument(lDoc2);
     writerB.optimize();
Index: lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java
===================================================================
--- lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java	(revision 995688)
+++ lucene/contrib/queries/src/test/org/apache/lucene/search/FuzzyLikeThisQueryTest.java	(working copy)
@@ -19,7 +19,6 @@
 
 import java.io.IOException;
 import java.util.HashSet;
-import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.MockAnalyzer;
@@ -40,8 +39,7 @@
 	@Override
 	protected void setUp() throws Exception	{
 	  super.setUp();
-	  Random random = newRandom();
-		directory = newDirectory(random);
+		directory = newDirectory();
 		RandomIndexWriter writer = new RandomIndexWriter(random, directory);
 		
 		//Add series of docs with misspelt names
