Index: lucene/CHANGES.txt
===================================================================
--- lucene/CHANGES.txt	(revision 1696564)
+++ lucene/CHANGES.txt	(working copy)
@@ -14,6 +14,10 @@
   all other modules with "compact2".  (Robert Muir, Uwe Schindler)
 
 New Features
+* LUCENE-6747: FingerprintFilter is a TokenFilter that outputs a single
+  token which is a concatenation of the sorted and de-duplicated set of 
+  input tokens. Useful for normalizing short text in clustering/linking 
+  tasks. (Mark Harwood, Adrien Grand)
 
 * LUCENE-5735: NumberRangePrefixTreeStrategy now includes interval/range faceting
   for counting ranges that align with the underlying terms as defined by the
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilter.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilter.java	(revision 0)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilter.java	(working copy)
@@ -0,0 +1,189 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Comparator;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.util.AttributeSource;
+
+/**
+ * Filter outputs a single token which is a concatenation of the sorted and
+ * de-duplicated set of input tokens. This can be useful for clustering/linking
+ * use cases.
+ */
+public class FingerprintFilter extends TokenFilter {
+
+  public static final int DEFAULT_MAX_OUTPUT_TOKEN_SIZE = 1024;
+  public static final char DEFAULT_SEPARATOR = ' ';
+  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+  private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+  private final PositionLengthAttribute posLenAtt = addAttribute(PositionLengthAttribute.class);
+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+
+  private CharArraySet uniqueTerms = null;
+  private final int maxOutputTokenSize;
+  private AttributeSource.State finalState;
+
+  private final char separator;
+
+  /**
+   * Create a new FingerprintFilter with default settings
+   */
+  public FingerprintFilter(TokenStream input) {
+    this(input, DEFAULT_MAX_OUTPUT_TOKEN_SIZE, DEFAULT_SEPARATOR);
+  }
+
+  /**
+   * Create a new FingerprintFilter with control over all settings
+   * 
+   * @param input
+   *          the source of tokens to be summarized into a single token
+   * @param maxOutputTokenSize
+   *          the maximum length of the summarized output token. If exceeded, no
+   *          output token is emitted
+   * @param separator
+   *          the character used to separate tokens combined into the single
+   *          output token
+   */
+  public FingerprintFilter(TokenStream input, int maxOutputTokenSize,
+      char separator) {
+    super(input);
+    this.maxOutputTokenSize = maxOutputTokenSize;
+    this.separator = separator;
+  }
+
+  @Override
+  public final boolean incrementToken() throws IOException {
+    if (uniqueTerms != null) {
+      // We have already built the single output token - there's no more 
+      return false;
+    }
+    boolean result = buildSingleOutputToken();
+    finalState = captureState();
+    return result;
+  }
+
+  /**
+   * Gathers all tokens from input, de-duplicates, sorts then concatenates.
+   * 
+   * @return
+   * @throws IOException
+   */
+  private final boolean buildSingleOutputToken() throws IOException {
+    char clonedLastTerm[] = null;
+    uniqueTerms = new CharArraySet(8, false);
+    int outputTokenSize = 0;
+    while (input.incrementToken()) {
+      if (outputTokenSize > maxOutputTokenSize) {
+        continue;
+      }
+
+      final char term[] = termAttribute.buffer();
+      final int length = termAttribute.length();
+
+      if (!uniqueTerms.contains(term, 0, length)) {
+        // clone the term, and add to the set of seen terms.
+        clonedLastTerm = new char[length];
+        System.arraycopy(term, 0, clonedLastTerm, 0, length);
+        if (uniqueTerms.size() > 0) {
+          outputTokenSize++; //Add 1 for the separator char we will output
+        }
+        uniqueTerms.add(clonedLastTerm);
+        outputTokenSize += length;
+      }
+    }
+    //Force end-of-stream operations to get the final state.
+    input.end();
+
+    //Gathering complete - now output exactly zero or one token:
+
+    //Set the attributes for the single output token
+    offsetAtt.setOffset(0, offsetAtt.endOffset());
+    posLenAtt.setPositionLength(1);
+    posIncrAtt.setPositionIncrement(1);
+    typeAtt.setType("fingerprint");
+
+    //No tokens gathered - no output
+    if (uniqueTerms.size() < 1) {
+      termAttribute.setEmpty();
+      return false;
+    }
+
+    //Tokens gathered are too large - no output
+    if (outputTokenSize > maxOutputTokenSize) {
+      termAttribute.setEmpty();
+      uniqueTerms.clear();
+      return false;
+    }
+
+    // Special case - faster option when we have a single token
+    if (uniqueTerms.size() == 1) {
+      termAttribute.setEmpty().append(new String(clonedLastTerm));
+      uniqueTerms.clear();
+      return true;
+    }
+
+    // Sort the set of deduplicated tokens and combine 
+    Object[] items = uniqueTerms.toArray();
+    Arrays.sort(items, new Comparator() {
+      @Override
+      public int compare(Object o1, Object o2) {
+        char v1[] = (char[]) o1;
+        char v2[] = (char[]) o2;
+        int len1 = v1.length;
+        int len2 = v2.length;
+        int lim = Math.min(len1, len2);
+
+        int k = 0;
+        while (k < lim) {
+          char c1 = v1[k];
+          char c2 = v2[k];
+          if (c1 != c2) {
+            return c1 - c2;
+          }
+          k++;
+        }
+        return len1 - len2;
+      }
+    });
+
+    StringBuilder sb = new StringBuilder();
+    for (Object item : items) {
+      if (sb.length() > 1) {
+        sb.append(separator);
+      }
+      sb.append((char[]) item);
+    }
+    termAttribute.setEmpty().append(sb);
+    uniqueTerms.clear();
+    return true;
+
+  }
+
+  @Override
+  public final void end() {
+    //We already called input.end() during incrementToken and captured the final state
+    if (finalState != null) {
+      restoreState(finalState);
+    }
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    uniqueTerms = null;
+  }
+
+}

Property changes on: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilter.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilterFactory.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilterFactory.java	(revision 0)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilterFactory.java	(working copy)
@@ -0,0 +1,58 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link FingerprintFilter}.
+ * 
+ * <pre class="prettyprint">
+ * The {@code maxOutputTokenSize} property is optional and defaults to {@code 1024}.  
+ * The {@code separator} property is optional and defaults to the space character.  
+ * See
+ * {@link FingerprintFilter} for an explanation of its use.
+ */
+public class FingerprintFilterFactory extends TokenFilterFactory {
+
+  public static final String MAX_OUTPUT_TOKEN_SIZE_KEY = "maxOutputTokenSize";
+  public static final String SEPARATOR_KEY = "separator";
+  final int maxOutputTokenSize;
+  final char separator;
+
+  /** Creates a new FingerprintFilterFactory */
+  public FingerprintFilterFactory(Map<String, String> args) {
+    super(args);
+    maxOutputTokenSize = getInt(args, MAX_OUTPUT_TOKEN_SIZE_KEY,
+        FingerprintFilter.DEFAULT_MAX_OUTPUT_TOKEN_SIZE);
+    separator = getChar(args, SEPARATOR_KEY,
+        FingerprintFilter.DEFAULT_SEPARATOR);
+    if (!args.isEmpty()) {
+      throw new IllegalArgumentException("Unknown parameters: " + args);
+    }
+  }
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new FingerprintFilter(input, maxOutputTokenSize, separator);
+  }
+
+}

Property changes on: lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/FingerprintFilterFactory.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestFingerprintFilter.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestFingerprintFilter.java	(revision 0)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestFingerprintFilter.java	(working copy)
@@ -0,0 +1,72 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+public class TestFingerprintFilter extends BaseTokenStreamTestCase {
+
+  public void testDupsAndSorting() throws Exception {
+    for (final boolean consumeAll : new boolean[] { true, false }) {
+      MockTokenizer tokenizer = whitespaceMockTokenizer("B2 A1 B2 E5");
+      tokenizer.setEnableChecks(consumeAll);
+      TokenStream stream = new FingerprintFilter(tokenizer);
+      assertTokenStreamContents(stream, new String[] { "A1 B2 E5" });
+    }
+  }
+
+  public void testAllDupValues() throws Exception {
+    for (final boolean consumeAll : new boolean[] { true, false }) {
+      MockTokenizer tokenizer = whitespaceMockTokenizer("B2 B2");
+      tokenizer.setEnableChecks(consumeAll);
+      TokenStream stream = new FingerprintFilter(tokenizer);
+      assertTokenStreamContents(stream, new String[] { "B2" });
+    }
+  }
+
+  public void testMaxFingerprintSize() throws Exception {
+    for (final boolean consumeAll : new boolean[] { true, false }) {
+      MockTokenizer tokenizer = whitespaceMockTokenizer("B2 A1 C3 D4 E5 F6 G7 H1");
+      tokenizer.setEnableChecks(consumeAll);
+      TokenStream stream = new FingerprintFilter(tokenizer, 4, ' ');
+      assertTokenStreamContents(stream, new String[] {});
+    }
+  }
+
+  public void testCustomSeparator() throws Exception {
+    for (final boolean consumeAll : new boolean[] { true, false }) {
+      MockTokenizer tokenizer = whitespaceMockTokenizer("B2 A1 C3 B2");
+      tokenizer.setEnableChecks(consumeAll);
+      TokenStream stream = new FingerprintFilter(tokenizer,
+          FingerprintFilter.DEFAULT_MAX_OUTPUT_TOKEN_SIZE, '_');
+      assertTokenStreamContents(stream, new String[] { "A1_B2_C3" });
+    }
+  }
+
+  public void testSingleToken() throws Exception {
+    for (final boolean consumeAll : new boolean[] { true, false }) {
+      MockTokenizer tokenizer = whitespaceMockTokenizer("A1");
+      tokenizer.setEnableChecks(consumeAll);
+      TokenStream stream = new FingerprintFilter(tokenizer);
+      assertTokenStreamContents(stream, new String[] { "A1" });
+    }
+  }
+
+}

Property changes on: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestFingerprintFilter.java
___________________________________________________________________
Added: svn:eol-style
## -0,0 +1 ##
+native
\ No newline at end of property
