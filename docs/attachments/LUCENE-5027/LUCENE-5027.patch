Index: lucene/core/src/java/org/apache/lucene/index/DocConsumer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocConsumer.java	(revision 1485036)
+++ lucene/core/src/java/org/apache/lucene/index/DocConsumer.java	(working copy)
@@ -24,5 +24,4 @@
   abstract void finishDocument() throws IOException;
   abstract void flush(final SegmentWriteState state) throws IOException;
   abstract void abort();
-  abstract void doAfterFlush();
 }
Index: lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java	(revision 1485036)
+++ lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor.java	(working copy)
@@ -144,15 +144,6 @@
     return fields;
   }
 
-  /** In flush we reset the fieldHash to not maintain per-field state
-   *  across segments */
-  @Override
-  void doAfterFlush() {
-    fieldHash = new DocFieldProcessorPerField[2];
-    hashMask = 1;
-    totalFieldCount = 0;
-  }
-
   private void rehash() {
     final int newHashSize = (fieldHash.length*2);
     assert newHashSize > fieldHash.length;
Index: lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(revision 1485036)
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java	(working copy)
@@ -428,7 +428,6 @@
   /** Reset after a flush */
   private void doAfterFlush() {
     segmentInfo = null;
-    consumer.doAfterFlush();
     directory.getCreatedFiles().clear();
     fieldInfos = new FieldInfos.Builder(fieldInfos.globalFieldNumbers);
     parent.subtractFlushedNumDocs(numDocsInRAM);
Index: lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java	(revision 1488285)
+++ lucene/core/src/java/org/apache/lucene/index/TermVectorsConsumer.java	(working copy)
@@ -18,6 +18,7 @@
  */
 
 import java.io.IOException;
+import java.util.Arrays;
 import java.util.Map;
 
 import org.apache.lucene.codecs.TermVectorsWriter;
@@ -139,8 +140,8 @@
   TermVectorsConsumerPerField[] perFields;
 
   void reset() {
+    perFields = null; // don't hang onto stuff from previous doc
     numVectorFields = 0;
-    perFields = new TermVectorsConsumerPerField[1];
   }
 
   @Override
@@ -149,7 +150,9 @@
   }
 
   void addFieldToFlush(TermVectorsConsumerPerField fieldToFlush) {
-    if (numVectorFields == perFields.length) {
+    if (perFields == null) {
+      perFields = new TermVectorsConsumerPerField[1];
+    } else if (numVectorFields == perFields.length) {
       int newSize = ArrayUtil.oversize(numVectorFields + 1, RamUsageEstimator.NUM_BYTES_OBJECT_REF);
       TermVectorsConsumerPerField[] newArray = new TermVectorsConsumerPerField[newSize];
       System.arraycopy(perFields, 0, newArray, 0, numVectorFields);
