Index: src/test/org/apache/lucene/index/TestStressIndexing2.java
===================================================================
--- src/test/org/apache/lucene/index/TestStressIndexing2.java	(revision 887525)
+++ src/test/org/apache/lucene/index/TestStressIndexing2.java	(working copy)
@@ -28,6 +28,7 @@
 
 import junit.framework.TestCase;
 
+// nocommit -- cut test over to flex API
 public class TestStressIndexing2 extends LuceneTestCase {
   static int maxFields=4;
   static int bigFieldSize=10;
Index: src/test/org/apache/lucene/index/TestFlex.java
===================================================================
--- src/test/org/apache/lucene/index/TestFlex.java	(revision 0)
+++ src/test/org/apache/lucene/index/TestFlex.java	(revision 0)
@@ -0,0 +1,61 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.*;
+import java.util.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.util.*;
+
+public class TestFlex extends LuceneTestCase {
+
+  // Test non-flex API emulated on flex index
+  public void testNonFlex() throws Exception {
+    Directory d = new MockRAMDirectory();
+
+    final int DOC_COUNT = 177;
+
+    IndexWriter w = new IndexWriter(d, new WhitespaceAnalyzer(),
+                                    IndexWriter.MaxFieldLength.UNLIMITED);
+    w.setMaxBufferedDocs(7);
+    Document doc = new Document();
+    doc.add(new Field("field1", "this is field1", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field2", "this is field2", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field3", "aaa", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field4", "bbb", Field.Store.NO, Field.Index.ANALYZED));
+    for(int i=0;i<DOC_COUNT;i++) {
+      w.addDocument(doc);
+    }
+
+    IndexReader r = w.getReader();
+
+    TermEnum terms = r.terms(new Term("field3", "bbb"));
+    // pre-flex API should seek to the next field
+    assertNotNull(terms.term());
+    assertEquals("field4", terms.term().field());
+
+    r.close();
+    w.close();
+    d.close();
+  }
+}
+

Property changes on: src/test/org/apache/lucene/index/TestFlex.java
___________________________________________________________________
Added: svn:eol-style
   + native

Index: src/test/org/apache/lucene/index/TestFlexExternalReader.java
===================================================================
--- src/test/org/apache/lucene/index/TestFlexExternalReader.java	(revision 0)
+++ src/test/org/apache/lucene/index/TestFlexExternalReader.java	(revision 0)
@@ -0,0 +1,184 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.*;
+import java.util.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.util.*;
+
+public class TestFlexExternalReader extends LuceneTestCase {
+
+  // Delegates to a "normal" IndexReader, making it look
+  // "external", to force testing of the "flex API on
+  // external reader" layer
+  private final static class ExternalReader extends IndexReader {
+    private final IndexReader r;
+    public ExternalReader(IndexReader r) {
+      this.r = r;
+    }
+
+    public TermFreqVector[] getTermFreqVectors(int docNumber) throws IOException {
+      return r.getTermFreqVectors(docNumber);
+    }
+
+    public TermFreqVector getTermFreqVector(int docNumber, String field) throws IOException {
+      return r.getTermFreqVector(docNumber, field);
+    }
+
+    public void getTermFreqVector(int docNumber, String field, TermVectorMapper mapper) throws IOException {
+      r.getTermFreqVector(docNumber, field, mapper);
+    }
+
+    public void getTermFreqVector(int docNumber, TermVectorMapper mapper) throws IOException {
+      r.getTermFreqVector(docNumber, mapper);
+    }
+
+    public int numDocs() {
+      return r.numDocs();
+    }
+
+    public int maxDoc() {
+      return r.maxDoc();
+    }
+
+    public Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
+      return r.document(n, fieldSelector);
+    }
+
+    public boolean isDeleted(int n) {
+      return r.isDeleted(n);
+    }
+
+    public boolean hasDeletions() {
+      return r.hasDeletions();
+    }
+
+    public byte[] norms(String field) throws IOException {
+      return r.norms(field);
+    }
+
+    public void norms(String field, byte[] bytes, int offset) 
+      throws IOException {
+      r.norms(field, bytes, offset);
+    }
+    
+    protected  void doSetNorm(int doc, String field, byte value)
+      throws CorruptIndexException, IOException {
+      r.doSetNorm(doc, field, value);
+    }
+
+    public TermEnum terms() throws IOException {
+      return r.terms();
+    }
+
+    public TermEnum terms(Term t) throws IOException {
+      return r.terms(t);
+    }
+
+    public int docFreq(Term t) throws IOException {
+      return r.docFreq(t);
+    }
+
+    public TermDocs termDocs() throws IOException {
+      return r.termDocs();
+    }
+
+    public TermPositions termPositions() throws IOException {
+      return r.termPositions();
+    }
+
+    public void doDelete(int docID) throws IOException {
+      r.doDelete(docID);
+    }
+
+    public void doUndeleteAll() throws IOException {
+      r.doUndeleteAll();
+    }
+
+    protected void doCommit(Map<String, String> commitUserData) throws IOException {
+      r.doCommit(commitUserData);
+    }
+
+    protected void doClose() throws IOException {
+      r.doClose();
+    }
+
+    public Collection<String> getFieldNames(FieldOption fldOption) {
+      return r.getFieldNames(fldOption);
+    }
+  }
+
+  public void testExternalReader() throws Exception {
+    Directory d = new MockRAMDirectory();
+
+    final int DOC_COUNT = 177;
+
+    IndexWriter w = new IndexWriter(d, new WhitespaceAnalyzer(),
+                                    IndexWriter.MaxFieldLength.UNLIMITED);
+    w.setMaxBufferedDocs(7);
+    Document doc = new Document();
+    doc.add(new Field("field1", "this is field1", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field2", "this is field2", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field3", "aaa", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field4", "bbb", Field.Store.NO, Field.Index.ANALYZED));
+    for(int i=0;i<DOC_COUNT;i++) {
+      w.addDocument(doc);
+    }
+
+    IndexReader r = new ExternalReader(w.getReader());
+
+    TermRef field1Term = new TermRef("field1");
+    TermRef field2Term = new TermRef("field2");
+    TermRef thisTerm = new TermRef("this");
+
+    assertEquals(DOC_COUNT, r.maxDoc());
+    assertEquals(DOC_COUNT, r.numDocs());
+    assertEquals(DOC_COUNT, r.docFreq(new Term("field1", "field1")));
+    assertEquals(DOC_COUNT, r.docFreq("field1", field1Term));
+
+    Fields fields = r.fields();
+    Terms terms = fields.terms("field1");
+    TermsEnum termsEnum = terms.iterator();
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(field1Term));
+
+    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, termsEnum.seek(field2Term));
+    assertTrue(new TermRef("is").termEquals(termsEnum.term()));
+
+    terms = fields.terms("field2");
+    termsEnum = terms.iterator();
+    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, termsEnum.seek(field1Term));
+    assertTrue(termsEnum.term().termEquals(field2Term));
+
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(field2Term));
+
+    termsEnum = fields.terms("field3").iterator();
+    assertEquals(TermsEnum.SeekStatus.END, termsEnum.seek(new TermRef("bbb")));
+
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(new TermRef("aaa")));
+    assertNull(termsEnum.next());
+
+    r.close();
+    w.close();
+    d.close();
+  }
+}

Property changes on: src/test/org/apache/lucene/index/TestFlexExternalReader.java
___________________________________________________________________
Added: svn:eol-style
   + native

Index: src/java/org/apache/lucene/index/LegacyFieldsEnum.java
===================================================================
--- src/java/org/apache/lucene/index/LegacyFieldsEnum.java	(revision 887525)
+++ src/java/org/apache/lucene/index/LegacyFieldsEnum.java	(working copy)
@@ -65,6 +65,7 @@
     private final String field;
     private TermEnum terms;
     private TermRef current;
+    private final TermRef tr = new TermRef();
 
     LegacyTermsEnum(IndexReader r, String field) throws IOException {
       this.r = r;
@@ -80,24 +81,27 @@
 
     @Override
     public SeekStatus seek(TermRef text) throws IOException {
-
-      // nocommit: too slow?
+      
+      // nocommit -- should we optimize for "silly seek"
+      // cases, here?  ie seek to term you're already on, to
+      // very next term , etc.
       terms.close();
       terms = r.terms(new Term(field, text.toString()));
+
       final Term t = terms.term();
       if (t == null) {
         current = null;
         return SeekStatus.END;
-      } else {
-        final TermRef tr = new TermRef(t.text());
+      } else if (t.field() == field) {
+        tr.copy(t.text());
+        current = tr;
         if (text.termEquals(tr)) {
-          current = tr;
           return SeekStatus.FOUND;
         } else {
-          // nocommit reuse TermRef instance
-          current = tr;
           return SeekStatus.NOT_FOUND;
         }
+      } else {
+        return SeekStatus.END;
       }
     }
 
@@ -114,8 +118,12 @@
     @Override
     public TermRef next() throws IOException {
       if (terms.next()) {
-        // nocommit -- reuse TermRef instance
-        current = new TermRef(terms.term().text());
+        if (terms.term().field == field) {
+          tr.copy(terms.term().text());
+          current = tr;
+        } else {
+          current = null;
+        }
         return current;
       } else {
         current = null;
Index: src/java/org/apache/lucene/index/SegmentReader.java
===================================================================
--- src/java/org/apache/lucene/index/SegmentReader.java	(revision 887525)
+++ src/java/org/apache/lucene/index/SegmentReader.java	(working copy)
@@ -1354,13 +1354,14 @@
     TermRef currentTerm;
 
     public LegacyTermEnum(Term t) throws IOException {
-      //System.out.println("sr.lte.init: term=" + t);
+      // System.out.println("sr.lte.init: term=" + t);
       fields = core.fields.iterator();
       currentField = fields.next();
       if (currentField == null) {
+        // no fields
         done = true;
       } else if (t != null) {
-        // Pre-seek
+        // Pre-seek to this term
 
         // nocommit -- inefficient; do we need
         // FieldsEnum.seek? (but this is slow only for
@@ -1375,29 +1376,40 @@
         }
 
         if (!done) {
-          if (currentField == t.field) {
-            // Field matches -- get terms
-            terms = fields.terms();
+          // We found some field
+          terms = fields.terms();
+          if (currentField.equals(t.field)) {
+            // We found exactly the requested field; now
+            // seek the term text:
             String text = t.text();
             TermRef tr;
+
             // this is a hack only for backwards compatibility.
             // previously you could supply a term ending with a lead surrogate,
             // and it would return the next Term.
             // if someone does this, tack on the lowest possible trail surrogate.
             // this emulates the old behavior, and forms "valid UTF-8" unicode.
             if (text.length() > 0 
-                && Character.isHighSurrogate(text.charAt(text.length() - 1)))
+                && Character.isHighSurrogate(text.charAt(text.length() - 1))) {
               tr = new TermRef(t.text() + "\uDC00");
-            else
+            } else {
               tr = new TermRef(t.text());
+            }
             TermsEnum.SeekStatus status = terms.seek(tr);
             if (status == TermsEnum.SeekStatus.END) {
-              // leave currentTerm null
+              // Rollover to the next field
+              terms = null;
+              next();
             } else if (status == TermsEnum.SeekStatus.FOUND) {
+              // Found exactly the term
               currentTerm = tr;
             } else {
+              // Found another term, in this same field
               currentTerm = terms.term();
             }
+          } else {
+            // Advance to first term in this field:
+            next();
           }
         }
       } else {
@@ -1433,7 +1445,8 @@
           // This field still has terms
           return true;
         } else {
-          // Done producing terms from this field
+          // Done producing terms from this field; advance
+          // to next field
           terms = null;
         }
       }
@@ -1441,10 +1454,8 @@
 
     @Override
     public Term term() {
-      if (terms != null && !done) {
-        if (currentTerm != null) {
-          return new Term(currentField, currentTerm.toString());
-        }
+      if (!done && terms != null && currentTerm != null) {
+        return new Term(currentField, currentTerm.toString());
       }
       return null;
     }
Index: src/java/org/apache/lucene/index/LegacyTerms.java
===================================================================
--- src/java/org/apache/lucene/index/LegacyTerms.java	(revision 887525)
+++ src/java/org/apache/lucene/index/LegacyTerms.java	(working copy)
@@ -17,9 +17,10 @@
  * limitations under the License.
  */
 
-
 import java.io.IOException;
 
+import org.apache.lucene.util.StringHelper;
+
 /** Implements flex API (FieldsEnum/TermsEnum) on top of
  *  pre-flex API.  Used only for IndexReader impls outside
  *  Lucene's core. */
@@ -30,7 +31,7 @@
 
   LegacyTerms(IndexReader r, String field) {
     this.r = r;
-    this.field = field;
+    this.field = StringHelper.intern(field);
   }
 
   @Override
Index: src/java/org/apache/lucene/index/LegacyFields.java
===================================================================
--- src/java/org/apache/lucene/index/LegacyFields.java	(revision 887525)
+++ src/java/org/apache/lucene/index/LegacyFields.java	(working copy)
@@ -37,7 +37,6 @@
 
   @Override
   public Terms terms(String field) throws IOException {
-    // nocommit
     return new LegacyTerms(r, field);
   }
 }
