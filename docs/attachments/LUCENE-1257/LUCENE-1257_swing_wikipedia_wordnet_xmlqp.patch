Index: contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java
===================================================================
--- contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java	(revision 834281)
+++ contrib/swing/src/java/org/apache/lucene/swing/models/ListSearcher.java	(working copy)
@@ -51,7 +51,7 @@
      * The reference links between the decorated ListModel
      * and this list model based on search criteria
      */
-    private ArrayList rowToModelIndex = new ArrayList();
+    private ArrayList<Integer> rowToModelIndex = new ArrayList<Integer>();
 
     /**
      * In memory lucene index
@@ -256,12 +256,12 @@
         searchString = null;
         rowToModelIndex.clear();
         for (int t=0; t<listModel.getSize(); t++){
-            rowToModelIndex.add(Integer.valueOf(t));
+            rowToModelIndex.add(t);
         }
     }
 
     private int getModelRow(int row){
-        return ((Integer) rowToModelIndex.get(row)).intValue();
+        return rowToModelIndex.get(row);
     }
 
     public int getSize() {
Index: contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java
===================================================================
--- contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java	(revision 834281)
+++ contrib/swing/src/java/org/apache/lucene/swing/models/TableSearcher.java	(working copy)
@@ -82,7 +82,7 @@
      * these keeps reference to the decorated table model for data
      * only rows that match the search criteria are linked
      */
-    private ArrayList rowToModelIndex = new ArrayList();
+    private ArrayList<Integer> rowToModelIndex = new ArrayList<Integer>();
 
 
     //Lucene stuff.
@@ -285,7 +285,7 @@
     }
 
     private int getModelRow(int row){
-        return ((Integer) rowToModelIndex.get(row)).intValue();
+        return rowToModelIndex.get(row);
     }
 
     /**
@@ -297,7 +297,7 @@
         searchString = null;
         rowToModelIndex.clear();
         for (int t=0; t<tableModel.getRowCount(); t++){
-            rowToModelIndex.add(Integer.valueOf(t));
+            rowToModelIndex.add(t);
         }
     }
 
@@ -316,7 +316,7 @@
     }
 
     @Override
-    public Class getColumnClass(int column) {
+    public Class<?> getColumnClass(int column) {
         return tableModel.getColumnClass(column);
     }
 
Index: contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
===================================================================
--- contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java	(revision 834281)
+++ contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java	(working copy)
@@ -115,8 +115,8 @@
   private final WikipediaTokenizerImpl scanner;
 
   private int tokenOutput = TOKENS_ONLY;
-  private Set untokenizedTypes = Collections.EMPTY_SET;
-  private Iterator tokens = null;
+  private Set<String> untokenizedTypes = Collections.emptySet();
+  private Iterator<AttributeSource.State> tokens = null;
   
   private OffsetAttribute offsetAtt;
   private TypeAttribute typeAtt;
@@ -131,7 +131,7 @@
    * @param input The Input Reader
    */
   public WikipediaTokenizer(Reader input) {
-    this(input, TOKENS_ONLY, Collections.EMPTY_SET);
+    this(input, TOKENS_ONLY, Collections.<String>emptySet());
   }
 
   /**
@@ -142,7 +142,7 @@
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
    * @param untokenizedTypes
    */
-  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {
+  public WikipediaTokenizer(Reader input, int tokenOutput, Set<String> untokenizedTypes) {
     super(input);
     this.scanner = new WikipediaTokenizerImpl(input);
     init(tokenOutput, untokenizedTypes);
@@ -156,7 +156,7 @@
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
    * @param untokenizedTypes
    */
-  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {
+  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set<String> untokenizedTypes) {
     super(factory, input);
     this.scanner = new WikipediaTokenizerImpl(input);
     init(tokenOutput, untokenizedTypes);
@@ -170,13 +170,13 @@
    * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}
    * @param untokenizedTypes
    */
-  public WikipediaTokenizer(AttributeSource source, Reader input, int tokenOutput, Set untokenizedTypes) {
+  public WikipediaTokenizer(AttributeSource source, Reader input, int tokenOutput, Set<String> untokenizedTypes) {
     super(source, input);
     this.scanner = new WikipediaTokenizerImpl(input);
     init(tokenOutput, untokenizedTypes);
   }
   
-  private void init(int tokenOutput, Set untokenizedTypes) {
+  private void init(int tokenOutput, Set<String> untokenizedTypes) {
     this.tokenOutput = tokenOutput;
     this.untokenizedTypes = untokenizedTypes;
     this.offsetAtt = addAttribute(OffsetAttribute.class);
@@ -194,7 +194,7 @@
   @Override
   public final boolean incrementToken() throws IOException {
     if (tokens != null && tokens.hasNext()){
-      AttributeSource.State state = (AttributeSource.State) tokens.next();
+      AttributeSource.State state = tokens.next();
       restoreState(state);
       return true;
     }
@@ -230,7 +230,7 @@
     int lastPos = theStart + numAdded;
     int tmpTokType;
     int numSeen = 0;
-    List tmp = new ArrayList();
+    List<AttributeSource.State> tmp = new ArrayList<AttributeSource.State>();
     setupSavedToken(0, type);
     tmp.add(captureState());
     //while we can get a token and that token is the same type and we have not transitioned to a new wiki-item of the same type
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java	(revision 834281)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java	(working copy)
@@ -110,8 +110,8 @@
 								final float boost)
 		throws IOException
 	{
-		final Set already = new HashSet(); // avoid dups 
-		List top = new LinkedList(); // needs to be separately listed..
+		final Set<String> already = new HashSet<String>(); // avoid dups 
+		List<String> top = new LinkedList<String>(); // needs to be separately listed..
 		final String field = ( f == null) ? "contents" : f;
 		if ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);
 
@@ -127,7 +127,7 @@
 		final BooleanQuery tmp = new BooleanQuery();
 		
 		// [2] form query
-		Iterator it = top.iterator();
+		Iterator<String> it = top.iterator();
 		while ( it.hasNext())
 		{
 			// [2a] add to level words in
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java	(revision 834281)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java	(working copy)
@@ -120,8 +120,8 @@
 								final float boost)
 		throws IOException
 	{
-		final Set already = new HashSet(); // avoid dups		
-		List top = new LinkedList(); // needs to be separately listed..
+		final Set<String> already = new HashSet<String>(); // avoid dups		
+		List<String> top = new LinkedList<String>(); // needs to be separately listed..
 
 		// [1] Parse query into separate words so that when we expand we can avoid dups
 		TokenStream ts = a.tokenStream( field, new StringReader( query));
@@ -135,11 +135,11 @@
 		final BooleanQuery tmp = new BooleanQuery();
 		
 		// [2] form query
-		Iterator it = top.iterator();
+		Iterator<String> it = top.iterator();
 		while ( it.hasNext())
 		{
 			// [2a] add to level words in
-			String word = (String) it.next();
+			String word = it.next();
 			TermQuery tq = new TermQuery( new Term( field, word));
 			tmp.add( tq, BooleanClause.Occur.SHOULD);
 
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/SynonymMap.java
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/SynonymMap.java	(revision 834281)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/SynonymMap.java	(working copy)
@@ -106,11 +106,8 @@
    *         <code>Character.isLetter()</code>.
    */
   public String[] getSynonyms(String word) {
-    Object syns = table.get(word);
-    if (syns == null) return EMPTY;
-    if (syns instanceof String) return new String[] {(String) syns};
-    
-    String[] synonyms = (String[]) syns;
+    String[] synonyms = table.get(word);
+    if (synonyms == null) return EMPTY;
     String[] copy = new String[synonyms.length]; // copy for guaranteed immutability
     System.arraycopy(synonyms, 0, copy, 0, synonyms.length);
     return copy;
@@ -261,7 +258,7 @@
     
     
     /* Part D: compute index data structure */
-    HashMap word2Syns = createIndex(word2Groups, group2Words);    
+    HashMap<String,String[]> word2Syns = createIndex(word2Groups, group2Words);    
         
     /* Part E: minimize memory consumption by a factor 3 (or so) */
 //    if (true) return word2Syns;
@@ -308,7 +305,7 @@
     return word2Syns;
   }
 
-  private HashMap<String,String[]> optimize(HashMap word2Syns, HashMap<String,String> internedWords) {
+  private HashMap<String,String[]> optimize(HashMap<String,String[]> word2Syns, HashMap<String,String> internedWords) {
     if (DEBUG) {
       System.err.println("before gc");
       for (int i=0; i < 10; i++) System.gc();
@@ -347,10 +344,8 @@
       for (int k=syns.length; --k >= 0; ) {
         syns[k] = internedWords.get(syns[k]);
       }
-      Object replacement = syns;
-      if (syns.length == 1) replacement = syns[0]; // minimize memory consumption some more
       word2Syns.remove(words[j]);
-      word2Syns.put(internedWords.get(words[j]), replacement);
+      word2Syns.put(internedWords.get(words[j]), syns);
     }
     
     if (DEBUG) {
Index: contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java
===================================================================
--- contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java	(revision 834281)
+++ contrib/wordnet/src/java/org/apache/lucene/wordnet/Syns2Index.java	(working copy)
@@ -131,9 +131,9 @@
         String line;
 
         // maps a word to all the "groups" it's in
-        final Map word2Nums = new TreeMap();
+        final Map<String,List<String>> word2Nums = new TreeMap<String,List<String>>();
         // maps a group to all the words in it
-        final Map num2Words = new TreeMap();
+        final Map<String,List<String>> num2Words = new TreeMap<String,List<String>>();
         // number of rejected words
         int ndecent = 0;
 
@@ -177,10 +177,10 @@
 
             // 1/2: word2Nums map
             // append to entry or add new one
-            List lis =(List) word2Nums.get(word);
+            List<String> lis = word2Nums.get(word);
             if (lis == null)
             {
-                lis = new LinkedList();
+                lis = new LinkedList<String>();
                 lis.add(num);
                 word2Nums.put(word, lis);
             }
@@ -188,10 +188,10 @@
                 lis.add(num);
 
             // 2/2: num2Words map
-            lis = (List) num2Words.get(num);
+            lis = num2Words.get(num);
             if (lis == null)
             {
-                lis = new LinkedList();
+                lis = new LinkedList<String>();
                 lis.add(word);
                 num2Words.put(num, lis);
             }
@@ -236,7 +236,7 @@
      * @param word2Nums
      * @param num2Words
      */
-    private static void index(String indexDir, Map word2Nums, Map num2Words)
+    private static void index(String indexDir, Map<String,List<String>> word2Nums, Map<String,List<String>> num2Words)
         throws Throwable
     {
         int row = 0;
@@ -247,10 +247,10 @@
           // override the specific index if it already exists
           IndexWriter writer = new IndexWriter(dir, ana, true, IndexWriter.MaxFieldLength.LIMITED);
           writer.setUseCompoundFile(true); // why?
-          Iterator i1 = word2Nums.keySet().iterator();
+          Iterator<String> i1 = word2Nums.keySet().iterator();
           while (i1.hasNext()) // for each word
           {
-              String g = (String) i1.next();
+              String g = i1.next();
               Document doc = new Document();
 
               int n = index(word2Nums, num2Words, g, doc);
@@ -276,25 +276,25 @@
     /**
      * Given the 2 maps fills a document for 1 word.
      */
-    private static int index(Map word2Nums, Map num2Words, String g, Document doc)
+    private static int index(Map<String,List<String>> word2Nums, Map<String,List<String>> num2Words, String g, Document doc)
         throws Throwable
     {
-        List keys = (List) word2Nums.get(g); // get list of key#'s
-        Iterator i2 = keys.iterator();
+        List<String> keys = word2Nums.get(g); // get list of key#'s
+        Iterator<String> i2 = keys.iterator();
 
-        Set already = new TreeSet(); // keep them sorted
+        Set<String> already = new TreeSet<String>(); // keep them sorted
 
         // pass 1: fill up 'already' with all words
         while (i2.hasNext()) // for each key#
         {
-            already.addAll((List) num2Words.get(i2.next())); // get list of words
+            already.addAll(num2Words.get(i2.next())); // get list of words
         }
         int num = 0;
         already.remove(g); // of course a word is it's own syn
-        Iterator it = already.iterator();
+        Iterator<String> it = already.iterator();
         while (it.hasNext())
         {
-            String cur = (String) it.next();
+            String cur = it.next();
             // don't store things like 'pit bull' -> 'american pit bull'
             if (!isDecent(cur))
             {
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/FilterBuilderFactory.java	(working copy)
@@ -29,10 +29,10 @@
  */
 public class FilterBuilderFactory implements FilterBuilder {
 
-	HashMap builders=new HashMap();
+	HashMap<String,FilterBuilder> builders=new HashMap<String,FilterBuilder>();
 	
 	public Filter getFilter(Element n) throws ParserException {
-		FilterBuilder builder=(FilterBuilder) builders.get(n.getNodeName());
+		FilterBuilder builder= builders.get(n.getNodeName());
 		if(builder==null)
 		{
 			throw new ParserException("No FilterBuilder defined for node "+n.getNodeName()); 
@@ -45,6 +45,6 @@
 	}
 	public FilterBuilder getFilterBuilder(String nodeName)
 	{
-		return (FilterBuilder) builders.get(nodeName);		
+		return builders.get(nodeName);		
 	}	
 }
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryBuilderFactory.java	(working copy)
@@ -29,10 +29,10 @@
  */
 public class QueryBuilderFactory implements QueryBuilder {
 
-	HashMap builders=new HashMap();
+	HashMap<String,QueryBuilder> builders=new HashMap<String,QueryBuilder>();
 	
 	public Query getQuery(Element n) throws ParserException {
-		QueryBuilder builder=(QueryBuilder) builders.get(n.getNodeName());
+		QueryBuilder builder= builders.get(n.getNodeName());
 		if(builder==null)
 		{
 			throw new ParserException("No QueryObjectBuilder defined for node "+n.getNodeName()); 
@@ -45,7 +45,7 @@
 	}
 	public QueryBuilder getQueryBuilder(String nodeName)
 	{
-		return (QueryBuilder) builders.get(nodeName);		
+		return builders.get(nodeName);		
 	}
 	
 }
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/QueryTemplateManager.java	(working copy)
@@ -55,7 +55,7 @@
 	static DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance ();
 	static TransformerFactory tFactory = TransformerFactory.newInstance();
 
-	HashMap compiledTemplatesCache=new HashMap();
+	HashMap<String,Templates> compiledTemplatesCache=new HashMap<String,Templates>();
 	Templates defaultCompiledTemplates=null;
 
 	
@@ -77,13 +77,13 @@
 	}
 	public String getQueryAsXmlString(Properties formProperties,String queryTemplateName) throws SAXException, IOException, ParserConfigurationException, TransformerException
 	{
-		Templates ts=(Templates) compiledTemplatesCache.get(queryTemplateName);
+		Templates ts= compiledTemplatesCache.get(queryTemplateName);
 		return getQueryAsXmlString(formProperties, ts);
 	}
 	
 	public Document getQueryAsDOM(Properties formProperties,String queryTemplateName) throws SAXException, IOException, ParserConfigurationException, TransformerException
 	{
-		Templates ts=(Templates) compiledTemplatesCache.get(queryTemplateName);
+		Templates ts= compiledTemplatesCache.get(queryTemplateName);
 		return getQueryAsDOM(formProperties, ts);
 	}
 	public String getQueryAsXmlString(Properties formProperties) throws SAXException, IOException, ParserConfigurationException, TransformerException
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/CachedFilterBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/CachedFilterBuilder.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/CachedFilterBuilder.java	(working copy)
@@ -53,7 +53,7 @@
 	private QueryBuilderFactory queryFactory;
 	private FilterBuilderFactory filterFactory;
 	
-    private  LRUCache filterCache = null;
+    private  LRUCache<Object,Filter> filterCache = null;
 
 	private int cacheSize;
 
@@ -72,7 +72,7 @@
 
 		if (filterCache == null)
 		{
-			filterCache = new LRUCache(cacheSize);
+			filterCache = new LRUCache<Object,Filter>(cacheSize);
 		}
 
 		// Test to see if child Element is a query or filter that needs to be
@@ -90,7 +90,7 @@
 			f = filterFactory.getFilter(childElement);
 			cacheKey = f;
 		}
-		Filter cachedFilter = (Filter) filterCache.get(cacheKey);
+		Filter cachedFilter = filterCache.get(cacheKey);
 		if (cachedFilter != null)
 		{
 			return cachedFilter; // cache hit
@@ -109,7 +109,7 @@
 		return cachedFilter;
 	}
 	
-	static class LRUCache extends java.util.LinkedHashMap
+	static class LRUCache<K,V> extends java.util.LinkedHashMap<K,V>
 	{
 	    public LRUCache(int maxsize)
 	    {
@@ -120,7 +120,7 @@
 	    protected int maxsize;
 
 	    @Override
-	    protected boolean removeEldestEntry(Entry eldest)
+	    protected boolean removeEldestEntry(Entry<K,V> eldest)
 	    {
 	        return size() > maxsize;
 	    }
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java	(working copy)
@@ -70,10 +70,10 @@
 		//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then 
 		//I use all analyzers/fields to generate multi-field compatible stop list
 		String stopWords=e.getAttribute("stopWords");
-		Set stopWordsSet=null;
+		Set<String> stopWordsSet=null;
 		if((stopWords!=null)&&(fields!=null))
 		{
-		    stopWordsSet=new HashSet();
+		    stopWordsSet=new HashSet<String>();
 		    for (int i = 0; i < fields.length; i++)
             {
                 TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanNearBuilder.java	(working copy)
@@ -41,7 +41,7 @@
  		String slopString=DOMUtils.getAttributeOrFail(e,"slop");
   		int slop=Integer.parseInt(slopString);
 		boolean inOrder=DOMUtils.getAttribute(e,"inOrder",false);
-		ArrayList spans=new ArrayList();
+		ArrayList<SpanQuery> spans=new ArrayList<SpanQuery>();
 		for (Node kid = e.getFirstChild(); kid != null; kid = kid.getNextSibling())
 		{
 				if (kid.getNodeType() == Node.ELEMENT_NODE) 
@@ -49,7 +49,7 @@
 					spans.add(factory.getSpanQuery((Element) kid));
 				}
 		}
-		SpanQuery[] spanQueries=(SpanQuery[]) spans.toArray(new SpanQuery[spans.size()]);
+		SpanQuery[] spanQueries= spans.toArray(new SpanQuery[spans.size()]);
 		SpanNearQuery snq=new SpanNearQuery(spanQueries,slop,inOrder);
 		return snq;
 	}
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrBuilder.java	(working copy)
@@ -41,7 +41,7 @@
     
 	public SpanQuery getSpanQuery(Element e) throws ParserException
 	{
-	    ArrayList clausesList=new ArrayList();
+	    ArrayList<SpanQuery> clausesList=new ArrayList<SpanQuery>();
 		for (Node kid = e.getFirstChild(); kid != null; kid = kid.getNextSibling())
 		{
 			if (kid.getNodeType() == Node.ELEMENT_NODE) 
@@ -50,7 +50,7 @@
 				clausesList.add(clause);				
 			}
 		}	    
-		SpanQuery[] clauses=(SpanQuery[]) clausesList.toArray(new SpanQuery[clausesList.size()]);
+		SpanQuery[] clauses= clausesList.toArray(new SpanQuery[clausesList.size()]);
 		SpanOrQuery soq = new SpanOrQuery(clauses);		
 		soq.setBoost(DOMUtils.getAttribute(e,"boost",1.0f));
 		return soq;
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java	(working copy)
@@ -54,7 +54,7 @@
 		
 		try
 		{
-			ArrayList clausesList=new ArrayList();
+			ArrayList<SpanQuery> clausesList=new ArrayList<SpanQuery>();
 			TokenStream ts=analyzer.tokenStream(fieldName,new StringReader(value));
 			TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 			
@@ -62,7 +62,7 @@
 			    SpanTermQuery stq=new SpanTermQuery(new Term(fieldName, termAtt.term()));
 			    clausesList.add(stq);
 			}
-			SpanOrQuery soq=new SpanOrQuery((SpanQuery[]) clausesList.toArray(new SpanQuery[clausesList.size()]));
+			SpanOrQuery soq=new SpanOrQuery(clausesList.toArray(new SpanQuery[clausesList.size()]));
 			soq.setBoost(DOMUtils.getAttribute(e,"boost",1.0f));
 			return soq;
 		}
Index: contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java
===================================================================
--- contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java	(revision 834281)
+++ contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanQueryBuilderFactory.java	(working copy)
@@ -28,7 +28,7 @@
  */
 public class SpanQueryBuilderFactory implements SpanQueryBuilder {
 
-	HashMap builders=new HashMap();
+	HashMap<String,SpanQueryBuilder> builders=new HashMap<String,SpanQueryBuilder>();
 	
 	public Query getQuery(Element e) throws ParserException {
 		return getSpanQuery(e);
@@ -39,7 +39,7 @@
 	}
 	public SpanQuery getSpanQuery(Element e) throws ParserException
 	{
-		SpanQueryBuilder builder=(SpanQueryBuilder) builders.get(e.getNodeName());
+		SpanQueryBuilder builder= builders.get(e.getNodeName());
 		if(builder==null)
 		{
 			throw new ParserException("No SpanQueryObjectBuilder defined for node "+e.getNodeName()); 
