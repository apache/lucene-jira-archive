Index: lucene/classification/src/test/org/apache/lucene/classification/BasicTestDataset.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/BasicTestDataset.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/BasicTestDataset.java	(working copy)
@@ -0,0 +1,244 @@
+package org.apache.lucene.classification;
+
+import java.io.IOException;
+import java.util.Random;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class BasicTestDataset<T> implements TestDataset{
+
+  public final String POLITICS_INPUT = "Here are some interesting questions and answers about Mitt Romney.. " +
+      "If you don't know the answer to the question about Mitt Romney, then simply click on the answer below the question section.";
+  public final BytesRef POLITICS_RESULT = new BytesRef("politics");
+
+  public final String TECHNOLOGY_INPUT = "Much is made of what the likes of Facebook, Google and Apple know about users." +
+      " Truth is, Amazon may know more.";
+  public final BytesRef TECHNOLOGY_RESULT = new BytesRef("technology");
+  
+  private String textFieldName;
+  private String categoryFieldName;
+  private String booleanFieldName;
+  
+  private RandomIndexWriter indexWriter;
+  private FieldType ft;
+  
+  
+  public String getTextFieldName() {
+    return textFieldName;
+  }
+
+  public String getCategoryFieldName() {
+    return categoryFieldName;
+  }
+
+  public void setUp(RandomIndexWriter indexWriter) throws Exception {
+    this.indexWriter=indexWriter;
+    textFieldName = "text";
+    categoryFieldName = "cat";
+    booleanFieldName = "bool";
+    ft = new FieldType(TextField.TYPE_STORED);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorOffsets(true);
+    ft.setStoreTermVectorPositions(true);
+  }
+  
+  private String createRandomString(Random random) {
+    StringBuilder builder = new StringBuilder();
+    for (int i = 0; i < 20; i++) {
+      builder.append(TestUtil.randomSimpleString(random, 5));
+      builder.append(" ");
+    }
+    return builder.toString();
+  }
+  
+  public void populateSampleIndex(Analyzer analyzer) throws IOException {
+    indexWriter.deleteAll();
+    indexWriter.commit();
+
+    String text;
+
+    Document doc = new Document();
+    text = "The traveling press secretary for Mitt Romney lost his cool and cursed at reporters " +
+        "who attempted to ask questions of the Republican presidential candidate in a public plaza near the Tomb of " +
+        "the Unknown Soldier in Warsaw Tuesday.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Mitt Romney seeks to assure Israel and Iran, as well as Jewish voters in the United" +
+        " States, that he will be tougher against Iran's nuclear ambitions than President Barack Obama.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "And there's a threshold question that he has to answer for the American people and " +
+        "that's whether he is prepared to be commander-in-chief,\" she continued. \"As we look to the past events, we " +
+        "know that this raises some questions about his preparedness and we'll see how the rest of his trip goes.\"";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Still, when it comes to gun policy, many congressional Democrats have \"decided to " +
+        "keep quiet and not go there,\" said Alan Lizotte, dean and professor at the State University of New York at " +
+        "Albany's School of Criminal Justice.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Standing amongst the thousands of people at the state Capitol, Jorstad, director of " +
+        "technology at the University of Wisconsin-La Crosse, documented the historic moment and shared it with the " +
+        "world through the Internet.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "So, about all those experts and analysts who've spent the past year or so saying " +
+        "Facebook was going to make a phone. A new expert has stepped forward to say it's not going to happen.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "More than 400 million people trust Google with their e-mail, and 50 million store files" +
+        " in the cloud using the Dropbox service. People manage their bank accounts, pay bills, trade stocks and " +
+        "generally transfer or store huge volumes of personal data online.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "unlabeled doc";
+    doc.add(new Field(textFieldName, text, ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    indexWriter.commit();
+  }
+  
+  public void populatePerformanceIndex(Analyzer analyzer) throws IOException {
+    indexWriter.deleteAll();
+    indexWriter.commit();
+
+    FieldType ft = new FieldType(TextField.TYPE_STORED);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorOffsets(true);
+    ft.setStoreTermVectorPositions(true);
+    int docs = 1000;
+    Random random = LuceneTestCase.random();
+    for (int i = 0; i < docs; i++) {
+      boolean b = random.nextBoolean();
+      Document doc = new Document();
+      doc.add(new Field(textFieldName, createRandomString(random), ft));
+      doc.add(new Field(categoryFieldName, b ? "technology" : "politics", ft));
+      doc.add(new Field(booleanFieldName, String.valueOf(b), ft));
+      indexWriter.addDocument(doc, analyzer);
+    }
+    indexWriter.commit();
+  }
+  
+  public void updateSampleIndex(Analyzer analyzer) throws Exception {
+
+    String text;
+
+    Document doc = new Document();
+    text = "Warren Bennis says John F. Kennedy grasped a key lesson about the presidency that few have followed.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Julian Zelizer says Bill Clinton is still trying to shape his party, years after the White House, while George W. Bush opts for a much more passive role.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Crossfire: Sen. Tim Scott passes on Sen. Lindsey Graham endorsement";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Illinois becomes 16th state to allow same-sex marriage.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "politics", ft));
+    doc.add(new Field(booleanFieldName, "true", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Apple is developing iPhones with curved-glass screens and enhanced sensors that detect different levels of pressure, according to a new report.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "The Xbox One is Microsoft's first new gaming console in eight years. It's a quality piece of hardware but it's also noteworthy because Microsoft is using it to make a statement.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "Google says it will replace a Google Maps image after a California father complained it shows the body of his teen-age son, who was shot to death in 2009.";
+    doc.add(new Field(textFieldName, text, ft));
+    doc.add(new Field(categoryFieldName, "technology", ft));
+    doc.add(new Field(booleanFieldName, "false", ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    doc = new Document();
+    text = "second unlabeled doc";
+    doc.add(new Field(textFieldName, text, ft));
+    indexWriter.addDocument(doc, analyzer);
+
+    indexWriter.commit();
+  }
+
+  
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/CNBTest.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/CNBTest.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/CNBTest.java	(working copy)
@@ -0,0 +1,218 @@
+package org.apache.lucene.classification;
+
+import java.util.List;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
+import org.apache.lucene.analysis.reverse.ReverseStringFilter;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class CNBTest extends LuceneTestCase{
+  private RandomIndexWriter indexWriter;
+  private Directory dir;
+  
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+    indexWriter = new RandomIndexWriter(random(), dir);
+  }
+
+  @Test
+  public void testBasicUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new CachingNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+    ta.checkCorrectClassification(new CachingNaiveBayesClassifier(), td.POLITICS_INPUT, td.POLITICS_RESULT, analyzer, indexWriter.getReader(), td);
+    
+  }
+
+  @Test
+  public void testBasicUsageWithQuery() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new CachingNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td, new TermQuery(new Term(td.getTextFieldName(), "it")));
+    
+  }
+
+  @Test
+  public void testNGramUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new NGramAnalyzer();
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new CachingNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+  }
+
+  private class NGramAnalyzer extends Analyzer {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      final Tokenizer tokenizer = new KeywordTokenizer();
+      return new TokenStreamComponents(tokenizer, new ReverseStringFilter(TEST_VERSION_CURRENT, new EdgeNGramTokenFilter(TEST_VERSION_CURRENT, new ReverseStringFilter(TEST_VERSION_CURRENT, tokenizer), 10, 20)));
+    }
+  }
+
+  @Test
+  public void testPerformance() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populatePerformanceIndex(analyzer);
+    ta.checkPerformance(new CachingNaiveBayesClassifier(), analyzer, indexWriter.getReader(), td);
+  }
+  
+  @Test
+  public void testOnline() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    CachingNaiveBayesClassifier classifier=new CachingNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    mtd.trainset1(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.A_RESULT, analyzer, indexWriter.getReader(), mtd);
+    mtd.onlinePachSet(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.B_RESULT, analyzer, indexWriter.getReader(), mtd);
+  }
+  
+  @Test
+  public void testNormalizedList() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    CachingNaiveBayesClassifier classifier=new CachingNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==3);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedListWithMax() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    CachingNaiveBayesClassifier classifier=new CachingNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT,2);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      //assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got too much element " + classificationResult.size(), classificationResult.size() <= 2);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==2);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedValue() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    CachingNaiveBayesClassifier classifier=new CachingNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      ClassificationResult<BytesRef> classificationResult = classifier.assignClass(mtd.A_INPUT);
+      
+      //mathematical inaccurancy
+      assertTrue("got a too big score " + classificationResult.getScore(), classificationResult.getScore() <= 1.0);
+      assertTrue("got a too small score " + classificationResult.getScore(), classificationResult.getScore() >= 0.0);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+    indexWriter.shutdown();
+    dir.close();
+  }
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/KNNTest.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/KNNTest.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/KNNTest.java	(working copy)
@@ -0,0 +1,223 @@
+package org.apache.lucene.classification;
+
+import java.util.List;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
+import org.apache.lucene.analysis.reverse.ReverseStringFilter;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class KNNTest extends LuceneTestCase{
+  private RandomIndexWriter indexWriter;
+  private Directory dir;
+  
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+    indexWriter = new RandomIndexWriter(random(), dir);
+  }
+
+  @Test
+  public void testBasicUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new KNearestNeighborClassifier(3), td.POLITICS_INPUT, td.POLITICS_RESULT, analyzer, indexWriter.getReader(), td);
+    ta.checkCorrectClassification(new KNearestNeighborClassifier(3, 2, 1), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+    
+  }
+
+  @Test
+  public void testBasicUsageWithQuery() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new KNearestNeighborClassifier(1), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td, new TermQuery(new Term(td.getTextFieldName(), "it")));
+    
+  }
+
+  @Test
+  public void testNGramUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new NGramAnalyzer();
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new KNearestNeighborClassifier(100), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+  }
+
+  private class NGramAnalyzer extends Analyzer {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      final Tokenizer tokenizer = new KeywordTokenizer();
+      return new TokenStreamComponents(tokenizer, new ReverseStringFilter(TEST_VERSION_CURRENT, new EdgeNGramTokenFilter(TEST_VERSION_CURRENT, new ReverseStringFilter(TEST_VERSION_CURRENT, tokenizer), 10, 20)));
+    }
+  }
+
+  @Test
+  public void testPerformance() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populatePerformanceIndex(analyzer);
+    ta.checkPerformance(new KNearestNeighborClassifier(100), analyzer, indexWriter.getReader(), td);
+  }
+  
+  @Test
+  public void testOnline() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    KNearestNeighborClassifier classifier=new KNearestNeighborClassifier(3);
+    mtd.setUp(indexWriter);
+    
+    mtd.trainset1(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.A_RESULT, analyzer, indexWriter.getReader(), mtd);
+    mtd.onlinePachSet(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.B_RESULT, analyzer, indexWriter.getReader(), mtd);
+  }
+  
+  @Test
+  public void testNormalizedList() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    KNearestNeighborClassifier classifier=new KNearestNeighborClassifier(100);
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==3);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedListWithMax() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    KNearestNeighborClassifier classifier=new KNearestNeighborClassifier(100);
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT,2);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+    //assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got too much element " + classificationResult.size(), classificationResult.size() <= 2);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==2);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedListSmallerRange() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    KNearestNeighborClassifier classifier=new KNearestNeighborClassifier(3);
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==1);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+    indexWriter.shutdown();
+    dir.close();
+  }
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/MathematicalTestDataset.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/MathematicalTestDataset.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/MathematicalTestDataset.java	(working copy)
@@ -0,0 +1,136 @@
+package org.apache.lucene.classification;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.util.BytesRef;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class MathematicalTestDataset implements TestDataset{
+  
+  public final String A_INPUT = "z z z z z z";
+  public final BytesRef A_RESULT = new BytesRef("a");
+  
+  public final String B_INPUT = "y y y y y y";
+  public final BytesRef B_RESULT = new BytesRef("b");
+  
+  
+  
+  private String textFieldName;
+  private String categoryFieldName;
+  private String booleanFieldName;
+  
+  private RandomIndexWriter indexWriter;
+  private FieldType ft;
+  
+  
+  public String getTextFieldName() {
+    return textFieldName;
+  }
+
+  public String getCategoryFieldName() {
+    return categoryFieldName;
+  }
+
+  public void setUp(RandomIndexWriter indexWriter) throws Exception {
+    this.indexWriter=indexWriter;
+    textFieldName = "text";
+    categoryFieldName = "cat";
+    booleanFieldName = "bool";
+    ft = new FieldType(TextField.TYPE_STORED);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorOffsets(true);
+    ft.setStoreTermVectorPositions(true);
+  }
+  
+  
+  
+  private String mathematical3DString(int x, int y, int z){
+    String text=new String();
+    
+    for(int i=0;i<x;i++)
+      text += "x ";
+    
+    for(int i=0;i<y;i++)
+      text += "y ";
+    
+    for(int i=0;i<z;i++)
+      text += "z ";
+    
+    return text;
+  }
+  private Document mathematical3DDoc(int x, int y, int z, String className){
+    Document doc = new Document();
+    
+    doc.add(new Field(textFieldName, mathematical3DString(x,y,z), ft));
+    doc.add(new Field(categoryFieldName, className, ft));
+    return doc;
+  }
+  /**
+   * Add a new document to the test set. These documents can easily representable
+   * in a 3D plot. There are 3 word in these test text (x, y, and z), and the 
+   * occurrence is the displacement on the plots.
+   * 
+   * @param x the occurrence number of "x" word
+   * @param y the occurrence number of "y" word
+   * @param z the occurrence number of "z" word
+   * @param className the name of the class where the document belongs to
+   * @param analyzer it is needed for document adding
+   */
+  public void mathematical3DTrain(int x, int y, int z, String className, Analyzer analyzer) throws IOException{
+    
+    Document doc =  mathematical3DDoc(x, y, z, className);
+    indexWriter.addDocument(doc, analyzer);
+  }
+  
+  public void trainset1(Analyzer analyzer) throws IOException{
+    indexWriter.deleteAll();
+    indexWriter.commit();
+    
+    mathematical3DTrain(0, 0, 5, "a", analyzer);
+    mathematical3DTrain(0, 1, 4, "a", analyzer);
+    mathematical3DTrain(1, 0, 4, "a", analyzer);
+    
+    mathematical3DTrain(0, 5, 0, "b", analyzer);
+    mathematical3DTrain(1, 4, 0, "b", analyzer);
+    mathematical3DTrain(0, 4, 1, "b", analyzer);
+    
+    mathematical3DTrain(5, 0, 0, "c", analyzer);
+    mathematical3DTrain(4, 1, 0, "c", analyzer);
+    mathematical3DTrain(4, 0, 1, "c", analyzer);
+    
+    indexWriter.commit();
+  }
+  
+  public void onlinePachSet(Analyzer analyzer) throws IOException{
+    mathematical3DTrain(0, 0, 5, "b", analyzer);
+    mathematical3DTrain(0, 1, 4, "b", analyzer);
+    mathematical3DTrain(1, 0, 4, "b", analyzer);
+    mathematical3DTrain(0, 0, 5, "b", analyzer);
+    mathematical3DTrain(0, 1, 4, "b", analyzer);
+    mathematical3DTrain(1, 0, 4, "b", analyzer);
+    
+    indexWriter.commit();
+  }
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/SNBTest.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/SNBTest.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/SNBTest.java	(working copy)
@@ -0,0 +1,219 @@
+package org.apache.lucene.classification;
+
+import java.util.List;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
+import org.apache.lucene.analysis.reverse.ReverseStringFilter;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class SNBTest extends LuceneTestCase {
+  
+  private RandomIndexWriter indexWriter;
+  private Directory dir;
+  
+  @Override
+  @Before
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+    indexWriter = new RandomIndexWriter(random(), dir);
+  }
+
+  @Test
+  public void testBasicUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new SimpleNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+    ta.checkCorrectClassification(new SimpleNaiveBayesClassifier(), td.POLITICS_INPUT, td.POLITICS_RESULT, analyzer, indexWriter.getReader(), td);
+    
+  }
+
+  @Test
+  public void testBasicUsageWithQuery() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new SimpleNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td, new TermQuery(new Term(td.getTextFieldName(), "it")));
+    
+  }
+
+  @Test
+  public void testNGramUsage() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new NGramAnalyzer();
+    td.setUp(indexWriter);
+    
+    td.populateSampleIndex(analyzer);
+    ta.checkCorrectClassification(new SimpleNaiveBayesClassifier(), td.TECHNOLOGY_INPUT, td.TECHNOLOGY_RESULT, analyzer, indexWriter.getReader(), td);
+  }
+
+  private class NGramAnalyzer extends Analyzer {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName) {
+      final Tokenizer tokenizer = new KeywordTokenizer();
+      return new TokenStreamComponents(tokenizer, new ReverseStringFilter(TEST_VERSION_CURRENT, new EdgeNGramTokenFilter(TEST_VERSION_CURRENT, new ReverseStringFilter(TEST_VERSION_CURRENT, tokenizer), 10, 20)));
+    }
+  }
+
+  @Test
+  public void testPerformance() throws Exception {
+    BasicTestDataset<BytesRef> td=new BasicTestDataset<BytesRef>();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    td.setUp(indexWriter);
+    
+    td.populatePerformanceIndex(analyzer);
+    ta.checkPerformance(new SimpleNaiveBayesClassifier(), analyzer, indexWriter.getReader(), td);
+  }
+  
+  @Test
+  public void testOnline() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    SimpleNaiveBayesClassifier classifier=new SimpleNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    mtd.trainset1(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.A_RESULT, analyzer, indexWriter.getReader(), mtd);
+    mtd.onlinePachSet(analyzer);
+    ta.checkCorrectClassification(classifier, mtd.A_INPUT, mtd.B_RESULT, analyzer, indexWriter.getReader(), mtd);
+  }
+  
+  @Test
+  public void testNormalizedList() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    SimpleNaiveBayesClassifier classifier=new SimpleNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==3);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedListWithMax() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    SimpleNaiveBayesClassifier classifier=new SimpleNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      List<ClassificationResult<BytesRef>> classificationResult = classifier.getClasses(mtd.A_INPUT,2);
+      double sum=0;
+      for(ClassificationResult<BytesRef> resultItem : classificationResult){
+        sum+=resultItem.getScore();
+      }
+      //mathematical inaccurancy
+      assertTrue("got a too big score sum " + sum, sum < 1.1);
+      //assertTrue("got a too small score sum " + sum, sum > 0.9);
+      assertTrue("got too much element " + classificationResult.size(), classificationResult.size() <= 2);
+      assertTrue("got not accurate neighbor number " + classificationResult.size(), classificationResult.size()==2);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Test
+  public void testNormalizedValue() throws Exception{
+    MathematicalTestDataset mtd=new MathematicalTestDataset();
+    TestAssertion<BytesRef> ta=new TestAssertion<BytesRef>();
+    Analyzer analyzer=new MockAnalyzer(random());
+    SimpleNaiveBayesClassifier classifier=new SimpleNaiveBayesClassifier();
+    mtd.setUp(indexWriter);
+    
+    
+    mtd.trainset1(analyzer);
+    AtomicReader atomicReader = null;
+    try{
+      atomicReader = SlowCompositeReaderWrapper.wrap(indexWriter.getReader());
+      classifier.train(atomicReader, mtd.getTextFieldName(), mtd.getCategoryFieldName(), analyzer);
+      
+      ClassificationResult<BytesRef> classificationResult = classifier.assignClass(mtd.A_INPUT);
+      
+      //mathematical inaccurancy
+      assertTrue("got a too big score " + classificationResult.getScore(), classificationResult.getScore() <= 1.0);
+      assertTrue("got a too small score " + classificationResult.getScore(), classificationResult.getScore() >= 0.0);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+    
+  }
+  
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+    indexWriter.shutdown();
+    dir.close();
+  }
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/TestAssertion.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/TestAssertion.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/TestAssertion.java	(working copy)
@@ -0,0 +1,67 @@
+package org.apache.lucene.classification;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SlowCompositeReaderWrapper;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.store.Directory;
+import org.junit.Assert;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestAssertion<T> extends Assert{  
+  protected void checkCorrectClassification(Classifier<T> classifier, String inputDoc, T expectedResult, Analyzer analyzer, DirectoryReader directoryReader, TestDataset testDataset) throws Exception {
+    checkCorrectClassification(classifier, inputDoc, expectedResult, analyzer, directoryReader, testDataset, null);
+  }
+
+  protected void checkCorrectClassification(Classifier<T> classifier, String inputDoc, T expectedResult, Analyzer analyzer, DirectoryReader directoryReader, TestDataset testDataset, Query query) throws Exception {
+    AtomicReader atomicReader = null;
+    try {
+      atomicReader = SlowCompositeReaderWrapper.wrap(directoryReader);
+      classifier.train(atomicReader, testDataset.getTextFieldName(), testDataset.getCategoryFieldName(), analyzer, query);
+      ClassificationResult<T> classificationResult = classifier.assignClass(inputDoc);
+      assertNotNull(classificationResult.getAssignedClass());
+      assertEquals("got an assigned class of " + classificationResult.getAssignedClass(), expectedResult, classificationResult.getAssignedClass());
+      assertTrue("got a not positive score " + classificationResult.getScore(), classificationResult.getScore() > 0);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+  }
+  
+  protected void checkPerformance(Classifier<T> classifier, Analyzer analyzer, DirectoryReader directoryReader, TestDataset testDataset) throws Exception {
+    AtomicReader atomicReader = null;
+    long trainStart = System.currentTimeMillis();
+    try {
+      atomicReader = SlowCompositeReaderWrapper.wrap(directoryReader);
+      classifier.train(atomicReader, testDataset.getTextFieldName(), testDataset.getCategoryFieldName(), analyzer);
+      long trainEnd = System.currentTimeMillis();
+      long trainTime = trainEnd - trainStart;
+      assertTrue("training took more than 2 mins : " + trainTime / 1000 + "s", trainTime < 120000);
+    } finally {
+      if (atomicReader != null)
+        atomicReader.close();
+    }
+  }
+
+}
Index: lucene/classification/src/test/org/apache/lucene/classification/TestDataset.java
===================================================================
--- lucene/classification/src/test/org/apache/lucene/classification/TestDataset.java	(revision 0)
+++ lucene/classification/src/test/org/apache/lucene/classification/TestDataset.java	(working copy)
@@ -0,0 +1,30 @@
+package org.apache.lucene.classification;
+
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.RandomIndexWriter;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public interface TestDataset {
+  public String getTextFieldName();
+
+  public String getCategoryFieldName();
+
+  public void setUp(RandomIndexWriter indexWriter) throws Exception;
+}
