diff --git build.xml build.xml
index 6e32216..56468be 100644
--- build.xml
+++ build.xml
@@ -277,7 +277,7 @@
 
     <echo>
       SUCCESS: You must right-click your project and choose Refresh.
-               Your project must use a Java 7 JRE.
+               Your project must use a Java 8 JRE.
     </echo>
   </target>
 
@@ -324,7 +324,7 @@ following two XML attributes/values (adjust values according to
 JDKs you have defined locally - see 
 File | Project Structure | Platform Settings | SDKs):
 
-    idea.jdk = project-jdk-name="1.7" project-jdk-type="JavaSDK"
+    idea.jdk = project-jdk-name="1.8" project-jdk-type="JavaSDK"
     </echo>
   </target>
 
@@ -371,22 +371,13 @@ File | Project Structure | Platform Settings | SDKs):
     </subant>
   </target>
   
-  <target name="-nightly-smoke-java8params" if="smokeTestRelease.java8">
-    <!-- convert path to UNIX style, so windows backslashes don't hurt escaping: -->
-    <pathconvert targetos="unix" property="-smokeTestRelease.java8params">
-      <regexpmapper from="^(.*)$" to="--test-java8 '\1'"/>
-      <path location="${smokeTestRelease.java8}"/>
-    </pathconvert>
-  </target>
-
-  <target name="nightly-smoke" description="Builds an unsigned release and smoke tests it (pass '-DsmokeTestRelease.java8=/path/to/jdk1.8.0' to additionally test with Java 8)"
-    depends="clean,-nightly-smoke-java8params">
-    <fail message="To run nightly smoke, the JDK must be exactly Java 1.7, was: ${java.specification.version}">
+  <target name="nightly-smoke" description="Builds an unsigned release and smoke tests it"
+    depends="clean">
+    <fail message="To run nightly smoke, the JDK must be exactly Java 1.8, was: ${java.specification.version}">
       <condition>
-        <not><equals arg1="${java.specification.version}" arg2="1.7"/></not>
+        <not><equals arg1="${java.specification.version}" arg2="1.8"/></not>
       </condition>
     </fail>
-    <property name="-smokeTestRelease.java8params" value=""/><!-- (if not yet defined) -->
     <exec executable="${python32.exe}" failonerror="true" taskname="python32">
       <arg value="-V"/>
     </exec>
@@ -410,7 +401,6 @@ File | Project Structure | Platform Settings | SDKs):
       <!-- Tell Python not to write any bytecode cache into the filesystem: -->
       <arg value="-B"/>
       <arg file="dev-tools/scripts/smokeTestRelease.py"/>
-      <arg line="${-smokeTestRelease.java8params}"/>
       <arg value="--revision"/>
       <arg value="skip"/>
       <!-- pass ${version.base} here to emulate a real release, without appendix like "-SNAPSHOT": -->
diff --git dev-tools/eclipse/dot.settings/org.eclipse.jdt.core.prefs dev-tools/eclipse/dot.settings/org.eclipse.jdt.core.prefs
index c852727..5ad4c2a 100644
--- dev-tools/eclipse/dot.settings/org.eclipse.jdt.core.prefs
+++ dev-tools/eclipse/dot.settings/org.eclipse.jdt.core.prefs
@@ -1,7 +1,7 @@
 #Sun Sep 23 13:02:27 EDT 2012
 eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.compliance=1.7
+org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.8
+org.eclipse.jdt.core.compiler.compliance=1.8
 org.eclipse.jdt.core.compiler.doc.comment.support=enabled
 org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
 org.eclipse.jdt.core.compiler.problem.enumIdentifier=error
@@ -18,7 +18,7 @@ org.eclipse.jdt.core.compiler.problem.missingJavadocTags=ignore
 org.eclipse.jdt.core.compiler.problem.missingJavadocTagsMethodTypeParameters=disabled
 org.eclipse.jdt.core.compiler.problem.missingJavadocTagsOverriding=disabled
 org.eclipse.jdt.core.compiler.problem.missingJavadocTagsVisibility=public
-org.eclipse.jdt.core.compiler.source=1.7
+org.eclipse.jdt.core.compiler.source=1.8
 org.eclipse.jdt.core.formatter.align_type_members_on_columns=false
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_allocation_expression=16
 org.eclipse.jdt.core.formatter.alignment_for_arguments_in_annotation=0
diff --git dev-tools/idea/.idea/modules.xml dev-tools/idea/.idea/modules.xml
index 5c096a6..762e885 100644
--- dev-tools/idea/.idea/modules.xml
+++ dev-tools/idea/.idea/modules.xml
@@ -56,7 +56,6 @@
       <module group="Solr/Contrib" filepath="$PROJECT_DIR$/solr/contrib/morphlines-core/morphlines-core.iml" />
       <module group="Solr/Contrib" filepath="$PROJECT_DIR$/solr/contrib/uima/uima.iml" />
       <module group="Solr/Contrib" filepath="$PROJECT_DIR$/solr/contrib/velocity/velocity.iml" />
-      <module group="Solr/Contrib" filepath="$PROJECT_DIR$/solr/contrib/analytics/analytics.iml" />
     </modules>
   </component>
 </project>
diff --git dev-tools/idea/.idea/workspace.xml dev-tools/idea/.idea/workspace.xml
index 2db9014..4510770 100644
--- dev-tools/idea/.idea/workspace.xml
+++ dev-tools/idea/.idea/workspace.xml
@@ -316,15 +316,6 @@
       <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
       <patterns><pattern testClass=".*\.Test[^.]*|.*\.[^.]*Test" /></patterns>
     </configuration>
-    <configuration default="false" name="Solr analytics contrib" type="JUnit" factoryName="JUnit">
-      <module name="analytics" />
-      <option name="TEST_OBJECT" value="pattern" />
-      <option name="WORKING_DIRECTORY" value="file://$PROJECT_DIR$/idea-build/solr/contrib/solr-analytics" />
-      <option name="VM_PARAMETERS" value="-ea" />
-      <option name="TEST_SEARCH_SCOPE"><value defaultName="singleModule" /></option>
-      <patterns><pattern testClass=".*\.Test[^.]*|.*\.[^.]*Test" /></patterns>
-    </configuration>
- 
     <list size="39">
       <item index="0" class="java.lang.String" itemvalue="JUnit.Lucene core" />
       <item index="1" class="java.lang.String" itemvalue="JUnit.Module analyzers-common" />
diff --git dev-tools/idea/lucene/suggest/suggest.iml dev-tools/idea/lucene/suggest/suggest.iml
index ef2b8ed..0f2ffae 100644
--- dev-tools/idea/lucene/suggest/suggest.iml
+++ dev-tools/idea/lucene/suggest/suggest.iml
@@ -7,7 +7,6 @@
     <content url="file://$MODULE_DIR$">
       <sourceFolder url="file://$MODULE_DIR$/src/java" isTestSource="false" />
       <sourceFolder url="file://$MODULE_DIR$/src/test" isTestSource="true" />
-      <sourceFolder url="file://$MODULE_DIR$/src/resources" isTestSource="false" />
     </content>
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
diff --git dev-tools/idea/solr/contrib/analytics/analytics.iml dev-tools/idea/solr/contrib/analytics/analytics.iml
deleted file mode 100644
index b325d69..0000000
--- dev-tools/idea/solr/contrib/analytics/analytics.iml
+++ /dev/null
@@ -1,36 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<module type="JAVA_MODULE" version="4">
-  <component name="NewModuleRootManager" inherit-compiler-output="false">
-    <output url="file://$MODULE_DIR$/../../../idea-build/solr/contrib/solr-analytics/classes/java" />
-    <output-test url="file://$MODULE_DIR$/../../../idea-build/solr/contrib/solr-analytics/classes/test" />
-    <exclude-output />
-    <content url="file://$MODULE_DIR$">
-      <sourceFolder url="file://$MODULE_DIR$/src/test" isTestSource="true" />
-      <sourceFolder url="file://$MODULE_DIR$/src/test-files" type="java-test-resource" />
-      <sourceFolder url="file://$MODULE_DIR$/src/java" isTestSource="false" />
-    </content>
-    <orderEntry type="inheritedJdk" />
-    <orderEntry type="sourceFolder" forTests="false" />
-    <orderEntry type="library" scope="TEST" name="JUnit" level="project" />
-    <orderEntry type="library" name="Solr core library" level="project" />
-    <orderEntry type="library" name="Solrj library" level="project" />
-    <orderEntry type="library" name="Solr analytics library" level="project" />
-    <orderEntry type="module" scope="TEST" module-name="lucene-test-framework" />
-    <orderEntry type="module" scope="TEST" module-name="solr-test-framework" />
-    <orderEntry type="module-library" scope="TEST">
-      <library>
-        <CLASSES>
-          <root url="file://$MODULE_DIR$/test-lib" />
-        </CLASSES>
-        <JAVADOC />
-        <SOURCES />
-        <jarDirectory url="file://$MODULE_DIR$/test-lib" recursive="false" />
-      </library>
-    </orderEntry>
-    <orderEntry type="module" module-name="lucene-core" />
-    <orderEntry type="module" module-name="queries" />
-    <orderEntry type="module" module-name="solr-core" />
-    <orderEntry type="module" module-name="solrj" />
-  </component>
-</module>
-
diff --git dev-tools/maven/README.maven dev-tools/maven/README.maven
index 8bd031c..a942ec9 100644
--- dev-tools/maven/README.maven
+++ dev-tools/maven/README.maven
@@ -36,7 +36,7 @@ A. How to use nightly Jenkins-built Lucene/Solr Maven artifacts
 
 B. How to generate Lucene/Solr Maven artifacts
 
-   Prerequisites: JDK 1.7+ and Ant 1.8.2+
+   Prerequisites: JDK 1.8+ and Ant 1.8.2+
 
    Run 'ant generate-maven-artifacts' to create an internal Maven
    repository, including POMs, binary .jars, source .jars, and javadoc
@@ -50,7 +50,7 @@ B. How to generate Lucene/Solr Maven artifacts
 
 C. How to deploy Maven artifacts to a repository
 
-   Prerequisites: JDK 1.7+ and Ant 1.8.2+
+   Prerequisites: JDK 1.8+ and Ant 1.8.2+
 
    You can deploy targets for all of Lucene/Solr, only Lucene, or only Solr,
    as in B. above.  To deploy to a Maven repository, the command is the same
@@ -77,7 +77,7 @@ D. How to use Maven to build Lucene/Solr
 
    The details, followed by some example Maven commands:
 
-   1. Prerequisites: JDK 1.7+ and Maven 2.2.1 or 3.X
+   1. Prerequisites: JDK 1.8+ and Maven 2.2.1 or 3.X
 
    2. Make sure your sources are up to date.  If you checked your sources out
       from the Apache Subversion repository, run "svn update" from the top
diff --git dev-tools/maven/pom.xml.template dev-tools/maven/pom.xml.template
index 7bc8042..f5dd902 100644
--- dev-tools/maven/pom.xml.template
+++ dev-tools/maven/pom.xml.template
@@ -43,7 +43,7 @@
     <vc-browse-base-url>http://svn.apache.org/viewvc/lucene/dev/trunk</vc-browse-base-url>
     <specification.version>@spec.version@</specification.version>
     <maven.build.timestamp.format>yyyy-MM-dd HH:mm:ss</maven.build.timestamp.format>
-    <java.compat.version>1.7</java.compat.version>
+    <java.compat.version>1.8</java.compat.version>
     <jetty.version>8.1.10.v20130312</jetty.version>
 
     <!-- RandomizedTesting library system properties -->
diff --git dev-tools/scripts/smokeTestRelease.py dev-tools/scripts/smokeTestRelease.py
index 4593848..d8b7a55 100644
--- dev-tools/scripts/smokeTestRelease.py
+++ dev-tools/scripts/smokeTestRelease.py
@@ -171,15 +171,15 @@ def checkJARMetaData(desc, jarFile, svnRevision, version):
     for verify in (
       'Specification-Vendor: The Apache Software Foundation',
       'Implementation-Vendor: The Apache Software Foundation',
-      # Make sure 1.7 compiler was used to build release bits:
-      'X-Compile-Source-JDK: 1.7',
+      # Make sure 1.8 compiler was used to build release bits:
+      'X-Compile-Source-JDK: 1.8',
       # Make sure 1.8 ant was used to build release bits: (this will match 1.8+)
       'Ant-Version: Apache Ant 1.8',
-      # Make sure .class files are 1.7 format:
-      'X-Compile-Target-JDK: 1.7',
+      # Make sure .class files are 1.8 format:
+      'X-Compile-Target-JDK: 1.8',
       'Specification-Version: %s' % version,
-      # Make sure the release was compiled with 1.7:
-      'Created-By: 1.7'):
+      # Make sure the release was compiled with 1.8:
+      'Created-By: 1.8'):
       if s.find(verify) == -1:
         raise RuntimeError('%s is missing "%s" inside its META-INF/MANIFEST.MF' % \
                            (desc, verify))
@@ -705,54 +705,32 @@ def verifyUnpacked(java, project, artifact, unpackPath, svnRevision, version, te
       raise RuntimeError('source release has WARs...')
 
     print('    run "ant validate"')
-    java.run_java7('ant validate', '%s/validate.log' % unpackPath)
+    java.run_java8('ant validate', '%s/validate.log' % unpackPath)
 
     if project == 'lucene':
-      print("    run tests w/ Java 7 and testArgs='%s'..." % testArgs)
-      java.run_java7('ant clean test %s' % testArgs, '%s/test.log' % unpackPath)
-      java.run_java7('ant jar', '%s/compile.log' % unpackPath)
-      testDemo(java.run_java7, isSrc, version, '1.7')
+      print("    run tests w/ Java 8 and testArgs='%s'..." % testArgs)
+      java.run_java8('ant clean test %s' % testArgs, '%s/test.log' % unpackPath)
+      java.run_java8('ant jar', '%s/compile.log' % unpackPath)
+      testDemo(java.run_java8, isSrc, version, '1.8')
 
-      print('    generate javadocs w/ Java 7...')
-      java.run_java7('ant javadocs', '%s/javadocs.log' % unpackPath)
+      print('    generate javadocs w/ Java 8...')
+      java.run_java8('ant javadocs', '%s/javadocs.log' % unpackPath)
       checkJavadocpathFull('%s/build/docs' % unpackPath)
 
-      if java.run_java8:
-        print("    run tests w/ Java 8 and testArgs='%s'..." % testArgs)
-        java.run_java8('ant clean test %s' % testArgs, '%s/test.log' % unpackPath)
-        java.run_java8('ant jar', '%s/compile.log' % unpackPath)
-        testDemo(java.run_java8, isSrc, version, '1.8')
-
-        print('    generate javadocs w/ Java 8...')
-        java.run_java8('ant javadocs', '%s/javadocs.log' % unpackPath)
-        checkJavadocpathFull('%s/build/docs' % unpackPath)
-
     else:
       os.chdir('solr')
 
-      print("    run tests w/ Java 7 and testArgs='%s'..." % testArgs)
-      java.run_java7('ant clean test -Dtests.slow=false %s' % testArgs, '%s/test.log' % unpackPath)
+      print("    run tests w/ Java 8 and testArgs='%s'..." % testArgs)
+      java.run_java8('ant clean test -Dtests.slow=false %s' % testArgs, '%s/test.log' % unpackPath)
 
       # test javadocs
-      print('    generate javadocs w/ Java 7...')
-      java.run_java7('ant clean javadocs', '%s/javadocs.log' % unpackPath)
+      print('    generate javadocs w/ Java 8...')
+      java.run_java8('ant clean javadocs', '%s/javadocs.log' % unpackPath)
       checkJavadocpathFull('%s/solr/build/docs' % unpackPath, False)
 
-      print('    test solr example w/ Java 7...')
-      java.run_java7('ant clean example', '%s/antexample.log' % unpackPath)
-      testSolrExample(unpackPath, java.java7_home, True)
-
-      if java.run_java8:
-        print("    run tests w/ Java 8 and testArgs='%s'..." % testArgs)
-        java.run_java8('ant clean test -Dtests.slow=false %s' % testArgs, '%s/test.log' % unpackPath)
-
-        print('    generate javadocs w/ Java 8...')
-        java.run_java8('ant clean javadocs', '%s/javadocs.log' % unpackPath)
-        checkJavadocpathFull('%s/solr/build/docs' % unpackPath, False)
-
-        print('    test solr example w/ Java 8...')
-        java.run_java8('ant clean example', '%s/antexample.log' % unpackPath)
-        testSolrExample(unpackPath, java.java8_home, True)
+      print('    test solr example w/ Java 8...')
+      java.run_java8('ant clean example', '%s/antexample.log' % unpackPath)
+      testSolrExample(unpackPath, java.java8_home, True)
 
       os.chdir('..')
       print('    check NOTICE')
@@ -763,9 +741,7 @@ def verifyUnpacked(java, project, artifact, unpackPath, svnRevision, version, te
     checkAllJARs(os.getcwd(), project, svnRevision, version, tmpDir, baseURL)
 
     if project == 'lucene':
-      testDemo(java.run_java7, isSrc, version, '1.7')
-      if java.run_java8:
-        testDemo(java.run_java8, isSrc, version, '1.8')
+      testDemo(java.run_java8, isSrc, version, '1.8')
 
       print('    check Lucene\'s javadoc JAR')
       checkJavadocpath('%s/docs' % unpackPath)
@@ -773,24 +749,14 @@ def verifyUnpacked(java, project, artifact, unpackPath, svnRevision, version, te
     else:
       checkSolrWAR('%s/example/webapps/solr.war' % unpackPath, svnRevision, version, tmpDir, baseURL)
 
-      print('    copying unpacked distribution for Java 7 ...')
-      java7UnpackPath = '%s-java7' % unpackPath
-      if os.path.exists(java7UnpackPath):
-        shutil.rmtree(java7UnpackPath)
-      shutil.copytree(unpackPath, java7UnpackPath)
-      os.chdir(java7UnpackPath)
-      print('    test solr example w/ Java 7...')
-      testSolrExample(java7UnpackPath, java.java7_home, False)
-
-      if java.run_java8:
-        print('    copying unpacked distribution for Java 8 ...')
-        java8UnpackPath = '%s-java8' % unpackPath
-        if os.path.exists(java8UnpackPath):
-          shutil.rmtree(java8UnpackPath)
-        shutil.copytree(unpackPath, java8UnpackPath)
-        os.chdir(java8UnpackPath)
-        print('    test solr example w/ Java 8...')
-        testSolrExample(java8UnpackPath, java.java8_home, False)
+      print('    copying unpacked distribution for Java 8 ...')
+      java8UnpackPath = '%s-java8' % unpackPath
+      if os.path.exists(java8UnpackPath):
+        shutil.rmtree(java8UnpackPath)
+      shutil.copytree(unpackPath, java8UnpackPath)
+      os.chdir(java8UnpackPath)
+      print('    test solr example w/ Java 8...')
+      testSolrExample(java8UnpackPath, java.java8_home, False)
 
       os.chdir(unpackPath)
 
@@ -1280,16 +1246,13 @@ def make_java_config(parser, java8_home):
     def run_java(cmd, logfile):
       run('%s; %s' % (cmd_prefix, cmd), logfile)
     return run_java
-  java7_home =  os.environ.get('JAVA_HOME')
-  if java7_home is None:
+  java8_home =  os.environ.get('JAVA_HOME')
+  if java8_home is None:
     parser.error('JAVA_HOME must be set')
-  run_java7 = _make_runner(java7_home, '1.7')
-  run_java8 = None
-  if java8_home is not None:
-    run_java8 = _make_runner(java8_home, '1.8')
+  run_java8 = _make_runner(java8_home, '1.8')
 
-  jc = namedtuple('JavaConfig', 'run_java7 java7_home run_java8 java8_home')
-  return jc(run_java7, java7_home, run_java8, java8_home)
+  jc = namedtuple('JavaConfig', 'run_java8 java8_home')
+  return jc(run_java8, java8_home)
 
 version_re = re.compile(r'(\d+\.\d+\.\d+(-ALPHA|-BETA)?)')
 revision_re = re.compile(r'rev(\d+)')
diff --git lucene/BUILD.txt lucene/BUILD.txt
index 5658305..9c66e81 100644
--- lucene/BUILD.txt
+++ lucene/BUILD.txt
@@ -1,19 +1,19 @@
 Lucene Build Instructions
 
 Basic steps:
-  0) Install JDK 1.7 (or greater), Ant 1.8.2+, Ivy 2.2.0
+  0) Install JDK 1.8 (or greater), Ant 1.8.2+, Ivy 2.2.0
   1) Download Lucene from Apache and unpack it
   2) Connect to the top-level of your Lucene installation
   3) Install JavaCC (optional)
   4) Run ant
 
-Step 0) Set up your development environment (JDK 1.7 or greater,
+Step 0) Set up your development environment (JDK 1.8 or greater,
 Ant 1.8.2+, Ivy 2.2.0)
 
 We'll assume that you know how to get and set up the JDK - if you
-don't, then we suggest starting at http://java.sun.com and learning
+don't, then we suggest starting at http://www.oracle.com/java/ and learning
 more about Java, before returning to this README. Lucene runs with
-JDK 1.7 and later.
+JDK 1.8 and later.
 
 Like many Open Source java projects, Lucene uses Apache Ant for build
 control.  Specifically, you MUST use Ant version 1.8.2+.
diff --git lucene/CHANGES.txt lucene/CHANGES.txt
index 0a2f1f7..29fa84e 100644
--- lucene/CHANGES.txt
+++ lucene/CHANGES.txt
@@ -5,6 +5,11 @@ http://s.apache.org/luceneversions
 
 ======================= Lucene 5.0.0 =======================
 
+System Requirements
+
+* LUCENE-5950: Move to Java 8 as minimum Java version.
+  (Ryan Ernst)
+
 New Features
 
 * LUCENE-5945: All file handling converted to NIO.2 apis. (Robert Muir)
@@ -127,11 +132,6 @@ New Features
   Directory.renameFile so that in-progress commits are never visible. 
   (Robert Muir)
 
-* LUCENE-5820: SuggestStopFilter should have a factory. 
-  (Varun Thacker via Steve Rowe)
-
-* LUCENE-5949: Add Accountable.getChildResources(). (Robert Muir)
-
 API Changes:
 
 * LUCENE-5900: Deprecated more constructors taking Version in *InfixSuggester and
diff --git lucene/SYSTEM_REQUIREMENTS.txt lucene/SYSTEM_REQUIREMENTS.txt
index 623120d..a888719 100644
--- lucene/SYSTEM_REQUIREMENTS.txt
+++ lucene/SYSTEM_REQUIREMENTS.txt
@@ -1,9 +1,6 @@
 # System Requirements 
 
-Apache Lucene runs of Java 7 or greater, Java 8 is verified to be
-compatible and may bring some performance improvements. When using
-Oracle Java 7 or OpenJDK 7, be sure to not use the GA build 147 or
-update versions u40, u45 and u51! We recommend using u55 or later.
+Apache Lucene runs on Java 8 or greater.
 
 It is also recommended to always use the latest update version of your
 Java VM, because bugs may affect Lucene. An overview of known JVM bugs
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesReader.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesReader.java
index e83a24e..f70d0fb 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesReader.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesReader.java
@@ -37,8 +37,6 @@ import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.store.CompoundFileDirectory;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -59,11 +57,12 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
   private static final String segmentSuffix = "dv";
 
   // ram instances we have already loaded
-  private final Map<String,NumericDocValues> numericInstances = new HashMap<>();
-  private final Map<String,BinaryDocValues> binaryInstances = new HashMap<>();
-  private final Map<String,SortedDocValues> sortedInstances = new HashMap<>();
-  
-  private final Map<String,Accountable> instanceInfo = new HashMap<>();
+  private final Map<Integer,NumericDocValues> numericInstances =
+      new HashMap<>();
+  private final Map<Integer,BinaryDocValues> binaryInstances =
+      new HashMap<>();
+  private final Map<Integer,SortedDocValues> sortedInstances =
+      new HashMap<>();
 
   private final AtomicLong ramBytesUsed;
 
@@ -76,7 +75,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
 
   @Override
   public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericDocValues instance = numericInstances.get(field.name);
+    NumericDocValues instance = numericInstances.get(field.number);
     if (instance == null) {
       String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "dat");
       IndexInput input = dir.openInput(fileName, state.context);
@@ -116,7 +115,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
           IOUtils.closeWhileHandlingException(input);
         }
       }
-      numericInstances.put(field.name, instance);
+      numericInstances.put(field.number, instance);
     }
     return instance;
   }
@@ -132,9 +131,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       for (int i = 0; i < values.length; i++) {
         values[i] = input.readLong();
       }
-      long bytesUsed = RamUsageEstimator.sizeOf(values);
-      instanceInfo.put(field.name, Accountables.namedAccountable("long array", bytesUsed));
-      ramBytesUsed.addAndGet(bytesUsed);
+      ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
       return new NumericDocValues() {
         @Override
         public long get(int docID) {
@@ -145,7 +142,6 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       final long minValue = input.readLong();
       final long defaultValue = input.readLong();
       final PackedInts.Reader reader = PackedInts.getReader(input);
-      instanceInfo.put(field.name, reader);
       ramBytesUsed.addAndGet(reader.ramBytesUsed());
       return new NumericDocValues() {
         @Override
@@ -174,9 +170,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     int maxDoc = state.segmentInfo.getDocCount();
     final byte values[] = new byte[maxDoc];
     input.readBytes(values, 0, values.length);
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("byte array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -198,9 +192,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     for (int i = 0; i < values.length; i++) {
       values[i] = input.readShort();
     }
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("short array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -222,9 +214,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     for (int i = 0; i < values.length; i++) {
       values[i] = input.readInt();
     }
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("int array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -246,9 +236,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     for (int i = 0; i < values.length; i++) {
       values[i] = input.readLong();
     }
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("long array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -270,9 +258,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     for (int i = 0; i < values.length; i++) {
       values[i] = input.readInt();
     }
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("float array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -294,9 +280,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     for (int i = 0; i < values.length; i++) {
       values[i] = input.readLong();
     }
-    long bytesUsed = RamUsageEstimator.sizeOf(values);
-    instanceInfo.put(field.name, Accountables.namedAccountable("double array", bytesUsed));
-    ramBytesUsed.addAndGet(bytesUsed);
+    ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
     return new NumericDocValues() {
       @Override
       public long get(int docID) {
@@ -307,7 +291,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
 
   @Override
   public synchronized BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryDocValues instance = binaryInstances.get(field.name);
+    BinaryDocValues instance = binaryInstances.get(field.number);
     if (instance == null) {
       switch(LegacyDocValuesType.valueOf(field.getAttribute(legacyKey))) {
         case BYTES_FIXED_STRAIGHT:
@@ -325,7 +309,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
         default:
           throw new AssertionError();
       }
-      binaryInstances.put(field.name, instance);
+      binaryInstances.put(field.number, instance);
     }
     return instance;
   }
@@ -345,7 +329,6 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       CodecUtil.checkEOF(input);
       success = true;
       ramBytesUsed.addAndGet(bytesReader.ramBytesUsed());
-      instanceInfo.put(field.name, bytesReader);
       return new BinaryDocValues() {
 
         @Override
@@ -387,9 +370,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       CodecUtil.checkEOF(data);
       CodecUtil.checkEOF(index);
       success = true;
-      long bytesUsed = bytesReader.ramBytesUsed() + reader.ramBytesUsed();
-      ramBytesUsed.addAndGet(bytesUsed);
-      instanceInfo.put(field.name, Accountables.namedAccountable("variable straight", bytesUsed));
+      ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + reader.ramBytesUsed());
       return new BinaryDocValues() {
         @Override
         public BytesRef get(int docID) {
@@ -433,9 +414,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       final PackedInts.Reader reader = PackedInts.getReader(index);
       CodecUtil.checkEOF(data);
       CodecUtil.checkEOF(index);
-      long bytesUsed = bytesReader.ramBytesUsed() + reader.ramBytesUsed();
-      ramBytesUsed.addAndGet(bytesUsed);
-      instanceInfo.put(field.name, Accountables.namedAccountable("fixed deref", bytesUsed));
+      ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + reader.ramBytesUsed());
       success = true;
       return new BinaryDocValues() {
         @Override
@@ -478,9 +457,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
       final PackedInts.Reader reader = PackedInts.getReader(index);
       CodecUtil.checkEOF(data);
       CodecUtil.checkEOF(index);
-      long bytesUsed = bytesReader.ramBytesUsed() + reader.ramBytesUsed();
-      ramBytesUsed.addAndGet(bytesUsed);
-      instanceInfo.put(field.name, Accountables.namedAccountable("variable deref", bytesUsed));
+      ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + reader.ramBytesUsed());
       success = true;
       return new BinaryDocValues() {
         
@@ -513,7 +490,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
 
   @Override
   public synchronized SortedDocValues getSorted(FieldInfo field) throws IOException {
-    SortedDocValues instance = sortedInstances.get(field.name);
+    SortedDocValues instance = sortedInstances.get(field.number);
     if (instance == null) {
       String dataName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "dat");
       String indexName = IndexFileNames.segmentFileName(state.segmentInfo.name + "_" + Integer.toString(field.number), segmentSuffix, "idx");
@@ -543,7 +520,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
           IOUtils.closeWhileHandlingException(data, index);
         }
       }
-      sortedInstances.put(field.name, instance);
+      sortedInstances.put(field.number, instance);
     }
     return instance;
   }
@@ -563,9 +540,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     bytes.copy(data, fixedLength * (long) valueCount);
     final PagedBytes.Reader bytesReader = bytes.freeze(true);
     final PackedInts.Reader reader = PackedInts.getReader(index);
-    long bytesUsed = bytesReader.ramBytesUsed() + reader.ramBytesUsed();
-    ramBytesUsed.addAndGet(bytesUsed);
-    instanceInfo.put(field.name, Accountables.namedAccountable("fixed sorted", bytesUsed));
+    ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + reader.ramBytesUsed());
 
     return correctBuggyOrds(new SortedDocValues() {
       @Override
@@ -603,9 +578,7 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
     final PackedInts.Reader ordsReader = PackedInts.getReader(index);
 
     final int valueCount = addressReader.size() - 1;
-    long bytesUsed = bytesReader.ramBytesUsed() + addressReader.ramBytesUsed() + ordsReader.ramBytesUsed();
-    ramBytesUsed.addAndGet(bytesUsed);
-    instanceInfo.put(field.name, Accountables.namedAccountable("var sorted", bytesUsed));
+    ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + addressReader.ramBytesUsed() + ordsReader.ramBytesUsed());
 
     return correctBuggyOrds(new SortedDocValues() {
       @Override
@@ -681,18 +654,8 @@ final class Lucene40DocValuesReader extends DocValuesProducer {
   public long ramBytesUsed() {
     return ramBytesUsed.get();
   }
-  
-  @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", instanceInfo);
-  }
 
   @Override
   public void checkIntegrity() throws IOException {
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
 }
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader.java
index a359938..6ca7bc7 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader.java
@@ -23,7 +23,6 @@ import org.apache.lucene.codecs.NormsProducer;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SegmentReadState;
-import org.apache.lucene.util.Accountable;
 
 /**
  * Reads 4.0/4.1 norms.
@@ -52,19 +51,9 @@ class Lucene40NormsReader extends NormsProducer {
   public long ramBytesUsed() {
     return impl.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return impl.getChildResources();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {
     impl.checkIntegrity();
   }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(" + impl + ")";
-  }
 }
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
index d8c5a31..0730d7b 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.lucene40;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.BlockTermState;
 import org.apache.lucene.codecs.CodecUtil;
@@ -36,7 +35,6 @@ import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -1165,17 +1163,8 @@ public class Lucene40PostingsReader extends PostingsReaderBase {
   public long ramBytesUsed() {
     return 0;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {}
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(positions=" + (proxIn != null) + ")";
-  }
 }
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader.java
index 82c71f2..a2848dc 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader.java
@@ -31,13 +31,11 @@ import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 
 import java.io.Closeable;
 import java.nio.charset.StandardCharsets;
-import java.util.Collections;
 
 /**
  * Class responsible for access to stored document fields.
@@ -260,17 +258,7 @@ public final class Lucene40StoredFieldsReader extends StoredFieldsReader impleme
   public long ramBytesUsed() {
     return RAM_BYTES_USED;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {}
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
 }
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java
index ec24b38..857d653 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.lucene40;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
@@ -27,7 +26,6 @@ import java.util.NoSuchElementException;
 
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.codecs.TermVectorsReader;
-import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.FieldInfo;
@@ -40,7 +38,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -124,12 +121,8 @@ public class Lucene40TermVectorsReader extends TermVectorsReader implements Clos
       assert HEADER_LENGTH_INDEX == tvx.getFilePointer();
       assert HEADER_LENGTH_DOCS == tvd.getFilePointer();
       assert HEADER_LENGTH_FIELDS == tvf.getFilePointer();
-      if (tvxVersion != tvdVersion) {
-        throw new CorruptIndexException("version mismatch: tvx=" + tvxVersion + " != tvd=" + tvdVersion + " (resource=" + tvd + ")");
-      }
-      if (tvxVersion != tvfVersion) {
-        throw new CorruptIndexException("version mismatch: tvx=" + tvxVersion + " != tvf=" + tvfVersion + " (resource=" + tvf + ")");
-      }
+      assert tvxVersion == tvdVersion;
+      assert tvxVersion == tvfVersion;
 
       numTotalDocs = (int) (tvx.length()-HEADER_LENGTH_INDEX >> 4);
 
@@ -712,18 +705,8 @@ public class Lucene40TermVectorsReader extends TermVectorsReader implements Clos
   public long ramBytesUsed() {
     return 0;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {}
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
 }
 
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesProducer.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesProducer.java
index 788ab22..ef7ed68 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesProducer.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesProducer.java
@@ -18,10 +18,7 @@ package org.apache.lucene.codecs.lucene42;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -44,8 +41,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -70,21 +65,19 @@ import org.apache.lucene.util.packed.PackedInts;
  */
 class Lucene42DocValuesProducer extends DocValuesProducer {
   // metadata maps (just file pointers and minimal stuff)
-  private final Map<String,NumericEntry> numerics;
-  private final Map<String,BinaryEntry> binaries;
-  private final Map<String,FSTEntry> fsts;
+  private final Map<Integer,NumericEntry> numerics;
+  private final Map<Integer,BinaryEntry> binaries;
+  private final Map<Integer,FSTEntry> fsts;
   private final IndexInput data;
   private final int version;
-  private final int numEntries;
   
   // ram instances we have already loaded
-  private final Map<String,NumericDocValues> numericInstances = new HashMap<>();
-  private final Map<String,BinaryDocValues> binaryInstances = new HashMap<>();
-  private final Map<String,FST<Long>> fstInstances = new HashMap<>();
-  
-  private final Map<String,Accountable> numericInfo = new HashMap<>();
-  private final Map<String,Accountable> binaryInfo = new HashMap<>();
-  private final Map<String,Accountable> addressInfo = new HashMap<>();
+  private final Map<Integer,NumericDocValues> numericInstances = 
+      new HashMap<>();
+  private final Map<Integer,BinaryDocValues> binaryInstances =
+      new HashMap<>();
+  private final Map<Integer,FST<Long>> fstInstances =
+      new HashMap<>();
   
   private final int maxDoc;
   private final AtomicLong ramBytesUsed;
@@ -119,7 +112,7 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
       numerics = new HashMap<>();
       binaries = new HashMap<>();
       fsts = new HashMap<>();
-      numEntries = readFields(in, state.fieldInfos);
+      readFields(in, state.fieldInfos);
 
       if (version >= VERSION_CHECKSUM) {
         CodecUtil.checkFooter(in);
@@ -163,13 +156,10 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
     }
   }
   
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numEntries = 0;
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numEntries++;
-      FieldInfo info = infos.fieldInfo(fieldNumber);
-      if (info == null) {
+      if (infos.fieldInfo(fieldNumber) == null) {
         // trickier to validate more: because we re-use for norms, because we use multiple entries
         // for "composite" types like sortedset, etc.
         throw new CorruptIndexException("Invalid field number: " + fieldNumber + " (resource=" + meta + ")");
@@ -191,7 +181,7 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
         if (entry.format != UNCOMPRESSED) {
           entry.packedIntsVersion = meta.readVInt();
         }
-        numerics.put(info.name, entry);
+        numerics.put(fieldNumber, entry);
       } else if (fieldType == BYTES) {
         BinaryEntry entry = new BinaryEntry();
         entry.offset = meta.readLong();
@@ -202,26 +192,25 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
           entry.packedIntsVersion = meta.readVInt();
           entry.blockSize = meta.readVInt();
         }
-        binaries.put(info.name, entry);
+        binaries.put(fieldNumber, entry);
       } else if (fieldType == FST) {
         FSTEntry entry = new FSTEntry();
         entry.offset = meta.readLong();
         entry.numOrds = meta.readVLong();
-        fsts.put(info.name, entry);
+        fsts.put(fieldNumber, entry);
       } else {
         throw new CorruptIndexException("invalid entry type: " + fieldType + ", input=" + meta);
       }
       fieldNumber = meta.readVInt();
     }
-    return numEntries;
   }
 
   @Override
   public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericDocValues instance = numericInstances.get(field.name);
+    NumericDocValues instance = numericInstances.get(field.number);
     if (instance == null) {
       instance = loadNumeric(field);
-      numericInstances.put(field.name, instance);
+      numericInstances.put(field.number, instance);
     }
     return instance;
   }
@@ -232,29 +221,14 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("numeric field", numericInfo));
-    resources.addAll(Accountables.namedAccountables("binary field", binaryInfo));
-    resources.addAll(Accountables.namedAccountables("addresses field", addressInfo));
-    resources.addAll(Accountables.namedAccountables("terms dict field", fstInstances));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     if (version >= VERSION_CHECKSUM) {
       CodecUtil.checksumEntireFile(data);
     }
   }
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(entries=" + numEntries + ")";
-  }
-
   private NumericDocValues loadNumeric(FieldInfo field) throws IOException {
-    NumericEntry entry = numerics.get(field.name);
+    NumericEntry entry = numerics.get(field.number);
     data.seek(entry.offset);
     switch (entry.format) {
       case TABLE_COMPRESSED:
@@ -270,7 +244,6 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
         final int bitsPerValue = data.readVInt();
         final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), entry.packedIntsVersion, maxDoc, bitsPerValue);
         ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed());
-        numericInfo.put(field.name, ordsReader);
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -281,13 +254,11 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
         final int blockSize = data.readVInt();
         final BlockPackedReader reader = new BlockPackedReader(data, entry.packedIntsVersion, blockSize, maxDoc, false);
         ramBytesUsed.addAndGet(reader.ramBytesUsed());
-        numericInfo.put(field.name, reader);
         return reader;
       case UNCOMPRESSED:
         final byte bytes[] = new byte[maxDoc];
         data.readBytes(bytes, 0, bytes.length);
         ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(bytes));
-        numericInfo.put(field.name, Accountables.namedAccountable("byte array", maxDoc));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -300,7 +271,6 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
         final int quotientBlockSize = data.readVInt();
         final BlockPackedReader quotientReader = new BlockPackedReader(data, entry.packedIntsVersion, quotientBlockSize, maxDoc, false);
         ramBytesUsed.addAndGet(quotientReader.ramBytesUsed());
-        numericInfo.put(field.name, quotientReader);
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -314,21 +284,20 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
 
   @Override
   public synchronized BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryDocValues instance = binaryInstances.get(field.name);
+    BinaryDocValues instance = binaryInstances.get(field.number);
     if (instance == null) {
       instance = loadBinary(field);
-      binaryInstances.put(field.name, instance);
+      binaryInstances.put(field.number, instance);
     }
     return instance;
   }
   
   private BinaryDocValues loadBinary(FieldInfo field) throws IOException {
-    BinaryEntry entry = binaries.get(field.name);
+    BinaryEntry entry = binaries.get(field.number);
     data.seek(entry.offset);
     PagedBytes bytes = new PagedBytes(16);
     bytes.copy(data, entry.numBytes);
     final PagedBytes.Reader bytesReader = bytes.freeze(true);
-    binaryInfo.put(field.name, bytesReader);
     if (entry.minLength == entry.maxLength) {
       final int fixedLength = entry.minLength;
       ramBytesUsed.addAndGet(bytesReader.ramBytesUsed());
@@ -342,7 +311,6 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
       };
     } else {
       final MonotonicBlockPackedReader addresses = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, maxDoc, false);
-      addressInfo.put(field.name, addresses);
       ramBytesUsed.addAndGet(bytesReader.ramBytesUsed() + addresses.ramBytesUsed());
       return new BinaryDocValues() {
 
@@ -360,15 +328,15 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    final FSTEntry entry = fsts.get(field.name);
+    final FSTEntry entry = fsts.get(field.number);
     FST<Long> instance;
     synchronized(this) {
-      instance = fstInstances.get(field.name);
+      instance = fstInstances.get(field.number);
       if (instance == null) {
         data.seek(entry.offset);
         instance = new FST<>(data, PositiveIntOutputs.getSingleton());
         ramBytesUsed.addAndGet(instance.ramBytesUsed());
-        fstInstances.put(field.name, instance);
+        fstInstances.put(field.number, instance);
       }
     }
     final NumericDocValues docToOrd = getNumeric(field);
@@ -434,18 +402,18 @@ class Lucene42DocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
-    final FSTEntry entry = fsts.get(field.name);
+    final FSTEntry entry = fsts.get(field.number);
     if (entry.numOrds == 0) {
       return DocValues.emptySortedSet(); // empty FST!
     }
     FST<Long> instance;
     synchronized(this) {
-      instance = fstInstances.get(field.name);
+      instance = fstInstances.get(field.number);
       if (instance == null) {
         data.seek(entry.offset);
         instance = new FST<>(data, PositiveIntOutputs.getSingleton());
         ramBytesUsed.addAndGet(instance.ramBytesUsed());
-        fstInstances.put(field.name, instance);
+        fstInstances.put(field.number, instance);
       }
     }
     final BinaryDocValues docToOrds = getBinary(field);
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42NormsProducer.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42NormsProducer.java
index c550fb4..a8b2073 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42NormsProducer.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene42/Lucene42NormsProducer.java
@@ -18,13 +18,11 @@ package org.apache.lucene.codecs.lucene42;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.NormsProducer;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SegmentReadState;
-import org.apache.lucene.util.Accountable;
 
 /**
  * Reads 4.2-4.8 norms.
@@ -53,19 +51,9 @@ class Lucene42NormsProducer extends NormsProducer {
   public long ramBytesUsed() {
     return impl.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return impl.getChildResources();
-  }
 
   @Override
   public void close() throws IOException {
     impl.close();
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(" + impl + ")";
-  }
 }
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer.java
index 574f208..7dedb33 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer.java
@@ -29,10 +29,7 @@ import static org.apache.lucene.codecs.lucene45.Lucene45DocValuesFormat.VERSION_
 
 import java.io.Closeable; // javadocs
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -56,8 +53,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -80,7 +75,6 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
   private final IndexInput data;
   private final int maxDoc;
   private final int version;
-  private final int numFields;
   
   // We need this for pre-4.9 indexes which recorded multiple fields' DocValues
   // updates under the same generation, and therefore the passed FieldInfos may
@@ -113,7 +107,7 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
       ordIndexes = new HashMap<>();
       binaries = new HashMap<>();
       sortedSets = new HashMap<>();
-      numFields = readFields(in, state.fieldInfos);
+      readFields(in, state.fieldInfos);
 
       if (version >= Lucene45DocValuesFormat.VERSION_CHECKSUM) {
         CodecUtil.checkFooter(in);
@@ -210,11 +204,9 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
     ordIndexes.put(fieldNumber, n2);
   }
 
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numFields = 0;
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numFields++;
       if ((lenientFieldInfoCheck && fieldNumber < 0) || (!lenientFieldInfoCheck && infos.fieldInfo(fieldNumber) == null)) {
         // trickier to validate more: because we re-use for norms, because we use multiple entries
         // for "composite" types like sortedset, etc.
@@ -249,7 +241,6 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
       }
       fieldNumber = meta.readVInt();
     }
-    return numFields;
   }
   
   static NumericEntry readNumericEntry(IndexInput meta) throws IOException {
@@ -339,24 +330,11 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("addresses field number", addressInstances));
-    resources.addAll(Accountables.namedAccountables("ord index field number", ordIndexInstances));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     if (version >= Lucene45DocValuesFormat.VERSION_CHECKSUM) {
       CodecUtil.checksumEntireFile(data);
     }
   }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + numFields + ")";
-  }
 
   LongValues getNumeric(NumericEntry entry) throws IOException {
     final IndexInput data = this.data.clone();
@@ -433,16 +411,18 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
   
   /** returns an address instance for variable-length binary values.
    *  @lucene.internal */
-  protected synchronized MonotonicBlockPackedReader getAddressInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
+  protected MonotonicBlockPackedReader getAddressInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
     final MonotonicBlockPackedReader addresses;
-    MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
-    if (addrInstance == null) {
-      data.seek(bytes.addressesOffset);
-      addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, bytes.count, false);
-      addressInstances.put(field.number, addrInstance);
-      ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
-    }
-    addresses = addrInstance;
+    synchronized (addressInstances) {
+      MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
+      if (addrInstance == null) {
+        data.seek(bytes.addressesOffset);
+        addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, bytes.count, false);
+        addressInstances.put(field.number, addrInstance);
+        ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      }
+      addresses = addrInstance;
+    }
     return addresses;
   }
   
@@ -473,23 +453,25 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
   
   /** returns an address instance for prefix-compressed binary values. 
    * @lucene.internal */
-  protected synchronized MonotonicBlockPackedReader getIntervalInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
+  protected MonotonicBlockPackedReader getIntervalInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
     final MonotonicBlockPackedReader addresses;
     final long interval = bytes.addressInterval;
-    MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
-    if (addrInstance == null) {
-      data.seek(bytes.addressesOffset);
-      final long size;
-      if (bytes.count % interval == 0) {
-        size = bytes.count / interval;
-      } else {
-        size = 1L + bytes.count / interval;
+    synchronized (addressInstances) {
+      MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
+      if (addrInstance == null) {
+        data.seek(bytes.addressesOffset);
+        final long size;
+        if (bytes.count % interval == 0) {
+          size = bytes.count / interval;
+        } else {
+          size = 1L + bytes.count / interval;
+        }
+        addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, size, false);
+        addressInstances.put(field.number, addrInstance);
+        ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
       }
-      addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, size, false);
-      addressInstances.put(field.number, addrInstance);
-      ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      addresses = addrInstance;
     }
-    addresses = addrInstance;
     return addresses;
   }
 
@@ -550,16 +532,18 @@ class Lucene45DocValuesProducer extends DocValuesProducer implements Closeable {
   
   /** returns an address instance for sortedset ordinal lists
    * @lucene.internal */
-  protected synchronized MonotonicBlockPackedReader getOrdIndexInstance(IndexInput data, FieldInfo field, NumericEntry entry) throws IOException {
+  protected MonotonicBlockPackedReader getOrdIndexInstance(IndexInput data, FieldInfo field, NumericEntry entry) throws IOException {
     final MonotonicBlockPackedReader ordIndex;
-    MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);
-    if (ordIndexInstance == null) {
-      data.seek(entry.offset);
-      ordIndexInstance = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);
-      ordIndexInstances.put(field.number, ordIndexInstance);
-      ramBytesUsed.addAndGet(ordIndexInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
-    }
-    ordIndex = ordIndexInstance;
+    synchronized (ordIndexInstances) {
+      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);
+      if (ordIndexInstance == null) {
+        data.seek(entry.offset);
+        ordIndexInstance = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);
+        ordIndexInstances.put(field.number, ordIndexInstance);
+        ramBytesUsed.addAndGet(ordIndexInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      }
+      ordIndex = ordIndexInstance;
+    }
     return ordIndex;
   }
   
diff --git lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
index 86d01b9..70b8dd8 100644
--- lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
+++ lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer.java
@@ -29,10 +29,7 @@ import static org.apache.lucene.codecs.lucene49.Lucene49DocValuesConsumer.TABLE_
 
 import java.io.Closeable; // javadocs
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -57,8 +54,6 @@ import org.apache.lucene.index.TermsEnum.SeekStatus;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.RandomAccessInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -69,21 +64,20 @@ import org.apache.lucene.util.packed.MonotonicBlockPackedReader;
 
 /** reader for {@link Lucene49DocValuesFormat} */
 class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
-  private final Map<String,NumericEntry> numerics;
-  private final Map<String,BinaryEntry> binaries;
-  private final Map<String,SortedSetEntry> sortedSets;
-  private final Map<String,SortedSetEntry> sortedNumerics;
-  private final Map<String,NumericEntry> ords;
-  private final Map<String,NumericEntry> ordIndexes;
+  private final Map<Integer,NumericEntry> numerics;
+  private final Map<Integer,BinaryEntry> binaries;
+  private final Map<Integer,SortedSetEntry> sortedSets;
+  private final Map<Integer,SortedSetEntry> sortedNumerics;
+  private final Map<Integer,NumericEntry> ords;
+  private final Map<Integer,NumericEntry> ordIndexes;
   private final AtomicLong ramBytesUsed;
   private final IndexInput data;
-  private final int numFields;
   private final int maxDoc;
   private final int version;
 
   // memory-resident structures
-  private final Map<String,MonotonicBlockPackedReader> addressInstances = new HashMap<>();
-  private final Map<String,MonotonicBlockPackedReader> ordIndexInstances = new HashMap<>();
+  private final Map<Integer,MonotonicBlockPackedReader> addressInstances = new HashMap<>();
+  private final Map<Integer,MonotonicBlockPackedReader> ordIndexInstances = new HashMap<>();
   
   /** expert: instantiates a new reader */
   Lucene49DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
@@ -102,7 +96,7 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
       binaries = new HashMap<>();
       sortedSets = new HashMap<>();
       sortedNumerics = new HashMap<>();
-      numFields = readFields(in, state.fieldInfos);
+      readFields(in, state.fieldInfos);
 
       CodecUtil.checkFooter(in);
       success = true;
@@ -141,110 +135,108 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
     ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));
   }
 
-  private void readSortedField(FieldInfo info, IndexInput meta) throws IOException {
+  private void readSortedField(int fieldNumber, IndexInput meta, FieldInfos infos) throws IOException {
     // sorted = binary + numeric
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene49DocValuesFormat.BINARY) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     BinaryEntry b = readBinaryEntry(meta);
-    binaries.put(info.name, b);
+    binaries.put(fieldNumber, b);
     
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene49DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n = readNumericEntry(meta);
-    ords.put(info.name, n);
+    ords.put(fieldNumber, n);
   }
 
-  private void readSortedSetFieldWithAddresses(FieldInfo info, IndexInput meta) throws IOException {
+  private void readSortedSetFieldWithAddresses(int fieldNumber, IndexInput meta, FieldInfos infos) throws IOException {
     // sortedset = binary + numeric (addresses) + ordIndex
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene49DocValuesFormat.BINARY) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     BinaryEntry b = readBinaryEntry(meta);
-    binaries.put(info.name, b);
+    binaries.put(fieldNumber, b);
 
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene49DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n1 = readNumericEntry(meta);
-    ords.put(info.name, n1);
+    ords.put(fieldNumber, n1);
 
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene49DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n2 = readNumericEntry(meta);
-    ordIndexes.put(info.name, n2);
+    ordIndexes.put(fieldNumber, n2);
   }
 
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numFields = 0;
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numFields++;
-      FieldInfo info = infos.fieldInfo(fieldNumber);
-      if (info == null) {
-        // trickier to validate more: because we use multiple entries for "composite" types like sortedset, etc.
+      if (infos.fieldInfo(fieldNumber) == null) {
+        // trickier to validate more: because we re-use for norms, because we use multiple entries
+        // for "composite" types like sortedset, etc.
         throw new CorruptIndexException("Invalid field number: " + fieldNumber + " (resource=" + meta + ")");
       }
       byte type = meta.readByte();
       if (type == Lucene49DocValuesFormat.NUMERIC) {
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
       } else if (type == Lucene49DocValuesFormat.BINARY) {
         BinaryEntry b = readBinaryEntry(meta);
-        binaries.put(info.name, b);
+        binaries.put(fieldNumber, b);
       } else if (type == Lucene49DocValuesFormat.SORTED) {
-        readSortedField(info, meta);
+        readSortedField(fieldNumber, meta, infos);
       } else if (type == Lucene49DocValuesFormat.SORTED_SET) {
         SortedSetEntry ss = readSortedSetEntry(meta);
-        sortedSets.put(info.name, ss);
+        sortedSets.put(fieldNumber, ss);
         if (ss.format == SORTED_WITH_ADDRESSES) {
-          readSortedSetFieldWithAddresses(info, meta);
+          readSortedSetFieldWithAddresses(fieldNumber, meta, infos);
         } else if (ss.format == SORTED_SINGLE_VALUED) {
           if (meta.readVInt() != fieldNumber) {
-            throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           if (meta.readByte() != Lucene49DocValuesFormat.SORTED) {
-            throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
-          readSortedField(info, meta);
+          readSortedField(fieldNumber, meta, infos);
         } else {
           throw new AssertionError();
         }
       } else if (type == Lucene49DocValuesFormat.SORTED_NUMERIC) {
         SortedSetEntry ss = readSortedSetEntry(meta);
-        sortedNumerics.put(info.name, ss);
+        sortedNumerics.put(fieldNumber, ss);
         if (meta.readVInt() != fieldNumber) {
-          throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+          throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
         }
         if (meta.readByte() != Lucene49DocValuesFormat.NUMERIC) {
-          throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+          throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
         }
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
         if (ss.format == SORTED_WITH_ADDRESSES) {
           if (meta.readVInt() != fieldNumber) {
-            throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           if (meta.readByte() != Lucene49DocValuesFormat.NUMERIC) {
-            throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           NumericEntry ordIndex = readNumericEntry(meta);
-          ordIndexes.put(info.name, ordIndex);
+          ordIndexes.put(fieldNumber, ordIndex);
         } else if (ss.format != SORTED_SINGLE_VALUED) {
           throw new AssertionError();
         }
@@ -253,7 +245,6 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
       }
       fieldNumber = meta.readVInt();
     }
-    return numFields;
   }
   
   static NumericEntry readNumericEntry(IndexInput meta) throws IOException {
@@ -333,7 +324,7 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
 
   @Override
   public NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericEntry entry = numerics.get(field.name);
+    NumericEntry entry = numerics.get(field.number);
     return getNumeric(entry);
   }
   
@@ -343,22 +334,9 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("addresses field", addressInstances));
-    resources.addAll(Accountables.namedAccountables("ord index field", ordIndexInstances));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     CodecUtil.checksumEntireFile(data);
   }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + numFields + ")";
-  }
 
   LongValues getNumeric(NumericEntry entry) throws IOException {
     RandomAccessInput slice = this.data.randomAccessSlice(entry.offset, entry.endOffset - entry.offset);
@@ -398,7 +376,7 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
 
   @Override
   public BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryEntry bytes = binaries.get(field.name);
+    BinaryEntry bytes = binaries.get(field.number);
     switch(bytes.format) {
       case BINARY_FIXED_UNCOMPRESSED:
         return getFixedBinary(field, bytes);
@@ -437,16 +415,18 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   }
   
   /** returns an address instance for variable-length binary values. */
-  private synchronized MonotonicBlockPackedReader getAddressInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
+  private MonotonicBlockPackedReader getAddressInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
     final MonotonicBlockPackedReader addresses;
-    MonotonicBlockPackedReader addrInstance = addressInstances.get(field.name);
-    if (addrInstance == null) {
-      data.seek(bytes.addressesOffset);
-      addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, bytes.count+1, false);
-      addressInstances.put(field.name, addrInstance);
-      ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+    synchronized (addressInstances) {
+      MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
+      if (addrInstance == null) {
+        data.seek(bytes.addressesOffset);
+        addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, bytes.count+1, false);
+        addressInstances.put(field.number, addrInstance);
+        ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      }
+      addresses = addrInstance;
     }
-    addresses = addrInstance;
     return addresses;
   }
   
@@ -476,23 +456,25 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   }
   
   /** returns an address instance for prefix-compressed binary values. */
-  private synchronized MonotonicBlockPackedReader getIntervalInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
+  private MonotonicBlockPackedReader getIntervalInstance(IndexInput data, FieldInfo field, BinaryEntry bytes) throws IOException {
     final MonotonicBlockPackedReader addresses;
     final long interval = bytes.addressInterval;
-    MonotonicBlockPackedReader addrInstance = addressInstances.get(field.name);
-    if (addrInstance == null) {
-      data.seek(bytes.addressesOffset);
-      final long size;
-      if (bytes.count % interval == 0) {
-        size = bytes.count / interval;
-      } else {
-        size = 1L + bytes.count / interval;
+    synchronized (addressInstances) {
+      MonotonicBlockPackedReader addrInstance = addressInstances.get(field.number);
+      if (addrInstance == null) {
+        data.seek(bytes.addressesOffset);
+        final long size;
+        if (bytes.count % interval == 0) {
+          size = bytes.count / interval;
+        } else {
+          size = 1L + bytes.count / interval;
+        }
+        addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, size, false);
+        addressInstances.put(field.number, addrInstance);
+        ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
       }
-      addrInstance = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, size, false);
-      addressInstances.put(field.name, addrInstance);
-      ramBytesUsed.addAndGet(addrInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      addresses = addrInstance;
     }
-    addresses = addrInstance;
     return addresses;
   }
 
@@ -507,9 +489,9 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
 
   @Override
   public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    final int valueCount = (int) binaries.get(field.name).count;
+    final int valueCount = (int) binaries.get(field.number).count;
     final BinaryDocValues binary = getBinary(field);
-    NumericEntry entry = ords.get(field.name);
+    NumericEntry entry = ords.get(field.number);
     final LongValues ordinals = getNumeric(entry);
     
     return new SortedDocValues() {
@@ -550,30 +532,32 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
   }
   
   /** returns an address instance for sortedset ordinal lists */
-  private synchronized MonotonicBlockPackedReader getOrdIndexInstance(IndexInput data, FieldInfo field, NumericEntry entry) throws IOException {
+  private MonotonicBlockPackedReader getOrdIndexInstance(IndexInput data, FieldInfo field, NumericEntry entry) throws IOException {
     final MonotonicBlockPackedReader ordIndex;
-    MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.name);
-    if (ordIndexInstance == null) {
-      data.seek(entry.offset);
-      ordIndexInstance = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.count+1, false);
-      ordIndexInstances.put(field.name, ordIndexInstance);
-      ramBytesUsed.addAndGet(ordIndexInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+    synchronized (ordIndexInstances) {
+      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);
+      if (ordIndexInstance == null) {
+        data.seek(entry.offset);
+        ordIndexInstance = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.count+1, false);
+        ordIndexInstances.put(field.number, ordIndexInstance);
+        ramBytesUsed.addAndGet(ordIndexInstance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
+      }
+      ordIndex = ordIndexInstance;
     }
-    ordIndex = ordIndexInstance;
     return ordIndex;
   }
   
   @Override
   public SortedNumericDocValues getSortedNumeric(FieldInfo field) throws IOException {
-    SortedSetEntry ss = sortedNumerics.get(field.name);
-    NumericEntry numericEntry = numerics.get(field.name);
+    SortedSetEntry ss = sortedNumerics.get(field.number);
+    NumericEntry numericEntry = numerics.get(field.number);
     final LongValues values = getNumeric(numericEntry);
     if (ss.format == SORTED_SINGLE_VALUED) {
       final Bits docsWithField = getMissingBits(numericEntry.missingOffset);
       return DocValues.singleton(values, docsWithField);
     } else if (ss.format == SORTED_WITH_ADDRESSES) {
       final IndexInput data = this.data.clone();
-      final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.name));
+      final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));
       
       return new SortedNumericDocValues() {
         long startOffset;
@@ -602,7 +586,7 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
 
   @Override
   public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
-    SortedSetEntry ss = sortedSets.get(field.name);
+    SortedSetEntry ss = sortedSets.get(field.number);
     if (ss.format == SORTED_SINGLE_VALUED) {
       final SortedDocValues values = getSorted(field);
       return DocValues.singleton(values);
@@ -611,12 +595,12 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
     }
 
     final IndexInput data = this.data.clone();
-    final long valueCount = binaries.get(field.name).count;
+    final long valueCount = binaries.get(field.number).count;
     // we keep the byte[]s and list of ords on disk, these could be large
     final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);
-    final LongValues ordinals = getNumeric(ords.get(field.name));
+    final LongValues ordinals = getNumeric(ords.get(field.number));
     // but the addresses to the ord stream are in RAM
-    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.name));
+    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));
     
     return new RandomAccessOrds() {
       long startOffset;
@@ -714,10 +698,10 @@ class Lucene49DocValuesProducer extends DocValuesProducer implements Closeable {
       case SORTED:
         return DocValues.docsWithValue(getSorted(field), maxDoc);
       case BINARY:
-        BinaryEntry be = binaries.get(field.name);
+        BinaryEntry be = binaries.get(field.number);
         return getMissingBits(be.missingOffset);
       case NUMERIC:
-        NumericEntry ne = numerics.get(field.name);
+        NumericEntry ne = numerics.get(field.number);
         return getMissingBits(ne.missingOffset);
       default:
         throw new AssertionError();
diff --git lucene/build.xml lucene/build.xml
index 22eb19a..3845478 100644
--- lucene/build.xml
+++ lucene/build.xml
@@ -346,7 +346,7 @@
     <svn-export-source source.dir="."/>
 
     <!-- Exclude javadoc package-list files under licenses incompatible with the ASL -->
-    <delete dir="${svn.export.dir}/tools/javadoc/java7"/>
+    <delete dir="${svn.export.dir}/tools/javadoc/java8"/>
     <!-- Exclude clover license files incompatible with the ASL -->
     <delete dir="${svn.export.dir}/tools/clover"/>
 
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
index 3d267c0..6496902 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsReader.java
@@ -18,10 +18,8 @@ package org.apache.lucene.codecs.blockterms;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.codecs.BlockTermState;
@@ -44,7 +42,6 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -266,11 +263,6 @@ public class BlockTermsReader extends FieldsProducer {
     public long ramBytesUsed() {
       return FIELD_READER_RAM_BYTES_USED;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
 
     @Override
     public TermsEnum iterator(TermsEnum reuse) throws IOException {
@@ -885,23 +877,6 @@ public class BlockTermsReader extends FieldsProducer {
     }
     return ramBytesUsed;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    if (indexReader != null) {
-      resources.add(Accountables.namedAccountable("term index", indexReader));
-    }
-    if (postingsReader != null) {
-      resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    }
-    return Collections.unmodifiableList(resources);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(index=" + indexReader + ",delegate=" + postingsReader + ")";
-  }
 
   @Override
   public void checkIntegrity() throws IOException {   
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader.java lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader.java
index 02d77eb..6065e5d 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader.java
@@ -25,16 +25,13 @@ import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.packed.MonotonicBlockPackedReader;
 
-import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Comparator;
-import java.util.List;
 import java.io.IOException;
 
 import org.apache.lucene.index.IndexFileNames;
@@ -64,7 +61,7 @@ public class FixedGapTermsIndexReader extends TermsIndexReaderBase {
   // all fields share this single logical byte[]
   private final PagedBytes.Reader termBytesReader;
 
-  final HashMap<String,FieldIndexData> fields = new HashMap<>();
+  final HashMap<FieldInfo,FieldIndexData> fields = new HashMap<>();
   
   // start of the field info data
   private long dirOffset;
@@ -118,7 +115,7 @@ public class FixedGapTermsIndexReader extends TermsIndexReaderBase {
           throw new CorruptIndexException("invalid packedIndexStart: " + packedIndexStart + " indexStart: " + indexStart + "numIndexTerms: " + numIndexTerms + " (resource=" + in + ")");
         }
         final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
-        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));
+        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));
         if (previous != null) {
           throw new CorruptIndexException("duplicate field: " + fieldInfo.name + " (resource=" + in + ")");
         }
@@ -273,28 +270,11 @@ public class FixedGapTermsIndexReader extends TermsIndexReaderBase {
       return ((termOffsets!=null)? termOffsets.ramBytesUsed() : 0) + 
           ((termsDictOffsets!=null)? termsDictOffsets.ramBytesUsed() : 0);
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      if (termOffsets != null) {
-        resources.add(Accountables.namedAccountable("term lengths", termOffsets));
-      }
-      if (termsDictOffsets != null) {
-        resources.add(Accountables.namedAccountable("offsets", termsDictOffsets));
-      }
-      return resources;
-    }
-
-    @Override
-    public String toString() {
-      return "FixedGapTermIndex(indexterms=" + numIndexTerms + ")";
-    }
   }
 
   @Override
   public FieldIndexEnum getFieldEnum(FieldInfo fieldInfo) {
-    return new IndexEnum(fields.get(fieldInfo.name));
+    return new IndexEnum(fields.get(fieldInfo));
   }
 
   @Override
@@ -318,14 +298,4 @@ public class FixedGapTermsIndexReader extends TermsIndexReaderBase {
     }
     return sizeInBytes;
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", fields);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",interval=" + indexInterval + ")";
-  }
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexReader.java lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexReader.java
index ef7540c..1cba75d 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.codecs.blockterms;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 import java.util.HashMap;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -30,7 +29,6 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.fst.BytesRefFSTEnum;
@@ -44,7 +42,7 @@ public class VariableGapTermsIndexReader extends TermsIndexReaderBase {
 
   private final PositiveIntOutputs fstOutputs = PositiveIntOutputs.getSingleton();
 
-  final HashMap<String,FieldIndexData> fields = new HashMap<>();
+  final HashMap<FieldInfo,FieldIndexData> fields = new HashMap<>();
   
   // start of the field info data
   private long dirOffset;
@@ -78,7 +76,7 @@ public class VariableGapTermsIndexReader extends TermsIndexReaderBase {
         final int field = in.readVInt();
         final long indexStart = in.readVLong();
         final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
-        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, fieldInfo, indexStart));
+        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, fieldInfo, indexStart));
         if (previous != null) {
           throw new CorruptIndexException("duplicate field: " + fieldInfo.name + " (resource=" + in + ")");
         }
@@ -177,25 +175,11 @@ public class VariableGapTermsIndexReader extends TermsIndexReaderBase {
     public long ramBytesUsed() {
       return fst == null ? 0 : fst.ramBytesUsed();
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      if (fst == null) {
-        return Collections.emptyList();
-      } else {
-        return Collections.singletonList(Accountables.namedAccountable("index data", fst));
-      }
-    }
-    
-    @Override
-    public String toString() {
-      return "VarGapTermIndex";
-    }
   }
 
   @Override
   public FieldIndexEnum getFieldEnum(FieldInfo fieldInfo) {
-    final FieldIndexData fieldData = fields.get(fieldInfo.name);
+    final FieldIndexData fieldData = fields.get(fieldInfo);
     if (fieldData.fst == null) {
       return null;
     } else {
@@ -225,14 +209,4 @@ public class VariableGapTermsIndexReader extends TermsIndexReaderBase {
     }
     return sizeInBytes;
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", fields);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ")";
-  }
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsReader.java
index a4503c3..a5f2a14 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsReader.java
@@ -18,10 +18,8 @@ package org.apache.lucene.codecs.blocktreeords;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -38,8 +36,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 
@@ -239,19 +235,11 @@ public final class OrdsBlockTreeTermsReader extends FieldsProducer {
 
   @Override
   public long ramBytesUsed() {
-    long sizeInBytes = postingsReader.ramBytesUsed();
+    long sizeInByes = ((postingsReader!=null) ? postingsReader.ramBytesUsed() : 0);
     for (OrdsFieldReader reader : fields.values()) {
-      sizeInBytes += reader.ramBytesUsed();
+      sizeInByes += reader.ramBytesUsed();
     }
-    return sizeInBytes;
-  }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("field", fields));
-    resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    return Collections.unmodifiableList(resources);
+    return sizeInByes;
   }
 
   @Override
@@ -262,9 +250,4 @@ public final class OrdsBlockTreeTermsReader extends FieldsProducer {
     // postings
     postingsReader.checkIntegrity();
   }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",delegate=" + postingsReader.toString() + ")";
-  }
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsFieldReader.java lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsFieldReader.java
index 9127ecf..44f4fbe 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsFieldReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsFieldReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.codecs.blocktreeords;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.blocktreeords.FSTOrdsOutputs.Output;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
@@ -28,7 +27,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
 import org.apache.lucene.util.fst.FST;
@@ -172,18 +170,4 @@ final class OrdsFieldReader extends Terms implements Accountable {
   public long ramBytesUsed() {
     return ((index!=null)? index.ramBytesUsed() : 0);
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (index == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singleton(Accountables.namedAccountable("term index", index));
-    }
-  }
-  
-  @Override
-  public String toString() {
-    return "OrdsBlockTreeTerms(terms=" + numTerms + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-  }
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
index 4760fd5..d37edea 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.bloom;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -43,8 +42,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -412,24 +409,9 @@ public final class BloomFilteringPostingsFormat extends PostingsFormat {
     }
 
     @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      resources.addAll(Accountables.namedAccountables("field", bloomsByFieldName));
-      if (delegateFieldsProducer != null) {
-        resources.add(Accountables.namedAccountable("delegate", delegateFieldsProducer));
-      }
-      return Collections.unmodifiableList(resources);
-    }
-
-    @Override
     public void checkIntegrity() throws IOException {
       delegateFieldsProducer.checkIntegrity();
     }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(fields=" + bloomsByFieldName.size() + ",delegate=" + delegateFieldsProducer + ")";
-    }
   }
   
   class BloomFilteredFieldsConsumer extends FieldsConsumer {
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
index 77cf7d0..1c919b4 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java
@@ -17,7 +17,6 @@ package org.apache.lucene.codecs.bloom;
  * limitations under the License.
  */
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
@@ -310,14 +309,4 @@ public class FuzzySet implements Accountable {
   public long ramBytesUsed() {
     return RamUsageEstimator.sizeOf(filter.getBits());
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(hash=" + hashFunction + ")";
-  }
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/bloom/MurmurHash2.java lucene/codecs/src/java/org/apache/lucene/codecs/bloom/MurmurHash2.java
index ea7486f..cb68903 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/bloom/MurmurHash2.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/bloom/MurmurHash2.java
@@ -98,9 +98,5 @@ public final class MurmurHash2 extends HashFunction{
   public final int hash(BytesRef br) {
     return hash32(br.bytes, br.offset, br.length);
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }  
+  
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectDocValuesProducer.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectDocValuesProducer.java
index 099ce51..562119f 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectDocValuesProducer.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectDocValuesProducer.java
@@ -18,10 +18,7 @@ package org.apache.lucene.codecs.memory;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -31,7 +28,6 @@ import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.RandomAccessOrds;
@@ -41,8 +37,6 @@ import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
@@ -55,22 +49,25 @@ import org.apache.lucene.util.RamUsageEstimator;
 
 class DirectDocValuesProducer extends DocValuesProducer {
   // metadata maps (just file pointers and minimal stuff)
-  private final Map<String,NumericEntry> numerics = new HashMap<>();
-  private final Map<String,BinaryEntry> binaries = new HashMap<>();
-  private final Map<String,SortedEntry> sorteds = new HashMap<>();
-  private final Map<String,SortedSetEntry> sortedSets = new HashMap<>();
-  private final Map<String,SortedNumericEntry> sortedNumerics = new HashMap<>();
+  private final Map<Integer,NumericEntry> numerics = new HashMap<>();
+  private final Map<Integer,BinaryEntry> binaries = new HashMap<>();
+  private final Map<Integer,SortedEntry> sorteds = new HashMap<>();
+  private final Map<Integer,SortedSetEntry> sortedSets = new HashMap<>();
+  private final Map<Integer,SortedNumericEntry> sortedNumerics = new HashMap<>();
   private final IndexInput data;
   
   // ram instances we have already loaded
-  private final Map<String,NumericRawValues> numericInstances = new HashMap<>();
-  private final Map<String,BinaryRawValues> binaryInstances = new HashMap<>();
-  private final Map<String,SortedRawValues> sortedInstances = new HashMap<>();
-  private final Map<String,SortedSetRawValues> sortedSetInstances = new HashMap<>();
-  private final Map<String,SortedNumericRawValues> sortedNumericInstances = new HashMap<>();
-  private final Map<String,FixedBitSet> docsWithFieldInstances = new HashMap<>();
-  
-  private final int numEntries;
+  private final Map<Integer,NumericDocValues> numericInstances = 
+      new HashMap<>();
+  private final Map<Integer,BinaryRawValues> binaryInstances =
+      new HashMap<>();
+  private final Map<Integer,SortedRawValues> sortedInstances =
+      new HashMap<>();
+  private final Map<Integer,SortedSetRawValues> sortedSetInstances =
+      new HashMap<>();
+  private final Map<Integer,SortedNumericRawValues> sortedNumericInstances =
+      new HashMap<>();
+  private final Map<Integer,Bits> docsWithFieldInstances = new HashMap<>();
   
   private final int maxDoc;
   private final AtomicLong ramBytesUsed;
@@ -98,7 +95,7 @@ class DirectDocValuesProducer extends DocValuesProducer {
       version = CodecUtil.checkHeader(in, metaCodec, 
                                       VERSION_START,
                                       VERSION_CURRENT);
-      numEntries = readFields(in, state.fieldInfos);
+      readFields(in);
 
       CodecUtil.checkFooter(in);
       success = true;
@@ -191,41 +188,37 @@ class DirectDocValuesProducer extends DocValuesProducer {
     return entry;
   }
 
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numEntries = 0;
+  private void readFields(IndexInput meta) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numEntries++;
-      FieldInfo info = infos.fieldInfo(fieldNumber);
       int fieldType = meta.readByte();
       if (fieldType == NUMBER) {
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
       } else if (fieldType == BYTES) {
-        binaries.put(info.name, readBinaryEntry(meta));
+        binaries.put(fieldNumber, readBinaryEntry(meta));
       } else if (fieldType == SORTED) {
         SortedEntry entry = readSortedEntry(meta);
-        sorteds.put(info.name, entry);
-        binaries.put(info.name, entry.values);
+        sorteds.put(fieldNumber, entry);
+        binaries.put(fieldNumber, entry.values);
       } else if (fieldType == SORTED_SET) {
         SortedSetEntry entry = readSortedSetEntry(meta, false);
-        sortedSets.put(info.name, entry);
-        binaries.put(info.name, entry.values);
+        sortedSets.put(fieldNumber, entry);
+        binaries.put(fieldNumber, entry.values);
       } else if (fieldType == SORTED_SET_SINGLETON) {
         SortedSetEntry entry = readSortedSetEntry(meta, true);
-        sortedSets.put(info.name, entry);
-        binaries.put(info.name, entry.values);
+        sortedSets.put(fieldNumber, entry);
+        binaries.put(fieldNumber, entry.values);
       } else if (fieldType == SORTED_NUMERIC) {
         SortedNumericEntry entry = readSortedNumericEntry(meta, false);
-        sortedNumerics.put(info.name, entry);
+        sortedNumerics.put(fieldNumber, entry);
       } else if (fieldType == SORTED_NUMERIC_SINGLETON) {
         SortedNumericEntry entry = readSortedNumericEntry(meta, true);
-        sortedNumerics.put(info.name, entry);
+        sortedNumerics.put(fieldNumber, entry);
       } else {
-        throw new CorruptIndexException("invalid entry type: " + fieldType + ", field= " + info.name + ", input=" + meta);
+        throw new CorruptIndexException("invalid entry type: " + fieldType + ", input=" + meta);
       }
       fieldNumber = meta.readVInt();
     }
-    return numEntries;
   }
 
   @Override
@@ -234,55 +227,35 @@ class DirectDocValuesProducer extends DocValuesProducer {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("numeric field", numericInstances));
-    resources.addAll(Accountables.namedAccountables("binary field", binaryInstances));
-    resources.addAll(Accountables.namedAccountables("sorted field", sortedInstances));
-    resources.addAll(Accountables.namedAccountables("sorted set field", sortedSetInstances));
-    resources.addAll(Accountables.namedAccountables("sorted numeric field", sortedNumericInstances));
-    resources.addAll(Accountables.namedAccountables("missing bitset field", docsWithFieldInstances));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(entries=" + numEntries + ")";
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     CodecUtil.checksumEntireFile(data);
   }
 
   @Override
   public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericRawValues instance = numericInstances.get(field.name);
+    NumericDocValues instance = numericInstances.get(field.number);
     if (instance == null) {
       // Lazy load
-      instance = loadNumeric(numerics.get(field.name));
-      numericInstances.put(field.name, instance);
+      instance = loadNumeric(numerics.get(field.number));
+      numericInstances.put(field.number, instance);
     }
-    return instance.numerics;
+    return instance;
   }
   
-  private NumericRawValues loadNumeric(NumericEntry entry) throws IOException {
-    NumericRawValues ret = new NumericRawValues();
+  private NumericDocValues loadNumeric(NumericEntry entry) throws IOException {
     data.seek(entry.offset + entry.missingBytes);
     switch (entry.byteWidth) {
     case 1:
       {
         final byte[] values = new byte[entry.count];
         data.readBytes(values, 0, entry.count);
-        ret.bytesUsed = RamUsageEstimator.sizeOf(values);
-        ramBytesUsed.addAndGet(ret.bytesUsed);
-        ret.numerics = new NumericDocValues() {
+        ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
+        return new NumericDocValues() {
           @Override
           public long get(int idx) {
             return values[idx];
           }
         };
-        return ret;
       }
 
     case 2:
@@ -291,15 +264,13 @@ class DirectDocValuesProducer extends DocValuesProducer {
         for(int i=0;i<entry.count;i++) {
           values[i] = data.readShort();
         }
-        ret.bytesUsed = RamUsageEstimator.sizeOf(values);
-        ramBytesUsed.addAndGet(ret.bytesUsed);
-        ret.numerics = new NumericDocValues() {
+        ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
+        return new NumericDocValues() {
           @Override
           public long get(int idx) {
             return values[idx];
           }
         };
-        return ret;
       }
 
     case 4:
@@ -308,15 +279,13 @@ class DirectDocValuesProducer extends DocValuesProducer {
         for(int i=0;i<entry.count;i++) {
           values[i] = data.readInt();
         }
-        ret.bytesUsed = RamUsageEstimator.sizeOf(values);
-        ramBytesUsed.addAndGet(ret.bytesUsed);
-        ret.numerics = new NumericDocValues() {
+        ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
+        return new NumericDocValues() {
           @Override
           public long get(int idx) {
             return values[idx];
           }
         };
-        return ret;
       }
 
     case 8:
@@ -325,15 +294,13 @@ class DirectDocValuesProducer extends DocValuesProducer {
         for(int i=0;i<entry.count;i++) {
           values[i] = data.readLong();
         }
-        ret.bytesUsed = RamUsageEstimator.sizeOf(values);
-        ramBytesUsed.addAndGet(ret.bytesUsed);
-        ret.numerics = new NumericDocValues() {
+        ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(values));
+        return new NumericDocValues() {
           @Override
           public long get(int idx) {
             return values[idx];
           }
         };
-        return ret;
       }
     
     default:
@@ -343,11 +310,11 @@ class DirectDocValuesProducer extends DocValuesProducer {
 
   @Override
   public synchronized BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryRawValues instance = binaryInstances.get(field.name);
+    BinaryRawValues instance = binaryInstances.get(field.number);
     if (instance == null) {
       // Lazy load
-      instance = loadBinary(binaries.get(field.name));
-      binaryInstances.put(field.name, instance);
+      instance = loadBinary(binaries.get(field.number));
+      binaryInstances.put(field.number, instance);
     }
     final byte[] bytes = instance.bytes;
     final int[] address = instance.address;
@@ -387,17 +354,17 @@ class DirectDocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    final SortedEntry entry = sorteds.get(field.name);
+    final SortedEntry entry = sorteds.get(field.number);
     SortedRawValues instance;
     synchronized (this) {
-      instance = sortedInstances.get(field.name);
+      instance = sortedInstances.get(field.number);
       if (instance == null) {
         // Lazy load
         instance = loadSorted(field);
-        sortedInstances.put(field.name, instance);
+        sortedInstances.put(field.number, instance);
       }
     }
-    return newSortedInstance(instance.docToOrd.numerics, getBinary(field), entry.values.count);
+    return newSortedInstance(instance.docToOrd, getBinary(field), entry.values.count);
   }
   
   private SortedDocValues newSortedInstance(final NumericDocValues docToOrd, final BinaryDocValues values, final int count) {
@@ -425,8 +392,8 @@ class DirectDocValuesProducer extends DocValuesProducer {
   }
 
   private SortedRawValues loadSorted(FieldInfo field) throws IOException {
-    final SortedEntry entry = sorteds.get(field.name);
-    final NumericRawValues docToOrd = loadNumeric(entry.docToOrd);
+    final SortedEntry entry = sorteds.get(field.number);
+    final NumericDocValues docToOrd = loadNumeric(entry.docToOrd);
     final SortedRawValues values = new SortedRawValues();
     values.docToOrd = docToOrd;
     return values;
@@ -434,21 +401,21 @@ class DirectDocValuesProducer extends DocValuesProducer {
 
   @Override
   public synchronized SortedNumericDocValues getSortedNumeric(FieldInfo field) throws IOException {
-    SortedNumericRawValues instance = sortedNumericInstances.get(field.name);
-    final SortedNumericEntry entry = sortedNumerics.get(field.name);
+    SortedNumericRawValues instance = sortedNumericInstances.get(field.number);
+    final SortedNumericEntry entry = sortedNumerics.get(field.number);
     if (instance == null) {
       // Lazy load
       instance = loadSortedNumeric(entry);
-      sortedNumericInstances.put(field.name, instance);
+      sortedNumericInstances.put(field.number, instance);
     }
     
     if (entry.docToAddress == null) {
-      final NumericDocValues single = instance.values.numerics;
-      final Bits docsWithField = getMissingBits(field, entry.values.missingOffset, entry.values.missingBytes);
+      final NumericDocValues single = instance.values;
+      final Bits docsWithField = getMissingBits(field.number, entry.values.missingOffset, entry.values.missingBytes);
       return DocValues.singleton(single, docsWithField);
     } else {
-      final NumericDocValues docToAddress = instance.docToAddress.numerics;
-      final NumericDocValues values = instance.values.numerics;
+      final NumericDocValues docToAddress = instance.docToAddress;
+      final NumericDocValues values = instance.values;
       
       return new SortedNumericDocValues() {
         int valueStart;
@@ -484,20 +451,20 @@ class DirectDocValuesProducer extends DocValuesProducer {
 
   @Override
   public synchronized SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
-    SortedSetRawValues instance = sortedSetInstances.get(field.name);
-    final SortedSetEntry entry = sortedSets.get(field.name);
+    SortedSetRawValues instance = sortedSetInstances.get(field.number);
+    final SortedSetEntry entry = sortedSets.get(field.number);
     if (instance == null) {
       // Lazy load
       instance = loadSortedSet(entry);
-      sortedSetInstances.put(field.name, instance);
+      sortedSetInstances.put(field.number, instance);
     }
 
     if (instance.docToOrdAddress == null) {
-      SortedDocValues sorted = newSortedInstance(instance.ords.numerics, getBinary(field), entry.values.count);
+      SortedDocValues sorted = newSortedInstance(instance.ords, getBinary(field), entry.values.count);
       return DocValues.singleton(sorted);
     } else {
-      final NumericDocValues docToOrdAddress = instance.docToOrdAddress.numerics;
-      final NumericDocValues ords = instance.ords.numerics;
+      final NumericDocValues docToOrdAddress = instance.docToOrdAddress;
+      final NumericDocValues ords = instance.ords;
       final BinaryDocValues values = getBinary(field);
       
       // Must make a new instance since the iterator has state:
@@ -557,13 +524,13 @@ class DirectDocValuesProducer extends DocValuesProducer {
     return instance;
   }
 
-  private Bits getMissingBits(FieldInfo field, final long offset, final long length) throws IOException {
+  private Bits getMissingBits(int fieldNumber, final long offset, final long length) throws IOException {
     if (offset == -1) {
       return new Bits.MatchAllBits(maxDoc);
     } else {
-      FixedBitSet instance;
+      Bits instance;
       synchronized(this) {
-        instance = docsWithFieldInstances.get(field.name);
+        instance = docsWithFieldInstances.get(fieldNumber);
         if (instance == null) {
           IndexInput data = this.data.clone();
           data.seek(offset);
@@ -573,7 +540,7 @@ class DirectDocValuesProducer extends DocValuesProducer {
             bits[i] = data.readLong();
           }
           instance = new FixedBitSet(bits, maxDoc);
-          docsWithFieldInstances.put(field.name, instance);
+          docsWithFieldInstances.put(fieldNumber, instance);
         }
       }
       return instance;
@@ -590,11 +557,11 @@ class DirectDocValuesProducer extends DocValuesProducer {
       case SORTED:
         return DocValues.docsWithValue(getSorted(field), maxDoc);
       case BINARY:
-        BinaryEntry be = binaries.get(field.name);
-        return getMissingBits(field, be.missingOffset, be.missingBytes);
+        BinaryEntry be = binaries.get(field.number);
+        return getMissingBits(field.number, be.missingOffset, be.missingBytes);
       case NUMERIC:
-        NumericEntry ne = numerics.get(field.name);
-        return getMissingBits(field, ne.missingOffset, ne.missingBytes);
+        NumericEntry ne = numerics.get(field.number);
+        return getMissingBits(field.number, ne.missingOffset, ne.missingBytes);
       default: 
         throw new AssertionError();
     }
@@ -605,130 +572,23 @@ class DirectDocValuesProducer extends DocValuesProducer {
     data.close();
   }
 
-  static class BinaryRawValues implements Accountable {
+  static class BinaryRawValues {
     byte[] bytes;
     int[] address;
-    
-    @Override
-    public long ramBytesUsed() {
-      long bytesUsed = RamUsageEstimator.sizeOf(bytes);
-      if (address != null) {
-        bytesUsed += RamUsageEstimator.sizeOf(address);
-      }
-      return bytesUsed;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      if (address != null) {
-        resources.add(Accountables.namedAccountable("addresses", RamUsageEstimator.sizeOf(address)));
-      }
-      resources.add(Accountables.namedAccountable("bytes", RamUsageEstimator.sizeOf(bytes)));
-      return Collections.unmodifiableList(resources);
-    }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName();
-    }
-  }
-  
-  static class NumericRawValues implements Accountable {
-    NumericDocValues numerics;
-    long bytesUsed;
-    
-    @Override
-    public long ramBytesUsed() {
-      return bytesUsed;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName();
-    }
   }
 
-  static class SortedRawValues implements Accountable {
-    NumericRawValues docToOrd;
-
-    @Override
-    public long ramBytesUsed() {
-      return docToOrd.ramBytesUsed();
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return docToOrd.getChildResources();
-    }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName();
-    }
+  static class SortedRawValues {
+    NumericDocValues docToOrd;
   }
   
-  static class SortedNumericRawValues implements Accountable {
-    NumericRawValues docToAddress;
-    NumericRawValues values;
-    
-    @Override
-    public long ramBytesUsed() {
-      long bytesUsed = values.ramBytesUsed();
-      if (docToAddress != null) {
-        bytesUsed += docToAddress.ramBytesUsed();
-      }
-      return bytesUsed;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      if (docToAddress != null) {
-        resources.add(Accountables.namedAccountable("addresses", docToAddress));
-      }
-      resources.add(Accountables.namedAccountable("values", values));
-      return Collections.unmodifiableList(resources);
-    }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName();
-    }
+  static class SortedNumericRawValues {
+    NumericDocValues docToAddress;
+    NumericDocValues values;
   }
 
-  static class SortedSetRawValues implements Accountable {
-    NumericRawValues docToOrdAddress;
-    NumericRawValues ords;
-
-    @Override
-    public long ramBytesUsed() {
-      long bytesUsed = ords.ramBytesUsed();
-      if (docToOrdAddress != null) {
-        bytesUsed += docToOrdAddress.ramBytesUsed();
-      }
-      return bytesUsed;
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      if (docToOrdAddress != null) {
-        resources.add(Accountables.namedAccountable("addresses", docToOrdAddress));
-      }
-      resources.add(Accountables.namedAccountable("ordinals", ords));
-      return Collections.unmodifiableList(resources);
-    }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName();
-    }
+  static class SortedSetRawValues {
+    NumericDocValues docToOrdAddress;
+    NumericDocValues ords;
   }
 
   static class NumericEntry {
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
index 418ae8c..456f5d8 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
@@ -41,7 +41,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.RAMOutputStream;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -160,22 +159,12 @@ public final class DirectPostingsFormat extends PostingsFormat {
       }
       return sizeInBytes;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Accountables.namedAccountables("field", fields);
-    }
 
     @Override
     public void checkIntegrity() throws IOException {
       // if we read entirely into ram, we already validated.
       // otherwise returned the raw postings reader
     }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(fields=" + fields.size() + ")";
-    }
   }
 
   private final static class DirectField extends Terms implements Accountable {
@@ -208,11 +197,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
             ((postings!=null) ? RamUsageEstimator.sizeOf(postings) : 0) + 
             ((payloads!=null) ? RamUsageEstimator.sizeOf(payloads) : 0);
       }
-
-      @Override
-      public Iterable<? extends Accountable> getChildResources() {
-        return Collections.emptyList();
-      }
     }
 
     // TODO: maybe specialize into prx/no-prx/no-frq cases?
@@ -261,11 +245,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
          
          return sizeInBytes;
       }
-      
-      @Override
-      public Iterable<? extends Accountable> getChildResources() {
-        return Collections.emptyList();
-      }
     }
 
     private final byte[] termBytes;
@@ -543,16 +522,6 @@ public final class DirectPostingsFormat extends PostingsFormat {
       
       return sizeInBytes;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-
-    @Override
-    public String toString() {
-      return "DirectTerms(terms=" + terms.length + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-    }
 
     // Compares in unicode (UTF8) order:
     int compare(int ord, BytesRef other) {
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
index 1e4e9cc..914852a 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
@@ -23,7 +23,6 @@ import java.util.ArrayList;
 import java.util.BitSet;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.index.CorruptIndexException;
@@ -44,8 +43,6 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.automaton.ByteRunAutomaton;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -185,7 +182,7 @@ public class FSTOrdTermsReader extends FieldsProducer {
     }
   }
 
-  final class TermsReader extends Terms implements Accountable {
+  final class TermsReader extends Terms {
     final FieldInfo fieldInfo;
     final long numTerms;
     final long sumTotalTermFreq;
@@ -279,33 +276,6 @@ public class FSTOrdTermsReader extends FieldsProducer {
       return new IntersectTermsEnum(compiled, startTerm);
     }
 
-    @Override
-    public long ramBytesUsed() {
-      long ramBytesUsed = 0;
-      if (index != null) {
-        ramBytesUsed += index.ramBytesUsed();
-        ramBytesUsed += RamUsageEstimator.sizeOf(metaBytesBlock);
-        ramBytesUsed += RamUsageEstimator.sizeOf(metaLongsBlock);
-        ramBytesUsed += RamUsageEstimator.sizeOf(skipInfo);
-        ramBytesUsed += RamUsageEstimator.sizeOf(statsBlock);
-      }
-      return ramBytesUsed;
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      if (index == null) {
-        return Collections.emptyList();
-      } else {
-        return Collections.singletonList(Accountables.namedAccountable("terms", index));
-      }
-    }
-    
-    @Override
-    public String toString() {
-      return "FSTOrdTerms(terms=" + numTerms + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-    }
-
     // Only wraps common operations for PBF interact
     abstract class BaseTermsEnum extends TermsEnum {
 
@@ -864,25 +834,18 @@ public class FSTOrdTermsReader extends FieldsProducer {
   public long ramBytesUsed() {
     long ramBytesUsed = postingsReader.ramBytesUsed();
     for (TermsReader r : fields.values()) {
-      ramBytesUsed += r.ramBytesUsed();
+      if (r.index != null) {
+        ramBytesUsed += r.index.ramBytesUsed();
+        ramBytesUsed += RamUsageEstimator.sizeOf(r.metaBytesBlock);
+        ramBytesUsed += RamUsageEstimator.sizeOf(r.metaLongsBlock);
+        ramBytesUsed += RamUsageEstimator.sizeOf(r.skipInfo);
+        ramBytesUsed += RamUsageEstimator.sizeOf(r.statsBlock);
+      }
     }
     return ramBytesUsed;
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("field", fields));
-    resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",delegate=" + postingsReader + ")";
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     postingsReader.checkIntegrity();
   }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermOutputs.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermOutputs.java
index d3bb26f..483ea9a 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermOutputs.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermOutputs.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.memory;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
@@ -80,11 +79,6 @@ class FSTTermOutputs extends Outputs<FSTTermOutputs.TermData> {
       return ramBytesUsed;
     }
 
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-    
     // NOTE: actually, FST nodes are seldom 
     // identical when outputs on their arcs 
     // aren't NO_OUTPUTs.
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
index 97b96c7..b19917c 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
@@ -22,7 +22,6 @@ import java.util.ArrayList;
 import java.util.BitSet;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.index.CorruptIndexException;
@@ -43,7 +42,6 @@ import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.automaton.ByteRunAutomaton;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -192,25 +190,7 @@ public class FSTTermsReader extends FieldsProducer {
 
     @Override
     public long ramBytesUsed() {
-      long bytesUsed = BASE_RAM_BYTES_USED;
-      if (dict != null) {
-        bytesUsed += dict.ramBytesUsed();
-      }
-      return bytesUsed;
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      if (dict == null) {
-        return Collections.emptyList();
-      } else {
-        return Collections.singletonList(Accountables.namedAccountable("terms", dict));
-      }
-    }
-    
-    @Override
-    public String toString() {
-      return "FSTTerms(terms=" + numTerms + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
+      return BASE_RAM_BYTES_USED + dict.ramBytesUsed();
     }
 
     @Override
@@ -772,19 +752,6 @@ public class FSTTermsReader extends FieldsProducer {
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("field", fields));
-    resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    return Collections.unmodifiableCollection(resources);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",delegate=" + postingsReader + ")";
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     postingsReader.checkIntegrity();
   }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
index f5ba225..5d732d9 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryDocValuesProducer.java
@@ -18,10 +18,7 @@ package org.apache.lucene.codecs.memory;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -44,8 +41,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -72,23 +67,23 @@ import org.apache.lucene.util.packed.PackedInts;
  */
 class MemoryDocValuesProducer extends DocValuesProducer {
   // metadata maps (just file pointers and minimal stuff)
-  private final Map<String,NumericEntry> numerics = new HashMap<>();
-  private final Map<String,BinaryEntry> binaries = new HashMap<>();
-  private final Map<String,FSTEntry> fsts = new HashMap<>();
-  private final Map<String,SortedSetEntry> sortedSets = new HashMap<>();
-  private final Map<String,SortedNumericEntry> sortedNumerics = new HashMap<>();
+  private final Map<Integer,NumericEntry> numerics = new HashMap<>();
+  private final Map<Integer,BinaryEntry> binaries = new HashMap<>();
+  private final Map<Integer,FSTEntry> fsts = new HashMap<>();
+  private final Map<Integer,SortedSetEntry> sortedSets = new HashMap<>();
+  private final Map<Integer,SortedNumericEntry> sortedNumerics = new HashMap<>();
   private final IndexInput data;
   
   // ram instances we have already loaded
-  private final Map<String,NumericDocValues> numericInstances = new HashMap<>();
-  private final Map<String,BytesAndAddresses> pagedBytesInstances = new HashMap<>();
-  private final Map<String,FST<Long>> fstInstances = new HashMap<>();
-  private final Map<String,FixedBitSet> docsWithFieldInstances = new HashMap<>();
-  private final Map<String,MonotonicBlockPackedReader> addresses = new HashMap<>();
+  private final Map<Integer,NumericDocValues> numericInstances = 
+      new HashMap<>();
+  private final Map<Integer,BytesAndAddresses> pagedBytesInstances =
+      new HashMap<>();
+  private final Map<Integer,FST<Long>> fstInstances =
+      new HashMap<>();
+  private final Map<Integer,Bits> docsWithFieldInstances = new HashMap<>();
+  private final Map<Integer,MonotonicBlockPackedReader> addresses = new HashMap<>();
   
-  private final Map<String,Accountable> numericInfo = new HashMap<>();
-
-  private final int numEntries;
   private final int maxDoc;
   private final AtomicLong ramBytesUsed;
   private final int version;
@@ -121,7 +116,7 @@ class MemoryDocValuesProducer extends DocValuesProducer {
       version = CodecUtil.checkHeader(in, metaCodec, 
                                       VERSION_START,
                                       VERSION_CURRENT);
-      numEntries = readFields(in, state.fieldInfos);
+      readFields(in, state.fieldInfos);
       CodecUtil.checkFooter(in);
       ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));
       success = true;
@@ -208,30 +203,24 @@ class MemoryDocValuesProducer extends DocValuesProducer {
     return entry;
   }
   
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numEntries = 0;
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numEntries++;
-      FieldInfo info = infos.fieldInfo(fieldNumber);
-      if (info == null) {
-        throw new CorruptIndexException("invalid field number: " + fieldNumber + " (resource=" + meta + ")");
-      }
       int fieldType = meta.readByte();
       if (fieldType == NUMBER) {
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
       } else if (fieldType == BYTES) {
-        binaries.put(info.name, readBinaryEntry(meta));
+        binaries.put(fieldNumber, readBinaryEntry(meta));
       } else if (fieldType == FST) {
-        fsts.put(info.name,readFSTEntry(meta));
+        fsts.put(fieldNumber,readFSTEntry(meta));
       } else if (fieldType == SORTED_SET) {
         SortedSetEntry entry = new SortedSetEntry();
         entry.singleton = false;
-        sortedSets.put(info.name, entry);
+        sortedSets.put(fieldNumber, entry);
       } else if (fieldType == SORTED_SET_SINGLETON) {
         SortedSetEntry entry = new SortedSetEntry();
         entry.singleton = true;
-        sortedSets.put(info.name, entry);
+        sortedSets.put(fieldNumber, entry);
       } else if (fieldType == SORTED_NUMERIC) {
         SortedNumericEntry entry = new SortedNumericEntry();
         entry.singleton = false;
@@ -239,25 +228,24 @@ class MemoryDocValuesProducer extends DocValuesProducer {
         entry.blockSize = meta.readVInt();
         entry.addressOffset = meta.readLong();
         entry.valueCount = meta.readLong();
-        sortedNumerics.put(info.name, entry);
+        sortedNumerics.put(fieldNumber, entry);
       } else if (fieldType == SORTED_NUMERIC_SINGLETON) {
         SortedNumericEntry entry = new SortedNumericEntry();
         entry.singleton = true;
-        sortedNumerics.put(info.name, entry);
+        sortedNumerics.put(fieldNumber, entry);
       } else {
-        throw new CorruptIndexException("invalid entry type: " + fieldType + ", fieldName=" + info.name + ", input=" + meta);
+        throw new CorruptIndexException("invalid entry type: " + fieldType + ", input=" + meta);
       }
       fieldNumber = meta.readVInt();
     }
-    return numEntries;
   }
 
   @Override
   public synchronized NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericDocValues instance = numericInstances.get(field.name);
+    NumericDocValues instance = numericInstances.get(field.number);
     if (instance == null) {
       instance = loadNumeric(field);
-      numericInstances.put(field.name, instance);
+      numericInstances.put(field.number, instance);
     }
     return instance;
   }
@@ -268,28 +256,12 @@ class MemoryDocValuesProducer extends DocValuesProducer {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("numeric field", numericInfo));
-    resources.addAll(Accountables.namedAccountables("pagedbytes field", pagedBytesInstances));
-    resources.addAll(Accountables.namedAccountables("term dict field", fstInstances));
-    resources.addAll(Accountables.namedAccountables("missing bitset field", docsWithFieldInstances));
-    resources.addAll(Accountables.namedAccountables("addresses field", addresses));
-    return Collections.unmodifiableList(resources);
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     CodecUtil.checksumEntireFile(data);
   }
   
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(entries=" + numEntries + ")";
-  }
-
   private NumericDocValues loadNumeric(FieldInfo field) throws IOException {
-    NumericEntry entry = numerics.get(field.name);
+    NumericEntry entry = numerics.get(field.number);
     data.seek(entry.offset + entry.missingBytes);
     switch (entry.format) {
       case TABLE_COMPRESSED:
@@ -305,7 +277,6 @@ class MemoryDocValuesProducer extends DocValuesProducer {
         final int bitsPerValue = data.readVInt();
         final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), entry.packedIntsVersion, (int)entry.count, bitsPerValue);
         ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed());
-        numericInfo.put(field.name, Accountables.namedAccountable("table compressed", ordsReader));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -318,7 +289,6 @@ class MemoryDocValuesProducer extends DocValuesProducer {
         final int bitsPerValueDelta = data.readVInt();
         final PackedInts.Reader deltaReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatIDDelta), entry.packedIntsVersion, (int)entry.count, bitsPerValueDelta);
         ramBytesUsed.addAndGet(deltaReader.ramBytesUsed());
-        numericInfo.put(field.name, Accountables.namedAccountable("delta compressed", deltaReader));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -329,7 +299,6 @@ class MemoryDocValuesProducer extends DocValuesProducer {
         final int blockSize = data.readVInt();
         final BlockPackedReader reader = new BlockPackedReader(data, entry.packedIntsVersion, blockSize, entry.count, false);
         ramBytesUsed.addAndGet(reader.ramBytesUsed());
-        numericInfo.put(field.name, Accountables.namedAccountable("block compressed", reader));
         return reader;
       case GCD_COMPRESSED:
         final long min = data.readLong();
@@ -338,7 +307,6 @@ class MemoryDocValuesProducer extends DocValuesProducer {
         final int bitsPerValueGCD = data.readVInt();
         final PackedInts.Reader quotientReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatIDGCD), entry.packedIntsVersion, (int)entry.count, bitsPerValueGCD);
         ramBytesUsed.addAndGet(quotientReader.ramBytesUsed());
-        numericInfo.put(field.name, Accountables.namedAccountable("gcd compressed", quotientReader));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -352,14 +320,14 @@ class MemoryDocValuesProducer extends DocValuesProducer {
 
   @Override
   public BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryEntry entry = binaries.get(field.name);
+    BinaryEntry entry = binaries.get(field.number);
 
     BytesAndAddresses instance;
     synchronized (this) {
-      instance = pagedBytesInstances.get(field.name);
+      instance = pagedBytesInstances.get(field.number);
       if (instance == null) {
         instance = loadBinary(field);
-        pagedBytesInstances.put(field.name, instance);
+        pagedBytesInstances.put(field.number, instance);
       }
     }
     final PagedBytes.Reader bytesReader = instance.reader;
@@ -394,7 +362,7 @@ class MemoryDocValuesProducer extends DocValuesProducer {
   
   private BytesAndAddresses loadBinary(FieldInfo field) throws IOException {
     BytesAndAddresses bytesAndAddresses = new BytesAndAddresses();
-    BinaryEntry entry = binaries.get(field.name);
+    BinaryEntry entry = binaries.get(field.number);
     data.seek(entry.offset);
     PagedBytes bytes = new PagedBytes(16);
     bytes.copy(data, entry.numBytes);
@@ -410,18 +378,18 @@ class MemoryDocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    final FSTEntry entry = fsts.get(field.name);
+    final FSTEntry entry = fsts.get(field.number);
     if (entry.numOrds == 0) {
       return DocValues.emptySorted();
     }
     FST<Long> instance;
     synchronized(this) {
-      instance = fstInstances.get(field.name);
+      instance = fstInstances.get(field.number);
       if (instance == null) {
         data.seek(entry.offset);
         instance = new FST<>(data, PositiveIntOutputs.getSingleton());
         ramBytesUsed.addAndGet(instance.ramBytesUsed());
-        fstInstances.put(field.name, instance);
+        fstInstances.put(field.number, instance);
       }
     }
     final NumericDocValues docToOrd = getNumeric(field);
@@ -484,21 +452,21 @@ class MemoryDocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedNumericDocValues getSortedNumeric(FieldInfo field) throws IOException {
-    SortedNumericEntry entry = sortedNumerics.get(field.name);
+    SortedNumericEntry entry = sortedNumerics.get(field.number);
     if (entry.singleton) {
       NumericDocValues values = getNumeric(field);
-      NumericEntry ne = numerics.get(field.name);
-      Bits docsWithField = getMissingBits(field, ne.missingOffset, ne.missingBytes);
+      NumericEntry ne = numerics.get(field.number);
+      Bits docsWithField = getMissingBits(field.number, ne.missingOffset, ne.missingBytes);
       return DocValues.singleton(values, docsWithField);
     } else {
       final NumericDocValues values = getNumeric(field);
       final MonotonicBlockPackedReader addr;
       synchronized (this) {
-        MonotonicBlockPackedReader res = addresses.get(field.name);
+        MonotonicBlockPackedReader res = addresses.get(field.number);
         if (res == null) {
           data.seek(entry.addressOffset);
           res = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.valueCount, false);
-          addresses.put(field.name, res);
+          addresses.put(field.number, res);
         }
         addr = res;
       }
@@ -552,23 +520,23 @@ class MemoryDocValuesProducer extends DocValuesProducer {
   
   @Override
   public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
-    SortedSetEntry sortedSetEntry = sortedSets.get(field.name);
+    SortedSetEntry sortedSetEntry = sortedSets.get(field.number);
     if (sortedSetEntry.singleton) {
       return DocValues.singleton(getSorted(field));
     }
     
-    final FSTEntry entry = fsts.get(field.name);
+    final FSTEntry entry = fsts.get(field.number);
     if (entry.numOrds == 0) {
       return DocValues.emptySortedSet(); // empty FST!
     }
     FST<Long> instance;
     synchronized(this) {
-      instance = fstInstances.get(field.name);
+      instance = fstInstances.get(field.number);
       if (instance == null) {
         data.seek(entry.offset);
         instance = new FST<>(data, PositiveIntOutputs.getSingleton());
         ramBytesUsed.addAndGet(instance.ramBytesUsed());
-        fstInstances.put(field.name, instance);
+        fstInstances.put(field.number, instance);
       }
     }
     final BinaryDocValues docToOrds = getBinary(field);
@@ -643,13 +611,13 @@ class MemoryDocValuesProducer extends DocValuesProducer {
     };
   }
   
-  private Bits getMissingBits(FieldInfo field, final long offset, final long length) throws IOException {
+  private Bits getMissingBits(int fieldNumber, final long offset, final long length) throws IOException {
     if (offset == -1) {
       return new Bits.MatchAllBits(maxDoc);
     } else {
-      FixedBitSet instance;
+      Bits instance;
       synchronized(this) {
-        instance = docsWithFieldInstances.get(field.name);
+        instance = docsWithFieldInstances.get(fieldNumber);
         if (instance == null) {
           IndexInput data = this.data.clone();
           data.seek(offset);
@@ -659,7 +627,7 @@ class MemoryDocValuesProducer extends DocValuesProducer {
             bits[i] = data.readLong();
           }
           instance = new FixedBitSet(bits, maxDoc);
-          docsWithFieldInstances.put(field.name, instance);
+          docsWithFieldInstances.put(fieldNumber, instance);
         }
       }
       return instance;
@@ -676,11 +644,11 @@ class MemoryDocValuesProducer extends DocValuesProducer {
       case SORTED:
         return DocValues.docsWithValue(getSorted(field), maxDoc);
       case BINARY:
-        BinaryEntry be = binaries.get(field.name);
-        return getMissingBits(field, be.missingOffset, be.missingBytes);
+        BinaryEntry be = binaries.get(field.number);
+        return getMissingBits(field.number, be.missingOffset, be.missingBytes);
       case NUMERIC:
-        NumericEntry ne = numerics.get(field.name);
-        return getMissingBits(field, ne.missingOffset, ne.missingBytes);
+        NumericEntry ne = numerics.get(field.number);
+        return getMissingBits(field.number, ne.missingOffset, ne.missingBytes);
       default: 
         throw new AssertionError();
     }
@@ -728,28 +696,9 @@ class MemoryDocValuesProducer extends DocValuesProducer {
     long valueCount;
   }
 
-  static class BytesAndAddresses implements Accountable {
+  static class BytesAndAddresses {
     PagedBytes.Reader reader;
     MonotonicBlockPackedReader addresses;
-    
-    @Override
-    public long ramBytesUsed() {
-      long bytesUsed = reader.ramBytesUsed();
-      if (addresses != null) {
-        bytesUsed += addresses.ramBytesUsed();
-      }
-      return bytesUsed;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      if (addresses != null) {
-        resources.add(Accountables.namedAccountable("addresses", addresses));
-      }
-      resources.add(Accountables.namedAccountable("term bytes", reader));
-      return Collections.unmodifiableList(resources);
-    }
   }
 
   // exposes FSTEnum directly as a TermsEnum: avoids binary-search next()
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
index 8e58251..cf0171d 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
@@ -47,7 +47,6 @@ import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.store.RAMOutputStream;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -954,20 +953,6 @@ public final class MemoryPostingsFormat extends PostingsFormat {
     public long ramBytesUsed() {
       return ((fst!=null) ? fst.ramBytesUsed() : 0);
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      if (fst == null) {
-        return Collections.emptyList();
-      } else {
-        return Collections.singletonList(Accountables.namedAccountable("terms", fst));
-      }
-    }
-    
-    @Override
-    public String toString() {
-      return "MemoryTerms(terms=" + termCount + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-    }
   }
 
   @Override
@@ -1028,16 +1013,6 @@ public final class MemoryPostingsFormat extends PostingsFormat {
       }
 
       @Override
-      public Iterable<? extends Accountable> getChildResources() {
-        return Accountables.namedAccountables("field", fields);
-      }
-
-      @Override
-      public String toString() {
-        return "MemoryPostings(fields=" + fields.size() + ")";
-      }
-
-      @Override
       public void checkIntegrity() throws IOException {}
     };
   }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesReader.java lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesReader.java
index e1e08d0..67d86dd 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesReader.java
@@ -34,7 +34,6 @@ import java.nio.charset.StandardCharsets;
 import java.text.DecimalFormat;
 import java.text.DecimalFormatSymbols;
 import java.text.ParseException;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
@@ -54,7 +53,6 @@ import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.store.BufferedChecksumIndexInput;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -511,16 +509,6 @@ class SimpleTextDocValuesReader extends DocValuesProducer {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ")";
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     BytesRefBuilder scratch = new BytesRefBuilder();
     IndexInput clone = data.clone();
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
index 780c821..0ef7d3b 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java
@@ -48,7 +48,6 @@ import org.apache.lucene.store.BufferedChecksumIndexInput;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -597,20 +596,6 @@ class SimpleTextFieldsReader extends FieldsProducer {
     }
 
     @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      if (fst == null) {
-        return Collections.emptyList();
-      } else {
-        return Collections.singletonList(Accountables.namedAccountable("term cache", fst));
-      }
-    }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(terms=" + termCount + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-    }
-
-    @Override
     public TermsEnum iterator(TermsEnum reuse) throws IOException {
       if (fst != null) {
         return new SimpleTextTermsEnum(fst, fieldInfo.getIndexOptions());
@@ -702,15 +687,5 @@ class SimpleTextFieldsReader extends FieldsProducer {
   }
 
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", termsCache);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ")";
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {}
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
index 244bd19..7faf8f1 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
@@ -28,7 +28,6 @@ import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.index.SegmentWriteState;
-import org.apache.lucene.util.Accountable;
 
 /**
  * plain-text norms format.
@@ -82,19 +81,9 @@ public class SimpleTextNormsFormat extends NormsFormat {
     }
     
     @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return impl.getChildResources();
-    }
-
-    @Override
     public void checkIntegrity() throws IOException {
       impl.checkIntegrity();
     }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + impl + ")";
-    }
   }
   
   /**
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsReader.java
index 8c183c2..9a0531a 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextStoredFieldsReader.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.simpletext;
 
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.StoredFieldsReader;
 import org.apache.lucene.index.FieldInfo;
@@ -33,7 +32,6 @@ import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -215,15 +213,5 @@ public class SimpleTextStoredFieldsReader extends StoredFieldsReader {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {}
 }
diff --git lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
index d085bba..45794ee 100644
--- lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
+++ lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java
@@ -38,7 +38,6 @@ import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -553,15 +552,5 @@ public class SimpleTextTermVectorsReader extends TermVectorsReader {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {}
 }
diff --git lucene/common-build.xml lucene/common-build.xml
index 3ece977..f6e9249 100644
--- lucene/common-build.xml
+++ lucene/common-build.xml
@@ -158,13 +158,13 @@
 
   <property name="javac.deprecation" value="off"/>
   <property name="javac.debug" value="on"/>
-  <property name="javac.source" value="1.7"/>
-  <property name="javac.target" value="1.7"/>
+  <property name="javac.source" value="1.8"/>
+  <property name="javac.target" value="1.8"/>
   <property name="javac.args" value="-Xlint -Xlint:-deprecation -Xlint:-serial -Xlint:-options"/>
-  <property name="javadoc.link" value="http://download.oracle.com/javase/7/docs/api/"/>
+  <property name="javadoc.link" value="http://download.oracle.com/javase/8/docs/api/"/>
   <property name="javadoc.link.junit" value="http://junit.sourceforge.net/javadoc/"/>
   <property name="javadoc.packagelist.dir" location="${common.dir}/tools/javadoc"/>
-  <available file="${javadoc.packagelist.dir}/java7/package-list" property="javadoc.java7.packagelist.exists"/>
+  <available file="${javadoc.packagelist.dir}/java8/package-list" property="javadoc.java8.packagelist.exists"/>
   <property name="javadoc.access" value="protected"/>
   <property name="javadoc.charset" value="utf-8"/>
   <property name="javadoc.dir" location="${common.dir}/build/docs"/>
@@ -283,7 +283,7 @@
   </propertyset>
 
   <patternset id="lucene.local.src.package.patterns"
-              excludes="**/pom.xml,**/*.iml,**/*.jar,build/**,dist/**,benchmark/work/**,benchmark/temp/**,tools/javadoc/java7/**,tools/clover/**"
+              excludes="**/pom.xml,**/*.iml,**/*.jar,build/**,dist/**,benchmark/work/**,benchmark/temp/**,tools/javadoc/java8/**,tools/clover/**"
   />
 
   <!-- Default exclude sources and javadoc jars from Ivy fetch to save time and bandwidth -->
@@ -300,9 +300,9 @@
     </condition>
   </fail>
 
-  <fail message="Minimum supported Java version is 1.7.">
+  <fail message="Minimum supported Java version is 1.8.">
     <condition>
-      <not><hasmethod classname="java.lang.Throwable" method="getSuppressed"/></not>
+      <not><hasmethod classname="java.util.Arrays" method="parallelSort"/></not>
     </condition>
   </fail>
 
@@ -328,7 +328,6 @@
    -->
   <condition property="build.java.runtime" value="${-cleaned.specification.version}" else="unknown">
     <or>
-      <equals arg1="${-cleaned.specification.version}" arg2="1.7"/>
       <equals arg1="${-cleaned.specification.version}" arg2="1.8"/>
       <equals arg1="${-cleaned.specification.version}" arg2="1.9"/>
     </or>
@@ -346,10 +345,7 @@
         <contains string="${java.vm.name}" substring="openjdk" casesensitive="false"/>
         <contains string="${java.vm.name}" substring="jrockit" casesensitive="false"/>
       </or>
-      <or>
-        <equals arg1="${build.java.runtime}" arg2="1.7"/>
-        <equals arg1="${build.java.runtime}" arg2="1.8"/>
-      </or>
+      <equals arg1="${build.java.runtime}" arg2="1.8"/>
       <!-- TODO: Fix this! For now only run this on 64bit, because jTIDY OOMs with default heap size: -->
       <contains string="${os.arch}" substring="64"/>
     </and>
@@ -357,15 +353,10 @@
 
   <!-- workaround for https://issues.apache.org/bugzilla/show_bug.cgi?id=53347 -->
   <condition property="build.compiler" value="javac1.7">
-    <and>
-      <not>
-        <equals arg1="${build.java.runtime}" arg2="1.7"/>
-      </not>
-      <or>
-        <antversion exactly="1.8.3" />
-        <antversion exactly="1.8.4" />
-      </or>
-    </and>
+    <or>
+      <antversion exactly="1.8.3" />
+      <antversion exactly="1.8.4" />
+    </or>
   </condition>
 
   <target name="-documentation-lint-unsupported" unless="documentation-lint.supported">
@@ -377,12 +368,8 @@
     <echo level="warning" message="WARN: Linting documentation HTML is not supported on this Java version (${build.java.runtime}) / JVM (${java.vm.name}). NOTHING DONE!"/>
   </target>
 
-  <!-- for now disable doclint on JDK 8+: -->
-  <condition property="javadoc.args" value="-Xdoclint:none" else="">
-    <not>
-      <equals arg1="${build.java.runtime}" arg2="1.7"/>
-    </not>
-  </condition>
+  <!-- for now disable doclint: -->
+  <property name="javadoc.args" value="-Xdoclint:none"/>
 
   <!-- Import custom ANT tasks. -->
   <import file="${common.dir}/tools/custom-tasks.xml" />
@@ -915,7 +902,7 @@
             <value><!-- empty/ default encoding. --></value>
 
             <!--
-            Disabled because of Java 1.7 bug on Linux/ Unix:
+            Disabled because of Java 1.8 bug on Linux/ Unix:
             http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7181721
 
             <value>UTF-16</value>     
@@ -1875,10 +1862,7 @@ ${ant.project.name}.test.dependencies=${test.classpath.list}
   <!-- ECJ Javadoc linting: -->
   
   <condition property="ecj-javadoc-lint.supported">
-    <or>
-      <equals arg1="${build.java.runtime}" arg2="1.7"/>
-      <equals arg1="${build.java.runtime}" arg2="1.8"/>
-    </or>
+    <equals arg1="${build.java.runtime}" arg2="1.8"/>
   </condition>
 
   <condition property="ecj-javadoc-lint-tests.supported">
@@ -1974,7 +1958,7 @@ ${ant.project.name}.test.dependencies=${test.classpath.list}
     <attribute name="overview" default="${src.dir}/overview.html"/>
     <attribute name="linksource" default="no"/>
     <sequential>
-      <antcall target="download-java7-javadoc-packagelist"/>
+      <antcall target="download-java8-javadoc-packagelist"/>
       <delete file="@{destdir}/stylesheet.css" failonerror="false"/>
       <copy todir="@{destdir}" file="${prettify.dir}/prettify.js" overwrite="false" />
       <record name="@{destdir}/log_javadoc.txt" action="start" append="no"/>
@@ -2004,7 +1988,7 @@ ${ant.project.name}.test.dependencies=${test.classpath.list}
         <tag name="lucene.internal"
         description="NOTE: This API is for internal purposes only and might change in incompatible ways in the next release."/>
       	<link offline="true" packagelistLoc="${javadoc.dir}"/>
-        <link offline="true" href="${javadoc.link}" packagelistLoc="${javadoc.packagelist.dir}/java7"/>
+        <link offline="true" href="${javadoc.link}" packagelistLoc="${javadoc.packagelist.dir}/java8"/>
         <bottom><![CDATA[
           <i>Copyright &copy; ${year} Apache Software Foundation.  All Rights Reserved.</i>
           <script src='{@docRoot}/prettify.js' type='text/javascript'></script>
@@ -2144,10 +2128,10 @@ ${ant.project.name}.test.dependencies=${test.classpath.list}
     </sequential>
   </macrodef>
 
-  <target name="download-java7-javadoc-packagelist" unless="javadoc.java7.packagelist.exists">
-    <mkdir dir="${javadoc.packagelist.dir}/java7"/>
+  <target name="download-java8-javadoc-packagelist" unless="javadoc.java8.packagelist.exists">
+    <mkdir dir="${javadoc.packagelist.dir}/java8"/>
     <get src="${javadoc.link}/package-list"
-         dest="${javadoc.packagelist.dir}/java7/package-list" ignoreerrors="true"/>
+         dest="${javadoc.packagelist.dir}/java8/package-list" ignoreerrors="true"/>
   </target>
 
   <!-- VALIDATION work -->
diff --git lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java
index 5fe3118..d475e6e 100644
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java
@@ -18,10 +18,8 @@ package org.apache.lucene.codecs.blocktree;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -37,8 +35,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 
@@ -297,19 +293,11 @@ public final class BlockTreeTermsReader extends FieldsProducer {
 
   @Override
   public long ramBytesUsed() {
-    long sizeInBytes = postingsReader.ramBytesUsed();
+    long sizeInByes = ((postingsReader!=null) ? postingsReader.ramBytesUsed() : 0);
     for(FieldReader reader : fields.values()) {
-      sizeInBytes += reader.ramBytesUsed();
+      sizeInByes += reader.ramBytesUsed();
     }
-    return sizeInBytes;
-  }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("field", fields));
-    resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    return Collections.unmodifiableList(resources);
+    return sizeInByes;
   }
 
   @Override
@@ -322,9 +310,4 @@ public final class BlockTreeTermsReader extends FieldsProducer {
       postingsReader.checkIntegrity();
     }
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",delegate=" + postingsReader + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
index 37f8873..c274f64 100644
--- lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/blocktree/FieldReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.codecs.blocktree;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
@@ -27,7 +26,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.automaton.CompiledAutomaton;
@@ -182,18 +180,4 @@ public final class FieldReader extends Terms implements Accountable {
   public long ramBytesUsed() {
     return BASE_RAM_BYTES_USED + ((index!=null)? index.ramBytesUsed() : 0);
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (index == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singleton(Accountables.namedAccountable("term index", index));
-    }
-  }
-
-  @Override
-  public String toString() {
-    return "BlockTreeTerms(terms=" + numTerms + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexReader.java lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexReader.java
index f9686b5..2979426 100644
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexReader.java
@@ -20,16 +20,12 @@ package org.apache.lucene.codecs.compressing;
 import static org.apache.lucene.util.BitUtil.zigZagDecode;
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collections;
-import java.util.List;
 
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.packed.PackedInts;
@@ -188,27 +184,4 @@ public final class CompressingStoredFieldsIndexReader implements Cloneable, Acco
     return res;
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    
-    long docBaseDeltaBytes = RamUsageEstimator.shallowSizeOf(docBasesDeltas);
-    for (PackedInts.Reader r : docBasesDeltas) {
-      docBaseDeltaBytes += r.ramBytesUsed();
-    }
-    resources.add(Accountables.namedAccountable("doc base deltas", docBaseDeltaBytes));
-    
-    long startPointerDeltaBytes = RamUsageEstimator.shallowSizeOf(startPointersDeltas);
-    for (PackedInts.Reader r : startPointersDeltas) {
-      startPointerDeltaBytes += r.ramBytesUsed();
-    }
-    resources.add(Accountables.namedAccountable("start pointer deltas", startPointerDeltaBytes));
-    
-    return resources;
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(blocks=" + docBases.length + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
index 7d1272a..eaeebf9 100644
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
@@ -38,7 +38,6 @@ import java.io.EOFException;
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.codecs.StoredFieldsReader;
@@ -56,8 +55,6 @@ import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -531,11 +528,6 @@ public final class CompressingStoredFieldsReader extends StoredFieldsReader {
   public long ramBytesUsed() {
     return indexReader.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.singleton(Accountables.namedAccountable("stored field index", indexReader));
-  }
 
   @Override
   public void checkIntegrity() throws IOException {
@@ -544,8 +536,4 @@ public final class CompressingStoredFieldsReader extends StoredFieldsReader {
     }
   }
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(mode=" + compressionMode + ",chunksize=" + chunkSize + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
index 9cac92b..5bfc04a 100644
--- lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader.java
@@ -32,7 +32,6 @@ import static org.apache.lucene.codecs.compressing.CompressingTermVectorsWriter.
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.Collections;
 import java.util.Iterator;
 import java.util.NoSuchElementException;
 
@@ -54,8 +53,6 @@ import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -1072,19 +1069,10 @@ public final class CompressingTermVectorsReader extends TermVectorsReader implem
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.singleton(Accountables.namedAccountable("term vector index", indexReader));
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     if (version >= VERSION_CHECKSUM) {
       CodecUtil.checksumEntireFile(vectorsStream);
     }
   }
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(mode=" + compressionMode + ",chunksize=" + chunkSize + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsReader.java lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsReader.java
index 26cb34b..68881e8 100644
--- lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsReader.java
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsReader.java
@@ -24,7 +24,6 @@ import static org.apache.lucene.codecs.lucene41.Lucene41PostingsWriter.IntBlockT
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.BlockTermState;
 import org.apache.lucene.codecs.CodecUtil;
@@ -40,7 +39,6 @@ import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
@@ -1582,11 +1580,6 @@ public final class Lucene41PostingsReader extends PostingsReaderBase {
   public long ramBytesUsed() {
     return BASE_RAM_BYTES_USED;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {
@@ -1602,9 +1595,4 @@ public final class Lucene41PostingsReader extends PostingsReaderBase {
       }
     }
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(positions=" + (posIn != null) + ",payloads=" + (payIn != null) +")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer.java lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer.java
index 912e087..3c7eeda 100644
--- lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer.java
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesProducer.java
@@ -36,10 +36,7 @@ import static org.apache.lucene.codecs.lucene410.Lucene410DocValuesConsumer.BLOC
 
 import java.io.Closeable; // javadocs
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -63,8 +60,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.RandomAccessInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -76,22 +71,21 @@ import org.apache.lucene.util.packed.MonotonicBlockPackedReader;
 
 /** reader for {@link Lucene410DocValuesFormat} */
 class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable {
-  private final Map<String,NumericEntry> numerics;
-  private final Map<String,BinaryEntry> binaries;
-  private final Map<String,SortedSetEntry> sortedSets;
-  private final Map<String,SortedSetEntry> sortedNumerics;
-  private final Map<String,NumericEntry> ords;
-  private final Map<String,NumericEntry> ordIndexes;
-  private final int numFields;
+  private final Map<Integer,NumericEntry> numerics;
+  private final Map<Integer,BinaryEntry> binaries;
+  private final Map<Integer,SortedSetEntry> sortedSets;
+  private final Map<Integer,SortedSetEntry> sortedNumerics;
+  private final Map<Integer,NumericEntry> ords;
+  private final Map<Integer,NumericEntry> ordIndexes;
   private final AtomicLong ramBytesUsed;
   private final IndexInput data;
   private final int maxDoc;
   private final int version;
 
   // memory-resident structures
-  private final Map<String,MonotonicBlockPackedReader> addressInstances = new HashMap<>();
-  private final Map<String,MonotonicBlockPackedReader> ordIndexInstances = new HashMap<>();
-  private final Map<String,ReverseTermsIndex> reverseIndexInstances = new HashMap<>();
+  private final Map<Integer,MonotonicBlockPackedReader> addressInstances = new HashMap<>();
+  private final Map<Integer,MonotonicBlockPackedReader> ordIndexInstances = new HashMap<>();
+  private final Map<Integer,ReverseTermsIndex> reverseIndexInstances = new HashMap<>();
   
   /** expert: instantiates a new reader */
   Lucene410DocValuesProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
@@ -110,7 +104,7 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
       binaries = new HashMap<>();
       sortedSets = new HashMap<>();
       sortedNumerics = new HashMap<>();
-      numFields = readFields(in, state.fieldInfos);
+      readFields(in, state.fieldInfos);
 
       CodecUtil.checkFooter(in);
       success = true;
@@ -149,110 +143,108 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
     ramBytesUsed = new AtomicLong(RamUsageEstimator.shallowSizeOfInstance(getClass()));
   }
 
-  private void readSortedField(FieldInfo info, IndexInput meta) throws IOException {
+  private void readSortedField(int fieldNumber, IndexInput meta, FieldInfos infos) throws IOException {
     // sorted = binary + numeric
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene410DocValuesFormat.BINARY) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     BinaryEntry b = readBinaryEntry(meta);
-    binaries.put(info.name, b);
+    binaries.put(fieldNumber, b);
     
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene410DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sorted entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sorted entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n = readNumericEntry(meta);
-    ords.put(info.name, n);
+    ords.put(fieldNumber, n);
   }
 
-  private void readSortedSetFieldWithAddresses(FieldInfo info, IndexInput meta) throws IOException {
+  private void readSortedSetFieldWithAddresses(int fieldNumber, IndexInput meta, FieldInfos infos) throws IOException {
     // sortedset = binary + numeric (addresses) + ordIndex
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene410DocValuesFormat.BINARY) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     BinaryEntry b = readBinaryEntry(meta);
-    binaries.put(info.name, b);
+    binaries.put(fieldNumber, b);
 
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene410DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n1 = readNumericEntry(meta);
-    ords.put(info.name, n1);
+    ords.put(fieldNumber, n1);
 
-    if (meta.readVInt() != info.number) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+    if (meta.readVInt() != fieldNumber) {
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     if (meta.readByte() != Lucene410DocValuesFormat.NUMERIC) {
-      throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+      throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
     }
     NumericEntry n2 = readNumericEntry(meta);
-    ordIndexes.put(info.name, n2);
+    ordIndexes.put(fieldNumber, n2);
   }
 
-  private int readFields(IndexInput meta, FieldInfos infos) throws IOException {
-    int numFields = 0;
+  private void readFields(IndexInput meta, FieldInfos infos) throws IOException {
     int fieldNumber = meta.readVInt();
     while (fieldNumber != -1) {
-      numFields++;
-      FieldInfo info = infos.fieldInfo(fieldNumber);
-      if (info == null) {
-        // trickier to validate more: because we use multiple entries for "composite" types like sortedset, etc.
+      if (infos.fieldInfo(fieldNumber) == null) {
+        // trickier to validate more: because we re-use for norms, because we use multiple entries
+        // for "composite" types like sortedset, etc.
         throw new CorruptIndexException("Invalid field number: " + fieldNumber + " (resource=" + meta + ")");
       }
       byte type = meta.readByte();
       if (type == Lucene410DocValuesFormat.NUMERIC) {
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
       } else if (type == Lucene410DocValuesFormat.BINARY) {
         BinaryEntry b = readBinaryEntry(meta);
-        binaries.put(info.name, b);
+        binaries.put(fieldNumber, b);
       } else if (type == Lucene410DocValuesFormat.SORTED) {
-        readSortedField(info, meta);
+        readSortedField(fieldNumber, meta, infos);
       } else if (type == Lucene410DocValuesFormat.SORTED_SET) {
         SortedSetEntry ss = readSortedSetEntry(meta);
-        sortedSets.put(info.name, ss);
+        sortedSets.put(fieldNumber, ss);
         if (ss.format == SORTED_WITH_ADDRESSES) {
-          readSortedSetFieldWithAddresses(info, meta);
+          readSortedSetFieldWithAddresses(fieldNumber, meta, infos);
         } else if (ss.format == SORTED_SINGLE_VALUED) {
           if (meta.readVInt() != fieldNumber) {
-            throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           if (meta.readByte() != Lucene410DocValuesFormat.SORTED) {
-            throw new CorruptIndexException("sortedset entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortedset entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
-          readSortedField(info, meta);
+          readSortedField(fieldNumber, meta, infos);
         } else {
           throw new AssertionError();
         }
       } else if (type == Lucene410DocValuesFormat.SORTED_NUMERIC) {
         SortedSetEntry ss = readSortedSetEntry(meta);
-        sortedNumerics.put(info.name, ss);
+        sortedNumerics.put(fieldNumber, ss);
         if (meta.readVInt() != fieldNumber) {
-          throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+          throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
         }
         if (meta.readByte() != Lucene410DocValuesFormat.NUMERIC) {
-          throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+          throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
         }
-        numerics.put(info.name, readNumericEntry(meta));
+        numerics.put(fieldNumber, readNumericEntry(meta));
         if (ss.format == SORTED_WITH_ADDRESSES) {
           if (meta.readVInt() != fieldNumber) {
-            throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           if (meta.readByte() != Lucene410DocValuesFormat.NUMERIC) {
-            throw new CorruptIndexException("sortednumeric entry for field: " + info.name + " is corrupt (resource=" + meta + ")");
+            throw new CorruptIndexException("sortednumeric entry for field: " + fieldNumber + " is corrupt (resource=" + meta + ")");
           }
           NumericEntry ordIndex = readNumericEntry(meta);
-          ordIndexes.put(info.name, ordIndex);
+          ordIndexes.put(fieldNumber, ordIndex);
         } else if (ss.format != SORTED_SINGLE_VALUED) {
           throw new AssertionError();
         }
@@ -261,7 +253,6 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
       }
       fieldNumber = meta.readVInt();
     }
-    return numFields;
   }
   
   static NumericEntry readNumericEntry(IndexInput meta) throws IOException {
@@ -341,7 +332,7 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
 
   @Override
   public NumericDocValues getNumeric(FieldInfo field) throws IOException {
-    NumericEntry entry = numerics.get(field.name);
+    NumericEntry entry = numerics.get(field.number);
     return getNumeric(entry);
   }
   
@@ -351,24 +342,10 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("addresses field", addressInstances));
-    resources.addAll(Accountables.namedAccountables("ord index field", ordIndexInstances));
-    resources.addAll(Accountables.namedAccountables("reverse index field", reverseIndexInstances));
-    return Collections.unmodifiableList(resources);
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     CodecUtil.checksumEntireFile(data);
   }
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + numFields + ")";
-  }
-
   LongValues getNumeric(NumericEntry entry) throws IOException {
     RandomAccessInput slice = this.data.randomAccessSlice(entry.offset, entry.endOffset - entry.offset);
     switch (entry.format) {
@@ -407,7 +384,7 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
 
   @Override
   public BinaryDocValues getBinary(FieldInfo field) throws IOException {
-    BinaryEntry bytes = binaries.get(field.name);
+    BinaryEntry bytes = binaries.get(field.number);
     switch(bytes.format) {
       case BINARY_FIXED_UNCOMPRESSED:
         return getFixedBinary(field, bytes);
@@ -443,11 +420,11 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   
   /** returns an address instance for variable-length binary values. */
   private synchronized MonotonicBlockPackedReader getAddressInstance(FieldInfo field, BinaryEntry bytes) throws IOException {
-    MonotonicBlockPackedReader addresses = addressInstances.get(field.name);
+    MonotonicBlockPackedReader addresses = addressInstances.get(field.number);
     if (addresses == null) {
       data.seek(bytes.addressesOffset);
       addresses = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, bytes.count+1, false);
-      addressInstances.put(field.name, addresses);
+      addressInstances.put(field.number, addresses);
       ramBytesUsed.addAndGet(addresses.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
     }
     return addresses;
@@ -480,12 +457,12 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   
   /** returns an address instance for prefix-compressed binary values. */
   private synchronized MonotonicBlockPackedReader getIntervalInstance(FieldInfo field, BinaryEntry bytes) throws IOException {
-    MonotonicBlockPackedReader addresses = addressInstances.get(field.name);
+    MonotonicBlockPackedReader addresses = addressInstances.get(field.number);
     if (addresses == null) {
       data.seek(bytes.addressesOffset);
       final long size = (bytes.count + INTERVAL_MASK) >>> INTERVAL_SHIFT;
       addresses = MonotonicBlockPackedReader.of(data, bytes.packedIntsVersion, bytes.blockSize, size, false);
-      addressInstances.put(field.name, addresses);
+      addressInstances.put(field.number, addresses);
       ramBytesUsed.addAndGet(addresses.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
     }
     return addresses;
@@ -493,7 +470,7 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   
   /** returns a reverse lookup instance for prefix-compressed binary values. */
   private synchronized ReverseTermsIndex getReverseIndexInstance(FieldInfo field, BinaryEntry bytes) throws IOException {
-    ReverseTermsIndex index = reverseIndexInstances.get(field.name);
+    ReverseTermsIndex index = reverseIndexInstances.get(field.number);
     if (index == null) {
       index = new ReverseTermsIndex();
       data.seek(bytes.reverseIndexOffset);
@@ -503,8 +480,8 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
       PagedBytes pagedBytes = new PagedBytes(15);
       pagedBytes.copy(data, dataSize);
       index.terms = pagedBytes.freeze(true);
-      reverseIndexInstances.put(field.name, index);
-      ramBytesUsed.addAndGet(index.ramBytesUsed());
+      reverseIndexInstances.put(field.number, index);
+      ramBytesUsed.addAndGet(index.termAddresses.ramBytesUsed() + index.terms.ramBytesUsed());
     }
     return index;
   }
@@ -519,9 +496,9 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
 
   @Override
   public SortedDocValues getSorted(FieldInfo field) throws IOException {
-    final int valueCount = (int) binaries.get(field.name).count;
+    final int valueCount = (int) binaries.get(field.number).count;
     final BinaryDocValues binary = getBinary(field);
-    NumericEntry entry = ords.get(field.name);
+    NumericEntry entry = ords.get(field.number);
     final LongValues ordinals = getNumeric(entry);
     return new SortedDocValues() {
 
@@ -562,11 +539,11 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   
   /** returns an address instance for sortedset ordinal lists */
   private synchronized MonotonicBlockPackedReader getOrdIndexInstance(FieldInfo field, NumericEntry entry) throws IOException {
-    MonotonicBlockPackedReader instance = ordIndexInstances.get(field.name);
+    MonotonicBlockPackedReader instance = ordIndexInstances.get(field.number);
     if (instance == null) {
       data.seek(entry.offset);
       instance = MonotonicBlockPackedReader.of(data, entry.packedIntsVersion, entry.blockSize, entry.count+1, false);
-      ordIndexInstances.put(field.name, instance);
+      ordIndexInstances.put(field.number, instance);
       ramBytesUsed.addAndGet(instance.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_INT);
     }
     return instance;
@@ -574,14 +551,14 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   
   @Override
   public SortedNumericDocValues getSortedNumeric(FieldInfo field) throws IOException {
-    SortedSetEntry ss = sortedNumerics.get(field.name);
-    NumericEntry numericEntry = numerics.get(field.name);
+    SortedSetEntry ss = sortedNumerics.get(field.number);
+    NumericEntry numericEntry = numerics.get(field.number);
     final LongValues values = getNumeric(numericEntry);
     if (ss.format == SORTED_SINGLE_VALUED) {
       final Bits docsWithField = getMissingBits(numericEntry.missingOffset);
       return DocValues.singleton(values, docsWithField);
     } else if (ss.format == SORTED_WITH_ADDRESSES) {
-      final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));
+      final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.number));
       
       return new SortedNumericDocValues() {
         long startOffset;
@@ -610,7 +587,7 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
 
   @Override
   public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {
-    SortedSetEntry ss = sortedSets.get(field.name);
+    SortedSetEntry ss = sortedSets.get(field.number);
     if (ss.format == SORTED_SINGLE_VALUED) {
       final SortedDocValues values = getSorted(field);
       return DocValues.singleton(values);
@@ -618,12 +595,12 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
       throw new AssertionError();
     }
 
-    final long valueCount = binaries.get(field.name).count;
+    final long valueCount = binaries.get(field.number).count;
     // we keep the byte[]s and list of ords on disk, these could be large
     final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);
-    final LongValues ordinals = getNumeric(ords.get(field.name));
+    final LongValues ordinals = getNumeric(ords.get(field.number));
     // but the addresses to the ord stream are in RAM
-    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.name));
+    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(field, ordIndexes.get(field.number));
     
     return new RandomAccessOrds() {
       long startOffset;
@@ -721,10 +698,10 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
       case SORTED:
         return DocValues.docsWithValue(getSorted(field), maxDoc);
       case BINARY:
-        BinaryEntry be = binaries.get(field.name);
+        BinaryEntry be = binaries.get(field.number);
         return getMissingBits(be.missingOffset);
       case NUMERIC:
-        NumericEntry ne = numerics.get(field.name);
+        NumericEntry ne = numerics.get(field.number);
         return getMissingBits(ne.missingOffset);
       default:
         throw new AssertionError();
@@ -801,27 +778,9 @@ class Lucene410DocValuesProducer extends DocValuesProducer implements Closeable
   }
   
   // used for reverse lookup to a small range of blocks
-  static class ReverseTermsIndex implements Accountable {
+  static class ReverseTermsIndex {
     public MonotonicBlockPackedReader termAddresses;
     public PagedBytes.Reader terms;
-    
-    @Override
-    public long ramBytesUsed() {
-      return termAddresses.ramBytesUsed() + terms.ramBytesUsed();
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      resources.add(Accountables.namedAccountable("term bytes", terms));
-      resources.add(Accountables.namedAccountable("term addresses", termAddresses));
-      return Collections.unmodifiableList(resources);
-    }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(size=" + termAddresses.size() + ")";
-    }
   }
   
   //in the compressed case, we add a few additional operations for
diff --git lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49NormsProducer.java lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49NormsProducer.java
index e1ea7f0..76d7177 100644
--- lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49NormsProducer.java
+++ lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49NormsProducer.java
@@ -20,7 +20,6 @@ package org.apache.lucene.codecs.lucene49;
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -33,8 +32,6 @@ import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.store.ChecksumIndexInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.packed.BlockPackedReader;
@@ -52,17 +49,15 @@ import static org.apache.lucene.codecs.lucene49.Lucene49NormsConsumer.UNCOMPRESS
  */
 class Lucene49NormsProducer extends NormsProducer {
   // metadata maps (just file pointers and minimal stuff)
-  private final Map<String,NormsEntry> norms = new HashMap<>();
+  private final Map<Integer,NormsEntry> norms = new HashMap<>();
   private final IndexInput data;
   private final int version;
   
   // ram instances we have already loaded
-  final Map<String,NumericDocValues> instances = new HashMap<>();
-  final Map<String,Accountable> instancesInfo = new HashMap<>();
+  final Map<Integer,NumericDocValues> instances = new HashMap<>();
   
   private final int maxDoc;
   private final AtomicLong ramBytesUsed;
-  private final AtomicInteger activeCount = new AtomicInteger();
     
   Lucene49NormsProducer(SegmentReadState state, String dataCodec, String dataExtension, String metaCodec, String metaExtension) throws IOException {
     maxDoc = state.segmentInfo.getDocCount();
@@ -128,18 +123,17 @@ class Lucene49NormsProducer extends NormsProducer {
         default:
           throw new CorruptIndexException("Unknown format: " + entry.format + ", input=" + meta);
       }
-      norms.put(info.name, entry);
+      norms.put(fieldNumber, entry);
       fieldNumber = meta.readVInt();
     }
   }
 
   @Override
   public synchronized NumericDocValues getNorms(FieldInfo field) throws IOException {
-    NumericDocValues instance = instances.get(field.name);
+    NumericDocValues instance = instances.get(field.number);
     if (instance == null) {
       instance = loadNorms(field);
-      instances.put(field.name, instance);
-      activeCount.incrementAndGet();
+      instances.put(field.number, instance);
     }
     return instance;
   }
@@ -150,21 +144,14 @@ class Lucene49NormsProducer extends NormsProducer {
   }
   
   @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", instancesInfo);
-  }
-  
-  @Override
   public void checkIntegrity() throws IOException {
     CodecUtil.checksumEntireFile(data);
   }
 
   private NumericDocValues loadNorms(FieldInfo field) throws IOException {
-    NormsEntry entry = norms.get(field.name);
+    NormsEntry entry = norms.get(field.number);
     switch(entry.format) {
       case CONST_COMPRESSED:
-        instancesInfo.put(field.name, Accountables.namedAccountable("constant", 8));
-        ramBytesUsed.addAndGet(8);
         final long v = entry.offset;
         return new NumericDocValues() {
           @Override
@@ -177,7 +164,6 @@ class Lucene49NormsProducer extends NormsProducer {
         final byte bytes[] = new byte[maxDoc];
         data.readBytes(bytes, 0, bytes.length);
         ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(bytes));
-        instancesInfo.put(field.name, Accountables.namedAccountable("byte array", maxDoc));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -190,7 +176,6 @@ class Lucene49NormsProducer extends NormsProducer {
         int blockSize = data.readVInt();
         final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, maxDoc, false);
         ramBytesUsed.addAndGet(reader.ramBytesUsed());
-        instancesInfo.put(field.name, Accountables.namedAccountable("delta compressed", reader));
         return reader;
       case TABLE_COMPRESSED:
         data.seek(entry.offset);
@@ -207,7 +192,6 @@ class Lucene49NormsProducer extends NormsProducer {
         final int bitsPerValue = data.readVInt();
         final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedVersion, maxDoc, bitsPerValue);
         ramBytesUsed.addAndGet(RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed());
-        instancesInfo.put(field.name, Accountables.namedAccountable("table compressed", ordsReader));
         return new NumericDocValues() {
           @Override
           public long get(int docID) {
@@ -228,9 +212,4 @@ class Lucene49NormsProducer extends NormsProducer {
     byte format;
     long offset;
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + norms.size() + ",active=" + activeCount.get() + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
index 578f717..60a6211 100644
--- lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
+++ lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldDocValuesFormat.java
@@ -19,7 +19,6 @@ package org.apache.lucene.codecs.perfield;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.IdentityHashMap;
 import java.util.Map;
@@ -38,8 +37,6 @@ import org.apache.lucene.index.SegmentWriteState;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
@@ -325,11 +322,6 @@ public abstract class PerFieldDocValuesFormat extends DocValuesFormat {
       }
       return size;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Accountables.namedAccountables("format", formats);
-    }
 
     @Override
     public void checkIntegrity() throws IOException {
@@ -337,11 +329,6 @@ public abstract class PerFieldDocValuesFormat extends DocValuesFormat {
         format.checkIntegrity();
       }
     }
-    
-    @Override
-    public String toString() {
-      return "PerFieldDocValues(formats=" + formats.size() + ")";
-    }
   }
 
   @Override
diff --git lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
index 0980eef..f6eae11 100644
--- lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
+++ lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldPostingsFormat.java
@@ -38,8 +38,6 @@ import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.index.SegmentWriteState;
 import org.apache.lucene.index.Terms;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -270,11 +268,6 @@ public abstract class PerFieldPostingsFormat extends PostingsFormat {
       }
       return ramBytesUsed;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Accountables.namedAccountables("format", formats);
-    }
 
     @Override
     public void checkIntegrity() throws IOException {
@@ -282,11 +275,6 @@ public abstract class PerFieldPostingsFormat extends PostingsFormat {
         producer.checkIntegrity();
       }
     }
-
-    @Override
-    public String toString() {
-      return "PerFieldPostings(formats=" + formats.size() + ")";
-    }
   }
 
   @Override
diff --git lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
index 10aaf73..1e649fa 100644
--- lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
+++ lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream.java
@@ -116,11 +116,6 @@ class BufferedUpdatesStream implements Accountable {
   public long ramBytesUsed() {
     return bytesUsed.get();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   public static class ApplyDeletesResult {
     
diff --git lucene/core/src/java/org/apache/lucene/index/CheckIndex.java lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
index 52178f7..cf2f080 100644
--- lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
+++ lucene/core/src/java/org/apache/lucene/index/CheckIndex.java
@@ -39,7 +39,6 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -533,7 +532,7 @@ public class CheckIndex {
 
       int toLoseDocCount = info.info.getDocCount();
 
-      SegmentReader reader = null;
+      AtomicReader reader = null;
 
       try {
         msg(infoStream, "    version=" + (version == null ? "3.0" : version));
@@ -661,11 +660,6 @@ public class CheckIndex {
         }
 
         msg(infoStream, "");
-        
-        if (verbose) {
-          msg(infoStream, "detailed segment RAM usage: ");
-          msg(infoStream, Accountables.toString(reader));
-        }
 
       } catch (Throwable t) {
         if (failFast) {
diff --git lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java
index 630a3b6..c79d693 100644
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java
@@ -20,7 +20,6 @@ package org.apache.lucene.index;
 import java.io.Closeable;
 import java.io.IOException;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.HashSet;
 import java.util.Queue;
 import java.util.Set;
@@ -670,11 +669,6 @@ final class DocumentsWriter implements Closeable, Accountable {
   public long ramBytesUsed() {
     return flushControl.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   static final class ApplyDeletesEvent implements Event {
     static final Event INSTANCE = new ApplyDeletesEvent();
diff --git lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
index 040b03b..d1c05a2 100644
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterDeleteQueue.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;
 import java.util.concurrent.locks.ReentrantLock;
 
@@ -457,11 +456,6 @@ final class DocumentsWriterDeleteQueue implements Accountable {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
-  @Override
   public String toString() {
     return "DWDQ: [ generation: " + generation + " ]";
   }
diff --git lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java
index 35d2232..2db5078 100644
--- lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java
+++ lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.IdentityHashMap;
 import java.util.Iterator;
 import java.util.LinkedList;
@@ -438,12 +437,6 @@ final class DocumentsWriterFlushControl implements Accountable {
     return getDeleteBytesUsed() + netBytes();
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    // TODO: improve this?
-    return Collections.emptyList();
-  }
-
   synchronized int numFlushingDWPT() {
     return flushingWriters.size();
   }
diff --git lucene/core/src/java/org/apache/lucene/index/IndexWriter.java lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index f3da83d..1538945 100644
--- lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -463,11 +463,6 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
     ensureOpen();
     return docWriter.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   /** Holds shared SegmentReader instances. IndexWriter uses
    *  SegmentReaders for 1) applying deletes, 2) doing
diff --git lucene/core/src/java/org/apache/lucene/index/MultiDocValues.java lucene/core/src/java/org/apache/lucene/index/MultiDocValues.java
index afc460a..8be1f1c 100644
--- lucene/core/src/java/org/apache/lucene/index/MultiDocValues.java
+++ lucene/core/src/java/org/apache/lucene/index/MultiDocValues.java
@@ -18,15 +18,12 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.index.MultiTermsEnum.TermsEnumIndex;
 import org.apache.lucene.index.MultiTermsEnum.TermsEnumWithSlice;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.InPlaceMergeSorter;
@@ -432,10 +429,6 @@ public class MultiDocValues {
         return BASE_RAM_BYTES_USED + RamUsageEstimator.sizeOf(newToOld) + RamUsageEstimator.sizeOf(oldToNew);
       }
 
-      @Override
-      public Iterable<? extends Accountable> getChildResources() {
-        return Collections.emptyList();
-      }
     }
 
     /**
@@ -641,16 +634,6 @@ public class MultiDocValues {
     public long ramBytesUsed() {
       return ramBytesUsed;
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      resources.add(Accountables.namedAccountable("global ord deltas", globalOrdDeltas));
-      resources.add(Accountables.namedAccountable("first segments", firstSegments));
-      resources.add(Accountables.namedAccountable("segment map", segmentMap));
-      // TODO: would be nice to return actual child segment deltas too, but the optimizations are confusing
-      return resources;
-    }
   }
   
   /** 
diff --git lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java
index 68b7101..1740333 100644
--- lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java
+++ lucene/core/src/java/org/apache/lucene/index/PrefixCodedTerms.java
@@ -18,7 +18,6 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 import java.util.Iterator;
 
 import org.apache.lucene.store.IndexInput;
@@ -45,11 +44,6 @@ class PrefixCodedTerms implements Iterable<Term>, Accountable {
     return buffer.ramBytesUsed();
   }
   
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
   /** @return iterator over the bytes */
   @Override
   public Iterator<Term> iterator() {
diff --git lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
index d971af2..4e372df 100644
--- lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
+++ lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders.java
@@ -215,7 +215,6 @@ final class SegmentCoreReaders implements Accountable {
     coreClosedListeners.remove(listener);
   }
 
-  // TODO: remove this, it can just be on SR
   @Override
   public long ramBytesUsed() {
     return BASE_RAM_BYTES_USED +
@@ -224,9 +223,4 @@ final class SegmentCoreReaders implements Accountable {
         ((fieldsReaderOrig!=null)? fieldsReaderOrig.ramBytesUsed() : 0) + 
         ((termVectorsReaderOrig!=null) ? termVectorsReaderOrig.ramBytesUsed() : 0);
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/index/SegmentDocValuesProducer.java lucene/core/src/java/org/apache/lucene/index/SegmentDocValuesProducer.java
index 420ea44..dc99a04 100644
--- lucene/core/src/java/org/apache/lucene/index/SegmentDocValuesProducer.java
+++ lucene/core/src/java/org/apache/lucene/index/SegmentDocValuesProducer.java
@@ -30,8 +30,6 @@ import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.codecs.DocValuesProducer;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.Version;
@@ -187,19 +185,5 @@ class SegmentDocValuesProducer extends DocValuesProducer {
       ramBytesUsed += producer.ramBytesUsed();
     }
     return ramBytesUsed;
-  }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    for (Accountable producer : dvProducers) {
-      resources.add(Accountables.namedAccountable("delegate", producer));
-    }
-    return Collections.unmodifiableList(resources);
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(producers=" + dvProducers.size() + ")";
-  }
+  }  
 }
diff --git lucene/core/src/java/org/apache/lucene/index/SegmentReader.java lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
index 1a836de..1b9b4d5 100644
--- lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
+++ lucene/core/src/java/org/apache/lucene/index/SegmentReader.java
@@ -18,17 +18,14 @@ package org.apache.lucene.index;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.codecs.DocValuesProducer;
 import org.apache.lucene.codecs.FieldInfosFormat;
-import org.apache.lucene.codecs.FieldsProducer;
 import org.apache.lucene.codecs.NormsProducer;
 import org.apache.lucene.codecs.StoredFieldsReader;
 import org.apache.lucene.codecs.TermVectorsReader;
@@ -37,7 +34,6 @@ import org.apache.lucene.store.CompoundFileDirectory;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.CloseableThreadLocal;
 import org.apache.lucene.util.IOUtils;
@@ -262,7 +258,7 @@ public final class SegmentReader extends AtomicReader implements Accountable {
   }
 
   @Override
-  public FieldsProducer fields() {
+  public Fields fields() {
     ensureOpen();
     return core.fields;
   }
@@ -542,28 +538,6 @@ public final class SegmentReader extends AtomicReader implements Accountable {
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    ensureOpen();
-    List<Accountable> resources = new ArrayList<>();
-    if (core.fields != null) {
-      resources.add(Accountables.namedAccountable("postings", core.fields));
-    }
-    if (core.normsProducer != null) {
-      resources.add(Accountables.namedAccountable("norms", core.normsProducer));
-    }
-    if (docValuesProducer != null) {
-      resources.add(Accountables.namedAccountable("docvalues", docValuesProducer));
-    }
-    if (getFieldsReader() != null) {
-      resources.add(Accountables.namedAccountable("stored fields", getFieldsReader()));
-    }
-    if (getTermVectorsReader() != null) {
-      resources.add(Accountables.namedAccountable("term vectors", getTermVectorsReader()));
-    }
-    return resources;
-  }
-
-  @Override
   public void checkIntegrity() throws IOException {
     ensureOpen();
     
diff --git lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter.java lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter.java
index 941ee83..01fc553 100644
--- lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter.java
+++ lucene/core/src/java/org/apache/lucene/search/CachingWrapperFilter.java
@@ -29,7 +29,6 @@ import java.util.WeakHashMap;
 import org.apache.lucene.index.AtomicReader;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.WAH8DocIdSet;
 
@@ -148,10 +147,4 @@ public class CachingWrapperFilter extends Filter implements Accountable {
 
     return total;
   }
-
-  @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    // Sync only to pull the current set of values:
-    return Accountables.namedAccountables("segment", cache);
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/search/DocIdSet.java lucene/core/src/java/org/apache/lucene/search/DocIdSet.java
index 14c3799..9120bfb 100644
--- lucene/core/src/java/org/apache/lucene/search/DocIdSet.java
+++ lucene/core/src/java/org/apache/lucene/search/DocIdSet.java
@@ -18,7 +18,6 @@ package org.apache.lucene.search;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
@@ -94,8 +93,4 @@ public abstract class DocIdSet implements Accountable {
     return false;
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
index b0a0142..cfe138b 100644
--- lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
+++ lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
@@ -19,7 +19,6 @@ package org.apache.lucene.search;
 
 import java.io.IOException;
 
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -63,11 +62,6 @@ public abstract class FilteredDocIdSet extends DocIdSet {
   public long ramBytesUsed() {
     return RamUsageEstimator.NUM_BYTES_OBJECT_REF + _innerSet.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return _innerSet.getChildResources();
-  }
 
   @Override
   public Bits bits() throws IOException {
diff --git lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
index 849732a..6dba544 100644
--- lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
+++ lucene/core/src/java/org/apache/lucene/search/spans/SpanMultiTermQueryWrapper.java
@@ -110,7 +110,10 @@ public class SpanMultiTermQueryWrapper<Q extends MultiTermQuery> extends SpanQue
   public String toString(String field) {
     StringBuilder builder = new StringBuilder();
     builder.append("SpanMultiTermQueryWrapper(");
-    builder.append(query.toString(field));
+    // NOTE: query.toString must be placed in a temp local to avoid compile errors on Java 8u20
+    // see https://bugs.openjdk.java.net/browse/JDK-8056984?page=com.atlassian.streams.streams-jira-plugin:activity-stream-issue-tab
+    String queryStr = query.toString(field);
+    builder.append(queryStr);
     builder.append(")");
     if (getBoost() != 1F) {
       builder.append('^');
diff --git lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
index 25742e4..c55d5ae 100644
--- lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
+++ lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
@@ -20,13 +20,11 @@ package org.apache.lucene.store;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
 
 import org.apache.lucene.store.RAMDirectory;      // javadocs
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.IOUtils;
 
 // TODO
@@ -258,9 +256,4 @@ public class NRTCachingDirectory extends FilterDirectory implements Accountable
   public long ramBytesUsed() {
     return cache.ramBytesUsed();
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.singleton(Accountables.namedAccountable("cache", cache));
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java
index 8be535a..7f5e4d7 100644
--- lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java
+++ lucene/core/src/java/org/apache/lucene/store/RAMDirectory.java
@@ -28,7 +28,6 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 
 
 /**
@@ -151,16 +150,6 @@ public class RAMDirectory extends BaseDirectory implements Accountable {
     return sizeInBytes.get();
   }
   
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("file", fileMap);
-  }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(id=" + getLockID() + ")";
-  }
-
   /** Removes an existing file in the directory.
    * @throws IOException if the file does not exist
    */
diff --git lucene/core/src/java/org/apache/lucene/store/RAMFile.java lucene/core/src/java/org/apache/lucene/store/RAMFile.java
index 4feed57..11c1d19 100644
--- lucene/core/src/java/org/apache/lucene/store/RAMFile.java
+++ lucene/core/src/java/org/apache/lucene/store/RAMFile.java
@@ -18,7 +18,6 @@ package org.apache.lucene.store;
  */
 
 import java.util.ArrayList;
-import java.util.Collections;
 
 import org.apache.lucene.util.Accountable;
 
@@ -83,13 +82,4 @@ public class RAMFile implements Accountable {
     return sizeInBytes;
   }
   
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(length=" + length + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java
index c1b02f9..1cc7e39 100644
--- lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java
+++ lucene/core/src/java/org/apache/lucene/store/RAMOutputStream.java
@@ -18,12 +18,10 @@ package org.apache.lucene.store;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 import java.util.zip.CRC32;
 import java.util.zip.Checksum;
 
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 
 /**
  * A memory-resident {@link IndexOutput} implementation.
@@ -184,11 +182,6 @@ public class RAMOutputStream extends IndexOutput implements Accountable {
   public long ramBytesUsed() {
     return (long) file.numBuffers() * (long) BUFFER_SIZE;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.singleton(Accountables.namedAccountable("file", file));
-  }
 
   @Override
   public long getChecksum() throws IOException {
diff --git lucene/core/src/java/org/apache/lucene/util/Accountable.java lucene/core/src/java/org/apache/lucene/util/Accountable.java
index 05792a2..d0d30df 100644
--- lucene/core/src/java/org/apache/lucene/util/Accountable.java
+++ lucene/core/src/java/org/apache/lucene/util/Accountable.java
@@ -29,12 +29,4 @@ public interface Accountable {
    */
   long ramBytesUsed();
 
-  /**
-   * Returns nested resources of this class. 
-   * The result should be a point-in-time snapshot (to avoid race conditions).
-   * @see Accountables
-   */
-  // TODO: on java8 make this a default method returning emptyList
-  Iterable<? extends Accountable> getChildResources();
-
 }
diff --git lucene/core/src/java/org/apache/lucene/util/Accountables.java lucene/core/src/java/org/apache/lucene/util/Accountables.java
deleted file mode 100644
index ab96795..0000000
--- lucene/core/src/java/org/apache/lucene/util/Accountables.java
+++ /dev/null
@@ -1,141 +0,0 @@
-package org.apache.lucene.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.List;
-import java.util.Map;
-
-/** 
- * Helper methods for constructing nested resource descriptions
- * and debugging RAM usage.
- * <p>
- * {@code toString(Accountable}} can be used to quickly debug the nested
- * structure of any Accountable.
- * <p>
- * The {@code namedAccountable} and {@code namedAccountables} methods return
- * type-safe, point-in-time snapshots of the provided resources.
- */
-public class Accountables {
-  private Accountables() {}
-  
-  /** 
-   * Returns a String description of an Accountable and any nested resources.
-   * This is intended for development and debugging.
-   */
-  public static String toString(Accountable a) {
-    StringBuilder sb = new StringBuilder();
-    toString(sb, a, 0);
-    return sb.toString();
-  }
-  
-  private static StringBuilder toString(StringBuilder dest, Accountable a, int depth) {
-    for (int i = 1; i < depth; i++) {
-      dest.append("    ");
-    }
-    
-    if (depth > 0) {
-      dest.append("|-- ");
-    }
-    
-    dest.append(a.toString());
-    dest.append(": ");
-    dest.append(RamUsageEstimator.humanReadableUnits(a.ramBytesUsed()));
-    dest.append(System.lineSeparator());
-    
-    for (Accountable child : a.getChildResources()) {
-      toString(dest, child, depth + 1);
-    }
-    
-    return dest;
-  }
-  
-  /**
-   * Augments an existing accountable with the provided description.
-   * <p>
-   * The resource description is constructed in this format:
-   * {@code description [toString()]}
-   * <p>
-   * This is a point-in-time type safe view: consumers 
-   * will not be able to cast or manipulate the resource in any way.
-   */
-  public static Accountable namedAccountable(String description, Accountable in) {
-    return namedAccountable(description + " [" + in + "]", in.getChildResources(), in.ramBytesUsed());
-  }
-  
-  /** 
-   * Returns an accountable with the provided description and bytes.
-   */
-  public static Accountable namedAccountable(String description, long bytes) {
-    return namedAccountable(description, Collections.<Accountable>emptyList(), bytes);
-  }
-  
-  /** 
-   * Converts a map of resources to a collection. 
-   * <p>
-   * The resource descriptions are constructed in this format:
-   * {@code prefix 'key' [toString()]}
-   * <p>
-   * This is a point-in-time type safe view: consumers 
-   * will not be able to cast or manipulate the resources in any way.
-   */
-  public static Collection<Accountable> namedAccountables(String prefix, Map<?,? extends Accountable> in) {
-    List<Accountable> resources = new ArrayList<>();
-    for (Map.Entry<?,? extends Accountable> kv : in.entrySet()) {
-      resources.add(namedAccountable(prefix + " '" + kv.getKey() + "'", kv.getValue()));
-    }
-    Collections.sort(resources, new Comparator<Accountable>() {
-      @Override
-      public int compare(Accountable o1, Accountable o2) {
-        return o1.toString().compareTo(o2.toString());
-      }
-    });
-    return Collections.unmodifiableList(resources);
-  }
-  
-  /** 
-   * Returns an accountable with the provided description, bytes, and children.
-   * <p>
-   * The resource descriptions are constructed in this format:
-   * {@code description [toString()]}
-   * <p>
-   * This is a point-in-time type safe view: consumers 
-   * will not be able to cast or manipulate the resources in any way..
-   */
-  private static Accountable namedAccountable(final String description, final Iterable<? extends Accountable> children, final long bytes) {
-    return new Accountable() {
-      @Override
-      public long ramBytesUsed() {
-        return bytes;
-      }
-
-      @Override
-      public Iterable<? extends Accountable> getChildResources() {
-        return children;
-      }
-
-      @Override
-      public String toString() {
-        return description;
-      }
-    };
-  }
-}
diff --git lucene/core/src/java/org/apache/lucene/util/Constants.java lucene/core/src/java/org/apache/lucene/util/Constants.java
index 4d76708..d4fe9ea 100644
--- lucene/core/src/java/org/apache/lucene/util/Constants.java
+++ lucene/core/src/java/org/apache/lucene/util/Constants.java
@@ -92,7 +92,7 @@ public final class Constants {
     }
     JRE_IS_64BIT = is64Bit;
   }
-  
+
   public static final boolean JRE_IS_MINIMUM_JAVA8 = JVM_MAJOR_VERSION > 1 || (JVM_MAJOR_VERSION == 1 && JVM_MINOR_VERSION >= 8);
   public static final boolean JRE_IS_MINIMUM_JAVA9 = JVM_MAJOR_VERSION > 1 || (JVM_MAJOR_VERSION == 1 && JVM_MINOR_VERSION >= 9);
 
diff --git lucene/core/src/java/org/apache/lucene/util/PagedBytes.java lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
index 7d6f166..5327f55 100644
--- lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
+++ lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
@@ -19,7 +19,6 @@ package org.apache.lucene.util;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
@@ -135,16 +134,6 @@ public final class PagedBytes implements Accountable {
       }
       return size;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-
-    @Override
-    public String toString() {
-      return "PagedBytes(blocksize=" + blockSize + ")";
-    }
   }
 
   /** 1&lt;&lt;blockBits must be bigger than biggest single
@@ -257,11 +246,6 @@ public final class PagedBytes implements Accountable {
     }
     return size;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   /** Copy bytes in, writing the length as a 1 or 2 byte
    *  vInt prefix. */
diff --git lucene/core/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java lucene/core/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java
index 789a808..f6e206b 100644
--- lucene/core/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java
+++ lucene/core/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java
@@ -157,9 +157,4 @@ public final class ByteSequenceOutputs extends Outputs<BytesRef> {
   public long ramBytesUsed(BytesRef output) {
     return BASE_NUM_BYTES + RamUsageEstimator.sizeOf(output.bytes);
   }
-
-  @Override
-  public String toString() {
-    return "ByteSequenceOutputs";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
index 8bd5295..25851fb 100644
--- lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
+++ lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
@@ -19,7 +19,6 @@ package org.apache.lucene.util.fst;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.store.DataInput;
@@ -481,14 +480,5 @@ class BytesStore extends DataOutput implements Accountable {
     }
     return size;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(numBlocks=" + blocks.size() + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/fst/FST.java lucene/core/src/java/org/apache/lucene/util/fst/FST.java
index 7842b1c..75d7f80 100644
--- lucene/core/src/java/org/apache/lucene/util/fst/FST.java
+++ lucene/core/src/java/org/apache/lucene/util/fst/FST.java
@@ -22,11 +22,9 @@ import java.io.BufferedOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
-import java.util.ArrayList;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -37,7 +35,6 @@ import org.apache.lucene.store.InputStreamDataInput;
 import org.apache.lucene.store.OutputStreamDataOutput;
 import org.apache.lucene.store.RAMOutputStream;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.IOUtils;
@@ -447,23 +444,6 @@ public final class FST<T> implements Accountable {
     return size;
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    if (packed) {
-      resources.add(Accountables.namedAccountable("node ref to address", nodeRefToAddress));
-    } else if (nodeAddress != null) {
-      resources.add(Accountables.namedAccountable("node addresses", nodeAddress));
-      resources.add(Accountables.namedAccountable("in counts", inCounts));
-    }
-    return resources;
-  }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(input=" + inputType + ",output=" + outputs + ",packed=" + packed + ",nodes=" + nodeCount + ",arcs=" + arcCount + ")";
-  }
-
   void finish(long newStartNode) throws IOException {
     if (startNode != -1) {
       throw new IllegalStateException("already finished");
diff --git lucene/core/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java lucene/core/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java
index f121043..136d3c1 100644
--- lucene/core/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java
+++ lucene/core/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java
@@ -160,9 +160,4 @@ public final class IntSequenceOutputs extends Outputs<IntsRef> {
   public long ramBytesUsed(IntsRef output) {
     return BASE_NUM_BYTES + RamUsageEstimator.sizeOf(output.ints);
   }
-  
-  @Override
-  public String toString() {
-    return "IntSequenceOutputs";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/fst/NoOutputs.java lucene/core/src/java/org/apache/lucene/util/fst/NoOutputs.java
index 91935a8..1d05126 100644
--- lucene/core/src/java/org/apache/lucene/util/fst/NoOutputs.java
+++ lucene/core/src/java/org/apache/lucene/util/fst/NoOutputs.java
@@ -106,9 +106,4 @@ public final class NoOutputs extends Outputs<Object> {
   public long ramBytesUsed(Object output) {
     return 0;
   }
-
-  @Override
-  public String toString() {
-    return "NoOutputs";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/packed/BlockPackedReader.java lucene/core/src/java/org/apache/lucene/util/packed/BlockPackedReader.java
index 9bc99b6..5304941 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/BlockPackedReader.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/BlockPackedReader.java
@@ -27,7 +27,6 @@ import static org.apache.lucene.util.packed.PackedInts.checkBlockSize;
 import static org.apache.lucene.util.packed.PackedInts.numBlocks;
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
@@ -43,7 +42,6 @@ public final class BlockPackedReader extends LongValues implements Accountable {
   private final long valueCount;
   private final long[] minValues;
   private final PackedInts.Reader[] subReaders;
-  private final long sumBPV;
 
   /** Sole constructor. */
   public BlockPackedReader(IndexInput in, int packedIntsVersion, int blockSize, long valueCount, boolean direct) throws IOException {
@@ -53,11 +51,9 @@ public final class BlockPackedReader extends LongValues implements Accountable {
     final int numBlocks = numBlocks(valueCount, blockSize);
     long[] minValues = null;
     subReaders = new PackedInts.Reader[numBlocks];
-    long sumBPV = 0;
     for (int i = 0; i < numBlocks; ++i) {
       final int token = in.readByte() & 0xFF;
       final int bitsPerValue = token >>> BPV_SHIFT;
-      sumBPV += bitsPerValue;
       if (bitsPerValue > 64) {
         throw new IOException("Corrupted");
       }
@@ -81,7 +77,6 @@ public final class BlockPackedReader extends LongValues implements Accountable {
       }
     }
     this.minValues = minValues;
-    this.sumBPV = sumBPV;
   }
 
   @Override
@@ -100,15 +95,4 @@ public final class BlockPackedReader extends LongValues implements Accountable {
     }
     return size;
   }
-
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-  
-  @Override
-  public String toString() {
-    long avgBPV = subReaders.length == 0 ? 0 : sumBPV / subReaders.length;
-    return getClass().getSimpleName() + "(blocksize=" + (1<<blockShift) + ",size=" + valueCount + ",avgBPV=" + avgBPV + ")";
-  }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
index e189ebf..20fa78d 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
@@ -18,7 +18,6 @@
 package org.apache.lucene.util.packed;
 
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.FixedBitSet; // for javadocs
@@ -363,10 +362,5 @@ public class EliasFanoEncoder implements Accountable {
         + RamUsageEstimator.sizeOf(upperLongs)
         + RamUsageEstimator.sizeOf(upperZeroBitPositionIndex);
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 }
 
diff --git lucene/core/src/java/org/apache/lucene/util/packed/MonotonicBlockPackedReader.java lucene/core/src/java/org/apache/lucene/util/packed/MonotonicBlockPackedReader.java
index 81633f6..06f7b4b 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/MonotonicBlockPackedReader.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/MonotonicBlockPackedReader.java
@@ -24,7 +24,6 @@ import static org.apache.lucene.util.packed.PackedInts.checkBlockSize;
 import static org.apache.lucene.util.packed.PackedInts.numBlocks;
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
@@ -47,7 +46,6 @@ public class MonotonicBlockPackedReader extends LongValues implements Accountabl
   final long[] minValues;
   final float[] averages;
   final PackedInts.Reader[] subReaders;
-  final long sumBPV;
 
   /** Sole constructor. */
   public static MonotonicBlockPackedReader of(IndexInput in, int packedIntsVersion, int blockSize, long valueCount, boolean direct) throws IOException {
@@ -70,7 +68,6 @@ public class MonotonicBlockPackedReader extends LongValues implements Accountabl
     minValues = new long[numBlocks];
     averages = new float[numBlocks];
     subReaders = new PackedInts.Reader[numBlocks];
-    long sumBPV = 0;
     for (int i = 0; i < numBlocks; ++i) {
       if (packedIntsVersion < PackedInts.VERSION_MONOTONIC_WITHOUT_ZIGZAG) {
         minValues[i] = in.readVLong();
@@ -79,7 +76,6 @@ public class MonotonicBlockPackedReader extends LongValues implements Accountabl
       }
       averages[i] = Float.intBitsToFloat(in.readInt());
       final int bitsPerValue = in.readVInt();
-      sumBPV += bitsPerValue;
       if (bitsPerValue > 64) {
         throw new IOException("Corrupted");
       }
@@ -96,7 +92,6 @@ public class MonotonicBlockPackedReader extends LongValues implements Accountabl
         }
       }
     }
-    this.sumBPV = sumBPV;
   }
 
   @Override
@@ -126,15 +121,5 @@ public class MonotonicBlockPackedReader extends LongValues implements Accountabl
     }
     return sizeInBytes;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-  
-  @Override
-  public String toString() {
-    long avgBPV = subReaders.length == 0 ? 0 : sumBPV / subReaders.length;
-    return getClass().getSimpleName() + "(blocksize=" + (1<<blockShift) + ",size=" + valueCount + ",avgBPV=" + avgBPV + ")";
-  }
+
 }
diff --git lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java
index 031c8a2..08b5559 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed16ThreeBlocks.java
@@ -126,6 +126,6 @@ final class Packed16ThreeBlocks extends PackedInts.MutableImpl {
   @Override
   public String toString() {
     return getClass().getSimpleName() + "(bitsPerValue=" + bitsPerValue
-        + ",size=" + size() + ",blocks=" + blocks.length + ")";
+        + ", size=" + size() + ", elements.length=" + blocks.length + ")";
   }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java
index a746957..30a708a 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed64.java
@@ -238,8 +238,8 @@ class Packed64 extends PackedInts.MutableImpl {
 
   @Override
   public String toString() {
-    return "Packed64(bitsPerValue=" + bitsPerValue + ",size="
-            + size() + ",blocks=" + blocks.length + ")";
+    return "Packed64(bitsPerValue=" + bitsPerValue + ", size="
+            + size() + ", elements.length=" + blocks.length + ")";
   }
 
   @Override
diff --git lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java
index 09eb669..f12744f 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed64SingleBlock.java
@@ -203,7 +203,7 @@ abstract class Packed64SingleBlock extends PackedInts.MutableImpl {
   @Override
   public String toString() {
     return getClass().getSimpleName() + "(bitsPerValue=" + bitsPerValue
-        + ",size=" + size() + ",blocks=" + blocks.length + ")";
+        + ", size=" + size() + ", elements.length=" + blocks.length + ")";
   }
 
   public static Packed64SingleBlock create(DataInput in,
diff --git lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java
index 08a8205..aff1433 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/Packed8ThreeBlocks.java
@@ -124,6 +124,6 @@ final class Packed8ThreeBlocks extends PackedInts.MutableImpl {
   @Override
   public String toString() {
     return getClass().getSimpleName() + "(bitsPerValue=" + bitsPerValue
-        + ",size=" + size() + ",blocks=" + blocks.length + ")";
+        + ", size=" + size() + ", elements.length=" + blocks.length + ")";
   }
 }
diff --git lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
index 382fff6..88959c4 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
@@ -19,7 +19,6 @@ package org.apache.lucene.util.packed;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.index.NumericDocValues;
@@ -479,10 +478,6 @@ public class PackedInts {
      */
     public abstract int size();
 
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   /**
@@ -632,6 +627,7 @@ public class PackedInts {
     public final int size() {
       return valueCount;
     }
+
   }
 
   static abstract class MutableImpl extends Mutable {
@@ -655,10 +651,6 @@ public class PackedInts {
       return valueCount;
     }
 
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(valueCount=" + valueCount + ",bitsPerValue=" + bitsPerValue + ")";
-    }
   }
 
   /** A {@link Reader} which has all its values equal to 0 (bitsPerValue = 0). */
@@ -694,6 +686,7 @@ public class PackedInts {
     public long ramBytesUsed() {
       return RamUsageEstimator.alignObjectSize(RamUsageEstimator.NUM_BYTES_OBJECT_HEADER + RamUsageEstimator.NUM_BYTES_INT);
     }
+
   }
 
   /** A write-once Writer.
diff --git lucene/core/src/java/org/apache/lucene/util/packed/PackedLongValues.java lucene/core/src/java/org/apache/lucene/util/packed/PackedLongValues.java
index 308db76..2a46fa5 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/PackedLongValues.java
+++ lucene/core/src/java/org/apache/lucene/util/packed/PackedLongValues.java
@@ -20,7 +20,6 @@ package org.apache.lucene.util.packed;
 import static org.apache.lucene.util.packed.PackedInts.checkBlockSize;
 
 import java.util.Arrays;
-import java.util.Collections;
 
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.ArrayUtil;
@@ -115,11 +114,6 @@ public class PackedLongValues extends LongValues implements Accountable {
   public long ramBytesUsed() {
     return ramBytesUsed;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   /** Return an iterator over the values of this array. */
   public Iterator iterator() {
@@ -214,11 +208,6 @@ public class PackedLongValues extends LongValues implements Accountable {
       return ramBytesUsed;
     }
 
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-
     /** Return the number of elements that have been added to this builder. */
     public final long size() {
       return size;
diff --git lucene/core/src/java/org/apache/lucene/util/packed/gen_Packed64SingleBlock.py lucene/core/src/java/org/apache/lucene/util/packed/gen_Packed64SingleBlock.py
index 4639da6..c21cb36 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/gen_Packed64SingleBlock.py
+++ lucene/core/src/java/org/apache/lucene/util/packed/gen_Packed64SingleBlock.py
@@ -222,7 +222,7 @@ abstract class Packed64SingleBlock extends PackedInts.MutableImpl {
   @Override
   public String toString() {
     return getClass().getSimpleName() + "(bitsPerValue=" + bitsPerValue
-        + ",size=" + size() + ",blocks=" + blocks.length + ")";
+        + ", size=" + size() + ", elements.length=" + blocks.length + ")";
   }
 
   public static Packed64SingleBlock create(DataInput in,
diff --git lucene/core/src/java/org/apache/lucene/util/packed/gen_PackedThreeBlocks.py lucene/core/src/java/org/apache/lucene/util/packed/gen_PackedThreeBlocks.py
index a43e5e0..ad1fd8d 100644
--- lucene/core/src/java/org/apache/lucene/util/packed/gen_PackedThreeBlocks.py
+++ lucene/core/src/java/org/apache/lucene/util/packed/gen_PackedThreeBlocks.py
@@ -158,7 +158,7 @@ if __name__ == '__main__':
   @Override
   public String toString() {
     return getClass().getSimpleName() + "(bitsPerValue=" + bitsPerValue
-        + ",size=" + size() + ",blocks=" + blocks.length + ")";
+        + ", size=" + size() + ", elements.length=" + blocks.length + ")";
   }
 }
 """ %(MASKS[bpv], 2*bpv, MASKS[bpv], bpv, MASKS[bpv], MASKS[bpv], 2*bpv, MASKS[bpv], bpv, MASKS[bpv], CASTS[bpv], 2*bpv, CASTS[bpv], bpv, CASTS[bpv], CASTS[bpv],
diff --git lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
index 4676904..d5be334 100644
--- lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
+++ lucene/core/src/test/org/apache/lucene/index/TestPrefixCodedTerms.java
@@ -113,7 +113,9 @@ public class TestPrefixCodedTerms extends LuceneTestCase {
     }
     
     Iterator<Term> expected = superSet.iterator();
-    Iterator<Term> actual = new MergedIterator<>(subs.toArray(new Iterator[0]));
+    // NOTE: currenlty using diamond operator on MergedIterator (without explicit Term class) causes
+    // errors on ecj used for javadoc lint
+    Iterator<Term> actual = new MergedIterator<Term>(subs.toArray(new Iterator[0]));
     while (actual.hasNext()) {
       assertTrue(expected.hasNext());
       assertEquals(expected.next(), actual.next());
diff --git lucene/expressions/build.xml lucene/expressions/build.xml
index 123e92c..4efbb86 100644
--- lucene/expressions/build.xml
+++ lucene/expressions/build.xml
@@ -98,10 +98,6 @@
       <property name="-grammar.relative.path" location="${grammar.path}" relative="true"/>
       <replace-value property="grammar.relative.path" value="${-grammar.relative.path}${file.separator}" from="${file.separator}" to="/"/>
       <java classname="org.antlr.Tool" fork="true" failonerror="true" classpathref="antlr.classpath" taskname="antlr">
-        <!-- this is a hack because antlr generates code comments in nondeterministic order
-         (using HashMap somewhere it should use LinkedHashMap). This hack only works for Java 7,
-         Java 8 always uses murmurhash for strings and uses time-of-day as seed. -->
-        <sysproperty key="jdk.map.althashing.threshold" value="-1"/>
         <sysproperty key="file.encoding" value="UTF-8"/>
         <sysproperty key="user.language" value="en"/>
         <sysproperty key="user.country" value="US"/>
diff --git lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java
index d50c5a3..805a017 100644
--- lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java
+++ lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.facet.taxonomy;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 import java.util.Map;
 import java.util.WeakHashMap;
 
@@ -26,7 +25,6 @@ import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.index.AtomicReaderContext;
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.IntsRef;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -148,11 +146,6 @@ public class CachedOrdinalsReader extends OrdinalsReader implements Accountable
       }
       return mem;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   @Override
@@ -164,9 +157,4 @@ public class CachedOrdinalsReader extends OrdinalsReader implements Accountable
 
     return bytes;
   }
-  
-  @Override
-  public synchronized Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("segment", ordsCache);
-  }
 }
diff --git lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
index ebaafb1..3c9786c 100644
--- lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
+++ lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping.java
@@ -315,7 +315,9 @@ public class TestGrouping extends LuceneTestCase {
         BytesRef groupValue = mvalGd.groupValue.exists() ? ((MutableValueStr) mvalGd.groupValue).value.get() : null;
         groups.add(new GroupDocs<>(Float.NaN, mvalGd.maxScore, mvalGd.totalHits, mvalGd.scoreDocs, groupValue, mvalGd.groupSortValues));
       }
-      return new TopGroups<>(mvalTopGroups.groupSort, mvalTopGroups.withinGroupSort, mvalTopGroups.totalHitCount, mvalTopGroups.totalGroupedHitCount, groups.toArray(new GroupDocs[groups.size()]), Float.NaN);
+      // NOTE: currenlty using diamond operator on TopGroups (without explicit Term class) causes
+      // errors on ecj used for javadoc lint
+      return new TopGroups<BytesRef>(mvalTopGroups.groupSort, mvalTopGroups.withinGroupSort, mvalTopGroups.totalHitCount, mvalTopGroups.totalGroupedHitCount, groups.toArray(new GroupDocs[groups.size()]), Float.NaN);
     }
     fail();
     return null;
diff --git lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
index 3c1acd1..59a816e 100644
--- lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
+++ lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
@@ -20,7 +20,6 @@ package org.apache.lucene.uninverting;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.codecs.PostingsFormat; // javadocs
@@ -182,11 +181,6 @@ public class DocTermOrds implements Accountable {
     return sz;
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
-
   /** Inverts all terms */
   public DocTermOrds(AtomicReader reader, Bits liveDocs, String field) throws IOException {
     this(reader, liveDocs, field, null, Integer.MAX_VALUE);
diff --git lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
index f264167..d68a39d 100644
--- lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
+++ lucene/misc/src/java/org/apache/lucene/uninverting/FieldCache.java
@@ -19,7 +19,6 @@ package org.apache.lucene.uninverting;
 
 import java.io.IOException;
 import java.io.PrintStream;
-import java.util.Collections;
 
 import org.apache.lucene.analysis.NumericTokenStream;
 import org.apache.lucene.document.DoubleField;
@@ -64,11 +63,6 @@ interface FieldCache {
       // don't call on the in-progress value, might make things angry.
       return RamUsageEstimator.NUM_BYTES_OBJECT_REF;
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   /**
diff --git lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
index 65dd48d..0db261d 100644
--- lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
+++ lucene/misc/src/java/org/apache/lucene/uninverting/FieldCacheImpl.java
@@ -20,7 +20,6 @@ package org.apache.lucene.uninverting;
 import java.io.IOException;
 import java.io.PrintStream;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -39,7 +38,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
@@ -381,11 +379,6 @@ class FieldCacheImpl implements FieldCache {
         return base + (bits.length() >>> 3);
       }
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   static final class DocsWithFieldCache extends Cache {
@@ -486,11 +479,6 @@ class FieldCacheImpl implements FieldCache {
     public long ramBytesUsed() {
       return values.ramBytesUsed() + RamUsageEstimator.NUM_BYTES_OBJECT_REF + RamUsageEstimator.NUM_BYTES_LONG;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   static final class LongCache extends Cache {
@@ -609,15 +597,6 @@ class FieldCacheImpl implements FieldCache {
              3*RamUsageEstimator.NUM_BYTES_OBJECT_REF +
              RamUsageEstimator.NUM_BYTES_INT;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      resources.add(Accountables.namedAccountable("term bytes", bytes));
-      resources.add(Accountables.namedAccountable("ord -> term", termOrdToBytesOffset));
-      resources.add(Accountables.namedAccountable("doc -> ord", docToTermOrd));
-      return resources;
-    }
   }
 
   public SortedDocValues getTermsIndex(AtomicReader reader, String field) throws IOException {
@@ -752,13 +731,6 @@ class FieldCacheImpl implements FieldCache {
     public long ramBytesUsed() {
       return bytes.ramBytesUsed() + docToOffset.ramBytesUsed() + 2*RamUsageEstimator.NUM_BYTES_OBJECT_REF;
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      List<Accountable> resources = new ArrayList<>();
-      resources.add(Accountables.namedAccountable("term bytes", bytes));
-      return resources;
-    }
   }
 
   // TODO: this if DocTermsIndex was already created, we
diff --git lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
index 566e48a..3eab793 100644
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.codecs.idversion;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.codecs.BlockTermState;
 import org.apache.lucene.codecs.CodecUtil;
@@ -28,7 +27,6 @@ import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BitUtil;
 import org.apache.lucene.util.Bits;
 
@@ -97,18 +95,8 @@ final class IDVersionPostingsReader extends PostingsReaderBase {
   public long ramBytesUsed() {
     return 0;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
 
   @Override
   public void checkIntegrity() throws IOException {
   }
-
-  @Override
-  public String toString() {
-    return getClass().getSimpleName();
-  }
 }
diff --git lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsReader.java lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsReader.java
index 8c581f4..558dd49 100644
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsReader.java
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsReader.java
@@ -18,10 +18,8 @@ package org.apache.lucene.codecs.idversion;
  */
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
-import java.util.List;
 import java.util.TreeMap;
 
 import org.apache.lucene.codecs.CodecUtil;
@@ -36,8 +34,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.fst.PairOutputs.Pair;
@@ -246,19 +242,11 @@ public final class VersionBlockTreeTermsReader extends FieldsProducer {
 
   @Override
   public long ramBytesUsed() {
-    long sizeInBytes = postingsReader.ramBytesUsed();
+    long sizeInByes = ((postingsReader!=null) ? postingsReader.ramBytesUsed() : 0);
     for(VersionFieldReader reader : fields.values()) {
-      sizeInBytes += reader.ramBytesUsed();
+      sizeInByes += reader.ramBytesUsed();
     }
-    return sizeInBytes;
-  }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    resources.addAll(Accountables.namedAccountables("field", fields));
-    resources.add(Accountables.namedAccountable("delegate", postingsReader));
-    return Collections.unmodifiableList(resources);
+    return sizeInByes;
   }
 
   @Override
@@ -269,9 +257,4 @@ public final class VersionBlockTreeTermsReader extends FieldsProducer {
     // postings
     postingsReader.checkIntegrity();
   }
-  
-  @Override
-  public String toString() {
-    return getClass().getSimpleName() + "(fields=" + fields.size() + ",delegate=" + postingsReader.toString() + ")";
-  }
 }
diff --git lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionFieldReader.java lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionFieldReader.java
index 6cc6392..504890f 100644
--- lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionFieldReader.java
+++ lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionFieldReader.java
@@ -18,7 +18,6 @@ package org.apache.lucene.codecs.idversion;
  */
 
 import java.io.IOException;
-import java.util.Collections;
 
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfo.IndexOptions;
@@ -27,7 +26,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.fst.FST;
 import org.apache.lucene.util.fst.PairOutputs.Pair;
@@ -161,18 +159,4 @@ final class VersionFieldReader extends Terms implements Accountable {
   public long ramBytesUsed() {
     return ((index!=null)? index.ramBytesUsed() : 0);
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (index == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singletonList(Accountables.namedAccountable("term index", index));
-    }
-  }
-
-  @Override
-  public String toString() {
-    return "IDVersionTerms(terms=" + numTerms + ",postings=" + sumDocFreq + ",positions=" + sumTotalTermFreq + ",docs=" + docCount + ")";
-  }
 }
diff --git lucene/suggest/build.xml lucene/suggest/build.xml
index d12597a..8ba3d25 100755
--- lucene/suggest/build.xml
+++ lucene/suggest/build.xml
@@ -24,7 +24,7 @@
   </description>
 	
   <!-- just a list of words for testing suggesters -->
-  <property name="rat.excludes" value="**/Top50KWiki.utf8,**/stop-snowball.txt"/>
+  <property name="rat.excludes" value="**/Top50KWiki.utf8"/>
 
   <import file="../module-build.xml"/>
 
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java lucene/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
index 0438149..ef22e2a 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
@@ -30,7 +30,6 @@ import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.store.InputStreamDataInput;
 import org.apache.lucene.store.OutputStreamDataOutput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.PriorityQueue;
@@ -269,13 +268,4 @@ public abstract class Lookup implements Accountable {
    */
   public abstract boolean load(DataInput input) throws IOException;
 
-  /**
-   * Returns nested resources of this class. 
-   * The result should be a point-in-time snapshot (to avoid race conditions).
-   * @see Accountables
-   */
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return null;
-  }
 }
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java
index dd0d89b..eb1f63f 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java
@@ -78,8 +78,6 @@ import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.Version;
@@ -727,29 +725,6 @@ public class AnalyzingInfixSuggester extends Lookup implements Closeable {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    try {
-      if (searcherMgr != null) {
-        IndexSearcher searcher = searcherMgr.acquire();
-        try {
-          for (AtomicReaderContext context : searcher.getIndexReader().leaves()) {
-            AtomicReader reader = FilterAtomicReader.unwrap(context.reader());
-            if (reader instanceof SegmentReader) {
-              resources.add(Accountables.namedAccountable("segment", (SegmentReader)reader));
-            }
-          }
-        } finally {
-          searcherMgr.release(searcher);
-        }
-      }
-      return resources;
-    } catch (IOException ioe) {
-      throw new RuntimeException(ioe);
-    }
-  }
-
-  @Override
   public long getCount() throws IOException {
     if (searcherMgr == null) {
       return 0;
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java
index 58d9e78..6496e3a 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java
@@ -37,8 +37,6 @@ import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -260,15 +258,6 @@ public class AnalyzingSuggester extends Lookup {
     return fst == null ? 0 : fst.ramBytesUsed();
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (fst == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singletonList(Accountables.namedAccountable("fst", fst));
-    }
-  }
-
   private int[] topoSortStates(Automaton a) {
     int[] states = new int[a.getNumStates()];
     final Set<Integer> visited = new HashSet<>();
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
index 222f15a..255fc1b 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
@@ -49,8 +49,6 @@ import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRefBuilder;
@@ -212,15 +210,6 @@ public class FreeTextSuggester extends Lookup {
     return fst.ramBytesUsed();
   }
 
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (fst == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singletonList(Accountables.namedAccountable("fst", fst));
-    }
-  }
-
   private static class AnalyzingComparator implements Comparator<BytesRef> {
 
     private final ByteArrayDataInput readerA = new ByteArrayDataInput();
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java
deleted file mode 100644
index 03bdc71..0000000
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/SuggestStopFilterFactory.java
+++ /dev/null
@@ -1,130 +0,0 @@
-package org.apache.lucene.search.suggest.analyzing;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoaderAware;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-import org.apache.lucene.analysis.util.WordlistLoader; // jdocs
-
-import java.util.Map;
-import java.io.IOException;
-
-/**
- * Factory for {@link SuggestStopFilter}.
- *
- * <pre class="prettyprint">
- * &lt;fieldType name="autosuggest" class="solr.TextField" 
- *            positionIncrementGap="100" autoGeneratePhraseQueries="true"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.SuggestStopFilterFactory" ignoreCase="true"
- *             words="stopwords.txt" format="wordset"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- * <p>
- * All attributes are optional:
- * </p>
- * <ul>
- *  <li><code>ignoreCase</code> defaults to <code>false</code></li>
- *  <li><code>words</code> should be the name of a stopwords file to parse, if not 
- *      specified the factory will use {@link StopAnalyzer#ENGLISH_STOP_WORDS_SET}
- *  </li>
- *  <li><code>format</code> defines how the <code>words</code> file will be parsed, 
- *      and defaults to <code>wordset</code>.  If <code>words</code> is not specified, 
- *      then <code>format</code> must not be specified.
- *  </li>
- * </ul>
- * <p>
- * The valid values for the <code>format</code> option are:
- * </p>
- * <ul>
- *  <li><code>wordset</code> - This is the default format, which supports one word per 
- *      line (including any intra-word whitespace) and allows whole line comments 
- *      begining with the "#" character.  Blank lines are ignored.  See 
- *      {@link WordlistLoader#getLines WordlistLoader.getLines} for details.
- *  </li>
- *  <li><code>snowball</code> - This format allows for multiple words specified on each 
- *      line, and trailing comments may be specified using the vertical line ("&#124;"). 
- *      Blank lines are ignored.  See 
- *      {@link WordlistLoader#getSnowballWordSet WordlistLoader.getSnowballWordSet}
- *      for details.
- *  </li>
- * </ul>
- */
-  public class SuggestStopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  /** the default format, one word per line, whole line comments start with "#" */
-  public static final String FORMAT_WORDSET = "wordset";
-  /** multiple words may be specified on each line, trailing comments start with "&#124;" */
-  public static final String FORMAT_SNOWBALL = "snowball";
-
-  private CharArraySet stopWords;
-  private final String stopWordFiles;
-  private final String format;
-  private final boolean ignoreCase;
-
-  /** Creates a new StopFilterFactory */
-  public SuggestStopFilterFactory(Map<String,String> args) {
-    super(args);
-    stopWordFiles = get(args, "words");
-    format = get(args, "format", (null == stopWordFiles ? null : FORMAT_WORDSET));
-    ignoreCase = getBoolean(args, "ignoreCase", false);
-    if (!args.isEmpty()) {
-      throw new IllegalArgumentException("Unknown parameters: " + args);
-    }
-  }
-
-  @Override
-  public void inform(ResourceLoader loader) throws IOException {
-    if (stopWordFiles != null) {
-      if (FORMAT_WORDSET.equalsIgnoreCase(format)) {
-        stopWords = getWordSet(loader, stopWordFiles, ignoreCase);
-      } else if (FORMAT_SNOWBALL.equalsIgnoreCase(format)) {
-        stopWords = getSnowballWordSet(loader, stopWordFiles, ignoreCase);
-      } else {
-        throw new IllegalArgumentException("Unknown 'format' specified for 'words' file: " + format);
-      }
-    } else {
-      if (null != format) {
-        throw new IllegalArgumentException("'format' can not be specified w/o an explicit 'words' file: " + format);
-      }
-      stopWords = new CharArraySet(StopAnalyzer.ENGLISH_STOP_WORDS_SET, ignoreCase);
-    }
-  }
-
-  /** Whether or not to ignore case */
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  /** Returns the configured stopword set */
-  public CharArraySet getStopWords() {
-    return stopWords;
-  }
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    SuggestStopFilter suggestStopFilter = new SuggestStopFilter(input, stopWords);
-    return suggestStopFilter;
-  }
-}
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
index a3ddc07..84ab69c 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
@@ -33,7 +33,6 @@ import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -315,18 +314,6 @@ public class FSTCompletionLookup extends Lookup implements Accountable {
   }
 
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    List<Accountable> resources = new ArrayList<>();
-    if (normalCompletion != null) {
-      resources.add(Accountables.namedAccountable("fst", normalCompletion.getFST()));
-    }
-    if (higherWeightsCompletion != null && (normalCompletion == null || normalCompletion.getFST() != higherWeightsCompletion.getFST())) {
-      resources.add(Accountables.namedAccountable("higher weights fst", higherWeightsCompletion.getFST()));
-    }
-    return resources;
-  }
-
-  @Override
   public long getCount() {
     return count;
   }
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
index d6b1c85..e8e70c9 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
@@ -31,8 +31,6 @@ import org.apache.lucene.store.ByteArrayDataInput;
 import org.apache.lucene.store.ByteArrayDataOutput;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -301,15 +299,6 @@ public class WFSTCompletionLookup extends Lookup {
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    if (fst == null) {
-      return Collections.emptyList();
-    } else {
-      return Collections.singleton(Accountables.namedAccountable("fst", fst));
-    }
-  }
-
-  @Override
   public long getCount() {
     return count;
   }
diff --git lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java
index 0791afd..c93ae9a 100644
--- lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java
+++ lucene/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellTernarySearchTrie.java
@@ -32,7 +32,6 @@ package org.apache.lucene.search.suggest.jaspell;
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
-import java.util.Collections;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.List;
@@ -111,11 +110,7 @@ public class JaspellTernarySearchTrie implements Accountable {
       }
       return mem;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
+
   }
 
   /**
@@ -903,9 +898,5 @@ public class JaspellTernarySearchTrie implements Accountable {
     }
     return mem;
   }
-  
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Collections.emptyList();
-  }
+
 }
diff --git lucene/suggest/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory lucene/suggest/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
deleted file mode 100644
index 053ccff..0000000
--- lucene/suggest/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory
+++ /dev/null
@@ -1,16 +0,0 @@
-#  Licensed to the Apache Software Foundation (ASF) under one or more
-#  contributor license agreements.  See the NOTICE file distributed with
-#  this work for additional information regarding copyright ownership.
-#  The ASF licenses this file to You under the Apache License, Version 2.0
-#  (the "License"); you may not use this file except in compliance with
-#  the License.  You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS,
-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#  See the License for the specific language governing permissions and
-#  limitations under the License.
-
-org.apache.lucene.search.suggest.analyzing.SuggestStopFilterFactory
diff --git lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java
deleted file mode 100644
index 7b0b661..0000000
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/TestSuggestStopFilterFactory.java
+++ /dev/null
@@ -1,121 +0,0 @@
-package org.apache.lucene.search.suggest.analyzing;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ClasspathResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.util.Version;
-
-public class TestSuggestStopFilterFactory extends BaseTokenStreamTestCase {
-
-  public void testInform() throws Exception {
-    ResourceLoader loader = new ClasspathResourceLoader(getClass());
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    SuggestStopFilterFactory factory = createFactory(
-        "words", "stop-1.txt",
-        "ignoreCase", "true");
-    CharArraySet words = factory.getStopWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 2, words.size() == 2);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
-
-    factory = createFactory("words", "stop-1.txt, stop-2.txt",
-        "ignoreCase", "true");
-    words = factory.getStopWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 4, words.size() == 4);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
-
-    factory = createFactory("words", "stop-snowball.txt",
-        "format", "snowball",
-        "ignoreCase", "true");
-    words = factory.getStopWords();
-    assertEquals(8, words.size());
-    assertTrue(words.contains("he"));
-    assertTrue(words.contains("him"));
-    assertTrue(words.contains("his"));
-    assertTrue(words.contains("himself"));
-    assertTrue(words.contains("she"));
-    assertTrue(words.contains("her"));
-    assertTrue(words.contains("hers"));
-    assertTrue(words.contains("herself"));
-
-    // defaults
-    factory = createFactory();
-    assertEquals(StopAnalyzer.ENGLISH_STOP_WORDS_SET, factory.getStopWords());
-    assertEquals(false, factory.isIgnoreCase());
-  }
-
-  /** Test that bogus arguments result in exception */
-  public void testBogusArguments() throws Exception {
-    try {
-      createFactory("bogusArg", "bogusValue");
-      fail();
-    } catch (IllegalArgumentException expected) {
-      assertTrue(expected.getMessage().contains("Unknown parameters"));
-    }
-  }
-
-  /** Test that bogus arguments result in exception */
-  public void testBogusFormats() throws Exception {
-    try {
-      createFactory("words", "stop-snowball.txt",
-          "format", "bogus");
-      fail();
-    } catch (IllegalArgumentException expected) {
-      String msg = expected.getMessage();
-      assertTrue(msg, msg.contains("Unknown"));
-      assertTrue(msg, msg.contains("format"));
-      assertTrue(msg, msg.contains("bogus"));
-    }
-    try {
-      createFactory(
-          // implicit default words file
-          "format", "bogus");
-      fail();
-    } catch (IllegalArgumentException expected) {
-      String msg = expected.getMessage();
-      assertTrue(msg, msg.contains("can not be specified"));
-      assertTrue(msg, msg.contains("format"));
-      assertTrue(msg, msg.contains("bogus"));
-    }
-  }                                             
-
-  private SuggestStopFilterFactory createFactory(String ... params) throws IOException {
-    if(params.length%2 != 0) {
-      throw new IllegalArgumentException("invalid keysAndValues map");
-    }
-    Map<String, String> args = new HashMap<>(params.length/2);
-    for(int i=0; i<params.length; i+=2) {
-      String previous = args.put(params[i], params[i+1]);
-      assertNull("duplicate values for key: " + params[i], previous);
-    }
-    args.put("luceneMatchVersion", Version.LATEST.toString());
-
-    SuggestStopFilterFactory factory = new SuggestStopFilterFactory(args);
-    factory.inform(new ClasspathResourceLoader(getClass()));
-    return factory;
-  }
-}
diff --git lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-1.txt lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-1.txt
deleted file mode 100644
index 3fe6d02..0000000
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-1.txt
+++ /dev/null
@@ -1,17 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-foo
-bar
diff --git lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-2.txt lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-2.txt
deleted file mode 100644
index 50531e7..0000000
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-2.txt
+++ /dev/null
@@ -1,17 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-junk
-more
diff --git lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-snowball.txt lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-snowball.txt
deleted file mode 100644
index 1c0c6f5..0000000
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/stop-snowball.txt
+++ /dev/null
@@ -1,10 +0,0 @@
- | This is a file in snowball format, empty lines are ignored, '|' is a comment
- | Additionally, multiple words can be on the same line, allowing stopwords to be
- | arranged in tables (useful in some languages where they might inflect)
-
- | fictitious table below
-
-|third person singular
-|Subject Object Possessive Reflexive
-he       him    his        himself| masculine
-she      her    hers       herself| feminine
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingDocValuesFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingDocValuesFormat.java
index ffa56c0..6327f3e 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingDocValuesFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingDocValuesFormat.java
@@ -19,6 +19,7 @@ package org.apache.lucene.codecs.asserting;
 
 import java.io.IOException;
 import java.util.Iterator;
+import java.util.NoSuchElementException;
 
 import org.apache.lucene.codecs.DocValuesConsumer;
 import org.apache.lucene.codecs.DocValuesFormat;
@@ -33,12 +34,10 @@ import org.apache.lucene.index.SegmentWriteState;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LongBitSet;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Just like {@link Lucene410DocValuesFormat} but with additional asserts.
@@ -81,7 +80,7 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
         count++;
       }
       assert count == maxDoc;
-      TestUtil.checkIterator(values.iterator(), maxDoc, true);
+      checkIterator(values.iterator(), maxDoc, true);
       in.addNumericField(field, values);
     }
     
@@ -93,7 +92,7 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
         count++;
       }
       assert count == maxDoc;
-      TestUtil.checkIterator(values.iterator(), maxDoc, true);
+      checkIterator(values.iterator(), maxDoc, true);
       in.addBinaryField(field, values);
     }
     
@@ -127,8 +126,8 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
       
       assert count == maxDoc;
       assert seenOrds.cardinality() == valueCount;
-      TestUtil.checkIterator(values.iterator(), valueCount, false);
-      TestUtil.checkIterator(docToOrd.iterator(), maxDoc, false);
+      checkIterator(values.iterator(), valueCount, false);
+      checkIterator(docToOrd.iterator(), maxDoc, false);
       in.addSortedField(field, values, docToOrd);
     }
     
@@ -151,8 +150,8 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
         }
       }
       assert valueIterator.hasNext() == false;
-      TestUtil.checkIterator(docToValueCount.iterator(), maxDoc, false);
-      TestUtil.checkIterator(values.iterator(), valueCount, false);
+      checkIterator(docToValueCount.iterator(), maxDoc, false);
+      checkIterator(values.iterator(), valueCount, false);
       in.addSortedNumericField(field, docToValueCount, values);
     }
     
@@ -196,9 +195,9 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
       
       assert docCount == maxDoc;
       assert seenOrds.cardinality() == valueCount;
-      TestUtil.checkIterator(values.iterator(), valueCount, false);
-      TestUtil.checkIterator(docToOrdCount.iterator(), maxDoc, false);
-      TestUtil.checkIterator(ords.iterator(), ordCount, false);
+      checkIterator(values.iterator(), valueCount, false);
+      checkIterator(docToOrdCount.iterator(), maxDoc, false);
+      checkIterator(ords.iterator(), ordCount, false);
       in.addSortedSetField(field, values, docToOrdCount, ords);
     }
     
@@ -208,6 +207,28 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
     }
   }
   
+  static <T> void checkIterator(Iterator<T> iterator, long expectedSize, boolean allowNull) {
+    for (long i = 0; i < expectedSize; i++) {
+      boolean hasNext = iterator.hasNext();
+      assert hasNext;
+      T v = iterator.next();
+      assert allowNull || v != null;
+      try {
+        iterator.remove();
+        throw new AssertionError("broken iterator (supports remove): " + iterator);
+      } catch (UnsupportedOperationException expected) {
+        // ok
+      }
+    }
+    assert !iterator.hasNext();
+    try {
+      iterator.next();
+      throw new AssertionError("broken iterator (allows next() when hasNext==false) " + iterator);
+    } catch (NoSuchElementException expected) {
+      // ok
+    }
+  }
+  
   static class AssertingDocValuesProducer extends DocValuesProducer {
     private final DocValuesProducer in;
     private final int maxDoc;
@@ -215,10 +236,6 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
     AssertingDocValuesProducer(DocValuesProducer in, int maxDoc) {
       this.in = in;
       this.maxDoc = maxDoc;
-      // do a few simple checks on init
-      assert toString() != null;
-      assert ramBytesUsed() >= 0;
-      assert getChildResources() != null;
     }
 
     @Override
@@ -277,26 +294,12 @@ public class AssertingDocValuesFormat extends DocValuesFormat {
 
     @Override
     public long ramBytesUsed() {
-      long v = in.ramBytesUsed();
-      assert v >= 0;
-      return v;
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      Iterable<? extends Accountable> res = in.getChildResources();
-      TestUtil.checkIterator(res.iterator());
-      return res;
+      return in.ramBytesUsed();
     }
 
     @Override
     public void checkIntegrity() throws IOException {
       in.checkIntegrity();
     }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + in.toString() + ")";
-    }
   }
 }
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingNormsFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingNormsFormat.java
index 4b2f0fc..4d1e1e1 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingNormsFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingNormsFormat.java
@@ -28,8 +28,6 @@ import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.index.SegmentWriteState;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Just like {@link Lucene49NormsFormat} but with additional asserts.
@@ -69,7 +67,7 @@ public class AssertingNormsFormat extends NormsFormat {
         count++;
       }
       assert count == maxDoc;
-      TestUtil.checkIterator(values.iterator(), maxDoc, false);
+      AssertingDocValuesFormat.checkIterator(values.iterator(), maxDoc, false);
       in.addNormsField(field, values);
     }
     
@@ -86,10 +84,6 @@ public class AssertingNormsFormat extends NormsFormat {
     AssertingNormsProducer(NormsProducer in, int maxDoc) {
       this.in = in;
       this.maxDoc = maxDoc;
-      // do a few simple checks on init
-      assert toString() != null;
-      assert ramBytesUsed() >= 0;
-      assert getChildResources() != null;
     }
 
     @Override
@@ -107,26 +101,12 @@ public class AssertingNormsFormat extends NormsFormat {
 
     @Override
     public long ramBytesUsed() {
-      long v = in.ramBytesUsed();
-      assert v >= 0;
-      return v;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      Iterable<? extends Accountable> res = in.getChildResources();
-      TestUtil.checkIterator(res.iterator());
-      return res;
+      return in.ramBytesUsed();
     }
 
     @Override
     public void checkIntegrity() throws IOException {
       in.checkIntegrity();
     }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + in.toString() + ")";
-    }
   }
 }
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
index de873c0..2f0c3ad 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingPostingsFormat.java
@@ -33,10 +33,8 @@ import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.index.SegmentWriteState;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Just like {@link Lucene41PostingsFormat} but with additional asserts.
@@ -63,10 +61,6 @@ public final class AssertingPostingsFormat extends PostingsFormat {
     
     AssertingFieldsProducer(FieldsProducer in) {
       this.in = in;
-      // do a few simple checks on init
-      assert toString() != null;
-      assert ramBytesUsed() >= 0;
-      assert getChildResources() != null;
     }
     
     @Override
@@ -94,27 +88,13 @@ public final class AssertingPostingsFormat extends PostingsFormat {
 
     @Override
     public long ramBytesUsed() {
-      long v = in.ramBytesUsed();
-      assert v >= 0;
-      return v;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      Iterable<? extends Accountable> res = in.getChildResources();
-      TestUtil.checkIterator(res.iterator());
-      return res;
+      return in.ramBytesUsed();
     }
 
     @Override
     public void checkIntegrity() throws IOException {
       in.checkIntegrity();
     }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + in.toString() + ")";
-    }
   }
 
   static class AssertingFieldsConsumer extends FieldsConsumer {
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java
index 6e3a2af..03adb31 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingStoredFieldsFormat.java
@@ -30,8 +30,6 @@ import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Just like {@link Lucene41StoredFieldsFormat} but with additional asserts.
@@ -56,10 +54,6 @@ public class AssertingStoredFieldsFormat extends StoredFieldsFormat {
     AssertingStoredFieldsReader(StoredFieldsReader in, int maxDoc) {
       this.in = in;
       this.maxDoc = maxDoc;
-      // do a few simple checks on init
-      assert toString() != null;
-      assert ramBytesUsed() >= 0;
-      assert getChildResources() != null;
     }
     
     @Override
@@ -80,27 +74,13 @@ public class AssertingStoredFieldsFormat extends StoredFieldsFormat {
 
     @Override
     public long ramBytesUsed() {
-      long v = in.ramBytesUsed();
-      assert v >= 0;
-      return v;
-    }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      Iterable<? extends Accountable> res = in.getChildResources();
-      TestUtil.checkIterator(res.iterator());
-      return res;
+      return in.ramBytesUsed();
     }
 
     @Override
     public void checkIntegrity() throws IOException {
       in.checkIntegrity();
     }
-
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + in.toString() + ")";
-    }
   }
 
   enum Status {
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingTermVectorsFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingTermVectorsFormat.java
index e9659c0..f31c8be 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingTermVectorsFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/asserting/AssertingTermVectorsFormat.java
@@ -30,9 +30,7 @@ import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.TestUtil;
 
 /**
  * Just like {@link Lucene42TermVectorsFormat} but with additional asserts.
@@ -55,10 +53,6 @@ public class AssertingTermVectorsFormat extends TermVectorsFormat {
 
     AssertingTermVectorsReader(TermVectorsReader in) {
       this.in = in;
-      // do a few simple checks on init
-      assert toString() != null;
-      assert ramBytesUsed() >= 0;
-      assert getChildResources() != null;
     }
 
     @Override
@@ -79,27 +73,13 @@ public class AssertingTermVectorsFormat extends TermVectorsFormat {
 
     @Override
     public long ramBytesUsed() {
-      long v = in.ramBytesUsed();
-      assert v >= 0;
-      return v;
-    }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      Iterable<? extends Accountable> res = in.getChildResources();
-      TestUtil.checkIterator(res.iterator());
-      return res;
+      return in.ramBytesUsed();
     }
 
     @Override
     public void checkIntegrity() throws IOException {
       in.checkIntegrity();
     }
-    
-    @Override
-    public String toString() {
-      return getClass().getSimpleName() + "(" + in.toString() + ")";
-    }
   }
 
   enum Status {
diff --git lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
index f811984..54179d3 100644
--- lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
+++ lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java
@@ -46,7 +46,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
@@ -96,11 +95,6 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
       }
       return sizeInBytes;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Accountables.namedAccountables("field", fieldToTerms);
-    }
 
     @Override
     public void checkIntegrity() throws IOException {}
@@ -129,11 +123,6 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
     }
 
     @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
-
-    @Override
     public long size() {
       return termToDocs.size();
     }
@@ -195,11 +184,6 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
       }
       return sizeInBytes;
     }
-
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   static class RAMDoc implements Accountable {
@@ -224,11 +208,6 @@ public final class RAMOnlyPostingsFormat extends PostingsFormat {
       }
       return sizeInBytes;
     }
-    
-    @Override
-    public Iterable<? extends Accountable> getChildResources() {
-      return Collections.emptyList();
-    }
   }
 
   // Classes for writing to the postings state
diff --git lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
index 33b442f..35ac91c 100644
--- lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
+++ lucene/test-framework/src/java/org/apache/lucene/util/TestUtil.java
@@ -29,10 +29,8 @@ import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.Arrays;
 import java.util.HashMap;
-import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.NoSuchElementException;
 import java.util.Random;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.TimeUnit;
@@ -69,7 +67,6 @@ import org.apache.lucene.index.ConcurrentMergeScheduler;
 import org.apache.lucene.index.DocsAndPositionsEnum;
 import org.apache.lucene.index.DocsEnum;
 import org.apache.lucene.index.FieldInfo.DocValuesType;
-import org.apache.lucene.index.FilterAtomicReader;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexableField;
@@ -77,7 +74,6 @@ import org.apache.lucene.index.LogMergePolicy;
 import org.apache.lucene.index.MergePolicy;
 import org.apache.lucene.index.MergeScheduler;
 import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.SegmentReader;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.TieredMergePolicy;
@@ -131,66 +127,6 @@ public final class TestUtil {
     }
   }
   
-  /** 
-   * Checks that the provided iterator is well-formed.
-   * <ul>
-   *   <li>is read-only: does not allow {@code remove}
-   *   <li>returns {@code expectedSize} number of elements
-   *   <li>does not return null elements, unless {@code allowNull} is true.
-   *   <li>throws NoSuchElementException if {@code next} is called
-   *       after {@code hasNext} returns false. 
-   * </ul>
-   */
-  public static <T> void checkIterator(Iterator<T> iterator, long expectedSize, boolean allowNull) {
-    for (long i = 0; i < expectedSize; i++) {
-      boolean hasNext = iterator.hasNext();
-      assert hasNext;
-      T v = iterator.next();
-      assert allowNull || v != null;
-      try {
-        iterator.remove();
-        throw new AssertionError("broken iterator (supports remove): " + iterator);
-      } catch (UnsupportedOperationException expected) {
-        // ok
-      }
-    }
-    assert !iterator.hasNext();
-    try {
-      iterator.next();
-      throw new AssertionError("broken iterator (allows next() when hasNext==false) " + iterator);
-    } catch (NoSuchElementException expected) {
-      // ok
-    }
-  }
-  
-  /** 
-   * Checks that the provided iterator is well-formed.
-   * <ul>
-   *   <li>is read-only: does not allow {@code remove}
-   *   <li>does not return null elements.
-   *   <li>throws NoSuchElementException if {@code next} is called
-   *       after {@code hasNext} returns false. 
-   * </ul>
-   */
-  public static <T> void checkIterator(Iterator<T> iterator) {
-    while (iterator.hasNext()) {
-      T v = iterator.next();
-      assert v != null;
-      try {
-        iterator.remove();
-        throw new AssertionError("broken iterator (supports remove): " + iterator);
-      } catch (UnsupportedOperationException expected) {
-        // ok
-      }
-    }
-    try {
-      iterator.next();
-      throw new AssertionError("broken iterator (allows next() when hasNext==false) " + iterator);
-    } catch (NoSuchElementException expected) {
-      // ok
-    }
-  }
-  
   public static void syncConcurrentMerges(IndexWriter writer) {
     syncConcurrentMerges(writer.getConfig().getMergeScheduler());
   }
@@ -254,16 +190,6 @@ public final class TestUtil {
     if (LuceneTestCase.INFOSTREAM) {
       System.out.println(bos.toString(IOUtils.UTF_8));
     }
-    
-    AtomicReader unwrapped = FilterAtomicReader.unwrap(reader);
-    if (unwrapped instanceof SegmentReader) {
-      SegmentReader sr = (SegmentReader) unwrapped;
-      long bytesUsed = sr.ramBytesUsed(); 
-      if (sr.ramBytesUsed() < 0) {
-        throw new IllegalStateException("invalid ramBytesUsed for reader: " + bytesUsed);
-      }
-      assert Accountables.toString(sr) != null;
-    }
   }
 
   /** start and end are BOTH inclusive */
diff --git lucene/tools/javadoc/ecj.javadocs.prefs lucene/tools/javadoc/ecj.javadocs.prefs
index b739886..51ef22a 100644
--- lucene/tools/javadoc/ecj.javadocs.prefs
+++ lucene/tools/javadoc/ecj.javadocs.prefs
@@ -1,7 +1,7 @@
 #Sun Sep 23 20:55:03 EDT 2012
 eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.7
-org.eclipse.jdt.core.compiler.compliance=1.7
+org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.8
+org.eclipse.jdt.core.compiler.compliance=1.8
 org.eclipse.jdt.core.compiler.doc.comment.support=enabled
 org.eclipse.jdt.core.compiler.problem.annotationSuperInterface=ignore
 org.eclipse.jdt.core.compiler.problem.assertIdentifier=error
@@ -88,4 +88,4 @@ org.eclipse.jdt.core.compiler.problem.unusedParameterWhenOverridingConcrete=disa
 org.eclipse.jdt.core.compiler.problem.unusedPrivateMember=ignore
 org.eclipse.jdt.core.compiler.problem.unusedWarningToken=ignore
 org.eclipse.jdt.core.compiler.problem.varargsArgumentNeedCast=ignore
-org.eclipse.jdt.core.compiler.source=1.7
+org.eclipse.jdt.core.compiler.source=1.8
diff --git lucene/tools/javadoc/java7/package-list lucene/tools/javadoc/java7/package-list
deleted file mode 100644
index b52fe94..0000000
--- lucene/tools/javadoc/java7/package-list
+++ /dev/null
@@ -1,209 +0,0 @@
-java.applet
-java.awt
-java.awt.color
-java.awt.datatransfer
-java.awt.dnd
-java.awt.event
-java.awt.font
-java.awt.geom
-java.awt.im
-java.awt.im.spi
-java.awt.image
-java.awt.image.renderable
-java.awt.print
-java.beans
-java.beans.beancontext
-java.io
-java.lang
-java.lang.annotation
-java.lang.instrument
-java.lang.invoke
-java.lang.management
-java.lang.ref
-java.lang.reflect
-java.math
-java.net
-java.nio
-java.nio.channels
-java.nio.channels.spi
-java.nio.charset
-java.nio.charset.spi
-java.nio.file
-java.nio.file.attribute
-java.nio.file.spi
-java.rmi
-java.rmi.activation
-java.rmi.dgc
-java.rmi.registry
-java.rmi.server
-java.security
-java.security.acl
-java.security.cert
-java.security.interfaces
-java.security.spec
-java.sql
-java.text
-java.text.spi
-java.util
-java.util.concurrent
-java.util.concurrent.atomic
-java.util.concurrent.locks
-java.util.jar
-java.util.logging
-java.util.prefs
-java.util.regex
-java.util.spi
-java.util.zip
-javax.accessibility
-javax.activation
-javax.activity
-javax.annotation
-javax.annotation.processing
-javax.crypto
-javax.crypto.interfaces
-javax.crypto.spec
-javax.imageio
-javax.imageio.event
-javax.imageio.metadata
-javax.imageio.plugins.bmp
-javax.imageio.plugins.jpeg
-javax.imageio.spi
-javax.imageio.stream
-javax.jws
-javax.jws.soap
-javax.lang.model
-javax.lang.model.element
-javax.lang.model.type
-javax.lang.model.util
-javax.management
-javax.management.loading
-javax.management.modelmbean
-javax.management.monitor
-javax.management.openmbean
-javax.management.relation
-javax.management.remote
-javax.management.remote.rmi
-javax.management.timer
-javax.naming
-javax.naming.directory
-javax.naming.event
-javax.naming.ldap
-javax.naming.spi
-javax.net
-javax.net.ssl
-javax.print
-javax.print.attribute
-javax.print.attribute.standard
-javax.print.event
-javax.rmi
-javax.rmi.CORBA
-javax.rmi.ssl
-javax.script
-javax.security.auth
-javax.security.auth.callback
-javax.security.auth.kerberos
-javax.security.auth.login
-javax.security.auth.spi
-javax.security.auth.x500
-javax.security.cert
-javax.security.sasl
-javax.sound.midi
-javax.sound.midi.spi
-javax.sound.sampled
-javax.sound.sampled.spi
-javax.sql
-javax.sql.rowset
-javax.sql.rowset.serial
-javax.sql.rowset.spi
-javax.swing
-javax.swing.border
-javax.swing.colorchooser
-javax.swing.event
-javax.swing.filechooser
-javax.swing.plaf
-javax.swing.plaf.basic
-javax.swing.plaf.metal
-javax.swing.plaf.multi
-javax.swing.plaf.nimbus
-javax.swing.plaf.synth
-javax.swing.table
-javax.swing.text
-javax.swing.text.html
-javax.swing.text.html.parser
-javax.swing.text.rtf
-javax.swing.tree
-javax.swing.undo
-javax.tools
-javax.transaction
-javax.transaction.xa
-javax.xml
-javax.xml.bind
-javax.xml.bind.annotation
-javax.xml.bind.annotation.adapters
-javax.xml.bind.attachment
-javax.xml.bind.helpers
-javax.xml.bind.util
-javax.xml.crypto
-javax.xml.crypto.dom
-javax.xml.crypto.dsig
-javax.xml.crypto.dsig.dom
-javax.xml.crypto.dsig.keyinfo
-javax.xml.crypto.dsig.spec
-javax.xml.datatype
-javax.xml.namespace
-javax.xml.parsers
-javax.xml.soap
-javax.xml.stream
-javax.xml.stream.events
-javax.xml.stream.util
-javax.xml.transform
-javax.xml.transform.dom
-javax.xml.transform.sax
-javax.xml.transform.stax
-javax.xml.transform.stream
-javax.xml.validation
-javax.xml.ws
-javax.xml.ws.handler
-javax.xml.ws.handler.soap
-javax.xml.ws.http
-javax.xml.ws.soap
-javax.xml.ws.spi
-javax.xml.ws.spi.http
-javax.xml.ws.wsaddressing
-javax.xml.xpath
-org.ietf.jgss
-org.omg.CORBA
-org.omg.CORBA.DynAnyPackage
-org.omg.CORBA.ORBPackage
-org.omg.CORBA.TypeCodePackage
-org.omg.CORBA.portable
-org.omg.CORBA_2_3
-org.omg.CORBA_2_3.portable
-org.omg.CosNaming
-org.omg.CosNaming.NamingContextExtPackage
-org.omg.CosNaming.NamingContextPackage
-org.omg.Dynamic
-org.omg.DynamicAny
-org.omg.DynamicAny.DynAnyFactoryPackage
-org.omg.DynamicAny.DynAnyPackage
-org.omg.IOP
-org.omg.IOP.CodecFactoryPackage
-org.omg.IOP.CodecPackage
-org.omg.Messaging
-org.omg.PortableInterceptor
-org.omg.PortableInterceptor.ORBInitInfoPackage
-org.omg.PortableServer
-org.omg.PortableServer.CurrentPackage
-org.omg.PortableServer.POAManagerPackage
-org.omg.PortableServer.POAPackage
-org.omg.PortableServer.ServantLocatorPackage
-org.omg.PortableServer.portable
-org.omg.SendingContext
-org.omg.stub.java.rmi
-org.w3c.dom
-org.w3c.dom.bootstrap
-org.w3c.dom.events
-org.w3c.dom.ls
-org.xml.sax
-org.xml.sax.ext
-org.xml.sax.helpers
diff --git lucene/tools/javadoc/java8/package-list lucene/tools/javadoc/java8/package-list
new file mode 100644
index 0000000..351c186
--- /dev/null
+++ lucene/tools/javadoc/java8/package-list
@@ -0,0 +1,217 @@
+java.applet
+java.awt
+java.awt.color
+java.awt.datatransfer
+java.awt.dnd
+java.awt.event
+java.awt.font
+java.awt.geom
+java.awt.im
+java.awt.im.spi
+java.awt.image
+java.awt.image.renderable
+java.awt.print
+java.beans
+java.beans.beancontext
+java.io
+java.lang
+java.lang.annotation
+java.lang.instrument
+java.lang.invoke
+java.lang.management
+java.lang.ref
+java.lang.reflect
+java.math
+java.net
+java.nio
+java.nio.channels
+java.nio.channels.spi
+java.nio.charset
+java.nio.charset.spi
+java.nio.file
+java.nio.file.attribute
+java.nio.file.spi
+java.rmi
+java.rmi.activation
+java.rmi.dgc
+java.rmi.registry
+java.rmi.server
+java.security
+java.security.acl
+java.security.cert
+java.security.interfaces
+java.security.spec
+java.sql
+java.text
+java.text.spi
+java.time
+java.time.chrono
+java.time.format
+java.time.temporal
+java.time.zone
+java.util
+java.util.concurrent
+java.util.concurrent.atomic
+java.util.concurrent.locks
+java.util.function
+java.util.jar
+java.util.logging
+java.util.prefs
+java.util.regex
+java.util.spi
+java.util.stream
+java.util.zip
+javax.accessibility
+javax.activation
+javax.activity
+javax.annotation
+javax.annotation.processing
+javax.crypto
+javax.crypto.interfaces
+javax.crypto.spec
+javax.imageio
+javax.imageio.event
+javax.imageio.metadata
+javax.imageio.plugins.bmp
+javax.imageio.plugins.jpeg
+javax.imageio.spi
+javax.imageio.stream
+javax.jws
+javax.jws.soap
+javax.lang.model
+javax.lang.model.element
+javax.lang.model.type
+javax.lang.model.util
+javax.management
+javax.management.loading
+javax.management.modelmbean
+javax.management.monitor
+javax.management.openmbean
+javax.management.relation
+javax.management.remote
+javax.management.remote.rmi
+javax.management.timer
+javax.naming
+javax.naming.directory
+javax.naming.event
+javax.naming.ldap
+javax.naming.spi
+javax.net
+javax.net.ssl
+javax.print
+javax.print.attribute
+javax.print.attribute.standard
+javax.print.event
+javax.rmi
+javax.rmi.CORBA
+javax.rmi.ssl
+javax.script
+javax.security.auth
+javax.security.auth.callback
+javax.security.auth.kerberos
+javax.security.auth.login
+javax.security.auth.spi
+javax.security.auth.x500
+javax.security.cert
+javax.security.sasl
+javax.sound.midi
+javax.sound.midi.spi
+javax.sound.sampled
+javax.sound.sampled.spi
+javax.sql
+javax.sql.rowset
+javax.sql.rowset.serial
+javax.sql.rowset.spi
+javax.swing
+javax.swing.border
+javax.swing.colorchooser
+javax.swing.event
+javax.swing.filechooser
+javax.swing.plaf
+javax.swing.plaf.basic
+javax.swing.plaf.metal
+javax.swing.plaf.multi
+javax.swing.plaf.nimbus
+javax.swing.plaf.synth
+javax.swing.table
+javax.swing.text
+javax.swing.text.html
+javax.swing.text.html.parser
+javax.swing.text.rtf
+javax.swing.tree
+javax.swing.undo
+javax.tools
+javax.transaction
+javax.transaction.xa
+javax.xml
+javax.xml.bind
+javax.xml.bind.annotation
+javax.xml.bind.annotation.adapters
+javax.xml.bind.attachment
+javax.xml.bind.helpers
+javax.xml.bind.util
+javax.xml.crypto
+javax.xml.crypto.dom
+javax.xml.crypto.dsig
+javax.xml.crypto.dsig.dom
+javax.xml.crypto.dsig.keyinfo
+javax.xml.crypto.dsig.spec
+javax.xml.datatype
+javax.xml.namespace
+javax.xml.parsers
+javax.xml.soap
+javax.xml.stream
+javax.xml.stream.events
+javax.xml.stream.util
+javax.xml.transform
+javax.xml.transform.dom
+javax.xml.transform.sax
+javax.xml.transform.stax
+javax.xml.transform.stream
+javax.xml.validation
+javax.xml.ws
+javax.xml.ws.handler
+javax.xml.ws.handler.soap
+javax.xml.ws.http
+javax.xml.ws.soap
+javax.xml.ws.spi
+javax.xml.ws.spi.http
+javax.xml.ws.wsaddressing
+javax.xml.xpath
+org.ietf.jgss
+org.omg.CORBA
+org.omg.CORBA.DynAnyPackage
+org.omg.CORBA.ORBPackage
+org.omg.CORBA.TypeCodePackage
+org.omg.CORBA.portable
+org.omg.CORBA_2_3
+org.omg.CORBA_2_3.portable
+org.omg.CosNaming
+org.omg.CosNaming.NamingContextExtPackage
+org.omg.CosNaming.NamingContextPackage
+org.omg.Dynamic
+org.omg.DynamicAny
+org.omg.DynamicAny.DynAnyFactoryPackage
+org.omg.DynamicAny.DynAnyPackage
+org.omg.IOP
+org.omg.IOP.CodecFactoryPackage
+org.omg.IOP.CodecPackage
+org.omg.Messaging
+org.omg.PortableInterceptor
+org.omg.PortableInterceptor.ORBInitInfoPackage
+org.omg.PortableServer
+org.omg.PortableServer.CurrentPackage
+org.omg.PortableServer.POAManagerPackage
+org.omg.PortableServer.POAPackage
+org.omg.PortableServer.ServantLocatorPackage
+org.omg.PortableServer.portable
+org.omg.SendingContext
+org.omg.stub.java.rmi
+org.w3c.dom
+org.w3c.dom.bootstrap
+org.w3c.dom.events
+org.w3c.dom.ls
+org.w3c.dom.views
+org.xml.sax
+org.xml.sax.ext
+org.xml.sax.helpers
diff --git solr/CHANGES.txt solr/CHANGES.txt
index 408572a..d066595 100644
--- solr/CHANGES.txt
+++ solr/CHANGES.txt
@@ -207,8 +207,6 @@ Bug Fixes
 * SOLR-6501: Binary Response Writer does not return wildcard fields.
   (Mike Hugo, Constantin Mitocaru, sarowe, shalin)
 
-* SOLR-6507: Fixed several bugs involving stats.field used with local params (hossman)
-
 Other Changes
 ---------------------
 
diff --git solr/README.txt solr/README.txt
index 13f4ca3..50b5d09 100644
--- solr/README.txt
+++ solr/README.txt
@@ -58,10 +58,10 @@ docs/index.html
 Instructions for Building Apache Solr from Source
 -------------------------------------------------
 
-1. Download the Java SE 7 JDK (Java Development Kit) or later from http://java.sun.com/
+1. Download the Java SE 8 JDK (Java Development Kit) or later from http://www.oracle.com/java/
    You will need the JDK installed, and the $JAVA_HOME/bin (Windows: %JAVA_HOME%\bin) 
    folder included on your command path. To test this, issue a "java -version" command 
-   from your shell (command prompt) and verify that the Java version is 1.7 or later.
+   from your shell (command prompt) and verify that the Java version is 1.8 or later.
 
 2. Download the Apache Ant binary distribution (1.8.2+) from 
    http://ant.apache.org/  You will need Ant installed and the $ANT_HOME/bin (Windows: 
diff --git solr/SYSTEM_REQUIREMENTS.txt solr/SYSTEM_REQUIREMENTS.txt
index a14c8f5..2c0fa87 100644
--- solr/SYSTEM_REQUIREMENTS.txt
+++ solr/SYSTEM_REQUIREMENTS.txt
@@ -1,9 +1,6 @@
 # System Requirements 
 
-Apache Solr runs of Java 7 or greater, Java 8 is verified to be
-compatible and may bring some performance improvements. When using
-Oracle Java 7 or OpenJDK 7, be sure to not use the GA build 147 or
-update versions u40, u45 and u51! We recommend using u55 or later.
+Apache Solr runs of Java 8 or greater.
 
 It is also recommended to always use the latest update version of your
 Java VM, because bugs may affect Solr. An overview of known JVM bugs
diff --git solr/bin/solr.cmd solr/bin/solr.cmd
index 3c3b237..225fea0 100644
--- solr/bin/solr.cmd
+++ solr/bin/solr.cmd
@@ -33,7 +33,7 @@ set NO_USER_PROMPT=0
 REM Verify Java is available
 if NOT DEFINED JAVA_HOME goto need_java_home
 "%JAVA_HOME%"\bin\java -version:1.8 -version > nul 2>&1
-IF ERRORLEVEL 1 "%JAVA_HOME%"\bin\java -version:1.7 -version > nul 2>&1
+IF ERRORLEVEL 1 "%JAVA_HOME%"\bin\java -version:1.8 -version > nul 2>&1
 IF ERRORLEVEL 1 goto need_java_vers
 set "JAVA=%JAVA_HOME%\bin\java"
 
@@ -698,11 +698,11 @@ IF "%FIRST_ARG%"=="start" (
 )
 
 :need_java_home
-@echo Please set the JAVA_HOME environment variable to the path where you installed Java 1.7+
+@echo Please set the JAVA_HOME environment variable to the path where you installed Java 1.8+
 goto done
 
 :need_java_vers
-@echo Java 1.7 or later is required to run Solr.
+@echo Java 1.8 or later is required to run Solr.
 goto done
 
 :err
diff --git solr/build.xml solr/build.xml
index 45dba5a..dab7d77 100644
--- solr/build.xml
+++ solr/build.xml
@@ -375,7 +375,7 @@
     <svn-export-source source.dir=".."/>
 
     <!-- Exclude javadoc package-list files under licenses incompatible with the ASL -->
-    <delete dir="${svn.export.dir}/lucene/tools/javadoc/java7"/>
+    <delete dir="${svn.export.dir}/lucene/tools/javadoc/java8"/>
     <!-- Exclude clover license files incompatible with the ASL -->
     <delete dir="${svn.export.dir}/lucene/tools/clover"/>
 
diff --git solr/common-build.xml solr/common-build.xml
index 7c2a145..2342215 100644
--- solr/common-build.xml
+++ solr/common-build.xml
@@ -25,9 +25,9 @@
   
   <property name="Name" value="Solr" />
   
-  <!-- solr uses 1.7 -->
-  <property name="javac.source" value="1.7"/>
-  <property name="javac.target" value="1.7"/>
+  <!-- solr uses 1.8 -->
+  <property name="javac.source" value="1.8"/>
+  <property name="javac.target" value="1.8"/>
   <property name="javac.args" value=""/>
   
   <property name="dest" location="${common-solr.dir}/build" />
diff --git solr/contrib/analytics/build.xml solr/contrib/analytics/build.xml
deleted file mode 100644
index 4a6926b..0000000
--- solr/contrib/analytics/build.xml
+++ /dev/null
@@ -1,33 +0,0 @@
-<?xml version="1.0"?>
-
-<!--
-    Licensed to the Apache Software Foundation (ASF) under one or more
-    contributor license agreements.  See the NOTICE file distributed with
-    this work for additional information regarding copyright ownership.
-    The ASF licenses this file to You under the Apache License, Version 2.0
-    the "License"); you may not use this file except in compliance with
-    the License.  You may obtain a copy of the License at
- 
-        http://www.apache.org/licenses/LICENSE-2.0
- 
-    Unless required by applicable law or agreed to in writing, software
-    distributed under the License is distributed on an "AS IS" BASIS,
-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-    See the License for the specific language governing permissions and
-    limitations under the License.
- -->
-
-<project name="solr-analytics" default="default">
-
-  <description>
-    Analytics Package
-  </description>
-
-  <import file="../contrib-build.xml"/>
-
-  <path id="test.classpath">
-    <path refid="solr.test.base.classpath"/>
-    <fileset dir="${test.lib.dir}" includes="*.jar"/>
-  </path>
-
-</project>
diff --git solr/contrib/analytics/ivy.xml solr/contrib/analytics/ivy.xml
deleted file mode 100644
index ef3c87d..0000000
--- solr/contrib/analytics/ivy.xml
+++ /dev/null
@@ -1,30 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one
-   or more contributor license agreements.  See the NOTICE file
-   distributed with this work for additional information
-   regarding copyright ownership.  The ASF licenses this file
-   to you under the Apache License, Version 2.0 (the
-   "License"); you may not use this file except in compliance
-   with the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing,
-   software distributed under the License is distributed on an
-   "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-   KIND, either express or implied.  See the License for the
-   specific language governing permissions and limitations
-   under the License.    
--->
-<ivy-module version="2.0">
-    <info organisation="org.apache.solr" module="analytics"/>
-      <configurations>
-        <conf name="compile" transitive="false"/>
-        <conf name="test" transitive="false"/>
-      </configurations>
-
-     <dependencies>
-       <dependency org="org.slf4j" name="jcl-over-slf4j" rev="${/org.slf4j/jcl-over-slf4j}" conf="test->*"/>
-     </dependencies>
-
-</ivy-module>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java
deleted file mode 100644
index fdcf66b..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java
+++ /dev/null
@@ -1,170 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Date;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.solr.analytics.expression.Expression;
-import org.apache.solr.analytics.expression.ExpressionFactory;
-import org.apache.solr.analytics.request.AnalyticsRequest;
-import org.apache.solr.analytics.request.ExpressionRequest;
-import org.apache.solr.analytics.statistics.StatsCollector;
-import org.apache.solr.analytics.statistics.StatsCollectorSupplierFactory;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.search.DocSet;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.google.common.base.Supplier;
-
-/**
- * A <code>BasicAccumulator</code> manages the ValueCounters and Expressions without regard to Facets.
- */
-public class BasicAccumulator extends ValueAccumulator {
-  private static final Logger log = LoggerFactory.getLogger(BasicAccumulator.class);
-  protected final SolrIndexSearcher searcher;
-  protected final AnalyticsRequest request;
-  protected final DocSet docs;
-  protected final Supplier<StatsCollector[]> statsCollectorArraySupplier;
-  protected final StatsCollector[] statsCollectors;
-  protected final Expression[] expressions;
-  protected final String[] expressionNames;
-  protected final String[] expressionStrings;
-  protected final Set<String> hiddenExpressions;
-  protected AtomicReaderContext context = null;
-  
-  public BasicAccumulator(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request) throws IOException {
-    this.searcher = searcher;
-    this.docs = docs;
-    this.request = request;
-    final List<ExpressionRequest> exRequests = new ArrayList<ExpressionRequest>(request.getExpressions()); // make a copy here
-    Collections.sort(exRequests);
-    log.info("Processing request '"+request.getName()+"'");
-    statsCollectorArraySupplier = StatsCollectorSupplierFactory.create(searcher.getSchema(), exRequests);
-    statsCollectors = statsCollectorArraySupplier.get();
-    int size = exRequests.size();
-    expressionNames = new String[size];
-    expressionStrings = new String[size];
-    int count = 0;
-    for (ExpressionRequest expRequest : exRequests) {
-      expressionNames[count] = expRequest.getName();
-      expressionStrings[count++] = expRequest.getExpressionString();
-    }
-    expressions = makeExpressions(statsCollectors);
-    hiddenExpressions = request.getHiddenExpressions();
-  }
-  
-  @Override
-  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
-    this.context = context;
-    for (StatsCollector counter : statsCollectors) {
-      counter.setNextReader(context);
-    }
-  }
- 
-  public static BasicAccumulator create(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request) throws IOException {
-    return new BasicAccumulator(searcher,docs,request);
-  }
-  
-  /**
-   * Passes the documents on to the {@link StatsCollector}s to be collected.
-   * @param doc Document to collect from
-   */
-  @Override
-  public void collect(int doc) throws IOException {
-    for (StatsCollector statsCollector : statsCollectors) {
-      statsCollector.collect(doc);
-    }
-  }
-  
-  @Override
-  public void compute() {
-    for (StatsCollector statsCollector : statsCollectors) {
-      statsCollector.compute();
-    }
-  }
-  
-  public NamedList<?> export(){
-    NamedList<Object> base = new NamedList<>();
-    for (int count = 0; count < expressions.length; count++) {
-      if (!hiddenExpressions.contains(expressionNames[count])) {
-        base.add(expressionNames[count], expressions[count].getValue());
-      }
-    }
-    return base;
-  }
-  
-  /**
-   * Builds an array of Expressions with the given list of counters
-   * @param statsCollectors the stats collectors
-   * @return The array of Expressions
-   */
-  public Expression[] makeExpressions(StatsCollector[] statsCollectors) {
-   Expression[] expressions = new Expression[expressionStrings.length];
-    for (int count = 0; count < expressionStrings.length; count++) {
-      expressions[count] = ExpressionFactory.create(expressionStrings[count], statsCollectors);
-    }
-    return expressions;
-  }
-  
-  /**
-   * Returns the value of an expression to use in a field or query facet.
-   * @param expressionName the name of the expression
-   * @return String String representation of pivot value
-   */
-  @SuppressWarnings({ "deprecation", "rawtypes" })
-  public String getResult(String expressionName) {
-    for (int count = 0; count < expressionNames.length; count++) {
-      if (expressionName.equals(expressionNames[count])) {
-        Comparable value = expressions[count].getValue();
-        if (value.getClass().equals(Date.class)) {
-          return TrieDateField.formatExternal((Date)value);
-        } else {
-          return value.toString();
-        }
-      }
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST, "Pivot expression "+expressionName+" not found.");
-  }
-
-  /**
-   * Used for JMX stats collecting. Counts the number of stats requests
-   * @return number of unique stats collectors
-   */
-  public long getNumStatsCollectors() {
-    return statsCollectors.length;
-  }
-
-  /**
-   * Used for JMX stats collecting. Counts the number of queries in all query facets
-   * @return number of queries requested in all query facets.
-   */
-  public long getNumQueries() {
-    return 0l;
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
deleted file mode 100644
index fb6d81d..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
+++ /dev/null
@@ -1,723 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.Date;
-import java.util.HashSet;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-import java.util.TreeMap;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.solr.analytics.accumulator.facet.FacetValueAccumulator;
-import org.apache.solr.analytics.accumulator.facet.FieldFacetAccumulator;
-import org.apache.solr.analytics.accumulator.facet.QueryFacetAccumulator;
-import org.apache.solr.analytics.accumulator.facet.RangeFacetAccumulator;
-import org.apache.solr.analytics.expression.Expression;
-import org.apache.solr.analytics.expression.ExpressionFactory;
-import org.apache.solr.analytics.request.AnalyticsContentHandler;
-import org.apache.solr.analytics.request.AnalyticsRequest;
-import org.apache.solr.analytics.request.FieldFacetRequest;
-import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
-import org.apache.solr.analytics.request.QueryFacetRequest;
-import org.apache.solr.analytics.request.RangeFacetRequest;
-import org.apache.solr.analytics.statistics.StatsCollector;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.analytics.util.RangeEndpointCalculator;
-import org.apache.solr.analytics.util.RangeEndpointCalculator.FacetRange;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.schema.SchemaField;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.search.DocSet;
-import org.apache.solr.search.QParser;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.apache.solr.search.SyntaxError;
-
-import com.google.common.collect.Iterables;
-
-/**
- * A <code>FacetingAccumulator</code> manages the StatsCollectors and Expressions for facets.
- */
-public class FacetingAccumulator extends BasicAccumulator implements FacetValueAccumulator {
-  public static final String MISSING_VALUE = "(MISSING)";
-  protected boolean basicsAndFieldFacetsComputed;
-  protected int leafNum;
-  protected AtomicReaderContext leaf;
-  protected final AnalyticsRequest analyticsRequest;
-  protected final Map<String,Map<String,Expression[]>> fieldFacetExpressions;
-  protected final Map<String,Map<String,Expression[]>> rangeFacetExpressions;
-  protected final Map<String,Map<String,Expression[]>> queryFacetExpressions;
-  protected final Map<String,Map<String,StatsCollector[]>> fieldFacetCollectors;
-  protected final Map<String,Map<String,StatsCollector[]>> rangeFacetCollectors;
-  protected final Map<String,Map<String,StatsCollector[]>> queryFacetCollectors;
-  protected final List<FieldFacetAccumulator> facetAccumulators;
-  protected final Set<String> hiddenFieldFacets;
-  /** the current value of this stat field */
-  protected final SolrQueryRequest queryRequest;
-  
-  protected List<RangeFacetRequest> rangeFacets = null;
-  protected List<QueryFacetRequest> queryFacets = null;
-  
-  protected long queryCount;
-  
-  public FacetingAccumulator(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request, SolrQueryRequest queryRequest) throws IOException {
-    // The parent Basic Accumulator keeps track of overall stats while
-    // the Faceting Accumulator only manages the facet stats
-    super(searcher, docs, request);
-    this.analyticsRequest = request;
-    this.queryRequest = queryRequest;
-    basicsAndFieldFacetsComputed = false;
-    List<FieldFacetRequest> fieldFreqs = request.getFieldFacets();
-    List<RangeFacetRequest> rangeFreqs = request.getRangeFacets();
-    List<QueryFacetRequest> queryFreqs = request.getQueryFacets();
-
-    this.fieldFacetExpressions = new TreeMap<>();
-    this.rangeFacetExpressions = new LinkedHashMap<>(rangeFreqs.size());
-    this.queryFacetExpressions = new LinkedHashMap<>(queryFreqs.size());
-    this.fieldFacetCollectors = new LinkedHashMap<>(fieldFreqs.size());
-    this.rangeFacetCollectors = new LinkedHashMap<>(rangeFreqs.size());
-    this.queryFacetCollectors = new LinkedHashMap<>(queryFreqs.size());
-    this.facetAccumulators = new ArrayList<>();
-    this.hiddenFieldFacets = new HashSet<>();
-    
-    /**
-     * For each field facet request add a bucket to the {@link Expression} map and {@link StatsCollector} map.
-     * Field facets are computed during the initial collection of documents, therefore
-     * the FieldFacetAccumulators are created initially.
-     */
-    for( FieldFacetRequest freq : fieldFreqs ){
-      final FieldFacetRequest fr = (FieldFacetRequest) freq;
-      if (fr.isHidden()) {
-        hiddenFieldFacets.add(fr.getName());
-      }
-      final SchemaField ff = fr.getField();
-      final FieldFacetAccumulator facc = FieldFacetAccumulator.create(searcher, this, ff);
-      facetAccumulators.add(facc);
-      fieldFacetExpressions.put(freq.getName(), new TreeMap<String, Expression[]>() );
-      fieldFacetCollectors.put(freq.getName(), new TreeMap<String,StatsCollector[]>());
-    }
-    /**
-     * For each range and query facet request add a bucket to the corresponding
-     * {@link Expression} map and {@link StatsCollector} map.
-     * Range and Query Facets are computed in the post processing, so the accumulators
-     * are not created initially.
-     */
-    for( RangeFacetRequest freq : rangeFreqs ){
-      if( rangeFacets == null ) rangeFacets = new ArrayList<>();
-      rangeFacets.add(freq);
-      rangeFacetExpressions.put(freq.getName(), new LinkedHashMap<String,Expression[]>() );
-      rangeFacetCollectors.put(freq.getName(), new LinkedHashMap<String,StatsCollector[]>());
-    }
-    for( QueryFacetRequest freq : queryFreqs ){
-      if( queryFacets == null ) queryFacets = new ArrayList<>();
-      queryFacets.add(freq);
-      queryFacetExpressions.put(freq.getName(), new LinkedHashMap<String,Expression[]>() );
-      queryFacetCollectors.put(freq.getName(), new LinkedHashMap<String,StatsCollector[]>());
-    }
-    this.queryCount = 0l;
-  }
-  
-  public static FacetingAccumulator create(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request, SolrQueryRequest queryRequest) throws IOException {
-    return new FacetingAccumulator(searcher,docs,request,queryRequest);
-  }
-
-  /**
-   * Update the readers for the {@link BasicAccumulator}, field facets and field facet {@link StatsCollector}s.
-   * @param context The context to read documents from.
-   * @throws IOException if there is an error setting the next reader
-   */
-  @Override
-  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
-    super.doSetNextReader(context);
-    for( Map<String,StatsCollector[]> valueList : fieldFacetCollectors.values() ){
-      for (StatsCollector[] statsCollectorList : valueList.values()) {
-        for (StatsCollector statsCollector : statsCollectorList) {
-          statsCollector.setNextReader(context);
-        }
-      }
-    }
-    for (FieldFacetAccumulator fa : facetAccumulators) {
-      fa.getLeafCollector(context);
-    }
-  }
-  
-  /**
-   * Updates the reader for all of the range facet {@link StatsCollector}s.
-   * @param context The context to read documents from.
-   * @throws IOException if there is an error setting the next reader
-   */
-  public void setRangeStatsCollectorReaders(AtomicReaderContext context) throws IOException {
-    super.getLeafCollector(context);
-    for( Map<String,StatsCollector[]> rangeList : rangeFacetCollectors.values() ){
-      for (StatsCollector[] statsCollectorList : rangeList.values()) {
-        for (StatsCollector statsCollector : statsCollectorList) {
-          statsCollector.setNextReader(context);
-        }
-      }
-    }
-  }
-
-  
-  /**
-   * Updates the reader for all of the query facet {@link StatsCollector}s.
-   * @param context The context to read documents from.
-   * @throws IOException if there is an error setting the next reader
-   */
-  public void setQueryStatsCollectorReaders(AtomicReaderContext context) throws IOException {
-    super.getLeafCollector(context);
-    for( Map<String,StatsCollector[]> queryList : queryFacetCollectors.values() ){
-      for (StatsCollector[] statsCollectorList : queryList.values()) {
-        for (StatsCollector statsCollector : statsCollectorList) {
-          statsCollector.setNextReader(context);
-        }
-      }
-    }
-  }
-
-  /**
-   * Called from Analytics stats, adds documents to the field 
-   * facets and the super {@link BasicAccumulator}.
-   */
-  @Override
-  public void collect(int doc) throws IOException {
-    for( FieldFacetAccumulator fa : facetAccumulators ){
-      fa.collect(doc);
-    }
-    super.collect(doc);
-  }
-  
-  /**
-   * Given a document, fieldFacet field and facetValue, adds the document to the
-   * {@link StatsCollector}s held in the bucket corresponding to the fieldFacet field and facetValue.
-   * Called during initial document collection.
-   */
-  @Override
-  public void collectField(int doc, String facetField, String facetValue) throws IOException {
-    Map<String,StatsCollector[]> map = fieldFacetCollectors.get(facetField);
-    StatsCollector[] statsCollectors = map.get(facetValue);
-    // If the facetValue has not been seen yet, a StatsCollector array is
-    // created and associated with that bucket.
-    if( statsCollectors == null ){
-      statsCollectors = statsCollectorArraySupplier.get();
-      map.put(facetValue,statsCollectors);
-      fieldFacetExpressions.get(facetField).put(facetValue,makeExpressions(statsCollectors));
-      for (StatsCollector statsCollector : statsCollectors) {
-        statsCollector.setNextReader(context);
-      }
-    }
-    for (StatsCollector statsCollector : statsCollectors) {
-      statsCollector.collect(doc);
-    }
-  }
-  
-  /**
-   * Given a document, rangeFacet field and range, adds the document to the
-   * {@link StatsCollector}s held in the bucket corresponding to the rangeFacet field and range.
-   * Called during post processing.
-   */
-  @Override
-  public void collectRange(int doc, String facetField, String range) throws IOException {
-    Map<String,StatsCollector[]> map = rangeFacetCollectors.get(facetField);
-    StatsCollector[] statsCollectors = map.get(range);
-    // If the range has not been seen yet, a StatsCollector array is
-    // created and associated with that bucket.
-    if( statsCollectors == null ){
-      statsCollectors = statsCollectorArraySupplier.get();
-      map.put(range,statsCollectors);
-      rangeFacetExpressions.get(facetField).put(range,makeExpressions(statsCollectors));
-      for (StatsCollector statsCollector : statsCollectors) {
-        statsCollector.setNextReader(context);
-      }
-    }
-    for (StatsCollector statsCollector : statsCollectors) {
-      statsCollector.collect(doc);
-    }
-  }
-  
-  /**
-   * Given a document, queryFacet name and query, adds the document to the
-   * {@link StatsCollector}s held in the bucket corresponding to the queryFacet name and query.
-   * Called during post processing.
-   */
-  @Override
-  public void collectQuery(int doc, String facetName, String query) throws IOException {
-    Map<String,StatsCollector[]> map = queryFacetCollectors.get(facetName);
-    StatsCollector[] statsCollectors = map.get(query);
-    // If the query has not been seen yet, a StatsCollector array is
-    // created and associated with that bucket.
-    if( statsCollectors == null ){
-      statsCollectors = statsCollectorArraySupplier.get();
-      map.put(query,statsCollectors);
-      queryFacetExpressions.get(facetName).put(query,makeExpressions(statsCollectors));
-      for (StatsCollector statsCollector : statsCollectors) {
-        statsCollector.setNextReader(context);
-      }
-    }
-    for (StatsCollector statsCollector : statsCollectors) {
-      statsCollector.collect(doc);
-    }
-  }
-
-  /**
-   * A comparator to compare expression values for field facet sorting.
-   */
-  public static class EntryComparator implements Comparator<Entry<String,Expression[]>> {
-    private final Comparator<Expression> comp;
-    private final int comparatorExpressionPlace;
-   
-    public EntryComparator(Comparator<Expression> comp, int comparatorExpressionPlace) {
-      this.comp = comp;
-      this.comparatorExpressionPlace = comparatorExpressionPlace;
-    }
-
-    @Override
-    public int compare(Entry<String,Expression[]> o1, Entry<String,Expression[]> o2) {
-      return comp.compare(o1.getValue()[comparatorExpressionPlace], o2.getValue()[comparatorExpressionPlace]);
-    }
-  }
-  
-  /**
-   * Finalizes the statistics within the each facet bucket before exporting;
-   */
-  @Override
-  public void compute() {
-    if (!basicsAndFieldFacetsComputed) {
-      super.compute();
-      for( Map<String, StatsCollector[]> f : fieldFacetCollectors.values() ){
-        for( StatsCollector[] arr : f.values() ){
-          for( StatsCollector b : arr ){
-            b.compute();
-          }
-        }
-      }
-      basicsAndFieldFacetsComputed = true;
-    }
-  }
-  
-  /**
-   * Finalizes the statistics within the a specific query facet before exporting;
-   */
-  public void computeQueryFacet(String facet) {
-    Map<String, StatsCollector[]> f = queryFacetCollectors.get(facet);
-    for( StatsCollector[] arr : f.values() ){
-      for( StatsCollector b : arr ){
-        b.compute();
-      }
-    }
-  }
-  
-  /**
-   * Finalizes the statistics within the a specific range facet before exporting;
-   */
-  public void computeRangeFacet(String facet) {
-    Map<String, StatsCollector[]> f = rangeFacetCollectors.get(facet);
-    for( StatsCollector[] arr : f.values() ){
-      for( StatsCollector b : arr ){
-        b.compute();
-      }
-    }
-  }
-  
-  /**
-   * Returns the value of an expression to use in a range or query facet.
-   * @param expressionName the name of the expression
-   * @param fieldFacet the facet field
-   * @param facetValue the facet value
-   * @return String String representation of pivot value
-   */
-  @SuppressWarnings({ "deprecation", "rawtypes" })
-  public String getResult(String expressionName, String fieldFacet, String facetValue) {
-    if (facetValue.contains(AnalyticsParams.RESULT) && !facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
-      try {
-        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
-        if (pivotStr.length==1) {
-          facetValue = getResult(pivotStr[0]);
-        } else if (pivotStr.length==3) {
-          facetValue = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
-        } else {
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" has an invalid amount of arguments.");
-        }
-      } catch (IndexOutOfBoundsException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" is invalid. Lacks parentheses.",e);
-      }
-    } 
-    if (fieldFacetExpressions.get(fieldFacet)!=null) {
-      Expression[] facetExpressions = fieldFacetExpressions.get(fieldFacet).get(facetValue);
-      for (int count = 0; count < expressionNames.length; count++) {
-        if (expressionName.equals(expressionNames[count])) {
-          Comparable value = facetExpressions[count].getValue();
-          if (value.getClass().equals(Date.class)) {
-            return TrieDateField.formatExternal((Date)value);
-          } else {
-            return value.toString();
-          }
-        }
-      }
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"Field Facet Pivot expression "+expressionName+" not found.");
-  }
-  
-  /**
-   * Returns the value of an expression to use in a range or query facet.
-   * @param currentFacet the name of the current facet
-   * @param expressionName the name of the expression
-   * @param queryFacet the facet query
-   * @param facetValue the field value
-   * @return String String representation of pivot value
-   */
-  @SuppressWarnings({ "deprecation", "rawtypes" })
-  public String getQueryResult(String currentFacet, String expressionName, String queryFacet, String facetValue) {
-    if (facetValue.contains(AnalyticsParams.RESULT) && !facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
-      try {
-        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
-        if (pivotStr.length==1) {
-          facetValue = getResult(pivotStr[0]);
-        } else if (pivotStr.length==3) {
-          facetValue = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
-        } else {
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" has an invalid amount of arguments.");
-        }
-      } catch (IndexOutOfBoundsException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" is invalid. Lacks parentheses.",e);
-      }
-    } 
-    if (facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
-      try {
-        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
-        if (pivotStr.length==1) {
-          facetValue = getResult(pivotStr[0]);
-        } else if (pivotStr.length==3) {
-          facetValue = getQueryResult(currentFacet,pivotStr[0],pivotStr[1],pivotStr[2]);
-        } else {
-          throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" has an invalid amount of arguments.");
-        }
-      } catch (IndexOutOfBoundsException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" is invalid. Lacks parentheses.",e);
-      }
-    } 
-    if (queryFacetExpressions.get(queryFacet)!=null) {
-      Expression[] facetExpressions = queryFacetExpressions.get(queryFacet).get(facetValue);
-      for (int count = 0; count < expressionNames.length; count++) {
-        if (expressionName.equals(expressionNames[count])) {
-          Comparable value = facetExpressions[count].getValue();
-          if (value.getClass().equals(Date.class)) {
-            return TrieDateField.formatExternal((Date)value);
-          } else {
-            return value.toString();
-          }
-        }
-      }
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"Field Facet Pivot expression "+expressionName+" not found.");
-  }
-  
-  @Override
-  @SuppressWarnings("unchecked")
-  public NamedList<?> export() {
-    final NamedList<Object> base = (NamedList<Object>)super.export();
-    NamedList<NamedList<?>> facetList = new NamedList<>();
-    
-    // Add the field facet buckets to the output
-    base.add("fieldFacets",facetList);
-    for( FieldFacetRequest freq : request.getFieldFacets() ){
-      final String name = freq.getName();
-      if (hiddenFieldFacets.contains(name)) {
-        continue;
-      }
-      final Map<String,Expression[]> buckets = fieldFacetExpressions.get(name);
-      final NamedList<Object> bucketBase = new NamedList<>();
-
-      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
-      
-      final FieldFacetRequest fr = (FieldFacetRequest) freq;
-     
-      final FacetSortSpecification sort = fr.getSort();
-      final int limit = fr.getLimit();
-      final int offset = fr.getOffset();
-      final boolean showMissing = fr.showsMissing();
-      if (!showMissing) {
-        buckets.remove(MISSING_VALUE);
-      }
-      // Sorting the buckets if a sort specification is provided
-      if( sort != null && buckets.values().iterator().hasNext()){
-        int sortPlace = Arrays.binarySearch(expressionNames, sort.getStatistic());
-        final Expression first = buckets.values().iterator().next()[sortPlace];
-        final Comparator<Expression> comp = (Comparator<Expression>) first.comparator(sort.getDirection());
-        
-        final List<Entry<String,Expression[]>> sorted = new ArrayList<>(buckets.size());
-        Iterables.addAll(sorted, iter);
-        Collections.sort(sorted, new EntryComparator(comp,sortPlace));
-        iter = sorted;
-      }
-      // apply the limit
-      if( limit > AnalyticsContentHandler.DEFAULT_FACET_LIMIT ){
-        if( offset > 0 ){
-          iter = Iterables.skip(iter, offset);
-        }
-        iter = Iterables.limit(iter, limit);
-      }
-      
-      // Export each expression in the bucket.
-      for( Entry<String,Expression[]> bucket : iter ){
-        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
-      }
-      
-      facetList.add(name, bucketBase);
-    }
-
-    // Add the range facet buckets to the output
-    facetList = new NamedList<>();
-    base.add("rangeFacets",facetList);
-    for( RangeFacetRequest freq : request.getRangeFacets() ){
-      final String name = freq.getName();
-      final Map<String,Expression[]> buckets = rangeFacetExpressions.get(name);
-      final NamedList<Object> bucketBase = new NamedList<>();
-
-      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
-      
-      for( Entry<String,Expression[]> bucket : iter ){
-        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
-      }
-      
-      facetList.add(name, bucketBase);
-    }
-    
-    // Add the query facet buckets to the output
-    facetList = new NamedList<>();
-    base.add("queryFacets",facetList);
-    for( QueryFacetRequest freq : request.getQueryFacets() ){
-      final String name = freq.getName();
-      final Map<String,Expression[]> buckets = queryFacetExpressions.get(name);
-      final NamedList<Object> bucketBase = new NamedList<>();
-
-      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
-      
-      for( Entry<String,Expression[]> bucket : iter ){
-        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
-      }
-      
-      facetList.add(name, bucketBase);
-    }
-
-    return base;
-  }
-  
-  /**
-   * Exports a list of expressions as a NamedList
-   * @param expressionArr an array of expressions
-   * @return named list of expressions
-   */
-  public NamedList<?> export(Expression[] expressionArr) {
-    NamedList<Object> base = new NamedList<>();
-    for (int count = 0; count < expressionArr.length; count++) {
-      if (!hiddenExpressions.contains(expressionNames[count])) {
-        base.add(expressionNames[count], expressionArr[count].getValue());
-      }
-    }
-    return base;
-  }
-
-  /**
-   * Processes the query and range facets.
-   * Must be called if range and/or query facets are supported.
-   */
-  @Override
-  public void postProcess() throws IOException {
-    super.compute();
-    for( Map<String, StatsCollector[]> f : fieldFacetCollectors.values() ){
-      for( StatsCollector[] arr : f.values() ){
-        for( StatsCollector b : arr ){
-          b.compute();
-        }
-      }
-    }
-    basicsAndFieldFacetsComputed = true;
-    final Filter filter = docs.getTopFilter();
-    if( rangeFacets != null ){
-      processRangeFacets(filter); 
-    }
-    if( queryFacets != null ){
-      processQueryFacets(filter); 
-    }
-  }
-  
-  /**
-   * Initiates the collecting of query facets
-   * @param filter the base filter to work against
-   * @throws IOException if searching failed
-   */
-  public void processQueryFacets(final Filter filter) throws IOException {
-    for( QueryFacetRequest qfr : queryFacets ){
-      for( String query : qfr.getQueries() ){
-        if (query.contains(AnalyticsParams.RESULT) && !query.contains(AnalyticsParams.QUERY_RESULT)) {
-          try {
-            String[] pivotStr = ExpressionFactory.getArguments(query.substring(query.indexOf('(')+1,query.lastIndexOf(')')).trim());
-            if (pivotStr.length==1) {
-              query = getResult(pivotStr[0]);
-            } else if (pivotStr.length==3) {
-              query = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
-            } else {
-              throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" has an invalid amount of arguments.");
-            }
-          } catch (IndexOutOfBoundsException e) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" is invalid. Lacks parentheses.",e);
-          }
-        } else if (query.contains(AnalyticsParams.QUERY_RESULT)) {
-          try {
-            String[] pivotStr = ExpressionFactory.getArguments(query.substring(query.indexOf('(')+1,query.lastIndexOf(')')).trim());
-            if (pivotStr.length==3) {
-              query = getQueryResult(qfr.getName(),pivotStr[0],pivotStr[1],pivotStr[2]);
-            } else {
-              throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" has an invalid amount of arguments.");
-            }
-          } catch (IndexOutOfBoundsException e) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" is invalid. Lacks parentheses.",e);
-          }
-        }
-        QueryFacetAccumulator qAcc = new QueryFacetAccumulator(this,qfr.getName(),query);
-        final Query q;
-        try {
-          q = QParser.getParser(query, null, queryRequest).getQuery();
-        } catch( SyntaxError e ){
-          throw new SolrException(ErrorCode.BAD_REQUEST,"Invalid query '"+query+"'",e);
-        }
-        // The searcher sends docIds to the QueryFacetAccumulator which forwards
-        // them to <code>collectQuery()</code> in this class for collection.
-        searcher.search(q, filter, qAcc);
-        computeQueryFacet(qfr.getName());
-        queryCount++;
-      }
-    }
-  }
-  
-  @Override
-  public long getNumQueries() {
-    return queryCount;
-  }
-
-  /**
-   * Initiates the collecting of range facets
-   * @param filter the base filter to use
-   * @throws IOException if searching fails
-   */
-  public void processRangeFacets(final Filter filter) throws IOException {
-    for( RangeFacetRequest rfr : rangeFacets ){
-      String[] pivotStr;
-      String start = rfr.getStart();
-      if (start.contains(AnalyticsParams.QUERY_RESULT)) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"Query result requests can not be used in Range Facets");
-      } else if (start.contains(AnalyticsParams.RESULT)) {
-        try {
-          pivotStr = ExpressionFactory.getArguments(start.substring(start.indexOf('(')+1,start.indexOf(')')).trim());
-          if (pivotStr.length==1) {
-            rfr.setStart(getResult(pivotStr[0]));
-          } else if (pivotStr.length==3) {
-            rfr.setStart(getResult(pivotStr[0],pivotStr[1],pivotStr[2]));
-          } else {
-            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+start+" has an invalid amount of arguments.");
-          }
-        } catch (IndexOutOfBoundsException e) {
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+start+" is invalid. Lacks parentheses.",e);
-        }
-      }
-      String end = rfr.getEnd();
-      if (end.contains(AnalyticsParams.QUERY_RESULT)) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "Query result requests can not be used in Range Facets");
-      } else if (end.contains(AnalyticsParams.RESULT)) {
-        try {
-          pivotStr = ExpressionFactory.getArguments(end.substring(end.indexOf('(')+1,end.indexOf(')')).trim());
-          if (pivotStr.length==1) {
-            rfr.setEnd(getResult(pivotStr[0]));
-          } else if (pivotStr.length==3) {
-            rfr.setEnd(getResult(pivotStr[0],pivotStr[1],pivotStr[2]));
-          } else {
-            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+end+" has an invalid amount of arguments.");
-          }
-        } catch (IndexOutOfBoundsException e) {
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+end+" is invalid. Lacks parentheses.",e);
-        }
-      }
-      String[] gaps = rfr.getGaps();
-      for (int count = 0; count<gaps.length; count++){
-        String gap = gaps[count];
-        if (gap.contains(AnalyticsParams.QUERY_RESULT)) {
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Query result requests can not be used in Range Facets");
-        } else if (gap.contains(AnalyticsParams.RESULT)) {
-          try {
-            pivotStr = ExpressionFactory.getArguments(gap.substring(gap.indexOf('(')+1,gap.indexOf(')')).trim());
-            if (pivotStr.length==1) {
-              gaps[count]=getResult(pivotStr[0]);
-            } else if (pivotStr.length==3) {
-              gaps[count]=getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
-            } else {
-              throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+gap+" has an invalid amount of arguments.");
-            }
-          } catch (IndexOutOfBoundsException e) {
-            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+gap+" is invalid. Lacks parentheses.",e);
-          }
-        }
-      }
-      // Computes the end points of the ranges in the rangeFacet
-      final RangeEndpointCalculator<? extends Comparable<?>> rec = RangeEndpointCalculator.create(rfr);
-      final SchemaField sf = rfr.getField();
-      
-      // Create a rangeFacetAccumulator for each range and 
-      // collect the documents for that range.
-      for( FacetRange range : rec.getRanges() ){
-        final String upper;
-        final String lower;
-        String facetValue = "";
-        if( range.lower == null ){
-          facetValue = "(*";
-          lower = null;
-        } else {
-          lower = range.lower;
-          facetValue = ((range.includeLower)?"[":"(") + range.lower;
-        }
-        facetValue+=" TO ";
-        if( range.upper == null ){
-          upper = null;
-          facetValue += "*)";
-        } else {
-          upper = range.upper;
-          facetValue += range.upper + ((range.includeUpper)?"]":")");
-        }
-        
-        Query q = sf.getType().getRangeQuery(null, sf, lower, upper, range.includeLower,range.includeUpper);
-        RangeFacetAccumulator rAcc = new RangeFacetAccumulator(this,rfr.getName(),facetValue);
-        // The searcher sends docIds to the RangeFacetAccumulator which forwards
-        // them to <code>collectRange()</code> in this class for collection.
-        searcher.search(q, filter, rAcc);
-        computeRangeFacet(sf.getName());
-      }
-    }
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java
deleted file mode 100644
index 90b8713..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.SimpleCollector;
-import org.apache.solr.common.util.NamedList;
-
-/**
- * Abstract Collector that manages all StatsCollectors, Expressions and Facets.
- */
-public abstract class ValueAccumulator extends SimpleCollector {
-  
-  /**
-   * Finalizes the statistics within each StatsCollector.
-   * Must be called before <code>export()</code>.
-   */
-  public abstract void compute();
-  public abstract NamedList<?> export();
-  
-  public void postProcess() throws IOException {
-    // NOP
-  }
-
-  @Override
-  public boolean acceptsDocsOutOfOrder() {
-    return true;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java
deleted file mode 100644
index 856f45f..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java
+++ /dev/null
@@ -1,36 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator.facet;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-
-/**
- * Interface that describes the methods needed for an Accumulator to be able to handle 
- * fieldFacets, rangeFacets and queryFacets.
- */
-public interface FacetValueAccumulator {
-
-  void collectField(int doc, String facetName, String facetValue) throws IOException;
-  void collectQuery(int doc, String facetName, String facetValue) throws IOException;
-  void collectRange(int doc, String facetName, String facetValue) throws IOException;
-  void setQueryStatsCollectorReaders(AtomicReaderContext context) throws IOException;
-  void setRangeStatsCollectorReaders(AtomicReaderContext context) throws IOException;
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java
deleted file mode 100644
index 0d04bfd..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java
+++ /dev/null
@@ -1,149 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator.facet;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.solr.analytics.accumulator.FacetingAccumulator;
-import org.apache.solr.analytics.accumulator.ValueAccumulator;
-import org.apache.solr.analytics.util.AnalyticsParsers;
-import org.apache.solr.analytics.util.AnalyticsParsers.NumericParser;
-import org.apache.solr.analytics.util.AnalyticsParsers.Parser;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.schema.SchemaField;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.search.SolrIndexSearcher;
-
-/**
- * An Accumulator that manages the faceting for fieldFacets.
- * Collects the field facet values.
- */
-public class FieldFacetAccumulator extends ValueAccumulator {
-  protected final Parser parser;
-  protected final FacetValueAccumulator parent;
-  protected final String name;
-  protected final SolrIndexSearcher searcher;
-  protected final SchemaField schemaField;
-  protected final boolean multiValued;
-  protected final boolean numField;
-  protected final boolean dateField;
-  protected SortedSetDocValues setValues;
-  protected SortedDocValues sortValues; 
-  protected NumericDocValues numValues; 
-  protected Bits numValuesBits; 
-  
-  public FieldFacetAccumulator(SolrIndexSearcher searcher, FacetValueAccumulator parent, SchemaField schemaField) throws IOException {  
-    if( !schemaField.hasDocValues() ){
-      throw new SolrException(ErrorCode.BAD_REQUEST, "Field '"+schemaField.getName()+"' does not have docValues");
-    }
-    this.searcher = searcher;
-    this.schemaField = schemaField;
-    this.name = schemaField.getName();
-    if (!schemaField.hasDocValues()) {
-      throw new IOException(name+" does not have docValues and therefore cannot be faceted over.");
-    }
-    this.multiValued = schemaField.multiValued();
-    this.numField = schemaField.getType().getNumericType()!=null;
-    this.dateField = schemaField.getType().getClass().equals(TrieDateField.class);
-    this.parent = parent;  
-    this.parser = AnalyticsParsers.getParser(schemaField.getType().getClass());
-  }
-
-  public static FieldFacetAccumulator create(SolrIndexSearcher searcher, FacetValueAccumulator parent, SchemaField facetField) throws IOException{
-    return new FieldFacetAccumulator(searcher,parent,facetField);
-  }
-
-  /**
-   * Move to the next set of documents to add to the field facet.
-   */
-  @Override
-  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
-    if (multiValued) {
-      setValues = context.reader().getSortedSetDocValues(name);
-    } else {
-      if (numField) {
-        numValues = context.reader().getNumericDocValues(name);
-        numValuesBits = context.reader().getDocsWithField(name);
-      } else {
-        sortValues = context.reader().getSortedDocValues(name);
-      }
-    }
-  }
-
-  /**
-   * Tell the FacetingAccumulator to collect the doc with the 
-   * given fieldFacet and value(s).
-   */
-  @Override
-  public void collect(int doc) throws IOException {
-    if (multiValued) {
-      boolean exists = false;
-      if (setValues!=null) {
-        setValues.setDocument(doc);
-        int term;
-        while ((term = (int)setValues.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {
-          exists = true;
-          final BytesRef value = setValues.lookupOrd(term);
-          parent.collectField(doc, name, parser.parse(value) );
-        }
-      }
-      if (!exists) {
-        parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
-      }
-    } else {
-      if(numField){
-        if(numValues != null) {
-          long v = numValues.get(doc);
-          if( v != 0 || numValuesBits.get(doc) ){
-            parent.collectField(doc, name, ((NumericParser)parser).parseNum(v));
-          } else {
-            parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
-          }
-        } else {
-          parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
-        }
-      } else {
-        if(sortValues != null) {
-          final int ord = sortValues.getOrd(doc);
-          if (ord < 0) {
-            parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
-          } else {
-            parent.collectField(doc, name, parser.parse(sortValues.lookupOrd(ord)) );
-          }
-        } else {
-          parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
-        }
-      }
-    }
-  }
-
-  @Override
-  public void compute() {}
- 
-  @Override
-  public NamedList<?> export() { return null; }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java
deleted file mode 100644
index 3a268ee..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java
+++ /dev/null
@@ -1,69 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator.facet;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.solr.analytics.accumulator.ValueAccumulator;
-import org.apache.solr.analytics.statistics.StatsCollector;
-import org.apache.solr.common.util.NamedList;
-
-/**
- * An Accumulator that manages a certain query of a given query facet.
- */
-public class QueryFacetAccumulator extends ValueAccumulator {
-  protected final FacetValueAccumulator parent;
-  protected final String facetName;
-  protected final String facetValue;
-
-  public QueryFacetAccumulator(FacetValueAccumulator parent, String facetName, String facetValue) {
-    this.parent = parent;
-    this.facetName = facetName;
-    this.facetValue = facetValue;
-  }
-
-  /**
-   * Tell the FacetingAccumulator to collect the doc with the 
-   * given queryFacet and query.
-   */
-  @Override
-  public void collect(int doc) throws IOException {
-    parent.collectQuery(doc, facetName, facetValue);
-  }
-
-  /**
-   * Update the readers of the queryFacet {@link StatsCollector}s in FacetingAccumulator
-   */
-  @Override
-  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
-    parent.setQueryStatsCollectorReaders(context);
-  }
-
-  @Override
-  public void compute() {
-    // NOP
-  }
-
-  @Override
-  public NamedList<?> export() {
-    // NOP
-    return null;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java
deleted file mode 100644
index 8c07c4f..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.accumulator.facet;
-
-import java.io.IOException;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.solr.analytics.statistics.StatsCollector;
-
-/**
- * An Accumulator that manages a certain range of a given range facet.
- */
-public class RangeFacetAccumulator extends QueryFacetAccumulator {
-  public RangeFacetAccumulator(FacetValueAccumulator parent, String facetName, String facetValue) {
-    super(parent, facetName, facetValue);
-  }
-
-  /**
-   * Tell the FacetingAccumulator to collect the doc with the 
-   * given rangeFacet and range.
-   */
-  @Override
-  public void collect(int doc) throws IOException {
-    parent.collectRange(doc, facetName, facetValue);
-  }
-
-  /**
-   * Update the readers of the rangeFacet {@link StatsCollector}s in FacetingAccumulator
-   */
-  @Override
-  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
-    parent.setRangeStatsCollectorReaders(context);
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/package.html
deleted file mode 100644
index 8737a00..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/facet/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Accumulators for accumulating over differnt types of facets
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/package.html
deleted file mode 100644
index b2cb8c2..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Accumulators accumulate values over different types of strucuture (eg result, facet, etc..)
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/BaseExpression.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/BaseExpression.java
deleted file mode 100644
index 1455cbc..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/BaseExpression.java
+++ /dev/null
@@ -1,89 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import java.util.Date;
-
-import org.apache.solr.analytics.statistics.StatsCollector;
-
-
-/**
- * <code>BaseExpression</code> returns the value returned by the {@link StatsCollector} for the specified stat.
- */
-public class BaseExpression extends Expression {
-  protected final StatsCollector statsCollector;
-  protected final String stat;
-  
-  public BaseExpression(StatsCollector statsCollector, String stat) {
-    this.statsCollector = statsCollector;
-    this.stat = stat;
-  }
-  
-  public Comparable getValue() {
-    if(statsCollector.getStatsList().contains(stat)) {
-      return statsCollector.getStat(stat);
-    }
-    return null;
-  }
-}
-/**
- * <code>ConstantStringExpression</code> returns the specified constant double.
- */
-class ConstantNumberExpression extends Expression {
-  protected final Double constant;
-  
-  public ConstantNumberExpression(double d) {
-    constant = new Double(d);
-  }
-  
-  public Comparable getValue() {
-    return constant;
-  }
-}
-/**
- * <code>ConstantStringExpression</code> returns the specified constant date.
- */
-class ConstantDateExpression extends Expression {
-  protected final Date constant;
-  
-  public ConstantDateExpression(Date date) {
-    constant = date;
-  }
-  
-  public ConstantDateExpression(Long date) {
-    constant = new Date(date);
-  }
-  
-  public Comparable getValue() {
-    return constant;
-  }
-}
-/**
- * <code>ConstantStringExpression</code> returns the specified constant string.
- */
-class ConstantStringExpression extends Expression {
-  protected final String constant;
-  
-  public ConstantStringExpression(String str) {
-    constant = str;
-  }
-  
-  public Comparable getValue() {
-    return constant;
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java
deleted file mode 100644
index f8579bf..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java
+++ /dev/null
@@ -1,100 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-/**
- * Abstraction of an expression that applies a function to two delegate expressions.
- */
-public abstract class DualDelegateExpression extends Expression {
-  protected Expression a;
-  protected Expression b;
-  public DualDelegateExpression(Expression a, Expression b) {
-    this.a = a;
-    this.b = b;
-  }
-}
-/**
- * <code>DivideExpression</code> returns the quotient of 'a' and 'b'.
- */
-class DivideExpression extends DualDelegateExpression {
-  
-  /**
-   * @param a numerator
-   * @param b divisor
-   */
-  public DivideExpression(Expression a, Expression b) {
-    super(a,b);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable aComp = a.getValue();
-    Comparable bComp = b.getValue();
-    if (aComp==null || bComp==null) {
-      return null;
-    }
-    double div = ((Number)aComp).doubleValue();
-    div = div / ((Number)bComp).doubleValue();
-    return new Double(div);
-  }
-}
-/**
- * <code>PowerExpression</code> returns 'a' to the power of 'b'.
- */
-class PowerExpression extends DualDelegateExpression {
-
-  /**
-   * @param a base
-   * @param b exponent
-   */
-  public PowerExpression(Expression a, Expression b) {
-    super(a,b);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable aComp = a.getValue();
-    Comparable bComp = b.getValue();
-    if (aComp==null || bComp==null) {
-      return null;
-    }
-    return new Double(Math.pow(((Number)aComp).doubleValue(),((Number)bComp).doubleValue()));
-  }
-}
-/**
- * <code>LogExpression</code> returns the log of the delegate's value given a base number.
- */
-class LogExpression extends DualDelegateExpression {
-  /**
-   * @param a number
-   * @param b base
-   */
-  public LogExpression(Expression a, Expression b) {
-    super(a,b);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable aComp = a.getValue();
-    Comparable bComp = b.getValue();
-    if (aComp==null || bComp==null) {
-      return null;
-    }
-    return Math.log(((Number)aComp).doubleValue())/Math.log(((Number)bComp).doubleValue());
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/Expression.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/Expression.java
deleted file mode 100644
index add0976..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/Expression.java
+++ /dev/null
@@ -1,44 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import java.util.Comparator;
-
-import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortDirection;
-
-/**
- * Expressions map either zero, one, two or many inputs to a single value. 
- * They can be defined recursively to compute complex math.
- */
-public abstract class Expression {
-  public abstract Comparable getValue();
-
-  public Comparator<Expression> comparator(final FacetSortDirection direction) {
-    return new Comparator<Expression>(){
-      @SuppressWarnings("unchecked")
-      @Override
-      public int compare(Expression a, Expression b) {
-        if( direction == FacetSortDirection.ASCENDING ){
-          return a.getValue().compareTo(b.getValue());
-        } else {
-          return b.getValue().compareTo(a.getValue());
-        }
-      }
-    };
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java
deleted file mode 100644
index 0fd9db0..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java
+++ /dev/null
@@ -1,181 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.solr.analytics.statistics.StatsCollector;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.schema.TrieDateField;
-
-public class ExpressionFactory {
-
-  /**
-   * Creates a single expression that contains delegate expressions and/or 
-   * a StatsCollector.
-   * StatsCollectors are given as input and not created within the method so that
-   * expressions can share the same StatsCollectors, minimizing computation.
-   * 
-   * @param expression String representation of the desired expression
-   * @param statsCollectors List of StatsCollectors to build the expression with. 
-   * @return the expression
-   */
-  @SuppressWarnings("deprecation")
-  public static Expression create(String expression, StatsCollector[] statsCollectors) {
-    int paren = expression.indexOf('(');
-    if (paren<=0) {
-      throw new SolrException(ErrorCode.BAD_REQUEST, "The expression ["+expression+"] has no arguments and is not supported.");
-    }
-    String topOperation = expression.substring(0,paren).trim();
-    String operands;
-    try {
-      operands = expression.substring(paren+1, expression.lastIndexOf(')')).trim();
-    } catch (Exception e) {
-      throw new SolrException(ErrorCode.BAD_REQUEST,"Missing closing parenthesis in ["+expression+"]",e);
-    }
-    
-    // Builds a statistic, constant or recursively builds an expression tree
-    
-    // Statistic 
-    if (AnalyticsParams.ALL_STAT_SET.contains(topOperation)) {
-      if (topOperation.equals(AnalyticsParams.STAT_PERCENTILE)) {
-        operands = expression.substring(expression.indexOf(',')+1, expression.lastIndexOf(')')).trim();
-        topOperation = topOperation+"_"+expression.substring(expression.indexOf('(')+1, expression.indexOf(',')).trim();
-      }
-      StatsCollector collector = null;
-      // Finds the desired counter and builds an expression around it and the desired statistic.
-      for (StatsCollector c : statsCollectors) {
-        if (c.valueSourceString().equals(operands)) { 
-          collector = c;
-          break;
-        }
-      }
-      if (collector == null) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "ValueSource ["+operands+"] in Expression ["+expression+"] not found.");
-      }
-      return new BaseExpression(collector, topOperation);
-    }
-    // Constant
-    if (topOperation.equals(AnalyticsParams.CONSTANT_NUMBER)) {
-      try {
-        return new ConstantNumberExpression(Double.parseDouble(operands));
-      } catch (NumberFormatException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "The constant "+operands+" cannot be converted into a number.",e);
-      }
-    } else if (topOperation.equals(AnalyticsParams.CONSTANT_DATE)) {
-      try {
-        return new ConstantDateExpression(TrieDateField.parseDate(operands));
-      } catch (ParseException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "The constant "+operands+" cannot be converted into a date.",e);
-      }
-    } else if (topOperation.equals(AnalyticsParams.CONSTANT_STRING)) {
-      operands = expression.substring(paren+1, expression.lastIndexOf(')'));
-      return new ConstantStringExpression(operands);
-    }
-    
-    // Complex Delegating Expressions
-    String[] arguments = getArguments(operands);
-    Expression[] expArgs = new Expression[arguments.length];
-    for (int count = 0; count < arguments.length; count++) {
-      // Recursively builds delegate expressions
-      expArgs[count] = create(arguments[count], statsCollectors);
-    }
-    
-    // Single Delegate Expressions
-    if (expArgs.length==1) {
-      // Numeric Expression
-      if (topOperation.equals(AnalyticsParams.NEGATE)) {
-        return new NegateExpression(expArgs[0]);
-      }
-      if (topOperation.equals(AnalyticsParams.ABSOLUTE_VALUE)) {
-        return new AbsoluteValueExpression(expArgs[0]);
-      }
-      // String Expression
-      else if (topOperation.equals(AnalyticsParams.REVERSE)) {
-        return new ReverseExpression(expArgs[0]);
-      }
-      throw new SolrException(ErrorCode.BAD_REQUEST, topOperation+" does not have the correct number of arguments.");
-    }  else {
-      // Multi Delegate Expressions
-      // Numeric Expression
-      if (topOperation.equals(AnalyticsParams.ADD)) {
-        return new AddExpression(expArgs);
-      } else if (topOperation.equals(AnalyticsParams.MULTIPLY)) {
-        return new MultiplyExpression(expArgs);
-      }
-      // Date Expression
-      else if (topOperation.equals(AnalyticsParams.DATE_MATH)) {
-        return new DateMathExpression(expArgs);
-      } 
-      // String Expression
-      else if (topOperation.equals(AnalyticsParams.CONCATENATE)) {
-        return new ConcatenateExpression(expArgs);
-      } 
-      // Dual Delegate Expressions
-      else if (expArgs.length==2 && (topOperation.equals(AnalyticsParams.DIVIDE) || topOperation.equals(AnalyticsParams.POWER) 
-          || topOperation.equals(AnalyticsParams.LOG))) {
-        // Numeric Expression
-        if (topOperation.equals(AnalyticsParams.DIVIDE)) {
-          return new DivideExpression(expArgs[0], expArgs[1]);
-        } else if (topOperation.equals(AnalyticsParams.POWER)) {
-          return new PowerExpression(expArgs[0], expArgs[1]);
-        } else if (topOperation.equals(AnalyticsParams.LOG)) {
-          return new LogExpression(expArgs[0], expArgs[1]);
-        }
-        return null;
-      }
-      throw new SolrException(ErrorCode.BAD_REQUEST, topOperation+" does not have the correct number of arguments or is unsupported.");
-    }
-    
-  }
-  
-  /**
-   * Splits up an Expression's arguments.
-   * 
-   * @param expression Current expression string
-   * @return List The list of arguments
-   */
-  public static String[] getArguments(String expression) {
-    String[] strings = new String[1];
-    int stack = 0;
-    int start = 0;
-    List<String> arguments = new ArrayList<>();
-    char[] chars = expression.toCharArray();
-    for (int count = 0; count < expression.length(); count++) {
-      char c = chars[count];
-      if (c==',' && stack == 0) {
-        arguments.add(expression.substring(start, count).replace("\\(","(").replace("\\)",")").replace("\\,",",").trim());
-        start = count+1;
-      } else if (c == '(') {
-        stack ++;
-      } else if (c == ')') {
-        stack --;
-      } else if (c == '\\') {
-        ; // Do nothing.
-      }
-    }
-    if (stack==0) {
-      arguments.add(expression.substring(start).trim());
-    }
-    return arguments.toArray(strings);
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java
deleted file mode 100644
index 4ea4825..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java
+++ /dev/null
@@ -1,132 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import java.text.ParseException;
-import java.util.Date;
-
-import org.apache.solr.util.DateMathParser;
-
-/**
- * Abstraction of an expression that applies a function to an array of delegate expressions.
- */
-public abstract class MultiDelegateExpression extends Expression {
-  protected final Expression[] delegates;
-  
-  public MultiDelegateExpression(Expression[] delegates) {
-    this.delegates = delegates;
-  }
-}
-/**
- * <code>AddExpression</code> returns the sum of it's components' values.
- */
-class AddExpression extends MultiDelegateExpression {
-  public AddExpression(Expression[] delegates) {
-    super(delegates);
-  }
-
-  @Override
-  public Comparable getValue() {
-    double sum = 0;
-    for (Expression delegate : delegates) {
-      Comparable dComp = delegate.getValue();
-      if (dComp==null) {
-        return null;
-      } else if (dComp.getClass().equals(Date.class)) {
-        dComp = new Long(((Date)dComp).getTime());
-      }
-      sum += ((Number)dComp).doubleValue();
-    }
-    return new Double(sum);
-  }
-}
-/**
- * <code>MultiplyExpression</code> returns the product of it's delegates' values.
- */
-class MultiplyExpression extends MultiDelegateExpression {
-  public MultiplyExpression(Expression[] delegates) {
-    super(delegates);
-  }
-
-  @Override
-  public Comparable getValue() {
-    double prod = 1;
-    for (Expression delegate : delegates) {
-      Comparable dComp = delegate.getValue();
-      if (dComp==null) {
-        return null;
-      }
-      prod *= ((Number)dComp).doubleValue();
-    }
-    return new Double(prod);
-  }
-}
-/**
- * <code>DateMathExpression</code> returns the start date modified by the DateMath operations
- */
-class DateMathExpression extends MultiDelegateExpression {
-  /**
-   * @param delegates A list of Expressions. The first element in the list
-   * should be a numeric Expression which represents the starting date. 
-   * The rest of the field should be string Expression objects which contain
-   * the DateMath operations to perform on the start date.
-   */
-  public DateMathExpression(Expression[] delegates) {
-    super(delegates);
-  }
-
-  @Override
-  public Comparable getValue() {
-    DateMathParser parser = new DateMathParser();
-    parser.setNow((Date)delegates[0].getValue());
-    try {
-      for (int count = 1; count<delegates.length; count++) {
-        Comparable dComp = delegates[count].getValue();
-        if (dComp==null) {
-          return null;
-        }
-        parser.setNow(parser.parseMath((String)dComp));
-      }
-      return parser.getNow();
-    } catch (ParseException e) {
-      e.printStackTrace();
-      return parser.getNow();
-    }
-  }
-}
-/**
- * <code>ConcatenateExpression</code> returns the concatenation of it's delegates' values in the order given.
- */
-class ConcatenateExpression extends MultiDelegateExpression {
-  public ConcatenateExpression(Expression[] delegates) {
-    super(delegates);
-  }
-
-  @Override
-  public Comparable getValue() {
-    StringBuilder builder = new StringBuilder();
-    for (Expression delegate : delegates) {
-      Comparable dComp = delegate.getValue();
-      if (dComp==null) {
-        return null;
-      }
-      builder.append(dComp.toString());
-    }
-    return builder.toString();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java
deleted file mode 100644
index c6ab60e..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java
+++ /dev/null
@@ -1,89 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import java.util.Date;
-
-/**
- * Abstraction of an expression that applies a function to one delegate expression.
- */
-public abstract class SingleDelegateExpression extends Expression {
-  protected Expression delegate;
-  
-  public SingleDelegateExpression(Expression delegate) {
-    this.delegate = delegate;
-  }
-}
-/**
- * <code>NegateExpression</code> returns the negation of the delegate's value.
- */
-class NegateExpression extends SingleDelegateExpression {
-  public NegateExpression(Expression delegate) {
-    super(delegate);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable nComp = delegate.getValue();
-    if (nComp==null) {
-      return null;
-    } else if (nComp.getClass().equals(Date.class)) {
-      nComp = new Long(((Date)nComp).getTime());
-    }
-    return new Double(((Number)nComp).doubleValue()*-1);
-  }
-}
-/**
- * <code>AbsoluteValueExpression</code> returns the negation of the delegate's value.
- */
-class AbsoluteValueExpression extends SingleDelegateExpression {
-  public AbsoluteValueExpression(Expression delegate) {
-    super(delegate);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable nComp = delegate.getValue();
-    if (nComp==null) {
-      return null;
-    }
-    double d = ((Number)nComp).doubleValue();
-    if (d<0) {
-      return new Double(d*-1);
-    } else {
-      return new Double(d);
-    }
-  }
-}
-/**
- * <code>StringExpression</code> returns the reverse of the delegate's string value.
- */
-class ReverseExpression extends SingleDelegateExpression {
-  public ReverseExpression(Expression delegate) {
-    super(delegate);
-  }
-
-  @Override
-  public Comparable getValue() {
-    Comparable rComp = delegate.getValue();
-    if (rComp==null) {
-      return null;
-    }
-    return new StringBuilder(rComp.toString()).reverse().toString();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/package.html
deleted file mode 100644
index 434f710..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/expression/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Expressions map either zero, one, two or many inputs to a single value. They can be defined recursively to compute complex math.
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java
deleted file mode 100644
index a57c546..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java
+++ /dev/null
@@ -1,114 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.plugin;
-
-import java.util.concurrent.atomic.AtomicLong;
-
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.SimpleOrderedMap;
-import org.apache.solr.util.stats.Snapshot;
-import org.apache.solr.util.stats.Timer;
-import org.apache.solr.util.stats.TimerContext;
-
-public class AnalyticsStatisticsCollector {
-  private final AtomicLong numRequests;
-  private final AtomicLong numAnalyticsRequests;
-  private final AtomicLong numStatsRequests;
-  private final AtomicLong numCollectedStats;
-  private final AtomicLong numFieldFacets;
-  private final AtomicLong numRangeFacets;
-  private final AtomicLong numQueryFacets;
-  private final AtomicLong numQueries;
-  private final Timer requestTimes;
-  
-  public TimerContext currentTimer;
-  
-  public AnalyticsStatisticsCollector() {
-    numRequests = new AtomicLong();
-    numAnalyticsRequests = new AtomicLong();
-    numStatsRequests = new AtomicLong();
-    numCollectedStats = new AtomicLong();
-    numFieldFacets = new AtomicLong();
-    numRangeFacets = new AtomicLong();
-    numQueryFacets = new AtomicLong();
-    numQueries = new AtomicLong();
-    requestTimes = new Timer();
-  }
-  
-  public void startRequest() {
-    numRequests.incrementAndGet();
-    currentTimer = requestTimes.time();
-  }
-  
-  public void addRequests(long num) {
-    numAnalyticsRequests.addAndGet(num);
-  }
-  
-  public void addStatsRequests(long num) {
-    numStatsRequests.addAndGet(num);
-  }
-  
-  public void addStatsCollected(long num) {
-    numCollectedStats.addAndGet(num);
-  }
-  
-  public void addFieldFacets(long num) {
-    numFieldFacets.addAndGet(num);
-  }
-  
-  public void addRangeFacets(long num) {
-    numRangeFacets.addAndGet(num);
-  }
-  
-  public void addQueryFacets(long num) {
-    numQueryFacets.addAndGet(num);
-  }
-  
-  public void addQueries(long num) {
-    numQueries.addAndGet(num);
-  }
-  
-  public void endRequest() {
-    currentTimer.stop();
-  }
-
-  public NamedList<Object> getStatistics() {
-    NamedList<Object> lst = new SimpleOrderedMap<>();
-    Snapshot snapshot = requestTimes.getSnapshot();
-    lst.add("requests", numRequests.longValue());
-    lst.add("analyticsRequests", numAnalyticsRequests.longValue());
-    lst.add("statsRequests", numStatsRequests.longValue());
-    lst.add("statsCollected", numCollectedStats.longValue());
-    lst.add("fieldFacets", numFieldFacets.longValue());
-    lst.add("rangeFacets", numRangeFacets.longValue());
-    lst.add("queryFacets", numQueryFacets.longValue());
-    lst.add("queriesInQueryFacets", numQueries.longValue());
-    lst.add("totalTime", requestTimes.getSum());
-    lst.add("avgRequestsPerSecond", requestTimes.getMeanRate());
-    lst.add("5minRateReqsPerSecond", requestTimes.getFiveMinuteRate());
-    lst.add("15minRateReqsPerSecond", requestTimes.getFifteenMinuteRate());
-    lst.add("avgTimePerRequest", requestTimes.getMean());
-    lst.add("medianRequestTime", snapshot.getMedian());
-    lst.add("75thPcRequestTime", snapshot.get75thPercentile());
-    lst.add("95thPcRequestTime", snapshot.get95thPercentile());
-    lst.add("99thPcRequestTime", snapshot.get99thPercentile());
-    lst.add("999thPcRequestTime", snapshot.get999thPercentile());
-    return lst;
-  }
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/package.html
deleted file mode 100644
index 7555251..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/plugin/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-MBean plugins for stats collection 
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java
deleted file mode 100644
index 6f85cf0..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import org.apache.solr.schema.SchemaField;
-
-/**
- * An abstract request for a facet over a single field, such as a field or range facet.
- */
-public abstract class AbstractFieldFacetRequest implements FacetRequest {
-  protected SchemaField field = null;
-  
-  public AbstractFieldFacetRequest(SchemaField field) {
-    this.field = field;
-  }
-
-  public SchemaField getField() {
-    return field;
-  }
-
-  public void setField(SchemaField field) {
-    this.field = field;
-  }
-
-  public String getName() {
-    return field.getName();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java
deleted file mode 100644
index db21094..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java
+++ /dev/null
@@ -1,315 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.util.ArrayList;
-import java.util.EnumSet;
-import java.util.List;
-
-import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortDirection;
-import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
-import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
-import org.apache.solr.common.params.FacetParams.FacetRangeOther;
-import org.apache.solr.schema.IndexSchema;
-import org.xml.sax.Attributes;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.Locator;
-import org.xml.sax.SAXException;
-
-/**
- * Handles the parsing of the AnalysisRequestEnvelope elements if passed in through XML.
- */
-public class AnalyticsContentHandler implements ContentHandler {
-  // XML Element/Attribute Name Constants
-  public final String ANALYTICS_REQUEST_ENVELOPE="analyticsRequestEnvelope";
-  
-  public final String ANALYTICS_REQUEST="analyticsRequest";
-  public final String NAME="name";
-  
-  public final String STATISTIC="statistic";
-  public final String EXPRESSION="expression";
-  
-  public final String FIELD_FACET="fieldFacet";
-  public final String FIELD="field";
-  public final String SHOW_MISSING="showMissing";
-  public final String LIMIT="limit";
-  public final String MIN_COUNT="minCount";
-  
-  public final String SORT_SPECIFICATION="sortSpecification";
-  public final String STAT_NAME="statName";
-  public final String DIRECTION="direction";
-  
-  public final String RANGE_FACET="rangeFacet";
-  public final String START="start";
-  public final String END="end";
-  public final String GAP="gap";
-  public final String INCLUDE_BOUNDARY="includeBoundary";
-  public final String OTHER_RANGE="otherRange";
-  public final String HARD_END="hardend";
-  
-  public final String QUERY_FACET="queryFacet";
-  public final String QUERY="query";
-  
-  // Default Values
-  public static final int DEFAULT_FACET_LIMIT = -1;
-  public static final boolean DEFAULT_FACET_HARDEND = false;
-  public static final int DEFAULT_FACET_MINCOUNT = 0;
-  public static final boolean DEFAULT_FACET_FIELD_SHOW_MISSING = false;
-
-  boolean inEnvelope = false;
-  boolean inRequest = false;
-  boolean inStatistic = false;
-  boolean inFieldFacet = false;
-  boolean inSortSpecification = false;
-  boolean inQueryFacet = false;
-  boolean inRangeFacet = false;
-  
-  private final IndexSchema schema;
-  
-  // Objects to use while building the Analytics Requests
-  
-  String currentElementText;
-  
-  List<AnalyticsRequest> requests;
-  
-  AnalyticsRequest analyticsRequest;
-  List<ExpressionRequest> expressionList;
-  List<FieldFacetRequest> fieldFacetList;
-  List<RangeFacetRequest> rangeFacetList;
-  List<QueryFacetRequest> queryFacetList;
-  
-  ExpressionRequest expression;
-  
-  FieldFacetRequest fieldFacet;
-  int limit;
-  int minCount;
-  boolean showMissing;
-  FacetSortSpecification sortSpecification;
-  
-  RangeFacetRequest rangeFacet;
-  boolean hardend;
-  List<String> gaps;
-  EnumSet<FacetRangeInclude> includeBoundaries;
-  EnumSet<FacetRangeOther> otherRanges;
-  
-  String queryName;
-  List<String> queries;
-  
-  public AnalyticsContentHandler(IndexSchema schema) {
-    this.schema = schema;
-  }
-
-  @Override
-  public void setDocumentLocator(Locator locator) { }
-
-  @Override
-  public void startDocument() throws SAXException { }
-
-  @Override
-  public void endDocument() throws SAXException { }
-
-  @Override
-  public void startPrefixMapping(String prefix, String uri) throws SAXException { }
-
-  @Override
-  public void endPrefixMapping(String prefix) throws SAXException { }
-
-  @Override
-  public void startElement(String uri, String localName, String qName, Attributes atts) throws SAXException {
-    currentElementText = "";
-    if (inEnvelope) {
-      if (inRequest) {
-        if (localName.equals(STATISTIC)) {
-          // Start a Statistic Request
-          inStatistic = true;
-        } else if (inFieldFacet) {
-          if (localName.equals(SORT_SPECIFICATION)) {
-            // Start a Sort Specification
-            inSortSpecification = true;
-            sortSpecification = new FacetSortSpecification();
-          }
-        } else if (localName.equals(FIELD_FACET)) {
-          // Start a Field Facet Request
-          // Get attributes (limit, minCount, showMissing)
-          String att = atts.getValue(uri,LIMIT);
-          if (att!=null) {
-            limit = Integer.parseInt(att);
-          } else {
-            limit = DEFAULT_FACET_LIMIT;
-          }
-          att = atts.getValue(uri,MIN_COUNT);
-          if (att!=null) {
-            minCount = Integer.parseInt(att);
-          } else {
-            minCount = DEFAULT_FACET_MINCOUNT;
-          }
-          att = atts.getValue(uri,SHOW_MISSING);
-          if (att!=null) {
-            showMissing = Boolean.parseBoolean(att);
-          } else {
-            showMissing = DEFAULT_FACET_FIELD_SHOW_MISSING;
-          }
-          
-          inFieldFacet = true;
-        } else if (localName.equals(RANGE_FACET)) {
-          // Start a Range Facet Request
-          // Get attributes (hardEnd)
-          String att = atts.getValue(uri,HARD_END);
-          if (att!=null) {
-            hardend = Boolean.parseBoolean(att);
-          } else {
-            hardend = false;
-          }
-          
-          // Initiate Range Facet classes
-          gaps = new ArrayList<>();
-          includeBoundaries = EnumSet.noneOf(FacetRangeInclude.class);
-          otherRanges = EnumSet.noneOf(FacetRangeOther.class);
-          inRangeFacet = true;
-        } else if (localName.equals(QUERY_FACET)) {
-          // Start a Query Facet Request
-          queries = new ArrayList<>();
-          inQueryFacet = true;
-        }
-      } else if (localName.equals(ANALYTICS_REQUEST)){
-        // Start an Analytics Request
-        
-        // Renew each list.
-        fieldFacetList = new ArrayList<>();
-        rangeFacetList = new ArrayList<>();
-        queryFacetList = new ArrayList<>();
-        expressionList = new ArrayList<>();
-        inRequest = true;
-      }
-    } else if (localName.equals(ANALYTICS_REQUEST_ENVELOPE)){
-      //Begin the parsing of the Analytics Requests
-      requests = new ArrayList<>();
-      inEnvelope = true;
-    }
-  }
-
-  @Override
-  public void endElement(String uri, String localName, String qName) throws SAXException {
-    if (inEnvelope) {
-      if (inRequest) {
-        if (inStatistic) {
-          if (localName.equals(EXPRESSION)) {
-            expression = new ExpressionRequest(currentElementText,currentElementText);
-          } else if (localName.equals(NAME)) {
-            expression.setName(currentElementText);
-          } else if (localName.equals(STATISTIC)) {
-            // Finished Parsing the Statistic Request
-            expressionList.add(expression);
-            inStatistic = false;
-          } 
-        } else if (inFieldFacet) {
-          if (inSortSpecification) {
-            if (localName.equals(STAT_NAME)) {
-              sortSpecification.setStatistic(currentElementText);
-            } else if (localName.equals(DIRECTION)) {
-              sortSpecification.setDirection(FacetSortDirection.fromExternal(currentElementText));
-            } else if (localName.equals(SORT_SPECIFICATION)) {
-              // Finished Parsing the Sort Specification
-              fieldFacet.setSort(sortSpecification);
-              inSortSpecification = false;
-            } 
-          } else if (localName.equals(FIELD)) {
-            fieldFacet = new FieldFacetRequest(schema.getField(currentElementText));
-          } else if (localName.equals(FIELD_FACET)) {
-            // Finished Parsing the Field Facet Request
-            fieldFacet.setLimit(limit);
-            fieldFacet.showMissing(showMissing);
-            fieldFacetList.add(fieldFacet);
-            inFieldFacet = false;
-          } 
-        } else if (inRangeFacet) {
-          if (localName.equals(FIELD)) {
-            rangeFacet = new RangeFacetRequest(schema.getField(currentElementText), "", "", new String[1]);
-          } else if (localName.equals(START)) {
-            rangeFacet.setStart(currentElementText);
-          } else if (localName.equals(END)) {
-            rangeFacet.setEnd(currentElementText);
-          } else if (localName.equals(GAP)) {
-            gaps.add(currentElementText);
-          } else if (localName.equals(INCLUDE_BOUNDARY)) {
-            includeBoundaries.add(FacetRangeInclude.get(currentElementText));
-          } else if (localName.equals(OTHER_RANGE)) {
-            otherRanges.add(FacetRangeOther.get(currentElementText));
-          } else if (localName.equals(RANGE_FACET)) {
-            // Finished Parsing the Range Facet Request
-            rangeFacet.setHardEnd(hardend);
-            rangeFacet.setGaps(gaps.toArray(new String[1]));
-            rangeFacet.setInclude(includeBoundaries);
-            rangeFacet.setOthers(otherRanges);
-            inRangeFacet = false;
-            rangeFacetList.add(rangeFacet);
-          } 
-        } else if (inQueryFacet) {
-          if (localName.equals(NAME)) {
-            queryName = currentElementText;
-          } else if (localName.equals(QUERY)) {
-            queries.add(currentElementText);
-          } else if (localName.equals(QUERY_FACET)) {
-            // Finished Parsing the Query Facet Request
-            QueryFacetRequest temp = new QueryFacetRequest(queryName);
-            temp.setQueries(queries);
-            queryFacetList.add(temp);
-            inQueryFacet = false;
-          }
-        } else if (localName.equals(NAME)) {
-          analyticsRequest = new AnalyticsRequest(currentElementText);
-        } else if (localName.equals(ANALYTICS_REQUEST)){
-          // Finished Parsing the Analytics Request
-          analyticsRequest.setExpressions(expressionList);
-          analyticsRequest.setFieldFacets(fieldFacetList);
-          analyticsRequest.setRangeFacets(rangeFacetList);
-          analyticsRequest.setQueryFacets(queryFacetList);
-          requests.add(analyticsRequest);
-          inRequest = false;
-        }
-      } else if (localName.equals(ANALYTICS_REQUEST_ENVELOPE)){
-        // Finished Parsing
-        inEnvelope = false;
-      }
-    }
-  }
-
-  @Override
-  public void characters(char[] ch, int start, int length) throws SAXException {
-    currentElementText += new String(ch,start,length);
-  }
-
-  @Override
-  public void ignorableWhitespace(char[] ch, int start, int length) throws SAXException { }
-
-  @Override
-  public void processingInstruction(String target, String data) throws SAXException { }
-
-  @Override
-  public void skippedEntity(String name) throws SAXException { }
-  
-  /**
-   * Returns the list of Analytics Requests built during parsing.
-   * 
-   * @return List of {@link AnalyticsRequest} objects specified by the given XML file
-   */
-  public List<AnalyticsRequest> getAnalyticsRequests() {
-    return requests;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java
deleted file mode 100644
index 2f24999..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java
+++ /dev/null
@@ -1,115 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-/**
- * Contains the specifications of an Analytics Request, specifically a name,
- * a list of Expressions, a list of field facets, a list of range facets, a list of query facets
- * and the list of expressions and their results calculated in previous AnalyticsRequests.
- */
-public class AnalyticsRequest {
-  
-  private String name;
-  private List<ExpressionRequest> expressions;
-  private Set<String> hiddenExpressions;
-  private List<FieldFacetRequest> fieldFacets;
-  private List<RangeFacetRequest> rangeFacets;
-  private List<QueryFacetRequest> queryFacets;
-  
-  public AnalyticsRequest(String name) {
-    this.name = name;
-    expressions = new ArrayList<>();
-    hiddenExpressions = new HashSet<>();
-    fieldFacets = new ArrayList<>();
-    rangeFacets = new ArrayList<>();
-    queryFacets = new ArrayList<>();
-  }
-  
-  public String getName() {
-    return name;
-  }
-  
-  public void setExpressions(List<ExpressionRequest> expressions) {
-    this.expressions = expressions;
-  }
-
-  public void addExpression(ExpressionRequest expressionRequest) {
-    expressions.add(expressionRequest);
-  }
-  
-  public List<ExpressionRequest> getExpressions() {
-    return expressions;
-  }
-
-  public void addHiddenExpression(ExpressionRequest expressionRequest) {
-    expressions.add(expressionRequest);
-    hiddenExpressions.add(expressionRequest.getName());
-  }
-  
-  public Set<String> getHiddenExpressions() {
-    return hiddenExpressions;
-  }
-  
-  public void setFieldFacets(List<FieldFacetRequest> fieldFacets) {
-    this.fieldFacets = fieldFacets;
-  }
-  
-  public List<FieldFacetRequest> getFieldFacets() {
-    return fieldFacets;
-  }
-  
-  public void setRangeFacets(List<RangeFacetRequest> rangeFacets) {
-    this.rangeFacets = rangeFacets;
-  }
-  
-  public List<RangeFacetRequest> getRangeFacets() {
-    return rangeFacets;
-  }
-  
-  public void setQueryFacets(List<QueryFacetRequest> queryFacets) {
-    this.queryFacets = queryFacets;
-  }
-  
-  public List<QueryFacetRequest> getQueryFacets() {
-    return queryFacets;
-  }
-  
-  @Override
-  public String toString() {
-    StringBuilder builder = new StringBuilder("<AnalyticsRequest name=" + name + ">");
-    for (ExpressionRequest exp : expressions) {
-      builder.append(exp.toString());
-    }
-    for (FieldFacetRequest facet : fieldFacets) {
-      builder.append(facet.toString());
-    }
-    for (RangeFacetRequest facet : rangeFacets) {
-      builder.append(facet.toString());
-    }
-    for (QueryFacetRequest facet : queryFacets) {
-      builder.append(facet.toString());
-    }
-    builder.append("</AnalyticsRequest>");
-    return builder.toString();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java
deleted file mode 100644
index 3e2e994..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java
+++ /dev/null
@@ -1,309 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
-import org.apache.solr.common.params.FacetParams.FacetRangeOther;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.schema.IndexSchema;
-
-/**
- * Parses the SolrParams to create a list of analytics requests.
- */
-public class AnalyticsRequestFactory implements AnalyticsParams {
-
-  public static final Pattern statPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+EXPRESSION+")\\.([^\\.]+)$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern hiddenStatPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+HIDDEN_EXPRESSION+")\\.([^\\.]+)$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern fieldFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+FIELD_FACET+")$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern fieldFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+FIELD_FACET+")\\.([^\\.]+)\\.("+LIMIT+"|"+OFFSET+"|"+HIDDEN+"|"+SHOW_MISSING+"|"+SORT_STATISTIC+"|"+SORT_DIRECTION+")$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern rangeFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+RANGE_FACET+")$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern rangeFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+RANGE_FACET+")\\.([^\\.]+)\\.("+START+"|"+END+"|"+GAP+"|"+HARDEND+"|"+INCLUDE_BOUNDARY+"|"+OTHER_RANGE+")$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern queryFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+QUERY_FACET+")$", Pattern.CASE_INSENSITIVE);
-  public static final Pattern queryFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+QUERY_FACET+")\\.([^\\.]+)\\.("+QUERY+"|"+DEPENDENCY+")$", Pattern.CASE_INSENSITIVE);
-  
-  public static List<AnalyticsRequest> parse(IndexSchema schema, SolrParams params) {
-    Map<String, AnalyticsRequest> requestMap = new HashMap<>();
-    Map<String, Map<String,FieldFacetRequest>> fieldFacetMap = new HashMap<>();
-    Map<String, Set<String>> fieldFacetSet = new HashMap<>();
-    Map<String, Map<String,RangeFacetRequest>> rangeFacetMap = new HashMap<>();
-    Map<String, Set<String>> rangeFacetSet = new HashMap<>();
-    Map<String, Map<String,QueryFacetRequest>> queryFacetMap = new HashMap<>();
-    Map<String, Set<String>> queryFacetSet = new HashMap<>();
-    List<AnalyticsRequest> requestList = new ArrayList<>();
-    
-    Iterator<String> paramsIterator = params.getParameterNamesIterator();
-    while (paramsIterator.hasNext()) {
-      String param = paramsIterator.next();
-      CharSequence paramSequence = param.subSequence(0, param.length());
-      
-      // Check if stat
-      Matcher m = statPattern.matcher(paramSequence);
-      if (m.matches()) {
-        makeExpression(requestMap,m.group(1),m.group(2),params.get(param));
-      } else {
-        // Check if hidden stat
-        m = hiddenStatPattern.matcher(paramSequence);
-        if (m.matches()) {
-          makeHiddenExpression(requestMap,m.group(1),m.group(2),params.get(param));
-        } else {
-          // Check if field facet
-          m = fieldFacetPattern.matcher(paramSequence);
-          if (m.matches()) {
-            makeFieldFacet(schema,fieldFacetMap,fieldFacetSet,m.group(1),params.getParams(param));
-          } else {
-            // Check if field facet parameter
-            m = fieldFacetParamPattern.matcher(paramSequence);
-            if (m.matches()) {
-              setFieldFacetParam(schema,fieldFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
-            } else {
-              // Check if range facet
-              m = rangeFacetPattern.matcher(paramSequence);
-              if (m.matches()) {
-                makeRangeFacet(schema,rangeFacetSet,m.group(1),params.getParams(param));
-              }  else {
-                // Check if range facet parameter
-                m = rangeFacetParamPattern.matcher(paramSequence);
-                if (m.matches()) {
-                  setRangeFacetParam(schema,rangeFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
-                }  else {
-                  // Check if query facet
-                  m = queryFacetPattern.matcher(paramSequence);
-                  if (m.matches()) {
-                    makeQueryFacet(schema,queryFacetSet,m.group(1),params.getParams(param));
-                  }  else {
-                    // Check if query
-                    m = queryFacetParamPattern.matcher(paramSequence);
-                    if (m.matches()) {
-                      setQueryFacetParam(schema,queryFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
-                    } 
-                  }
-                }
-              }
-            }
-          }
-        }
-      }
-    }
-    for (String reqName : requestMap.keySet()) {
-      AnalyticsRequest ar = requestMap.get(reqName);
-      List<FieldFacetRequest> ffrs = new ArrayList<>();
-      if (fieldFacetSet.get(reqName)!=null) {
-        for (String field : fieldFacetSet.get(reqName)) {
-          ffrs.add(fieldFacetMap.get(reqName).get(field));
-        }
-      }
-      ar.setFieldFacets(ffrs);
-      
-      List<RangeFacetRequest> rfrs = new ArrayList<>();
-      if (rangeFacetSet.get(reqName)!=null) {
-        for (String field : rangeFacetSet.get(reqName)) {
-          RangeFacetRequest rfr = rangeFacetMap.get(reqName).get(field);
-          if (rfr != null) {
-            rfrs.add(rfr);
-          }
-        }
-      }
-      ar.setRangeFacets(rfrs);
-      
-      List<QueryFacetRequest> qfrs = new ArrayList<>();
-      if (queryFacetSet.get(reqName)!=null) {
-        for (String name : queryFacetSet.get(reqName)) {
-          QueryFacetRequest qfr = queryFacetMap.get(reqName).get(name);
-          if (qfr != null) {
-            addQueryFacet(qfrs,qfr);
-          }
-        }
-      }
-      for (QueryFacetRequest qfr : qfrs) {
-        if (qfr.getDependencies().size()>0) {
-          throw new SolrException(ErrorCode.BAD_REQUEST,"The query facet dependencies "+qfr.getDependencies().toString()+" either do not exist or are defined in a dependency looop.");
-        }
-      }
-      ar.setQueryFacets(qfrs);
-      requestList.add(ar);
-    }
-    return requestList; 
-  }
-
-  private static void makeFieldFacet(IndexSchema schema, Map<String, Map<String, FieldFacetRequest>> fieldFacetMap, Map<String, Set<String>> fieldFacetSet, String requestName, String[] fields) {
-    Map<String, FieldFacetRequest> facetMap = fieldFacetMap.get(requestName);
-    if (facetMap == null) {
-      facetMap = new HashMap<>();
-      fieldFacetMap.put(requestName, facetMap);
-    }
-    Set<String> set = fieldFacetSet.get(requestName);
-    if (set == null) {
-      set = new HashSet<>();
-      fieldFacetSet.put(requestName, set);
-    }
-    for (String field : fields) {
-      if (facetMap.get(field) == null) {
-        facetMap.put(field,new FieldFacetRequest(schema.getField(field)));
-      }
-      set.add(field);
-    }
-  }
-
-  private static void setFieldFacetParam(IndexSchema schema, Map<String, Map<String, FieldFacetRequest>> fieldFacetMap, String requestName, String field, String paramType, String[] params) {
-    Map<String, FieldFacetRequest> facetMap = fieldFacetMap.get(requestName);
-    if (facetMap == null) {
-      facetMap = new HashMap<>();
-      fieldFacetMap.put(requestName, facetMap);
-    }
-    FieldFacetRequest fr = facetMap.get(field);
-    if (fr == null) {
-      fr = new FieldFacetRequest(schema.getField(field));
-      facetMap.put(field,fr);
-    }
-    if (paramType.equals("limit")||paramType.equals("l")) {
-      fr.setLimit(Integer.parseInt(params[0]));
-    } else if (paramType.equals("offset")||paramType.equals("off")) {
-      fr.setOffset(Integer.parseInt(params[0]));
-    } else if (paramType.equals("hidden")||paramType.equals("h")) {
-      fr.setHidden(Boolean.parseBoolean(params[0]));
-    } else if (paramType.equals("showmissing")||paramType.equals("sm")) {
-      fr.showMissing(Boolean.parseBoolean(params[0]));
-    } else if (paramType.equals("sortstatistic")||paramType.equals("sortstat")||paramType.equals("ss")) {
-      fr.setSort(new FacetSortSpecification(params[0],fr.getDirection()));
-    } else if (paramType.equals("sortdirection")||paramType.equals("sd")) {
-      fr.setDirection(params[0]);
-    } 
-  }
-
-  private static void makeRangeFacet(IndexSchema schema, Map<String, Set<String>> rangeFacetSet, String requestName, String[] fields) {
-    Set<String> set = rangeFacetSet.get(requestName);
-    if (set == null) {
-      set = new HashSet<>();
-      rangeFacetSet.put(requestName, set);
-    }
-    for (String field : fields) {
-      set.add(field);
-    }
-  }
-
-  private static void setRangeFacetParam(IndexSchema schema, Map<String, Map<String, RangeFacetRequest>> rangeFacetMap, String requestName, String field, String paramType, String[] params) {
-    Map<String, RangeFacetRequest> facetMap = rangeFacetMap.get(requestName);
-    if (facetMap == null) {
-      facetMap = new HashMap<>();
-      rangeFacetMap.put(requestName, facetMap);
-    }
-    RangeFacetRequest rr = facetMap.get(field);
-    if (rr == null) {
-      rr = new RangeFacetRequest(schema.getField(field));
-      facetMap.put(field,rr);
-    }
-    if (paramType.equals("start")||paramType.equals("st")) {
-      rr.setStart(params[0]);
-    } else if (paramType.equals("end")||paramType.equals("e")) {
-      rr.setEnd(params[0]);
-    } else if (paramType.equals("gap")||paramType.equals("g")) {
-      rr.setGaps(params[0].split(","));
-    } else if (paramType.equals("hardend")||paramType.equals("he")) {
-      rr.setHardEnd(Boolean.parseBoolean(params[0]));
-    } else if (paramType.equals("includebound")||paramType.equals("ib")) {
-      for (String param : params) {
-        rr.addInclude(FacetRangeInclude.get(param));
-      }
-    } else if (paramType.equals("otherrange")||paramType.equals("or")) {
-      for (String param : params) {
-        rr.addOther(FacetRangeOther.get(param));
-      }
-    } 
-  }
-
-  private static void makeQueryFacet(IndexSchema schema,Map<String, Set<String>> queryFacetSet, String requestName, String[] names) {
-    Set<String> set = queryFacetSet.get(requestName);
-    if (set == null) {
-      set = new HashSet<>();
-      queryFacetSet.put(requestName, set);
-    }
-    for (String name : names) {
-      set.add(name);
-    }
-  }
-
-  private static void setQueryFacetParam(IndexSchema schema, Map<String, Map<String, QueryFacetRequest>> queryFacetMap, String requestName, String name, String paramType, String[] params) {
-    Map<String, QueryFacetRequest> facetMap = queryFacetMap.get(requestName);
-    if (facetMap == null) {
-      facetMap = new HashMap<>();
-      queryFacetMap.put(requestName, facetMap);
-    }
-    QueryFacetRequest qr = facetMap.get(name);
-    if (qr == null) {
-      qr = new QueryFacetRequest(name);
-      facetMap.put(name,qr);
-    }
-    if (paramType.equals("query")||paramType.equals("q")) {
-      for (String query : params) {
-        qr.addQuery(query);
-      }
-    } else if (paramType.equals("dependency")||paramType.equals("d")) {
-      for (String depend : params) {
-        qr.addDependency(depend);
-      }
-    }
-  }
-
-  private static void makeHiddenExpression(Map<String, AnalyticsRequest> requestMap, String requestName, String expressionName, String expression) {
-    AnalyticsRequest req = requestMap.get(requestName);
-    if (req == null) {
-      req = new AnalyticsRequest(requestName);
-      requestMap.put(requestName, req);
-    }
-    req.addHiddenExpression(new ExpressionRequest(expressionName,expression));
-  }
-
-  private static void makeExpression(Map<String, AnalyticsRequest> requestMap, String requestName, String expressionName, String expression) {
-    AnalyticsRequest req = requestMap.get(requestName);
-    if (req == null) {
-      req = new AnalyticsRequest(requestName);
-      requestMap.put(requestName, req);
-    }
-    req.addExpression(new ExpressionRequest(expressionName,expression));
-  }
-  
-  private static void addQueryFacet(List<QueryFacetRequest> currentList, QueryFacetRequest queryFacet) {
-    Set<String> depends = queryFacet.getDependencies();
-    int place = 0;
-    for (QueryFacetRequest qfr : currentList) {
-      if (qfr.getDependencies().remove(queryFacet.getName())) {
-        break;
-      }
-      place++;
-      depends.remove(qfr.getName());
-    }
-    currentList.add(place,queryFacet);
-    for (int count = place+1; count < currentList.size(); count++) {
-      currentList.get(count).getDependencies().remove(queryFacet.getName());
-    }
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
deleted file mode 100644
index adc6807..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
+++ /dev/null
@@ -1,138 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.io.IOException;
-import java.util.List;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.solr.analytics.accumulator.BasicAccumulator;
-import org.apache.solr.analytics.accumulator.FacetingAccumulator;
-import org.apache.solr.analytics.accumulator.ValueAccumulator;
-import org.apache.solr.analytics.plugin.AnalyticsStatisticsCollector;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.search.DocSet;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Class which computes the set of {@link AnalyticsRequest}s.
- */
-public class AnalyticsStats {
-  protected DocSet docs;
-  protected SolrParams params;
-  protected SolrIndexSearcher searcher;
-  protected SolrQueryRequest req;
-  protected AnalyticsStatisticsCollector statsCollector;
-  private static final Logger log = LoggerFactory.getLogger(AnalyticsStats.class);
-  
-  public AnalyticsStats(SolrQueryRequest req, DocSet docs, SolrParams params, AnalyticsStatisticsCollector statsCollector) {
-    this.req = req;
-    this.searcher = req.getSearcher();
-    this.docs = docs;
-    this.params = params; 
-    this.statsCollector = statsCollector;
-  }
-
-  /**
-   * Calculates the analytics requested in the Parameters.
-   * 
-   * @return List of results formated to mirror the input XML.
-   * @throws IOException if execution fails
-   */
-  public NamedList<?> execute() throws IOException {
-    statsCollector.startRequest();
-    NamedList<Object> res = new NamedList<>();
-    List<AnalyticsRequest> requests;
-    
-    requests = AnalyticsRequestFactory.parse(searcher.getSchema(), params);
-
-    if(requests == null || requests.size()==0){
-      return res;
-    }
-    statsCollector.addRequests(requests.size());
-    
-    // Get filter to all docs
-    Filter filter = docs.getTopFilter();
-    
-    // Computing each Analytics Request Seperately
-    for( AnalyticsRequest areq : requests ){
-      // The Accumulator which will control the statistics generation
-      // for the entire analytics request
-      ValueAccumulator accumulator; 
-      
-      // The number of total facet requests
-      int facets = areq.getFieldFacets().size()+areq.getRangeFacets().size()+areq.getQueryFacets().size();
-      try {
-        if( facets== 0 ){
-          accumulator = BasicAccumulator.create(searcher, docs, areq);
-        } else {
-          accumulator = FacetingAccumulator.create(searcher, docs, areq, req);
-        }
-      } catch (IOException e) {
-        log.warn("Analytics request '"+areq.getName()+"' failed", e);
-        continue;
-      }
-
-      statsCollector.addStatsCollected(((BasicAccumulator)accumulator).getNumStatsCollectors());
-      statsCollector.addStatsRequests(areq.getExpressions().size());
-      statsCollector.addFieldFacets(areq.getFieldFacets().size());
-      statsCollector.addRangeFacets(areq.getRangeFacets().size());
-      statsCollector.addQueryFacets(areq.getQueryFacets().size());
-      statsCollector.addQueries(((BasicAccumulator)accumulator).getNumQueries());
-      
-      // Loop through the documents returned by the query and add to accumulator
-      List<AtomicReaderContext> contexts = searcher.getTopReaderContext().leaves();
-      for (int leafNum = 0; leafNum < contexts.size(); leafNum++) {
-        AtomicReaderContext context = contexts.get(leafNum);
-        DocIdSet dis = filter.getDocIdSet(context, null); // solr docsets already exclude any deleted docs
-        DocIdSetIterator disi = null;
-        if (dis != null) {
-          disi = dis.iterator();
-        }
-
-        if (disi != null) {
-          accumulator.getLeafCollector(context);
-          int doc = disi.nextDoc();
-          while( doc != DocIdSetIterator.NO_MORE_DOCS){
-            // Add a document to the statistics being generated
-            accumulator.collect(doc);
-            doc = disi.nextDoc();
-          }
-        }
-      }
-      
-      // do some post-processing
-      accumulator.postProcess();
-     
-      // compute the stats
-      accumulator.compute();
-      
-      res.add(areq.getName(),accumulator.export());
-    }
-
-    statsCollector.endRequest();
-    return res;
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/ExpressionRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/ExpressionRequest.java
deleted file mode 100644
index 1549cdf..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/ExpressionRequest.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import org.apache.solr.analytics.expression.Expression;
-
-/**
- * Contains name and string representation of an expression.
- */
-public class ExpressionRequest implements Comparable<ExpressionRequest> {
-  private String name;
-  private String expressionString;
-  private Expression expression;
-  
-  /**
-   * @param name The name of the Expression.
-   * @param expressionString The string representation of the desired Expression.
-   */
-  public ExpressionRequest(String name, String expressionString) {
-    this.name = name;
-    this.expressionString = expressionString;
-  }
-
-  public void setExpressionString(String expressionString) {
-    this.expressionString = expressionString;
-  }
-  
-  public String getExpressionString() {
-    return expressionString;
-  }
-  
-  public void setExpression(Expression expression) {
-    this.expression = expression;
-  }
-  
-  public Expression getExpression() {
-    return expression;
-  }
-  
-  public void setName(String name) {
-    this.name = name;
-  }
-  
-  public String getName() {
-    return name;
-  }
-
-  @Override
-  public int compareTo(ExpressionRequest o) {
-    return name.compareTo(o.getName());
-  }
-  
-  @Override
-  public String toString() {
-    return "<ExpressionRequest name=" + name + " expression=" + expressionString + "/>";
-  }
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FacetRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FacetRequest.java
deleted file mode 100644
index 6cca99d..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FacetRequest.java
+++ /dev/null
@@ -1,27 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-public interface FacetRequest {
-  
-  /**
-   * Get the name of this facet (commonly the field name)
-   * @return the name
-   */
-  String getName();  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java
deleted file mode 100644
index 7884476..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java
+++ /dev/null
@@ -1,173 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.schema.SchemaField;
-
-import java.util.Locale;
-
-
-/**
- * Contains all of the specifications for a field facet.
- */
-public class FieldFacetRequest extends AbstractFieldFacetRequest {
-
-  private FacetSortSpecification sort = null;
-  private FacetSortDirection dir = null;
-  private int limit;
-  private int offset;
-  private boolean missing;
-  private boolean hidden;
-  
-  
-  public static enum FacetSortDirection {
-    ASCENDING ,
-    DESCENDING;
-   
-    public static FacetSortDirection fromExternal(String value){
-      final String sort = value.toLowerCase(Locale.ROOT);
-      if( "asc".equals(sort) )            return ASCENDING;
-      if( "ascending".equals(sort) )      return ASCENDING;
-      if( "desc".equals(sort) )           return DESCENDING;
-      if( "descending".equals(sort) )     return DESCENDING;
-      return Enum.valueOf(FacetSortDirection.class, value);
-    }
-  }
-  
-  /**
-   * Specifies how to sort the buckets of a field facet.
-   * 
-   */
-  public static class FacetSortSpecification {
-    private String statistic;
-    private FacetSortDirection direction = FacetSortDirection.DESCENDING;
-    
-    public FacetSortSpecification(){}
-    
-    /**
-     * @param statistic The name of a statistic specified in the {@link AnalyticsRequest}
-     * which is wrapping the {@link FieldFacetRequest} being sorted.
-     */
-    public FacetSortSpecification(String statistic) {
-      this.statistic = statistic;
-    }
-    
-    public FacetSortSpecification(String statistic, FacetSortDirection direction) {
-      this(statistic);
-      this.direction = direction;
-    }
-    
-    public String getStatistic() {
-      return statistic;
-    }
-    public void setStatistic(String statistic) {
-      this.statistic = statistic;
-    }
-    public FacetSortDirection getDirection() {
-      return direction;
-    }
-    public void setDirection(FacetSortDirection direction) {
-      this.direction = direction;
-    }
-
-    public static FacetSortSpecification fromExternal(String spec){
-      String[] parts = spec.split(" ",2);
-      if( parts.length == 1 ){
-        return new FacetSortSpecification(parts[0]);
-      } else {
-        return new FacetSortSpecification(parts[0], FacetSortDirection.fromExternal(parts[1]));
-      }
-    }
-
-    @Override
-    public String toString() {
-      return "<SortSpec stat=" + statistic + " dir=" + direction + ">";
-    }
-  }
-
-  public FieldFacetRequest(SchemaField field) {
-    super(field);
-    this.limit = AnalyticsParams.DEFAULT_LIMIT;
-    this.hidden = AnalyticsParams.DEFAULT_HIDDEN;
-  }
-
-  public FacetSortDirection getDirection() {
-    return dir;
-  }
-
-  public void setDirection(String dir) {
-    this.dir = FacetSortDirection.fromExternal(dir);
-    if (sort!=null) {
-      sort.setDirection(this.dir);
-    }
-  }
-
-  public FacetSortSpecification getSort() {
-    return sort;
-  }
-
-  public void setSort(FacetSortSpecification sort) {
-    this.sort = sort;
-  }
-
-  public boolean showsMissing() {
-    return missing;
-  }
-
-  /**
-   * If there are missing values in the facet field, include the bucket 
-   * for the missing facet values in the facet response.
-   * @param missing true/false if we calculate missing
-   */
-  public void showMissing(boolean missing) {
-    this.missing = missing;
-  }
-
-  public int getLimit() {
-    return limit;
-  }
-
-  public void setLimit(int limit) {
-    this.limit = limit;
-  }
-  
-  public int getOffset() {
-    return offset;
-  }
-
-  public void setOffset(int offset) {
-    this.offset = offset;
-  }
-
-  public boolean isHidden() {
-    return hidden;
-  }
-
-  public void setHidden(boolean hidden) {
-    this.hidden = hidden;
-  }
-
-  @Override
-  public String toString() {
-    return "<FieldFacetRequest field="+field.getName()+(sort==null?"":" sort=" + sort) + " limit=" + limit+" offset="+offset+">";
-  }
-
-
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java
deleted file mode 100644
index b02740c..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java
+++ /dev/null
@@ -1,75 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-/**
- * Contains all of the specifications for a query facet.
- */
-public class QueryFacetRequest implements FacetRequest {
-  private String name;
-  private List<String> queries;
-  private Set<String> dependencies;
-  
-  public QueryFacetRequest() {
-    dependencies = new HashSet<>();
-  }
-
-  public QueryFacetRequest(String name) {
-    this.name = name;
-    this.queries = new ArrayList<>();
-    dependencies = new HashSet<>();
-  }
- 
-  public List<String> getQueries() {
-    return queries;
-  }
-
-  public void setQueries(List<String> queries) {
-    this.queries = queries;
-  }
-
-  public void addQuery(String query) {
-    queries.add(query);
-  }
-
-  public Set<String> getDependencies() {
-    return dependencies;
-  }
-
-  public void setDependencies(Set<String> dependencies) {
-    this.dependencies = dependencies;
-  }
-
-  public void addDependency(String dependency) {
-    dependencies.add(dependency);
-  }
-
-  public String getName() {
-    return name;
-  }
-
-  public void setName(String name) {
-    this.name = name;
-  }
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java solr/contrib/analytics/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java
deleted file mode 100644
index 8c70b98..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java
+++ /dev/null
@@ -1,130 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.request;
-
-import java.util.Arrays;
-import java.util.EnumSet;
-
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
-import org.apache.solr.common.params.FacetParams.FacetRangeOther;
-import org.apache.solr.schema.SchemaField;
-
-/**
- * Contains all of the specifications for a range facet.
- */
-public class RangeFacetRequest extends AbstractFieldFacetRequest {
-  protected String start;
-  protected String end;
-  protected String[] gaps;
-  protected boolean hardEnd = false;
-  protected EnumSet<FacetRangeInclude> include;
-  protected boolean includeCalled = false;
-  protected EnumSet<FacetRangeOther> others;
-  protected boolean othersCalled = false;
-  
-  public RangeFacetRequest(SchemaField field) {
-    super(field);
-    include = EnumSet.of(AnalyticsParams.DEFAULT_INCLUDE);
-    others = EnumSet.of(AnalyticsParams.DEFAULT_OTHER);
-  }
-  
-  public RangeFacetRequest(SchemaField field, String start, String end, String[] gaps) {
-    super(field);
-    this.start = start;
-    this.end = end;
-    this.gaps = gaps;
-  }
-
-  public String getStart() {
-    return start;
-  }
-
-  public void setStart(String start) {
-    this.start = start;
-  }
-
-  public String getEnd() {
-    return end;
-  }
-
-  public void setEnd(String end) {
-    this.end = end;
-  }
-
-  public EnumSet<FacetRangeInclude> getInclude() {
-    return include;
-  }
-
-  public void setInclude(EnumSet<FacetRangeInclude> include) {
-    includeCalled = true;
-    this.include = include;
-  }
-
-  public void addInclude(FacetRangeInclude include) {
-    if (includeCalled) {
-      this.include.add(include);
-    } else {
-      includeCalled = true;
-      this.include = EnumSet.of(include);
-    }
-  }
-
-  public String[] getGaps() {
-    return gaps;
-  }
-
-  public void setGaps(String[] gaps) {
-    this.gaps = gaps;
-  }
-
-  public boolean isHardEnd() {
-    return hardEnd;
-  }
-
-  public void setHardEnd(boolean hardEnd) {
-    this.hardEnd = hardEnd;
-  }
-
-  public EnumSet<FacetRangeOther> getOthers() {
-    return others;
-  }
-
-  public void setOthers(EnumSet<FacetRangeOther> others) {
-    othersCalled = true;
-    this.others = others;
-  }
-
-  public void addOther(FacetRangeOther other) {
-    if (othersCalled) {
-      this.others.add(other);
-    } else {
-      othersCalled = true;
-      this.others = EnumSet.of(other);
-    }
-  }
-
-  @Override
-  public String toString() {
-    return "<RangeFacetRequest field="+field.getName() + " start=" + start + ", end=" + end + ", gap=" + Arrays.toString(gaps) + ", hardEnd=" + hardEnd + 
-                               ", include=" + include + ", others=" + others +">";
-  }
-
-  
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/request/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/request/package.html
deleted file mode 100644
index 08822a9..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/request/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Request objects for creating Analytics requests
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java
deleted file mode 100644
index 093ab29..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java
+++ /dev/null
@@ -1,75 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.util.mutable.MutableValue;
-
-/**
- * <code>AbstractDelegationStatsCollector</code> objects wrap other StatsCollectors.
- * While they compute their own statistics they pass along all inputs and requests
- * to the delegates as well.
- */
-public abstract class AbstractDelegatingStatsCollector implements StatsCollector{
-  protected final StatsCollector delegate;
-  protected final Set<String> statsList;
-  MutableValue value;
-  FunctionValues function;
-  
-  /**
-   * @param delegate The delegate computing statistics on the same set of values.
-   */
-  public AbstractDelegatingStatsCollector(StatsCollector delegate) {
-    this.delegate = delegate;
-    this.statsList = delegate.getStatsList();
-  }
-  
-  public void setNextReader(AtomicReaderContext context) throws IOException {
-    delegate.setNextReader(context);
-    value = getValue();
-    function = getFunction();
-  }
-  
-  public StatsCollector delegate(){
-    return delegate;
-  }
-  
-  public Set<String> getStatsList(){
-    return statsList;
-  }
-  
-  public MutableValue getValue() {
-    return delegate.getValue();
-  }
-  
-  public FunctionValues getFunction() {
-    return delegate.getFunction();
-  }
-  
-  public void collect(int doc) {
-    delegate.collect(doc);
-  }
-  
-  public String valueSourceString() {
-    return delegate.valueSourceString();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java
deleted file mode 100644
index 8095536..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.List;
-
-import org.apache.solr.analytics.util.MedianCalculator;
-
-/**
- * <code>MedianStatsCollector</code> computes the median.
- */
-public class MedianStatsCollector extends AbstractDelegatingStatsCollector{
-
-  private final List<Double> values = new ArrayList<>();
-  protected double median;
-  
-  public MedianStatsCollector(StatsCollector delegate) {
-    super(delegate);
-  }
-
-  public Double getMedian() {
-    return new Double(MedianCalculator.getMedian(values));
-  }
-
-  @Override
-  public Comparable getStat(String stat) {
-    if (stat.equals("median")) {
-      return new Double(median);
-    }
-    return delegate.getStat(stat);
-  }
-  
-  public void compute(){
-    delegate.compute();
-    median = getMedian();
-  }
-  
-  @Override
-  public void collect(int doc) {
-    super.collect(doc);
-    if (value.exists) {
-      values.add(function.doubleVal(doc));
-    }
-  }
-}
-class DateMedianStatsCollector extends MedianStatsCollector{
-  
-  public DateMedianStatsCollector(StatsCollector delegate) {
-    super(delegate);
-  }
-
-  @Override
-  public Comparable getStat(String stat) {
-    if (stat.equals("median")) {
-      return new Date((long)median);
-    }
-    return delegate.getStat(stat);
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java
deleted file mode 100644
index 45cec2b..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java
+++ /dev/null
@@ -1,115 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.io.IOException;
-import java.util.Locale;
-import java.util.Set;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.FunctionValues.ValueFiller;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.util.mutable.MutableValue;
-
-/**
- * <code>MinMaxStatsCollector</code> computes the min, max, number of values and number of missing values.
- */
-public class MinMaxStatsCollector implements StatsCollector{
-  protected long missingCount = 0;
-  protected long valueCount = 0;
-  protected MutableValue max;
-  protected MutableValue min;
-  protected MutableValue value;
-  protected final Set<String> statsList;
-  protected final ValueSource source;
-  protected FunctionValues function;
-  protected ValueFiller valueFiller;
-  
-  public MinMaxStatsCollector(ValueSource source, Set<String> statsList) {
-    this.source = source;
-    this.statsList = statsList;
-  }
-  
-  public void setNextReader(AtomicReaderContext context) throws IOException {
-    function = source.getValues(null, context);
-    valueFiller = function.getValueFiller();
-    value = valueFiller.getValue();
-  }
-  
-  public void collect(int doc) {
-    valueFiller.fillValue(doc);
-    if( value.exists ){
-      valueCount += 1;
-      if ( max==null ) max = value.duplicate();
-      else if( !max.exists || value.compareTo(max) > 0 ) max.copy(value);
-      if ( min==null ) min = value.duplicate();
-      else if( !min.exists || value.compareTo(min) < 0 ) min.copy(value);
-    } else {
-      missingCount += 1;
-    }
-  }
- 
-  @Override
-  public String toString() {
-    return String.format(Locale.ROOT, "<min=%s max=%s c=%d m=%d>", min, max, valueCount, missingCount );
-  }
-  
-  public Comparable getStat(String stat){
-    if (stat.equals("min")&&min!=null) {
-      return (Comparable)min.toObject();
-    }
-    if (stat.equals("max")&&max!=null) {
-      return (Comparable)max.toObject();
-    }
-    if (stat.equals("count")) {
-      return new Long(valueCount);
-    }
-    if (stat.equals("missing")) {
-      return new Long(missingCount);
-    }
-
-    return null;
-//    throw new IllegalArgumentException("No stat named '"+stat+"' in this collector " + this);
-  }
-  
-  public Set<String> getStatsList() {
-    return statsList;
-  }
-
-  @Override
-  public void compute() {  }
-  
-  @Override 
-  public MutableValue getValue() {
-    return value;
-  }
-  
-  @Override 
-  public FunctionValues getFunction() {
-    return function;
-  }
-  
-  public String valueSourceString() {
-    return source.toString();
-  }
-  
-  public String statString(String stat) {
-    return stat+"("+valueSourceString()+")";
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java
deleted file mode 100644
index ef3de5d..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.util.Set;
-
-import org.apache.lucene.queries.function.ValueSource;
-
-/**
- * <code>NumericStatsCollector</code> computes the sum, sum of squares, mean and standard deviation.
- */
-public class NumericStatsCollector extends MinMaxStatsCollector {
-  protected double sum = 0;
-  protected double sumOfSquares = 0;
-  protected double mean = 0;
-  protected double stddev = 0;
-  
-  public NumericStatsCollector(ValueSource source, Set<String> statsList) {
-    super(source, statsList);
-  }
-  
-  public void collect(int doc) {
-    super.collect(doc);
-    double value = function.doubleVal(doc);
-    sum += value;
-    sumOfSquares += (value * value);
-  }
-  
-  @Override
-  public Comparable getStat(String stat) {
-    if (stat.equals("sum")) {
-      return new Double(sum);
-    }
-    if (stat.equals("sumofsquares")) {
-      return new Double(sumOfSquares);
-    }
-    if (stat.equals("mean")) {
-      return new Double(mean);
-    }
-    if (stat.equals("stddev")) {
-      return new Double(stddev);
-    }
-    return super.getStat(stat);
-  }  
-  
-  @Override
-  public void compute(){
-    super.compute();
-    mean = (valueCount==0)? 0:sum / valueCount;
-    stddev = (valueCount <= 1) ? 0.0D : Math.sqrt((sumOfSquares/valueCount) - (mean*mean));
-  }
-  
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java
deleted file mode 100644
index 2ddfb99..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.regex.Pattern;
-
-import org.apache.solr.analytics.util.PercentileCalculator;
-
-import com.google.common.collect.Iterables;
-
-/**
- * <code>PercentileStatsCollector</code> computes a given list of percentiles.
- */
-@SuppressWarnings("rawtypes")
-public class PercentileStatsCollector extends AbstractDelegatingStatsCollector{
-  public final List<Comparable> values = new ArrayList<>();
-  public static final Pattern PERCENTILE_PATTERN = Pattern.compile("perc(?:entile)?_(\\d+)",Pattern.CASE_INSENSITIVE);
-  protected final double[] percentiles;
-  protected final String[] percentileNames;
-  protected Comparable[] results;
-  
-  public PercentileStatsCollector(StatsCollector delegate, double[] percentiles, String[] percentileNames) {
-    super(delegate);
-    this.percentiles = percentiles;
-    this.percentileNames = percentileNames;
-  }
-
-  @Override
-  public Comparable getStat(String stat) {
-    for( int i=0; i < percentiles.length; i++ ){
-      if (stat.equals(percentileNames[i])) {
-        if (results!=null) {
-          return results[i];
-        } else {
-          return null;
-        }
-      }
-    }
-    return delegate.getStat(stat);
-  }
-
-  public void compute(){
-    delegate.compute();
-    if (values.size()>0) {
-      results = Iterables.toArray(getPercentiles(),Comparable.class);
-    } else {
-      results = null;
-    }
-  }
-
-  @SuppressWarnings({ "unchecked"})
-  protected List<Comparable> getPercentiles() {
-    return PercentileCalculator.getPercentiles(values, percentiles);
-  }
-  
-  public void collect(int doc) {
-    super.collect(doc);
-    if (value.exists) {
-      values.add((Comparable)value.toObject());
-    }
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollector.java
deleted file mode 100644
index b3f173d..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollector.java
+++ /dev/null
@@ -1,70 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.util.mutable.MutableValue;
-
-/**
- * <code>StatsCollector</code> implementations reduce a list of Objects to a single value.
- * Most implementations reduce a list to a statistic on that list.
- */
-public interface StatsCollector {
-  
-  /**
-   * Collect values from the value source and add to statistics.
-   * @param doc Document to collect from
-   */
-  void collect(int doc);
-  
-  /**
-   * @param context The context to read documents from.
-   * @throws IOException if setting next reader fails
-   */
-  void setNextReader(AtomicReaderContext context) throws IOException;
-  
-  MutableValue getValue();
-  FunctionValues getFunction();
-  
-  /**
-   * @return The set of statistics being computed by the stats collector.
-   */
-  Set<String> getStatsList();
-  
-  /**
-   * Return the value of the given statistic.
-   * @param stat the stat
-   * @return a comparable
-   */
-  Comparable getStat(String stat);
-  
-  /**
-   * After all documents have been collected, this method should be
-   * called to finalize the calculations of each statistic.
-   */
-  void compute();
-  
-  /**
-   * @return The string representation of the value source.
-   */
-  String valueSourceString();
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java
deleted file mode 100644
index 35b5d58..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java
+++ /dev/null
@@ -1,658 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeMap;
-
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
-import org.apache.lucene.queries.function.valuesource.DoubleFieldSource;
-import org.apache.lucene.queries.function.valuesource.FloatFieldSource;
-import org.apache.lucene.queries.function.valuesource.IntFieldSource;
-import org.apache.lucene.queries.function.valuesource.LongFieldSource;
-import org.apache.solr.analytics.expression.ExpressionFactory;
-import org.apache.solr.analytics.request.ExpressionRequest;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.analytics.util.AnalyticsParsers;
-import org.apache.solr.analytics.util.valuesource.AbsoluteValueDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.AddDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.ConcatStringFunction;
-import org.apache.solr.analytics.util.valuesource.ConstDateSource;
-import org.apache.solr.analytics.util.valuesource.ConstDoubleSource;
-import org.apache.solr.analytics.util.valuesource.ConstStringSource;
-import org.apache.solr.analytics.util.valuesource.DateFieldSource;
-import org.apache.solr.analytics.util.valuesource.DateMathFunction;
-import org.apache.solr.analytics.util.valuesource.DivDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.DualDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.FilterFieldSource;
-import org.apache.solr.analytics.util.valuesource.LogDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.MultiDateFunction;
-import org.apache.solr.analytics.util.valuesource.MultiDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.MultiplyDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.NegateDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.PowDoubleFunction;
-import org.apache.solr.analytics.util.valuesource.ReverseStringFunction;
-import org.apache.solr.analytics.util.valuesource.SingleDoubleFunction;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.IndexSchema;
-import org.apache.solr.schema.SchemaField;
-import org.apache.solr.schema.StrField;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.schema.TrieDoubleField;
-import org.apache.solr.schema.TrieFloatField;
-import org.apache.solr.schema.TrieIntField;
-import org.apache.solr.schema.TrieLongField;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.google.common.base.Supplier;
-
-public class StatsCollectorSupplierFactory {
-  private static final Logger log = LoggerFactory.getLogger(StatsCollectorSupplierFactory.class);
-  
-  // FunctionTypes
-  final static int NUMBER_TYPE = 0;
-  final static int DATE_TYPE = 1;
-  final static int STRING_TYPE = 2;
-  final static int FIELD_TYPE = 3;
-  final static int FILTER_TYPE = 4;
-  
-  /**
-   * Builds a Supplier that will generate identical arrays of new StatsCollectors.
-   * 
-   * @param schema The Schema being used.
-   * @param exRequests The expression requests to generate a StatsCollector[] from.
-   * @return A Supplier that will return an array of new StatsCollector.
-   */
-  @SuppressWarnings("unchecked")
-  public static Supplier<StatsCollector[]> create(IndexSchema schema, List<ExpressionRequest> exRequests ) {
-    final Map<String, Set<String>> collectorStats =  new TreeMap<>();
-    final Map<String, Set<Integer>> collectorPercs =  new TreeMap<>();
-    final Map<String, ValueSource> collectorSources =  new TreeMap<>();
-    
-    // Iterate through all expression request to make a list of ValueSource strings
-    // and statistics that need to be calculated on those ValueSources.
-    for (ExpressionRequest expRequest : exRequests) {
-      String statExpression = expRequest.getExpressionString();
-      Set<String> statistics = getStatistics(statExpression);
-      if (statistics == null) {
-        continue;
-      }
-      for (String statExp : statistics) {
-        String stat;
-        String operands;
-        try {
-          stat = statExp.substring(0, statExp.indexOf('(')).trim();
-          operands = statExp.substring(statExp.indexOf('(')+1, statExp.lastIndexOf(')')).trim();
-        } catch (Exception e) {
-          throw new SolrException(ErrorCode.BAD_REQUEST,"Unable to parse statistic: ["+statExpression+"]",e);
-        }
-        String[] arguments = ExpressionFactory.getArguments(operands);
-        String source = arguments[0];
-        if (stat.equals(AnalyticsParams.STAT_PERCENTILE)) {
-          // The statistic is a percentile, extra parsing is required
-          if (arguments.length<2) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"Too few arguments given for "+stat+"() in ["+statExp+"].");
-          } else if (arguments.length>2) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"Too many arguments given for "+stat+"() in ["+statExp+"].");
-          }
-          source = arguments[1];
-          Set<Integer> percs = collectorPercs.get(source);
-          if (percs == null) {
-            percs = new HashSet<>();
-            collectorPercs.put(source, percs);
-          }
-          try {
-            int perc = Integer.parseInt(arguments[0]);
-            if (perc>0 && perc<100) {
-              percs.add(perc);
-            } else {
-              throw new SolrException(ErrorCode.BAD_REQUEST,"The percentile in ["+statExp+"] is not between 0 and 100, exculsive.");
-            }
-          } catch (NumberFormatException e) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+arguments[0]+"\" cannot be converted into a percentile.",e);
-          }
-        } else if (arguments.length>1) {
-          throw new SolrException(ErrorCode.BAD_REQUEST,"Too many arguments given for "+stat+"() in ["+statExp+"].");
-        } else if (arguments.length==0) {
-          throw new SolrException(ErrorCode.BAD_REQUEST,"No arguments given for "+stat+"() in ["+statExp+"].");
-        } 
-        // Only unique ValueSources will be made; therefore statistics must be accumulated for
-        // each ValueSource, even across different expression requests
-        Set<String> stats = collectorStats.get(source);
-        if (stats == null) {
-          stats = new HashSet<>();
-          collectorStats.put(source, stats);
-        }
-        if(AnalyticsParams.STAT_PERCENTILE.equals(stat)) {
-          stats.add(stat + "_"+ arguments[0]);
-        } else {
-          stats.add(stat);
-        }
-      }
-    }
-    String[] keys = collectorStats.keySet().toArray(new String[0]);
-    for (String sourceStr : keys) {
-      // Build one ValueSource for each unique value source string
-      ValueSource source = buildSourceTree(schema, sourceStr);
-      if (source == null) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The statistic ["+sourceStr+"] could not be parsed.");
-      }
-      String builtString = source.toString();
-      collectorSources.put(builtString,source);
-      // Replace the user given string with the correctly built string
-      if (!builtString.equals(sourceStr)) {
-        Set<String> stats = collectorStats.remove(sourceStr);
-        if (stats!=null) {
-          collectorStats.put(builtString, stats);
-        }
-        Set<Integer> percs = collectorPercs.remove(sourceStr);
-        if (percs!=null) {
-          collectorPercs.put(builtString, percs);
-        }
-        for (ExpressionRequest er : exRequests) {
-          er.setExpressionString(er.getExpressionString().replace(sourceStr, builtString));
-        }
-      }
-    }
-    if (collectorSources.size()==0) {
-      return new Supplier<StatsCollector[]>() {
-        @Override
-        public StatsCollector[] get() {
-          return new StatsCollector[0];
-        }
-      };
-    }
-    
-    log.info("Stats objects: "+collectorStats.size()+" sr="+collectorSources.size()+" pr="+collectorPercs.size() );
-    
-    // All information is stored in final arrays so that nothing 
-    // has to be computed when the Supplier's get() method is called.
-    final Set<String>[] statsArr = collectorStats.values().toArray(new Set[0]);
-    final ValueSource[] sourceArr = collectorSources.values().toArray(new ValueSource[0]);
-    final boolean[] uniqueBools = new boolean[statsArr.length];
-    final boolean[] medianBools = new boolean[statsArr.length];
-    final boolean[] numericBools = new boolean[statsArr.length];
-    final boolean[] dateBools = new boolean[statsArr.length];
-    final double[][] percsArr = new double[statsArr.length][];
-    final String[][] percsNames = new String[statsArr.length][];
-    for (int count = 0; count < sourceArr.length; count++) {
-      uniqueBools[count] = statsArr[count].contains(AnalyticsParams.STAT_UNIQUE);
-      medianBools[count] = statsArr[count].contains(AnalyticsParams.STAT_MEDIAN);
-      numericBools[count] = statsArr[count].contains(AnalyticsParams.STAT_SUM)||statsArr[count].contains(AnalyticsParams.STAT_SUM_OF_SQUARES)||statsArr[count].contains(AnalyticsParams.STAT_MEAN)||statsArr[count].contains(AnalyticsParams.STAT_STANDARD_DEVIATION);
-      dateBools[count] = (sourceArr[count] instanceof DateFieldSource) | (sourceArr[count] instanceof MultiDateFunction) | (sourceArr[count] instanceof ConstDateSource);
-      Set<Integer> ps = collectorPercs.get(sourceArr[count].toString());
-      if (ps!=null) {
-        percsArr[count] = new double[ps.size()];
-        percsNames[count] = new String[ps.size()];
-        int percCount = 0;
-        for (int p : ps) {
-          percsArr[count][percCount] = p/100.0;
-          percsNames[count][percCount++] = AnalyticsParams.STAT_PERCENTILE+"_"+p;
-        }
-      }
-    }
-    // Making the Supplier
-    return new Supplier<StatsCollector[]>() {
-      public StatsCollector[] get() {
-        StatsCollector[] collectors = new StatsCollector[statsArr.length];
-        for (int count = 0; count < statsArr.length; count++) {
-          if(numericBools[count]){
-            StatsCollector sc = new NumericStatsCollector(sourceArr[count], statsArr[count]);
-            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
-            if(medianBools[count]) sc = new MedianStatsCollector(sc);
-            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
-            collectors[count]=sc;
-          } else if (dateBools[count]) {
-            StatsCollector sc = new MinMaxStatsCollector(sourceArr[count], statsArr[count]);
-            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
-            if(medianBools[count]) sc = new DateMedianStatsCollector(sc);
-            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
-           collectors[count]=sc;
-          } else {
-            StatsCollector sc = new MinMaxStatsCollector(sourceArr[count], statsArr[count]);
-            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
-            if(medianBools[count]) sc = new MedianStatsCollector(sc);
-            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
-            collectors[count]=sc;
-          }
-        }
-        return collectors;
-      }
-    };
-  }
-  
-  /**
-   * Finds the set of statistics that must be computed for the expression.
-   * @param expression The string representation of an expression
-   * @return The set of statistics (sum, mean, median, etc.) found in the expression
-   */
-  public static Set<String> getStatistics(String expression) {
-    HashSet<String> set = new HashSet<>();
-    int firstParen = expression.indexOf('(');
-    if (firstParen>0) {
-      String topOperation = expression.substring(0,firstParen).trim();
-      if (AnalyticsParams.ALL_STAT_SET.contains(topOperation)) {
-        set.add(expression);
-      } else if (!(topOperation.equals(AnalyticsParams.CONSTANT_NUMBER)||topOperation.equals(AnalyticsParams.CONSTANT_DATE)||topOperation.equals(AnalyticsParams.CONSTANT_STRING))) {
-        String operands = expression.substring(firstParen+1, expression.lastIndexOf(')')).trim();
-        String[] arguments = ExpressionFactory.getArguments(operands);
-        for (String argument : arguments) {
-          Set<String> more = getStatistics(argument);
-          if (more!=null) {
-            set.addAll(more);
-          }
-        }
-      }
-    }
-    if (set.size()==0) {
-      return null;
-    }
-    return set;
-  }
-  
-  /**
-   * Builds a Value Source from a given string
-   * 
-   * @param schema The schema being used.
-   * @param expression The string to be turned into an expression.
-   * @return The completed ValueSource
-   */
-  private static ValueSource buildSourceTree(IndexSchema schema, String expression) {
-    return buildSourceTree(schema,expression,FIELD_TYPE);
-  }
-  
-  /**
-   * Builds a Value Source from a given string and a given source type
-   * 
-   * @param schema The schema being used.
-   * @param expression The string to be turned into an expression.
-   * @param sourceType The type of source that must be returned.
-   * @return The completed ValueSource
-   */
-  private static ValueSource buildSourceTree(IndexSchema schema, String expression, int sourceType) {
-    int expressionType = getSourceType(expression);
-    if (sourceType != FIELD_TYPE && expressionType != FIELD_TYPE && 
-        expressionType != FILTER_TYPE && expressionType != sourceType) {
-      return null;
-    }
-    switch (expressionType) {
-    case NUMBER_TYPE : return buildNumericSource(schema, expression);
-    case DATE_TYPE : return buildDateSource(schema, expression);
-    case STRING_TYPE : return buildStringSource(schema, expression);
-    case FIELD_TYPE : return buildFieldSource(schema, expression, sourceType);
-    case FILTER_TYPE : return buildFilterSource(schema, expression.substring(expression.indexOf('(')+1,expression.lastIndexOf(')')), sourceType);
-    default : throw new SolrException(ErrorCode.BAD_REQUEST,expression+" is not a valid operation.");
-    }
-  }
-
-  /**
-   * Determines what type of value source the expression represents.
-   * 
-   * @param expression The expression representing the desired ValueSource
-   * @return NUMBER_TYPE, DATE_TYPE, STRING_TYPE or -1
-   */
-  private static int getSourceType(String expression) {
-    int paren = expression.indexOf('(');
-    if (paren<0) {
-      return FIELD_TYPE;
-    }
-    String operation = expression.substring(0,paren).trim();
-
-    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)) {
-      return NUMBER_TYPE;
-    } else if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)) {
-      return DATE_TYPE;
-    } else if (AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
-      return STRING_TYPE;
-    } else if (operation.equals(AnalyticsParams.FILTER)) {
-      return FILTER_TYPE;
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+operation+"\" in ["+expression+"] is not supported.");
-  }
-  
-  /**
-   *  Builds a value source for a given field, making sure that the field fits a given source type.
-   * @param schema the schema
-   * @param expressionString The name of the field to build a Field Source from.
-   * @param sourceType FIELD_TYPE for any type of field, NUMBER_TYPE for numeric fields, 
-   * DATE_TYPE for date fields and STRING_TYPE for string fields.
-   * @return a value source
-   */
-  private static ValueSource buildFieldSource(IndexSchema schema, String expressionString, int sourceType) {
-    SchemaField sf;
-    try {
-      sf = schema.getField(expressionString);
-    } catch (SolrException e) {
-      throw new SolrException(ErrorCode.BAD_REQUEST,"The field "+expressionString+" does not exist.",e);
-    }
-    FieldType type = sf.getType();
-    if ( type instanceof TrieIntField) {
-      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new IntFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    } else if (type instanceof TrieLongField) {
-      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new LongFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    } else if (type instanceof TrieFloatField) {
-      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new FloatFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    } else if (type instanceof TrieDoubleField) {
-      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new DoubleFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    } else if (type instanceof TrieDateField) {
-      if (sourceType!=DATE_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new DateFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    } else if (type instanceof StrField) {
-      if (sourceType!=STRING_TYPE&&sourceType!=FIELD_TYPE) {
-        return null;
-      }
-      return new BytesRefFieldSource(expressionString) {
-        public String description() {
-          return field;
-        }
-      };
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST, type.toString()+" is not a supported field type in Solr Analytics.");
-  }
-  
-  /**
-   * Builds a default is missing source that wraps a given source. A missing value is required for all 
-   * non-field value sources.
-   * @param schema the schema
-   * @param expressionString The name of the field to build a Field Source from.
-   * @param sourceType FIELD_TYPE for any type of field, NUMBER_TYPE for numeric fields, 
-   * DATE_TYPE for date fields and STRING_TYPE for string fields.
-   * @return a value source
-   */
-  @SuppressWarnings("deprecation")
-  private static ValueSource buildFilterSource(IndexSchema schema, String expressionString, int sourceType) {
-    String[] arguments = ExpressionFactory.getArguments(expressionString);
-    if (arguments.length!=2) {
-      throw new SolrException(ErrorCode.BAD_REQUEST,"Invalid arguments were given for \""+AnalyticsParams.FILTER+"\".");
-    }
-    ValueSource delegateSource = buildSourceTree(schema, arguments[0], sourceType);
-    if (delegateSource==null) {
-      return null;
-    }
-    Object defaultObject;
-
-    ValueSource src = delegateSource;
-    if (delegateSource instanceof FilterFieldSource) {
-      src = ((FilterFieldSource)delegateSource).getRootSource();
-    }
-    if ( src instanceof IntFieldSource) {
-      try {
-        defaultObject = new Integer(arguments[1]);
-      } catch (NumberFormatException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into an integer.",e);
-      }
-    } else if ( src instanceof DateFieldSource || src instanceof MultiDateFunction) {
-      try {
-        defaultObject = TrieDateField.parseDate(arguments[1]);
-      } catch (ParseException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a date.",e);
-      }
-    } else if ( src instanceof LongFieldSource ) {
-      try {
-        defaultObject = new Long(arguments[1]);
-      } catch (NumberFormatException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a long.",e);
-      }
-    } else if ( src instanceof FloatFieldSource ) {
-      try {
-        defaultObject = new Float(arguments[1]);
-      } catch (NumberFormatException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a float.",e);
-      }
-    } else if ( src instanceof DoubleFieldSource || src instanceof SingleDoubleFunction ||
-                src instanceof DualDoubleFunction|| src instanceof MultiDoubleFunction) {
-      try {
-        defaultObject = new Double(arguments[1]);
-      } catch (NumberFormatException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a double.",e);
-      }
-    } else {
-      defaultObject = arguments[1];
-    }
-    return new FilterFieldSource(delegateSource,defaultObject);
-  } 
-  
-  /**
-   * Recursively parses and breaks down the expression string to build a numeric ValueSource.
-   * 
-   * @param schema The schema to pull fields from.
-   * @param expressionString The expression string to build a ValueSource from.
-   * @return The value source represented by the given expressionString
-   */
-  private static ValueSource buildNumericSource(IndexSchema schema, String expressionString) {
-    int paren = expressionString.indexOf('(');
-    String[] arguments;
-    String operands;
-    if (paren<0) {
-      return buildFieldSource(schema,expressionString,NUMBER_TYPE);
-    } else {
-      try {
-        operands = expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim();
-      } catch (Exception e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"Missing closing parenthesis in ["+expressionString+"]");
-      }
-      arguments = ExpressionFactory.getArguments(operands);
-    }
-    String operation = expressionString.substring(0, paren).trim();
-    if (operation.equals(AnalyticsParams.CONSTANT_NUMBER)) {
-      if (arguments.length!=1) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant number declaration ["+expressionString+"] does not have exactly 1 argument.");
-      }
-      return new ConstDoubleSource(Double.parseDouble(arguments[0]));
-    } else if (operation.equals(AnalyticsParams.NEGATE)) {
-      if (arguments.length!=1) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The negate operation ["+expressionString+"] does not have exactly 1 argument.");
-      }
-      ValueSource argSource = buildNumericSource(schema, arguments[0]);
-      if (argSource==null) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+AnalyticsParams.NEGATE+"\" requires a numeric field or operation as argument. \""+arguments[0]+"\" is not a numeric field or operation.");
-      }
-      return new NegateDoubleFunction(argSource);
-    }  else if (operation.equals(AnalyticsParams.ABSOLUTE_VALUE)) {
-      if (arguments.length!=1) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The absolute value operation ["+expressionString+"] does not have exactly 1 argument.");
-      }
-      ValueSource argSource = buildNumericSource(schema, arguments[0]);
-      if (argSource==null) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+AnalyticsParams.NEGATE+"\" requires a numeric field or operation as argument. \""+arguments[0]+"\" is not a numeric field or operation.");
-      }
-      return new AbsoluteValueDoubleFunction(argSource);
-    } else if (operation.equals(AnalyticsParams.FILTER)) {
-      return buildFilterSource(schema, operands, NUMBER_TYPE);
-    }
-    List<ValueSource> subExpressions = new ArrayList<>();
-    for (String argument : arguments) {
-      ValueSource argSource = buildNumericSource(schema, argument);
-      if (argSource == null) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+operation+"\" requires numeric fields or operations as arguments. \""+argument+"\" is not a numeric field or operation.");
-      }
-      subExpressions.add(argSource);
-    }
-    if (operation.equals(AnalyticsParams.ADD)) {
-      return new AddDoubleFunction(subExpressions.toArray(new ValueSource[0]));
-    } else if (operation.equals(AnalyticsParams.MULTIPLY)) {
-      return new MultiplyDoubleFunction(subExpressions.toArray(new ValueSource[0]));
-    } else if (operation.equals(AnalyticsParams.DIVIDE)) {
-      if (subExpressions.size()!=2) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The divide operation ["+expressionString+"] does not have exactly 2 arguments.");
-      }
-      return new DivDoubleFunction(subExpressions.get(0),subExpressions.get(1));
-    } else if (operation.equals(AnalyticsParams.POWER)) {
-      if (subExpressions.size()!=2) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The power operation ["+expressionString+"] does not have exactly 2 arguments.");
-      }
-      return new PowDoubleFunction(subExpressions.get(0),subExpressions.get(1));
-    } else if (operation.equals(AnalyticsParams.LOG)) {
-      if (subExpressions.size()!=2) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The log operation ["+expressionString+"] does not have exactly 2 arguments.");
-      }
-      return new LogDoubleFunction(subExpressions.get(0), subExpressions.get(1));
-    } 
-    if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)||AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
-      return null;
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
-  }
-
-  
-  /**
-   * Recursively parses and breaks down the expression string to build a date ValueSource.
-   * 
-   * @param schema The schema to pull fields from.
-   * @param expressionString The expression string to build a ValueSource from.
-   * @return The value source represented by the given expressionString
-   */
-  @SuppressWarnings("deprecation")
-  private static ValueSource buildDateSource(IndexSchema schema, String expressionString) {
-    int paren = expressionString.indexOf('(');
-    String[] arguments;
-    if (paren<0) {
-      return buildFieldSource(schema, expressionString, DATE_TYPE);
-    } else {
-      arguments = ExpressionFactory.getArguments(expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim());
-    }
-    String operands = arguments[0];
-    String operation = expressionString.substring(0, paren).trim();
-    if (operation.equals(AnalyticsParams.CONSTANT_DATE)) {
-      if (arguments.length!=1) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant date declaration ["+expressionString+"] does not have exactly 1 argument.");
-      }
-      try {
-        return new ConstDateSource(TrieDateField.parseDate(operands));
-      } catch (ParseException e) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant "+operands+" cannot be converted into a date.",e);
-      }
-    } else if (operation.equals(AnalyticsParams.FILTER)) {
-      return buildFilterSource(schema, operands, DATE_TYPE);
-    }
-    if (operation.equals(AnalyticsParams.DATE_MATH)) {
-      List<ValueSource> subExpressions = new ArrayList<>();
-      boolean first = true;
-      for (String argument : arguments) {
-        ValueSource argSource;
-        if (first) {
-          first = false;
-          argSource = buildDateSource(schema, argument);
-          if (argSource == null) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.DATE_MATH+"\" requires the first argument be a date operation or field. ["+argument+"] is not a date operation or field.");
-          }
-        } else {
-          argSource = buildStringSource(schema, argument);
-          if (argSource == null) {
-            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.DATE_MATH+"\" requires that all arguments except the first be string operations. ["+argument+"] is not a string operation.");
-          }
-        }
-        subExpressions.add(argSource);
-      }
-      return new DateMathFunction(subExpressions.toArray(new ValueSource[0]));
-    }
-    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)||AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
-      return null;
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
-  }
-
-  
-  /**
-   * Recursively parses and breaks down the expression string to build a string ValueSource.
-   * 
-   * @param schema The schema to pull fields from.
-   * @param expressionString The expression string to build a ValueSource from.
-   * @return The value source represented by the given expressionString
-   */
-  private static ValueSource buildStringSource(IndexSchema schema, String expressionString) {
-    int paren = expressionString.indexOf('(');
-    String[] arguments;
-    if (paren<0) {
-      return buildFieldSource(schema, expressionString, FIELD_TYPE);
-    } else {
-      arguments = ExpressionFactory.getArguments(expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim());
-    }
-    String operands = arguments[0];
-    String operation = expressionString.substring(0, paren).trim();
-    if (operation.equals(AnalyticsParams.CONSTANT_STRING)) {
-      operands = expressionString.substring(paren+1, expressionString.lastIndexOf(')'));
-      return new ConstStringSource(operands);
-    } else if (operation.equals(AnalyticsParams.FILTER)) {
-      return buildFilterSource(schema,operands,FIELD_TYPE);
-    } else if (operation.equals(AnalyticsParams.REVERSE)) {
-      if (arguments.length!=1) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.REVERSE+"\" requires exactly one argument. The number of arguments in "+expressionString+" is not 1.");
-      }
-      return new ReverseStringFunction(buildStringSource(schema, operands));
-    }
-    List<ValueSource> subExpressions = new ArrayList<>();
-    for (String argument : arguments) {
-      subExpressions.add(buildSourceTree(schema, argument));
-    }
-    if (operation.equals(AnalyticsParams.CONCATENATE)) {
-      return new ConcatStringFunction(subExpressions.toArray(new ValueSource[0]));
-    } 
-    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)) {
-      return buildNumericSource(schema, expressionString);
-    } else if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)) {
-      return buildDateSource(schema, expressionString);
-    }
-    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java
deleted file mode 100644
index a06a093..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.statistics;
-
-import java.util.HashSet;
-import java.util.Set;
-
-/**
- * <code>UniqueValueCounter</code> computes the number of unique values.
- */
-public class UniqueStatsCollector extends AbstractDelegatingStatsCollector{
-  private final Set<Object> uniqueValues = new HashSet<>();
-  
-  public UniqueStatsCollector(StatsCollector delegate) {
-    super(delegate);
-  }
-  
-  @Override
-  public void collect(int doc) {
-    super.collect(doc);
-    if (value.exists) {
-      uniqueValues.add(value.toObject());
-    }
-  }
-
-  @Override
-  public Comparable getStat(String stat) {
-    if (stat.equals("unique")) {
-      return new Long(uniqueValues.size());
-    }
-    return delegate.getStat(stat);
-  }
-
-  @Override
-  public void compute() {
-    delegate.compute();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/package.html
deleted file mode 100644
index 99539fc..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/statistics/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Statistics collectors reduce a list of Objects to a single value. Most implementations reduce a list to a statistic on that list.
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParams.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParams.java
deleted file mode 100644
index d7f220a..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParams.java
+++ /dev/null
@@ -1,114 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util;
-
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
-import org.apache.solr.common.params.FacetParams.FacetRangeOther;
-
-import com.google.common.collect.Lists;
-import com.google.common.collect.Sets;
-
-public interface AnalyticsParams {
-  // Full length Analytics Params
-  public static final String ANALYTICS = "olap";
-  
-  public static final String REQUEST = "o|olap";
-
-  public static final String EXPRESSION = "s|stat|statistic";
-  public static final String HIDDEN_EXPRESSION = "hs|hiddenstat|hiddenstatistic";
-
-  public static final String FIELD_FACET = "ff|fieldfacet";
-  public static final String LIMIT = "l|limit";
-  public static final String OFFSET = "off|offset";
-  public static final String HIDDEN = "h|hidden";
-  public static final String SHOW_MISSING = "sm|showmissing";
-  public static final String SORT_STATISTIC ="ss|sortstat|sortstatistic";
-  public static final String SORT_DIRECTION ="sd|sortdirection";
-  
-  public static final String RANGE_FACET = "rf|rangefacet";
-  public static final String START = "st|start";
-  public static final String END = "e|end";
-  public static final String GAP = "g|gap";
-  public static final String HARDEND = "he|hardend";
-  public static final String INCLUDE_BOUNDARY = "ib|includebound";
-  public static final String OTHER_RANGE = "or|otherrange";
-  
-  public static final String QUERY_FACET = "qf|queryfacet";
-  public static final String DEPENDENCY = "d|dependecy";
-  public static final String QUERY = "q|query";
-  
-  //Defaults
-  public static final boolean DEFAULT_ABBREVIATE_PREFIX = true;
-  public static final String DEFAULT_SORT_DIRECTION = "ascending";
-  public static final int DEFAULT_LIMIT = -1;
-  public static final boolean DEFAULT_HIDDEN = false;
-  public static final boolean DEFAULT_HARDEND = false;
-  public static final boolean DEFAULT_SHOW_MISSING = false;
-  public static final FacetRangeInclude DEFAULT_INCLUDE = FacetRangeInclude.LOWER;
-  public static final FacetRangeOther DEFAULT_OTHER = FacetRangeOther.NONE;
-  
-  // Statistic Function Names (Cannot share names with ValueSource & Expression Functions)
-  public static final String STAT_COUNT = "count";
-  public static final String STAT_MISSING = "missing";
-  public static final String STAT_SUM = "sum";
-  public static final String STAT_SUM_OF_SQUARES = "sumofsquares";
-  public static final String STAT_STANDARD_DEVIATION = "stddev";
-  public static final String STAT_MEAN = "mean";
-  public static final String STAT_UNIQUE = "unique";
-  public static final String STAT_MEDIAN = "median";
-  public static final String STAT_PERCENTILE = "percentile";
-  public static final String STAT_MIN = "min";
-  public static final String STAT_MAX = "max";
-  
-  public static final List<String> ALL_STAT_LIST = Collections.unmodifiableList(Lists.newArrayList(STAT_COUNT, STAT_MISSING, STAT_SUM, STAT_SUM_OF_SQUARES, STAT_STANDARD_DEVIATION, STAT_MEAN, STAT_UNIQUE, STAT_MEDIAN, STAT_PERCENTILE,STAT_MIN,STAT_MAX));
-  public static final Set<String> ALL_STAT_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(ALL_STAT_LIST));
-
-  // ValueSource & Expression Function Names (Cannot share names with Statistic Functions)
-  // No specific type
-  final static String FILTER = "filter";
-  final static String RESULT = "result";
-  final static String QUERY_RESULT = "qresult";
-  
-  // Numbers
-  final static String CONSTANT_NUMBER = "const_num";
-  final static String NEGATE = "neg";
-  final static String ABSOLUTE_VALUE = "abs";
-  final static String LOG = "log";
-  final static String ADD = "add";
-  final static String MULTIPLY = "mult";
-  final static String DIVIDE = "div";
-  final static String POWER = "pow";
-  public static final Set<String> NUMERIC_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_NUMBER,NEGATE,ABSOLUTE_VALUE,LOG,ADD,MULTIPLY,DIVIDE,POWER)));
-  
-  // Dates
-  final static String CONSTANT_DATE = "const_date";
-  final static String DATE_MATH = "date_math";
-  public static final Set<String> DATE_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_DATE,DATE_MATH)));
-  
-  //Strings
-  final static String CONSTANT_STRING = "const_str";
-  final static String REVERSE = "rev";
-  final static String CONCATENATE = "concat";
-  public static final Set<String> STRING_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_STRING,REVERSE,CONCATENATE)));
-  
-  // Field Source Wrappers
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
deleted file mode 100644
index 0e4eceb..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Date;
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.schema.TrieDoubleField;
-import org.apache.solr.schema.TrieFloatField;
-import org.apache.solr.schema.TrieIntField;
-import org.apache.solr.schema.TrieLongField;
-
-/** 
- * Class to hold the parsers used for Solr Analytics.
- */
-public class AnalyticsParsers {
-
-  /**
-   * Returns a parser that will translate a BytesRef or long from DocValues into 
-   * a String that correctly represents the value.
-   * @param class1 class of the FieldType of the field being faceted on.
-   * @return A Parser
-   */
-  public static Parser getParser(Class<? extends FieldType> class1) {
-    if (class1.equals(TrieIntField.class)) {
-      return AnalyticsParsers.INT_DOC_VALUES_PARSER;
-    } else if (class1.equals(TrieLongField.class)) {
-      return AnalyticsParsers.LONG_DOC_VALUES_PARSER;
-    } else if (class1.equals(TrieFloatField.class)) {
-      return AnalyticsParsers.FLOAT_DOC_VALUES_PARSER;
-    } else if (class1.equals(TrieDoubleField.class)) {
-      return AnalyticsParsers.DOUBLE_DOC_VALUES_PARSER;
-    } else if (class1.equals(TrieDateField.class)) {
-      return AnalyticsParsers.DATE_DOC_VALUES_PARSER;
-    } else {
-      return AnalyticsParsers.STRING_PARSER;
-    }
-  }
-
-  /**
-   * For use in classes that grab values by docValue.
-   * Converts a BytesRef object into the correct readable text.
-   */
-  public static interface Parser {
-    String parse(BytesRef bytes) throws IOException;
-  }
-  
-  /**
-   * Converts the long returned by NumericDocValues into the
-   * correct number and return it as a string.
-   */
-  public static interface NumericParser extends Parser {
-    String parseNum(long l);
-  }
-  
-  /**
-   * Converts the BytesRef or long to the correct int string.
-   */
-  public static final NumericParser INT_DOC_VALUES_PARSER = new NumericParser() {
-    public String parse(BytesRef bytes) throws IOException {
-      try {
-        return ""+NumericUtils.prefixCodedToInt(bytes);
-      } catch (NumberFormatException e) {
-        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to an int.");
-      }
-    }
-    @Override
-    public String parseNum(long l) {
-      return ""+(int)l;
-    }
-  };
-  
-  /**
-   * Converts the BytesRef or long to the correct long string.
-   */
-  public static final NumericParser LONG_DOC_VALUES_PARSER = new NumericParser() {
-    public String parse(BytesRef bytes) throws IOException {
-      try {
-        return ""+NumericUtils.prefixCodedToLong(bytes);
-      } catch (NumberFormatException e) {
-        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a long.");
-      }
-    }
-    @Override
-    public String parseNum(long l) {
-      return ""+l;
-    }
-  };
-  
-  /**
-   * Converts the BytesRef or long to the correct float string.
-   */
-  public static final NumericParser FLOAT_DOC_VALUES_PARSER = new NumericParser() {
-    public String parse(BytesRef bytes) throws IOException {
-      try {
-        return ""+NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(bytes));
-      } catch (NumberFormatException e) {
-        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a float.");
-      }
-    }
-    @Override
-    public String parseNum(long l) {
-      return ""+NumericUtils.sortableIntToFloat((int)l);
-    }
-  };
-  
-  /**
-   * Converts the BytesRef or long to the correct double string.
-   */
-  public static final NumericParser DOUBLE_DOC_VALUES_PARSER = new NumericParser() {
-    public String parse(BytesRef bytes) throws IOException {
-      try {
-        return ""+NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(bytes));
-      } catch (NumberFormatException e) {
-        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a double.");
-      }
-    }
-    @Override
-    public String parseNum(long l) {
-      return ""+NumericUtils.sortableLongToDouble(l);
-    }
-  };
-  
-  /**
-   * Converts the BytesRef or long to the correct date string.
-   */
-  public static final NumericParser DATE_DOC_VALUES_PARSER = new NumericParser() {
-    @SuppressWarnings("deprecation")
-    public String parse(BytesRef bytes) throws IOException {
-      try {
-        return TrieDateField.formatExternal(new Date(NumericUtils.prefixCodedToLong(bytes)));
-      } catch (NumberFormatException e) {
-        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a date.");
-      }
-    }
-    @SuppressWarnings("deprecation")
-    @Override
-    public String parseNum(long l) {
-      return ""+TrieDateField.formatExternal(new Date(l));
-    }
-  };
-  
-  /**
-   * Converts the BytesRef to the correct string.
-   */
-  public static final Parser STRING_PARSER = new Parser() {
-    public String parse(BytesRef bytes) {
-      return bytes.utf8ToString();
-    }
-  };
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/MedianCalculator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/MedianCalculator.java
deleted file mode 100644
index 4857597..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/MedianCalculator.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util;
-
-import java.util.List;
-
-public class MedianCalculator {
-
-  /**
-   * Calculates the median of the given list of numbers.
-   *
-   * @param list A list of {@link Comparable} {@link Number} objects
-   * @return The median of the given list as a double.
-   */
-  public static <T extends Number & Comparable<T>> double getMedian(List<T> list) {
-    int size = list.size() - 1;
-    if (size == -1) {
-      return 0;
-    }
-
-    select(list, .5 * size, 0, size);
-
-    int firstIdx = (int) (Math.floor(.5 * size));
-    int secondIdx = (firstIdx <= size && size % 2 == 1) ? firstIdx + 1 : firstIdx;
-    double result = list.get(firstIdx).doubleValue() * .5 + list.get(secondIdx).doubleValue() * .5;
-
-    return result;
-  }
-
-  private static <T extends Comparable<T>> void select(List<T> list, double place, int begin, int end) {
-    T split;
-    if (end - begin < 10) {
-      split = list.get((int) (Math.random() * (end - begin + 1)) + begin);
-    } else {
-      split = split(list, begin, end);
-    }
-
-    Point result = partition(list, begin, end, split);
-
-    if (place < result.low) {
-      select(list, place, begin, result.low);
-    } else if (place > result.high) {
-      select(list, place, result.high, end);
-    } else {
-      if (result.low == (int) (Math.floor(place)) && result.low > begin) {
-        select(list, result.low, begin, result.low);
-      }
-      if (result.high == (int) (Math.ceil(place)) && result.high < end) {
-        select(list, result.high, result.high, end);
-      }
-    }
-  }
-
-  private static <T extends Comparable<T>> T split(List<T> list, int begin, int end) {
-    T temp;
-    int num = (end - begin + 1);
-    int recursiveSize = (int) Math.sqrt((double) num);
-    int step = num / recursiveSize;
-    for (int i = 1; i < recursiveSize; i++) {
-      int swapFrom = i * step + begin;
-      int swapTo = i + begin;
-      temp = list.get(swapFrom);
-      list.set(swapFrom, list.get(swapTo));
-      list.set(swapTo, temp);
-    }
-    recursiveSize--;
-    select(list, recursiveSize / 2 + begin, begin, recursiveSize + begin);
-    return list.get(recursiveSize / 2 + begin);
-  }
-
-  private static <T extends Comparable<T>> Point partition(List<T> list, int begin, int end, T indexElement) {
-    T temp;
-    int left, right;
-    for (left = begin, right = end; left < right; left++, right--) {
-      while (list.get(left).compareTo(indexElement) < 0) {
-        left++;
-      }
-      while (right != begin - 1 && list.get(right).compareTo(indexElement) >= 0) {
-        right--;
-      }
-      if (right <= left) {
-        left--;
-        right++;
-        break;
-      }
-      temp = list.get(left);
-      list.set(left, list.get(right));
-      list.set(right, temp);
-    }
-    while (left != begin - 1 && list.get(left).compareTo(indexElement) >= 0) {
-      left--;
-    }
-    while (right != end + 1 && list.get(right).compareTo(indexElement) <= 0) {
-      right++;
-    }
-    int rightMove = right + 1;
-    while (rightMove < end + 1) {
-      if (list.get(rightMove).equals(indexElement)) {
-        temp = list.get(rightMove);
-        list.set(rightMove, list.get(right));
-        list.set(right, temp);
-        do {
-          right++;
-        } while (list.get(right).equals(indexElement));
-        if (rightMove <= right) {
-          rightMove = right;
-        }
-      }
-      rightMove++;
-    }
-    return new Point(left, right);
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/PercentileCalculator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/PercentileCalculator.java
deleted file mode 100644
index 714575e..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/PercentileCalculator.java
+++ /dev/null
@@ -1,177 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-public class PercentileCalculator {
-  /**
-   * Calculates a list of percentile values for a given list of objects and percentiles.
-   *
-   * @param list     The list of {@link Comparable} objects to calculate the percentiles of.
-   * @param percents The array of percentiles (.01 to .99) to calculate.
-   * @return a list of comparables
-   */
-  public static <T extends Comparable<T>> List<T> getPercentiles(List<T> list, double[] percents) {
-    int size = list.size();
-    if (size == 0) {
-      return null;
-    }
-
-    int[] percs = new int[percents.length];
-    for (int i = 0; i < percs.length; i++) {
-      percs[i] = (int) Math.round(percents[i] * size - .5);
-    }
-    int[] percentiles = Arrays.copyOf(percs, percs.length);
-    Arrays.sort(percentiles);
-
-    if (percentiles[0] < 0 || percentiles[percentiles.length - 1] > size - 1) {
-      throw new IllegalArgumentException();
-    }
-
-    List<T> results = new ArrayList<>(percs.length);
-
-    distributeAndFind(list, percentiles, 0, percentiles.length - 1);
-
-    for (int i = 0; i < percs.length; i++) {
-      results.add(list.get(percs[i]));
-    }
-    return results;
-  }
-
-  private static <T extends Comparable<T>> void distributeAndFind(List<T> list, int[] percentiles, int beginIdx, int endIdx) {
-    if (endIdx < beginIdx) {
-      return;
-    }
-    int middleIdxb = beginIdx;
-    int middleIdxe = beginIdx;
-    int begin = (beginIdx == 0) ? -1 : percentiles[beginIdx - 1];
-    int end = (endIdx == percentiles.length - 1) ? list.size() : percentiles[endIdx + 1];
-    double middle = (begin + end) / 2.0;
-    for (int i = beginIdx; i <= endIdx; i++) {
-      double value = Math.abs(percentiles[i] - middle) - Math.abs(percentiles[middleIdxb] - middle);
-      if (percentiles[i] == percentiles[middleIdxb]) {
-        middleIdxe = i;
-      } else if (value < 0) {
-        middleIdxb = i;
-        do {
-          middleIdxe = i;
-          i++;
-        } while (i <= endIdx && percentiles[middleIdxb] == percentiles[i]);
-        break;
-      }
-    }
-
-    int middlePlace = percentiles[middleIdxb];
-    int beginPlace = begin + 1;
-    int endPlace = end - 1;
-
-    select(list, middlePlace, beginPlace, endPlace);
-    distributeAndFind(list, percentiles, beginIdx, middleIdxb - 1);
-    distributeAndFind(list, percentiles, middleIdxe + 1, endIdx);
-  }
-
-  private static <T extends Comparable<T>> void select(List<T> list, int place, int begin, int end) {
-    T split;
-    if (end - begin < 10) {
-      split = list.get((int) (Math.random() * (end - begin + 1)) + begin);
-    } else {
-      split = split(list, begin, end);
-    }
-
-    Point result = partition(list, begin, end, split);
-
-    if (place <= result.low) {
-      select(list, place, begin, result.low);
-    } else if (place >= result.high) {
-      select(list, place, result.high, end);
-    }
-  }
-
-  private static <T extends Comparable<T>> T split(List<T> list, int begin, int end) {
-    T temp;
-    int num = (end - begin + 1);
-    int recursiveSize = (int) Math.sqrt((double) num);
-    int step = num / recursiveSize;
-    for (int i = 1; i < recursiveSize; i++) {
-      int swapFrom = i * step + begin;
-      int swapTo = i + begin;
-      temp = list.get(swapFrom);
-      list.set(swapFrom, list.get(swapTo));
-      list.set(swapTo, temp);
-    }
-    recursiveSize--;
-    select(list, recursiveSize / 2 + begin, begin, recursiveSize + begin);
-    return list.get(recursiveSize / 2 + begin);
-  }
-
-  private static <T extends Comparable<T>> Point partition(List<T> list, int begin, int end, T indexElement) {
-    T temp;
-    int left, right;
-    for (left = begin, right = end; left <= right; left++, right--) {
-      while (list.get(left).compareTo(indexElement) < 0) {
-        left++;
-      }
-      while (right != begin - 1 && list.get(right).compareTo(indexElement) >= 0) {
-        right--;
-      }
-      if (right <= left) {
-        left--;
-        right++;
-        break;
-      }
-      temp = list.get(left);
-      list.set(left, list.get(right));
-      list.set(right, temp);
-    }
-    while (left > begin - 1 && list.get(left).compareTo(indexElement) >= 0) {
-      left--;
-    }
-    while (right < end + 1 && list.get(right).compareTo(indexElement) <= 0) {
-      right++;
-    }
-    int rightMove = right + 1;
-    while (rightMove < end + 1) {
-      if (list.get(rightMove).equals(indexElement)) {
-        temp = list.get(rightMove);
-        list.set(rightMove, list.get(right));
-        list.set(right, temp);
-        do {
-          right++;
-        } while (list.get(right).equals(indexElement));
-        if (rightMove <= right) {
-          rightMove = right;
-        }
-      }
-      rightMove++;
-    }
-    return new Point(left, right);
-  }
-}
-
-class Point {
-  public int low;
-  public int high;
-
-  public Point(int low, int high) {
-    this.low = low;
-    this.high = high;
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java
deleted file mode 100644
index 6eabe29..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java
+++ /dev/null
@@ -1,356 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util;
-
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.EnumSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.solr.analytics.request.RangeFacetRequest;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
-import org.apache.solr.common.params.FacetParams.FacetRangeOther;
-import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.SchemaField;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.schema.TrieField;
-import org.apache.solr.util.DateMathParser;
-
-
-public abstract class RangeEndpointCalculator<T extends Comparable<T>> {
-  protected final SchemaField field;
-  protected final RangeFacetRequest request;
-  
-  public RangeEndpointCalculator(final RangeFacetRequest request) {
-    this.field = request.getField();
-    this.request = request;
-  }
-
-  /**
-   * Formats a Range endpoint for use as a range label name in the response.
-   * Default Impl just uses toString()
-   */
-  public String formatValue(final T val) {
-    return val.toString();
-  }
-  
-  /**
-   * Parses a String param into an Range endpoint value throwing 
-   * a useful exception if not possible
-   */
-  public final T getValue(final String rawval) {
-    try {
-      return parseVal(rawval);
-    } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't parse value "+rawval+" for field: " + field.getName(), e);
-    }
-  }
-  
-  /**
-   * Parses a String param into an Range endpoint. 
-   * Can throw a low level format exception as needed.
-   */
-  protected abstract T parseVal(final String rawval) throws java.text.ParseException;
-
-  /** 
-   * Parses a String param into a value that represents the gap and 
-   * can be included in the response, throwing 
-   * a useful exception if not possible.
-   *
-   * Note: uses Object as the return type instead of T for things like 
-   * Date where gap is just a DateMathParser string 
-   */
-  public final Object getGap(final String gap) {
-    try {
-      return parseGap(gap);
-    } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't parse gap "+gap+" for field: " + field.getName(), e);
-    }
-  }
-
-  /**
-   * Parses a String param into a value that represents the gap and 
-   * can be included in the response. 
-   * Can throw a low level format exception as needed.
-   *
-   * Default Impl calls parseVal
-   */
-  protected Object parseGap(final String rawval) throws java.text.ParseException {
-    return parseVal(rawval);
-  }
-
-  /**
-   * Adds the String gap param to a low Range endpoint value to determine 
-   * the corrisponding high Range endpoint value, throwing 
-   * a useful exception if not possible.
-   */
-  public final T addGap(T value, String gap) {
-    try {
-      return parseAndAddGap(value, gap);
-    } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't add gap "+gap+" to value " + value + " for field: " + field.getName(), e);
-    }
-  }
-  
-  /**
-   * Adds the String gap param to a low Range endpoint value to determine 
-   * the corrisponding high Range endpoint value.
-   * Can throw a low level format exception as needed.
-   */
-  protected abstract T parseAndAddGap(T value, String gap) throws java.text.ParseException;
-
-  public static class FacetRange {
-    public final String name;
-    public final String lower;
-    public final String upper;
-    public final boolean includeLower;
-    public final boolean includeUpper;
-    
-    public FacetRange(String name, String lower, String upper, boolean includeLower, boolean includeUpper) {
-      this.name = name;
-      this.lower = lower;
-      this.upper = upper;
-      this.includeLower = includeLower;
-      this.includeUpper = includeUpper;
-    }
-  }
-  
-  public List<FacetRange> getRanges(){
-
-    final T start = getValue(request.getStart());
-    T end = getValue(request.getEnd()); // not final, hardend may change this
-    
-    if( end.compareTo(start) < 0 ){
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "range facet 'end' comes before 'start': "+end+" < "+start);
-    }
-    
-    // explicitly return the gap.  compute this early so we are more 
-    // likely to catch parse errors before attempting math
-    final String[] gaps = request.getGaps();
-    String gap = gaps[0];
-    
-    final EnumSet<FacetRangeInclude> include = request.getInclude();
-        
-    T low = start;
-    
-    List<FacetRange> ranges = new ArrayList<>();
-    
-    int gapCounter = 0;
-    
-    while (low.compareTo(end) < 0) {
-      if (gapCounter<gaps.length) {
-        gap = gaps[gapCounter++];
-      }
-      T high = addGap(low,gap);
-      if (end.compareTo(high) < 0) {
-        if (request.isHardEnd()){
-          high = end;
-        } else {
-          end = high;
-        }
-      }
-      
-      if (high.compareTo(low) < 0) {
-        throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "range facet infinite loop (is gap negative? did the math overflow?)");
-      }
-      
-      if (high.compareTo(low) == 0) {
-        throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "range facet infinite loop: gap is either zero, or too small relative start/end and caused underflow: " + low + " + " + gap + " = " + high );
-      }
-      
-      final boolean includeLower = (include.contains(FacetRangeInclude.ALL) ||
-                                    include.contains(FacetRangeInclude.LOWER) ||
-                                   (include.contains(FacetRangeInclude.EDGE) && 
-                                   0 == low.compareTo(start)));
-      final boolean includeUpper = (include.contains(FacetRangeInclude.ALL) ||
-                                    include.contains(FacetRangeInclude.UPPER) ||
-                                   (include.contains(FacetRangeInclude.EDGE) && 
-                                   0 == high.compareTo(end)));
-      
-      final String lowS = formatValue(low);
-      final String highS = formatValue(high);
-
-      ranges.add( new FacetRange(lowS,lowS,highS,includeLower,includeUpper) );
-      low = high;
-    }
-    
-    final Set<FacetRangeOther> others = request.getOthers();
-    if (null != others && 0 < others.size() ) {
-      
-      // no matter what other values are listed, we don't do
-      // anything if "none" is specified.
-      if( !others.contains(FacetRangeOther.NONE) ) {
-        
-        boolean all = others.contains(FacetRangeOther.ALL);
-
-        if (all || others.contains(FacetRangeOther.BEFORE)) {
-          // include upper bound if "outer" or if first gap doesn't already include it
-          ranges.add( new FacetRange(FacetRangeOther.BEFORE.toString(), 
-                                        null, formatValue(start), false, include.contains(FacetRangeInclude.OUTER) || include.contains(FacetRangeInclude.ALL) ||
-                                                            !(include.contains(FacetRangeInclude.LOWER) || include.contains(FacetRangeInclude.EDGE)) ) );
-          
-        }
-        if (all || others.contains(FacetRangeOther.AFTER)) {
-          // include lower bound if "outer" or if last gap doesn't already include it
-          ranges.add( new FacetRange(FacetRangeOther.AFTER.toString(), 
-                                        formatValue(end), null, include.contains(FacetRangeInclude.OUTER) || include.contains(FacetRangeInclude.ALL) ||
-                                                   !(include.contains(FacetRangeInclude.UPPER) || include.contains(FacetRangeInclude.EDGE)), false) );
-        }
-        if (all || others.contains(FacetRangeOther.BETWEEN)) {
-          ranges.add( new FacetRange(FacetRangeOther.BETWEEN.toString(), formatValue(start), formatValue(end),
-                                        include.contains(FacetRangeInclude.LOWER) || include.contains(FacetRangeInclude.EDGE) || include.contains(FacetRangeInclude.ALL),
-                                        include.contains(FacetRangeInclude.UPPER) || include.contains(FacetRangeInclude.EDGE) || include.contains(FacetRangeInclude.ALL)) );
-        }
-      }
-      
-    }
-  
-    return ranges;
-  }
-  
-  public static RangeEndpointCalculator<? extends Comparable<?>> create(RangeFacetRequest request){
-    final SchemaField sf = request.getField();
-    final FieldType ft = sf.getType();
-    final RangeEndpointCalculator<?> calc;
-    if (ft instanceof TrieField) {
-      final TrieField trie = (TrieField)ft;
-      switch (trie.getType()) {
-        case FLOAT:
-          calc = new FloatRangeEndpointCalculator(request);
-          break;
-        case DOUBLE:
-          calc = new DoubleRangeEndpointCalculator(request);
-          break;
-        case INTEGER:
-          calc = new IntegerRangeEndpointCalculator(request);
-          break;
-        case LONG:
-          calc = new LongRangeEndpointCalculator(request);
-          break;
-        case DATE:
-          calc = new DateRangeEndpointCalculator(request, null);
-          break;
-        default:
-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Unable to range facet on tried field of unexpected type:" + sf.getName());
-      }
-    } else {
-      throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "Unable to range facet on field:" + sf);
-    } 
-    return calc;
-  }
-  
-  public static class FloatRangeEndpointCalculator extends RangeEndpointCalculator<Float> {
-  
-    public FloatRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
-    
-    @Override
-    protected Float parseVal(String rawval) {
-      return Float.valueOf(rawval);
-    }
-    
-    @Override
-    public Float parseAndAddGap(Float value, String gap) {
-      return new Float(value.floatValue() + Float.valueOf(gap).floatValue());
-    }
-    
-  }
-  
-  public static class DoubleRangeEndpointCalculator extends RangeEndpointCalculator<Double> {
-  
-    public DoubleRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
-    
-    @Override
-    protected Double parseVal(String rawval) {
-      return Double.valueOf(rawval);
-    }
-    
-    @Override
-    public Double parseAndAddGap(Double value, String gap) {
-      return new Double(value.doubleValue() + Double.valueOf(gap).doubleValue());
-    }
-    
-  }
-  
-  public static class IntegerRangeEndpointCalculator extends RangeEndpointCalculator<Integer> {
-  
-    public IntegerRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
-    
-    @Override
-    protected Integer parseVal(String rawval) {
-      return Integer.valueOf(rawval);
-    }
-    
-    @Override
-    public Integer parseAndAddGap(Integer value, String gap) {
-      return new Integer(value.intValue() + Integer.valueOf(gap).intValue());
-    }
-    
-  }
-  
-  public static class LongRangeEndpointCalculator extends RangeEndpointCalculator<Long> {
-  
-    public LongRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
-    
-    @Override
-    protected Long parseVal(String rawval) {
-      return Long.valueOf(rawval);
-    }
-    
-    @Override
-    public Long parseAndAddGap(Long value, String gap) {
-      return new Long(value.longValue() + Long.valueOf(gap).longValue());
-    }
-    
-  }
-  
-  public static class DateRangeEndpointCalculator extends RangeEndpointCalculator<Date> {
-    private final Date now;
-    public DateRangeEndpointCalculator(final RangeFacetRequest request, final Date now) { 
-      super(request); 
-      this.now = now;
-      if (! (field.getType() instanceof TrieDateField) ) {
-        throw new IllegalArgumentException("SchemaField must use field type extending TrieDateField");
-      }
-    }
-    
-    @Override
-    public String formatValue(Date val) {
-      return ((TrieDateField)field.getType()).toExternal(val);
-    }
-    
-    @Override
-    protected Date parseVal(String rawval) {
-      return ((TrieDateField)field.getType()).parseMath(now, rawval);
-    }
-    
-    @Override
-    protected Object parseGap(final String rawval) {
-      return rawval;
-    }
-    
-    @Override
-    public Date parseAndAddGap(Date value, String gap) throws java.text.ParseException {
-      final DateMathParser dmp = new DateMathParser();
-      dmp.setNow(value);
-      return dmp.parseMath(gap);
-    }
-    
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/util/package.html
deleted file mode 100644
index 3cc6e4a..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-Utilities used by analytics component
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java
deleted file mode 100644
index f429248..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java
+++ /dev/null
@@ -1,59 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>AbsoluteValueDoubleFunction</code> takes the absolute value of the double value of the source it contains.
- */
-public class AbsoluteValueDoubleFunction extends SingleDoubleFunction {
-  public final static String NAME = AnalyticsParams.ABSOLUTE_VALUE;
-  
-  public AbsoluteValueDoubleFunction(ValueSource source) {
-    super(source);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  public String description() {
-    return name()+"("+source.description()+")";
-  }
-
-  protected double func(int doc, FunctionValues vals) {
-    double d = vals.doubleVal(doc);
-    if (d<0) {
-      return d*-1;
-    } else {
-      return d;
-    }
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    AbsoluteValueDoubleFunction other = (AbsoluteValueDoubleFunction)o;
-    return this.source.equals(other.source);
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java
deleted file mode 100644
index 7784feb..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>AddDoubleFunction</code> returns the sum of it's components.
- */
-public class AddDoubleFunction extends MultiDoubleFunction {
-  public final static String NAME = AnalyticsParams.ADD;
-
-  public AddDoubleFunction(ValueSource[] sources) {
-    super(sources);
-  }
-
-  @Override
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected double func(int doc, FunctionValues[] valsArr) {
-    double sum = 0d;
-    for (FunctionValues val : valsArr) {
-      sum += val.doubleVal(doc);
-    }
-    return sum;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java
deleted file mode 100644
index 97537a7..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>ConcatStringFunction</code> concatenates the string values of its 
- * components in the order given.
- */
-public class ConcatStringFunction extends MultiStringFunction {
-  public final static String NAME = AnalyticsParams.CONCATENATE;
-
-  public ConcatStringFunction(ValueSource[] sources) {
-    super(sources);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected String func(int doc, FunctionValues[] valsArr) {
-    StringBuilder sb = new StringBuilder();
-    for (FunctionValues val : valsArr) {
-      String v = val.strVal(doc);
-      if(v == null){
-        return null;
-      } else {
-        sb.append(v);
-      }
-    }
-    return sb.toString();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java
deleted file mode 100644
index 1ed8ca7..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java
+++ /dev/null
@@ -1,114 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.text.ParseException;
-import java.util.Date;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.docvalues.FloatDocValues;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.lucene.util.mutable.MutableValueDate;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.schema.TrieDateField;
-
-/**
- * <code>ConstDateSource</code> returns a constant date for all documents
- */
-public class ConstDateSource extends ConstDoubleSource {
-  public final static String NAME = AnalyticsParams.CONSTANT_DATE;
-
-  public ConstDateSource(Date constant) throws ParseException {
-    super(constant.getTime());
-  }
-
-  public ConstDateSource(Long constant) {
-    super(constant);
-  }
-
-  @SuppressWarnings("deprecation")
-  @Override
-  public String description() {
-    return name()+"(" + TrieDateField.formatExternal(new Date(getLong())) + ")";
-  }
-
-  protected String name() {
-    return NAME;
-  }
-  
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    return new FloatDocValues(this) {
-      @Override
-      public float floatVal(int doc) {
-        return getFloat();
-      }
-      @Override
-      public int intVal(int doc) {
-        return getInt();
-      }
-      @Override
-      public long longVal(int doc) {
-        return getLong();
-      }
-      @Override
-      public double doubleVal(int doc) {
-        return getDouble();
-      }
-      @Override
-      public String toString(int doc) {
-        return description();
-      }
-      @Override
-      public Object objectVal(int doc) {
-        return new Date(longVal(doc));
-      }
-      @SuppressWarnings("deprecation")
-      @Override
-      public String strVal(int doc) {
-        return TrieDateField.formatExternal(new Date(longVal(doc)));
-      }
-      @Override
-      public boolean boolVal(int doc) {
-        return getFloat() != 0.0f;
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final MutableValueDate mval = new MutableValueDate();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            mval.value = longVal(doc);
-            mval.exists = true;
-          }
-        };
-      }
-    };
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java
deleted file mode 100644
index 6311086..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java
+++ /dev/null
@@ -1,106 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
-import org.apache.lucene.queries.function.valuesource.ConstNumberSource;
-import org.apache.lucene.queries.function.valuesource.ConstValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>ConstDoubleSource</code> returns a constant double for all documents
- */
-public class ConstDoubleSource extends ConstNumberSource {
-  public final static String NAME = AnalyticsParams.CONSTANT_NUMBER;
-  final double constant;
-
-  public ConstDoubleSource(double constant) {
-    this.constant = constant;
-  }
-
-  @Override
-  public String description() {
-    return name()+"(" + getFloat() + ")";
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    return new DoubleDocValues(this) {
-      @Override
-      public double doubleVal(int doc) {
-        return constant;
-      }
-      @Override
-      public boolean exists(int doc) {
-        return true;
-      }
-    };
-  }
-
-  @Override
-  public int hashCode() {
-    return (int)Double.doubleToLongBits(constant) * 31;
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (!(o instanceof ConstValueSource)) return false;
-    ConstDoubleSource other = (ConstDoubleSource)o;
-    return  this.constant == other.constant;
-  }
-
-  @Override
-  public int getInt() {
-    return (int)constant;
-  }
-
-  @Override
-  public long getLong() {
-    return (long)constant;
-  }
-
-  @Override
-  public float getFloat() {
-    return (float)constant;
-  }
-
-  @Override
-  public double getDouble() {
-    return constant;
-  }
-
-  @Override
-  public Number getNumber() {
-    return new Double(constant);
-  }
-
-  @Override
-  public boolean getBool() {
-    return constant != 0.0f;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java
deleted file mode 100644
index c2c9af7..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.valuesource.LiteralValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>ConstStringSource</code> returns a constant string for all documents
- */
-public class ConstStringSource extends LiteralValueSource {
-  public final static String NAME = AnalyticsParams.CONSTANT_STRING;
-
-  public ConstStringSource(String string) {
-    super(string);
-  }
-
-  @Override
-  public String description() {
-    return name()+"(" + string + ")";
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (this == o) return true;
-    if (!(o instanceof ConstStringSource)) return false;
-    ConstStringSource that = (ConstStringSource) o;
-
-    return getValue().equals(that.getValue());
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
deleted file mode 100644
index c002e35..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Date;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.docvalues.LongDocValues;
-import org.apache.lucene.queries.function.valuesource.LongFieldSource;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.lucene.util.mutable.MutableValueDate;
-import org.apache.solr.schema.TrieDateField;
-
-/**
- * Extends {@link LongFieldSource} to have a field source that takes in 
- * and returns {@link Date} values while working with long values internally.
- */
-public class DateFieldSource extends LongFieldSource {
-
-  public DateFieldSource(String field) {
-    super(field);
-  }
-
-  public long externalToLong(String extVal) {
-    return NumericUtils.prefixCodedToLong(new BytesRef(extVal));
-  }
-
-  public Object longToObject(long val) {
-    return new Date(val);
-  }
-
-  @SuppressWarnings("deprecation")
-  public String longToString(long val) {
-    return TrieDateField.formatExternal((Date)longToObject(val));
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final NumericDocValues arr = DocValues.getNumeric(readerContext.reader(), field);
-    final Bits valid = DocValues.getDocsWithField(readerContext.reader(), field);
-    return new LongDocValues(this) {
-      @Override
-      public long longVal(int doc) {
-        return arr.get(doc);
-      }
-
-      @Override
-      public boolean exists(int doc) {
-        return valid.get(doc);
-      }
-
-      @Override
-      public Object objectVal(int doc) {
-        return exists(doc) ? longToObject(arr.get(doc)) : null;
-      }
-
-      @Override
-      public String strVal(int doc) {
-        return exists(doc) ? longToString(arr.get(doc)) : null;
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final MutableValueDate mval = new MutableValueDate();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            mval.value = arr.get(doc);
-            mval.exists = exists(doc);
-          }
-        };
-      }
-
-    };
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (o.getClass() != this.getClass()) return false;
-    DateFieldSource other = (DateFieldSource) o;
-    return field.equals(other.field);
-  }
-
-  @Override
-  public int hashCode() {
-    int h = this.getClass().hashCode();
-    h += super.hashCode();
-    return h;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java
deleted file mode 100644
index f2d4c4a..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.text.ParseException;
-import java.util.Date;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.util.DateMathParser;
-
-/**
- * <code>DateMathFunction</code> returns a start date modified by a list of DateMath operations.
- */
-public class DateMathFunction extends MultiDateFunction {
-  public final static String NAME = AnalyticsParams.DATE_MATH;
-  final private DateMathParser parser;
-  
-  /**
-   * @param sources A list of ValueSource objects. The first element in the list
-   * should be a {@link DateFieldSource} or {@link ConstDateSource} object which
-   * represents the starting date. The rest of the field should be {@link BytesRefFieldSource}
-   * or {@link ConstStringSource} objects which contain the DateMath operations to perform on 
-   * the start date.
-   */
-  public DateMathFunction(ValueSource[] sources) {
-    super(sources);
-    parser = new DateMathParser();
-  }
-
-  @Override
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected long func(int doc, FunctionValues[] valsArr) {
-    long time = 0;
-    Date date = (Date)valsArr[0].objectVal(doc);
-    try {
-      parser.setNow(date);
-      for (int count = 1; count < valsArr.length; count++) {
-          date = parser.parseMath(valsArr[count].strVal(doc));
-        parser.setNow(date);
-      }
-      time = parser.getNow().getTime();
-    } catch (ParseException e) {
-      e.printStackTrace();
-      time = date.getTime();
-    }
-    return time;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java
deleted file mode 100644
index f029d79..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>DivDoubleFunction</code> returns the quotient of 'a' and 'b'.
- */
-public class DivDoubleFunction extends DualDoubleFunction {
-  public final static String NAME = AnalyticsParams.DIVIDE;
-
-  /**
-    * @param   a  the numerator.
-    * @param   b  the denominator.
-    */
-  public DivDoubleFunction(ValueSource a, ValueSource b) {
-    super(a, b);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
-    return aVals.doubleVal(doc)/bVals.doubleVal(doc);
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java
deleted file mode 100644
index 21f5eda..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
-import org.apache.lucene.search.IndexSearcher;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps two ValueSources
- * and applies an extendible double function to their values.
- **/
-public abstract class DualDoubleFunction extends ValueSource {
-  protected final ValueSource a;
-  protected final ValueSource b;
-
-  public DualDoubleFunction(ValueSource a, ValueSource b) {
-    this.a = a;
-    this.b = b;
-  }
-
-  protected abstract String name();
-  protected abstract double func(int doc, FunctionValues aVals, FunctionValues bVals);
-
-  @Override
-  public String description() {
-    return name() + "(" + a.description() + "," + b.description() + ")";
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues aVals =  a.getValues(context, readerContext);
-    final FunctionValues bVals =  b.getValues(context, readerContext);
-    return new DoubleDocValues(this) {
-      @Override
-      public double doubleVal(int doc) {
-        return func(doc, aVals, bVals);
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        return aVals.exists(doc) & bVals.exists(doc);
-      }
-
-      @Override
-      public String toString(int doc) {
-        return name() + '(' + aVals.toString(doc) + ',' + bVals.toString(doc) + ')';
-      }
-    };
-  }
-
-  @Override
-  public void createWeight(Map context, IndexSearcher searcher) throws IOException {
-    a.createWeight(context,searcher);
-    b.createWeight(context,searcher);
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    DualDoubleFunction other = (DualDoubleFunction)o;
-    return this.a.equals(other.a)
-        && this.b.equals(other.b);
-  }
-
-  @Override
-  public int hashCode() {
-    int h = a.hashCode();
-    h ^= (h << 13) | (h >>> 20);
-    h += b.hashCode();
-    h ^= (h << 23) | (h >>> 10);
-    h += name().hashCode();
-    return h;
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java
deleted file mode 100644
index 33a9995..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java
+++ /dev/null
@@ -1,156 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Date;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.schema.TrieDateField;
-
-/**
- * <code>DefaultIsMissingFieldSource</code> wraps a field source to return missing values 
- * if the value is equal to the default value.
- */
-public class FilterFieldSource extends ValueSource {
-  public final static String NAME = AnalyticsParams.FILTER;
-  public final Object missValue;
-  protected final ValueSource source;
-  
-  public FilterFieldSource(ValueSource source, Object missValue) {
-    this.source = source;
-    this.missValue = missValue;
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @SuppressWarnings("deprecation")
-  @Override
-  public String description() {
-    if (missValue.getClass().equals(Date.class)) {
-      return name()+"("+source.description()+","+TrieDateField.formatExternal((Date)missValue)+")";
-    } else {
-      return name()+"("+source.description()+","+missValue.toString()+")";
-    }
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues vals =  source.getValues(context, readerContext);
-    return new FunctionValues() {
-
-      @Override
-      public byte byteVal(int doc) {
-        return vals.byteVal(doc);
-      }
-
-      @Override
-      public short shortVal(int doc) {
-        return vals.shortVal(doc);
-      }
-
-      @Override
-      public float floatVal(int doc) {
-        return vals.floatVal(doc);
-      }
-
-      @Override
-      public int intVal(int doc) {
-        return vals.intVal(doc);
-      }
-
-      @Override
-      public long longVal(int doc) {
-        return vals.longVal(doc);
-      }
-
-      @Override
-      public double doubleVal(int doc) {
-        return vals.doubleVal(doc);
-      }
-
-      @Override
-      public String strVal(int doc) {
-        return vals.strVal(doc);
-      }
-
-      @Override
-      public Object objectVal(int doc) {
-        return exists(doc)? vals.objectVal(doc) : null;
-      }
-
-      @Override
-      public boolean exists(int doc) {
-        Object other = vals.objectVal(doc);
-        return other!=null&&!missValue.equals(other);
-      }
-
-      @Override
-      public String toString(int doc) {
-        return NAME + '(' + vals.toString(doc) + ')';
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final ValueFiller delegateFiller = vals.getValueFiller();
-          private final MutableValue mval = delegateFiller.getValue();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            delegateFiller.fillValue(doc);
-            mval.exists = exists(doc);
-          }
-        };
-      }
-    };
-  }
-  
-  public ValueSource getRootSource() {
-    if (source instanceof FilterFieldSource) {
-      return ((FilterFieldSource)source).getRootSource();
-    } else {
-      return source;
-    }
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    FilterFieldSource other = (FilterFieldSource)o;
-    return this.source.equals(other.source) && this.missValue.equals(other.missValue);
-  }
-
-  @Override
-  public int hashCode() {
-    return source.hashCode()+name().hashCode();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java
deleted file mode 100644
index c4729a3..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java
+++ /dev/null
@@ -1,42 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>LogDoubleFunction</code> returns the log of a double value with a given base.
- */
-public class LogDoubleFunction extends DualDoubleFunction {
-  public final static String NAME = AnalyticsParams.LOG;
-  
-  public LogDoubleFunction(ValueSource a, ValueSource b) {
-    super(a,b);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
-    return Math.log(aVals.doubleVal(doc))/Math.log(bVals.doubleVal(doc));
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java
deleted file mode 100644
index 1b51f6d..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java
+++ /dev/null
@@ -1,134 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.LongDocValues;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.lucene.util.mutable.MutableValueDate;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
- * and applies an extendible date function to their values.
- **/
-public abstract class MultiDateFunction extends ValueSource {
-  protected final ValueSource[] sources;
-  
-  public MultiDateFunction(ValueSource[] sources) {
-    this.sources = sources;
-  }
-
-  abstract protected String name();
-  abstract protected long func(int doc, FunctionValues[] valsArr);
-
-  @Override
-  public String description() {
-    StringBuilder sb = new StringBuilder();
-    sb.append(name()).append('(');
-    boolean firstTime=true;
-    for (ValueSource source : sources) {
-      if (firstTime) {
-        firstTime=false;
-      } else {
-        sb.append(',');
-      }
-      sb.append(source);
-    }
-    sb.append(')');
-    return sb.toString();
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues[] valsArr = new FunctionValues[sources.length];
-    for (int i=0; i<sources.length; i++) {
-      valsArr[i] = sources[i].getValues(context, readerContext);
-    }
-
-    return new LongDocValues(this) {
-      @Override
-      public long longVal(int doc) {
-        return func(doc, valsArr);
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        boolean exists = true;
-        for (FunctionValues val : valsArr) {
-          exists = exists & val.exists(doc);
-        }
-        return exists;
-      }
-      
-      @Override
-      public String toString(int doc) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(name()).append('(');
-        boolean firstTime=true;
-        for (FunctionValues vals : valsArr) {
-          if (firstTime) {
-            firstTime=false;
-          } else {
-            sb.append(',');
-          }
-          sb.append(vals.toString(doc));
-        }
-        sb.append(')');
-        return sb.toString();
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final MutableValueDate mval = new MutableValueDate();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            mval.value = longVal(doc);
-            mval.exists = exists(doc);
-          }
-        };
-      }
-    };
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    MultiDateFunction other = (MultiDateFunction)o;
-    return this.name().equals(other.name())
-            && Arrays.equals(this.sources, other.sources);
-  }
-
-  @Override
-  public int hashCode() {
-    return Arrays.hashCode(sources) + name().hashCode();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java
deleted file mode 100644
index db6f0d0..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
-import org.apache.lucene.search.IndexSearcher;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
- * and applies an extendible double function to their values.
- **/
-public abstract class MultiDoubleFunction extends ValueSource {
-  protected final ValueSource[] sources;
-
-  public MultiDoubleFunction(ValueSource[] sources) {
-    this.sources = sources;
-  }
-
-  abstract protected String name();
-  abstract protected double func(int doc, FunctionValues[] valsArr);
-
-  @Override
-  public String description() {
-    StringBuilder sb = new StringBuilder();
-    sb.append(name()).append('(');
-    boolean firstTime=true;
-    for (ValueSource source : sources) {
-      if (firstTime) {
-        firstTime=false;
-      } else {
-        sb.append(',');
-      }
-      sb.append(source);
-    }
-    sb.append(')');
-    return sb.toString();
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues[] valsArr = new FunctionValues[sources.length];
-    for (int i=0; i<sources.length; i++) {
-      valsArr[i] = sources[i].getValues(context, readerContext);
-    }
-
-    return new DoubleDocValues(this) {
-      @Override
-      public double doubleVal(int doc) {
-        return func(doc, valsArr);
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        boolean exists = true;
-        for (FunctionValues val : valsArr) {
-          exists = exists & val.exists(doc);
-        }
-        return exists;
-      }
-       
-      @Override
-      public String toString(int doc) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(name()).append('(');
-        boolean firstTime=true;
-        for (FunctionValues vals : valsArr) {
-          if (firstTime) {
-            firstTime=false;
-          } else {
-            sb.append(',');
-          }
-          sb.append(vals.toString(doc));
-        }
-        sb.append(')');
-        return sb.toString();
-      }
-    };
-  }
-
-  @Override
-  public void createWeight(Map context, IndexSearcher searcher) throws IOException {
-    for (ValueSource source : sources)
-      source.createWeight(context, searcher);
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    MultiDoubleFunction other = (MultiDoubleFunction)o;
-    return this.name().equals(other.name())
-            && Arrays.equals(this.sources, other.sources);
-  }
-
-  @Override
-  public int hashCode() {
-    return Arrays.hashCode(sources) + name().hashCode();
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java
deleted file mode 100644
index 5ef3fdd..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java
+++ /dev/null
@@ -1,147 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.StrDocValues;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.lucene.util.mutable.MutableValueStr;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
- * and applies an extendible string function to their values.
- **/
-public abstract class MultiStringFunction extends ValueSource {
-  protected final ValueSource[] sources;
-  
-  public MultiStringFunction(ValueSource[] sources) {
-    this.sources = sources;
-  }
-
-  abstract protected String name();
-  abstract protected CharSequence func(int doc, FunctionValues[] valsArr);
-
-  @Override
-  public String description() {
-    StringBuilder sb = new StringBuilder();
-    sb.append(name()).append('(');
-    boolean firstTime=true;
-    for (ValueSource source : sources) {
-      if (firstTime) {
-        firstTime=false;
-      } else {
-        sb.append(',');
-      }
-      sb.append(source);
-    }
-    sb.append(')');
-    return sb.toString();
-  }
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues[] valsArr = new FunctionValues[sources.length];
-    for (int i=0; i<sources.length; i++) {
-      valsArr[i] = sources[i].getValues(context, readerContext);
-    }
-
-    return new StrDocValues(this) {
-      @Override
-      public String strVal(int doc) {
-        CharSequence cs = func(doc, valsArr);
-        return  cs != null ? cs.toString() : null;
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        boolean exists = true;
-        for (FunctionValues val : valsArr) {
-          exists = exists & val.exists(doc);
-        }
-        return exists;
-      }
-      
-      @Override
-      public boolean bytesVal(int doc, BytesRefBuilder bytes) {
-        bytes.clear();
-        CharSequence cs = func(doc, valsArr);
-        if( cs != null ){
-          bytes.copyChars(func(doc,valsArr));
-          return true;
-        } else {
-          return false;
-        }
-      }
-      
-      @Override
-      public String toString(int doc) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(name()).append('(');
-        boolean firstTime=true;
-        for (FunctionValues vals : valsArr) {
-          if (firstTime) {
-            firstTime=false;
-          } else {
-            sb.append(',');
-          }
-          sb.append(vals.toString(doc));
-        }
-        sb.append(')');
-        return sb.toString();
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final MutableValueStr mval = new MutableValueStr();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            mval.exists = bytesVal(doc, mval.value);
-          }
-        };
-      }
-    };
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    MultiStringFunction other = (MultiStringFunction)o;
-    return this.name().equals(other.name())
-            && Arrays.equals(this.sources, other.sources);
-  }
-
-  @Override
-  public int hashCode() {
-    return Arrays.hashCode(sources) + name().hashCode();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java
deleted file mode 100644
index 5f9de24..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>MultiplyDoubleFunction</code> returns the product of it's components.
- */
-public class MultiplyDoubleFunction extends MultiDoubleFunction {
-  public final static String NAME = AnalyticsParams.MULTIPLY;
-
-  public MultiplyDoubleFunction(ValueSource[] sources) {
-    super(sources);
-  }
-
-  @Override
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected double func(int doc, FunctionValues[] valsArr) {
-    double product = 1d;
-    for (FunctionValues val : valsArr) {
-      product *= val.doubleVal(doc);
-    }
-    return product;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java
deleted file mode 100644
index 4bff8d0..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>NegateDoubleFunction</code> negates the double value of the source it contains.
- */
-public class NegateDoubleFunction extends SingleDoubleFunction {
-  public final static String NAME = AnalyticsParams.NEGATE;
-  
-  public NegateDoubleFunction(ValueSource source) {
-    super(source);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  public String description() {
-    return name()+"("+source.description()+")";
-  }
-
-  protected double func(int doc, FunctionValues vals) {
-    return vals.doubleVal(doc)*-1;
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    NegateDoubleFunction other = (NegateDoubleFunction)o;
-    return this.source.equals(other.source);
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java
deleted file mode 100644
index 1b4348b..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>PowDoubleFunction</code> returns 'a' raised to the power of 'b'.
- */
-public class PowDoubleFunction extends DualDoubleFunction {
-  public final static String NAME = AnalyticsParams.POWER;
-
-  /**
-    * @param   a  the base.
-    * @param   b  the exponent.
-    */
-  public PowDoubleFunction(ValueSource a, ValueSource b) {
-    super(a, b);
-  }
-
-  @Override
-  protected String name() {
-    return NAME;
-  }
-
-  @Override
-  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
-    return Math.pow(aVals.doubleVal(doc), bVals.doubleVal(doc));
-  }
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java
deleted file mode 100644
index 568f94e..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java
+++ /dev/null
@@ -1,44 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import org.apache.commons.lang.StringUtils;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.solr.analytics.util.AnalyticsParams;
-
-/**
- * <code>ReverseStringFunction</code> reverses the string value of the source it contains.
- */
-public class ReverseStringFunction extends SingleStringFunction {
-  public final static String NAME = AnalyticsParams.REVERSE;
-  
-  public ReverseStringFunction(ValueSource source) {
-    super(source);
-  }
-
-  protected String name() {
-    return NAME;
-  }
-
-  protected CharSequence func(int doc, FunctionValues vals) {
-    String val = vals.strVal(doc);
-    return val != null ? StringUtils.reverse(val) : null;
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java
deleted file mode 100644
index 45fc4ca..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps one ValueSource
- * and applies an extendible double function to its values.
- */
-public abstract class SingleDoubleFunction extends ValueSource {
-  protected final ValueSource source;
-  
-  public SingleDoubleFunction(ValueSource source) {
-    this.source = source;
-  }
-
-  @Override
-  public String description() {
-    return name()+"("+source.description()+")";
-  }
-
-  abstract String name();
-  abstract double func(int doc, FunctionValues vals);
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues vals =  source.getValues(context, readerContext);
-    return new DoubleDocValues(this) {
-      @Override
-      public double doubleVal(int doc) {
-        return func(doc, vals);
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        return vals.exists(doc);
-      }
-
-      @Override
-      public String toString(int doc) {
-        return name() + '(' + vals.toString(doc) + ')';
-      }
-    };
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    SingleDoubleFunction other = (SingleDoubleFunction)o;
-    return this.source.equals(other.source);
-  }
-
-  @Override
-  public int hashCode() {
-    return source.hashCode()+name().hashCode();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java
deleted file mode 100644
index 7540649..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-import java.io.IOException;
-import java.util.Map;
-
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.queries.function.FunctionValues;
-import org.apache.lucene.queries.function.ValueSource;
-import org.apache.lucene.queries.function.docvalues.StrDocValues;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.mutable.MutableValue;
-import org.apache.lucene.util.mutable.MutableValueStr;
-
-/**
- * Abstract {@link ValueSource} implementation which wraps one ValueSource
- * and applies an extendible string function to its values.
- */
-public abstract class SingleStringFunction extends ValueSource {
-  protected final ValueSource source;
-  
-  public SingleStringFunction(ValueSource source) {
-    this.source = source;
-  }
-
-  @Override
-  public String description() {
-    return name()+"("+source.description()+")";
-  }
-
-  abstract String name();
-  abstract CharSequence func(int doc, FunctionValues vals);
-
-  @Override
-  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
-    final FunctionValues vals =  source.getValues(context, readerContext);
-    return new StrDocValues(this) {
-      @Override
-      public String strVal(int doc) {
-        CharSequence cs = func(doc, vals);
-        return cs != null ? cs.toString() : null;
-      }
-      
-      @Override
-      public boolean bytesVal(int doc, BytesRefBuilder bytes) {
-        CharSequence cs = func(doc, vals);
-        if( cs != null ){
-          bytes.copyChars(func(doc,vals));
-          return true;
-        } else {
-          bytes.clear();
-          return false;
-        }
-      }
-
-      @Override
-      public Object objectVal(int doc) {
-        return strVal(doc);
-      }
-      
-      @Override
-      public boolean exists(int doc) {
-        return vals.exists(doc);
-      }
-
-      @Override
-      public String toString(int doc) {
-        return name() + '(' + strVal(doc) + ')';
-      }
-
-      @Override
-      public ValueFiller getValueFiller() {
-        return new ValueFiller() {
-          private final MutableValueStr mval = new MutableValueStr();
-
-          @Override
-          public MutableValue getValue() {
-            return mval;
-          }
-
-          @Override
-          public void fillValue(int doc) {
-            mval.exists = bytesVal(doc, mval.value);
-          }
-        };
-      }
-    };
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (getClass() != o.getClass()) return false;
-    SingleStringFunction other = (SingleStringFunction)o;
-    return this.source.equals(other.source);
-  }
-
-  @Override
-  public int hashCode() {
-    return source.hashCode()+name().hashCode();
-  }
-
-}
diff --git solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/package.html solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/package.html
deleted file mode 100644
index c5059c1..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/analytics/util/valuesource/package.html
+++ /dev/null
@@ -1,27 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-<p>
-ValueSource function/sources used by analytics component
-</p>
-</body>
-</html>
diff --git solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java
deleted file mode 100644
index 38e73e2..0000000
--- solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.handler.component;
-
-import java.io.IOException;
-
-import org.apache.solr.analytics.plugin.AnalyticsStatisticsCollector;
-import org.apache.solr.analytics.request.AnalyticsStats;
-import org.apache.solr.analytics.util.AnalyticsParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-
-public class AnalyticsComponent extends SearchComponent {
-  public static final String COMPONENT_NAME = "analytics";
-  private final AnalyticsStatisticsCollector analyticsCollector = new AnalyticsStatisticsCollector();;
-
-  @Override
-  public void prepare(ResponseBuilder rb) throws IOException {
-    if (rb.req.getParams().getBool(AnalyticsParams.ANALYTICS,false)) {
-      rb.setNeedDocSet( true );
-    }
-  }
-
-  @Override
-  public void process(ResponseBuilder rb) throws IOException {
-    if (rb.req.getParams().getBool(AnalyticsParams.ANALYTICS,false)) {
-      SolrParams params = rb.req.getParams();
-      AnalyticsStats s = new AnalyticsStats(rb.req, rb.getResults().docSet, params, analyticsCollector);
-      rb.rsp.add( "stats", s.execute() );
-    }
-  }
-  
-  /*
-  @Override
-  public int distributedProcess(ResponseBuilder rb) throws IOException {
-    return ResponseBuilder.STAGE_DONE;
-  }
-  
-  @Override
-  public void modifyRequest(ResponseBuilder rb, SearchComponent who, ShardRequest sreq) {
-    // TODO Auto-generated method stub
-    super.modifyRequest(rb, who, sreq);
-  }
-  
-  @Override
-  public void handleResponses(ResponseBuilder rb, ShardRequest sreq) {
-    // TODO Auto-generated method stub
-    super.handleResponses(rb, sreq);
-  }
- 
-  @Override
-  public void finishStage(ResponseBuilder rb) {
-    // TODO Auto-generated method stub
-    super.finishStage(rb);
-  }
-  */
-  
-  @Override
-  public String getName() {
-    return COMPONENT_NAME;
-  }
-  
-  @Override
-  public String getDescription() {
-    return "Perform analytics";
-  }
-
-  @Override
-  public String getVersion() {
-    return getClass().getPackage().getSpecificationVersion();
-  }
-
-  @Override
-  public NamedList getStatistics() {
-    return analyticsCollector.getStatistics();
-  }
-}
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/expressions.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/expressions.txt
deleted file mode 100644
index 329d32d..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/expressions.txt
+++ /dev/null
@@ -1,70 +0,0 @@
-o.ar.s.sum=sum(int_id)
-o.ar.s.unique=unique(long_ld)
-o.ar.s.su=add(sum(int_id),unique(long_ld))
-o.ar.s.mean=mean(int_id)
-o.ar.s.count=count(long_ld)
-o.ar.s.median=median(int_id)
-o.ar.s.mcm=add(mean(int_id),count(long_ld),median(int_id))
-
-o.mr.s.sum=sum(int_id)
-o.mr.s.unique=unique(long_ld)
-o.mr.s.su=mult(sum(int_id),unique(long_ld))
-o.mr.s.mean=mean(int_id)
-o.mr.s.count=count(long_ld)
-o.mr.s.median=median(int_id)
-o.mr.s.mcm=mult(mean(int_id),count(long_ld),median(int_id))
-
-o.dr.s.sum=sum(int_id)
-o.dr.s.unique=unique(long_ld)
-o.dr.s.su=div(sum(int_id),unique(long_ld))
-o.dr.s.mean=mean(int_id)
-o.dr.s.count=count(long_ld)
-o.dr.s.mc=div(mean(int_id),count(long_ld))
-
-o.pr.s.sum=sum(int_id)
-o.pr.s.unique=unique(long_ld)
-o.pr.s.su=pow(sum(int_id),unique(long_ld))
-o.pr.s.mean=mean(int_id)
-o.pr.s.count=count(long_ld)
-o.pr.s.mc=pow(mean(int_id),count(long_ld))
-
-o.nr.s.sum=sum(int_id)
-o.nr.s.s=neg(sum(int_id))
-o.nr.s.count=count(long_ld)
-o.nr.s.c=neg(count(long_ld))
-
-o.avr.s.sum=sum(int_id)
-o.avr.s.s=abs(neg(sum(int_id)))
-o.avr.s.count=count(long_ld)
-o.avr.s.c=abs(neg(count(long_ld)))
-
-o.cnr.s.c8=const_num(8)
-o.cnr.s.c10=const_num(10)
-
-o.dmr.s.median=median(date_dtd)
-o.dmr.s.cme=const_str(+2YEARS)
-o.dmr.s.dmme=date_math(median(date_dtd),const_str(+2YEARS))
-o.dmr.s.max=max(date_dtd)
-o.dmr.s.cma=const_str(+2MONTHS)
-o.dmr.s.dmma=date_math(max(date_dtd),const_str(+2MONTHS))
-
-o.cdr.s.cd1=const_date(1800-12-31T23:59:59Z)
-o.cdr.s.cs1=const_str(1800-12-31T23:59:59Z)
-o.cdr.s.cd2=const_date(1804-06-30T23:59:59Z)
-o.cdr.s.cs2=const_str(1804-06-30T23:59:59Z)
-
-o.csr.s.cs1=const_str(this is the first)
-o.csr.s.cs2=const_str(this is the second)
-o.csr.s.cs3=const_str(this is the third)
-
-o.cr.s.csmin=const_str(this is the first)
-o.cr.s.min=min(string_sd)
-o.cr.s.ccmin=concat(const_str(this is the first),min(string_sd))
-o.cr.s.csmax=const_str(this is the second)
-o.cr.s.max=max(string_sd)
-o.cr.s.ccmax=concat(const_str(this is the second),max(string_sd))
-
-o.rr.s.min=min(string_sd)
-o.rr.s.rmin=rev(min(string_sd))
-o.rr.s.max=max(string_sd)
-o.rr.s.rmax=rev(max(string_sd))
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacetExtras.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacetExtras.txt
deleted file mode 100644
index 3979f57..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacetExtras.txt
+++ /dev/null
@@ -1,66 +0,0 @@
-o.sr.s.mean=mean(int_id)
-o.sr.s.median=median(int_id)
-o.sr.s.count=count(int_id)
-o.sr.s.percentile_20=percentile(20,int_id)
-o.sr.ff=long_ld
-o.sr.ff.long_ld.ss=mean
-o.sr.ff.long_ld.sd=asc
-o.sr.ff=float_fd
-o.sr.ff.float_fd.ss=median
-o.sr.ff.float_fd.sd=desc
-o.sr.ff=double_dd
-o.sr.ff.double_dd.ss=count
-o.sr.ff.double_dd.sd=asc
-o.sr.ff=string_sd
-o.sr.ff.string_sd.ss=percentile_20
-o.sr.ff.string_sd.sd=desc
-
-o.lr.s.mean=mean(int_id)
-o.lr.s.median=median(int_id)
-o.lr.s.count=count(int_id)
-o.lr.s.percentile_20=percentile(20,int_id)
-o.lr.ff=long_ld
-o.lr.ff.long_ld.ss=mean
-o.lr.ff.long_ld.sd=asc
-o.lr.ff.long_ld.limit=5
-o.lr.ff=float_fd
-o.lr.ff.float_fd.ss=median
-o.lr.ff.float_fd.sd=desc
-o.lr.ff.float_fd.limit=3
-o.lr.ff=double_dd
-o.lr.ff.double_dd.ss=count
-o.lr.ff.double_dd.sd=asc
-o.lr.ff.double_dd.limit=7
-o.lr.ff=string_sd
-o.lr.ff.string_sd.ss=percentile_20
-o.lr.ff.string_sd.sd=desc
-o.lr.ff.string_sd.limit=1
-
-
-
-o.offAll.s.mean=mean(int_id)
-o.offAll.ff=long_ld
-o.offAll.ff.long_ld.ss=mean
-o.offAll.ff.long_ld.sd=asc
-o.offAll.ff.long_ld.limit=7
-
-o.off0.s.mean=mean(int_id)
-o.off0.ff=long_ld
-o.off0.ff.long_ld.ss=mean
-o.off0.ff.long_ld.sd=asc
-o.off0.ff.long_ld.limit=2
-o.off0.ff.long_ld.offset=0
-
-o.off1.s.mean=mean(int_id)
-o.off1.ff=long_ld
-o.off1.ff.long_ld.ss=mean
-o.off1.ff.long_ld.sd=asc
-o.off1.ff.long_ld.limit=2
-o.off1.ff.long_ld.offset=2
-
-o.off2.s.mean=mean(int_id)
-o.off2.ff=long_ld
-o.off2.ff.long_ld.ss=mean
-o.off2.ff.long_ld.sd=asc
-o.off2.ff.long_ld.limit=3
-o.off2.ff.long_ld.offset=4
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacets.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacets.txt
deleted file mode 100644
index 5ba5953..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/fieldFacets.txt
+++ /dev/null
@@ -1,132 +0,0 @@
-o.sum.s.int=sum(int_id)
-o.sum.s.long=sum(long_ld)
-o.sum.s.float=sum(float_fd)
-o.sum.s.double=sum(double_dd)
-o.sum.ff=string_sd
-o.sum.ff=date_dtd
-
-o.mean.s.int=mean(int_id)
-o.mean.s.long=mean(long_ld)
-o.mean.s.float=mean(float_fd)
-o.mean.s.double=mean(double_dd)
-o.mean.ff=string_sd
-o.mean.ff=date_dtd
-
-o.sumOfSquares.s.int=sumofsquares(int_id)
-o.sumOfSquares.s.long=sumofsquares(long_ld)
-o.sumOfSquares.s.float=sumofsquares(float_fd)
-o.sumOfSquares.s.double=sumofsquares(double_dd)
-o.sumOfSquares.ff=string_sd
-o.sumOfSquares.ff=date_dtd
-
-o.stddev.s.int=stddev(int_id)
-o.stddev.s.long=stddev(long_ld)
-o.stddev.s.float=stddev(float_fd)
-o.stddev.s.double=stddev(double_dd)
-o.stddev.ff=string_sd
-o.stddev.ff=date_dtd
-
-o.median.s.int=median(int_id)
-o.median.s.long=median(long_ld)
-o.median.s.float=median(float_fd)
-o.median.s.double=median(double_dd)
-o.median.ff=string_sd
-o.median.ff=date_dtd
-
-o.percentile_20n.s.int=percentile(20,int_id)
-o.percentile_20n.s.long=percentile(20,long_ld)
-o.percentile_20n.s.float=percentile(20,float_fd)
-o.percentile_20n.s.double=percentile(20,double_dd)
-o.percentile_20n.ff=string_sd
-o.percentile_20n.ff=date_dtd
-
-o.percentile_20.s.str=percentile(20,string_sd)
-o.percentile_20.s.date=percentile(20,date_dtd)
-o.percentile_20.ff=int_id
-o.percentile_20.ff=long_ld
-
-o.percentile_60n.s.int=percentile(60,int_id)
-o.percentile_60n.s.long=percentile(60,long_ld)
-o.percentile_60n.s.float=percentile(60,float_fd)
-o.percentile_60n.s.double=percentile(60,double_dd)
-o.percentile_60n.ff=string_sd
-o.percentile_60n.ff=date_dtd
-
-o.percentile_60.s.str=percentile(60,string_sd)
-o.percentile_60.s.date=percentile(60,date_dtd)
-o.percentile_60.ff=int_id
-o.percentile_60.ff=long_ld
-
-o.minn.s.int=min(int_id)
-o.minn.s.long=min(long_ld)
-o.minn.s.float=min(float_fd)
-o.minn.s.double=min(double_dd)
-o.minn.ff=string_sd
-o.minn.ff=date_dtd
-
-o.min.s.str=min(string_sd)
-o.min.s.date=min(date_dtd)
-o.min.ff=int_id
-o.min.ff=long_ld
-
-o.maxn.s.int=max(int_id)
-o.maxn.s.long=max(long_ld)
-o.maxn.s.float=max(float_fd)
-o.maxn.s.double=max(double_dd)
-o.maxn.ff=string_sd
-o.maxn.ff=date_dtd
-
-o.max.s.str=max(string_sd)
-o.max.s.date=max(date_dtd)
-o.max.ff=int_id
-o.max.ff=long_ld
-
-o.countn.s.int=count(int_id)
-o.countn.s.long=count(long_ld)
-o.countn.s.float=count(float_fd)
-o.countn.s.double=count(double_dd)
-o.countn.ff=string_sd
-o.countn.ff=date_dtd
-
-o.count.s.str=count(string_sd)
-o.count.s.date=count(date_dtd)
-o.count.ff=int_id
-o.count.ff=long_ld
-
-o.uniquen.s.int=unique(int_id)
-o.uniquen.s.long=unique(long_ld)
-o.uniquen.s.float=unique(float_fd)
-o.uniquen.s.double=unique(double_dd)
-o.uniquen.ff=string_sd
-o.uniquen.ff=date_dtd
-
-o.unique.s.str=unique(string_sd)
-o.unique.s.date=unique(date_dtd)
-o.unique.ff=int_id
-o.unique.ff=long_ld
-
-o.missingn.s.int=missing(int_id)
-o.missingn.s.long=missing(long_ld)
-o.missingn.s.float=missing(float_fd)
-o.missingn.s.double=missing(double_dd)
-o.missingn.ff=string_sd
-o.missingn.ff=date_dtd
-
-o.missing.s.str=missing(string_sd)
-o.missing.s.date=missing(date_dtd)
-o.missing.ff=int_id
-o.missing.ff=long_ld
-
-o.multivalued.s.mean=mean(int_id)
-o.multivalued.ff=long_ldm
-o.multivalued.ff=string_sdm
-o.multivalued.ff=date_dtdm
-
-o.missingf.s.mean=mean(int_id)
-o.missingf.ff=date_dtd
-o.missingf.ff.date_dtd.dim=true
-o.missingf.ff=string_sd
-o.missingf.ff.string_sd.dim=true
-o.missingf.ff.string_sd.sm=true
-o.missingf.ff=date_dtdm
-o.missingf.ff.date_dtdm.sm=true
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/functions.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/functions.txt
deleted file mode 100644
index e4930b6..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/functions.txt
+++ /dev/null
@@ -1,62 +0,0 @@
-o.ar.s.sum=sum(add(int_id,float_fd))
-o.ar.s.sumc=sum(add_if_dd)
-o.ar.s.mean=mean(add(long_ld,double_dd,float_fd))
-o.ar.s.meanc=mean(add_ldf_dd)
-
-o.mr.s.sum=sum(mult(int_id,float_fd))
-o.mr.s.sumc=sum(mult_if_dd)
-o.mr.s.mean=mean(mult(long_ld,double_dd,float_fd))
-o.mr.s.meanc=mean(mult_ldf_dd)
-
-o.dr.s.sum=sum(div(int_id,float_fd))
-o.dr.s.sumc=sum(div_if_dd)
-o.dr.s.mean=mean(div(long_ld,double_dd))
-o.dr.s.meanc=mean(div_ld_dd)
-
-o.pr.s.sum=sum(pow(int_id,float_fd))
-o.pr.s.sumc=sum(pow_if_dd)
-o.pr.s.mean=mean(pow(long_ld,double_dd))
-o.pr.s.meanc=mean(pow_ld_dd)
-
-o.nr.s.sum=sum(neg(int_id))
-o.nr.s.sumc=sum(neg_i_dd)
-o.nr.s.mean=mean(neg(long_ld))
-o.nr.s.meanc=mean(neg_l_dd)
-
-o.avr.s.sum=sum(abs(neg(int_id)))
-o.avr.s.sumc=sum(int_id)
-o.avr.s.mean=mean(abs(neg(int_id)))
-o.avr.s.meanc=mean(int_id)
-
-o.cnr.s.sum=sum(const_num(8))
-o.cnr.s.sumc=sum(const_8_dd)
-o.cnr.s.mean=mean(const_num(10))
-o.cnr.s.meanc=mean(const_10_dd)
-
-o.dmr.s.median=median(date_math(date_dtd,const_str(+2YEARS)))
-o.dmr.s.medianc=median(dm_2y_dtd)
-o.dmr.s.max=max(date_math(date_dtd,const_str(+2MONTHS)))
-o.dmr.s.maxc=max(dm_2m_dtd)
-
-o.cdr.s.median=median(const_date(1800-06-30T23:59:59Z))
-o.cdr.s.medianc=median(const_00_dtd)
-o.cdr.s.max=max(const_date(1804-06-30T23:59:59Z))
-o.cdr.s.maxc=max(const_04_dtd)
-
-o.csr.s.min=min(const_str(this is the first))
-o.csr.s.minc=min(const_first_sd)
-o.csr.s.max=max(const_str(this is the second))
-o.csr.s.maxc=max(const_second_sd)
-
-o.cr.s.min=min(concat(const_str(this is the first),string_sd))
-o.cr.s.minc=min(concat_first_sd)
-o.cr.s.max=max(concat(const_str(this is the second),string_sd))
-o.cr.s.maxc=max(concat_second_sd)
-
-o.rr.s.min=min(rev(string_sd))
-o.rr.s.minc=min(rev_sd)
-o.rr.s.max=max(rev(string_sd))
-o.rr.s.maxc=max(rev_sd)
-
-o.ms.s.min=min(miss_dd)
-o.ms.s.max=max(miss_dd)
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/noFacets.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/noFacets.txt
deleted file mode 100644
index b3d9163..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/noFacets.txt
+++ /dev/null
@@ -1,74 +0,0 @@
-o.sr.s.int_id=sum(int_i)
-o.sr.s.long_ld=sum(long_l)
-o.sr.s.float_fd=sum(float_f)
-o.sr.s.double_dd=sum(double_d)
-
-o.sosr.s.int_id=sumofsquares(int_id)
-o.sosr.s.long_ld=sumofsquares(long_ld)
-o.sosr.s.float_fd=sumofsquares(float_fd)
-o.sosr.s.double_dd=sumofsquares(double_dd)
-
-o.mr.s.int_id=mean(int_id)
-o.mr.s.long_ld=mean(long_ld)
-o.mr.s.float_fd=mean(float_fd)
-o.mr.s.double_dd=mean(double_dd)
-
-o.str.s.int_id=stddev(int_id)
-o.str.s.long_ld=stddev(long_ld)
-o.str.s.float_fd=stddev(float_fd)
-o.str.s.double_dd=stddev(double_dd)
-
-o.medr.s.int_id=median(int_id)
-o.medr.s.long_ld=median(long_ld)
-o.medr.s.float_fd=median(float_fd)
-o.medr.s.double_dd=median(double_dd)
-o.medr.s.date_dtd=median(date_dtd)
-
-o.p2r.s.int_id=percentile(20,int_id)
-o.p2r.s.long_ld=percentile(20,long_ld)
-o.p2r.s.float_fd=percentile(20,float_fd)
-o.p2r.s.double_dd=percentile(20,double_dd)
-o.p2r.s.date_dtd=percentile(20,date_dtd)
-o.p2r.s.string_sd=percentile(20,string_sd)
-
-o.p6r.s.int_id=percentile(60,int_id)
-o.p6r.s.long_ld=percentile(60,long_ld)
-o.p6r.s.float_fd=percentile(60,float_fd)
-o.p6r.s.double_dd=percentile(60,double_dd)
-o.p6r.s.date_dtd=percentile(60,date_dtd)
-o.p6r.s.string_sd=percentile(60,string_sd)
-
-o.mir.s.int_id=min(int_id)
-o.mir.s.long_ld=min(long_ld)
-o.mir.s.float_fd=min(float_fd)
-o.mir.s.double_dd=min(double_dd)
-o.mir.s.date_dtd=min(date_dtd)
-o.mir.s.string_sd=min(string_sd)
-
-o.mar.s.int_id=max(int_id)
-o.mar.s.long_ld=max(long_ld)
-o.mar.s.float_fd=max(float_fd)
-o.mar.s.double_dd=max(double_dd)
-o.mar.s.date_dtd=max(date_dtd)
-o.mar.s.string_sd=max(string_sd)
-
-o.cr.s.int_id=count(int_id)
-o.cr.s.long_ld=count(long_ld)
-o.cr.s.float_fd=count(float_fd)
-o.cr.s.double_dd=count(double_dd)
-o.cr.s.date_dtd=count(date_dtd)
-o.cr.s.string_sd=count(string_sd)
-
-o.ur.s.int_id=unique(int_id)
-o.ur.s.long_ld=unique(long_ld)
-o.ur.s.float_fd=unique(float_fd)
-o.ur.s.double_dd=unique(double_dd)
-o.ur.s.date_dtd=unique(date_dtd)
-o.ur.s.string_sd=unique(string_sd)
-
-o.misr.s.int_id=missing(int_id)
-o.misr.s.long_ld=missing(long_ld)
-o.misr.s.float_fd=missing(float_fd)
-o.misr.s.double_dd=missing(double_dd)
-o.misr.s.date_dtd=missing(date_dtd)
-o.misr.s.string_sd=missing(string_sd)
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/queryFacets.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/queryFacets.txt
deleted file mode 100644
index 6be4a4e..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/queryFacets.txt
+++ /dev/null
@@ -1,45 +0,0 @@
-o.ir.s.sum=sum(int_id)
-o.ir.s.mean=mean(int_id)
-o.ir.s.median=median(int_id)
-o.ir.s.percentile_8=percentile(8,int_id)
-o.ir.ff=string_sd
-o.ir.ff.string_sd.h=true
-o.ir.qf=float1
-o.ir.qf.float1.q=float_fd:[* TO 50]
-o.ir.qf=float2
-o.ir.qf.float2.q=float_fd:[* TO 30]
-
-o.pr.s.sum=sum(int_id)
-o.pr.s.mean=mean(int_id)
-o.pr.s.median=median(int_id)
-o.pr.s.q1=concat(const_str(float_fd:[), percentile(10,int_id), const_str( TO ), median(int_id), const_str(]))
-o.pr.hs.q2=concat(const_str(float_fd:[), percentile(30,int_id), const_str( TO ), median(int_id), const_str(]))
-o.pr.hs.q3=concat(const_str(float_fd:[), percentile(40,int_id), const_str( TO ), median(int_id), const_str(]))
-o.pr.s.percentile_8=percentile(8,int_id)
-o.pr.ff=string_sd
-o.pr.ff.string_sd.h=true
-o.pr.qf=float3
-o.pr.qf.float3.q=result(q1)
-o.pr.qf.float3.q=result(q2)
-o.pr.qf.float3.q=result(q3)
-o.pr.qf.float3.q=result(q1,string_sd,abc2)
-o.pr.qf=float4
-o.pr.qf.float4.d=float3
-o.pr.qf.float4.q=qresult(q1,float3,result(q1))
-
-o.lr.s.sum=sum(long_ld)
-o.lr.s.mean=mean(long_ld)
-o.lr.s.median=median(long_ld)
-o.lr.s.percentile_8=percentile(8,long_ld)
-o.lr.qf=string
-o.lr.qf.string.q=string_sd:abc1
-o.lr.qf.string.q=string_sd:abc2
-
-o.fr.s.sum=sum(float_fd)
-o.fr.s.mean=mean(float_fd)
-o.fr.s.median=median(float_fd)
-o.fr.s.percentile_8=percentile(8,float_fd)
-o.fr.qf=lad
-o.fr.qf.lad.q=long_ld:[20 TO *]
-o.fr.qf.lad.q=long_ld:[30 TO *]
-o.fr.qf.lad.q=double_dd:[* TO 50]
diff --git solr/contrib/analytics/src/test-files/analytics/requestFiles/rangeFacets.txt solr/contrib/analytics/src/test-files/analytics/requestFiles/rangeFacets.txt
deleted file mode 100644
index cbfe052..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestFiles/rangeFacets.txt
+++ /dev/null
@@ -1,170 +0,0 @@
-o.ri.s.sum=sum(int_id)
-o.ri.s.mean=mean(int_id)
-o.ri.s.median=median(int_id)
-o.ri.s.count=count(int_id)
-o.ri.s.sumOfSquares=sumofsquares(int_id)
-o.ri.rf=long_ld
-o.ri.rf.long_ld.st=5
-o.ri.rf.long_ld.e=30
-o.ri.rf.long_ld.g=5
-o.ri.rf.long_ld.ib=lower
-o.ri.rf.long_ld.or=all
-o.ri.rf=double_dd
-o.ri.rf.double_dd.st=3
-o.ri.rf.double_dd.e=39
-o.ri.rf.double_dd.g=7
-o.ri.rf.double_dd.ib=upper
-o.ri.rf.double_dd.ib=outer
-o.ri.rf.double_dd.or=all
-o.ri.rf=date_dtd
-o.ri.rf.date_dtd.st=1007-01-01T23:59:59Z
-o.ri.rf.date_dtd.e=1044-01-01T23:59:59Z
-o.ri.rf.date_dtd.g=+7YEARS
-o.ri.rf.date_dtd.ib=lower
-o.ri.rf.date_dtd.ib=edge
-o.ri.rf.date_dtd.ib=outer
-o.ri.rf.date_dtd.or=all
-
-o.rf.s.sum=sum(float_fd)
-o.rf.s.mean=mean(float_fd)
-o.rf.s.median=median(float_fd)
-o.rf.s.count=count(float_fd)
-o.rf.s.sumOfSquares=sumofsquares(float_fd)
-o.rf.rf=long_ld
-o.rf.rf.long_ld.st=0
-o.rf.rf.long_ld.e=29
-o.rf.rf.long_ld.g=4
-o.rf.rf.long_ld.ib=all
-o.rf.rf.long_ld.or=all
-o.rf.rf=double_dd
-o.rf.rf.double_dd.st=4
-o.rf.rf.double_dd.e=47
-o.rf.rf.double_dd.g=11
-o.rf.rf.double_dd.ib=edge
-o.rf.rf.double_dd.or=all
-o.rf.rf=date_dtd
-o.rf.rf.date_dtd.st=1004-01-01T23:59:59Z
-o.rf.rf.date_dtd.e=1046-01-01T23:59:59Z
-o.rf.rf.date_dtd.g=+5YEARS
-o.rf.rf.date_dtd.ib=upper
-o.rf.rf.date_dtd.ib=edge
-o.rf.rf.date_dtd.or=all
-
-o.hi.s.sum=sum(int_id)
-o.hi.s.mean=mean(int_id)
-o.hi.s.median=median(int_id)
-o.hi.s.count=count(int_id)
-o.hi.s.sumOfSquares=sumofsquares(int_id)
-o.hi.rf=long_ld
-o.hi.rf.long_ld.st=5
-o.hi.rf.long_ld.e=30
-o.hi.rf.long_ld.g=5
-o.hi.rf.long_ld.he=true
-o.hi.rf.long_ld.ib=lower
-o.hi.rf.long_ld.or=all
-o.hi.rf=double_dd
-o.hi.rf.double_dd.st=3
-o.hi.rf.double_dd.e=39
-o.hi.rf.double_dd.g=7
-o.hi.rf.double_dd.he=true
-o.hi.rf.double_dd.ib=upper
-o.hi.rf.double_dd.ib=outer
-o.hi.rf.double_dd.or=all
-o.hi.rf=date_dtd
-o.hi.rf.date_dtd.st=1007-01-01T23:59:59Z
-o.hi.rf.date_dtd.e=1044-01-01T23:59:59Z
-o.hi.rf.date_dtd.g=+7YEARS
-o.hi.rf.date_dtd.he=true
-o.hi.rf.date_dtd.ib=lower
-o.hi.rf.date_dtd.ib=edge
-o.hi.rf.date_dtd.ib=outer
-o.hi.rf.date_dtd.or=all
-
-o.hf.s.sum=sum(float_fd)
-o.hf.s.mean=mean(float_fd)
-o.hf.s.median=median(float_fd)
-o.hf.s.count=count(float_fd)
-o.hf.s.sumOfSquares=sumofsquares(float_fd)
-o.hf.rf=long_ld
-o.hf.rf.long_ld.st=0
-o.hf.rf.long_ld.e=29
-o.hf.rf.long_ld.g=4
-o.hf.rf.long_ld.he=true
-o.hf.rf.long_ld.ib=all
-o.hf.rf.long_ld.or=all
-o.hf.rf=double_dd
-o.hf.rf.double_dd.st=4
-o.hf.rf.double_dd.e=47
-o.hf.rf.double_dd.g=11
-o.hf.rf.double_dd.he=true
-o.hf.rf.double_dd.ib=edge
-o.hf.rf.double_dd.or=all
-o.hf.rf=date_dtd
-o.hf.rf.date_dtd.st=1004-01-01T23:59:59Z
-o.hf.rf.date_dtd.e=1046-01-01T23:59:59Z
-o.hf.rf.date_dtd.g=+5YEARS
-o.hf.rf.date_dtd.he=true
-o.hf.rf.date_dtd.ib=upper
-o.hf.rf.date_dtd.ib=edge
-o.hf.rf.date_dtd.or=all
-
-o.mi.s.sum=sum(int_id)
-o.mi.s.mean=mean(int_id)
-o.mi.s.median=median(int_id)
-o.mi.s.count=count(int_id)
-o.mi.s.sumOfSquares=sumofsquares(int_id)
-o.mi.rf=long_ld
-o.mi.rf.long_ld.st=5
-o.mi.rf.long_ld.e=30
-o.mi.rf.long_ld.g=4,2,6,3
-o.mi.rf.long_ld.ib=lower
-o.mi.rf.long_ld.or=all
-o.mi.rf=double_dd
-o.mi.rf.double_dd.st=3
-o.mi.rf.double_dd.e=39
-o.mi.rf.double_dd.g=3,1,7
-o.mi.rf.double_dd.ib=upper
-o.mi.rf.double_dd.ib=outer
-o.mi.rf.double_dd.or=all
-o.mi.rf=date_dtd
-o.mi.rf.date_dtd.st=1007-01-01T23:59:59Z
-o.mi.rf.date_dtd.e=1044-01-01T23:59:59Z
-o.mi.rf.date_dtd.g=+2YEARS,+7YEARS
-o.mi.rf.date_dtd.ib=lower
-o.mi.rf.date_dtd.ib=edge
-o.mi.rf.date_dtd.ib=outer
-o.mi.rf.date_dtd.or=all
-
-o.mf.s.sum=sum(float_fd)
-o.mf.s.mean=mean(float_fd)
-o.mf.s.median=median(float_fd)
-o.mf.s.count=count(float_fd)
-o.mf.s.sumOfSquares=sumofsquares(float_fd)
-o.mf.rf=long_ld
-o.mf.rf.long_ld.st=0
-o.mf.rf.long_ld.e=29
-o.mf.rf.long_ld.g=1,4
-o.mf.rf.long_ld.ib=all
-o.mf.rf.long_ld.or=all
-o.mf.rf=double_dd
-o.mf.rf.double_dd.st=4
-o.mf.rf.double_dd.e=47
-o.mf.rf.double_dd.g=2,3,11
-o.mf.rf.double_dd.ib=edge
-o.mf.rf.double_dd.or=all
-o.mf.rf=date_dtd
-o.mf.rf.date_dtd.st=1004-01-01T23:59:59Z
-o.mf.rf.date_dtd.e=1046-01-01T23:59:59Z
-o.mf.rf.date_dtd.g=+4YEARS,+5YEARS
-o.mf.rf.date_dtd.ib=upper
-o.mf.rf.date_dtd.ib=edge
-o.mf.rf.date_dtd.or=all
-
-o.pf.s.mean=mean(float_fd)
-o.pf.hs.min=min(date_dtd)
-o.pf.hs.max=max(date_dtd)
-o.pf.hs.gap=const_str(+5YEARS)
-o.pf.rf=date_dtd
-o.pf.rf.date_dtd.st=result(min)
-o.pf.rf.date_dtd.e=result(max)
-o.pf.rf.date_dtd.g=result(gap)
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/expressions.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/expressions.xml
deleted file mode 100644
index 511805d..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/expressions.xml
+++ /dev/null
@@ -1,285 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>Add Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>unique</name>
- 		</statistic>
- 		<statistic>
- 			<expression>add(sum(int(int_id)),unique(long(long_ld)))</expression>
- 			<name>add sum and unique</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>add(mean(int(int_id)),count(long(long_ld)),median(int(int_id)))</expression>
- 			<name>add mean and count and median</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Multiply Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>unique</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mult(sum(int(int_id)),unique(long(long_ld)))</expression>
- 			<name>multiply sum and unique</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mult(mean(int(int_id)),count(long(long_ld)),median(int(int_id)))</expression>
- 			<name>multiply mean and count and median</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Divide Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>unique</name>
- 		</statistic>
- 		<statistic>
- 			<expression>div(sum(int(int_id)),unique(long(long_ld)))</expression>
- 			<name>divide sum by unique</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>div(mean(int(int_id)),count(long(long_ld)))</expression>
- 			<name>divide mean by count</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Power Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>unique</name>
- 		</statistic>
- 		<statistic>
- 			<expression>pow(sum(int(int_id)),unique(long(long_ld)))</expression>
- 			<name>power sum by unique</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>pow(mean(int(int_id)),count(long(long_ld)))</expression>
- 			<name>power mean by count</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Negate Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>neg(sum(int(int_id)))</expression>
- 			<name>negate of sum</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>neg(count(long(long_ld)))</expression>
- 			<name>negate of count</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Const Num Request</name>
- 		
- 		<statistic>
- 			<expression>const_num(8)</expression>
- 			<name>constant 8</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_num(10)</expression>
- 			<name>constant 10</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Date Math Request</name>
- 		
- 		<statistic>
- 			<expression>median(date(date_dtd))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_str(+2YEARS)</expression>
- 			<name>constant str median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>date_math(median(date(date_dtd)),const_str(+2YEARS))</expression>
- 			<name>date math median</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(date(date_dtd))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_str(+2MONTHS)</expression>
- 			<name>constant str max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>date_math(max(date(date_dtd)),const_str(+2MONTHS))</expression>
- 			<name>date math max</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Constant Date Request</name>
- 		
- 		<statistic>
- 			<expression>const_str(1800-12-31T23:59:59Z)</expression>
- 			<name>const str 1</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_date(1800-12-31T23:59:59Z)</expression>
- 			<name>const date 1</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_str(1804-06-30T23:59:59Z)</expression>
- 			<name>const str 2</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_date(1804-06-30T23:59:59Z)</expression>
- 			<name>const date 2</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Constant String Request</name>
- 		
- 		<statistic>
- 			<expression>const_str(this is the first)</expression>
- 			<name>const str 1</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_str(this is the second)</expression>
- 			<name>const str 2</name>
- 		</statistic>
- 		<statistic>
- 			<expression>const_str(this is the third)</expression>
- 			<name>const str 3</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Concatenate Request</name>
- 		
- 		<statistic>
- 			<expression>const_str(this is the first)</expression>
- 			<name>const str min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(str(string_sd))</expression>
- 			<name>min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>concat(const_str(this is the first),min(str(string_sd)))</expression>
- 			<name>concat const and min</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>const_str(this is the second)</expression>
- 			<name>const str max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(str(string_sd))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>concat(const_str(this is the second),max(str(string_sd)))</expression>
- 			<name>concat const and max</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Reverse Request</name>
- 		
- 		<statistic>
- 			<expression>min(str(string_sd))</expression>
- 			<name>min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>rev(min(str(string_sd)))</expression>
- 			<name>reverse min</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(str(string_sd))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>rev(max(str(string_sd)))</expression>
- 			<name>reverse max</name>
- 		</statistic>
- 	</analyticsRequest>
-</analyticsRequestEnvelope> 
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml
deleted file mode 100644
index 5d7bf07..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml
+++ /dev/null
@@ -1,101 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>sort request</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,int(int_id))</expression>
- 			<name>perc_20</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>long_ld</field>
- 			<sortSpecification>
- 				<statName>mean</statName>
- 				<direction>asc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>float_fd</field>
- 			<sortSpecification>
- 				<statName>median</statName>
- 				<direction>desc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>double_dd</field>
- 			<sortSpecification>
- 				<statName>count</statName>
- 				<direction>asc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>string_sd</field>
- 			<sortSpecification>
- 				<statName>perc_20</statName>
- 				<direction>desc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>limit request</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,int(int_id))</expression>
- 			<name>perc_20</name>
- 		</statistic>
- 		
- 		<fieldFacet limit="5">
- 			<field>long_ld</field>
- 			<sortSpecification>
- 				<statName>mean</statName>
- 				<direction>asc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet limit="3">
- 			<field>float_fd</field>
- 			<sortSpecification>
- 				<statName>median</statName>
- 				<direction>desc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet limit="7">
- 			<field>double_dd</field>
- 			<sortSpecification>
- 				<statName>count</statName>
- 				<direction>asc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 		<fieldFacet limit="1">
- 			<field>string_sd</field>
- 			<sortSpecification>
- 				<statName>perc_20</statName>
- 				<direction>desc</direction>
- 			</sortSpecification>
- 		</fieldFacet>
- 	</analyticsRequest>
-</analyticsRequestEnvelope>
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacets.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacets.xml
deleted file mode 100644
index 53dd2d3..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/fieldFacets.xml
+++ /dev/null
@@ -1,496 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>sum</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>mean</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>sumOfSquares</name>
- 		
- 		<statistic>
- 			<expression>sumofsquares(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>stddev</name>
- 		
- 		<statistic>
- 			<expression>stddev(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>median</name>
- 		
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>perc_20 numeric</name>
- 		
- 		<statistic>
- 			<expression>perc(20,int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>perc_20</name>
- 		
- 		<statistic>
- 			<expression>perc(20,str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>perc_60 numeric</name>
- 		
- 		<statistic>
- 			<expression>perc(60,int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>perc_60</name>
- 		
- 		<statistic>
- 			<expression>perc(60,str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>min numeric</name>
- 		
- 		<statistic>
- 			<expression>min(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>min</name>
- 		
- 		<statistic>
- 			<expression>min(str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>max numeric</name>
- 		
- 		<statistic>
- 			<expression>max(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>max</name>
- 		
- 		<statistic>
- 			<expression>max(str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>count numeric</name>
- 		
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>count</name>
- 		
- 		<statistic>
- 			<expression>count(str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>unique numeric</name>
- 		
- 		<statistic>
- 			<expression>unique(int(int_id))</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(float(float_fd))</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(double(double_dd))</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>unique</name>
- 		
- 		<statistic>
- 			<expression>unique(str(string_sd))</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(date(date_dtd))</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>missing numeric</name>
- 		
- 		<statistic>
- 			<expression>missing(int{int_id})</expression>
- 			<name>int</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(long{long_ld})</expression>
- 			<name>long</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(float{float_fd})</expression>
- 			<name>float</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(double{double_dd})</expression>
- 			<name>double</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>missing</name>
- 		
- 		<statistic>
- 			<expression>missing(str{string_sd})</expression>
- 			<name>str</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(date{date_dtd})</expression>
- 			<name>date</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>int_id</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>long_ld</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>multivalued</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>long_ldm</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>string_sdm</field>
- 		</fieldFacet>
- 		<fieldFacet>
- 			<field>date_dtdm</field>
- 		</fieldFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>missing facet</name>
-
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<fieldFacet>
- 			<field>date_dtd</field>
- 		</fieldFacet>
- 		<fieldFacet showMissing="true">
- 			<field>string_sd</field>
- 		</fieldFacet>
- 		<fieldFacet showMissing="true">
- 			<field>date_dtdm</field>
- 		</fieldFacet>
- 	</analyticsRequest>
-</analyticsRequestEnvelope>
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/functions.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/functions.xml
deleted file mode 100644
index 40f5ada..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/functions.xml
+++ /dev/null
@@ -1,246 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>Add Request</name>
- 		
- 		<statistic>
- 			<expression>sum(add(int(int_id),float(float_fd)))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(add_if_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(add(long(long_ld),double(double_dd),float(float_fd)))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(add_ldf_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Multiply Request</name>
- 		
- 		<statistic>
- 			<expression>sum(mult(int(int_id),float(float_fd)))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(mult_if_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(mult(long(long_ld),double(double_dd),float(float_fd)))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(mult_ldf_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Divide Request</name>
- 		
- 		<statistic>
- 			<expression>sum(div(int(int_id),float(float_fd)))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(div_if_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(div(long(long_ld),double(double_dd)))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(double(div_ld_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Power Request</name>
- 		
- 		<statistic>
- 			<expression>sum(pow(int(int_id),float(float_fd))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(pow_if_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(pow(long(long_ld),double(double_dd)))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(double(pow_ld_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Negate Request</name>
- 		
- 		<statistic>
- 			<expression>sum(neg(int(int_id)))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(neg_i_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(neg(long(long_ld)))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(neg_l_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Const Num Request</name>
- 		
- 		<statistic>
- 			<expression>sum(const_num(8))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(const_8_dd))</expression>
- 			<name>sum calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(const_num(10))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(const_10_dd))</expression>
- 			<name>mean calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Date Math Request</name>
- 		
- 		<statistic>
- 			<expression>median(date_math(date(date_dtd),const_str(+2YEARS)))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(date(dm_2y_dtd))</expression>
- 			<name>median calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(date_math(date(date_dtd),const_str(+2MONTHS)))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(date(dm_2m_dtd))</expression>
- 			<name>max calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Constant Date Request</name>
- 		
- 		<statistic>
- 			<expression>median(const_date(1800-06-30T23:59:59Z))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(date(const_00_dtd))</expression>
- 			<name>median calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(const_date(1804-06-30T23:59:59Z))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(date(const_04_dtd))</expression>
- 			<name>max calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Constant String Request</name>
- 		
- 		<statistic>
- 			<expression>min(const_str(this is the first))</expression>
- 			<name>min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(str(const_first_sd))</expression>
- 			<name>min calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(const_str(this is the second))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(str(const_second_sd))</expression>
- 			<name>max calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Concatenate Request</name>
- 		
- 		<statistic>
- 			<expression>min(concat(const_str(this is the first),str(string_sd)))</expression>
- 			<name>min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(str(concat_first_sd))</expression>
- 			<name>min calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(concat(const_str(this is the second),str(string_sd)))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(str(concat_second_sd))</expression>
- 			<name>max calced</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Reverse Request</name>
- 		
- 		<statistic>
- 			<expression>min(rev(str(string_sd)))</expression>
- 			<name>min</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(str(rev_sd))</expression>
- 			<name>min calced</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>max(rev(str(string_sd)))</expression>
- 			<name>max</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(str(rev_sd))</expression>
- 			<name>max calced</name>
- 		</statistic>
- 	</analyticsRequest>
-</analyticsRequestEnvelope> 
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/noFacets.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/noFacets.xml
deleted file mode 100644
index ce00d38..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/noFacets.xml
+++ /dev/null
@@ -1,310 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>Sum Request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>SumOfSquares Request</name>
- 		
- 		<statistic>
- 			<expression>sumofsquares(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Mean Request</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>mean(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Stddev Request</name>
- 		
- 		<statistic>
- 			<expression>stddev(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>stddev(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Median Request</name>
- 		
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Perc 20 Request</name>
- 		
- 		<statistic>
- 			<expression>perc(20,int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(20,str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Perc 60 Request</name>
- 		
- 		<statistic>
- 			<expression>perc(60,int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>perc(60,str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Min Request</name>
- 		
- 		<statistic>
- 			<expression>min(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>min(str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Max Request</name>
- 		
- 		<statistic>
- 			<expression>max(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>max(str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Unique Request</name>
- 		
- 		<statistic>
- 			<expression>unique(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>unique(str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Count Request</name>
- 		
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(long(long_ld))</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(float(float_fd))</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(double(double_dd))</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(date(date_dtd))</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(str(string_sd))</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
- 	
- 	<analyticsRequest>
- 		<name>Missing Request</name>
- 		 		
- 		<statistic>
- 			<expression>missing(int{int_id})</expression>
- 			<name>int_id</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(long{long_ld})</expression>
- 			<name>long_ld</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(float{float_fd})</expression>
- 			<name>float_fd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(double{double_dd})</expression>
- 			<name>double_dd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(date{date_dtd})</expression>
- 			<name>date_dtd</name>
- 		</statistic>
- 		<statistic>
- 			<expression>missing(str{string_sd})</expression>
- 			<name>string_sd</name>
- 		</statistic>
- 	</analyticsRequest>
-</analyticsRequestEnvelope> 
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/queryFacets.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/queryFacets.xml
deleted file mode 100644
index 73f615b..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/queryFacets.xml
+++ /dev/null
@@ -1,94 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>int request</name>
- 		
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>perc(8,int(int_id))</expression>
- 			<name>perc_8</name>
- 		</statistic>
- 		
- 		<queryFacet>
- 			<name>float1</name>
- 			<query>float_fd:[* TO 50]</query>
- 		</queryFacet>
- 		<queryFacet>
- 			<name>float2</name>
- 			<query>float_fd:[* TO 30]</query>
- 		</queryFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>long request</name>
- 		
- 		<statistic>
- 			<expression>sum(long(long_ld))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(long(long_ld))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>median(long(long_ld))</expression>
- 			<name>median</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>perc(8,long(long_ld))</expression>
- 			<name>perc_8</name>
- 		</statistic>
- 		
- 		<queryFacet>
- 			<name>string</name>
- 			<query>string_sd:abc1</query>
- 			<query>string_sd:abc2</query>
- 		</queryFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>float request</name>
- 		
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>median</name>
- 		</statistic>
- 		
- 		<statistic>
- 			<expression>perc(8,float(float_fd))</expression>
- 			<name>perc_8</name>
- 		</statistic>
- 		
- 		<queryFacet>
- 			<name>long and double</name>
- 			<query>long_ld:[20 TO *]</query>
- 			<query>long_ld:[30 TO *]</query>
- 			<query>double_dd:[* TO 50]</query>
- 		</queryFacet>
- 	</analyticsRequest>
-</analyticsRequestEnvelope>
diff --git solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/rangeFacets.xml solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/rangeFacets.xml
deleted file mode 100644
index 3434d2e..0000000
--- solr/contrib/analytics/src/test-files/analytics/requestXMLFiles/rangeFacets.xml
+++ /dev/null
@@ -1,319 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<analyticsRequestEnvelope stats="true" olap="true">
- 	<analyticsRequest>
- 		<name>regular int</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(int(int_id))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="false">
- 			<field>long_ld</field>
- 			<start>5</start>
- 			<end>30</end>
- 			<gap>5</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>double_dd</field>
- 			<start>3</start>
- 			<end>39</end>
- 			<gap>7</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>date_dtd</field>
- 			<start>1007-01-01T23:59:59Z</start>
- 			<end>1044-01-01T23:59:59Z</end>
- 			<gap>+7YEARS</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>regular float</name>
- 		
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(float(float_fd))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(float(float_fd))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="false">
- 			<field>long_ld</field>
- 			<start>0</start>
- 			<end>29</end>
- 			<gap>4</gap>
- 			<includeBoundary>all</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>double_dd</field>
- 			<start>4</start>
- 			<end>47</end>
- 			<gap>11</gap>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>date_dtd</field>
- 			<start>1004-01-01T23:59:59Z</start>
- 			<end>1046-01-01T23:59:59Z</end>
- 			<gap>+5YEARS</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>hardend int</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(int(int_id))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="true">
- 			<field>long_ld</field>
- 			<start>5</start>
- 			<end>30</end>
- 			<gap>5</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="true">
- 			<field>double_dd</field>
- 			<start>3</start>
- 			<end>39</end>
- 			<gap>7</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="true">
- 			<field>date_dtd</field>
- 			<start>1007-01-01T23:59:59Z</start>
- 			<end>1044-01-01T23:59:59Z</end>
- 			<gap>+7YEARS</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>hardend float</name>
- 		
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(float(float_fd))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(float(float_fd))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="true">
- 			<field>long_ld</field>
- 			<start>0</start>
- 			<end>29</end>
- 			<gap>4</gap>
- 			<includeBoundary>all</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="true">
- 			<field>double_dd</field>
- 			<start>4</start>
- 			<end>47</end>
- 			<gap>11</gap>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="true">
- 			<field>date_dtd</field>
- 			<start>1004-01-01T23:59:59Z</start>
- 			<end>1046-01-01T23:59:59Z</end>
- 			<gap>+5YEARS</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>multigap int</name>
- 		
- 		<statistic>
- 			<expression>mean(int(int_id))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(int(int_id))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(int(int_id))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(int(int_id))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(int(int_id))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="false">
- 			<field>long_ld</field>
- 			<start>5</start>
- 			<end>30</end>
- 			<gap>4</gap>
- 			<gap>2</gap>
- 			<gap>6</gap>
- 			<gap>3</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>double_dd</field>
- 			<start>3</start>
- 			<end>39</end>
- 			<gap>3</gap>
- 			<gap>1</gap>
- 			<gap>7</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>date_dtd</field>
- 			<start>1007-01-01T23:59:59Z</start>
- 			<end>1044-01-01T23:59:59Z</end>
- 			<gap>+2YEARS</gap>
- 			<gap>+7YEARS</gap>
- 			<includeBoundary>lower</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<includeBoundary>outer</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
- 	<analyticsRequest>
- 		<name>multigap float</name>
- 		
- 		<statistic>
- 			<expression>mean(float(float_fd))</expression>
- 			<name>mean</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sum(float(float_fd))</expression>
- 			<name>sum</name>
- 		</statistic>
- 		<statistic>
- 			<expression>median(float(float_fd))</expression>
- 			<name>median</name>
- 		</statistic>
- 		<statistic>
- 			<expression>count(float(float_fd))</expression>
- 			<name>count</name>
- 		</statistic>
- 		<statistic>
- 			<expression>sumofsquares(float(float_fd))</expression>
- 			<name>sumOfSquares</name>
- 		</statistic>
- 		
- 		<rangeFacet hardend="false">
- 			<field>long_ld</field>
- 			<start>0</start>
- 			<end>29</end>
- 			<gap>1</gap>
- 			<gap>4</gap>
- 			<includeBoundary>all</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>double_dd</field>
- 			<start>4</start>
- 			<end>47</end>
- 			<gap>2</gap>
- 			<gap>3</gap>
- 			<gap>11</gap>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 		<rangeFacet hardend="false">
- 			<field>date_dtd</field>
- 			<start>1004-01-01T23:59:59Z</start>
- 			<end>1046-01-01T23:59:59Z</end>
- 			<gap>+4YEARS</gap>
- 			<gap>+5YEARS</gap>
- 			<includeBoundary>upper</includeBoundary>
- 			<includeBoundary>edge</includeBoundary>
- 			<otherRange>all</otherRange>
- 		</rangeFacet>
- 	</analyticsRequest>
-</analyticsRequestEnvelope>
diff --git solr/contrib/analytics/src/test-files/solr/collection1/conf/schema-analytics.xml solr/contrib/analytics/src/test-files/solr/collection1/conf/schema-analytics.xml
deleted file mode 100644
index 3c5713d..0000000
--- solr/contrib/analytics/src/test-files/solr/collection1/conf/schema-analytics.xml
+++ /dev/null
@@ -1,94 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- The Solr schema file. This file should be named "schema.xml" and
-     should be located where the classloader for the Solr webapp can find it.
-
-     This schema is used for testing, and as such has everything and the
-     kitchen sink thrown in. See example/solr/conf/schema.xml for a
-     more concise example.
-
-  -->
-
-<schema name="schema-docValues" version="1.5">
-  <types>
-
-    <!-- field type definitions... note that the "name" attribute is
-         just a label to be used by field definitions.  The "class"
-         attribute and any other attributes determine the real type and
-         behavior of the fieldtype.
-      -->
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't sort correctly or support range queries.)
-         These are provided more for backward compatability, allowing one
-         to create a schema that matches an existing lucene index.
-    -->
-    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="float" class="solr.TrieFloatField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="long" class="solr.TrieLongField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="double" class="solr.TrieDoubleField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
-         seconds part (.999) is optional.
-      -->
-    <fieldtype name="date" class="solr.TrieDateField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-
-    <fieldtype name="boolean" class="solr.BoolField" />
-    <fieldtype name="string" class="solr.StrField" />
-
-    <fieldType name="uuid" class="solr.UUIDField" />
-
-  </types>
-
-
-  <fields>
-
-    <field name="id" type="string" required="true" />
-
-    <field name="floatdv" type="float" indexed="false" stored="false" docValues="true" default="1" />
-    <field name="intdv" type="int" indexed="false" stored="false" docValues="true" default="2" />
-    <field name="doubledv" type="double" indexed="false" stored="false" docValues="true" default="3" />
-    <field name="longdv" type="long" indexed="false" stored="false" docValues="true" default="4" />
-    <field name="datedv" type="date" indexed="false" stored="false" docValues="true" default="1995-12-31T23:59:59.999Z" />
-
-    <field name="stringdv" type="string" indexed="false" stored="false" docValues="true" default="solr" />
-    <field name="stringdvm" type="string" indexed="false" stored="false" docValues="true" default="solr" multiValued="true" />
-    
-    <dynamicField name="*_i" type="int" indexed="true" stored="true" docValues="false" multiValued="false" />
-    <dynamicField name="*_id" type="int" indexed="true" stored="true" docValues="true" multiValued="false" />
-    <dynamicField name="*_idm" type="int" indexed="true" stored="true" docValues="true" multiValued="true" />
-    <dynamicField name="*_l" type="long" indexed="true" stored="true" docValues="false" multiValued="false" />
-    <dynamicField name="*_ld" type="long" indexed="true" stored="true" docValues="true" multiValued="false" />
-    <dynamicField name="*_ldm" type="long" indexed="true" stored="true" docValues="true" multiValued="true" />
-    <dynamicField name="*_f" type="float" indexed="true" stored="true" docValues="false" multiValued="false" />
-    <dynamicField name="*_fd" type="float" indexed="true" stored="true" docValues="true" multiValued="false" />
-    <dynamicField name="*_fdm" type="float" indexed="true" stored="true" docValues="true" multiValued="true" />
-    <dynamicField name="*_d" type="double" indexed="true" stored="true" docValues="false" multiValued="false" />
-    <dynamicField name="*_dd" type="double" indexed="true" stored="true" docValues="true" multiValued="false" />
-    <dynamicField name="*_ddm" type="double" indexed="true" stored="true" docValues="true" multiValued="true" />
-    <dynamicField name="*_dt" type="date" indexed="true" stored="true" docValues="false" multiValued="false" />
-    <dynamicField name="*_dtd" type="date" indexed="true" stored="true" docValues="true" multiValued="false" />
-    <dynamicField name="*_dtdm" type="date" indexed="true" stored="true" docValues="true" multiValued="true" />
-    <dynamicField name="*_s" type="string" indexed="true" stored="true" docValues="false" multiValued="false"/>
-    <dynamicField name="*_sd" type="string" indexed="true" stored="true" docValues="true" multiValued="false"/>
-    <dynamicField name="*_sdm" type="string" indexed="true" stored="true" docValues="true" multiValued="true" />
-  </fields>
-
-  <uniqueKey>id</uniqueKey>
-
-</schema>
diff --git solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig-basic.xml solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig-basic.xml
deleted file mode 100644
index 0d6d1d5..0000000
--- solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig-basic.xml
+++ /dev/null
@@ -1,41 +0,0 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LATEST}</luceneMatchVersion>
-  <dataDir>${solr.data.dir:}</dataDir>
-  <xi:include href="solrconfig.snippet.randomindexconfig.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
-  <directoryFactory name="DirectoryFactory" class="${solr.directoryFactory:solr.RAMDirectoryFactory}"/>
-
-  <requestHandler name="standard" class="solr.StandardRequestHandler">
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>analytics</str>
-      <str>highlight</str>
-      <str>debug</str>
-      <str>expand</str>
-    </arr>
-  </requestHandler>
-
-  <requestHandler name="/update" class="solr.UpdateRequestHandler" />
-
-  <searchComponent name="analytics" class="org.apache.solr.handler.component.AnalyticsComponent" />
-
-</config>
diff --git solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig.snippet.randomindexconfig.xml solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig.snippet.randomindexconfig.xml
deleted file mode 100644
index 055f3d7..0000000
--- solr/contrib/analytics/src/test-files/solr/collection1/conf/solrconfig.snippet.randomindexconfig.xml
+++ /dev/null
@@ -1,48 +0,0 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<!-- 
-
-A solrconfig.xml snippet containing indexConfig settings for randomized testing.
-
--->
-<indexConfig>
-  <!-- this sys property is not set by SolrTestCaseJ4 because we ideally want to use
-       the RandomMergePolicy in all tests - but some tests expect very specific
-       Merge behavior, so those tests can set it as needed.
-  -->
-  <mergePolicy class="${solr.tests.mergePolicy:org.apache.solr.util.RandomMergePolicy}" />
-  
-  <useCompoundFile>${useCompoundFile:false}</useCompoundFile>
-
-  <maxBufferedDocs>${solr.tests.maxBufferedDocs}</maxBufferedDocs>
-  <maxIndexingThreads>${solr.tests.maxIndexingThreads}</maxIndexingThreads>
-  <ramBufferSizeMB>${solr.tests.ramBufferSizeMB}</ramBufferSizeMB>
-
-  <mergeScheduler class="${solr.tests.mergeScheduler}" />
-  <nrtMode>${solr.tests.nrtMode:true}</nrtMode>
-
-  <writeLockTimeout>1000</writeLockTimeout>
-  <commitLockTimeout>10000</commitLockTimeout>
-
-  <!-- this sys property is not set by SolrTestCaseJ4 because almost all tests should
-       use the single process lockType for speed - but tests that explicitly need
-       to vary the lockType canset it as needed.
-  -->
-  <lockType>${solr.tests.lockType:single}</lockType>
-</indexConfig>
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java
deleted file mode 100644
index 2089a79..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java
+++ /dev/null
@@ -1,217 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics;
-
-import java.io.ByteArrayInputStream;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Scanner;
-
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
-import javax.xml.parsers.ParserConfigurationException;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-import org.apache.commons.lang.StringUtils;
-import org.apache.lucene.util.IOUtils;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.analytics.util.MedianCalculator;
-import org.apache.solr.analytics.util.PercentileCalculator;
-import org.apache.solr.request.SolrQueryRequest;
-import org.w3c.dom.Document;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import com.google.common.collect.ObjectArrays;
-
-public class AbstractAnalyticsStatsTest extends SolrTestCaseJ4 {
-  
-  protected static final String[] BASEPARMS = new String[]{ "q", "*:*", "indent", "true", "olap", "true", "rows", "0" };
-  protected static final HashMap<String,Object> defaults = new HashMap<>();
-
-  public static enum VAL_TYPE {
-    INTEGER("int"),
-    LONG("long"),
-    FLOAT("float"),
-    DOUBLE("double"),
-    STRING("str"),
-    DATE("date");
-
-    private VAL_TYPE (final String text) {
-      this.text = text;
-    }
-
-    private final String text;
-
-    @Override
-    public String toString() {
-      return text;
-    }
-  }
-
-  static private Document doc;
-  static private XPathFactory xPathFact =  XPathFactory.newInstance();
-
-  static private String rawResponse;
-
-  public static void setResponse(String response) throws ParserConfigurationException, IOException, SAXException {
-    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
-    factory.setNamespaceAware(true); // never forget this!
-    DocumentBuilder builder = factory.newDocumentBuilder();
-    doc = builder.parse(new InputSource(new ByteArrayInputStream(response.getBytes(StandardCharsets.UTF_8))));
-    xPathFact = XPathFactory.newInstance();
-    rawResponse = response;
-  }
-
-  protected String getRawResponse() {
-    return rawResponse;
-  }
-
-  public Object getStatResult(String section, String name, VAL_TYPE type) throws XPathExpressionException {
-
-    // Construct the XPath expression. The form better not change or all these will fail.
-    StringBuilder sb = new StringBuilder("/response/lst[@name='stats']/lst[@name='").append(section).append("']");
-
-    // This is a little fragile in that it demands the elements have the same name as type, i.e. when looking for a
-    // VAL_TYPE.DOUBLE, the element in question is <double name="blah">47.0</double>.
-    sb.append("/").append(type.toString()).append("[@name='").append(name).append("']");
-    String val = xPathFact.newXPath().compile(sb.toString()).evaluate(doc, XPathConstants.STRING).toString();
-    try {
-      switch (type) {
-        case INTEGER: return Integer.parseInt(val);
-        case DOUBLE:  return Double.parseDouble(val);
-        case FLOAT:   return Float.parseFloat(val);
-        case LONG:    return Long.parseLong(val);
-        case STRING:  assertTrue(rawResponse, val != null && val.length() > 0 ); return val;
-        case DATE:    assertTrue(rawResponse, val != null && val.length() > 0 ); return val;
-      }
-    } catch (Exception e) {
-      e.printStackTrace();
-      fail("Caught exception in getStatResult, xPath = " + sb.toString() + " \nraw data: " + rawResponse);
-    }
-    fail("Unknown type used in getStatResult");
-    return null; // Really can't get here, but the compiler thinks we can!
-  }
-
-
-  public <T extends Number & Comparable<T>> Double calculateNumberStat(ArrayList<T> list, String stat) {
-    Double result;
-    if (stat.equals("median")) {
-      result = MedianCalculator.getMedian(list);
-    } else if (stat.equals("mean")) {
-      double d = 0;
-      for (T element : list) {
-        d += element.doubleValue();
-      }
-      result = Double.valueOf(d/list.size());
-    } else if (stat.equals("sum")) {
-      double d = 0;
-      for (T element : list) {
-        d += element.doubleValue();
-      }
-      result = Double.valueOf(d);
-    } else if (stat.equals("sumOfSquares")) {
-      double d = 0;
-      for (T element : list) {
-        d += element.doubleValue()*element.doubleValue();
-      }
-      result = Double.valueOf(d);
-    } else if (stat.equals("stddev")) {
-      double sum = 0;
-      double sumSquares = 0;
-      for (T element : list) {
-        sum += element.doubleValue();
-        sumSquares += element.doubleValue()*element.doubleValue();
-      }
-      result = Math.sqrt(sumSquares/list.size()-sum*sum/(list.size()*list.size()));
-    } else {
-      throw new IllegalArgumentException();
-    }
-    return result;
-  }
-
-  public <T extends Comparable<T>> Object calculateStat(ArrayList<T> list, String stat) {
-    Object result;
-    if (stat.contains("perc_")) {
-      double[] perc = new double[]{Double.parseDouble(stat.substring(5))/100};
-      result = PercentileCalculator.getPercentiles(list, perc).get(0);
-    } else if (stat.equals("count")) {
-      result = Long.valueOf(list.size());
-    } else if (stat.equals("unique")) {
-      HashSet<T> set = new HashSet<>();
-      set.addAll(list);
-      result = Long.valueOf((long)set.size());
-    } else if (stat.equals("max")) {
-      Collections.sort(list);
-      result = list.get(list.size()-1);
-    } else if (stat.equals("min")) {
-      Collections.sort(list);
-      result = list.get(0);
-    } else {
-      result = null;
-    }
-    return result;
-  }
-
-  @SuppressWarnings("unchecked")
-  public <T extends Comparable<T>> Long calculateMissing(ArrayList<T> list, String type) {
-    T def = (T)defaults.get(type);
-    long miss = 0;
-    for (T element : list) {
-      if (element.compareTo(def)==0) {
-        miss++;
-      }
-    }
-    return Long.valueOf(miss);
-  }
-  
-  public static SolrQueryRequest request(String...args){
-    return SolrTestCaseJ4.req( ObjectArrays.concat(BASEPARMS, args,String.class) );
-  }
-
-  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
-    InputStream in = clazz.getResourceAsStream(fileName);
-    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
-    Scanner file = new Scanner(in, "UTF-8");
-    try { 
-      ArrayList<String> strList = new ArrayList<>();
-      while (file.hasNextLine()) {
-        String line = file.nextLine();
-        line = line.trim();
-        if( StringUtils.isBlank(line) || line.startsWith("#")){
-          continue;
-        }
-        String[] param = line.split("=");
-        strList.add(param[0]);
-        strList.add(param[1]);
-      }
-      return strList.toArray(new String[0]);
-    } finally {
-      IOUtils.closeWhileHandlingException(file, in);
-    }
-  }
-  
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/NoFacetTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/NoFacetTest.java
deleted file mode 100644
index f217150..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/NoFacetTest.java
+++ /dev/null
@@ -1,480 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics;
-
-
-import java.util.ArrayList;
-import java.util.List;
-
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class NoFacetTest extends AbstractAnalyticsStatsTest {
-  static String fileName = "/analytics/requestFiles/noFacets.txt";
-
-  static public final int INT = 71;
-  static public final int LONG = 36;
-  static public final int FLOAT = 93;
-  static public final int DOUBLE = 49;
-  static public final int DATE = 12;
-  static public final int STRING = 28;
-  static public final int NUM_LOOPS = 100;
-  
-  //INT
-  static ArrayList<Integer> intTestStart; 
-  static long intMissing = 0;
-  
-  //LONG
-  static ArrayList<Long> longTestStart; 
-  static long longMissing = 0;
-  
-  //FLOAT
-  static ArrayList<Float> floatTestStart; 
-  static long floatMissing = 0;
-  
-  //DOUBLE
-  static ArrayList<Double> doubleTestStart; 
-  static long doubleMissing = 0;
-  
-  //DATE
-  static ArrayList<String> dateTestStart; 
-  static long dateMissing = 0;
-  
-  //STR
-  static ArrayList<String> stringTestStart; 
-  static long stringMissing = 0;
-  
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-    defaults.put("int_id", new Integer(0));
-    defaults.put("long_ld", new Long(0));
-    defaults.put("float_fd", new Float(0));
-    defaults.put("double_dd", new Double(0));
-    defaults.put("date_dtd", "1800-12-31T23:59:59Z");
-    defaults.put("string_sd", "str0");
-    
-    intTestStart = new ArrayList<>();
-    longTestStart = new ArrayList<>();
-    floatTestStart = new ArrayList<>();
-    doubleTestStart = new ArrayList<>();
-    dateTestStart = new ArrayList<>();
-    stringTestStart = new ArrayList<>();
-    
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT;
-      long l = j%LONG;
-      float f = j%FLOAT;
-      double d = j%DOUBLE;
-      String dt = (1800+j%DATE) + "-12-31T23:59:59Z";
-      String s = "str" + (j%STRING);
-      List<String> fields = new ArrayList<>();
-      fields.add("id"); fields.add("1000"+j);
-      
-      if( i != 0 ){
-        fields.add("int_id"); fields.add("" + i);
-        intTestStart.add(i);
-      } else intMissing++;
-      
-      if( l != 0l ){
-        fields.add("long_ld"); fields.add("" + l);
-        longTestStart.add(l);
-      } else longMissing++;
-      
-      if( f != 0.0f ){
-        fields.add("float_fd"); fields.add("" + f);
-        floatTestStart.add(f);
-      } else floatMissing++;
-      
-      if( d != 0.0d ){
-        fields.add("double_dd"); fields.add("" + d);
-        doubleTestStart.add(d);
-      } else doubleMissing++;
-      
-      if( (j%DATE) != 0 ){
-        fields.add("date_dtd"); fields.add(dt);
-        dateTestStart.add(dt);
-      } else dateMissing++;
-      
-      if( (j%STRING) != 0 ){
-        fields.add("string_sd"); fields.add(s);
-        stringTestStart.add(s);
-      } else stringMissing++;
-      
-      fields.add("int_i"); fields.add("" + i);
-      fields.add("long_l"); fields.add("" + l);
-      fields.add("float_f"); fields.add("" + f);
-      fields.add("double_d"); fields.add("" + d);
-      
-      assertU(adoc(fields.toArray(new String[0])));
-      
-      
-      if (usually()) {
-        assertU(commit());  // to have several segments
-      }
-    }
-    
-    assertU(commit()); 
-    
-    //Sort ascending tests
-    setResponse(h.query(request(fileToStringArr(NoFacetTest.class, fileName))));
-  }
-      
-  @Test
-  public void sumTest() throws Exception {
-    //Int
-    Double intResult = (Double)getStatResult("sr", "int_id", VAL_TYPE.DOUBLE);
-    Double intTest = (Double)calculateNumberStat(intTestStart, "sum");
-    assertEquals(getRawResponse(), intResult,intTest);
-    
-    //Long
-    Double longResult = (Double)getStatResult("sr", "long_ld", VAL_TYPE.DOUBLE);
-    Double longTest = (Double)calculateNumberStat(longTestStart, "sum");
-    assertEquals(getRawResponse(), longResult,longTest);
-    
-    //Float
-    Double floatResult = (Double)getStatResult("sr", "float_fd", VAL_TYPE.DOUBLE);
-    Double floatTest = (Double)calculateNumberStat(floatTestStart, "sum");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-    
-    //Double
-    Double doubleResult = (Double)getStatResult("sr", "double_dd", VAL_TYPE.DOUBLE);
-        Double doubleTest = (Double) calculateNumberStat(doubleTestStart, "sum");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-  }
-  
-  @Test
-  public void sumOfSquaresTest() throws Exception { 
-    //Int
-    Double intResult = (Double)getStatResult("sosr", "int_id", VAL_TYPE.DOUBLE);
-    Double intTest = (Double)calculateNumberStat(intTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(), intResult,intTest);
-    
-    //Long
-    Double longResult = (Double)getStatResult("sosr", "long_ld", VAL_TYPE.DOUBLE);
-    Double longTest = (Double)calculateNumberStat(longTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(), longResult,longTest);
-    
-    //Float
-    Double floatResult = (Double)getStatResult("sosr", "float_fd", VAL_TYPE.DOUBLE);
-    Double floatTest = (Double)calculateNumberStat(floatTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-    
-    //Double
-    Double doubleResult = (Double)getStatResult("sosr", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-  }
-  
-  @Test
-  public void meanTest() throws Exception { 
-    //Int
-    Double intResult = (Double)getStatResult("mr", "int_id", VAL_TYPE.DOUBLE);
-    Double intTest = (Double)calculateNumberStat(intTestStart, "mean");
-    assertEquals(getRawResponse(), intResult,intTest);
-    
-    //Long
-    Double longResult = (Double)getStatResult("mr", "long_ld", VAL_TYPE.DOUBLE);
-    Double longTest = (Double)calculateNumberStat(longTestStart, "mean");
-    assertEquals(getRawResponse(), longResult,longTest);
-    
-    //Float
-    Double floatResult = (Double)getStatResult("mr", "float_fd", VAL_TYPE.DOUBLE);
-    Double floatTest = (Double)calculateNumberStat(floatTestStart, "mean");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-    
-    //Double
-    Double doubleResult = (Double)getStatResult("mr", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "mean");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-  }
-  
-  @Test
-  public void stddevTest() throws Exception { 
-    //Int
-    Double intResult = (Double)getStatResult("str", "int_id", VAL_TYPE.DOUBLE);
-    Double intTest = (Double)calculateNumberStat(intTestStart, "stddev");
-    assertEquals(getRawResponse(), intResult, intTest, 0.00000000001);
-    
-    //Long
-    Double longResult = (Double)getStatResult("str", "long_ld", VAL_TYPE.DOUBLE);
-    Double longTest = (Double)calculateNumberStat(longTestStart, "stddev");
-    assertEquals(getRawResponse(), longResult, longTest, 0.00000000001);
-    
-    //Float
-    Double floatResult = (Double)getStatResult("str", "float_fd", VAL_TYPE.DOUBLE);
-    Double floatTest = (Double)calculateNumberStat(floatTestStart, "stddev");
-    assertEquals(getRawResponse(), floatResult, floatTest, 0.00000000001);
-
-
-    //Double
-    Double doubleResult = (Double)getStatResult("str", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "stddev");
-    assertEquals(getRawResponse(), doubleResult, doubleTest, 0.00000000001);
-  }
-  
-  @Test
-  public void medianTest() throws Exception { 
-    //Int
-    Double intResult = (Double)getStatResult("medr", "int_id", VAL_TYPE.DOUBLE);
-    Double intTest = (Double)calculateNumberStat(intTestStart, "median");
-    assertEquals(getRawResponse(), intResult,intTest);
-    
-    //Long
-    Double longResult = (Double)getStatResult("medr", "long_ld", VAL_TYPE.DOUBLE);
-    Double longTest = (Double)calculateNumberStat(longTestStart, "median");
-    assertEquals(getRawResponse(), longResult,longTest);
-    
-    //Float
-    Double floatResult = (Double)getStatResult("medr", "float_fd", VAL_TYPE.DOUBLE);
-    Double floatTest = (Double)calculateNumberStat(floatTestStart, "median");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-    
-    //Double
-    Double doubleResult = (Double)getStatResult("medr", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "median");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-  }
-  
-  @Test
-  public void perc20Test() throws Exception {
-    //Int 20
-    Integer intResult = (Integer)getStatResult("p2r", "int_id", VAL_TYPE.INTEGER);
-    Integer intTest = (Integer)calculateStat(intTestStart, "perc_20");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long 20
-    Long longResult = (Long)getStatResult("p2r", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "perc_20");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float 20
-    Float floatResult = (Float)getStatResult("p2r", "float_fd", VAL_TYPE.FLOAT);
-    Float floatTest = (Float)calculateStat(floatTestStart, "perc_20");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double 20
-    Double doubleResult = (Double)getStatResult("p2r", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateStat(doubleTestStart, "perc_20");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date 20
-    String dateResult = (String)getStatResult("p2r", "date_dtd", VAL_TYPE.DATE);
-    String dateTest = (String)calculateStat(dateTestStart, "perc_20");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String 20
-    String stringResult = (String)getStatResult("p2r", "string_sd", VAL_TYPE.STRING);
-    String stringTest = (String)calculateStat(stringTestStart, "perc_20");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }
-  
-  @Test
-  public void perc60Test() throws Exception { 
-    //Int 60
-    Integer intResult = (Integer)getStatResult("p6r", "int_id", VAL_TYPE.INTEGER);
-    Integer intTest = (Integer)calculateStat(intTestStart, "perc_60");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long 60
-    Long longResult = (Long)getStatResult("p6r", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "perc_60");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float 60
-    Float floatResult = (Float)getStatResult("p6r", "float_fd", VAL_TYPE.FLOAT);
-    Float floatTest = (Float)calculateStat(floatTestStart, "perc_60");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double 60
-    Double doubleResult = (Double)getStatResult("p6r", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateStat(doubleTestStart, "perc_60");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date 60
-    String dateResult = (String)getStatResult("p6r", "date_dtd", VAL_TYPE.DATE);
-    String dateTest = (String)calculateStat(dateTestStart, "perc_60");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String 60
-    String stringResult = (String)getStatResult("p6r", "string_sd", VAL_TYPE.STRING);
-    String stringTest = (String)calculateStat(stringTestStart, "perc_60");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }
-  
-  @Test
-  public void minTest() throws Exception { 
-    //Int
-    Integer intResult = (Integer)getStatResult("mir", "int_id", VAL_TYPE.INTEGER);
-    Integer intTest = (Integer)calculateStat(intTestStart, "min");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long
-    Long longResult = (Long)getStatResult("mir", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "min");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float
-    Float floatResult = (Float)getStatResult("mir", "float_fd", VAL_TYPE.FLOAT);
-    Float floatTest = (Float)calculateStat(floatTestStart, "min");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double
-    Double doubleResult = (Double)getStatResult("mir", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateStat(doubleTestStart, "min");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date
-    String dateResult = (String)getStatResult("mir", "date_dtd", VAL_TYPE.DATE);
-    String dateTest = (String)calculateStat(dateTestStart, "min");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String
-    String stringResult = (String)getStatResult("mir", "string_sd", VAL_TYPE.STRING);
-    String stringTest = (String)calculateStat(stringTestStart, "min");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }
-  
-  @Test
-  public void maxTest() throws Exception { 
-    //Int
-    Integer intResult = (Integer)getStatResult("mar", "int_id", VAL_TYPE.INTEGER);
-    Integer intTest = (Integer)calculateStat(intTestStart, "max");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long
-    Long longResult = (Long)getStatResult("mar", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "max");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float
-    Float floatResult = (Float)getStatResult("mar", "float_fd", VAL_TYPE.FLOAT);
-    Float floatTest = (Float)calculateStat(floatTestStart, "max");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double
-    Double doubleResult = (Double)getStatResult("mar", "double_dd", VAL_TYPE.DOUBLE);
-    Double doubleTest = (Double)calculateStat(doubleTestStart, "max");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date
-    String dateResult = (String)getStatResult("mar", "date_dtd", VAL_TYPE.DATE);
-    String dateTest = (String)calculateStat(dateTestStart, "max");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String
-    String stringResult = (String)getStatResult("mar", "string_sd", VAL_TYPE.STRING);
-    String stringTest = (String)calculateStat(stringTestStart, "max");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }
-  
-  @Test
-  public void uniqueTest() throws Exception { 
-    //Int
-    Long intResult = (Long)getStatResult("ur", "int_id", VAL_TYPE.LONG);
-    Long intTest = (Long)calculateStat(intTestStart, "unique");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long
-    Long longResult = (Long)getStatResult("ur", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "unique");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float
-    Long floatResult = (Long)getStatResult("ur", "float_fd", VAL_TYPE.LONG);
-    Long floatTest = (Long)calculateStat(floatTestStart, "unique");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double
-    Long doubleResult = (Long)getStatResult("ur", "double_dd", VAL_TYPE.LONG);
-    Long doubleTest = (Long)calculateStat(doubleTestStart, "unique");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date
-    Long dateResult = (Long)getStatResult("ur", "date_dtd", VAL_TYPE.LONG);
-    Long dateTest = (Long)calculateStat(dateTestStart, "unique");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String
-    Long stringResult = (Long)getStatResult("ur", "string_sd", VAL_TYPE.LONG);
-    Long stringTest = (Long)calculateStat(stringTestStart, "unique");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }
-  
-  @Test
-  public void countTest() throws Exception { 
-    //Int
-    Long intResult = (Long)getStatResult("cr", "int_id", VAL_TYPE.LONG);
-    Long intTest = (Long)calculateStat(intTestStart, "count");
-    assertEquals(getRawResponse(), intResult,intTest);
-
-    //Long
-    Long longResult = (Long)getStatResult("cr", "long_ld", VAL_TYPE.LONG);
-    Long longTest = (Long)calculateStat(longTestStart, "count");
-    assertEquals(getRawResponse(), longResult,longTest);
-
-    //Float
-    Long floatResult = (Long)getStatResult("cr", "float_fd", VAL_TYPE.LONG);
-    Long floatTest = (Long)calculateStat(floatTestStart, "count");
-    assertEquals(getRawResponse(), floatResult,floatTest);
-
-    //Double
-    Long doubleResult = (Long)getStatResult("cr", "double_dd", VAL_TYPE.LONG);
-    Long doubleTest = (Long)calculateStat(doubleTestStart, "count");
-    assertEquals(getRawResponse(), doubleResult,doubleTest);
-
-    //Date
-    Long dateResult = (Long)getStatResult("cr", "date_dtd", VAL_TYPE.LONG);
-    Long dateTest = (Long)calculateStat(dateTestStart, "count");
-    assertEquals(getRawResponse(), dateResult,dateTest);
-
-    //String
-    Long stringResult = (Long)getStatResult("cr", "string_sd", VAL_TYPE.LONG);
-    Long stringTest = (Long)calculateStat(stringTestStart, "count");
-    assertEquals(getRawResponse(), stringResult,stringTest);
-  }  
-    
-  @Test
-  public void missingDefaultTest() throws Exception { 
-    //Int
-    long intResult = (Long)getStatResult("misr", "int_id", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), intMissing,intResult);
-
-    //Long
-    long longResult = (Long)getStatResult("misr", "long_ld", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), longMissing,longResult);
-
-    //Float
-    long floatResult = (Long)getStatResult("misr", "float_fd", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), floatMissing,floatResult);
-
-    //Double
-    long doubleResult = (Long)getStatResult("misr", "double_dd", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), doubleMissing,doubleResult);
-
-    //Date
-    long dateResult = (Long)getStatResult("misr", "date_dtd", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), dateMissing,dateResult);
-
-    //String
-    long stringResult = (Long)getStatResult("misr", "string_sd", VAL_TYPE.LONG);
-    assertEquals(getRawResponse(), stringMissing, stringResult);
-  }
-
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/expression/ExpressionTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/expression/ExpressionTest.java
deleted file mode 100644
index 5cf8be1..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/expression/ExpressionTest.java
+++ /dev/null
@@ -1,251 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.expression;
-
-import com.google.common.collect.ObjectArrays;
-
-import org.apache.lucene.util.IOUtils;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.analytics.AbstractAnalyticsStatsTest;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.schema.TrieDateField;
-import org.apache.solr.util.DateMathParser;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.FileNotFoundException;
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.Scanner;
-
-public class ExpressionTest extends AbstractAnalyticsStatsTest {
-  private static final String fileName = "/analytics/requestFiles/expressions.txt";
-
-  private static final String[] BASEPARMS = new String[]{"q", "*:*", "indent", "true", "stats", "true", "olap", "true", "rows", "0"};
-
-  private static final int INT = 71;
-  private static final int LONG = 36;
-  private static final int FLOAT = 93;
-  private static final int DOUBLE = 49;
-  private static final int DATE = 12;
-  private static final int STRING = 28;
-  private static final int NUM_LOOPS = 100;
-
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml", "schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j % INT;
-      long l = j % LONG;
-      float f = j % FLOAT;
-      double d = j % DOUBLE;
-      String dt = (1800 + j % DATE) + "-12-31T23:59:59Z";
-      String s = "str" + (j % STRING);
-      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f,
-          "double_dd", "" + d, "date_dtd", dt, "string_sd", s));
-
-      if (usually()) {
-        assertU(commit()); // to have several segments
-      }
-    }
-
-    assertU(commit());
-
-    setResponse(h.query(request(fileToStringArr(ExpressionTest.class, fileName))));
-  }
-
-  @Test
-  public void addTest() throws Exception {
-    double sumResult = (Double) getStatResult("ar", "sum", VAL_TYPE.DOUBLE);
-    double uniqueResult = ((Long) getStatResult("ar", "unique", VAL_TYPE.LONG)).doubleValue();
-    double result = (Double) getStatResult("ar", "su", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), sumResult + uniqueResult, result, 0.0);
-
-    double meanResult = (Double) getStatResult("ar", "mean", VAL_TYPE.DOUBLE);
-    double medianResult = (Double) getStatResult("ar", "median", VAL_TYPE.DOUBLE);
-    double countResult = ((Long) getStatResult("ar", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("ar", "mcm", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), meanResult + countResult + medianResult, result, 0.0);
-  }
-
-  @Test
-  public void multiplyTest() throws Exception {
-    double sumResult = (Double) getStatResult("mr", "sum", VAL_TYPE.DOUBLE);
-    double uniqueResult = ((Long) getStatResult("mr", "unique", VAL_TYPE.LONG)).doubleValue();
-    double result = (Double) getStatResult("mr", "su", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), sumResult * uniqueResult, result, 0.0);
-
-    double meanResult = (Double) getStatResult("mr", "mean", VAL_TYPE.DOUBLE);
-    double medianResult = (Double) getStatResult("mr", "median", VAL_TYPE.DOUBLE);
-    double countResult = ((Long) getStatResult("mr", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("mr", "mcm", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), meanResult * countResult * medianResult, result, 0.0);
-  }
-
-  @Test
-  public void divideTest() throws Exception {
-    double sumResult = (Double) getStatResult("dr", "sum", VAL_TYPE.DOUBLE);
-    double uniqueResult = ((Long) getStatResult("dr", "unique", VAL_TYPE.LONG)).doubleValue();
-    double result = (Double) getStatResult("dr", "su", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), sumResult / uniqueResult, result, 0.0);
-
-    double meanResult = (Double) getStatResult("dr", "mean", VAL_TYPE.DOUBLE);
-    double countResult = ((Long) getStatResult("dr", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("dr", "mc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), meanResult / countResult, result, 0.0);
-  }
-
-  @Test
-  public void powerTest() throws Exception {
-    double sumResult = (Double) getStatResult("pr", "sum", VAL_TYPE.DOUBLE);
-    double uniqueResult = ((Long) getStatResult("pr", "unique", VAL_TYPE.LONG)).doubleValue();
-    double result = (Double) getStatResult("pr", "su", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), Math.pow(sumResult, uniqueResult), result, 0.0);
-
-    double meanResult = (Double) getStatResult("pr", "mean", VAL_TYPE.DOUBLE);
-    double countResult = ((Long) getStatResult("pr", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("pr", "mc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), Math.pow(meanResult, countResult), result, 0.0);
-  }
-
-  @Test
-  public void negateTest() throws Exception {
-    double sumResult = (Double) getStatResult("nr", "sum", VAL_TYPE.DOUBLE);
-    double result = (Double) getStatResult("nr", "s", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), -1 * sumResult, result, 0.0);
-
-    double countResult = ((Long) getStatResult("nr", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("nr", "c", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), -1 * countResult, result, 0.0);
-  }
-
-  @Test
-  public void absoluteValueTest() throws Exception {
-    double sumResult = (Double) getStatResult("avr", "sum", VAL_TYPE.DOUBLE);
-    double result = (Double) getStatResult("avr", "s", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), sumResult, result, 0.0);
-
-    double countResult = ((Long) getStatResult("avr", "count", VAL_TYPE.LONG)).doubleValue();
-    result = (Double) getStatResult("avr", "c", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), countResult, result, 0.0);
-  }
-
-  @Test
-  public void constantNumberTest() throws Exception {
-    double result = (Double) getStatResult("cnr", "c8", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), 8, result, 0.0);
-
-    result = (Double) getStatResult("cnr", "c10", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), 10, result, 0.0);
-  }
-
-  @SuppressWarnings("deprecation")
-  @Test
-  public void dateMathTest() throws Exception {
-    String math = (String) getStatResult("dmr", "cme", VAL_TYPE.STRING);
-    DateMathParser date = new DateMathParser();
-    date.setNow(TrieDateField.parseDate((String) getStatResult("dmr", "median", VAL_TYPE.DATE)));
-    String dateMath = (String) getStatResult("dmr", "dmme", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), TrieDateField.parseDate(dateMath), date.parseMath(math));
-
-    math = (String) getStatResult("dmr", "cma", VAL_TYPE.STRING);
-    date = new DateMathParser();
-    date.setNow(TrieDateField.parseDate((String) getStatResult("dmr", "max", VAL_TYPE.DATE)));
-    dateMath = (String) getStatResult("dmr", "dmma", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), TrieDateField.parseDate(dateMath), date.parseMath(math));
-  }
-
-  @Test
-  public void constantDateTest() throws Exception {
-    String date = (String) getStatResult("cdr", "cd1", VAL_TYPE.DATE);
-    String str = (String) getStatResult("cdr", "cs1", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), date, str);
-
-    date = (String) getStatResult("cdr", "cd2", VAL_TYPE.DATE);
-    str = (String) getStatResult("cdr", "cs2", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), date, str);
-  }
-
-  @Test
-  public void constantStringTest() throws Exception {
-    String str = (String) getStatResult("csr", "cs1", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), str, "this is the first");
-
-    str = (String) getStatResult("csr", "cs2", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), str, "this is the second");
-
-    str = (String) getStatResult("csr", "cs3", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), str, "this is the third");
-  }
-
-  @Test
-  public void concatenateTest() throws Exception {
-    StringBuilder builder = new StringBuilder();
-    builder.append((String) getStatResult("cr", "csmin", VAL_TYPE.STRING));
-    builder.append((String) getStatResult("cr", "min", VAL_TYPE.STRING));
-    String concat = (String) getStatResult("cr", "ccmin", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), concat, builder.toString());
-
-    builder.setLength(0);
-    builder.append((String) getStatResult("cr", "csmax", VAL_TYPE.STRING));
-    builder.append((String) getStatResult("cr", "max", VAL_TYPE.STRING));
-    concat = (String) getStatResult("cr", "ccmax", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), concat, builder.toString());
-  }
-
-  @Test
-  public void reverseTest() throws Exception {
-    StringBuilder builder = new StringBuilder();
-    builder.append((String) getStatResult("rr", "min", VAL_TYPE.STRING));
-    String rev = (String) getStatResult("rr", "rmin", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), rev, builder.reverse().toString());
-
-    builder.setLength(0);
-    builder.append((String) getStatResult("rr", "max", VAL_TYPE.STRING));
-    rev = (String) getStatResult("rr", "rmax", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), rev, builder.reverse().toString());
-  }
-
-  public static SolrQueryRequest request(String... args) {
-    return SolrTestCaseJ4.req(ObjectArrays.concat(BASEPARMS, args, String.class));
-  }
-
-  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
-    InputStream in = clazz.getResourceAsStream(fileName);
-    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
-    Scanner file = new Scanner(in, "UTF-8");
-    try { 
-      ArrayList<String> strList = new ArrayList<>();
-      while (file.hasNextLine()) {
-        String line = file.nextLine();
-        if (line.length()<2) {
-          continue;
-        }
-        String[] param = line.split("=");
-        strList.add(param[0]);
-        strList.add(param[1]);
-      }
-      return strList.toArray(new String[0]);
-    } finally {
-      IOUtils.closeWhileHandlingException(file, in);
-    }
-  }
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java
deleted file mode 100644
index 3d3ca3f..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java
+++ /dev/null
@@ -1,302 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.facet;
-
-import java.io.ByteArrayInputStream;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Scanner;
-
-import org.apache.lucene.util.IOUtils;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.analytics.util.MedianCalculator;
-import org.apache.solr.analytics.util.PercentileCalculator;
-import org.apache.solr.request.SolrQueryRequest;
-
-import com.google.common.collect.ObjectArrays;
-
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
-import javax.xml.parsers.ParserConfigurationException;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-public class AbstractAnalyticsFacetTest extends SolrTestCaseJ4 {
-  protected static final HashMap<String,Object> defaults = new HashMap<>();
-  
-  protected String latestType = "";
-
-  private static Document doc;
-  private static XPathFactory xPathFact =  XPathFactory.newInstance();
-  private static String rawResponse;
-
-  protected static void setResponse(String response) throws ParserConfigurationException, IOException, SAXException {
-    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
-    factory.setNamespaceAware(true); // never forget this!
-    DocumentBuilder builder = factory.newDocumentBuilder();
-    doc = builder.parse(new InputSource(new ByteArrayInputStream(response.getBytes(StandardCharsets.UTF_8))));
-    xPathFact = XPathFactory.newInstance();
-    rawResponse = response;
-  }
-
-  protected String getRawResponse() {
-    return rawResponse;
-  }
-
-  protected Node getNode(String xPath) throws XPathExpressionException {
-    return (Node)xPathFact.newXPath().compile(xPath).evaluate(doc, XPathConstants.NODE);
-  }
-  private NodeList getNodes(String n1, String n2, String n3, String element, String n4) throws XPathExpressionException {
-    // Construct the XPath expression. The form better not change or all these will fail.
-    StringBuilder sb = new StringBuilder("/response/lst[@name='stats']/lst[@name='").append(n1).append("']");
-    sb.append("/lst[@name='").append(n2).append("']");
-    sb.append("/lst[@name='").append(n3).append("']");
-    sb.append("//").append(element).append("[@name='").append(n4).append("']");
-    return (NodeList)xPathFact.newXPath().compile(sb.toString()).evaluate(doc, XPathConstants.NODESET);
-
-  }
-  protected ArrayList<String> getStringList(String n1, String n2, String n3, String element, String n4)
-      throws XPathExpressionException {
-    ArrayList<String> ret = new ArrayList<>();
-    NodeList nodes = getNodes(n1, n2, n3, element, n4);
-    for (int idx = 0; idx < nodes.getLength(); ++idx) {
-      ret.add(nodes.item(idx).getTextContent());
-    }
-    return ret;
-  }
-
-  protected ArrayList<Integer> getIntegerList(String n1, String n2, String n3, String element, String n4)
-      throws XPathExpressionException {
-    ArrayList<Integer> ret = new ArrayList<>();
-    NodeList nodes = getNodes(n1, n2, n3, element, n4);
-    for (int idx = 0; idx < nodes.getLength(); ++idx) {
-      ret.add(Integer.parseInt(nodes.item(idx).getTextContent()));
-    }
-    return ret;
-  }
-  protected ArrayList<Long> getLongList(String n1, String n2, String n3, String element, String n4)
-      throws XPathExpressionException {
-    ArrayList<Long> ret = new ArrayList<>();
-    NodeList nodes = getNodes(n1, n2, n3, element, n4);
-    for (int idx = 0; idx < nodes.getLength(); ++idx) {
-      ret.add(Long.parseLong(nodes.item(idx).getTextContent()));
-    }
-    return ret;
-  }
-  protected ArrayList<Float> getFloatList(String n1, String n2, String n3, String element, String n4)
-      throws XPathExpressionException {
-    ArrayList<Float> ret = new ArrayList<>();
-    NodeList nodes = getNodes(n1, n2, n3, element, n4);
-    for (int idx = 0; idx < nodes.getLength(); ++idx) {
-      ret.add(Float.parseFloat(nodes.item(idx).getTextContent()));
-    }
-    return ret;
-  }
-
-  protected ArrayList<Double> getDoubleList(String n1, String n2, String n3, String element, String n4)
-      throws XPathExpressionException {
-    ArrayList<Double> ret = new ArrayList<>();
-    NodeList nodes = getNodes(n1, n2, n3, element, n4);
-    for (int idx = 0; idx < nodes.getLength(); ++idx) {
-      ret.add(Double.parseDouble(nodes.item(idx).getTextContent()));
-    }
-    return ret;
-  }
-
-
-  public static void increment(List<Long> list, int idx){
-    Long i = list.remove(idx);
-    list.add(idx, i+1);
-  }
-  
-  public static String[] filter(String...args){
-    List<String> l = new ArrayList<>();
-    for( int i=0; i <args.length; i+=2){
-      if( args[i+1].equals("0") || args[i+1].equals("0.0") || 
-          args[i+1].equals("1800-12-31T23:59:59Z") || args[i+1].equals("str0") ||
-          args[i+1].equals("this is the firststr0") || 
-          args[i+1].equals("this is the secondstr0") ){
-        continue;
-      }
-      l.add(args[i]);
-      l.add(args[i+1]);
-    }
-    return l.toArray(new String[0]);
-  }
-  
-  protected void setLatestType(String latestType) {
-    this.latestType = latestType;
-  }
-
-  @SuppressWarnings({ "unchecked", "rawtypes" })
-  public <T extends Number & Comparable<T>> ArrayList calculateNumberStat(ArrayList<ArrayList<T>> lists, String stat) {
-    ArrayList result;
-    if (stat.equals("median")) {
-      result = new ArrayList<Double>();
-      for (List<T> list : lists) {
-        result.add(MedianCalculator.getMedian(list));
-      }
-    } else if (stat.equals("mean")) {
-      result = new ArrayList<Double>();
-      for (List<T> list : lists) {
-        double d = 0;
-        for (T element : list) {
-          d += element.doubleValue();
-        }
-        result.add(d/list.size());
-      }
-    } else if (stat.equals("sum")) {
-      result = new ArrayList<Double>();
-      for (Collection<T> list : lists) {
-        double d = 0;
-        for (T element : list) {
-          d += element.doubleValue();
-        }
-        result.add(d);
-      }
-    } else if (stat.equals("sumOfSquares")) {
-      result = new ArrayList<Double>();
-      for (List<T> list : lists) {
-        double d = 0;
-        for (T element : list) {
-          d += element.doubleValue()*element.doubleValue();
-        }
-        result.add(d);
-      }
-    } else if (stat.equals("stddev")) {
-      result = new ArrayList<Double>();
-      for (List<T> list : lists) {
-        double sum = 0;
-        double sumSquares = 0;
-        for (T element : list) {
-          sum += element.doubleValue();
-          sumSquares += element.doubleValue()*element.doubleValue();
-        }
-        String res = Double.toString(Math.sqrt(sumSquares/list.size()-sum*sum/(list.size()*list.size())));
-        result.add(Double.parseDouble(res));
-      }
-    } else {
-      throw new IllegalArgumentException();
-    }
-    return result;
-  }
-
-  @SuppressWarnings({ "unchecked", "rawtypes" })
-  public <T extends Comparable<T>> ArrayList calculateStat(ArrayList<ArrayList<T>> lists, String stat) {
-    ArrayList result;
-    if (stat.contains("perc_")) {
-      double[] perc = new double[]{Double.parseDouble(stat.substring(5))/100};
-      result = new ArrayList<T>();
-      for (List<T> list : lists) {
-        if( list.size() == 0) continue;
-        result.add(PercentileCalculator.getPercentiles(list, perc).get(0));
-      }
-    } else if (stat.equals("count")) {
-      result = new ArrayList<Long>();
-      for (List<T> list : lists) {
-        //if( list.size() == 0) continue;
-        result.add((long)list.size());
-      }
-    } else if (stat.equals("missing")) {
-      result = new ArrayList<Long>();
-      for (ArrayList<T> list : lists) {
-        if( list.size() == 0) continue;
-        result.add(calculateMissing(list,latestType));
-      }
-    } else if (stat.equals("unique")) {
-      result = new ArrayList<Long>();
-      for (List<T> list : lists) {
-        HashSet<T> set = new HashSet<>();
-        set.addAll(list);
-        result.add((long)set.size());
-      }
-    } else if (stat.equals("max")) {
-      result = new ArrayList<T>();
-      for (List<T> list : lists) {
-        if( list.size() == 0) continue;
-        Collections.sort(list);
-        result.add(list.get(list.size()-1));
-      }
-    } else if (stat.equals("min")) {
-      result = new ArrayList<T>();
-      for (List<T> list : lists) {
-        if( list.size() == 0) continue;
-        Collections.sort((List<T>)list);
-        result.add(list.get(0));
-      }
-    } else {
-      result = null;
-    }
-    return result;
-  }
-
-  @SuppressWarnings("unchecked")
-  public <T extends Comparable<T>> Long calculateMissing(ArrayList<T> list, String type) {
-    T def = (T)defaults.get(type);
-    long miss = 0;
-    for (T element : list) {
-      if (element.compareTo(def)==0) {
-        miss++;
-      }
-    }
-    return Long.valueOf(miss);
-  }
-  
-  public static SolrQueryRequest request(String...args){
-    return SolrTestCaseJ4.req( ObjectArrays.concat(BASEPARMS, args,String.class) );
-  }
-  
-  public static final String[] BASEPARMS = new String[]{ "q", "*:*", "indent", "true", "olap", "true", "rows", "0" };
-
-  
-  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
-    InputStream in = clazz.getResourceAsStream(fileName);
-    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
-    Scanner file = new Scanner(in, "UTF-8");
-    try { 
-      ArrayList<String> strList = new ArrayList<>();
-      while (file.hasNextLine()) {
-        String line = file.nextLine();
-        if (line.length()<2) {
-          continue;
-        }
-        String[] param = line.split("=");
-        strList.add(param[0]);
-        strList.add(param[1]);
-      }
-      return strList.toArray(new String[0]);
-    } finally {
-      IOUtils.closeWhileHandlingException(file, in);
-    }
-  }
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java
deleted file mode 100644
index 09e63fb..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java
+++ /dev/null
@@ -1,174 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.facet;
-
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-
-import org.junit.Assert;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class FieldFacetExtrasTest extends AbstractAnalyticsFacetTest {
-  static String fileName = "/analytics/requestFiles/fieldFacetExtras.txt";
-
-  public static final int INT = 21;
-  public static final int LONG = 22;
-  public static final int FLOAT = 23;
-  public static final int DOUBLE = 24;
-  public static final int DATE = 25;
-  public static final int STRING = 26;
-  public static final int NUM_LOOPS = 100;
-  
-  //INT
-  static ArrayList<ArrayList<Integer>> intLongTestStart; 
-  static ArrayList<ArrayList<Integer>> intFloatTestStart; 
-  static ArrayList<ArrayList<Integer>> intDoubleTestStart; 
-  static ArrayList<ArrayList<Integer>> intStringTestStart; 
-  
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-
-    //INT
-    intLongTestStart = new ArrayList<>();
-    intFloatTestStart = new ArrayList<>();
-    intDoubleTestStart = new ArrayList<>();
-    intStringTestStart = new ArrayList<>();
-
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT;
-      long l = j%LONG;
-      float f = j%FLOAT;
-      double d = j%DOUBLE;
-      int dt = j%DATE;
-      int s = j%STRING;
-      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59.999Z", "string_sd", "abc" + s));
-      //Long
-      if (j-LONG<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intLongTestStart.add(list1);
-      } else {
-        intLongTestStart.get((int)l).add(i);
-      }
-      //String
-      if (j-FLOAT<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intFloatTestStart.add(list1);
-      } else {
-        intFloatTestStart.get((int)f).add(i);
-      }
-      //String
-      if (j-DOUBLE<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intDoubleTestStart.add(list1);
-      } else {
-        intDoubleTestStart.get((int)d).add(i);
-      }
-      //String
-      if (j-STRING<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intStringTestStart.add(list1);
-      } else {
-        intStringTestStart.get(s).add(i);
-      }
-      
-      if (usually()) {
-        assertU(commit()); // to have several segments
-      }
-    }
-    
-    assertU(commit()); 
-    setResponse(h.query(request(fileToStringArr(FieldFacetExtrasTest.class, fileName))));
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void limitTest() throws Exception { 
-
-    Collection<Double> lon = getDoubleList("lr", "fieldFacets", "long_ld", "double", "mean");
-    assertEquals(getRawResponse(), lon.size(),5);
-    Collection<Double> flo = getDoubleList("lr", "fieldFacets", "float_fd", "double", "median");
-    assertEquals(getRawResponse(), flo.size(),3);
-    Collection<Long> doub = getLongList("lr", "fieldFacets", "double_dd", "long", "count");
-    assertEquals(getRawResponse(), doub.size(),7);
-    Collection<Integer> string = getIntegerList("lr", "fieldFacets", "string_sd", "int", "percentile_20");
-    assertEquals(getRawResponse(), string.size(),1);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void offsetTest() throws Exception { 
-
-    Collection<Double> lon;
-   
-    List<Double> all = new ArrayList<>();
-    lon = getDoubleList("off0", "fieldFacets", "long_ld", "double", "mean");
-    assertEquals(getRawResponse(), lon.size(),2);
-    assertArrayEquals(new Double[]{ 1.5,  2.0 }, lon.toArray(new Double[0]));
-    all.addAll(lon);
-    
-    lon = getDoubleList("off1", "fieldFacets", "long_ld", "double", "mean");
-    assertEquals(getRawResponse(), lon.size(),2);
-    assertArrayEquals(new Double[]{ 3.0,  4.0 }, lon.toArray(new Double[0]));
-    all.addAll(lon);
-    
-    lon = getDoubleList("off2", "fieldFacets", "long_ld", "double", "mean");
-    assertEquals(getRawResponse(), lon.size(),3);
-    assertArrayEquals(new Double[]{ 5.0,  5.75, 6.0 }, lon.toArray(new Double[0]));
-    all.addAll(lon);
-    
-    lon = getDoubleList("offAll", "fieldFacets", "long_ld", "double", "mean");
-    assertEquals(getRawResponse(), lon.size(),7);
-    assertArrayEquals(all.toArray(new Double[0]), lon.toArray(new Double[0]));
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void sortTest() throws Exception { 
-    Collection<Double> lon = getDoubleList("sr", "fieldFacets", "long_ld", "double", "mean");
-    ArrayList<Double> longTest = calculateNumberStat(intLongTestStart, "mean");
-    Collections.sort(longTest);
-    assertEquals(getRawResponse(), longTest,lon);
-    
-    Collection<Double> flo = getDoubleList("sr", "fieldFacets", "float_fd", "double", "median");
-    ArrayList<Double> floatTest = calculateNumberStat(intFloatTestStart, "median");
-    Collections.sort(floatTest,Collections.reverseOrder());
-    assertEquals(getRawResponse(), floatTest,flo);
-    
-    Collection<Long> doub = getLongList("sr", "fieldFacets", "double_dd", "long", "count");
-    ArrayList<Long> doubleTest = (ArrayList<Long>)calculateStat(intDoubleTestStart, "count");
-    Collections.sort(doubleTest);
-    assertEquals(getRawResponse(), doubleTest,doub);
-    
-    Collection<Integer> string = getIntegerList("sr", "fieldFacets", "string_sd", "int", "percentile_20");
-    ArrayList<Integer> stringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_20");
-    Collections.sort(stringTest,Collections.reverseOrder());
-    assertEquals(getRawResponse(), stringTest,string);
-  }
-
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java
deleted file mode 100644
index 2eab53a..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java
+++ /dev/null
@@ -1,1084 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.facet;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-
-import org.junit.Assert;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-
-public class FieldFacetTest extends AbstractAnalyticsFacetTest{
-  static String fileName = "/analytics/requestFiles/fieldFacets.txt";
-
-  public static final int INT = 71;
-  public static final int LONG = 36;
-  public static final int LONGM = 50;
-  public static final int FLOAT = 73;
-  public static final int FLOATM = 84;
-  public static final int DOUBLE = 49;
-  public static final int DATE = 12;
-  public static final int DATEM = 30;
-  public static final int STRING = 28;
-  public static final int STRINGM = 40;
-  public static final int NUM_LOOPS = 100;
-  
-  //INT
-  private static ArrayList<ArrayList<Integer>> intDateTestStart; 
-  private static ArrayList<Long> intDateTestMissing; 
-  private static ArrayList<ArrayList<Integer>> intStringTestStart; 
-  private static ArrayList<Long> intStringTestMissing; 
-  
-  //LONG
-  private static ArrayList<ArrayList<Long>> longDateTestStart; 
-  private static ArrayList<Long> longDateTestMissing; 
-  private static ArrayList<ArrayList<Long>> longStringTestStart; 
-  private static ArrayList<Long> longStringTestMissing; 
-  
-  //FLOAT
-  private static ArrayList<ArrayList<Float>> floatDateTestStart; 
-  private static ArrayList<Long> floatDateTestMissing; 
-  private static ArrayList<ArrayList<Float>> floatStringTestStart; 
-  private static ArrayList<Long> floatStringTestMissing; 
-  
-  //DOUBLE
-  private static ArrayList<ArrayList<Double>> doubleDateTestStart; 
-  private static ArrayList<Long> doubleDateTestMissing; 
-  private static ArrayList<ArrayList<Double>> doubleStringTestStart; 
-  private static ArrayList<Long> doubleStringTestMissing; 
-  
-  //DATE
-  private static ArrayList<ArrayList<String>> dateIntTestStart; 
-  private static ArrayList<Long> dateIntTestMissing; 
-  private static ArrayList<ArrayList<String>> dateLongTestStart; 
-  private static ArrayList<Long> dateLongTestMissing; 
-  
-  //String
-  private static ArrayList<ArrayList<String>> stringIntTestStart; 
-  private static ArrayList<Long> stringIntTestMissing; 
-  private static ArrayList<ArrayList<String>> stringLongTestStart; 
-  private static ArrayList<Long> stringLongTestMissing; 
-  
-  //Multi-Valued
-  private static ArrayList<ArrayList<Integer>> multiLongTestStart; 
-  private static ArrayList<Long> multiLongTestMissing; 
-  private static ArrayList<ArrayList<Integer>> multiStringTestStart; 
-  private static ArrayList<Long> multiStringTestMissing; 
-  private static ArrayList<ArrayList<Integer>> multiDateTestStart; 
-  private static ArrayList<Long> multiDateTestMissing; 
-  
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-    
-    defaults.put("int", new Integer(0));
-    defaults.put("long", new Long(0));
-    defaults.put("float", new Float(0));
-    defaults.put("double", new Double(0));
-    defaults.put("date", "1800-12-31T23:59:59Z");
-    defaults.put("string", "str0");
-
-    //INT
-    intDateTestStart = new ArrayList<>();
-    intDateTestMissing = new ArrayList<>();
-    intStringTestStart = new ArrayList<>();
-    intStringTestMissing = new ArrayList<>();
-    
-    //LONG
-    longDateTestStart = new ArrayList<>();
-    longDateTestMissing = new ArrayList<>();
-    longStringTestStart = new ArrayList<>();
-    longStringTestMissing = new ArrayList<>();
-    
-    //FLOAT
-    floatDateTestStart = new ArrayList<>();
-    floatDateTestMissing = new ArrayList<>();
-    floatStringTestStart = new ArrayList<>();
-    floatStringTestMissing = new ArrayList<>();
-    
-    //DOUBLE
-    doubleDateTestStart = new ArrayList<>();
-    doubleDateTestMissing = new ArrayList<>();
-    doubleStringTestStart = new ArrayList<>();
-    doubleStringTestMissing = new ArrayList<>();
-    
-    //DATE
-    dateIntTestStart = new ArrayList<>();
-    dateIntTestMissing = new ArrayList<>();
-    dateLongTestStart = new ArrayList<>();
-    dateLongTestMissing = new ArrayList<>();
-    
-    //String
-    stringIntTestStart = new ArrayList<>();
-    stringIntTestMissing = new ArrayList<>();
-    stringLongTestStart = new ArrayList<>();
-    stringLongTestMissing = new ArrayList<>();
-    
-    //Multi-Valued
-    multiLongTestStart = new ArrayList<>();
-    multiLongTestMissing = new ArrayList<>();
-    multiStringTestStart = new ArrayList<>();
-    multiStringTestMissing = new ArrayList<>();
-    multiDateTestStart = new ArrayList<>();
-    multiDateTestMissing = new ArrayList<>();
-
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT;
-      long l = j%LONG;
-      long lm = j%LONGM;
-      float f = j%FLOAT;
-      double d = j%DOUBLE;
-      int dt = j%DATE;
-      int dtm = j%DATEM;
-      int s = j%STRING;
-      int sm = j%STRINGM;
-      if (dt==0 && dtm == 0) {
-        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
-          "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm)));
-      } else if (dt == 0) {
-        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
-            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
-            "date_dtdm", (1800+dtm) + "-12-31T23:59:59Z")));
-      } else if (dtm == 0) {
-        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
-            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
-            "date_dtdm", (1800+dt) + "-12-31T23:59:59Z")));
-      } else {
-        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
-            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
-            "date_dtdm", (1800+dt) + "-12-31T23:59:59Z", "date_dtdm", (1800+dtm) + "-12-31T23:59:59Z")));
-      }
-      
-      if( dt != 0 ){
-        //Dates
-        if (j-DATE<0) {
-          ArrayList<Integer> list1 = new ArrayList<>();
-          if( i != 0 ){
-            list1.add(i);
-            intDateTestMissing.add(0l);
-          } else {
-            intDateTestMissing.add(1l);
-          }
-          intDateTestStart.add(list1);
-          ArrayList<Long> list2 = new ArrayList<>();
-          if( l != 0l ){
-            list2.add(l);
-            longDateTestMissing.add(0l);
-          } else {
-            longDateTestMissing.add(1l);
-          }
-          longDateTestStart.add(list2);
-          ArrayList<Float> list3 = new ArrayList<>();
-          if ( f != 0.0f ){
-            list3.add(f);
-            floatDateTestMissing.add(0l);
-          } else {
-            floatDateTestMissing.add(1l);
-            
-          }
-          floatDateTestStart.add(list3);
-          ArrayList<Double> list4 = new ArrayList<>();
-          if( d != 0.0d ){
-            list4.add(d);
-            doubleDateTestMissing.add(0l);
-          } else {
-            doubleDateTestMissing.add(1l);
-          }
-          doubleDateTestStart.add(list4);
-          ArrayList<Integer> list5 = new ArrayList<>();
-          if( i != 0 ){
-            list5.add(i);
-            multiDateTestMissing.add(0l);
-          } else {
-            multiDateTestMissing.add(1l);
-            
-          }
-          multiDateTestStart.add(list5);
-        } else {
-          if( i != 0 ) intDateTestStart.get(dt-1).add(i); else increment(intDateTestMissing,dt-1);
-          if( l != 0l ) longDateTestStart.get(dt-1).add(l); else increment(longDateTestMissing,dt-1);
-          if( f != 0.0f ) floatDateTestStart.get(dt-1).add(f); else increment(floatDateTestMissing,dt-1);
-          if( d != 0.0d ) doubleDateTestStart.get(dt-1).add(d); else increment(doubleDateTestMissing,dt-1);
-          if( i != 0 ) multiDateTestStart.get(dt-1).add(i); else increment(multiDateTestMissing,dt-1);
-        }
-      }
-      
-      if (j-DATEM<0 && dtm!=dt && dtm!=0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        if( i != 0 ){
-          list1.add(i);
-          multiDateTestMissing.add(0l);
-        } else {
-          multiDateTestMissing.add(1l);
-        }
-        multiDateTestStart.add(list1);
-      } else if (dtm!=dt && dtm!=0) {
-        if( i != 0 ) multiDateTestStart.get(dtm-1).add(i);
-      }
-      
-      if( s != 0 ){
-        //Strings
-        if (j-STRING<0) {
-          ArrayList<Integer> list1 = new ArrayList<>();
-          if( i != 0 ){
-            list1.add(i);
-            intStringTestMissing.add(0l);
-          } else {
-            intStringTestMissing.add(1l);
-          }
-          intStringTestStart.add(list1);
-          ArrayList<Long> list2 = new ArrayList<>();
-          if( l != 0l ){
-            list2.add(l);
-            longStringTestMissing.add(0l);
-          } else {
-            longStringTestMissing.add(1l);
-          }
-          longStringTestStart.add(list2);
-          ArrayList<Float> list3 = new ArrayList<>();
-          if( f != 0.0f ){
-            list3.add(f);
-            floatStringTestMissing.add(0l);
-          } else {
-            floatStringTestMissing.add(1l);
-          }
-          floatStringTestStart.add(list3);
-          ArrayList<Double> list4 = new ArrayList<>();
-          if( d != 0.0d ){
-            list4.add(d);
-            doubleStringTestMissing.add(0l);
-          } else {
-            doubleStringTestMissing.add(1l);
-          }
-          doubleStringTestStart.add(list4);
-          ArrayList<Integer> list5 = new ArrayList<>();
-          if( i != 0 ){
-            list5.add(i);
-            multiStringTestMissing.add(0l);
-          } else {
-            multiStringTestMissing.add(1l);
-          }
-          multiStringTestStart.add(list5);
-        } else {
-          if( i != 0 ) intStringTestStart.get(s-1).add(i); else increment(intStringTestMissing,s-1);
-          if( l != 0l ) longStringTestStart.get(s-1).add(l); else increment(longStringTestMissing,s-1);
-          if( f != 0.0f ) floatStringTestStart.get(s-1).add(f); else increment(floatStringTestMissing,s-1);
-          if( d != 0.0d ) doubleStringTestStart.get(s-1).add(d); else increment(doubleStringTestMissing,s-1);
-          if( i != 0 ) multiStringTestStart.get(s-1).add(i); else increment(multiStringTestMissing,s-1);
-        }
-      }
-      
-      //Strings
-      if( sm != 0 ){
-        if (j-STRINGM<0&&sm!=s) {
-          ArrayList<Integer> list1 = new ArrayList<>();
-          if( i != 0 ){
-            list1.add(i);
-            multiStringTestMissing.add(0l);
-          } else {
-            multiStringTestMissing.add(1l);
-          }
-          multiStringTestStart.add(list1);
-        } else if (sm!=s) {
-          if( i != 0 ) multiStringTestStart.get(sm-1).add(i); else increment(multiStringTestMissing,sm-1);
-        }
-      }
-      
-      //Int
-      if( i != 0 ){
-        if (j-INT<0) {
-          ArrayList<String> list1 = new ArrayList<>();
-          if( dt != 0 ){
-            list1.add((1800+dt) + "-12-31T23:59:59Z");
-            dateIntTestMissing.add(0l);
-          } else {
-            dateIntTestMissing.add(1l);
-          }
-          dateIntTestStart.add(list1);
-          ArrayList<String> list2 = new ArrayList<>();
-          if( s != 0 ){
-            list2.add("str"+s);
-            stringIntTestMissing.add(0l);
-          } else {
-            stringIntTestMissing.add(1l);
-          }
-          stringIntTestStart.add(list2);
-        } else {
-          if( dt != 0 ) dateIntTestStart.get(i-1).add((1800+dt) + "-12-31T23:59:59Z"); else increment(dateIntTestMissing,i-1);
-          if( s != 0 ) stringIntTestStart.get(i-1).add("str"+s); else increment(stringIntTestMissing,i-1);
-        }
-      }
-      
-      //Long
-      if( l != 0 ){
-        if (j-LONG<0) {
-          ArrayList<String> list1 = new ArrayList<>();
-          if( dt != 0 ){
-            list1.add((1800+dt) + "-12-31T23:59:59Z");
-            dateLongTestMissing.add(0l);
-          } else {
-            dateLongTestMissing.add(1l);
-          }
-          dateLongTestStart.add(list1);
-          ArrayList<String> list2 = new ArrayList<>();
-          if( s != 0 ){
-            list2.add("str"+s);
-            stringLongTestMissing.add(0l);
-          } else {
-            stringLongTestMissing.add(1l);
-          }
-          stringLongTestStart.add(list2);
-          ArrayList<Integer> list3 = new ArrayList<>();
-          if( i != 0 ){
-            list3.add(i);
-            multiLongTestMissing.add(0l);
-          } else {
-            multiLongTestMissing.add(1l);
-          }
-          multiLongTestStart.add(list3);
-        } else {
-          if( dt != 0 ) dateLongTestStart.get((int)l-1).add((1800+dt) + "-12-31T23:59:59Z"); else increment(dateLongTestMissing,(int)l-1);
-          if( s != 0 ) stringLongTestStart.get((int)l-1).add("str"+s); else increment(stringLongTestMissing,(int)l-1);
-          if( i != 0 ) multiLongTestStart.get((int)l-1).add(i); else increment(multiLongTestMissing,(int)l-1);
-        }
-      }
-      
-      //Long
-      if( lm != 0 ){
-        if (j-LONGM<0&&lm!=l) {
-          ArrayList<Integer> list1 = new ArrayList<>();
-          if( i != 0 ){
-            list1.add(i);
-            multiLongTestMissing.add(0l);
-          } else {
-            multiLongTestMissing.add(1l);
-          }
-          multiLongTestStart.add(list1);
-        } else if (lm!=l) {
-          if( i != 0 ) multiLongTestStart.get((int)lm-1).add(i); else increment( multiLongTestMissing,(int)lm-1);
-        }
-      }
-      
-      if (usually()) {
-        assertU(commit()); // to have several segments
-      }
-    }
-    
-    assertU(commit());
-    String[] reqFacetParamas = fileToStringArr(FieldFacetTest.class, fileName);
-    String[] reqParamas = new String[reqFacetParamas.length + 2];
-    System.arraycopy(reqFacetParamas, 0, reqParamas, 0, reqFacetParamas.length);
-    reqParamas[reqFacetParamas.length] = "solr";
-    reqParamas[reqFacetParamas.length+1] = "asc";
-    setResponse(h.query(request(reqFacetParamas)));
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void sumTest() throws Exception { 
-    //Int Date
-    Collection<Double> intDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "int");
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "sum");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Double> intString = getDoubleList("sum","fieldFacets", "string_sd", "double", "int");
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "sum");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Double> longDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "long");
-    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "sum");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Double> longString = getDoubleList("sum","fieldFacets", "string_sd", "double", "long");
-    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "sum");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Double> floatDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "float");
-    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "sum");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Double> floatString = getDoubleList("sum","fieldFacets", "string_sd", "double", "float");
-    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "sum");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "sum");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("sum","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "sum");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void meanTest() throws Exception { 
-    //Int Date
-    Collection<Double> intDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "int");
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "mean");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Double> intString = getDoubleList("mean","fieldFacets", "string_sd", "double", "int");
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "mean");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Double> longDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "long");
-    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "mean");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Double> longString = getDoubleList("mean","fieldFacets", "string_sd", "double", "long");
-    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "mean");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Double> floatDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "float");
-    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "mean");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Double> floatString = getDoubleList("mean","fieldFacets", "string_sd", "double", "float");
-    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "mean");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "mean");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("mean","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "mean");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void sumOfSquaresFacetAscTest() throws Exception {
-    //Int Date
-    Collection<Double> intDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "int");
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Double> intString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "int");
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Double> longDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "long");
-    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Double> longString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "long");
-    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Double> floatDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "float");
-    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Double> floatString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "float");
-    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "sumOfSquares");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void stddevFacetAscTest() throws Exception { 
-    //Int Date
-    ArrayList<Double> intDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "int");
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "stddev");
-    checkStddevs(intDate,intDateTest);
-    //Int String
-    ArrayList<Double> intString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "int");
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "stddev");
-    checkStddevs(intString,intStringTest);
-
-    //Long Date
-    ArrayList<Double> longDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "long");
-    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "stddev");
-    checkStddevs(longDate,longDateTest);
-    //Long String
-    ArrayList<Double> longString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "long");
-    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "stddev");
-    checkStddevs(longString,longStringTest);
-
-    //Float Date
-    ArrayList<Double> floatDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "float");
-    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "stddev");
-    checkStddevs(floatDate,floatDateTest);
-    //Float String
-    ArrayList<Double> floatString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "float");
-    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "stddev");
-    checkStddevs(floatString,floatStringTest);
-
-    //Double Date
-    ArrayList<Double> doubleDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "stddev");
-    checkStddevs(doubleDate,doubleDateTest);
-    //Double String
-    ArrayList<Double> doubleString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "stddev");
-    checkStddevs(doubleString,doubleStringTest);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void medianFacetAscTest() throws Exception { 
-    //Int Date
-    Collection<Double> intDate = getDoubleList( "median","fieldFacets", "date_dtd", "double", "int");
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "median");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Double> intString = getDoubleList("median","fieldFacets", "string_sd", "double", "int");
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "median");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Double> longDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "long");
-    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "median");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Double> longString = getDoubleList("median","fieldFacets", "string_sd", "double", "long");
-    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "median");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Double> floatDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "float");
-    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "median");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Double> floatString = getDoubleList("median","fieldFacets", "string_sd", "double", "float");
-    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "median");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "median");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("median","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "median");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void perc20Test() throws Exception { 
-    //Int Date
-    Collection<Integer> intDate = getIntegerList("percentile_20n","fieldFacets", "date_dtd", "int", "int");
-    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "perc_20");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Integer> intString = getIntegerList("percentile_20n","fieldFacets", "string_sd", "int", "int");
-    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_20");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("percentile_20n","fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "perc_20");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Long> longString = getLongList("percentile_20n","fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "perc_20");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Float> floatDate = getFloatList("percentile_20n","fieldFacets", "date_dtd", "float", "float");
-    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "perc_20");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Float> floatString = getFloatList("percentile_20n","fieldFacets", "string_sd", "float", "float");
-    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "perc_20");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("percentile_20n","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "perc_20");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("percentile_20n","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "perc_20");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-
-    //Date Int
-    Collection<String> dateInt = getStringList("percentile_20","fieldFacets", "int_id", "date", "date");
-    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "perc_20");
-    assertEquals(getRawResponse(),dateInt,dateIntTest);
-    //Date Long
-    Collection<String> dateString = getStringList("percentile_20","fieldFacets", "long_ld", "date", "date");
-    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "perc_20");
-    assertEquals(getRawResponse(),dateString,dateLongTest);
-
-    //String Int
-    Collection<String> stringInt = getStringList("percentile_20","fieldFacets", "int_id", "str", "str");
-    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "perc_20");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    //String Long
-    Collection<String> stringLong = getStringList("percentile_20","fieldFacets", "long_ld", "str", "str");
-    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "perc_20");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void perc60Test() throws Exception { 
-    //Int Date
-    Collection<Integer> intDate = getIntegerList("percentile_60n","fieldFacets", "date_dtd", "int", "int");
-    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "perc_60");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Integer> intString = getIntegerList("percentile_60n","fieldFacets", "string_sd", "int", "int");
-    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_60");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("percentile_60n","fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "perc_60");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Long> longString = getLongList("percentile_60n","fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "perc_60");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Float> floatDate = getFloatList("percentile_60n","fieldFacets", "date_dtd", "float", "float");
-    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "perc_60");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Float> floatString = getFloatList("percentile_60n","fieldFacets", "string_sd", "float", "float");
-    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "perc_60");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("percentile_60n","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "perc_60");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("percentile_60n","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "perc_60");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-
-    //Date Int
-    Collection<String> dateInt = getStringList("percentile_60","fieldFacets", "int_id", "date", "date");
-    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "perc_60");
-    assertEquals(getRawResponse(),dateInt,dateIntTest);
-    //Date Long
-    Collection<String> dateString = getStringList("percentile_60","fieldFacets", "long_ld", "date", "date");
-    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "perc_60");
-    assertEquals(getRawResponse(),dateString,dateLongTest);
-
-    //String Int
-    Collection<String> stringInt = getStringList("percentile_60","fieldFacets", "int_id", "str", "str");
-    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "perc_60");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    //String Long
-    Collection<String> stringLong = getStringList("percentile_60","fieldFacets", "long_ld", "str", "str");
-    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "perc_60");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void minTest() throws Exception { 
-    //Int Date
-    Collection<Integer> intDate = getIntegerList("minn","fieldFacets", "date_dtd", "int", "int");
-    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "min");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Integer> intString = getIntegerList("minn","fieldFacets", "string_sd", "int", "int");
-    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "min");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("minn","fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "min");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Long> longString = getLongList("minn","fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "min");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Float> floatDate = getFloatList("minn","fieldFacets", "date_dtd", "float", "float");
-    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "min");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Float> floatString = getFloatList("minn","fieldFacets", "string_sd", "float", "float");
-    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "min");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("minn","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "min");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Double> doubleString = getDoubleList("minn","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "min");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-
-    //Date Int
-    Collection<String> dateInt = getStringList("min","fieldFacets", "int_id", "date", "date");
-    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "min");
-    assertEquals(getRawResponse(),dateInt,dateIntTest);
-    //Date Long
-    Collection<String> dateString = getStringList("min","fieldFacets", "long_ld", "date", "date");
-    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "min");
-    assertEquals(getRawResponse(),dateString,dateLongTest);
-
-    //String Int
-    Collection<String> stringInt = getStringList("min","fieldFacets", "int_id", "str", "str");
-    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "min");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    //String Long
-    Collection<String> stringLong = getStringList("min","fieldFacets", "long_ld", "str", "str");
-    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "min");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void maxTest() throws Exception { 
-    //Int Date
-    Collection<Integer> intDate = getIntegerList("maxn","fieldFacets", "date_dtd", "int", "int");
-    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "max");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    
-    //Int String
-    Collection<Integer> intString = getIntegerList("maxn","fieldFacets", "string_sd", "int", "int");
-    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "max");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("maxn","fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "max");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    
-    //Long String
-    Collection<Long> longString = getLongList("maxn","fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "max");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Float> floatDate = getFloatList("maxn","fieldFacets", "date_dtd", "float", "float");
-    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "max");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    
-    //Float String
-    Collection<Float> floatString = getFloatList("maxn","fieldFacets", "string_sd", "float", "float");
-    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "max");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Double> doubleDate = getDoubleList("maxn","fieldFacets", "date_dtd", "double", "double");
-    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "max");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    
-    //Double String
-    Collection<Double> doubleString = getDoubleList("maxn","fieldFacets", "string_sd", "double", "double");
-    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "max");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-    
-    //String Int
-    Collection<String> stringInt = getStringList("max","fieldFacets", "int_id", "str", "str");
-    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "max");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    
-    //String Long
-    Collection<String> stringLong = getStringList("max","fieldFacets", "long_ld", "str", "str");
-    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "max");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-
-    //Date Int
-    Collection<String> dateInt = getStringList("max","fieldFacets", "int_id", "date", "date");
-    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "max");
-    assertEquals(getRawResponse(),dateInt,dateIntTest);
-    
-    //Date Long
-    Collection<String> dateString = getStringList("max","fieldFacets", "long_ld", "date", "date");
-    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "max");
-    assertEquals(getRawResponse(),dateString,dateLongTest);
-
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void uniqueTest() throws Exception { 
-    //Int Date
-    Collection<Long> intDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "int");
-    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(intDateTestStart, "unique");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    //Int String
-    Collection<Long> intString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "int");
-    ArrayList<Long> intStringTest = (ArrayList<Long>)calculateStat(intStringTestStart, "unique");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "unique");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    //Long String
-    Collection<Long> longString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "unique");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Long> floatDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "float");
-    ArrayList<Long> floatDateTest = (ArrayList<Long>)calculateStat(floatDateTestStart, "unique");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    //Float String
-    Collection<Long> floatString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "float");
-    ArrayList<Long> floatStringTest = (ArrayList<Long>)calculateStat(floatStringTestStart, "unique");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Long> doubleDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "double");
-    ArrayList<Long> doubleDateTest = (ArrayList<Long>)calculateStat(doubleDateTestStart, "unique");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    //Double String
-    Collection<Long> doubleString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "double");
-    ArrayList<Long> doubleStringTest = (ArrayList<Long>)calculateStat(doubleStringTestStart, "unique");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-
-    //Date Int
-    Collection<Long> dateInt = getLongList("unique", "fieldFacets", "int_id", "long", "date");
-    ArrayList<Long> dateIntTest = (ArrayList<Long>)calculateStat(dateIntTestStart, "unique");
-    assertEquals(getRawResponse(),dateInt,dateIntTest);
-    //Date Long
-    Collection<Long> dateString = getLongList("unique", "fieldFacets", "long_ld", "long", "date");
-    ArrayList<Long> dateLongTest = (ArrayList<Long>)calculateStat(dateLongTestStart, "unique");
-    assertEquals(getRawResponse(),dateString,dateLongTest);
-
-    //String Int
-    Collection<Long> stringInt = getLongList("unique", "fieldFacets", "int_id", "long", "str");
-    ArrayList<Long> stringIntTest = (ArrayList<Long>)calculateStat(stringIntTestStart, "unique");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    //String Long
-    Collection<Long> stringLong = getLongList("unique", "fieldFacets", "long_ld", "long", "str");
-    ArrayList<Long> stringLongTest = (ArrayList<Long>)calculateStat(stringLongTestStart, "unique");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void countTest() throws Exception { 
-    //Int Date
-    Collection<Long> intDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "int");
-    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(intDateTestStart, "count");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    
-    //Int String
-    Collection<Long> intString = getLongList("countn", "fieldFacets", "string_sd", "long", "int");
-    ArrayList<Long> intStringTest = (ArrayList<Long>)calculateStat(intStringTestStart, "count");
-    assertEquals(getRawResponse(),intString,intStringTest);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "long");
-    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "count");
-    assertEquals(getRawResponse(),longDate,longDateTest);
-    
-    //Long String
-    Collection<Long> longString = getLongList("countn", "fieldFacets", "string_sd", "long", "long");
-    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "count");
-    assertEquals(getRawResponse(),longString,longStringTest);
-
-    //Float Date
-    Collection<Long> floatDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "float");
-    ArrayList<Long> floatDateTest = (ArrayList<Long>)calculateStat(floatDateTestStart, "count");
-    assertEquals(getRawResponse(),floatDate,floatDateTest);
-    
-    //Float String
-    Collection<Long> floatString = getLongList("countn", "fieldFacets", "string_sd", "long", "float");
-    ArrayList<Long> floatStringTest = (ArrayList<Long>)calculateStat(floatStringTestStart, "count");
-    assertEquals(getRawResponse(),floatString,floatStringTest);
-
-    //Double Date
-    Collection<Long> doubleDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "double");
-    ArrayList<Long> doubleDateTest = (ArrayList<Long>)calculateStat(doubleDateTestStart, "count");
-    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
-    
-    //Double String
-    Collection<Long> doubleString = getLongList("countn", "fieldFacets", "string_sd", "long", "double");
-    ArrayList<Long> doubleStringTest = (ArrayList<Long>)calculateStat(doubleStringTestStart, "count");
-    assertEquals(getRawResponse(),doubleString,doubleStringTest);
-
-    //Date Int
-    Collection<Long> dateInt = getLongList("count", "fieldFacets", "int_id", "long", "date");
-    ArrayList<Long> dateIntTest = (ArrayList<Long>)calculateStat(dateIntTestStart, "count");
-    assertEquals(getRawResponse(),dateIntTest,dateInt);
-    
-    //Date Long
-    Collection<Long> dateLong = getLongList("count", "fieldFacets", "long_ld", "long", "date");
-    ArrayList<Long> dateLongTest = (ArrayList<Long>)calculateStat(dateLongTestStart, "count");
-    assertEquals(getRawResponse(),dateLong,dateLongTest);
-
-    //String Int
-    Collection<Long> stringInt = getLongList("count", "fieldFacets", "int_id", "long", "str");
-    ArrayList<Long> stringIntTest = (ArrayList<Long>)calculateStat(stringIntTestStart, "count");
-    assertEquals(getRawResponse(),stringInt,stringIntTest);
-    
-    //String Long
-    Collection<Long> stringLong = getLongList("count", "fieldFacets", "long_ld", "long", "str");
-    ArrayList<Long> stringLongTest = (ArrayList<Long>)calculateStat(stringLongTestStart, "count");
-    assertEquals(getRawResponse(),stringLong,stringLongTest);
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void missingTest() throws Exception { 
-    //Int Date
-    Collection<Long> intDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "int");
-    setLatestType("int");
-    assertEquals(getRawResponse(),intDateTestMissing,intDate);
-    
-    //Int String
-    Collection<Long> intString = getLongList("missingn", "fieldFacets", "string_sd", "long", "int");
-    assertEquals(getRawResponse(),intStringTestMissing,intString);
-
-    //Long Date
-    Collection<Long> longDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "long");
-    setLatestType("long");
-    assertEquals(getRawResponse(),longDateTestMissing,longDate);
-    
-    //Long String
-    Collection<Long> longString = getLongList("missingn", "fieldFacets", "string_sd", "long", "long");
-    assertEquals(getRawResponse(),longStringTestMissing,longString);
-
-    //Float Date
-    Collection<Long> floatDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "float");
-    setLatestType("float");
-    assertEquals(getRawResponse(),floatDateTestMissing,floatDate);
-    
-    //Float String
-    Collection<Long> floatString = getLongList("missingn", "fieldFacets", "string_sd", "long", "float");
-    assertEquals(getRawResponse(),floatStringTestMissing,floatString);
-
-    //Double Date
-    Collection<Long> doubleDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "double");
-    setLatestType("double");
-    assertEquals(getRawResponse(),doubleDateTestMissing,doubleDate);
-    
-    //Double String
-    Collection<Long> doubleString = getLongList("missingn", "fieldFacets", "string_sd", "long", "double");
-    assertEquals(getRawResponse(),doubleStringTestMissing,doubleString);
-
-    //Date Int
-    Collection<Long> dateInt = getLongList("missing", "fieldFacets", "int_id", "long", "date");
-    setLatestType("date");
-    assertEquals(getRawResponse(),dateIntTestMissing,dateInt);
-    
-    //Date Long
-    Collection<Long> dateLong = getLongList("missing", "fieldFacets", "long_ld", "long", "date");
-    assertEquals(getRawResponse(),dateLongTestMissing,dateLong);
-
-    //String Int
-    Collection<Long> stringInt = getLongList("missing", "fieldFacets", "int_id", "long", "str");
-    setLatestType("string");
-    assertEquals(getRawResponse(),stringIntTestMissing,stringInt);
-    
-    //String Long
-    Collection<Long> stringLong = getLongList("missing", "fieldFacets", "long_ld", "long", "str");
-    assertEquals(getRawResponse(),stringLongTestMissing,stringLong);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void multiValueTest() throws Exception { 
-    //Long
-    Collection<Double> lon = getDoubleList("multivalued", "fieldFacets", "long_ldm", "double", "mean");
-    ArrayList<Double> longTest = calculateNumberStat(multiLongTestStart, "mean");
-    assertEquals(getRawResponse(),lon,longTest);
-    //Date
-    Collection<Double> date = getDoubleList("multivalued", "fieldFacets", "date_dtdm", "double", "mean");
-    ArrayList<Double> dateTest = calculateNumberStat(multiDateTestStart, "mean");
-    assertEquals(getRawResponse(),date,dateTest);
-    //String
-    Collection<Double> string = getDoubleList("multivalued", "fieldFacets", "string_sdm", "double", "mean");
-    ArrayList<Double> stringTest = calculateNumberStat(multiStringTestStart, "mean");
-    assertEquals(getRawResponse(),string,stringTest);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void missingFacetTest() throws Exception { 
-    //int MultiDate
-    String xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='date_dtdm']/lst[@name='(MISSING)']";
-    assertNotNull(getRawResponse(), getNode(xPath));
-
-    ArrayList<Double> string = getDoubleList("missingf", "fieldFacets", "date_dtdm", "double", "mean");
-    string.remove(0);
-    ArrayList<Double> stringTest = calculateNumberStat(multiDateTestStart, "mean");
-    assertEquals(getRawResponse(), string,stringTest);
-    
-    //Int String
-    xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='string_sd']/lst[@name='(MISSING)']";
-    assertNotNull(getRawResponse(), getNode(xPath));
-
-    xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='string_sd']/lst[@name='str0']";
-    assertNull(getRawResponse(), getNode(xPath));
-    List<Double> intString = getDoubleList("missingf", "fieldFacets", "string_sd", "double", "mean");
-    intString.remove(0);
-    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "mean");
-    assertEquals(getRawResponse(), intString,intStringTest);
-    
-    //Int Date
-    Collection<Double> intDate = getDoubleList("missingf", "fieldFacets", "date_dtd", "double", "mean");
-    ArrayList<ArrayList<Double>> intDateMissingTestStart = (ArrayList<ArrayList<Double>>) intDateTestStart.clone();
-    ArrayList<Double> intDateTest = calculateNumberStat(intDateMissingTestStart, "mean");
-    assertEquals(getRawResponse(),intDate,intDateTest);
-    
-    
-  }
-
-  private void checkStddevs(ArrayList<Double> list1, ArrayList<Double> list2) {
-    Collections.sort(list1);
-    Collections.sort(list2);
-    for (int i = 0; i<list1.size(); i++) {
-      if ((Math.abs(list1.get(i)-list2.get(i))<.00000000001) == false) {
-        Assert.assertEquals(getRawResponse(), list1.get(i), list2.get(i), 0.00000000001);
-      }
-    }
-  }
-
-  public static void assertEquals(String mes, Object actual, Object expected) {
-    Collections.sort((List<Comparable>) actual);
-    Collections.sort((List<Comparable>)  expected);
-    Assert.assertEquals(mes, actual, expected);
-  }
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java
deleted file mode 100644
index 8c5787d..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java
+++ /dev/null
@@ -1,125 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.facet;
-
-
-import java.util.ArrayList;
-
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class QueryFacetTest extends AbstractAnalyticsFacetTest {
-  static String fileName = "/analytics/requestFiles/queryFacets.txt";
-
-  public final int INT = 71;
-  public final int LONG = 36;
-  public final int FLOAT = 93;
-  public final int DOUBLE = 49;
-  public final int DATE = 12;
-  public final int STRING = 28;
-  public final int NUM_LOOPS = 100;
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void queryTest() throws Exception { 
-    h.update("<delete><query>*:*</query></delete>");
-    //INT
-    ArrayList<ArrayList<Integer>> int1TestStart = new ArrayList<>();
-    int1TestStart.add(new ArrayList<Integer>());
-    ArrayList<ArrayList<Integer>> int2TestStart = new ArrayList<>();
-    int2TestStart.add(new ArrayList<Integer>());
-    
-    //LONG
-    ArrayList<ArrayList<Long>> longTestStart = new ArrayList<>();
-    longTestStart.add(new ArrayList<Long>());
-    longTestStart.add(new ArrayList<Long>());
-    
-    //FLOAT
-    ArrayList<ArrayList<Float>> floatTestStart = new ArrayList<>();
-    floatTestStart.add(new ArrayList<Float>());
-    floatTestStart.add(new ArrayList<Float>());
-    floatTestStart.add(new ArrayList<Float>());
-    
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT;
-      long l = j%LONG;
-      float f = j%FLOAT;
-      double d = j%DOUBLE;
-      int dt = j%DATE;
-      int s = j%STRING;
-      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59.999Z", "string_sd", "abc" + new Integer(s).toString().charAt(0)));
-
-      if (f<=50) {
-        int1TestStart.get(0).add(i);
-      }
-      if (f<=30) {
-        int2TestStart.get(0).add(i);
-      }
-      if (new Integer(s).toString().charAt(0)=='1') {
-        longTestStart.get(0).add(l);
-      }
-      if (new Integer(s).toString().charAt(0)=='2') {
-        longTestStart.get(1).add(l);
-      }
-      if (l>=20) {
-        floatTestStart.get(0).add(f);
-      }
-      if (l>=30) {
-        floatTestStart.get(1).add(f);
-      }
-      if (d<=50) {
-        floatTestStart.get(2).add(f);
-      }
-      
-      if (usually()) {
-        assertU(commit()); // to have several segments
-      }
-    }
-    
-    assertU(commit()); 
-    
-    //Query ascending tests
-    setResponse(h.query(request(fileToStringArr(QueryFacetTest.class, fileName))));
-    
-    //Int One
-    ArrayList<Double> int1 = getDoubleList("ir", "queryFacets", "float1", "double", "sum");
-    ArrayList<Double> int1Test = calculateNumberStat(int1TestStart, "sum");
-    assertEquals(getRawResponse(), int1, int1Test);
-    //Int Two
-    ArrayList<Integer> int2 = getIntegerList("ir", "queryFacets", "float2", "int", "percentile_8");
-    ArrayList<Integer> int2Test = (ArrayList<Integer>)calculateStat(int2TestStart, "perc_8");
-    assertEquals(getRawResponse(), int2, int2Test);
-
-    //Long
-    ArrayList<Double> long1 = getDoubleList("lr", "queryFacets", "string", "double", "median");
-    ArrayList<Double> long1Test = calculateNumberStat(longTestStart, "median");
-    assertEquals(getRawResponse(),long1,long1Test);
-
-    //Float
-    ArrayList<Double> float1 = getDoubleList("fr", "queryFacets", "lad", "double", "mean");
-    ArrayList<Double> float1Test = calculateNumberStat(floatTestStart, "mean");
-    assertEquals(getRawResponse(), float1, float1Test);
-  }
-
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java
deleted file mode 100644
index c6e7494..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java
+++ /dev/null
@@ -1,445 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.facet;
-
-
-import java.util.ArrayList;
-
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-
-public class RangeFacetTest extends AbstractAnalyticsFacetTest {
-  static String fileName = "/analytics/requestFiles/rangeFacets.txt";
-
-  public static final int INT = 71;
-  public static final int LONG = 36;
-  public static final int FLOAT = 93;
-  public static final int DOUBLE = 48;
-  public static final int DATE = 52;
-  public static final int STRING = 28;
-  public static final int NUM_LOOPS = 100;
-  
-  //INT
-  static ArrayList<ArrayList<Integer>> intLongTestStart; 
-  static ArrayList<ArrayList<Integer>> intDoubleTestStart; 
-  static ArrayList<ArrayList<Integer>> intDateTestStart; 
-  
-  //FLOAT
-  static ArrayList<ArrayList<Float>> floatLongTestStart; 
-  static ArrayList<ArrayList<Float>> floatDoubleTestStart; 
-  static ArrayList<ArrayList<Float>> floatDateTestStart; 
-  
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-    
-    //INT
-    intLongTestStart = new ArrayList<>();
-    intDoubleTestStart = new ArrayList<>();
-    intDateTestStart = new ArrayList<>();
-    
-    //FLOAT
-    floatLongTestStart = new ArrayList<>();
-    floatDoubleTestStart = new ArrayList<>();
-    floatDateTestStart = new ArrayList<>();
-    
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT;
-      long l = j%LONG;
-      float f = j%FLOAT;
-      double d = j%DOUBLE;
-      int dt = j%DATE;
-      int s = j%STRING;
-      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-          "double_dd", "" + d,  "date_dtd", (1000+dt) + "-01-01T23:59:59Z", "string_sd", "abc" + s));
-      //Longs
-      if (j-LONG<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intLongTestStart.add(list1);
-        ArrayList<Float> list2 = new ArrayList<>();
-        list2.add(f);
-        floatLongTestStart.add(list2);
-      } else {
-        intLongTestStart.get((int)l).add(i);
-        floatLongTestStart.get((int)l).add(f);
-      }
-      //Doubles
-      if (j-DOUBLE<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intDoubleTestStart.add(list1);
-        ArrayList<Float> list2 = new ArrayList<>();
-        list2.add(f);
-        floatDoubleTestStart.add(list2);
-      } else {
-        intDoubleTestStart.get((int)d).add(i);
-        floatDoubleTestStart.get((int)d).add(f);
-      }
-      //Dates
-      if (j-DATE<0) {
-        ArrayList<Integer> list1 = new ArrayList<>();
-        list1.add(i);
-        intDateTestStart.add(list1);
-        ArrayList<Float> list2 = new ArrayList<>();
-        list2.add(f);
-        floatDateTestStart.add(list2);
-      } else {
-        intDateTestStart.get(dt).add(i);
-        floatDateTestStart.get(dt).add(f);
-      }
-      
-      if (usually()) {
-        assertU(commit());  // to have several segments
-      }
-    }
-    
-    assertU(commit()); 
-    
-    setResponse(h.query(request(fileToStringArr(RangeFacetTest.class, fileName))));
-  }
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void rangeTest() throws Exception {
-    
-    //Int Long
-    ArrayList<Long> intLong = getLongList("ri", "rangeFacets", "long_ld", "long", "count");
-    ArrayList<Long> intLongTest = calculateStat(transformLists(intLongTestStart, 5, 30, 5
-                                                        , false, true, false, false, false), "count");
-    assertEquals(getRawResponse(), intLong,intLongTest);
-    //Int Double
-    ArrayList<Double> intDouble = getDoubleList("ri", "rangeFacets", "double_dd", "double", "mean");
-    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, 7
-                                                          , false, false, true, false, true), "mean");
-    assertEquals(getRawResponse(), intDouble,intDoubleTest);
-    //Int Date
-    ArrayList<Long> intDate = getLongList("ri", "rangeFacets", "date_dtd", "long", "count");
-    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, 7
-                                                      , false, true, false, true, true), "count");
-    assertEquals(getRawResponse(), intDate,intDateTest);
-    
-    //Float Long
-    ArrayList<Double> floatLong = getDoubleList("rf", "rangeFacets", "long_ld", "double", "median");
-    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, 4
-                                                          , false, true, true, true, true), "median");
-    assertEquals(getRawResponse(), floatLong,floatLongTest);
-    //Float Double
-    ArrayList<Long> floatDouble = getLongList("rf", "rangeFacets", "double_dd", "long", "count");
-    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, 11
-                                                                     , false, false, false, true, false), "count");
-    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
-    //Float Date                      
-    ArrayList<Double> floatDate = getDoubleList("rf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
-    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, 5
-                                                          , false, false, true, true, false), "sumOfSquares");
-    assertEquals(getRawResponse(), floatDate,floatDateTest);
-  }
-  
-
-  @SuppressWarnings("unchecked")
-  @Test
-  public void hardendRangeTest() throws Exception {
-    //Int Long
-    ArrayList<Double> intLong = getDoubleList("hi", "rangeFacets", "long_ld", "double", "sum");
-    ArrayList<Double> intLongTest = calculateNumberStat(transformLists(intLongTestStart, 5, 30, 5
-                                                        , true, true, false, false, false), "sum");
-    assertEquals(getRawResponse(), intLong,intLongTest);
-    //Int Double
-    ArrayList<Double> intDouble = getDoubleList("hi", "rangeFacets", "double_dd", "double", "mean");
-    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, 7
-                                                          , true, false, true, false, true), "mean");
-    assertEquals(getRawResponse(), intDouble,intDoubleTest);
-    //Int Date
-    ArrayList<Long> intDate = getLongList("hi", "rangeFacets", "date_dtd", "long", "count");
-    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, 7
-                                                      , true, true, false, true, true), "count");
-    assertEquals(getRawResponse(), intDate,intDateTest);
-    
-    //Float Long
-    ArrayList<Double> floatLong = getDoubleList("hf", "rangeFacets", "long_ld", "double", "median");
-    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, 4
-                                                          , true, true, true, true, true), "median");
-    assertEquals(getRawResponse(), floatLong,floatLongTest);
-    //Float Double
-    ArrayList<Long> floatDouble = getLongList("hf", "rangeFacets", "double_dd", "long", "count");
-    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, 11
-                                                                     , true, false, false, true, false), "count");
-    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
-    //Float Date                      
-    ArrayList<Double> floatDate = getDoubleList("hf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
-    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, 5
-                                                          , true, false, true, true, false), "sumOfSquares");
-    assertEquals(getRawResponse(), floatDate,floatDateTest);
-  }
-  
-  @SuppressWarnings("unchecked")
-  @Test
-  public void multiGapTest() throws Exception {
-    //Int Long
-    ArrayList<Double> intLong = getDoubleList("mi", "rangeFacets", "long_ld", "double", "sum");
-    ArrayList<Double> intLongTest = calculateNumberStat(transformLists(intLongTestStart, 5, 30, "4,2,6,3"
-                                                        , false, true, false, false, false), "sum");
-    assertEquals(getRawResponse(), intLong,intLongTest);
-    //Int Double
-    ArrayList<Double> intDouble = getDoubleList("mi", "rangeFacets", "double_dd", "double", "mean");
-    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, "3,1,7"
-                                                          , false, false, true, false, true), "mean");
-    assertEquals(getRawResponse(), intDouble,intDoubleTest);
-    //Int Date
-    ArrayList<Long> intDate = getLongList("mi", "rangeFacets", "date_dtd", "long", "count");
-    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, "2,7"
-                                                      , false, true, false, true, true), "count");
-    assertEquals(getRawResponse(), intDate,intDateTest);
-    
-    //Float Long
-    ArrayList<Double> floatLong = getDoubleList("mf", "rangeFacets", "long_ld", "double", "median");
-    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, "1,4"
-                                                          , false, true, true, true, true), "median");;
-    assertEquals(getRawResponse(), floatLong,floatLongTest);
-    //Float Double
-    ArrayList<Long> floatDouble = getLongList("mf", "rangeFacets", "double_dd", "long", "count");
-    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, "2,3,11"
-                                                          , false, false, false, true, false), "count");
-    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
-    //Float Date                      
-    ArrayList<Double> floatDate = getDoubleList("mf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
-    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, "4,5"
-                                                          , false, false, true, true, false), "sumOfSquares");
-    assertEquals(getRawResponse(), floatDate,floatDateTest);
-  }
-  
-  private <T> ArrayList<ArrayList<T>> transformLists(ArrayList<ArrayList<T>> listsStart, int start, int end, int gap
-      , boolean hardend, boolean incLow, boolean incUp, boolean incEdge, boolean incOut) {
-    int off = (end-start)%gap;
-    if (!hardend && off>0) {
-      end+=gap-off;
-    }
-
-    ArrayList<ArrayList<T>> lists = new ArrayList<>();
-    ArrayList<T> between = new ArrayList<>();
-    if (incLow && incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i; j<=i+gap && j<=end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start; i<listsStart.size() && i<=end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else if (incLow && !incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i; j<i+gap && j<end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start; i<listsStart.size() && i<end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else if (!incLow && incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i+1; j<=i+gap && j<=end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start+1; i<listsStart.size() && i<=end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i+1; j<i+gap && j<end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start+1; i<listsStart.size() && i<end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    }
-    
-    if (incEdge && !incLow && start>=0) {
-      lists.get(0).addAll(listsStart.get(start));
-      between.addAll(listsStart.get(start));
-    }
-    if (incEdge && !incUp && end<listsStart.size()) {
-      lists.get(lists.size()-1).addAll(listsStart.get(end));
-      between.addAll(listsStart.get(end));
-    }
-    ArrayList<T> before = new ArrayList<>();
-    ArrayList<T> after = new ArrayList<>();
-    if (incOut || !(incLow||incEdge)) {
-      for (int i = 0; i<=start; i++) {
-        before.addAll(listsStart.get(i));
-      }
-    } else {
-      for (int i = 0; i<start; i++) {
-        before.addAll(listsStart.get(i));
-      }
-    }
-    if (incOut || !(incUp||incEdge)) {
-      for (int i = end; i<listsStart.size(); i++) {
-        after.addAll(listsStart.get(i));
-      }
-    } 
-    else {
-      for (int i = end+1; i<listsStart.size(); i++) {
-        after.addAll(listsStart.get(i));
-      }
-    }
-    if (before.size()>0) {
-      lists.add(before);
-    }
-    if (after.size()>0) {
-      lists.add(after);
-    }
-    if (between.size()>0) {
-      lists.add(between);
-    }
-    return lists;
-  }
-  
-  private <T> ArrayList<ArrayList<T>> transformLists(ArrayList<ArrayList<T>> listsStart, int start, int end, String gapString
-      , boolean hardend, boolean incLow, boolean incUp, boolean incEdge, boolean incOut) {
-    String[] stringGaps = gapString.split(",");
-    int[] gaps = new int[stringGaps.length];
-    for (int i = 0; i<gaps.length; i++) {
-      gaps[i] = Integer.parseInt(stringGaps[i]);
-    }
-    int bigGap = 0;
-    int last = gaps[gaps.length-1];
-    for (int i = 0; i<gaps.length-1; i++) {
-      bigGap += gaps[i];
-    }
-    int off = (end-start-bigGap)%last;
-    if (!hardend && off>0) {
-      end+=last-off;
-    }
-    
-    ArrayList<ArrayList<T>> lists = new ArrayList<>();
-    ArrayList<T> between = new ArrayList<>();
-    int gap = 0;
-    int gapCounter = 0;
-    if (incLow && incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        if (gapCounter<gaps.length) {
-          gap = gaps[gapCounter++];
-        }
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i; j<=i+gap && j<=end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start; i<listsStart.size() && i<=end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else if (incLow && !incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        if (gapCounter<gaps.length) {
-          gap = gaps[gapCounter++];
-        }
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i; j<i+gap && j<end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start; i<listsStart.size() && i<end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else if (!incLow && incUp) {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        if (gapCounter<gaps.length) {
-          gap = gaps[gapCounter++];
-        }
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i+1; j<=i+gap && j<=end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start+1; i<listsStart.size() && i<=end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    } else {
-      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
-        if (gapCounter<gaps.length) {
-          gap = gaps[gapCounter++];
-        }
-        ArrayList<T> list = new ArrayList<>();
-        for (int j = i+1; j<i+gap && j<end && j<listsStart.size(); j++) {
-          list.addAll(listsStart.get(j));
-        }
-        lists.add(list);
-      }
-      for (int i = start+1; i<listsStart.size() && i<end; i++) {
-        between.addAll(listsStart.get(i));
-      }
-    }
-    
-    if (incEdge && !incLow && start>=0) {
-      lists.get(0).addAll(listsStart.get(start));
-      between.addAll(listsStart.get(start));
-    }
-    if (incEdge && !incUp && end<listsStart.size()) {
-      lists.get(lists.size()-1).addAll(listsStart.get(end));
-      between.addAll(listsStart.get(end));
-    }
-    ArrayList<T> before = new ArrayList<>();
-    ArrayList<T> after = new ArrayList<>();
-    if (incOut || !(incLow||incEdge)) {
-      for (int i = 0; i<=start; i++) {
-        before.addAll(listsStart.get(i));
-      }
-    } else {
-      for (int i = 0; i<start; i++) {
-        before.addAll(listsStart.get(i));
-      }
-    }
-    if (incOut || !(incUp||incEdge)) {
-      for (int i = end; i<listsStart.size(); i++) {
-        after.addAll(listsStart.get(i));
-      }
-    } 
-    else {
-      for (int i = end+1; i<listsStart.size(); i++) {
-        after.addAll(listsStart.get(i));
-      }
-    }
-    if (before.size()>0) {
-      lists.add(before);
-    }
-    if (after.size()>0) {
-      lists.add(after);
-    }
-    if (between.size()>0) {
-      lists.add(between);
-    }
-    return lists;
-  }
-  
-}
diff --git solr/contrib/analytics/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java solr/contrib/analytics/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java
deleted file mode 100644
index 6a91401..0000000
--- solr/contrib/analytics/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java
+++ /dev/null
@@ -1,234 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analytics.util.valuesource;
-
-
-import org.apache.solr.analytics.AbstractAnalyticsStatsTest;
-import org.apache.solr.analytics.facet.AbstractAnalyticsFacetTest;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class FunctionTest extends AbstractAnalyticsStatsTest {
-  static String fileName = "/analytics/requestFiles/functions.txt";
-
-  static public final int INT = 71;
-  static public final int LONG = 36;
-  static public final int FLOAT = 93;
-  static public final int DOUBLE = 49;
-  static public final int DATE = 12;
-  static public final int STRING = 28;
-  static public final int NUM_LOOPS = 100;
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig-basic.xml","schema-analytics.xml");
-    h.update("<delete><query>*:*</query></delete>");
-    
-    for (int j = 0; j < NUM_LOOPS; ++j) {
-      int i = j%INT+1;
-      long l = j%LONG+1;
-      float f = j%FLOAT+1;
-      double d = j%DOUBLE+1;
-      double d0 = j%DOUBLE;
-      String dt = (1800+j%DATE) + "-06-30T23:59:59Z";
-      String s = "str" + (j%STRING);
-
-      double add_if = (double)i+f;
-      double add_ldf = (double)l+d+f;
-      double mult_if = (double)i*f;
-      double mult_ldf = (double)l*d*f;
-      double div_if = (double)i/f;
-      double div_ld = (double)l/d;
-      double pow_if = Math.pow(i,f);
-      double pow_ld = Math.pow(l,d);
-      double neg_i = (double)i*-1;
-      double neg_l = (double)l*-1;
-      String dm_2y = (1802+j%DATE) + "-06-30T23:59:59Z";
-      String dm_2m = (1800+j%DATE) + "-08-30T23:59:59Z";
-      String concat_first = "this is the first"+s;
-      String concat_second = "this is the second"+s;
-      String rev = new StringBuilder(s).reverse().toString();
-      
-      assertU(adoc(AbstractAnalyticsFacetTest.filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
-            "double_dd", "" + d,  "date_dtd", dt, "string_sd", s,
-            "add_if_dd", ""+add_if, "add_ldf_dd", ""+add_ldf, "mult_if_dd", ""+mult_if, "mult_ldf_dd", ""+mult_ldf,
-            "div_if_dd", ""+div_if, "div_ld_dd", ""+div_ld, "pow_if_dd", ""+pow_if, "pow_ld_dd", ""+pow_ld,
-            "neg_i_dd", ""+neg_i, "neg_l_dd", ""+neg_l, "const_8_dd", "8", "const_10_dd", "10", "dm_2y_dtd", dm_2y, "dm_2m_dtd", dm_2m,
-            "const_00_dtd", "1800-06-30T23:59:59Z", "const_04_dtd", "1804-06-30T23:59:59Z", "const_first_sd", "this is the first", "const_second_sd", "this is the second",
-            "concat_first_sd", concat_first, "concat_second_sd", concat_second, "rev_sd", rev, "miss_dd", ""+d0 )));
-      
-      
-      if (usually()) {
-        assertU(commit()); // to have several segments
-      }
-    }
-    
-    assertU(commit()); 
-    
-    setResponse(h.query(request(fileToStringArr(FunctionTest.class, fileName))));
-  }
-      
-  @Test
-  public void addTest() throws Exception { 
-    double result = (Double)getStatResult("ar", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("ar", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    // TODO checfk why asserted 2times
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-
-    result = (Double)getStatResult("ar", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("ar", "meanc", VAL_TYPE.DOUBLE);
-    assertTrue(result==calculated);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-  }
-  
-  @Test
-  public void multiplyTest() throws Exception { 
-    double result = (Double)getStatResult("mr", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("mr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-    
-    result = (Double)getStatResult("mr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("mr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-  }
-  
-  @Test
-  public void divideTest() throws Exception { 
-    Double result = (Double)getStatResult("dr", "sum", VAL_TYPE.DOUBLE);
-    Double calculated = (Double)getStatResult("dr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-    
-    result = (Double)getStatResult("dr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("dr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-  }
-  
-  @Test
-  public void powerTest() throws Exception { 
-    double result = (Double)getStatResult("pr", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("pr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-    
-    result = (Double)getStatResult("pr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("pr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-  }
-  
-  @Test
-  public void negateTest() throws Exception { 
-    double result = (Double)getStatResult("nr", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("nr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-    
-    result = (Double)getStatResult("nr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("nr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-  }
-
-  @Test 
-  public void absoluteValueTest() throws Exception {
-    double result = (Double)getStatResult("avr", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("avr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-    
-    result = (Double)getStatResult("avr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("avr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-  }
-  
-  @Test
-  public void constantNumberTest() throws Exception { 
-    double result = (Double)getStatResult("cnr", "sum", VAL_TYPE.DOUBLE);
-    double calculated = (Double)getStatResult("cnr", "sumc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    
-    result = (Double)getStatResult("cnr", "mean", VAL_TYPE.DOUBLE);
-    calculated = (Double)getStatResult("cnr", "meanc", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), result, calculated, 0.0);
-    assertEquals(getRawResponse(),  result, calculated, 0.0);
-  }
-  
-  @Test
-  public void dateMathTest() throws Exception {
-    String result = (String)getStatResult("dmr", "median", VAL_TYPE.DATE);
-    String calculated = (String)getStatResult("dmr", "medianc", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), result, calculated);
-    
-    result = (String)getStatResult("dmr", "max", VAL_TYPE.DATE);
-    calculated = (String)getStatResult("dmr", "maxc", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), result, calculated);
-  }
-  
-  @Test
-  public void constantDateTest() throws Exception { 
-    String result = (String)getStatResult("cdr", "median", VAL_TYPE.DATE);
-    String calculated = (String)getStatResult("cdr", "medianc", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), result, calculated);
-    assertEquals(getRawResponse(), result, calculated);
-    
-    result = (String)getStatResult("cdr", "max", VAL_TYPE.DATE);
-    calculated = (String)getStatResult("cdr", "maxc", VAL_TYPE.DATE);
-    assertEquals(getRawResponse(), result, calculated);
-  }
-  
-  @Test
-  public void constantStringTest() throws Exception { 
-    String result = (String)getStatResult("csr", "min", VAL_TYPE.STRING);
-    String calculated = (String)getStatResult("csr", "minc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-    
-    result = (String)getStatResult("csr", "max", VAL_TYPE.STRING);
-    calculated = (String)getStatResult("csr", "maxc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-  }
-  
-  @Test
-  public void concatenateTest() throws Exception { 
-    String result = (String)getStatResult("cr", "min", VAL_TYPE.STRING);
-    String calculated = (String)getStatResult("cr", "minc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-    
-    result = (String)getStatResult("cr", "max", VAL_TYPE.STRING);
-    calculated = (String)getStatResult("cr", "maxc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-  }
-  
-  @Test
-  public void reverseTest() throws Exception { 
-    String result = (String)getStatResult("rr", "min", VAL_TYPE.STRING);
-    String calculated = (String)getStatResult("rr", "minc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-    
-    result = (String)getStatResult("rr", "max", VAL_TYPE.STRING);
-    calculated = (String)getStatResult("rr", "maxc", VAL_TYPE.STRING);
-    assertEquals(getRawResponse(), result, calculated);
-  }
-  
-  @Test
-  public void missingTest() throws Exception { 
-    double min = (Double)getStatResult("ms", "min", VAL_TYPE.DOUBLE);
-    double max = (Double)getStatResult("ms", "max", VAL_TYPE.DOUBLE);
-    assertEquals(getRawResponse(), 48.0d, max, 0.0);
-    assertEquals(getRawResponse(), 1.0d, min, 0.0);
-  }
-
-}
diff --git solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
index 981577c..3ca6b12 100644
--- solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
+++ solr/contrib/clustering/src/test-files/clustering/solr/collection1/conf/schema.xml
@@ -244,7 +244,7 @@
              See the Java Regular Expression documentation for more
              infomation on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
index 8eb1bde..a40174c 100644
--- solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
+++ solr/contrib/dataimporthandler/src/test-files/dih/solr/collection1/conf/dataimport-solr_id-schema.xml
@@ -229,7 +229,7 @@
              See the Java Regular Expression documentation for more
              infomation on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
index fe70b37..997dc3c 100644
--- solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
+++ solr/contrib/uima/src/test-files/uima/solr/collection1/conf/schema.xml
@@ -361,7 +361,7 @@
           documentation for more information on pattern and replacement
           string syntax.
 
-          http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+          http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
         -->
         <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])"
           replacement="" replace="all" />
diff --git solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
index f63705b..62d1f91 100644
--- solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
+++ solr/contrib/uima/src/test-files/uima/uima-tokenizers-schema.xml
@@ -357,7 +357,7 @@
           documentation for more information on pattern and replacement
           string syntax.
 
-          http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+          http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
         -->
         <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])"
           replacement="" replace="all" />
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java
new file mode 100644
index 0000000..fdcf66b
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/BasicAccumulator.java
@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Date;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.solr.analytics.expression.Expression;
+import org.apache.solr.analytics.expression.ExpressionFactory;
+import org.apache.solr.analytics.request.AnalyticsRequest;
+import org.apache.solr.analytics.request.ExpressionRequest;
+import org.apache.solr.analytics.statistics.StatsCollector;
+import org.apache.solr.analytics.statistics.StatsCollectorSupplierFactory;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.search.DocSet;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.base.Supplier;
+
+/**
+ * A <code>BasicAccumulator</code> manages the ValueCounters and Expressions without regard to Facets.
+ */
+public class BasicAccumulator extends ValueAccumulator {
+  private static final Logger log = LoggerFactory.getLogger(BasicAccumulator.class);
+  protected final SolrIndexSearcher searcher;
+  protected final AnalyticsRequest request;
+  protected final DocSet docs;
+  protected final Supplier<StatsCollector[]> statsCollectorArraySupplier;
+  protected final StatsCollector[] statsCollectors;
+  protected final Expression[] expressions;
+  protected final String[] expressionNames;
+  protected final String[] expressionStrings;
+  protected final Set<String> hiddenExpressions;
+  protected AtomicReaderContext context = null;
+  
+  public BasicAccumulator(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request) throws IOException {
+    this.searcher = searcher;
+    this.docs = docs;
+    this.request = request;
+    final List<ExpressionRequest> exRequests = new ArrayList<ExpressionRequest>(request.getExpressions()); // make a copy here
+    Collections.sort(exRequests);
+    log.info("Processing request '"+request.getName()+"'");
+    statsCollectorArraySupplier = StatsCollectorSupplierFactory.create(searcher.getSchema(), exRequests);
+    statsCollectors = statsCollectorArraySupplier.get();
+    int size = exRequests.size();
+    expressionNames = new String[size];
+    expressionStrings = new String[size];
+    int count = 0;
+    for (ExpressionRequest expRequest : exRequests) {
+      expressionNames[count] = expRequest.getName();
+      expressionStrings[count++] = expRequest.getExpressionString();
+    }
+    expressions = makeExpressions(statsCollectors);
+    hiddenExpressions = request.getHiddenExpressions();
+  }
+  
+  @Override
+  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
+    this.context = context;
+    for (StatsCollector counter : statsCollectors) {
+      counter.setNextReader(context);
+    }
+  }
+ 
+  public static BasicAccumulator create(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request) throws IOException {
+    return new BasicAccumulator(searcher,docs,request);
+  }
+  
+  /**
+   * Passes the documents on to the {@link StatsCollector}s to be collected.
+   * @param doc Document to collect from
+   */
+  @Override
+  public void collect(int doc) throws IOException {
+    for (StatsCollector statsCollector : statsCollectors) {
+      statsCollector.collect(doc);
+    }
+  }
+  
+  @Override
+  public void compute() {
+    for (StatsCollector statsCollector : statsCollectors) {
+      statsCollector.compute();
+    }
+  }
+  
+  public NamedList<?> export(){
+    NamedList<Object> base = new NamedList<>();
+    for (int count = 0; count < expressions.length; count++) {
+      if (!hiddenExpressions.contains(expressionNames[count])) {
+        base.add(expressionNames[count], expressions[count].getValue());
+      }
+    }
+    return base;
+  }
+  
+  /**
+   * Builds an array of Expressions with the given list of counters
+   * @param statsCollectors the stats collectors
+   * @return The array of Expressions
+   */
+  public Expression[] makeExpressions(StatsCollector[] statsCollectors) {
+   Expression[] expressions = new Expression[expressionStrings.length];
+    for (int count = 0; count < expressionStrings.length; count++) {
+      expressions[count] = ExpressionFactory.create(expressionStrings[count], statsCollectors);
+    }
+    return expressions;
+  }
+  
+  /**
+   * Returns the value of an expression to use in a field or query facet.
+   * @param expressionName the name of the expression
+   * @return String String representation of pivot value
+   */
+  @SuppressWarnings({ "deprecation", "rawtypes" })
+  public String getResult(String expressionName) {
+    for (int count = 0; count < expressionNames.length; count++) {
+      if (expressionName.equals(expressionNames[count])) {
+        Comparable value = expressions[count].getValue();
+        if (value.getClass().equals(Date.class)) {
+          return TrieDateField.formatExternal((Date)value);
+        } else {
+          return value.toString();
+        }
+      }
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST, "Pivot expression "+expressionName+" not found.");
+  }
+
+  /**
+   * Used for JMX stats collecting. Counts the number of stats requests
+   * @return number of unique stats collectors
+   */
+  public long getNumStatsCollectors() {
+    return statsCollectors.length;
+  }
+
+  /**
+   * Used for JMX stats collecting. Counts the number of queries in all query facets
+   * @return number of queries requested in all query facets.
+   */
+  public long getNumQueries() {
+    return 0l;
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
new file mode 100644
index 0000000..fb6d81d
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
@@ -0,0 +1,723 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.Date;
+import java.util.HashSet;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+import java.util.TreeMap;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.Query;
+import org.apache.solr.analytics.accumulator.facet.FacetValueAccumulator;
+import org.apache.solr.analytics.accumulator.facet.FieldFacetAccumulator;
+import org.apache.solr.analytics.accumulator.facet.QueryFacetAccumulator;
+import org.apache.solr.analytics.accumulator.facet.RangeFacetAccumulator;
+import org.apache.solr.analytics.expression.Expression;
+import org.apache.solr.analytics.expression.ExpressionFactory;
+import org.apache.solr.analytics.request.AnalyticsContentHandler;
+import org.apache.solr.analytics.request.AnalyticsRequest;
+import org.apache.solr.analytics.request.FieldFacetRequest;
+import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
+import org.apache.solr.analytics.request.QueryFacetRequest;
+import org.apache.solr.analytics.request.RangeFacetRequest;
+import org.apache.solr.analytics.statistics.StatsCollector;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.analytics.util.RangeEndpointCalculator;
+import org.apache.solr.analytics.util.RangeEndpointCalculator.FacetRange;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.schema.SchemaField;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.search.DocSet;
+import org.apache.solr.search.QParser;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.apache.solr.search.SyntaxError;
+
+import com.google.common.collect.Iterables;
+
+/**
+ * A <code>FacetingAccumulator</code> manages the StatsCollectors and Expressions for facets.
+ */
+public class FacetingAccumulator extends BasicAccumulator implements FacetValueAccumulator {
+  public static final String MISSING_VALUE = "(MISSING)";
+  protected boolean basicsAndFieldFacetsComputed;
+  protected int leafNum;
+  protected AtomicReaderContext leaf;
+  protected final AnalyticsRequest analyticsRequest;
+  protected final Map<String,Map<String,Expression[]>> fieldFacetExpressions;
+  protected final Map<String,Map<String,Expression[]>> rangeFacetExpressions;
+  protected final Map<String,Map<String,Expression[]>> queryFacetExpressions;
+  protected final Map<String,Map<String,StatsCollector[]>> fieldFacetCollectors;
+  protected final Map<String,Map<String,StatsCollector[]>> rangeFacetCollectors;
+  protected final Map<String,Map<String,StatsCollector[]>> queryFacetCollectors;
+  protected final List<FieldFacetAccumulator> facetAccumulators;
+  protected final Set<String> hiddenFieldFacets;
+  /** the current value of this stat field */
+  protected final SolrQueryRequest queryRequest;
+  
+  protected List<RangeFacetRequest> rangeFacets = null;
+  protected List<QueryFacetRequest> queryFacets = null;
+  
+  protected long queryCount;
+  
+  public FacetingAccumulator(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request, SolrQueryRequest queryRequest) throws IOException {
+    // The parent Basic Accumulator keeps track of overall stats while
+    // the Faceting Accumulator only manages the facet stats
+    super(searcher, docs, request);
+    this.analyticsRequest = request;
+    this.queryRequest = queryRequest;
+    basicsAndFieldFacetsComputed = false;
+    List<FieldFacetRequest> fieldFreqs = request.getFieldFacets();
+    List<RangeFacetRequest> rangeFreqs = request.getRangeFacets();
+    List<QueryFacetRequest> queryFreqs = request.getQueryFacets();
+
+    this.fieldFacetExpressions = new TreeMap<>();
+    this.rangeFacetExpressions = new LinkedHashMap<>(rangeFreqs.size());
+    this.queryFacetExpressions = new LinkedHashMap<>(queryFreqs.size());
+    this.fieldFacetCollectors = new LinkedHashMap<>(fieldFreqs.size());
+    this.rangeFacetCollectors = new LinkedHashMap<>(rangeFreqs.size());
+    this.queryFacetCollectors = new LinkedHashMap<>(queryFreqs.size());
+    this.facetAccumulators = new ArrayList<>();
+    this.hiddenFieldFacets = new HashSet<>();
+    
+    /**
+     * For each field facet request add a bucket to the {@link Expression} map and {@link StatsCollector} map.
+     * Field facets are computed during the initial collection of documents, therefore
+     * the FieldFacetAccumulators are created initially.
+     */
+    for( FieldFacetRequest freq : fieldFreqs ){
+      final FieldFacetRequest fr = (FieldFacetRequest) freq;
+      if (fr.isHidden()) {
+        hiddenFieldFacets.add(fr.getName());
+      }
+      final SchemaField ff = fr.getField();
+      final FieldFacetAccumulator facc = FieldFacetAccumulator.create(searcher, this, ff);
+      facetAccumulators.add(facc);
+      fieldFacetExpressions.put(freq.getName(), new TreeMap<String, Expression[]>() );
+      fieldFacetCollectors.put(freq.getName(), new TreeMap<String,StatsCollector[]>());
+    }
+    /**
+     * For each range and query facet request add a bucket to the corresponding
+     * {@link Expression} map and {@link StatsCollector} map.
+     * Range and Query Facets are computed in the post processing, so the accumulators
+     * are not created initially.
+     */
+    for( RangeFacetRequest freq : rangeFreqs ){
+      if( rangeFacets == null ) rangeFacets = new ArrayList<>();
+      rangeFacets.add(freq);
+      rangeFacetExpressions.put(freq.getName(), new LinkedHashMap<String,Expression[]>() );
+      rangeFacetCollectors.put(freq.getName(), new LinkedHashMap<String,StatsCollector[]>());
+    }
+    for( QueryFacetRequest freq : queryFreqs ){
+      if( queryFacets == null ) queryFacets = new ArrayList<>();
+      queryFacets.add(freq);
+      queryFacetExpressions.put(freq.getName(), new LinkedHashMap<String,Expression[]>() );
+      queryFacetCollectors.put(freq.getName(), new LinkedHashMap<String,StatsCollector[]>());
+    }
+    this.queryCount = 0l;
+  }
+  
+  public static FacetingAccumulator create(SolrIndexSearcher searcher, DocSet docs, AnalyticsRequest request, SolrQueryRequest queryRequest) throws IOException {
+    return new FacetingAccumulator(searcher,docs,request,queryRequest);
+  }
+
+  /**
+   * Update the readers for the {@link BasicAccumulator}, field facets and field facet {@link StatsCollector}s.
+   * @param context The context to read documents from.
+   * @throws IOException if there is an error setting the next reader
+   */
+  @Override
+  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
+    super.doSetNextReader(context);
+    for( Map<String,StatsCollector[]> valueList : fieldFacetCollectors.values() ){
+      for (StatsCollector[] statsCollectorList : valueList.values()) {
+        for (StatsCollector statsCollector : statsCollectorList) {
+          statsCollector.setNextReader(context);
+        }
+      }
+    }
+    for (FieldFacetAccumulator fa : facetAccumulators) {
+      fa.getLeafCollector(context);
+    }
+  }
+  
+  /**
+   * Updates the reader for all of the range facet {@link StatsCollector}s.
+   * @param context The context to read documents from.
+   * @throws IOException if there is an error setting the next reader
+   */
+  public void setRangeStatsCollectorReaders(AtomicReaderContext context) throws IOException {
+    super.getLeafCollector(context);
+    for( Map<String,StatsCollector[]> rangeList : rangeFacetCollectors.values() ){
+      for (StatsCollector[] statsCollectorList : rangeList.values()) {
+        for (StatsCollector statsCollector : statsCollectorList) {
+          statsCollector.setNextReader(context);
+        }
+      }
+    }
+  }
+
+  
+  /**
+   * Updates the reader for all of the query facet {@link StatsCollector}s.
+   * @param context The context to read documents from.
+   * @throws IOException if there is an error setting the next reader
+   */
+  public void setQueryStatsCollectorReaders(AtomicReaderContext context) throws IOException {
+    super.getLeafCollector(context);
+    for( Map<String,StatsCollector[]> queryList : queryFacetCollectors.values() ){
+      for (StatsCollector[] statsCollectorList : queryList.values()) {
+        for (StatsCollector statsCollector : statsCollectorList) {
+          statsCollector.setNextReader(context);
+        }
+      }
+    }
+  }
+
+  /**
+   * Called from Analytics stats, adds documents to the field 
+   * facets and the super {@link BasicAccumulator}.
+   */
+  @Override
+  public void collect(int doc) throws IOException {
+    for( FieldFacetAccumulator fa : facetAccumulators ){
+      fa.collect(doc);
+    }
+    super.collect(doc);
+  }
+  
+  /**
+   * Given a document, fieldFacet field and facetValue, adds the document to the
+   * {@link StatsCollector}s held in the bucket corresponding to the fieldFacet field and facetValue.
+   * Called during initial document collection.
+   */
+  @Override
+  public void collectField(int doc, String facetField, String facetValue) throws IOException {
+    Map<String,StatsCollector[]> map = fieldFacetCollectors.get(facetField);
+    StatsCollector[] statsCollectors = map.get(facetValue);
+    // If the facetValue has not been seen yet, a StatsCollector array is
+    // created and associated with that bucket.
+    if( statsCollectors == null ){
+      statsCollectors = statsCollectorArraySupplier.get();
+      map.put(facetValue,statsCollectors);
+      fieldFacetExpressions.get(facetField).put(facetValue,makeExpressions(statsCollectors));
+      for (StatsCollector statsCollector : statsCollectors) {
+        statsCollector.setNextReader(context);
+      }
+    }
+    for (StatsCollector statsCollector : statsCollectors) {
+      statsCollector.collect(doc);
+    }
+  }
+  
+  /**
+   * Given a document, rangeFacet field and range, adds the document to the
+   * {@link StatsCollector}s held in the bucket corresponding to the rangeFacet field and range.
+   * Called during post processing.
+   */
+  @Override
+  public void collectRange(int doc, String facetField, String range) throws IOException {
+    Map<String,StatsCollector[]> map = rangeFacetCollectors.get(facetField);
+    StatsCollector[] statsCollectors = map.get(range);
+    // If the range has not been seen yet, a StatsCollector array is
+    // created and associated with that bucket.
+    if( statsCollectors == null ){
+      statsCollectors = statsCollectorArraySupplier.get();
+      map.put(range,statsCollectors);
+      rangeFacetExpressions.get(facetField).put(range,makeExpressions(statsCollectors));
+      for (StatsCollector statsCollector : statsCollectors) {
+        statsCollector.setNextReader(context);
+      }
+    }
+    for (StatsCollector statsCollector : statsCollectors) {
+      statsCollector.collect(doc);
+    }
+  }
+  
+  /**
+   * Given a document, queryFacet name and query, adds the document to the
+   * {@link StatsCollector}s held in the bucket corresponding to the queryFacet name and query.
+   * Called during post processing.
+   */
+  @Override
+  public void collectQuery(int doc, String facetName, String query) throws IOException {
+    Map<String,StatsCollector[]> map = queryFacetCollectors.get(facetName);
+    StatsCollector[] statsCollectors = map.get(query);
+    // If the query has not been seen yet, a StatsCollector array is
+    // created and associated with that bucket.
+    if( statsCollectors == null ){
+      statsCollectors = statsCollectorArraySupplier.get();
+      map.put(query,statsCollectors);
+      queryFacetExpressions.get(facetName).put(query,makeExpressions(statsCollectors));
+      for (StatsCollector statsCollector : statsCollectors) {
+        statsCollector.setNextReader(context);
+      }
+    }
+    for (StatsCollector statsCollector : statsCollectors) {
+      statsCollector.collect(doc);
+    }
+  }
+
+  /**
+   * A comparator to compare expression values for field facet sorting.
+   */
+  public static class EntryComparator implements Comparator<Entry<String,Expression[]>> {
+    private final Comparator<Expression> comp;
+    private final int comparatorExpressionPlace;
+   
+    public EntryComparator(Comparator<Expression> comp, int comparatorExpressionPlace) {
+      this.comp = comp;
+      this.comparatorExpressionPlace = comparatorExpressionPlace;
+    }
+
+    @Override
+    public int compare(Entry<String,Expression[]> o1, Entry<String,Expression[]> o2) {
+      return comp.compare(o1.getValue()[comparatorExpressionPlace], o2.getValue()[comparatorExpressionPlace]);
+    }
+  }
+  
+  /**
+   * Finalizes the statistics within the each facet bucket before exporting;
+   */
+  @Override
+  public void compute() {
+    if (!basicsAndFieldFacetsComputed) {
+      super.compute();
+      for( Map<String, StatsCollector[]> f : fieldFacetCollectors.values() ){
+        for( StatsCollector[] arr : f.values() ){
+          for( StatsCollector b : arr ){
+            b.compute();
+          }
+        }
+      }
+      basicsAndFieldFacetsComputed = true;
+    }
+  }
+  
+  /**
+   * Finalizes the statistics within the a specific query facet before exporting;
+   */
+  public void computeQueryFacet(String facet) {
+    Map<String, StatsCollector[]> f = queryFacetCollectors.get(facet);
+    for( StatsCollector[] arr : f.values() ){
+      for( StatsCollector b : arr ){
+        b.compute();
+      }
+    }
+  }
+  
+  /**
+   * Finalizes the statistics within the a specific range facet before exporting;
+   */
+  public void computeRangeFacet(String facet) {
+    Map<String, StatsCollector[]> f = rangeFacetCollectors.get(facet);
+    for( StatsCollector[] arr : f.values() ){
+      for( StatsCollector b : arr ){
+        b.compute();
+      }
+    }
+  }
+  
+  /**
+   * Returns the value of an expression to use in a range or query facet.
+   * @param expressionName the name of the expression
+   * @param fieldFacet the facet field
+   * @param facetValue the facet value
+   * @return String String representation of pivot value
+   */
+  @SuppressWarnings({ "deprecation", "rawtypes" })
+  public String getResult(String expressionName, String fieldFacet, String facetValue) {
+    if (facetValue.contains(AnalyticsParams.RESULT) && !facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
+      try {
+        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
+        if (pivotStr.length==1) {
+          facetValue = getResult(pivotStr[0]);
+        } else if (pivotStr.length==3) {
+          facetValue = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
+        } else {
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" has an invalid amount of arguments.");
+        }
+      } catch (IndexOutOfBoundsException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" is invalid. Lacks parentheses.",e);
+      }
+    } 
+    if (fieldFacetExpressions.get(fieldFacet)!=null) {
+      Expression[] facetExpressions = fieldFacetExpressions.get(fieldFacet).get(facetValue);
+      for (int count = 0; count < expressionNames.length; count++) {
+        if (expressionName.equals(expressionNames[count])) {
+          Comparable value = facetExpressions[count].getValue();
+          if (value.getClass().equals(Date.class)) {
+            return TrieDateField.formatExternal((Date)value);
+          } else {
+            return value.toString();
+          }
+        }
+      }
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"Field Facet Pivot expression "+expressionName+" not found.");
+  }
+  
+  /**
+   * Returns the value of an expression to use in a range or query facet.
+   * @param currentFacet the name of the current facet
+   * @param expressionName the name of the expression
+   * @param queryFacet the facet query
+   * @param facetValue the field value
+   * @return String String representation of pivot value
+   */
+  @SuppressWarnings({ "deprecation", "rawtypes" })
+  public String getQueryResult(String currentFacet, String expressionName, String queryFacet, String facetValue) {
+    if (facetValue.contains(AnalyticsParams.RESULT) && !facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
+      try {
+        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
+        if (pivotStr.length==1) {
+          facetValue = getResult(pivotStr[0]);
+        } else if (pivotStr.length==3) {
+          facetValue = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
+        } else {
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+facetValue+" has an invalid amount of arguments.");
+        }
+      } catch (IndexOutOfBoundsException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" is invalid. Lacks parentheses.",e);
+      }
+    } 
+    if (facetValue.contains(AnalyticsParams.QUERY_RESULT)) {
+      try {
+        String[] pivotStr = ExpressionFactory.getArguments(facetValue.substring(facetValue.indexOf('(')+1,facetValue.lastIndexOf(')')).trim());
+        if (pivotStr.length==1) {
+          facetValue = getResult(pivotStr[0]);
+        } else if (pivotStr.length==3) {
+          facetValue = getQueryResult(currentFacet,pivotStr[0],pivotStr[1],pivotStr[2]);
+        } else {
+          throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" has an invalid amount of arguments.");
+        }
+      } catch (IndexOutOfBoundsException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+facetValue+" is invalid. Lacks parentheses.",e);
+      }
+    } 
+    if (queryFacetExpressions.get(queryFacet)!=null) {
+      Expression[] facetExpressions = queryFacetExpressions.get(queryFacet).get(facetValue);
+      for (int count = 0; count < expressionNames.length; count++) {
+        if (expressionName.equals(expressionNames[count])) {
+          Comparable value = facetExpressions[count].getValue();
+          if (value.getClass().equals(Date.class)) {
+            return TrieDateField.formatExternal((Date)value);
+          } else {
+            return value.toString();
+          }
+        }
+      }
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"Field Facet Pivot expression "+expressionName+" not found.");
+  }
+  
+  @Override
+  @SuppressWarnings("unchecked")
+  public NamedList<?> export() {
+    final NamedList<Object> base = (NamedList<Object>)super.export();
+    NamedList<NamedList<?>> facetList = new NamedList<>();
+    
+    // Add the field facet buckets to the output
+    base.add("fieldFacets",facetList);
+    for( FieldFacetRequest freq : request.getFieldFacets() ){
+      final String name = freq.getName();
+      if (hiddenFieldFacets.contains(name)) {
+        continue;
+      }
+      final Map<String,Expression[]> buckets = fieldFacetExpressions.get(name);
+      final NamedList<Object> bucketBase = new NamedList<>();
+
+      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
+      
+      final FieldFacetRequest fr = (FieldFacetRequest) freq;
+     
+      final FacetSortSpecification sort = fr.getSort();
+      final int limit = fr.getLimit();
+      final int offset = fr.getOffset();
+      final boolean showMissing = fr.showsMissing();
+      if (!showMissing) {
+        buckets.remove(MISSING_VALUE);
+      }
+      // Sorting the buckets if a sort specification is provided
+      if( sort != null && buckets.values().iterator().hasNext()){
+        int sortPlace = Arrays.binarySearch(expressionNames, sort.getStatistic());
+        final Expression first = buckets.values().iterator().next()[sortPlace];
+        final Comparator<Expression> comp = (Comparator<Expression>) first.comparator(sort.getDirection());
+        
+        final List<Entry<String,Expression[]>> sorted = new ArrayList<>(buckets.size());
+        Iterables.addAll(sorted, iter);
+        Collections.sort(sorted, new EntryComparator(comp,sortPlace));
+        iter = sorted;
+      }
+      // apply the limit
+      if( limit > AnalyticsContentHandler.DEFAULT_FACET_LIMIT ){
+        if( offset > 0 ){
+          iter = Iterables.skip(iter, offset);
+        }
+        iter = Iterables.limit(iter, limit);
+      }
+      
+      // Export each expression in the bucket.
+      for( Entry<String,Expression[]> bucket : iter ){
+        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
+      }
+      
+      facetList.add(name, bucketBase);
+    }
+
+    // Add the range facet buckets to the output
+    facetList = new NamedList<>();
+    base.add("rangeFacets",facetList);
+    for( RangeFacetRequest freq : request.getRangeFacets() ){
+      final String name = freq.getName();
+      final Map<String,Expression[]> buckets = rangeFacetExpressions.get(name);
+      final NamedList<Object> bucketBase = new NamedList<>();
+
+      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
+      
+      for( Entry<String,Expression[]> bucket : iter ){
+        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
+      }
+      
+      facetList.add(name, bucketBase);
+    }
+    
+    // Add the query facet buckets to the output
+    facetList = new NamedList<>();
+    base.add("queryFacets",facetList);
+    for( QueryFacetRequest freq : request.getQueryFacets() ){
+      final String name = freq.getName();
+      final Map<String,Expression[]> buckets = queryFacetExpressions.get(name);
+      final NamedList<Object> bucketBase = new NamedList<>();
+
+      Iterable<Entry<String,Expression[]>> iter = buckets.entrySet();
+      
+      for( Entry<String,Expression[]> bucket : iter ){
+        bucketBase.add(bucket.getKey(),export(bucket.getValue()));
+      }
+      
+      facetList.add(name, bucketBase);
+    }
+
+    return base;
+  }
+  
+  /**
+   * Exports a list of expressions as a NamedList
+   * @param expressionArr an array of expressions
+   * @return named list of expressions
+   */
+  public NamedList<?> export(Expression[] expressionArr) {
+    NamedList<Object> base = new NamedList<>();
+    for (int count = 0; count < expressionArr.length; count++) {
+      if (!hiddenExpressions.contains(expressionNames[count])) {
+        base.add(expressionNames[count], expressionArr[count].getValue());
+      }
+    }
+    return base;
+  }
+
+  /**
+   * Processes the query and range facets.
+   * Must be called if range and/or query facets are supported.
+   */
+  @Override
+  public void postProcess() throws IOException {
+    super.compute();
+    for( Map<String, StatsCollector[]> f : fieldFacetCollectors.values() ){
+      for( StatsCollector[] arr : f.values() ){
+        for( StatsCollector b : arr ){
+          b.compute();
+        }
+      }
+    }
+    basicsAndFieldFacetsComputed = true;
+    final Filter filter = docs.getTopFilter();
+    if( rangeFacets != null ){
+      processRangeFacets(filter); 
+    }
+    if( queryFacets != null ){
+      processQueryFacets(filter); 
+    }
+  }
+  
+  /**
+   * Initiates the collecting of query facets
+   * @param filter the base filter to work against
+   * @throws IOException if searching failed
+   */
+  public void processQueryFacets(final Filter filter) throws IOException {
+    for( QueryFacetRequest qfr : queryFacets ){
+      for( String query : qfr.getQueries() ){
+        if (query.contains(AnalyticsParams.RESULT) && !query.contains(AnalyticsParams.QUERY_RESULT)) {
+          try {
+            String[] pivotStr = ExpressionFactory.getArguments(query.substring(query.indexOf('(')+1,query.lastIndexOf(')')).trim());
+            if (pivotStr.length==1) {
+              query = getResult(pivotStr[0]);
+            } else if (pivotStr.length==3) {
+              query = getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
+            } else {
+              throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" has an invalid amount of arguments.");
+            }
+          } catch (IndexOutOfBoundsException e) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" is invalid. Lacks parentheses.",e);
+          }
+        } else if (query.contains(AnalyticsParams.QUERY_RESULT)) {
+          try {
+            String[] pivotStr = ExpressionFactory.getArguments(query.substring(query.indexOf('(')+1,query.lastIndexOf(')')).trim());
+            if (pivotStr.length==3) {
+              query = getQueryResult(qfr.getName(),pivotStr[0],pivotStr[1],pivotStr[2]);
+            } else {
+              throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" has an invalid amount of arguments.");
+            }
+          } catch (IndexOutOfBoundsException e) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"Result request "+query+" is invalid. Lacks parentheses.",e);
+          }
+        }
+        QueryFacetAccumulator qAcc = new QueryFacetAccumulator(this,qfr.getName(),query);
+        final Query q;
+        try {
+          q = QParser.getParser(query, null, queryRequest).getQuery();
+        } catch( SyntaxError e ){
+          throw new SolrException(ErrorCode.BAD_REQUEST,"Invalid query '"+query+"'",e);
+        }
+        // The searcher sends docIds to the QueryFacetAccumulator which forwards
+        // them to <code>collectQuery()</code> in this class for collection.
+        searcher.search(q, filter, qAcc);
+        computeQueryFacet(qfr.getName());
+        queryCount++;
+      }
+    }
+  }
+  
+  @Override
+  public long getNumQueries() {
+    return queryCount;
+  }
+
+  /**
+   * Initiates the collecting of range facets
+   * @param filter the base filter to use
+   * @throws IOException if searching fails
+   */
+  public void processRangeFacets(final Filter filter) throws IOException {
+    for( RangeFacetRequest rfr : rangeFacets ){
+      String[] pivotStr;
+      String start = rfr.getStart();
+      if (start.contains(AnalyticsParams.QUERY_RESULT)) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"Query result requests can not be used in Range Facets");
+      } else if (start.contains(AnalyticsParams.RESULT)) {
+        try {
+          pivotStr = ExpressionFactory.getArguments(start.substring(start.indexOf('(')+1,start.indexOf(')')).trim());
+          if (pivotStr.length==1) {
+            rfr.setStart(getResult(pivotStr[0]));
+          } else if (pivotStr.length==3) {
+            rfr.setStart(getResult(pivotStr[0],pivotStr[1],pivotStr[2]));
+          } else {
+            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+start+" has an invalid amount of arguments.");
+          }
+        } catch (IndexOutOfBoundsException e) {
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+start+" is invalid. Lacks parentheses.",e);
+        }
+      }
+      String end = rfr.getEnd();
+      if (end.contains(AnalyticsParams.QUERY_RESULT)) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "Query result requests can not be used in Range Facets");
+      } else if (end.contains(AnalyticsParams.RESULT)) {
+        try {
+          pivotStr = ExpressionFactory.getArguments(end.substring(end.indexOf('(')+1,end.indexOf(')')).trim());
+          if (pivotStr.length==1) {
+            rfr.setEnd(getResult(pivotStr[0]));
+          } else if (pivotStr.length==3) {
+            rfr.setEnd(getResult(pivotStr[0],pivotStr[1],pivotStr[2]));
+          } else {
+            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+end+" has an invalid amount of arguments.");
+          }
+        } catch (IndexOutOfBoundsException e) {
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+end+" is invalid. Lacks parentheses.",e);
+        }
+      }
+      String[] gaps = rfr.getGaps();
+      for (int count = 0; count<gaps.length; count++){
+        String gap = gaps[count];
+        if (gap.contains(AnalyticsParams.QUERY_RESULT)) {
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Query result requests can not be used in Range Facets");
+        } else if (gap.contains(AnalyticsParams.RESULT)) {
+          try {
+            pivotStr = ExpressionFactory.getArguments(gap.substring(gap.indexOf('(')+1,gap.indexOf(')')).trim());
+            if (pivotStr.length==1) {
+              gaps[count]=getResult(pivotStr[0]);
+            } else if (pivotStr.length==3) {
+              gaps[count]=getResult(pivotStr[0],pivotStr[1],pivotStr[2]);
+            } else {
+              throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+gap+" has an invalid amount of arguments.");
+            }
+          } catch (IndexOutOfBoundsException e) {
+            throw new SolrException(ErrorCode.BAD_REQUEST, "Result request "+gap+" is invalid. Lacks parentheses.",e);
+          }
+        }
+      }
+      // Computes the end points of the ranges in the rangeFacet
+      final RangeEndpointCalculator<? extends Comparable<?>> rec = RangeEndpointCalculator.create(rfr);
+      final SchemaField sf = rfr.getField();
+      
+      // Create a rangeFacetAccumulator for each range and 
+      // collect the documents for that range.
+      for( FacetRange range : rec.getRanges() ){
+        final String upper;
+        final String lower;
+        String facetValue = "";
+        if( range.lower == null ){
+          facetValue = "(*";
+          lower = null;
+        } else {
+          lower = range.lower;
+          facetValue = ((range.includeLower)?"[":"(") + range.lower;
+        }
+        facetValue+=" TO ";
+        if( range.upper == null ){
+          upper = null;
+          facetValue += "*)";
+        } else {
+          upper = range.upper;
+          facetValue += range.upper + ((range.includeUpper)?"]":")");
+        }
+        
+        Query q = sf.getType().getRangeQuery(null, sf, lower, upper, range.includeLower,range.includeUpper);
+        RangeFacetAccumulator rAcc = new RangeFacetAccumulator(this,rfr.getName(),facetValue);
+        // The searcher sends docIds to the RangeFacetAccumulator which forwards
+        // them to <code>collectRange()</code> in this class for collection.
+        searcher.search(q, filter, rAcc);
+        computeRangeFacet(sf.getName());
+      }
+    }
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java
new file mode 100644
index 0000000..90b8713
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/ValueAccumulator.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.search.LeafCollector;
+import org.apache.lucene.search.SimpleCollector;
+import org.apache.solr.common.util.NamedList;
+
+/**
+ * Abstract Collector that manages all StatsCollectors, Expressions and Facets.
+ */
+public abstract class ValueAccumulator extends SimpleCollector {
+  
+  /**
+   * Finalizes the statistics within each StatsCollector.
+   * Must be called before <code>export()</code>.
+   */
+  public abstract void compute();
+  public abstract NamedList<?> export();
+  
+  public void postProcess() throws IOException {
+    // NOP
+  }
+
+  @Override
+  public boolean acceptsDocsOutOfOrder() {
+    return true;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java
new file mode 100644
index 0000000..856f45f
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FacetValueAccumulator.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator.facet;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+
+/**
+ * Interface that describes the methods needed for an Accumulator to be able to handle 
+ * fieldFacets, rangeFacets and queryFacets.
+ */
+public interface FacetValueAccumulator {
+
+  void collectField(int doc, String facetName, String facetValue) throws IOException;
+  void collectQuery(int doc, String facetName, String facetValue) throws IOException;
+  void collectRange(int doc, String facetName, String facetValue) throws IOException;
+  void setQueryStatsCollectorReaders(AtomicReaderContext context) throws IOException;
+  void setRangeStatsCollectorReaders(AtomicReaderContext context) throws IOException;
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java
new file mode 100644
index 0000000..0d04bfd
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/facet/FieldFacetAccumulator.java
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator.facet;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.solr.analytics.accumulator.FacetingAccumulator;
+import org.apache.solr.analytics.accumulator.ValueAccumulator;
+import org.apache.solr.analytics.util.AnalyticsParsers;
+import org.apache.solr.analytics.util.AnalyticsParsers.NumericParser;
+import org.apache.solr.analytics.util.AnalyticsParsers.Parser;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.schema.SchemaField;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.search.SolrIndexSearcher;
+
+/**
+ * An Accumulator that manages the faceting for fieldFacets.
+ * Collects the field facet values.
+ */
+public class FieldFacetAccumulator extends ValueAccumulator {
+  protected final Parser parser;
+  protected final FacetValueAccumulator parent;
+  protected final String name;
+  protected final SolrIndexSearcher searcher;
+  protected final SchemaField schemaField;
+  protected final boolean multiValued;
+  protected final boolean numField;
+  protected final boolean dateField;
+  protected SortedSetDocValues setValues;
+  protected SortedDocValues sortValues; 
+  protected NumericDocValues numValues; 
+  protected Bits numValuesBits; 
+  
+  public FieldFacetAccumulator(SolrIndexSearcher searcher, FacetValueAccumulator parent, SchemaField schemaField) throws IOException {  
+    if( !schemaField.hasDocValues() ){
+      throw new SolrException(ErrorCode.BAD_REQUEST, "Field '"+schemaField.getName()+"' does not have docValues");
+    }
+    this.searcher = searcher;
+    this.schemaField = schemaField;
+    this.name = schemaField.getName();
+    if (!schemaField.hasDocValues()) {
+      throw new IOException(name+" does not have docValues and therefore cannot be faceted over.");
+    }
+    this.multiValued = schemaField.multiValued();
+    this.numField = schemaField.getType().getNumericType()!=null;
+    this.dateField = schemaField.getType().getClass().equals(TrieDateField.class);
+    this.parent = parent;  
+    this.parser = AnalyticsParsers.getParser(schemaField.getType().getClass());
+  }
+
+  public static FieldFacetAccumulator create(SolrIndexSearcher searcher, FacetValueAccumulator parent, SchemaField facetField) throws IOException{
+    return new FieldFacetAccumulator(searcher,parent,facetField);
+  }
+
+  /**
+   * Move to the next set of documents to add to the field facet.
+   */
+  @Override
+  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
+    if (multiValued) {
+      setValues = context.reader().getSortedSetDocValues(name);
+    } else {
+      if (numField) {
+        numValues = context.reader().getNumericDocValues(name);
+        numValuesBits = context.reader().getDocsWithField(name);
+      } else {
+        sortValues = context.reader().getSortedDocValues(name);
+      }
+    }
+  }
+
+  /**
+   * Tell the FacetingAccumulator to collect the doc with the 
+   * given fieldFacet and value(s).
+   */
+  @Override
+  public void collect(int doc) throws IOException {
+    if (multiValued) {
+      boolean exists = false;
+      if (setValues!=null) {
+        setValues.setDocument(doc);
+        int term;
+        while ((term = (int)setValues.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {
+          exists = true;
+          final BytesRef value = setValues.lookupOrd(term);
+          parent.collectField(doc, name, parser.parse(value) );
+        }
+      }
+      if (!exists) {
+        parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
+      }
+    } else {
+      if(numField){
+        if(numValues != null) {
+          long v = numValues.get(doc);
+          if( v != 0 || numValuesBits.get(doc) ){
+            parent.collectField(doc, name, ((NumericParser)parser).parseNum(v));
+          } else {
+            parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
+          }
+        } else {
+          parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
+        }
+      } else {
+        if(sortValues != null) {
+          final int ord = sortValues.getOrd(doc);
+          if (ord < 0) {
+            parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
+          } else {
+            parent.collectField(doc, name, parser.parse(sortValues.lookupOrd(ord)) );
+          }
+        } else {
+          parent.collectField(doc, name, FacetingAccumulator.MISSING_VALUE );
+        }
+      }
+    }
+  }
+
+  @Override
+  public void compute() {}
+ 
+  @Override
+  public NamedList<?> export() { return null; }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java
new file mode 100644
index 0000000..3a268ee
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/facet/QueryFacetAccumulator.java
@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator.facet;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.solr.analytics.accumulator.ValueAccumulator;
+import org.apache.solr.analytics.statistics.StatsCollector;
+import org.apache.solr.common.util.NamedList;
+
+/**
+ * An Accumulator that manages a certain query of a given query facet.
+ */
+public class QueryFacetAccumulator extends ValueAccumulator {
+  protected final FacetValueAccumulator parent;
+  protected final String facetName;
+  protected final String facetValue;
+
+  public QueryFacetAccumulator(FacetValueAccumulator parent, String facetName, String facetValue) {
+    this.parent = parent;
+    this.facetName = facetName;
+    this.facetValue = facetValue;
+  }
+
+  /**
+   * Tell the FacetingAccumulator to collect the doc with the 
+   * given queryFacet and query.
+   */
+  @Override
+  public void collect(int doc) throws IOException {
+    parent.collectQuery(doc, facetName, facetValue);
+  }
+
+  /**
+   * Update the readers of the queryFacet {@link StatsCollector}s in FacetingAccumulator
+   */
+  @Override
+  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
+    parent.setQueryStatsCollectorReaders(context);
+  }
+
+  @Override
+  public void compute() {
+    // NOP
+  }
+
+  @Override
+  public NamedList<?> export() {
+    // NOP
+    return null;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java solr/core/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java
new file mode 100644
index 0000000..8c07c4f
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/facet/RangeFacetAccumulator.java
@@ -0,0 +1,50 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.accumulator.facet;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.solr.analytics.statistics.StatsCollector;
+
+/**
+ * An Accumulator that manages a certain range of a given range facet.
+ */
+public class RangeFacetAccumulator extends QueryFacetAccumulator {
+  public RangeFacetAccumulator(FacetValueAccumulator parent, String facetName, String facetValue) {
+    super(parent, facetName, facetValue);
+  }
+
+  /**
+   * Tell the FacetingAccumulator to collect the doc with the 
+   * given rangeFacet and range.
+   */
+  @Override
+  public void collect(int doc) throws IOException {
+    parent.collectRange(doc, facetName, facetValue);
+  }
+
+  /**
+   * Update the readers of the rangeFacet {@link StatsCollector}s in FacetingAccumulator
+   */
+  @Override
+  protected void doSetNextReader(AtomicReaderContext context) throws IOException {
+    parent.setRangeStatsCollectorReaders(context);
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/facet/package.html solr/core/src/java/org/apache/solr/analytics/accumulator/facet/package.html
new file mode 100644
index 0000000..8737a00
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/facet/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Accumulators for accumulating over differnt types of facets
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/accumulator/package.html solr/core/src/java/org/apache/solr/analytics/accumulator/package.html
new file mode 100644
index 0000000..b2cb8c2
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/accumulator/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Accumulators accumulate values over different types of strucuture (eg result, facet, etc..)
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/expression/BaseExpression.java solr/core/src/java/org/apache/solr/analytics/expression/BaseExpression.java
new file mode 100644
index 0000000..1455cbc
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/BaseExpression.java
@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import java.util.Date;
+
+import org.apache.solr.analytics.statistics.StatsCollector;
+
+
+/**
+ * <code>BaseExpression</code> returns the value returned by the {@link StatsCollector} for the specified stat.
+ */
+public class BaseExpression extends Expression {
+  protected final StatsCollector statsCollector;
+  protected final String stat;
+  
+  public BaseExpression(StatsCollector statsCollector, String stat) {
+    this.statsCollector = statsCollector;
+    this.stat = stat;
+  }
+  
+  public Comparable getValue() {
+    if(statsCollector.getStatsList().contains(stat)) {
+      return statsCollector.getStat(stat);
+    }
+    return null;
+  }
+}
+/**
+ * <code>ConstantStringExpression</code> returns the specified constant double.
+ */
+class ConstantNumberExpression extends Expression {
+  protected final Double constant;
+  
+  public ConstantNumberExpression(double d) {
+    constant = new Double(d);
+  }
+  
+  public Comparable getValue() {
+    return constant;
+  }
+}
+/**
+ * <code>ConstantStringExpression</code> returns the specified constant date.
+ */
+class ConstantDateExpression extends Expression {
+  protected final Date constant;
+  
+  public ConstantDateExpression(Date date) {
+    constant = date;
+  }
+  
+  public ConstantDateExpression(Long date) {
+    constant = new Date(date);
+  }
+  
+  public Comparable getValue() {
+    return constant;
+  }
+}
+/**
+ * <code>ConstantStringExpression</code> returns the specified constant string.
+ */
+class ConstantStringExpression extends Expression {
+  protected final String constant;
+  
+  public ConstantStringExpression(String str) {
+    constant = str;
+  }
+  
+  public Comparable getValue() {
+    return constant;
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java solr/core/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java
new file mode 100644
index 0000000..f8579bf
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/DualDelegateExpression.java
@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+/**
+ * Abstraction of an expression that applies a function to two delegate expressions.
+ */
+public abstract class DualDelegateExpression extends Expression {
+  protected Expression a;
+  protected Expression b;
+  public DualDelegateExpression(Expression a, Expression b) {
+    this.a = a;
+    this.b = b;
+  }
+}
+/**
+ * <code>DivideExpression</code> returns the quotient of 'a' and 'b'.
+ */
+class DivideExpression extends DualDelegateExpression {
+  
+  /**
+   * @param a numerator
+   * @param b divisor
+   */
+  public DivideExpression(Expression a, Expression b) {
+    super(a,b);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable aComp = a.getValue();
+    Comparable bComp = b.getValue();
+    if (aComp==null || bComp==null) {
+      return null;
+    }
+    double div = ((Number)aComp).doubleValue();
+    div = div / ((Number)bComp).doubleValue();
+    return new Double(div);
+  }
+}
+/**
+ * <code>PowerExpression</code> returns 'a' to the power of 'b'.
+ */
+class PowerExpression extends DualDelegateExpression {
+
+  /**
+   * @param a base
+   * @param b exponent
+   */
+  public PowerExpression(Expression a, Expression b) {
+    super(a,b);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable aComp = a.getValue();
+    Comparable bComp = b.getValue();
+    if (aComp==null || bComp==null) {
+      return null;
+    }
+    return new Double(Math.pow(((Number)aComp).doubleValue(),((Number)bComp).doubleValue()));
+  }
+}
+/**
+ * <code>LogExpression</code> returns the log of the delegate's value given a base number.
+ */
+class LogExpression extends DualDelegateExpression {
+  /**
+   * @param a number
+   * @param b base
+   */
+  public LogExpression(Expression a, Expression b) {
+    super(a,b);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable aComp = a.getValue();
+    Comparable bComp = b.getValue();
+    if (aComp==null || bComp==null) {
+      return null;
+    }
+    return Math.log(((Number)aComp).doubleValue())/Math.log(((Number)bComp).doubleValue());
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/Expression.java solr/core/src/java/org/apache/solr/analytics/expression/Expression.java
new file mode 100644
index 0000000..add0976
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/Expression.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import java.util.Comparator;
+
+import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortDirection;
+
+/**
+ * Expressions map either zero, one, two or many inputs to a single value. 
+ * They can be defined recursively to compute complex math.
+ */
+public abstract class Expression {
+  public abstract Comparable getValue();
+
+  public Comparator<Expression> comparator(final FacetSortDirection direction) {
+    return new Comparator<Expression>(){
+      @SuppressWarnings("unchecked")
+      @Override
+      public int compare(Expression a, Expression b) {
+        if( direction == FacetSortDirection.ASCENDING ){
+          return a.getValue().compareTo(b.getValue());
+        } else {
+          return b.getValue().compareTo(a.getValue());
+        }
+      }
+    };
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java solr/core/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java
new file mode 100644
index 0000000..0fd9db0
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/ExpressionFactory.java
@@ -0,0 +1,181 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.solr.analytics.statistics.StatsCollector;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.schema.TrieDateField;
+
+public class ExpressionFactory {
+
+  /**
+   * Creates a single expression that contains delegate expressions and/or 
+   * a StatsCollector.
+   * StatsCollectors are given as input and not created within the method so that
+   * expressions can share the same StatsCollectors, minimizing computation.
+   * 
+   * @param expression String representation of the desired expression
+   * @param statsCollectors List of StatsCollectors to build the expression with. 
+   * @return the expression
+   */
+  @SuppressWarnings("deprecation")
+  public static Expression create(String expression, StatsCollector[] statsCollectors) {
+    int paren = expression.indexOf('(');
+    if (paren<=0) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, "The expression ["+expression+"] has no arguments and is not supported.");
+    }
+    String topOperation = expression.substring(0,paren).trim();
+    String operands;
+    try {
+      operands = expression.substring(paren+1, expression.lastIndexOf(')')).trim();
+    } catch (Exception e) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,"Missing closing parenthesis in ["+expression+"]",e);
+    }
+    
+    // Builds a statistic, constant or recursively builds an expression tree
+    
+    // Statistic 
+    if (AnalyticsParams.ALL_STAT_SET.contains(topOperation)) {
+      if (topOperation.equals(AnalyticsParams.STAT_PERCENTILE)) {
+        operands = expression.substring(expression.indexOf(',')+1, expression.lastIndexOf(')')).trim();
+        topOperation = topOperation+"_"+expression.substring(expression.indexOf('(')+1, expression.indexOf(',')).trim();
+      }
+      StatsCollector collector = null;
+      // Finds the desired counter and builds an expression around it and the desired statistic.
+      for (StatsCollector c : statsCollectors) {
+        if (c.valueSourceString().equals(operands)) { 
+          collector = c;
+          break;
+        }
+      }
+      if (collector == null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "ValueSource ["+operands+"] in Expression ["+expression+"] not found.");
+      }
+      return new BaseExpression(collector, topOperation);
+    }
+    // Constant
+    if (topOperation.equals(AnalyticsParams.CONSTANT_NUMBER)) {
+      try {
+        return new ConstantNumberExpression(Double.parseDouble(operands));
+      } catch (NumberFormatException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "The constant "+operands+" cannot be converted into a number.",e);
+      }
+    } else if (topOperation.equals(AnalyticsParams.CONSTANT_DATE)) {
+      try {
+        return new ConstantDateExpression(TrieDateField.parseDate(operands));
+      } catch (ParseException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST, "The constant "+operands+" cannot be converted into a date.",e);
+      }
+    } else if (topOperation.equals(AnalyticsParams.CONSTANT_STRING)) {
+      operands = expression.substring(paren+1, expression.lastIndexOf(')'));
+      return new ConstantStringExpression(operands);
+    }
+    
+    // Complex Delegating Expressions
+    String[] arguments = getArguments(operands);
+    Expression[] expArgs = new Expression[arguments.length];
+    for (int count = 0; count < arguments.length; count++) {
+      // Recursively builds delegate expressions
+      expArgs[count] = create(arguments[count], statsCollectors);
+    }
+    
+    // Single Delegate Expressions
+    if (expArgs.length==1) {
+      // Numeric Expression
+      if (topOperation.equals(AnalyticsParams.NEGATE)) {
+        return new NegateExpression(expArgs[0]);
+      }
+      if (topOperation.equals(AnalyticsParams.ABSOLUTE_VALUE)) {
+        return new AbsoluteValueExpression(expArgs[0]);
+      }
+      // String Expression
+      else if (topOperation.equals(AnalyticsParams.REVERSE)) {
+        return new ReverseExpression(expArgs[0]);
+      }
+      throw new SolrException(ErrorCode.BAD_REQUEST, topOperation+" does not have the correct number of arguments.");
+    }  else {
+      // Multi Delegate Expressions
+      // Numeric Expression
+      if (topOperation.equals(AnalyticsParams.ADD)) {
+        return new AddExpression(expArgs);
+      } else if (topOperation.equals(AnalyticsParams.MULTIPLY)) {
+        return new MultiplyExpression(expArgs);
+      }
+      // Date Expression
+      else if (topOperation.equals(AnalyticsParams.DATE_MATH)) {
+        return new DateMathExpression(expArgs);
+      } 
+      // String Expression
+      else if (topOperation.equals(AnalyticsParams.CONCATENATE)) {
+        return new ConcatenateExpression(expArgs);
+      } 
+      // Dual Delegate Expressions
+      else if (expArgs.length==2 && (topOperation.equals(AnalyticsParams.DIVIDE) || topOperation.equals(AnalyticsParams.POWER) 
+          || topOperation.equals(AnalyticsParams.LOG))) {
+        // Numeric Expression
+        if (topOperation.equals(AnalyticsParams.DIVIDE)) {
+          return new DivideExpression(expArgs[0], expArgs[1]);
+        } else if (topOperation.equals(AnalyticsParams.POWER)) {
+          return new PowerExpression(expArgs[0], expArgs[1]);
+        } else if (topOperation.equals(AnalyticsParams.LOG)) {
+          return new LogExpression(expArgs[0], expArgs[1]);
+        }
+        return null;
+      }
+      throw new SolrException(ErrorCode.BAD_REQUEST, topOperation+" does not have the correct number of arguments or is unsupported.");
+    }
+    
+  }
+  
+  /**
+   * Splits up an Expression's arguments.
+   * 
+   * @param expression Current expression string
+   * @return List The list of arguments
+   */
+  public static String[] getArguments(String expression) {
+    String[] strings = new String[1];
+    int stack = 0;
+    int start = 0;
+    List<String> arguments = new ArrayList<>();
+    char[] chars = expression.toCharArray();
+    for (int count = 0; count < expression.length(); count++) {
+      char c = chars[count];
+      if (c==',' && stack == 0) {
+        arguments.add(expression.substring(start, count).replace("\\(","(").replace("\\)",")").replace("\\,",",").trim());
+        start = count+1;
+      } else if (c == '(') {
+        stack ++;
+      } else if (c == ')') {
+        stack --;
+      } else if (c == '\\') {
+        ; // Do nothing.
+      }
+    }
+    if (stack==0) {
+      arguments.add(expression.substring(start).trim());
+    }
+    return arguments.toArray(strings);
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java solr/core/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java
new file mode 100644
index 0000000..4ea4825
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/MultiDelegateExpression.java
@@ -0,0 +1,132 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import java.text.ParseException;
+import java.util.Date;
+
+import org.apache.solr.util.DateMathParser;
+
+/**
+ * Abstraction of an expression that applies a function to an array of delegate expressions.
+ */
+public abstract class MultiDelegateExpression extends Expression {
+  protected final Expression[] delegates;
+  
+  public MultiDelegateExpression(Expression[] delegates) {
+    this.delegates = delegates;
+  }
+}
+/**
+ * <code>AddExpression</code> returns the sum of it's components' values.
+ */
+class AddExpression extends MultiDelegateExpression {
+  public AddExpression(Expression[] delegates) {
+    super(delegates);
+  }
+
+  @Override
+  public Comparable getValue() {
+    double sum = 0;
+    for (Expression delegate : delegates) {
+      Comparable dComp = delegate.getValue();
+      if (dComp==null) {
+        return null;
+      } else if (dComp.getClass().equals(Date.class)) {
+        dComp = new Long(((Date)dComp).getTime());
+      }
+      sum += ((Number)dComp).doubleValue();
+    }
+    return new Double(sum);
+  }
+}
+/**
+ * <code>MultiplyExpression</code> returns the product of it's delegates' values.
+ */
+class MultiplyExpression extends MultiDelegateExpression {
+  public MultiplyExpression(Expression[] delegates) {
+    super(delegates);
+  }
+
+  @Override
+  public Comparable getValue() {
+    double prod = 1;
+    for (Expression delegate : delegates) {
+      Comparable dComp = delegate.getValue();
+      if (dComp==null) {
+        return null;
+      }
+      prod *= ((Number)dComp).doubleValue();
+    }
+    return new Double(prod);
+  }
+}
+/**
+ * <code>DateMathExpression</code> returns the start date modified by the DateMath operations
+ */
+class DateMathExpression extends MultiDelegateExpression {
+  /**
+   * @param delegates A list of Expressions. The first element in the list
+   * should be a numeric Expression which represents the starting date. 
+   * The rest of the field should be string Expression objects which contain
+   * the DateMath operations to perform on the start date.
+   */
+  public DateMathExpression(Expression[] delegates) {
+    super(delegates);
+  }
+
+  @Override
+  public Comparable getValue() {
+    DateMathParser parser = new DateMathParser();
+    parser.setNow((Date)delegates[0].getValue());
+    try {
+      for (int count = 1; count<delegates.length; count++) {
+        Comparable dComp = delegates[count].getValue();
+        if (dComp==null) {
+          return null;
+        }
+        parser.setNow(parser.parseMath((String)dComp));
+      }
+      return parser.getNow();
+    } catch (ParseException e) {
+      e.printStackTrace();
+      return parser.getNow();
+    }
+  }
+}
+/**
+ * <code>ConcatenateExpression</code> returns the concatenation of it's delegates' values in the order given.
+ */
+class ConcatenateExpression extends MultiDelegateExpression {
+  public ConcatenateExpression(Expression[] delegates) {
+    super(delegates);
+  }
+
+  @Override
+  public Comparable getValue() {
+    StringBuilder builder = new StringBuilder();
+    for (Expression delegate : delegates) {
+      Comparable dComp = delegate.getValue();
+      if (dComp==null) {
+        return null;
+      }
+      builder.append(dComp.toString());
+    }
+    return builder.toString();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java solr/core/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java
new file mode 100644
index 0000000..c6ab60e
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/SingleDelegateExpression.java
@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import java.util.Date;
+
+/**
+ * Abstraction of an expression that applies a function to one delegate expression.
+ */
+public abstract class SingleDelegateExpression extends Expression {
+  protected Expression delegate;
+  
+  public SingleDelegateExpression(Expression delegate) {
+    this.delegate = delegate;
+  }
+}
+/**
+ * <code>NegateExpression</code> returns the negation of the delegate's value.
+ */
+class NegateExpression extends SingleDelegateExpression {
+  public NegateExpression(Expression delegate) {
+    super(delegate);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable nComp = delegate.getValue();
+    if (nComp==null) {
+      return null;
+    } else if (nComp.getClass().equals(Date.class)) {
+      nComp = new Long(((Date)nComp).getTime());
+    }
+    return new Double(((Number)nComp).doubleValue()*-1);
+  }
+}
+/**
+ * <code>AbsoluteValueExpression</code> returns the negation of the delegate's value.
+ */
+class AbsoluteValueExpression extends SingleDelegateExpression {
+  public AbsoluteValueExpression(Expression delegate) {
+    super(delegate);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable nComp = delegate.getValue();
+    if (nComp==null) {
+      return null;
+    }
+    double d = ((Number)nComp).doubleValue();
+    if (d<0) {
+      return new Double(d*-1);
+    } else {
+      return new Double(d);
+    }
+  }
+}
+/**
+ * <code>StringExpression</code> returns the reverse of the delegate's string value.
+ */
+class ReverseExpression extends SingleDelegateExpression {
+  public ReverseExpression(Expression delegate) {
+    super(delegate);
+  }
+
+  @Override
+  public Comparable getValue() {
+    Comparable rComp = delegate.getValue();
+    if (rComp==null) {
+      return null;
+    }
+    return new StringBuilder(rComp.toString()).reverse().toString();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/expression/package.html solr/core/src/java/org/apache/solr/analytics/expression/package.html
new file mode 100644
index 0000000..434f710
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/expression/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Expressions map either zero, one, two or many inputs to a single value. They can be defined recursively to compute complex math.
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java solr/core/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java
new file mode 100644
index 0000000..a57c546
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/plugin/AnalyticsStatisticsCollector.java
@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.plugin;
+
+import java.util.concurrent.atomic.AtomicLong;
+
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SimpleOrderedMap;
+import org.apache.solr.util.stats.Snapshot;
+import org.apache.solr.util.stats.Timer;
+import org.apache.solr.util.stats.TimerContext;
+
+public class AnalyticsStatisticsCollector {
+  private final AtomicLong numRequests;
+  private final AtomicLong numAnalyticsRequests;
+  private final AtomicLong numStatsRequests;
+  private final AtomicLong numCollectedStats;
+  private final AtomicLong numFieldFacets;
+  private final AtomicLong numRangeFacets;
+  private final AtomicLong numQueryFacets;
+  private final AtomicLong numQueries;
+  private final Timer requestTimes;
+  
+  public TimerContext currentTimer;
+  
+  public AnalyticsStatisticsCollector() {
+    numRequests = new AtomicLong();
+    numAnalyticsRequests = new AtomicLong();
+    numStatsRequests = new AtomicLong();
+    numCollectedStats = new AtomicLong();
+    numFieldFacets = new AtomicLong();
+    numRangeFacets = new AtomicLong();
+    numQueryFacets = new AtomicLong();
+    numQueries = new AtomicLong();
+    requestTimes = new Timer();
+  }
+  
+  public void startRequest() {
+    numRequests.incrementAndGet();
+    currentTimer = requestTimes.time();
+  }
+  
+  public void addRequests(long num) {
+    numAnalyticsRequests.addAndGet(num);
+  }
+  
+  public void addStatsRequests(long num) {
+    numStatsRequests.addAndGet(num);
+  }
+  
+  public void addStatsCollected(long num) {
+    numCollectedStats.addAndGet(num);
+  }
+  
+  public void addFieldFacets(long num) {
+    numFieldFacets.addAndGet(num);
+  }
+  
+  public void addRangeFacets(long num) {
+    numRangeFacets.addAndGet(num);
+  }
+  
+  public void addQueryFacets(long num) {
+    numQueryFacets.addAndGet(num);
+  }
+  
+  public void addQueries(long num) {
+    numQueries.addAndGet(num);
+  }
+  
+  public void endRequest() {
+    currentTimer.stop();
+  }
+
+  public NamedList<Object> getStatistics() {
+    NamedList<Object> lst = new SimpleOrderedMap<>();
+    Snapshot snapshot = requestTimes.getSnapshot();
+    lst.add("requests", numRequests.longValue());
+    lst.add("analyticsRequests", numAnalyticsRequests.longValue());
+    lst.add("statsRequests", numStatsRequests.longValue());
+    lst.add("statsCollected", numCollectedStats.longValue());
+    lst.add("fieldFacets", numFieldFacets.longValue());
+    lst.add("rangeFacets", numRangeFacets.longValue());
+    lst.add("queryFacets", numQueryFacets.longValue());
+    lst.add("queriesInQueryFacets", numQueries.longValue());
+    lst.add("totalTime", requestTimes.getSum());
+    lst.add("avgRequestsPerSecond", requestTimes.getMeanRate());
+    lst.add("5minRateReqsPerSecond", requestTimes.getFiveMinuteRate());
+    lst.add("15minRateReqsPerSecond", requestTimes.getFifteenMinuteRate());
+    lst.add("avgTimePerRequest", requestTimes.getMean());
+    lst.add("medianRequestTime", snapshot.getMedian());
+    lst.add("75thPcRequestTime", snapshot.get75thPercentile());
+    lst.add("95thPcRequestTime", snapshot.get95thPercentile());
+    lst.add("99thPcRequestTime", snapshot.get99thPercentile());
+    lst.add("999thPcRequestTime", snapshot.get999thPercentile());
+    return lst;
+  }
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/plugin/package.html solr/core/src/java/org/apache/solr/analytics/plugin/package.html
new file mode 100644
index 0000000..7555251
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/plugin/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+MBean plugins for stats collection 
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java solr/core/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java
new file mode 100644
index 0000000..6f85cf0
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/AbstractFieldFacetRequest.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import org.apache.solr.schema.SchemaField;
+
+/**
+ * An abstract request for a facet over a single field, such as a field or range facet.
+ */
+public abstract class AbstractFieldFacetRequest implements FacetRequest {
+  protected SchemaField field = null;
+  
+  public AbstractFieldFacetRequest(SchemaField field) {
+    this.field = field;
+  }
+
+  public SchemaField getField() {
+    return field;
+  }
+
+  public void setField(SchemaField field) {
+    this.field = field;
+  }
+
+  public String getName() {
+    return field.getName();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java solr/core/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java
new file mode 100644
index 0000000..db21094
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/AnalyticsContentHandler.java
@@ -0,0 +1,315 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.util.ArrayList;
+import java.util.EnumSet;
+import java.util.List;
+
+import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortDirection;
+import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
+import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
+import org.apache.solr.common.params.FacetParams.FacetRangeOther;
+import org.apache.solr.schema.IndexSchema;
+import org.xml.sax.Attributes;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.Locator;
+import org.xml.sax.SAXException;
+
+/**
+ * Handles the parsing of the AnalysisRequestEnvelope elements if passed in through XML.
+ */
+public class AnalyticsContentHandler implements ContentHandler {
+  // XML Element/Attribute Name Constants
+  public final String ANALYTICS_REQUEST_ENVELOPE="analyticsRequestEnvelope";
+  
+  public final String ANALYTICS_REQUEST="analyticsRequest";
+  public final String NAME="name";
+  
+  public final String STATISTIC="statistic";
+  public final String EXPRESSION="expression";
+  
+  public final String FIELD_FACET="fieldFacet";
+  public final String FIELD="field";
+  public final String SHOW_MISSING="showMissing";
+  public final String LIMIT="limit";
+  public final String MIN_COUNT="minCount";
+  
+  public final String SORT_SPECIFICATION="sortSpecification";
+  public final String STAT_NAME="statName";
+  public final String DIRECTION="direction";
+  
+  public final String RANGE_FACET="rangeFacet";
+  public final String START="start";
+  public final String END="end";
+  public final String GAP="gap";
+  public final String INCLUDE_BOUNDARY="includeBoundary";
+  public final String OTHER_RANGE="otherRange";
+  public final String HARD_END="hardend";
+  
+  public final String QUERY_FACET="queryFacet";
+  public final String QUERY="query";
+  
+  // Default Values
+  public static final int DEFAULT_FACET_LIMIT = -1;
+  public static final boolean DEFAULT_FACET_HARDEND = false;
+  public static final int DEFAULT_FACET_MINCOUNT = 0;
+  public static final boolean DEFAULT_FACET_FIELD_SHOW_MISSING = false;
+
+  boolean inEnvelope = false;
+  boolean inRequest = false;
+  boolean inStatistic = false;
+  boolean inFieldFacet = false;
+  boolean inSortSpecification = false;
+  boolean inQueryFacet = false;
+  boolean inRangeFacet = false;
+  
+  private final IndexSchema schema;
+  
+  // Objects to use while building the Analytics Requests
+  
+  String currentElementText;
+  
+  List<AnalyticsRequest> requests;
+  
+  AnalyticsRequest analyticsRequest;
+  List<ExpressionRequest> expressionList;
+  List<FieldFacetRequest> fieldFacetList;
+  List<RangeFacetRequest> rangeFacetList;
+  List<QueryFacetRequest> queryFacetList;
+  
+  ExpressionRequest expression;
+  
+  FieldFacetRequest fieldFacet;
+  int limit;
+  int minCount;
+  boolean showMissing;
+  FacetSortSpecification sortSpecification;
+  
+  RangeFacetRequest rangeFacet;
+  boolean hardend;
+  List<String> gaps;
+  EnumSet<FacetRangeInclude> includeBoundaries;
+  EnumSet<FacetRangeOther> otherRanges;
+  
+  String queryName;
+  List<String> queries;
+  
+  public AnalyticsContentHandler(IndexSchema schema) {
+    this.schema = schema;
+  }
+
+  @Override
+  public void setDocumentLocator(Locator locator) { }
+
+  @Override
+  public void startDocument() throws SAXException { }
+
+  @Override
+  public void endDocument() throws SAXException { }
+
+  @Override
+  public void startPrefixMapping(String prefix, String uri) throws SAXException { }
+
+  @Override
+  public void endPrefixMapping(String prefix) throws SAXException { }
+
+  @Override
+  public void startElement(String uri, String localName, String qName, Attributes atts) throws SAXException {
+    currentElementText = "";
+    if (inEnvelope) {
+      if (inRequest) {
+        if (localName.equals(STATISTIC)) {
+          // Start a Statistic Request
+          inStatistic = true;
+        } else if (inFieldFacet) {
+          if (localName.equals(SORT_SPECIFICATION)) {
+            // Start a Sort Specification
+            inSortSpecification = true;
+            sortSpecification = new FacetSortSpecification();
+          }
+        } else if (localName.equals(FIELD_FACET)) {
+          // Start a Field Facet Request
+          // Get attributes (limit, minCount, showMissing)
+          String att = atts.getValue(uri,LIMIT);
+          if (att!=null) {
+            limit = Integer.parseInt(att);
+          } else {
+            limit = DEFAULT_FACET_LIMIT;
+          }
+          att = atts.getValue(uri,MIN_COUNT);
+          if (att!=null) {
+            minCount = Integer.parseInt(att);
+          } else {
+            minCount = DEFAULT_FACET_MINCOUNT;
+          }
+          att = atts.getValue(uri,SHOW_MISSING);
+          if (att!=null) {
+            showMissing = Boolean.parseBoolean(att);
+          } else {
+            showMissing = DEFAULT_FACET_FIELD_SHOW_MISSING;
+          }
+          
+          inFieldFacet = true;
+        } else if (localName.equals(RANGE_FACET)) {
+          // Start a Range Facet Request
+          // Get attributes (hardEnd)
+          String att = atts.getValue(uri,HARD_END);
+          if (att!=null) {
+            hardend = Boolean.parseBoolean(att);
+          } else {
+            hardend = false;
+          }
+          
+          // Initiate Range Facet classes
+          gaps = new ArrayList<>();
+          includeBoundaries = EnumSet.noneOf(FacetRangeInclude.class);
+          otherRanges = EnumSet.noneOf(FacetRangeOther.class);
+          inRangeFacet = true;
+        } else if (localName.equals(QUERY_FACET)) {
+          // Start a Query Facet Request
+          queries = new ArrayList<>();
+          inQueryFacet = true;
+        }
+      } else if (localName.equals(ANALYTICS_REQUEST)){
+        // Start an Analytics Request
+        
+        // Renew each list.
+        fieldFacetList = new ArrayList<>();
+        rangeFacetList = new ArrayList<>();
+        queryFacetList = new ArrayList<>();
+        expressionList = new ArrayList<>();
+        inRequest = true;
+      }
+    } else if (localName.equals(ANALYTICS_REQUEST_ENVELOPE)){
+      //Begin the parsing of the Analytics Requests
+      requests = new ArrayList<>();
+      inEnvelope = true;
+    }
+  }
+
+  @Override
+  public void endElement(String uri, String localName, String qName) throws SAXException {
+    if (inEnvelope) {
+      if (inRequest) {
+        if (inStatistic) {
+          if (localName.equals(EXPRESSION)) {
+            expression = new ExpressionRequest(currentElementText,currentElementText);
+          } else if (localName.equals(NAME)) {
+            expression.setName(currentElementText);
+          } else if (localName.equals(STATISTIC)) {
+            // Finished Parsing the Statistic Request
+            expressionList.add(expression);
+            inStatistic = false;
+          } 
+        } else if (inFieldFacet) {
+          if (inSortSpecification) {
+            if (localName.equals(STAT_NAME)) {
+              sortSpecification.setStatistic(currentElementText);
+            } else if (localName.equals(DIRECTION)) {
+              sortSpecification.setDirection(FacetSortDirection.fromExternal(currentElementText));
+            } else if (localName.equals(SORT_SPECIFICATION)) {
+              // Finished Parsing the Sort Specification
+              fieldFacet.setSort(sortSpecification);
+              inSortSpecification = false;
+            } 
+          } else if (localName.equals(FIELD)) {
+            fieldFacet = new FieldFacetRequest(schema.getField(currentElementText));
+          } else if (localName.equals(FIELD_FACET)) {
+            // Finished Parsing the Field Facet Request
+            fieldFacet.setLimit(limit);
+            fieldFacet.showMissing(showMissing);
+            fieldFacetList.add(fieldFacet);
+            inFieldFacet = false;
+          } 
+        } else if (inRangeFacet) {
+          if (localName.equals(FIELD)) {
+            rangeFacet = new RangeFacetRequest(schema.getField(currentElementText), "", "", new String[1]);
+          } else if (localName.equals(START)) {
+            rangeFacet.setStart(currentElementText);
+          } else if (localName.equals(END)) {
+            rangeFacet.setEnd(currentElementText);
+          } else if (localName.equals(GAP)) {
+            gaps.add(currentElementText);
+          } else if (localName.equals(INCLUDE_BOUNDARY)) {
+            includeBoundaries.add(FacetRangeInclude.get(currentElementText));
+          } else if (localName.equals(OTHER_RANGE)) {
+            otherRanges.add(FacetRangeOther.get(currentElementText));
+          } else if (localName.equals(RANGE_FACET)) {
+            // Finished Parsing the Range Facet Request
+            rangeFacet.setHardEnd(hardend);
+            rangeFacet.setGaps(gaps.toArray(new String[1]));
+            rangeFacet.setInclude(includeBoundaries);
+            rangeFacet.setOthers(otherRanges);
+            inRangeFacet = false;
+            rangeFacetList.add(rangeFacet);
+          } 
+        } else if (inQueryFacet) {
+          if (localName.equals(NAME)) {
+            queryName = currentElementText;
+          } else if (localName.equals(QUERY)) {
+            queries.add(currentElementText);
+          } else if (localName.equals(QUERY_FACET)) {
+            // Finished Parsing the Query Facet Request
+            QueryFacetRequest temp = new QueryFacetRequest(queryName);
+            temp.setQueries(queries);
+            queryFacetList.add(temp);
+            inQueryFacet = false;
+          }
+        } else if (localName.equals(NAME)) {
+          analyticsRequest = new AnalyticsRequest(currentElementText);
+        } else if (localName.equals(ANALYTICS_REQUEST)){
+          // Finished Parsing the Analytics Request
+          analyticsRequest.setExpressions(expressionList);
+          analyticsRequest.setFieldFacets(fieldFacetList);
+          analyticsRequest.setRangeFacets(rangeFacetList);
+          analyticsRequest.setQueryFacets(queryFacetList);
+          requests.add(analyticsRequest);
+          inRequest = false;
+        }
+      } else if (localName.equals(ANALYTICS_REQUEST_ENVELOPE)){
+        // Finished Parsing
+        inEnvelope = false;
+      }
+    }
+  }
+
+  @Override
+  public void characters(char[] ch, int start, int length) throws SAXException {
+    currentElementText += new String(ch,start,length);
+  }
+
+  @Override
+  public void ignorableWhitespace(char[] ch, int start, int length) throws SAXException { }
+
+  @Override
+  public void processingInstruction(String target, String data) throws SAXException { }
+
+  @Override
+  public void skippedEntity(String name) throws SAXException { }
+  
+  /**
+   * Returns the list of Analytics Requests built during parsing.
+   * 
+   * @return List of {@link AnalyticsRequest} objects specified by the given XML file
+   */
+  public List<AnalyticsRequest> getAnalyticsRequests() {
+    return requests;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java
new file mode 100644
index 0000000..2f24999
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequest.java
@@ -0,0 +1,115 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * Contains the specifications of an Analytics Request, specifically a name,
+ * a list of Expressions, a list of field facets, a list of range facets, a list of query facets
+ * and the list of expressions and their results calculated in previous AnalyticsRequests.
+ */
+public class AnalyticsRequest {
+  
+  private String name;
+  private List<ExpressionRequest> expressions;
+  private Set<String> hiddenExpressions;
+  private List<FieldFacetRequest> fieldFacets;
+  private List<RangeFacetRequest> rangeFacets;
+  private List<QueryFacetRequest> queryFacets;
+  
+  public AnalyticsRequest(String name) {
+    this.name = name;
+    expressions = new ArrayList<>();
+    hiddenExpressions = new HashSet<>();
+    fieldFacets = new ArrayList<>();
+    rangeFacets = new ArrayList<>();
+    queryFacets = new ArrayList<>();
+  }
+  
+  public String getName() {
+    return name;
+  }
+  
+  public void setExpressions(List<ExpressionRequest> expressions) {
+    this.expressions = expressions;
+  }
+
+  public void addExpression(ExpressionRequest expressionRequest) {
+    expressions.add(expressionRequest);
+  }
+  
+  public List<ExpressionRequest> getExpressions() {
+    return expressions;
+  }
+
+  public void addHiddenExpression(ExpressionRequest expressionRequest) {
+    expressions.add(expressionRequest);
+    hiddenExpressions.add(expressionRequest.getName());
+  }
+  
+  public Set<String> getHiddenExpressions() {
+    return hiddenExpressions;
+  }
+  
+  public void setFieldFacets(List<FieldFacetRequest> fieldFacets) {
+    this.fieldFacets = fieldFacets;
+  }
+  
+  public List<FieldFacetRequest> getFieldFacets() {
+    return fieldFacets;
+  }
+  
+  public void setRangeFacets(List<RangeFacetRequest> rangeFacets) {
+    this.rangeFacets = rangeFacets;
+  }
+  
+  public List<RangeFacetRequest> getRangeFacets() {
+    return rangeFacets;
+  }
+  
+  public void setQueryFacets(List<QueryFacetRequest> queryFacets) {
+    this.queryFacets = queryFacets;
+  }
+  
+  public List<QueryFacetRequest> getQueryFacets() {
+    return queryFacets;
+  }
+  
+  @Override
+  public String toString() {
+    StringBuilder builder = new StringBuilder("<AnalyticsRequest name=" + name + ">");
+    for (ExpressionRequest exp : expressions) {
+      builder.append(exp.toString());
+    }
+    for (FieldFacetRequest facet : fieldFacets) {
+      builder.append(facet.toString());
+    }
+    for (RangeFacetRequest facet : rangeFacets) {
+      builder.append(facet.toString());
+    }
+    for (QueryFacetRequest facet : queryFacets) {
+      builder.append(facet.toString());
+    }
+    builder.append("</AnalyticsRequest>");
+    return builder.toString();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java
new file mode 100644
index 0000000..3e2e994
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/AnalyticsRequestFactory.java
@@ -0,0 +1,309 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.apache.solr.analytics.request.FieldFacetRequest.FacetSortSpecification;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
+import org.apache.solr.common.params.FacetParams.FacetRangeOther;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.schema.IndexSchema;
+
+/**
+ * Parses the SolrParams to create a list of analytics requests.
+ */
+public class AnalyticsRequestFactory implements AnalyticsParams {
+
+  public static final Pattern statPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+EXPRESSION+")\\.([^\\.]+)$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern hiddenStatPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+HIDDEN_EXPRESSION+")\\.([^\\.]+)$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern fieldFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+FIELD_FACET+")$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern fieldFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+FIELD_FACET+")\\.([^\\.]+)\\.("+LIMIT+"|"+OFFSET+"|"+HIDDEN+"|"+SHOW_MISSING+"|"+SORT_STATISTIC+"|"+SORT_DIRECTION+")$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern rangeFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+RANGE_FACET+")$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern rangeFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+RANGE_FACET+")\\.([^\\.]+)\\.("+START+"|"+END+"|"+GAP+"|"+HARDEND+"|"+INCLUDE_BOUNDARY+"|"+OTHER_RANGE+")$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern queryFacetPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+QUERY_FACET+")$", Pattern.CASE_INSENSITIVE);
+  public static final Pattern queryFacetParamPattern = Pattern.compile("^o(?:lap)?\\.([^\\.]+)\\.(?:"+QUERY_FACET+")\\.([^\\.]+)\\.("+QUERY+"|"+DEPENDENCY+")$", Pattern.CASE_INSENSITIVE);
+  
+  public static List<AnalyticsRequest> parse(IndexSchema schema, SolrParams params) {
+    Map<String, AnalyticsRequest> requestMap = new HashMap<>();
+    Map<String, Map<String,FieldFacetRequest>> fieldFacetMap = new HashMap<>();
+    Map<String, Set<String>> fieldFacetSet = new HashMap<>();
+    Map<String, Map<String,RangeFacetRequest>> rangeFacetMap = new HashMap<>();
+    Map<String, Set<String>> rangeFacetSet = new HashMap<>();
+    Map<String, Map<String,QueryFacetRequest>> queryFacetMap = new HashMap<>();
+    Map<String, Set<String>> queryFacetSet = new HashMap<>();
+    List<AnalyticsRequest> requestList = new ArrayList<>();
+    
+    Iterator<String> paramsIterator = params.getParameterNamesIterator();
+    while (paramsIterator.hasNext()) {
+      String param = paramsIterator.next();
+      CharSequence paramSequence = param.subSequence(0, param.length());
+      
+      // Check if stat
+      Matcher m = statPattern.matcher(paramSequence);
+      if (m.matches()) {
+        makeExpression(requestMap,m.group(1),m.group(2),params.get(param));
+      } else {
+        // Check if hidden stat
+        m = hiddenStatPattern.matcher(paramSequence);
+        if (m.matches()) {
+          makeHiddenExpression(requestMap,m.group(1),m.group(2),params.get(param));
+        } else {
+          // Check if field facet
+          m = fieldFacetPattern.matcher(paramSequence);
+          if (m.matches()) {
+            makeFieldFacet(schema,fieldFacetMap,fieldFacetSet,m.group(1),params.getParams(param));
+          } else {
+            // Check if field facet parameter
+            m = fieldFacetParamPattern.matcher(paramSequence);
+            if (m.matches()) {
+              setFieldFacetParam(schema,fieldFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
+            } else {
+              // Check if range facet
+              m = rangeFacetPattern.matcher(paramSequence);
+              if (m.matches()) {
+                makeRangeFacet(schema,rangeFacetSet,m.group(1),params.getParams(param));
+              }  else {
+                // Check if range facet parameter
+                m = rangeFacetParamPattern.matcher(paramSequence);
+                if (m.matches()) {
+                  setRangeFacetParam(schema,rangeFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
+                }  else {
+                  // Check if query facet
+                  m = queryFacetPattern.matcher(paramSequence);
+                  if (m.matches()) {
+                    makeQueryFacet(schema,queryFacetSet,m.group(1),params.getParams(param));
+                  }  else {
+                    // Check if query
+                    m = queryFacetParamPattern.matcher(paramSequence);
+                    if (m.matches()) {
+                      setQueryFacetParam(schema,queryFacetMap,m.group(1),m.group(2),m.group(3),params.getParams(param));
+                    } 
+                  }
+                }
+              }
+            }
+          }
+        }
+      }
+    }
+    for (String reqName : requestMap.keySet()) {
+      AnalyticsRequest ar = requestMap.get(reqName);
+      List<FieldFacetRequest> ffrs = new ArrayList<>();
+      if (fieldFacetSet.get(reqName)!=null) {
+        for (String field : fieldFacetSet.get(reqName)) {
+          ffrs.add(fieldFacetMap.get(reqName).get(field));
+        }
+      }
+      ar.setFieldFacets(ffrs);
+      
+      List<RangeFacetRequest> rfrs = new ArrayList<>();
+      if (rangeFacetSet.get(reqName)!=null) {
+        for (String field : rangeFacetSet.get(reqName)) {
+          RangeFacetRequest rfr = rangeFacetMap.get(reqName).get(field);
+          if (rfr != null) {
+            rfrs.add(rfr);
+          }
+        }
+      }
+      ar.setRangeFacets(rfrs);
+      
+      List<QueryFacetRequest> qfrs = new ArrayList<>();
+      if (queryFacetSet.get(reqName)!=null) {
+        for (String name : queryFacetSet.get(reqName)) {
+          QueryFacetRequest qfr = queryFacetMap.get(reqName).get(name);
+          if (qfr != null) {
+            addQueryFacet(qfrs,qfr);
+          }
+        }
+      }
+      for (QueryFacetRequest qfr : qfrs) {
+        if (qfr.getDependencies().size()>0) {
+          throw new SolrException(ErrorCode.BAD_REQUEST,"The query facet dependencies "+qfr.getDependencies().toString()+" either do not exist or are defined in a dependency looop.");
+        }
+      }
+      ar.setQueryFacets(qfrs);
+      requestList.add(ar);
+    }
+    return requestList; 
+  }
+
+  private static void makeFieldFacet(IndexSchema schema, Map<String, Map<String, FieldFacetRequest>> fieldFacetMap, Map<String, Set<String>> fieldFacetSet, String requestName, String[] fields) {
+    Map<String, FieldFacetRequest> facetMap = fieldFacetMap.get(requestName);
+    if (facetMap == null) {
+      facetMap = new HashMap<>();
+      fieldFacetMap.put(requestName, facetMap);
+    }
+    Set<String> set = fieldFacetSet.get(requestName);
+    if (set == null) {
+      set = new HashSet<>();
+      fieldFacetSet.put(requestName, set);
+    }
+    for (String field : fields) {
+      if (facetMap.get(field) == null) {
+        facetMap.put(field,new FieldFacetRequest(schema.getField(field)));
+      }
+      set.add(field);
+    }
+  }
+
+  private static void setFieldFacetParam(IndexSchema schema, Map<String, Map<String, FieldFacetRequest>> fieldFacetMap, String requestName, String field, String paramType, String[] params) {
+    Map<String, FieldFacetRequest> facetMap = fieldFacetMap.get(requestName);
+    if (facetMap == null) {
+      facetMap = new HashMap<>();
+      fieldFacetMap.put(requestName, facetMap);
+    }
+    FieldFacetRequest fr = facetMap.get(field);
+    if (fr == null) {
+      fr = new FieldFacetRequest(schema.getField(field));
+      facetMap.put(field,fr);
+    }
+    if (paramType.equals("limit")||paramType.equals("l")) {
+      fr.setLimit(Integer.parseInt(params[0]));
+    } else if (paramType.equals("offset")||paramType.equals("off")) {
+      fr.setOffset(Integer.parseInt(params[0]));
+    } else if (paramType.equals("hidden")||paramType.equals("h")) {
+      fr.setHidden(Boolean.parseBoolean(params[0]));
+    } else if (paramType.equals("showmissing")||paramType.equals("sm")) {
+      fr.showMissing(Boolean.parseBoolean(params[0]));
+    } else if (paramType.equals("sortstatistic")||paramType.equals("sortstat")||paramType.equals("ss")) {
+      fr.setSort(new FacetSortSpecification(params[0],fr.getDirection()));
+    } else if (paramType.equals("sortdirection")||paramType.equals("sd")) {
+      fr.setDirection(params[0]);
+    } 
+  }
+
+  private static void makeRangeFacet(IndexSchema schema, Map<String, Set<String>> rangeFacetSet, String requestName, String[] fields) {
+    Set<String> set = rangeFacetSet.get(requestName);
+    if (set == null) {
+      set = new HashSet<>();
+      rangeFacetSet.put(requestName, set);
+    }
+    for (String field : fields) {
+      set.add(field);
+    }
+  }
+
+  private static void setRangeFacetParam(IndexSchema schema, Map<String, Map<String, RangeFacetRequest>> rangeFacetMap, String requestName, String field, String paramType, String[] params) {
+    Map<String, RangeFacetRequest> facetMap = rangeFacetMap.get(requestName);
+    if (facetMap == null) {
+      facetMap = new HashMap<>();
+      rangeFacetMap.put(requestName, facetMap);
+    }
+    RangeFacetRequest rr = facetMap.get(field);
+    if (rr == null) {
+      rr = new RangeFacetRequest(schema.getField(field));
+      facetMap.put(field,rr);
+    }
+    if (paramType.equals("start")||paramType.equals("st")) {
+      rr.setStart(params[0]);
+    } else if (paramType.equals("end")||paramType.equals("e")) {
+      rr.setEnd(params[0]);
+    } else if (paramType.equals("gap")||paramType.equals("g")) {
+      rr.setGaps(params[0].split(","));
+    } else if (paramType.equals("hardend")||paramType.equals("he")) {
+      rr.setHardEnd(Boolean.parseBoolean(params[0]));
+    } else if (paramType.equals("includebound")||paramType.equals("ib")) {
+      for (String param : params) {
+        rr.addInclude(FacetRangeInclude.get(param));
+      }
+    } else if (paramType.equals("otherrange")||paramType.equals("or")) {
+      for (String param : params) {
+        rr.addOther(FacetRangeOther.get(param));
+      }
+    } 
+  }
+
+  private static void makeQueryFacet(IndexSchema schema,Map<String, Set<String>> queryFacetSet, String requestName, String[] names) {
+    Set<String> set = queryFacetSet.get(requestName);
+    if (set == null) {
+      set = new HashSet<>();
+      queryFacetSet.put(requestName, set);
+    }
+    for (String name : names) {
+      set.add(name);
+    }
+  }
+
+  private static void setQueryFacetParam(IndexSchema schema, Map<String, Map<String, QueryFacetRequest>> queryFacetMap, String requestName, String name, String paramType, String[] params) {
+    Map<String, QueryFacetRequest> facetMap = queryFacetMap.get(requestName);
+    if (facetMap == null) {
+      facetMap = new HashMap<>();
+      queryFacetMap.put(requestName, facetMap);
+    }
+    QueryFacetRequest qr = facetMap.get(name);
+    if (qr == null) {
+      qr = new QueryFacetRequest(name);
+      facetMap.put(name,qr);
+    }
+    if (paramType.equals("query")||paramType.equals("q")) {
+      for (String query : params) {
+        qr.addQuery(query);
+      }
+    } else if (paramType.equals("dependency")||paramType.equals("d")) {
+      for (String depend : params) {
+        qr.addDependency(depend);
+      }
+    }
+  }
+
+  private static void makeHiddenExpression(Map<String, AnalyticsRequest> requestMap, String requestName, String expressionName, String expression) {
+    AnalyticsRequest req = requestMap.get(requestName);
+    if (req == null) {
+      req = new AnalyticsRequest(requestName);
+      requestMap.put(requestName, req);
+    }
+    req.addHiddenExpression(new ExpressionRequest(expressionName,expression));
+  }
+
+  private static void makeExpression(Map<String, AnalyticsRequest> requestMap, String requestName, String expressionName, String expression) {
+    AnalyticsRequest req = requestMap.get(requestName);
+    if (req == null) {
+      req = new AnalyticsRequest(requestName);
+      requestMap.put(requestName, req);
+    }
+    req.addExpression(new ExpressionRequest(expressionName,expression));
+  }
+  
+  private static void addQueryFacet(List<QueryFacetRequest> currentList, QueryFacetRequest queryFacet) {
+    Set<String> depends = queryFacet.getDependencies();
+    int place = 0;
+    for (QueryFacetRequest qfr : currentList) {
+      if (qfr.getDependencies().remove(queryFacet.getName())) {
+        break;
+      }
+      place++;
+      depends.remove(qfr.getName());
+    }
+    currentList.add(place,queryFacet);
+    for (int count = place+1; count < currentList.size(); count++) {
+      currentList.get(count).getDependencies().remove(queryFacet.getName());
+    }
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/AnalyticsStats.java solr/core/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
new file mode 100644
index 0000000..adc6807
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
@@ -0,0 +1,138 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Filter;
+import org.apache.solr.analytics.accumulator.BasicAccumulator;
+import org.apache.solr.analytics.accumulator.FacetingAccumulator;
+import org.apache.solr.analytics.accumulator.ValueAccumulator;
+import org.apache.solr.analytics.plugin.AnalyticsStatisticsCollector;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.search.DocSet;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Class which computes the set of {@link AnalyticsRequest}s.
+ */
+public class AnalyticsStats {
+  protected DocSet docs;
+  protected SolrParams params;
+  protected SolrIndexSearcher searcher;
+  protected SolrQueryRequest req;
+  protected AnalyticsStatisticsCollector statsCollector;
+  private static final Logger log = LoggerFactory.getLogger(AnalyticsStats.class);
+  
+  public AnalyticsStats(SolrQueryRequest req, DocSet docs, SolrParams params, AnalyticsStatisticsCollector statsCollector) {
+    this.req = req;
+    this.searcher = req.getSearcher();
+    this.docs = docs;
+    this.params = params; 
+    this.statsCollector = statsCollector;
+  }
+
+  /**
+   * Calculates the analytics requested in the Parameters.
+   * 
+   * @return List of results formated to mirror the input XML.
+   * @throws IOException if execution fails
+   */
+  public NamedList<?> execute() throws IOException {
+    statsCollector.startRequest();
+    NamedList<Object> res = new NamedList<>();
+    List<AnalyticsRequest> requests;
+    
+    requests = AnalyticsRequestFactory.parse(searcher.getSchema(), params);
+
+    if(requests == null || requests.size()==0){
+      return res;
+    }
+    statsCollector.addRequests(requests.size());
+    
+    // Get filter to all docs
+    Filter filter = docs.getTopFilter();
+    
+    // Computing each Analytics Request Seperately
+    for( AnalyticsRequest areq : requests ){
+      // The Accumulator which will control the statistics generation
+      // for the entire analytics request
+      ValueAccumulator accumulator; 
+      
+      // The number of total facet requests
+      int facets = areq.getFieldFacets().size()+areq.getRangeFacets().size()+areq.getQueryFacets().size();
+      try {
+        if( facets== 0 ){
+          accumulator = BasicAccumulator.create(searcher, docs, areq);
+        } else {
+          accumulator = FacetingAccumulator.create(searcher, docs, areq, req);
+        }
+      } catch (IOException e) {
+        log.warn("Analytics request '"+areq.getName()+"' failed", e);
+        continue;
+      }
+
+      statsCollector.addStatsCollected(((BasicAccumulator)accumulator).getNumStatsCollectors());
+      statsCollector.addStatsRequests(areq.getExpressions().size());
+      statsCollector.addFieldFacets(areq.getFieldFacets().size());
+      statsCollector.addRangeFacets(areq.getRangeFacets().size());
+      statsCollector.addQueryFacets(areq.getQueryFacets().size());
+      statsCollector.addQueries(((BasicAccumulator)accumulator).getNumQueries());
+      
+      // Loop through the documents returned by the query and add to accumulator
+      List<AtomicReaderContext> contexts = searcher.getTopReaderContext().leaves();
+      for (int leafNum = 0; leafNum < contexts.size(); leafNum++) {
+        AtomicReaderContext context = contexts.get(leafNum);
+        DocIdSet dis = filter.getDocIdSet(context, null); // solr docsets already exclude any deleted docs
+        DocIdSetIterator disi = null;
+        if (dis != null) {
+          disi = dis.iterator();
+        }
+
+        if (disi != null) {
+          accumulator.getLeafCollector(context);
+          int doc = disi.nextDoc();
+          while( doc != DocIdSetIterator.NO_MORE_DOCS){
+            // Add a document to the statistics being generated
+            accumulator.collect(doc);
+            doc = disi.nextDoc();
+          }
+        }
+      }
+      
+      // do some post-processing
+      accumulator.postProcess();
+     
+      // compute the stats
+      accumulator.compute();
+      
+      res.add(areq.getName(),accumulator.export());
+    }
+
+    statsCollector.endRequest();
+    return res;
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/ExpressionRequest.java solr/core/src/java/org/apache/solr/analytics/request/ExpressionRequest.java
new file mode 100644
index 0000000..1549cdf
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/ExpressionRequest.java
@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import org.apache.solr.analytics.expression.Expression;
+
+/**
+ * Contains name and string representation of an expression.
+ */
+public class ExpressionRequest implements Comparable<ExpressionRequest> {
+  private String name;
+  private String expressionString;
+  private Expression expression;
+  
+  /**
+   * @param name The name of the Expression.
+   * @param expressionString The string representation of the desired Expression.
+   */
+  public ExpressionRequest(String name, String expressionString) {
+    this.name = name;
+    this.expressionString = expressionString;
+  }
+
+  public void setExpressionString(String expressionString) {
+    this.expressionString = expressionString;
+  }
+  
+  public String getExpressionString() {
+    return expressionString;
+  }
+  
+  public void setExpression(Expression expression) {
+    this.expression = expression;
+  }
+  
+  public Expression getExpression() {
+    return expression;
+  }
+  
+  public void setName(String name) {
+    this.name = name;
+  }
+  
+  public String getName() {
+    return name;
+  }
+
+  @Override
+  public int compareTo(ExpressionRequest o) {
+    return name.compareTo(o.getName());
+  }
+  
+  @Override
+  public String toString() {
+    return "<ExpressionRequest name=" + name + " expression=" + expressionString + "/>";
+  }
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/FacetRequest.java solr/core/src/java/org/apache/solr/analytics/request/FacetRequest.java
new file mode 100644
index 0000000..6cca99d
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/FacetRequest.java
@@ -0,0 +1,27 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+public interface FacetRequest {
+  
+  /**
+   * Get the name of this facet (commonly the field name)
+   * @return the name
+   */
+  String getName();  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java solr/core/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java
new file mode 100644
index 0000000..7884476
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/FieldFacetRequest.java
@@ -0,0 +1,173 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.schema.SchemaField;
+
+import java.util.Locale;
+
+
+/**
+ * Contains all of the specifications for a field facet.
+ */
+public class FieldFacetRequest extends AbstractFieldFacetRequest {
+
+  private FacetSortSpecification sort = null;
+  private FacetSortDirection dir = null;
+  private int limit;
+  private int offset;
+  private boolean missing;
+  private boolean hidden;
+  
+  
+  public static enum FacetSortDirection {
+    ASCENDING ,
+    DESCENDING;
+   
+    public static FacetSortDirection fromExternal(String value){
+      final String sort = value.toLowerCase(Locale.ROOT);
+      if( "asc".equals(sort) )            return ASCENDING;
+      if( "ascending".equals(sort) )      return ASCENDING;
+      if( "desc".equals(sort) )           return DESCENDING;
+      if( "descending".equals(sort) )     return DESCENDING;
+      return Enum.valueOf(FacetSortDirection.class, value);
+    }
+  }
+  
+  /**
+   * Specifies how to sort the buckets of a field facet.
+   * 
+   */
+  public static class FacetSortSpecification {
+    private String statistic;
+    private FacetSortDirection direction = FacetSortDirection.DESCENDING;
+    
+    public FacetSortSpecification(){}
+    
+    /**
+     * @param statistic The name of a statistic specified in the {@link AnalyticsRequest}
+     * which is wrapping the {@link FieldFacetRequest} being sorted.
+     */
+    public FacetSortSpecification(String statistic) {
+      this.statistic = statistic;
+    }
+    
+    public FacetSortSpecification(String statistic, FacetSortDirection direction) {
+      this(statistic);
+      this.direction = direction;
+    }
+    
+    public String getStatistic() {
+      return statistic;
+    }
+    public void setStatistic(String statistic) {
+      this.statistic = statistic;
+    }
+    public FacetSortDirection getDirection() {
+      return direction;
+    }
+    public void setDirection(FacetSortDirection direction) {
+      this.direction = direction;
+    }
+
+    public static FacetSortSpecification fromExternal(String spec){
+      String[] parts = spec.split(" ",2);
+      if( parts.length == 1 ){
+        return new FacetSortSpecification(parts[0]);
+      } else {
+        return new FacetSortSpecification(parts[0], FacetSortDirection.fromExternal(parts[1]));
+      }
+    }
+
+    @Override
+    public String toString() {
+      return "<SortSpec stat=" + statistic + " dir=" + direction + ">";
+    }
+  }
+
+  public FieldFacetRequest(SchemaField field) {
+    super(field);
+    this.limit = AnalyticsParams.DEFAULT_LIMIT;
+    this.hidden = AnalyticsParams.DEFAULT_HIDDEN;
+  }
+
+  public FacetSortDirection getDirection() {
+    return dir;
+  }
+
+  public void setDirection(String dir) {
+    this.dir = FacetSortDirection.fromExternal(dir);
+    if (sort!=null) {
+      sort.setDirection(this.dir);
+    }
+  }
+
+  public FacetSortSpecification getSort() {
+    return sort;
+  }
+
+  public void setSort(FacetSortSpecification sort) {
+    this.sort = sort;
+  }
+
+  public boolean showsMissing() {
+    return missing;
+  }
+
+  /**
+   * If there are missing values in the facet field, include the bucket 
+   * for the missing facet values in the facet response.
+   * @param missing true/false if we calculate missing
+   */
+  public void showMissing(boolean missing) {
+    this.missing = missing;
+  }
+
+  public int getLimit() {
+    return limit;
+  }
+
+  public void setLimit(int limit) {
+    this.limit = limit;
+  }
+  
+  public int getOffset() {
+    return offset;
+  }
+
+  public void setOffset(int offset) {
+    this.offset = offset;
+  }
+
+  public boolean isHidden() {
+    return hidden;
+  }
+
+  public void setHidden(boolean hidden) {
+    this.hidden = hidden;
+  }
+
+  @Override
+  public String toString() {
+    return "<FieldFacetRequest field="+field.getName()+(sort==null?"":" sort=" + sort) + " limit=" + limit+" offset="+offset+">";
+  }
+
+
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java solr/core/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java
new file mode 100644
index 0000000..b02740c
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/QueryFacetRequest.java
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * Contains all of the specifications for a query facet.
+ */
+public class QueryFacetRequest implements FacetRequest {
+  private String name;
+  private List<String> queries;
+  private Set<String> dependencies;
+  
+  public QueryFacetRequest() {
+    dependencies = new HashSet<>();
+  }
+
+  public QueryFacetRequest(String name) {
+    this.name = name;
+    this.queries = new ArrayList<>();
+    dependencies = new HashSet<>();
+  }
+ 
+  public List<String> getQueries() {
+    return queries;
+  }
+
+  public void setQueries(List<String> queries) {
+    this.queries = queries;
+  }
+
+  public void addQuery(String query) {
+    queries.add(query);
+  }
+
+  public Set<String> getDependencies() {
+    return dependencies;
+  }
+
+  public void setDependencies(Set<String> dependencies) {
+    this.dependencies = dependencies;
+  }
+
+  public void addDependency(String dependency) {
+    dependencies.add(dependency);
+  }
+
+  public String getName() {
+    return name;
+  }
+
+  public void setName(String name) {
+    this.name = name;
+  }
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java solr/core/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java
new file mode 100644
index 0000000..8c70b98
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/RangeFacetRequest.java
@@ -0,0 +1,130 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.request;
+
+import java.util.Arrays;
+import java.util.EnumSet;
+
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
+import org.apache.solr.common.params.FacetParams.FacetRangeOther;
+import org.apache.solr.schema.SchemaField;
+
+/**
+ * Contains all of the specifications for a range facet.
+ */
+public class RangeFacetRequest extends AbstractFieldFacetRequest {
+  protected String start;
+  protected String end;
+  protected String[] gaps;
+  protected boolean hardEnd = false;
+  protected EnumSet<FacetRangeInclude> include;
+  protected boolean includeCalled = false;
+  protected EnumSet<FacetRangeOther> others;
+  protected boolean othersCalled = false;
+  
+  public RangeFacetRequest(SchemaField field) {
+    super(field);
+    include = EnumSet.of(AnalyticsParams.DEFAULT_INCLUDE);
+    others = EnumSet.of(AnalyticsParams.DEFAULT_OTHER);
+  }
+  
+  public RangeFacetRequest(SchemaField field, String start, String end, String[] gaps) {
+    super(field);
+    this.start = start;
+    this.end = end;
+    this.gaps = gaps;
+  }
+
+  public String getStart() {
+    return start;
+  }
+
+  public void setStart(String start) {
+    this.start = start;
+  }
+
+  public String getEnd() {
+    return end;
+  }
+
+  public void setEnd(String end) {
+    this.end = end;
+  }
+
+  public EnumSet<FacetRangeInclude> getInclude() {
+    return include;
+  }
+
+  public void setInclude(EnumSet<FacetRangeInclude> include) {
+    includeCalled = true;
+    this.include = include;
+  }
+
+  public void addInclude(FacetRangeInclude include) {
+    if (includeCalled) {
+      this.include.add(include);
+    } else {
+      includeCalled = true;
+      this.include = EnumSet.of(include);
+    }
+  }
+
+  public String[] getGaps() {
+    return gaps;
+  }
+
+  public void setGaps(String[] gaps) {
+    this.gaps = gaps;
+  }
+
+  public boolean isHardEnd() {
+    return hardEnd;
+  }
+
+  public void setHardEnd(boolean hardEnd) {
+    this.hardEnd = hardEnd;
+  }
+
+  public EnumSet<FacetRangeOther> getOthers() {
+    return others;
+  }
+
+  public void setOthers(EnumSet<FacetRangeOther> others) {
+    othersCalled = true;
+    this.others = others;
+  }
+
+  public void addOther(FacetRangeOther other) {
+    if (othersCalled) {
+      this.others.add(other);
+    } else {
+      othersCalled = true;
+      this.others = EnumSet.of(other);
+    }
+  }
+
+  @Override
+  public String toString() {
+    return "<RangeFacetRequest field="+field.getName() + " start=" + start + ", end=" + end + ", gap=" + Arrays.toString(gaps) + ", hardEnd=" + hardEnd + 
+                               ", include=" + include + ", others=" + others +">";
+  }
+
+  
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/request/package.html solr/core/src/java/org/apache/solr/analytics/request/package.html
new file mode 100644
index 0000000..08822a9
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/request/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Request objects for creating Analytics requests
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java
new file mode 100644
index 0000000..093ab29
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/AbstractDelegatingStatsCollector.java
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.util.mutable.MutableValue;
+
+/**
+ * <code>AbstractDelegationStatsCollector</code> objects wrap other StatsCollectors.
+ * While they compute their own statistics they pass along all inputs and requests
+ * to the delegates as well.
+ */
+public abstract class AbstractDelegatingStatsCollector implements StatsCollector{
+  protected final StatsCollector delegate;
+  protected final Set<String> statsList;
+  MutableValue value;
+  FunctionValues function;
+  
+  /**
+   * @param delegate The delegate computing statistics on the same set of values.
+   */
+  public AbstractDelegatingStatsCollector(StatsCollector delegate) {
+    this.delegate = delegate;
+    this.statsList = delegate.getStatsList();
+  }
+  
+  public void setNextReader(AtomicReaderContext context) throws IOException {
+    delegate.setNextReader(context);
+    value = getValue();
+    function = getFunction();
+  }
+  
+  public StatsCollector delegate(){
+    return delegate;
+  }
+  
+  public Set<String> getStatsList(){
+    return statsList;
+  }
+  
+  public MutableValue getValue() {
+    return delegate.getValue();
+  }
+  
+  public FunctionValues getFunction() {
+    return delegate.getFunction();
+  }
+  
+  public void collect(int doc) {
+    delegate.collect(doc);
+  }
+  
+  public String valueSourceString() {
+    return delegate.valueSourceString();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java
new file mode 100644
index 0000000..8095536
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/MedianStatsCollector.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
+
+import org.apache.solr.analytics.util.MedianCalculator;
+
+/**
+ * <code>MedianStatsCollector</code> computes the median.
+ */
+public class MedianStatsCollector extends AbstractDelegatingStatsCollector{
+
+  private final List<Double> values = new ArrayList<>();
+  protected double median;
+  
+  public MedianStatsCollector(StatsCollector delegate) {
+    super(delegate);
+  }
+
+  public Double getMedian() {
+    return new Double(MedianCalculator.getMedian(values));
+  }
+
+  @Override
+  public Comparable getStat(String stat) {
+    if (stat.equals("median")) {
+      return new Double(median);
+    }
+    return delegate.getStat(stat);
+  }
+  
+  public void compute(){
+    delegate.compute();
+    median = getMedian();
+  }
+  
+  @Override
+  public void collect(int doc) {
+    super.collect(doc);
+    if (value.exists) {
+      values.add(function.doubleVal(doc));
+    }
+  }
+}
+class DateMedianStatsCollector extends MedianStatsCollector{
+  
+  public DateMedianStatsCollector(StatsCollector delegate) {
+    super(delegate);
+  }
+
+  @Override
+  public Comparable getStat(String stat) {
+    if (stat.equals("median")) {
+      return new Date((long)median);
+    }
+    return delegate.getStat(stat);
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java
new file mode 100644
index 0000000..45cec2b
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/MinMaxStatsCollector.java
@@ -0,0 +1,115 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.io.IOException;
+import java.util.Locale;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.FunctionValues.ValueFiller;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.util.mutable.MutableValue;
+
+/**
+ * <code>MinMaxStatsCollector</code> computes the min, max, number of values and number of missing values.
+ */
+public class MinMaxStatsCollector implements StatsCollector{
+  protected long missingCount = 0;
+  protected long valueCount = 0;
+  protected MutableValue max;
+  protected MutableValue min;
+  protected MutableValue value;
+  protected final Set<String> statsList;
+  protected final ValueSource source;
+  protected FunctionValues function;
+  protected ValueFiller valueFiller;
+  
+  public MinMaxStatsCollector(ValueSource source, Set<String> statsList) {
+    this.source = source;
+    this.statsList = statsList;
+  }
+  
+  public void setNextReader(AtomicReaderContext context) throws IOException {
+    function = source.getValues(null, context);
+    valueFiller = function.getValueFiller();
+    value = valueFiller.getValue();
+  }
+  
+  public void collect(int doc) {
+    valueFiller.fillValue(doc);
+    if( value.exists ){
+      valueCount += 1;
+      if ( max==null ) max = value.duplicate();
+      else if( !max.exists || value.compareTo(max) > 0 ) max.copy(value);
+      if ( min==null ) min = value.duplicate();
+      else if( !min.exists || value.compareTo(min) < 0 ) min.copy(value);
+    } else {
+      missingCount += 1;
+    }
+  }
+ 
+  @Override
+  public String toString() {
+    return String.format(Locale.ROOT, "<min=%s max=%s c=%d m=%d>", min, max, valueCount, missingCount );
+  }
+  
+  public Comparable getStat(String stat){
+    if (stat.equals("min")&&min!=null) {
+      return (Comparable)min.toObject();
+    }
+    if (stat.equals("max")&&max!=null) {
+      return (Comparable)max.toObject();
+    }
+    if (stat.equals("count")) {
+      return new Long(valueCount);
+    }
+    if (stat.equals("missing")) {
+      return new Long(missingCount);
+    }
+
+    return null;
+//    throw new IllegalArgumentException("No stat named '"+stat+"' in this collector " + this);
+  }
+  
+  public Set<String> getStatsList() {
+    return statsList;
+  }
+
+  @Override
+  public void compute() {  }
+  
+  @Override 
+  public MutableValue getValue() {
+    return value;
+  }
+  
+  @Override 
+  public FunctionValues getFunction() {
+    return function;
+  }
+  
+  public String valueSourceString() {
+    return source.toString();
+  }
+  
+  public String statString(String stat) {
+    return stat+"("+valueSourceString()+")";
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java
new file mode 100644
index 0000000..ef3de5d
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/NumericStatsCollector.java
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.util.Set;
+
+import org.apache.lucene.queries.function.ValueSource;
+
+/**
+ * <code>NumericStatsCollector</code> computes the sum, sum of squares, mean and standard deviation.
+ */
+public class NumericStatsCollector extends MinMaxStatsCollector {
+  protected double sum = 0;
+  protected double sumOfSquares = 0;
+  protected double mean = 0;
+  protected double stddev = 0;
+  
+  public NumericStatsCollector(ValueSource source, Set<String> statsList) {
+    super(source, statsList);
+  }
+  
+  public void collect(int doc) {
+    super.collect(doc);
+    double value = function.doubleVal(doc);
+    sum += value;
+    sumOfSquares += (value * value);
+  }
+  
+  @Override
+  public Comparable getStat(String stat) {
+    if (stat.equals("sum")) {
+      return new Double(sum);
+    }
+    if (stat.equals("sumofsquares")) {
+      return new Double(sumOfSquares);
+    }
+    if (stat.equals("mean")) {
+      return new Double(mean);
+    }
+    if (stat.equals("stddev")) {
+      return new Double(stddev);
+    }
+    return super.getStat(stat);
+  }  
+  
+  @Override
+  public void compute(){
+    super.compute();
+    mean = (valueCount==0)? 0:sum / valueCount;
+    stddev = (valueCount <= 1) ? 0.0D : Math.sqrt((sumOfSquares/valueCount) - (mean*mean));
+  }
+  
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java
new file mode 100644
index 0000000..2ddfb99
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/PercentileStatsCollector.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Pattern;
+
+import org.apache.solr.analytics.util.PercentileCalculator;
+
+import com.google.common.collect.Iterables;
+
+/**
+ * <code>PercentileStatsCollector</code> computes a given list of percentiles.
+ */
+@SuppressWarnings("rawtypes")
+public class PercentileStatsCollector extends AbstractDelegatingStatsCollector{
+  public final List<Comparable> values = new ArrayList<>();
+  public static final Pattern PERCENTILE_PATTERN = Pattern.compile("perc(?:entile)?_(\\d+)",Pattern.CASE_INSENSITIVE);
+  protected final double[] percentiles;
+  protected final String[] percentileNames;
+  protected Comparable[] results;
+  
+  public PercentileStatsCollector(StatsCollector delegate, double[] percentiles, String[] percentileNames) {
+    super(delegate);
+    this.percentiles = percentiles;
+    this.percentileNames = percentileNames;
+  }
+
+  @Override
+  public Comparable getStat(String stat) {
+    for( int i=0; i < percentiles.length; i++ ){
+      if (stat.equals(percentileNames[i])) {
+        if (results!=null) {
+          return results[i];
+        } else {
+          return null;
+        }
+      }
+    }
+    return delegate.getStat(stat);
+  }
+
+  public void compute(){
+    delegate.compute();
+    if (values.size()>0) {
+      results = Iterables.toArray(getPercentiles(),Comparable.class);
+    } else {
+      results = null;
+    }
+  }
+
+  @SuppressWarnings({ "unchecked"})
+  protected List<Comparable> getPercentiles() {
+    return PercentileCalculator.getPercentiles(values, percentiles);
+  }
+  
+  public void collect(int doc) {
+    super.collect(doc);
+    if (value.exists) {
+      values.add((Comparable)value.toObject());
+    }
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollector.java
new file mode 100644
index 0000000..b3f173d
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollector.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.util.mutable.MutableValue;
+
+/**
+ * <code>StatsCollector</code> implementations reduce a list of Objects to a single value.
+ * Most implementations reduce a list to a statistic on that list.
+ */
+public interface StatsCollector {
+  
+  /**
+   * Collect values from the value source and add to statistics.
+   * @param doc Document to collect from
+   */
+  void collect(int doc);
+  
+  /**
+   * @param context The context to read documents from.
+   * @throws IOException if setting next reader fails
+   */
+  void setNextReader(AtomicReaderContext context) throws IOException;
+  
+  MutableValue getValue();
+  FunctionValues getFunction();
+  
+  /**
+   * @return The set of statistics being computed by the stats collector.
+   */
+  Set<String> getStatsList();
+  
+  /**
+   * Return the value of the given statistic.
+   * @param stat the stat
+   * @return a comparable
+   */
+  Comparable getStat(String stat);
+  
+  /**
+   * After all documents have been collected, this method should be
+   * called to finalize the calculations of each statistic.
+   */
+  void compute();
+  
+  /**
+   * @return The string representation of the value source.
+   */
+  String valueSourceString();
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java
new file mode 100644
index 0000000..35b5d58
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/StatsCollectorSupplierFactory.java
@@ -0,0 +1,658 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeMap;
+
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
+import org.apache.lucene.queries.function.valuesource.DoubleFieldSource;
+import org.apache.lucene.queries.function.valuesource.FloatFieldSource;
+import org.apache.lucene.queries.function.valuesource.IntFieldSource;
+import org.apache.lucene.queries.function.valuesource.LongFieldSource;
+import org.apache.solr.analytics.expression.ExpressionFactory;
+import org.apache.solr.analytics.request.ExpressionRequest;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.analytics.util.AnalyticsParsers;
+import org.apache.solr.analytics.util.valuesource.AbsoluteValueDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.AddDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.ConcatStringFunction;
+import org.apache.solr.analytics.util.valuesource.ConstDateSource;
+import org.apache.solr.analytics.util.valuesource.ConstDoubleSource;
+import org.apache.solr.analytics.util.valuesource.ConstStringSource;
+import org.apache.solr.analytics.util.valuesource.DateFieldSource;
+import org.apache.solr.analytics.util.valuesource.DateMathFunction;
+import org.apache.solr.analytics.util.valuesource.DivDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.DualDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.FilterFieldSource;
+import org.apache.solr.analytics.util.valuesource.LogDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.MultiDateFunction;
+import org.apache.solr.analytics.util.valuesource.MultiDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.MultiplyDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.NegateDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.PowDoubleFunction;
+import org.apache.solr.analytics.util.valuesource.ReverseStringFunction;
+import org.apache.solr.analytics.util.valuesource.SingleDoubleFunction;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.IndexSchema;
+import org.apache.solr.schema.SchemaField;
+import org.apache.solr.schema.StrField;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.schema.TrieDoubleField;
+import org.apache.solr.schema.TrieFloatField;
+import org.apache.solr.schema.TrieIntField;
+import org.apache.solr.schema.TrieLongField;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.base.Supplier;
+
+public class StatsCollectorSupplierFactory {
+  private static final Logger log = LoggerFactory.getLogger(StatsCollectorSupplierFactory.class);
+  
+  // FunctionTypes
+  final static int NUMBER_TYPE = 0;
+  final static int DATE_TYPE = 1;
+  final static int STRING_TYPE = 2;
+  final static int FIELD_TYPE = 3;
+  final static int FILTER_TYPE = 4;
+  
+  /**
+   * Builds a Supplier that will generate identical arrays of new StatsCollectors.
+   * 
+   * @param schema The Schema being used.
+   * @param exRequests The expression requests to generate a StatsCollector[] from.
+   * @return A Supplier that will return an array of new StatsCollector.
+   */
+  @SuppressWarnings("unchecked")
+  public static Supplier<StatsCollector[]> create(IndexSchema schema, List<ExpressionRequest> exRequests ) {
+    final Map<String, Set<String>> collectorStats =  new TreeMap<>();
+    final Map<String, Set<Integer>> collectorPercs =  new TreeMap<>();
+    final Map<String, ValueSource> collectorSources =  new TreeMap<>();
+    
+    // Iterate through all expression request to make a list of ValueSource strings
+    // and statistics that need to be calculated on those ValueSources.
+    for (ExpressionRequest expRequest : exRequests) {
+      String statExpression = expRequest.getExpressionString();
+      Set<String> statistics = getStatistics(statExpression);
+      if (statistics == null) {
+        continue;
+      }
+      for (String statExp : statistics) {
+        String stat;
+        String operands;
+        try {
+          stat = statExp.substring(0, statExp.indexOf('(')).trim();
+          operands = statExp.substring(statExp.indexOf('(')+1, statExp.lastIndexOf(')')).trim();
+        } catch (Exception e) {
+          throw new SolrException(ErrorCode.BAD_REQUEST,"Unable to parse statistic: ["+statExpression+"]",e);
+        }
+        String[] arguments = ExpressionFactory.getArguments(operands);
+        String source = arguments[0];
+        if (stat.equals(AnalyticsParams.STAT_PERCENTILE)) {
+          // The statistic is a percentile, extra parsing is required
+          if (arguments.length<2) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"Too few arguments given for "+stat+"() in ["+statExp+"].");
+          } else if (arguments.length>2) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"Too many arguments given for "+stat+"() in ["+statExp+"].");
+          }
+          source = arguments[1];
+          Set<Integer> percs = collectorPercs.get(source);
+          if (percs == null) {
+            percs = new HashSet<>();
+            collectorPercs.put(source, percs);
+          }
+          try {
+            int perc = Integer.parseInt(arguments[0]);
+            if (perc>0 && perc<100) {
+              percs.add(perc);
+            } else {
+              throw new SolrException(ErrorCode.BAD_REQUEST,"The percentile in ["+statExp+"] is not between 0 and 100, exculsive.");
+            }
+          } catch (NumberFormatException e) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+arguments[0]+"\" cannot be converted into a percentile.",e);
+          }
+        } else if (arguments.length>1) {
+          throw new SolrException(ErrorCode.BAD_REQUEST,"Too many arguments given for "+stat+"() in ["+statExp+"].");
+        } else if (arguments.length==0) {
+          throw new SolrException(ErrorCode.BAD_REQUEST,"No arguments given for "+stat+"() in ["+statExp+"].");
+        } 
+        // Only unique ValueSources will be made; therefore statistics must be accumulated for
+        // each ValueSource, even across different expression requests
+        Set<String> stats = collectorStats.get(source);
+        if (stats == null) {
+          stats = new HashSet<>();
+          collectorStats.put(source, stats);
+        }
+        if(AnalyticsParams.STAT_PERCENTILE.equals(stat)) {
+          stats.add(stat + "_"+ arguments[0]);
+        } else {
+          stats.add(stat);
+        }
+      }
+    }
+    String[] keys = collectorStats.keySet().toArray(new String[0]);
+    for (String sourceStr : keys) {
+      // Build one ValueSource for each unique value source string
+      ValueSource source = buildSourceTree(schema, sourceStr);
+      if (source == null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The statistic ["+sourceStr+"] could not be parsed.");
+      }
+      String builtString = source.toString();
+      collectorSources.put(builtString,source);
+      // Replace the user given string with the correctly built string
+      if (!builtString.equals(sourceStr)) {
+        Set<String> stats = collectorStats.remove(sourceStr);
+        if (stats!=null) {
+          collectorStats.put(builtString, stats);
+        }
+        Set<Integer> percs = collectorPercs.remove(sourceStr);
+        if (percs!=null) {
+          collectorPercs.put(builtString, percs);
+        }
+        for (ExpressionRequest er : exRequests) {
+          er.setExpressionString(er.getExpressionString().replace(sourceStr, builtString));
+        }
+      }
+    }
+    if (collectorSources.size()==0) {
+      return new Supplier<StatsCollector[]>() {
+        @Override
+        public StatsCollector[] get() {
+          return new StatsCollector[0];
+        }
+      };
+    }
+    
+    log.info("Stats objects: "+collectorStats.size()+" sr="+collectorSources.size()+" pr="+collectorPercs.size() );
+    
+    // All information is stored in final arrays so that nothing 
+    // has to be computed when the Supplier's get() method is called.
+    final Set<String>[] statsArr = collectorStats.values().toArray(new Set[0]);
+    final ValueSource[] sourceArr = collectorSources.values().toArray(new ValueSource[0]);
+    final boolean[] uniqueBools = new boolean[statsArr.length];
+    final boolean[] medianBools = new boolean[statsArr.length];
+    final boolean[] numericBools = new boolean[statsArr.length];
+    final boolean[] dateBools = new boolean[statsArr.length];
+    final double[][] percsArr = new double[statsArr.length][];
+    final String[][] percsNames = new String[statsArr.length][];
+    for (int count = 0; count < sourceArr.length; count++) {
+      uniqueBools[count] = statsArr[count].contains(AnalyticsParams.STAT_UNIQUE);
+      medianBools[count] = statsArr[count].contains(AnalyticsParams.STAT_MEDIAN);
+      numericBools[count] = statsArr[count].contains(AnalyticsParams.STAT_SUM)||statsArr[count].contains(AnalyticsParams.STAT_SUM_OF_SQUARES)||statsArr[count].contains(AnalyticsParams.STAT_MEAN)||statsArr[count].contains(AnalyticsParams.STAT_STANDARD_DEVIATION);
+      dateBools[count] = (sourceArr[count] instanceof DateFieldSource) | (sourceArr[count] instanceof MultiDateFunction) | (sourceArr[count] instanceof ConstDateSource);
+      Set<Integer> ps = collectorPercs.get(sourceArr[count].toString());
+      if (ps!=null) {
+        percsArr[count] = new double[ps.size()];
+        percsNames[count] = new String[ps.size()];
+        int percCount = 0;
+        for (int p : ps) {
+          percsArr[count][percCount] = p/100.0;
+          percsNames[count][percCount++] = AnalyticsParams.STAT_PERCENTILE+"_"+p;
+        }
+      }
+    }
+    // Making the Supplier
+    return new Supplier<StatsCollector[]>() {
+      public StatsCollector[] get() {
+        StatsCollector[] collectors = new StatsCollector[statsArr.length];
+        for (int count = 0; count < statsArr.length; count++) {
+          if(numericBools[count]){
+            StatsCollector sc = new NumericStatsCollector(sourceArr[count], statsArr[count]);
+            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
+            if(medianBools[count]) sc = new MedianStatsCollector(sc);
+            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
+            collectors[count]=sc;
+          } else if (dateBools[count]) {
+            StatsCollector sc = new MinMaxStatsCollector(sourceArr[count], statsArr[count]);
+            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
+            if(medianBools[count]) sc = new DateMedianStatsCollector(sc);
+            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
+           collectors[count]=sc;
+          } else {
+            StatsCollector sc = new MinMaxStatsCollector(sourceArr[count], statsArr[count]);
+            if(uniqueBools[count]) sc = new UniqueStatsCollector(sc);
+            if(medianBools[count]) sc = new MedianStatsCollector(sc);
+            if(percsArr[count]!=null) sc = new PercentileStatsCollector(sc,percsArr[count],percsNames[count]);
+            collectors[count]=sc;
+          }
+        }
+        return collectors;
+      }
+    };
+  }
+  
+  /**
+   * Finds the set of statistics that must be computed for the expression.
+   * @param expression The string representation of an expression
+   * @return The set of statistics (sum, mean, median, etc.) found in the expression
+   */
+  public static Set<String> getStatistics(String expression) {
+    HashSet<String> set = new HashSet<>();
+    int firstParen = expression.indexOf('(');
+    if (firstParen>0) {
+      String topOperation = expression.substring(0,firstParen).trim();
+      if (AnalyticsParams.ALL_STAT_SET.contains(topOperation)) {
+        set.add(expression);
+      } else if (!(topOperation.equals(AnalyticsParams.CONSTANT_NUMBER)||topOperation.equals(AnalyticsParams.CONSTANT_DATE)||topOperation.equals(AnalyticsParams.CONSTANT_STRING))) {
+        String operands = expression.substring(firstParen+1, expression.lastIndexOf(')')).trim();
+        String[] arguments = ExpressionFactory.getArguments(operands);
+        for (String argument : arguments) {
+          Set<String> more = getStatistics(argument);
+          if (more!=null) {
+            set.addAll(more);
+          }
+        }
+      }
+    }
+    if (set.size()==0) {
+      return null;
+    }
+    return set;
+  }
+  
+  /**
+   * Builds a Value Source from a given string
+   * 
+   * @param schema The schema being used.
+   * @param expression The string to be turned into an expression.
+   * @return The completed ValueSource
+   */
+  private static ValueSource buildSourceTree(IndexSchema schema, String expression) {
+    return buildSourceTree(schema,expression,FIELD_TYPE);
+  }
+  
+  /**
+   * Builds a Value Source from a given string and a given source type
+   * 
+   * @param schema The schema being used.
+   * @param expression The string to be turned into an expression.
+   * @param sourceType The type of source that must be returned.
+   * @return The completed ValueSource
+   */
+  private static ValueSource buildSourceTree(IndexSchema schema, String expression, int sourceType) {
+    int expressionType = getSourceType(expression);
+    if (sourceType != FIELD_TYPE && expressionType != FIELD_TYPE && 
+        expressionType != FILTER_TYPE && expressionType != sourceType) {
+      return null;
+    }
+    switch (expressionType) {
+    case NUMBER_TYPE : return buildNumericSource(schema, expression);
+    case DATE_TYPE : return buildDateSource(schema, expression);
+    case STRING_TYPE : return buildStringSource(schema, expression);
+    case FIELD_TYPE : return buildFieldSource(schema, expression, sourceType);
+    case FILTER_TYPE : return buildFilterSource(schema, expression.substring(expression.indexOf('(')+1,expression.lastIndexOf(')')), sourceType);
+    default : throw new SolrException(ErrorCode.BAD_REQUEST,expression+" is not a valid operation.");
+    }
+  }
+
+  /**
+   * Determines what type of value source the expression represents.
+   * 
+   * @param expression The expression representing the desired ValueSource
+   * @return NUMBER_TYPE, DATE_TYPE, STRING_TYPE or -1
+   */
+  private static int getSourceType(String expression) {
+    int paren = expression.indexOf('(');
+    if (paren<0) {
+      return FIELD_TYPE;
+    }
+    String operation = expression.substring(0,paren).trim();
+
+    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)) {
+      return NUMBER_TYPE;
+    } else if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)) {
+      return DATE_TYPE;
+    } else if (AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
+      return STRING_TYPE;
+    } else if (operation.equals(AnalyticsParams.FILTER)) {
+      return FILTER_TYPE;
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+operation+"\" in ["+expression+"] is not supported.");
+  }
+  
+  /**
+   *  Builds a value source for a given field, making sure that the field fits a given source type.
+   * @param schema the schema
+   * @param expressionString The name of the field to build a Field Source from.
+   * @param sourceType FIELD_TYPE for any type of field, NUMBER_TYPE for numeric fields, 
+   * DATE_TYPE for date fields and STRING_TYPE for string fields.
+   * @return a value source
+   */
+  private static ValueSource buildFieldSource(IndexSchema schema, String expressionString, int sourceType) {
+    SchemaField sf;
+    try {
+      sf = schema.getField(expressionString);
+    } catch (SolrException e) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,"The field "+expressionString+" does not exist.",e);
+    }
+    FieldType type = sf.getType();
+    if ( type instanceof TrieIntField) {
+      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new IntFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    } else if (type instanceof TrieLongField) {
+      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new LongFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    } else if (type instanceof TrieFloatField) {
+      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new FloatFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    } else if (type instanceof TrieDoubleField) {
+      if (sourceType!=NUMBER_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new DoubleFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    } else if (type instanceof TrieDateField) {
+      if (sourceType!=DATE_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new DateFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    } else if (type instanceof StrField) {
+      if (sourceType!=STRING_TYPE&&sourceType!=FIELD_TYPE) {
+        return null;
+      }
+      return new BytesRefFieldSource(expressionString) {
+        public String description() {
+          return field;
+        }
+      };
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST, type.toString()+" is not a supported field type in Solr Analytics.");
+  }
+  
+  /**
+   * Builds a default is missing source that wraps a given source. A missing value is required for all 
+   * non-field value sources.
+   * @param schema the schema
+   * @param expressionString The name of the field to build a Field Source from.
+   * @param sourceType FIELD_TYPE for any type of field, NUMBER_TYPE for numeric fields, 
+   * DATE_TYPE for date fields and STRING_TYPE for string fields.
+   * @return a value source
+   */
+  @SuppressWarnings("deprecation")
+  private static ValueSource buildFilterSource(IndexSchema schema, String expressionString, int sourceType) {
+    String[] arguments = ExpressionFactory.getArguments(expressionString);
+    if (arguments.length!=2) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,"Invalid arguments were given for \""+AnalyticsParams.FILTER+"\".");
+    }
+    ValueSource delegateSource = buildSourceTree(schema, arguments[0], sourceType);
+    if (delegateSource==null) {
+      return null;
+    }
+    Object defaultObject;
+
+    ValueSource src = delegateSource;
+    if (delegateSource instanceof FilterFieldSource) {
+      src = ((FilterFieldSource)delegateSource).getRootSource();
+    }
+    if ( src instanceof IntFieldSource) {
+      try {
+        defaultObject = new Integer(arguments[1]);
+      } catch (NumberFormatException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into an integer.",e);
+      }
+    } else if ( src instanceof DateFieldSource || src instanceof MultiDateFunction) {
+      try {
+        defaultObject = TrieDateField.parseDate(arguments[1]);
+      } catch (ParseException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a date.",e);
+      }
+    } else if ( src instanceof LongFieldSource ) {
+      try {
+        defaultObject = new Long(arguments[1]);
+      } catch (NumberFormatException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a long.",e);
+      }
+    } else if ( src instanceof FloatFieldSource ) {
+      try {
+        defaultObject = new Float(arguments[1]);
+      } catch (NumberFormatException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a float.",e);
+      }
+    } else if ( src instanceof DoubleFieldSource || src instanceof SingleDoubleFunction ||
+                src instanceof DualDoubleFunction|| src instanceof MultiDoubleFunction) {
+      try {
+        defaultObject = new Double(arguments[1]);
+      } catch (NumberFormatException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The filter value "+arguments[1]+" cannot be converted into a double.",e);
+      }
+    } else {
+      defaultObject = arguments[1];
+    }
+    return new FilterFieldSource(delegateSource,defaultObject);
+  } 
+  
+  /**
+   * Recursively parses and breaks down the expression string to build a numeric ValueSource.
+   * 
+   * @param schema The schema to pull fields from.
+   * @param expressionString The expression string to build a ValueSource from.
+   * @return The value source represented by the given expressionString
+   */
+  private static ValueSource buildNumericSource(IndexSchema schema, String expressionString) {
+    int paren = expressionString.indexOf('(');
+    String[] arguments;
+    String operands;
+    if (paren<0) {
+      return buildFieldSource(schema,expressionString,NUMBER_TYPE);
+    } else {
+      try {
+        operands = expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim();
+      } catch (Exception e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"Missing closing parenthesis in ["+expressionString+"]");
+      }
+      arguments = ExpressionFactory.getArguments(operands);
+    }
+    String operation = expressionString.substring(0, paren).trim();
+    if (operation.equals(AnalyticsParams.CONSTANT_NUMBER)) {
+      if (arguments.length!=1) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant number declaration ["+expressionString+"] does not have exactly 1 argument.");
+      }
+      return new ConstDoubleSource(Double.parseDouble(arguments[0]));
+    } else if (operation.equals(AnalyticsParams.NEGATE)) {
+      if (arguments.length!=1) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The negate operation ["+expressionString+"] does not have exactly 1 argument.");
+      }
+      ValueSource argSource = buildNumericSource(schema, arguments[0]);
+      if (argSource==null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+AnalyticsParams.NEGATE+"\" requires a numeric field or operation as argument. \""+arguments[0]+"\" is not a numeric field or operation.");
+      }
+      return new NegateDoubleFunction(argSource);
+    }  else if (operation.equals(AnalyticsParams.ABSOLUTE_VALUE)) {
+      if (arguments.length!=1) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The absolute value operation ["+expressionString+"] does not have exactly 1 argument.");
+      }
+      ValueSource argSource = buildNumericSource(schema, arguments[0]);
+      if (argSource==null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+AnalyticsParams.NEGATE+"\" requires a numeric field or operation as argument. \""+arguments[0]+"\" is not a numeric field or operation.");
+      }
+      return new AbsoluteValueDoubleFunction(argSource);
+    } else if (operation.equals(AnalyticsParams.FILTER)) {
+      return buildFilterSource(schema, operands, NUMBER_TYPE);
+    }
+    List<ValueSource> subExpressions = new ArrayList<>();
+    for (String argument : arguments) {
+      ValueSource argSource = buildNumericSource(schema, argument);
+      if (argSource == null) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The operation \""+operation+"\" requires numeric fields or operations as arguments. \""+argument+"\" is not a numeric field or operation.");
+      }
+      subExpressions.add(argSource);
+    }
+    if (operation.equals(AnalyticsParams.ADD)) {
+      return new AddDoubleFunction(subExpressions.toArray(new ValueSource[0]));
+    } else if (operation.equals(AnalyticsParams.MULTIPLY)) {
+      return new MultiplyDoubleFunction(subExpressions.toArray(new ValueSource[0]));
+    } else if (operation.equals(AnalyticsParams.DIVIDE)) {
+      if (subExpressions.size()!=2) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The divide operation ["+expressionString+"] does not have exactly 2 arguments.");
+      }
+      return new DivDoubleFunction(subExpressions.get(0),subExpressions.get(1));
+    } else if (operation.equals(AnalyticsParams.POWER)) {
+      if (subExpressions.size()!=2) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The power operation ["+expressionString+"] does not have exactly 2 arguments.");
+      }
+      return new PowDoubleFunction(subExpressions.get(0),subExpressions.get(1));
+    } else if (operation.equals(AnalyticsParams.LOG)) {
+      if (subExpressions.size()!=2) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The log operation ["+expressionString+"] does not have exactly 2 arguments.");
+      }
+      return new LogDoubleFunction(subExpressions.get(0), subExpressions.get(1));
+    } 
+    if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)||AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
+      return null;
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
+  }
+
+  
+  /**
+   * Recursively parses and breaks down the expression string to build a date ValueSource.
+   * 
+   * @param schema The schema to pull fields from.
+   * @param expressionString The expression string to build a ValueSource from.
+   * @return The value source represented by the given expressionString
+   */
+  @SuppressWarnings("deprecation")
+  private static ValueSource buildDateSource(IndexSchema schema, String expressionString) {
+    int paren = expressionString.indexOf('(');
+    String[] arguments;
+    if (paren<0) {
+      return buildFieldSource(schema, expressionString, DATE_TYPE);
+    } else {
+      arguments = ExpressionFactory.getArguments(expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim());
+    }
+    String operands = arguments[0];
+    String operation = expressionString.substring(0, paren).trim();
+    if (operation.equals(AnalyticsParams.CONSTANT_DATE)) {
+      if (arguments.length!=1) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant date declaration ["+expressionString+"] does not have exactly 1 argument.");
+      }
+      try {
+        return new ConstDateSource(TrieDateField.parseDate(operands));
+      } catch (ParseException e) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"The constant "+operands+" cannot be converted into a date.",e);
+      }
+    } else if (operation.equals(AnalyticsParams.FILTER)) {
+      return buildFilterSource(schema, operands, DATE_TYPE);
+    }
+    if (operation.equals(AnalyticsParams.DATE_MATH)) {
+      List<ValueSource> subExpressions = new ArrayList<>();
+      boolean first = true;
+      for (String argument : arguments) {
+        ValueSource argSource;
+        if (first) {
+          first = false;
+          argSource = buildDateSource(schema, argument);
+          if (argSource == null) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.DATE_MATH+"\" requires the first argument be a date operation or field. ["+argument+"] is not a date operation or field.");
+          }
+        } else {
+          argSource = buildStringSource(schema, argument);
+          if (argSource == null) {
+            throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.DATE_MATH+"\" requires that all arguments except the first be string operations. ["+argument+"] is not a string operation.");
+          }
+        }
+        subExpressions.add(argSource);
+      }
+      return new DateMathFunction(subExpressions.toArray(new ValueSource[0]));
+    }
+    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)||AnalyticsParams.STRING_OPERATION_SET.contains(operation)) {
+      return null;
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
+  }
+
+  
+  /**
+   * Recursively parses and breaks down the expression string to build a string ValueSource.
+   * 
+   * @param schema The schema to pull fields from.
+   * @param expressionString The expression string to build a ValueSource from.
+   * @return The value source represented by the given expressionString
+   */
+  private static ValueSource buildStringSource(IndexSchema schema, String expressionString) {
+    int paren = expressionString.indexOf('(');
+    String[] arguments;
+    if (paren<0) {
+      return buildFieldSource(schema, expressionString, FIELD_TYPE);
+    } else {
+      arguments = ExpressionFactory.getArguments(expressionString.substring(paren+1, expressionString.lastIndexOf(')')).trim());
+    }
+    String operands = arguments[0];
+    String operation = expressionString.substring(0, paren).trim();
+    if (operation.equals(AnalyticsParams.CONSTANT_STRING)) {
+      operands = expressionString.substring(paren+1, expressionString.lastIndexOf(')'));
+      return new ConstStringSource(operands);
+    } else if (operation.equals(AnalyticsParams.FILTER)) {
+      return buildFilterSource(schema,operands,FIELD_TYPE);
+    } else if (operation.equals(AnalyticsParams.REVERSE)) {
+      if (arguments.length!=1) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,"\""+AnalyticsParams.REVERSE+"\" requires exactly one argument. The number of arguments in "+expressionString+" is not 1.");
+      }
+      return new ReverseStringFunction(buildStringSource(schema, operands));
+    }
+    List<ValueSource> subExpressions = new ArrayList<>();
+    for (String argument : arguments) {
+      subExpressions.add(buildSourceTree(schema, argument));
+    }
+    if (operation.equals(AnalyticsParams.CONCATENATE)) {
+      return new ConcatStringFunction(subExpressions.toArray(new ValueSource[0]));
+    } 
+    if (AnalyticsParams.NUMERIC_OPERATION_SET.contains(operation)) {
+      return buildNumericSource(schema, expressionString);
+    } else if (AnalyticsParams.DATE_OPERATION_SET.contains(operation)) {
+      return buildDateSource(schema, expressionString);
+    }
+    throw new SolrException(ErrorCode.BAD_REQUEST,"The operation ["+expressionString+"] is not supported.");
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java solr/core/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java
new file mode 100644
index 0000000..a06a093
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/UniqueStatsCollector.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.statistics;
+
+import java.util.HashSet;
+import java.util.Set;
+
+/**
+ * <code>UniqueValueCounter</code> computes the number of unique values.
+ */
+public class UniqueStatsCollector extends AbstractDelegatingStatsCollector{
+  private final Set<Object> uniqueValues = new HashSet<>();
+  
+  public UniqueStatsCollector(StatsCollector delegate) {
+    super(delegate);
+  }
+  
+  @Override
+  public void collect(int doc) {
+    super.collect(doc);
+    if (value.exists) {
+      uniqueValues.add(value.toObject());
+    }
+  }
+
+  @Override
+  public Comparable getStat(String stat) {
+    if (stat.equals("unique")) {
+      return new Long(uniqueValues.size());
+    }
+    return delegate.getStat(stat);
+  }
+
+  @Override
+  public void compute() {
+    delegate.compute();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/statistics/package.html solr/core/src/java/org/apache/solr/analytics/statistics/package.html
new file mode 100644
index 0000000..99539fc
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/statistics/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Statistics collectors reduce a list of Objects to a single value. Most implementations reduce a list to a statistic on that list.
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParams.java solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParams.java
new file mode 100644
index 0000000..d7f220a
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParams.java
@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util;
+
+import java.util.Collections;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
+import org.apache.solr.common.params.FacetParams.FacetRangeOther;
+
+import com.google.common.collect.Lists;
+import com.google.common.collect.Sets;
+
+public interface AnalyticsParams {
+  // Full length Analytics Params
+  public static final String ANALYTICS = "olap";
+  
+  public static final String REQUEST = "o|olap";
+
+  public static final String EXPRESSION = "s|stat|statistic";
+  public static final String HIDDEN_EXPRESSION = "hs|hiddenstat|hiddenstatistic";
+
+  public static final String FIELD_FACET = "ff|fieldfacet";
+  public static final String LIMIT = "l|limit";
+  public static final String OFFSET = "off|offset";
+  public static final String HIDDEN = "h|hidden";
+  public static final String SHOW_MISSING = "sm|showmissing";
+  public static final String SORT_STATISTIC ="ss|sortstat|sortstatistic";
+  public static final String SORT_DIRECTION ="sd|sortdirection";
+  
+  public static final String RANGE_FACET = "rf|rangefacet";
+  public static final String START = "st|start";
+  public static final String END = "e|end";
+  public static final String GAP = "g|gap";
+  public static final String HARDEND = "he|hardend";
+  public static final String INCLUDE_BOUNDARY = "ib|includebound";
+  public static final String OTHER_RANGE = "or|otherrange";
+  
+  public static final String QUERY_FACET = "qf|queryfacet";
+  public static final String DEPENDENCY = "d|dependecy";
+  public static final String QUERY = "q|query";
+  
+  //Defaults
+  public static final boolean DEFAULT_ABBREVIATE_PREFIX = true;
+  public static final String DEFAULT_SORT_DIRECTION = "ascending";
+  public static final int DEFAULT_LIMIT = -1;
+  public static final boolean DEFAULT_HIDDEN = false;
+  public static final boolean DEFAULT_HARDEND = false;
+  public static final boolean DEFAULT_SHOW_MISSING = false;
+  public static final FacetRangeInclude DEFAULT_INCLUDE = FacetRangeInclude.LOWER;
+  public static final FacetRangeOther DEFAULT_OTHER = FacetRangeOther.NONE;
+  
+  // Statistic Function Names (Cannot share names with ValueSource & Expression Functions)
+  public static final String STAT_COUNT = "count";
+  public static final String STAT_MISSING = "missing";
+  public static final String STAT_SUM = "sum";
+  public static final String STAT_SUM_OF_SQUARES = "sumofsquares";
+  public static final String STAT_STANDARD_DEVIATION = "stddev";
+  public static final String STAT_MEAN = "mean";
+  public static final String STAT_UNIQUE = "unique";
+  public static final String STAT_MEDIAN = "median";
+  public static final String STAT_PERCENTILE = "percentile";
+  public static final String STAT_MIN = "min";
+  public static final String STAT_MAX = "max";
+  
+  public static final List<String> ALL_STAT_LIST = Collections.unmodifiableList(Lists.newArrayList(STAT_COUNT, STAT_MISSING, STAT_SUM, STAT_SUM_OF_SQUARES, STAT_STANDARD_DEVIATION, STAT_MEAN, STAT_UNIQUE, STAT_MEDIAN, STAT_PERCENTILE,STAT_MIN,STAT_MAX));
+  public static final Set<String> ALL_STAT_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(ALL_STAT_LIST));
+
+  // ValueSource & Expression Function Names (Cannot share names with Statistic Functions)
+  // No specific type
+  final static String FILTER = "filter";
+  final static String RESULT = "result";
+  final static String QUERY_RESULT = "qresult";
+  
+  // Numbers
+  final static String CONSTANT_NUMBER = "const_num";
+  final static String NEGATE = "neg";
+  final static String ABSOLUTE_VALUE = "abs";
+  final static String LOG = "log";
+  final static String ADD = "add";
+  final static String MULTIPLY = "mult";
+  final static String DIVIDE = "div";
+  final static String POWER = "pow";
+  public static final Set<String> NUMERIC_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_NUMBER,NEGATE,ABSOLUTE_VALUE,LOG,ADD,MULTIPLY,DIVIDE,POWER)));
+  
+  // Dates
+  final static String CONSTANT_DATE = "const_date";
+  final static String DATE_MATH = "date_math";
+  public static final Set<String> DATE_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_DATE,DATE_MATH)));
+  
+  //Strings
+  final static String CONSTANT_STRING = "const_str";
+  final static String REVERSE = "rev";
+  final static String CONCATENATE = "concat";
+  public static final Set<String> STRING_OPERATION_SET = Collections.unmodifiableSet(Sets.newLinkedHashSet(Lists.newArrayList(CONSTANT_STRING,REVERSE,CONCATENATE)));
+  
+  // Field Source Wrappers
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
new file mode 100644
index 0000000..0e4eceb
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/AnalyticsParsers.java
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Date;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.schema.TrieDoubleField;
+import org.apache.solr.schema.TrieFloatField;
+import org.apache.solr.schema.TrieIntField;
+import org.apache.solr.schema.TrieLongField;
+
+/** 
+ * Class to hold the parsers used for Solr Analytics.
+ */
+public class AnalyticsParsers {
+
+  /**
+   * Returns a parser that will translate a BytesRef or long from DocValues into 
+   * a String that correctly represents the value.
+   * @param class1 class of the FieldType of the field being faceted on.
+   * @return A Parser
+   */
+  public static Parser getParser(Class<? extends FieldType> class1) {
+    if (class1.equals(TrieIntField.class)) {
+      return AnalyticsParsers.INT_DOC_VALUES_PARSER;
+    } else if (class1.equals(TrieLongField.class)) {
+      return AnalyticsParsers.LONG_DOC_VALUES_PARSER;
+    } else if (class1.equals(TrieFloatField.class)) {
+      return AnalyticsParsers.FLOAT_DOC_VALUES_PARSER;
+    } else if (class1.equals(TrieDoubleField.class)) {
+      return AnalyticsParsers.DOUBLE_DOC_VALUES_PARSER;
+    } else if (class1.equals(TrieDateField.class)) {
+      return AnalyticsParsers.DATE_DOC_VALUES_PARSER;
+    } else {
+      return AnalyticsParsers.STRING_PARSER;
+    }
+  }
+
+  /**
+   * For use in classes that grab values by docValue.
+   * Converts a BytesRef object into the correct readable text.
+   */
+  public static interface Parser {
+    String parse(BytesRef bytes) throws IOException;
+  }
+  
+  /**
+   * Converts the long returned by NumericDocValues into the
+   * correct number and return it as a string.
+   */
+  public static interface NumericParser extends Parser {
+    String parseNum(long l);
+  }
+  
+  /**
+   * Converts the BytesRef or long to the correct int string.
+   */
+  public static final NumericParser INT_DOC_VALUES_PARSER = new NumericParser() {
+    public String parse(BytesRef bytes) throws IOException {
+      try {
+        return ""+NumericUtils.prefixCodedToInt(bytes);
+      } catch (NumberFormatException e) {
+        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to an int.");
+      }
+    }
+    @Override
+    public String parseNum(long l) {
+      return ""+(int)l;
+    }
+  };
+  
+  /**
+   * Converts the BytesRef or long to the correct long string.
+   */
+  public static final NumericParser LONG_DOC_VALUES_PARSER = new NumericParser() {
+    public String parse(BytesRef bytes) throws IOException {
+      try {
+        return ""+NumericUtils.prefixCodedToLong(bytes);
+      } catch (NumberFormatException e) {
+        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a long.");
+      }
+    }
+    @Override
+    public String parseNum(long l) {
+      return ""+l;
+    }
+  };
+  
+  /**
+   * Converts the BytesRef or long to the correct float string.
+   */
+  public static final NumericParser FLOAT_DOC_VALUES_PARSER = new NumericParser() {
+    public String parse(BytesRef bytes) throws IOException {
+      try {
+        return ""+NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(bytes));
+      } catch (NumberFormatException e) {
+        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a float.");
+      }
+    }
+    @Override
+    public String parseNum(long l) {
+      return ""+NumericUtils.sortableIntToFloat((int)l);
+    }
+  };
+  
+  /**
+   * Converts the BytesRef or long to the correct double string.
+   */
+  public static final NumericParser DOUBLE_DOC_VALUES_PARSER = new NumericParser() {
+    public String parse(BytesRef bytes) throws IOException {
+      try {
+        return ""+NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(bytes));
+      } catch (NumberFormatException e) {
+        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a double.");
+      }
+    }
+    @Override
+    public String parseNum(long l) {
+      return ""+NumericUtils.sortableLongToDouble(l);
+    }
+  };
+  
+  /**
+   * Converts the BytesRef or long to the correct date string.
+   */
+  public static final NumericParser DATE_DOC_VALUES_PARSER = new NumericParser() {
+    @SuppressWarnings("deprecation")
+    public String parse(BytesRef bytes) throws IOException {
+      try {
+        return TrieDateField.formatExternal(new Date(NumericUtils.prefixCodedToLong(bytes)));
+      } catch (NumberFormatException e) {
+        throw new IOException("The byte array "+Arrays.toString(bytes.bytes)+" cannot be converted to a date.");
+      }
+    }
+    @SuppressWarnings("deprecation")
+    @Override
+    public String parseNum(long l) {
+      return ""+TrieDateField.formatExternal(new Date(l));
+    }
+  };
+  
+  /**
+   * Converts the BytesRef to the correct string.
+   */
+  public static final Parser STRING_PARSER = new Parser() {
+    public String parse(BytesRef bytes) {
+      return bytes.utf8ToString();
+    }
+  };
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/MedianCalculator.java solr/core/src/java/org/apache/solr/analytics/util/MedianCalculator.java
new file mode 100644
index 0000000..4857597
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/MedianCalculator.java
@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util;
+
+import java.util.List;
+
+public class MedianCalculator {
+
+  /**
+   * Calculates the median of the given list of numbers.
+   *
+   * @param list A list of {@link Comparable} {@link Number} objects
+   * @return The median of the given list as a double.
+   */
+  public static <T extends Number & Comparable<T>> double getMedian(List<T> list) {
+    int size = list.size() - 1;
+    if (size == -1) {
+      return 0;
+    }
+
+    select(list, .5 * size, 0, size);
+
+    int firstIdx = (int) (Math.floor(.5 * size));
+    int secondIdx = (firstIdx <= size && size % 2 == 1) ? firstIdx + 1 : firstIdx;
+    double result = list.get(firstIdx).doubleValue() * .5 + list.get(secondIdx).doubleValue() * .5;
+
+    return result;
+  }
+
+  private static <T extends Comparable<T>> void select(List<T> list, double place, int begin, int end) {
+    T split;
+    if (end - begin < 10) {
+      split = list.get((int) (Math.random() * (end - begin + 1)) + begin);
+    } else {
+      split = split(list, begin, end);
+    }
+
+    Point result = partition(list, begin, end, split);
+
+    if (place < result.low) {
+      select(list, place, begin, result.low);
+    } else if (place > result.high) {
+      select(list, place, result.high, end);
+    } else {
+      if (result.low == (int) (Math.floor(place)) && result.low > begin) {
+        select(list, result.low, begin, result.low);
+      }
+      if (result.high == (int) (Math.ceil(place)) && result.high < end) {
+        select(list, result.high, result.high, end);
+      }
+    }
+  }
+
+  private static <T extends Comparable<T>> T split(List<T> list, int begin, int end) {
+    T temp;
+    int num = (end - begin + 1);
+    int recursiveSize = (int) Math.sqrt((double) num);
+    int step = num / recursiveSize;
+    for (int i = 1; i < recursiveSize; i++) {
+      int swapFrom = i * step + begin;
+      int swapTo = i + begin;
+      temp = list.get(swapFrom);
+      list.set(swapFrom, list.get(swapTo));
+      list.set(swapTo, temp);
+    }
+    recursiveSize--;
+    select(list, recursiveSize / 2 + begin, begin, recursiveSize + begin);
+    return list.get(recursiveSize / 2 + begin);
+  }
+
+  private static <T extends Comparable<T>> Point partition(List<T> list, int begin, int end, T indexElement) {
+    T temp;
+    int left, right;
+    for (left = begin, right = end; left < right; left++, right--) {
+      while (list.get(left).compareTo(indexElement) < 0) {
+        left++;
+      }
+      while (right != begin - 1 && list.get(right).compareTo(indexElement) >= 0) {
+        right--;
+      }
+      if (right <= left) {
+        left--;
+        right++;
+        break;
+      }
+      temp = list.get(left);
+      list.set(left, list.get(right));
+      list.set(right, temp);
+    }
+    while (left != begin - 1 && list.get(left).compareTo(indexElement) >= 0) {
+      left--;
+    }
+    while (right != end + 1 && list.get(right).compareTo(indexElement) <= 0) {
+      right++;
+    }
+    int rightMove = right + 1;
+    while (rightMove < end + 1) {
+      if (list.get(rightMove).equals(indexElement)) {
+        temp = list.get(rightMove);
+        list.set(rightMove, list.get(right));
+        list.set(right, temp);
+        do {
+          right++;
+        } while (list.get(right).equals(indexElement));
+        if (rightMove <= right) {
+          rightMove = right;
+        }
+      }
+      rightMove++;
+    }
+    return new Point(left, right);
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/PercentileCalculator.java solr/core/src/java/org/apache/solr/analytics/util/PercentileCalculator.java
new file mode 100644
index 0000000..714575e
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/PercentileCalculator.java
@@ -0,0 +1,177 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+public class PercentileCalculator {
+  /**
+   * Calculates a list of percentile values for a given list of objects and percentiles.
+   *
+   * @param list     The list of {@link Comparable} objects to calculate the percentiles of.
+   * @param percents The array of percentiles (.01 to .99) to calculate.
+   * @return a list of comparables
+   */
+  public static <T extends Comparable<T>> List<T> getPercentiles(List<T> list, double[] percents) {
+    int size = list.size();
+    if (size == 0) {
+      return null;
+    }
+
+    int[] percs = new int[percents.length];
+    for (int i = 0; i < percs.length; i++) {
+      percs[i] = (int) Math.round(percents[i] * size - .5);
+    }
+    int[] percentiles = Arrays.copyOf(percs, percs.length);
+    Arrays.sort(percentiles);
+
+    if (percentiles[0] < 0 || percentiles[percentiles.length - 1] > size - 1) {
+      throw new IllegalArgumentException();
+    }
+
+    List<T> results = new ArrayList<>(percs.length);
+
+    distributeAndFind(list, percentiles, 0, percentiles.length - 1);
+
+    for (int i = 0; i < percs.length; i++) {
+      results.add(list.get(percs[i]));
+    }
+    return results;
+  }
+
+  private static <T extends Comparable<T>> void distributeAndFind(List<T> list, int[] percentiles, int beginIdx, int endIdx) {
+    if (endIdx < beginIdx) {
+      return;
+    }
+    int middleIdxb = beginIdx;
+    int middleIdxe = beginIdx;
+    int begin = (beginIdx == 0) ? -1 : percentiles[beginIdx - 1];
+    int end = (endIdx == percentiles.length - 1) ? list.size() : percentiles[endIdx + 1];
+    double middle = (begin + end) / 2.0;
+    for (int i = beginIdx; i <= endIdx; i++) {
+      double value = Math.abs(percentiles[i] - middle) - Math.abs(percentiles[middleIdxb] - middle);
+      if (percentiles[i] == percentiles[middleIdxb]) {
+        middleIdxe = i;
+      } else if (value < 0) {
+        middleIdxb = i;
+        do {
+          middleIdxe = i;
+          i++;
+        } while (i <= endIdx && percentiles[middleIdxb] == percentiles[i]);
+        break;
+      }
+    }
+
+    int middlePlace = percentiles[middleIdxb];
+    int beginPlace = begin + 1;
+    int endPlace = end - 1;
+
+    select(list, middlePlace, beginPlace, endPlace);
+    distributeAndFind(list, percentiles, beginIdx, middleIdxb - 1);
+    distributeAndFind(list, percentiles, middleIdxe + 1, endIdx);
+  }
+
+  private static <T extends Comparable<T>> void select(List<T> list, int place, int begin, int end) {
+    T split;
+    if (end - begin < 10) {
+      split = list.get((int) (Math.random() * (end - begin + 1)) + begin);
+    } else {
+      split = split(list, begin, end);
+    }
+
+    Point result = partition(list, begin, end, split);
+
+    if (place <= result.low) {
+      select(list, place, begin, result.low);
+    } else if (place >= result.high) {
+      select(list, place, result.high, end);
+    }
+  }
+
+  private static <T extends Comparable<T>> T split(List<T> list, int begin, int end) {
+    T temp;
+    int num = (end - begin + 1);
+    int recursiveSize = (int) Math.sqrt((double) num);
+    int step = num / recursiveSize;
+    for (int i = 1; i < recursiveSize; i++) {
+      int swapFrom = i * step + begin;
+      int swapTo = i + begin;
+      temp = list.get(swapFrom);
+      list.set(swapFrom, list.get(swapTo));
+      list.set(swapTo, temp);
+    }
+    recursiveSize--;
+    select(list, recursiveSize / 2 + begin, begin, recursiveSize + begin);
+    return list.get(recursiveSize / 2 + begin);
+  }
+
+  private static <T extends Comparable<T>> Point partition(List<T> list, int begin, int end, T indexElement) {
+    T temp;
+    int left, right;
+    for (left = begin, right = end; left <= right; left++, right--) {
+      while (list.get(left).compareTo(indexElement) < 0) {
+        left++;
+      }
+      while (right != begin - 1 && list.get(right).compareTo(indexElement) >= 0) {
+        right--;
+      }
+      if (right <= left) {
+        left--;
+        right++;
+        break;
+      }
+      temp = list.get(left);
+      list.set(left, list.get(right));
+      list.set(right, temp);
+    }
+    while (left > begin - 1 && list.get(left).compareTo(indexElement) >= 0) {
+      left--;
+    }
+    while (right < end + 1 && list.get(right).compareTo(indexElement) <= 0) {
+      right++;
+    }
+    int rightMove = right + 1;
+    while (rightMove < end + 1) {
+      if (list.get(rightMove).equals(indexElement)) {
+        temp = list.get(rightMove);
+        list.set(rightMove, list.get(right));
+        list.set(right, temp);
+        do {
+          right++;
+        } while (list.get(right).equals(indexElement));
+        if (rightMove <= right) {
+          rightMove = right;
+        }
+      }
+      rightMove++;
+    }
+    return new Point(left, right);
+  }
+}
+
+class Point {
+  public int low;
+  public int high;
+
+  public Point(int low, int high) {
+    this.low = low;
+    this.high = high;
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java solr/core/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java
new file mode 100644
index 0000000..6eabe29
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/RangeEndpointCalculator.java
@@ -0,0 +1,356 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.EnumSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.solr.analytics.request.RangeFacetRequest;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.params.FacetParams.FacetRangeInclude;
+import org.apache.solr.common.params.FacetParams.FacetRangeOther;
+import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.SchemaField;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.schema.TrieField;
+import org.apache.solr.util.DateMathParser;
+
+
+public abstract class RangeEndpointCalculator<T extends Comparable<T>> {
+  protected final SchemaField field;
+  protected final RangeFacetRequest request;
+  
+  public RangeEndpointCalculator(final RangeFacetRequest request) {
+    this.field = request.getField();
+    this.request = request;
+  }
+
+  /**
+   * Formats a Range endpoint for use as a range label name in the response.
+   * Default Impl just uses toString()
+   */
+  public String formatValue(final T val) {
+    return val.toString();
+  }
+  
+  /**
+   * Parses a String param into an Range endpoint value throwing 
+   * a useful exception if not possible
+   */
+  public final T getValue(final String rawval) {
+    try {
+      return parseVal(rawval);
+    } catch (Exception e) {
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't parse value "+rawval+" for field: " + field.getName(), e);
+    }
+  }
+  
+  /**
+   * Parses a String param into an Range endpoint. 
+   * Can throw a low level format exception as needed.
+   */
+  protected abstract T parseVal(final String rawval) throws java.text.ParseException;
+
+  /** 
+   * Parses a String param into a value that represents the gap and 
+   * can be included in the response, throwing 
+   * a useful exception if not possible.
+   *
+   * Note: uses Object as the return type instead of T for things like 
+   * Date where gap is just a DateMathParser string 
+   */
+  public final Object getGap(final String gap) {
+    try {
+      return parseGap(gap);
+    } catch (Exception e) {
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't parse gap "+gap+" for field: " + field.getName(), e);
+    }
+  }
+
+  /**
+   * Parses a String param into a value that represents the gap and 
+   * can be included in the response. 
+   * Can throw a low level format exception as needed.
+   *
+   * Default Impl calls parseVal
+   */
+  protected Object parseGap(final String rawval) throws java.text.ParseException {
+    return parseVal(rawval);
+  }
+
+  /**
+   * Adds the String gap param to a low Range endpoint value to determine 
+   * the corrisponding high Range endpoint value, throwing 
+   * a useful exception if not possible.
+   */
+  public final T addGap(T value, String gap) {
+    try {
+      return parseAndAddGap(value, gap);
+    } catch (Exception e) {
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Can't add gap "+gap+" to value " + value + " for field: " + field.getName(), e);
+    }
+  }
+  
+  /**
+   * Adds the String gap param to a low Range endpoint value to determine 
+   * the corrisponding high Range endpoint value.
+   * Can throw a low level format exception as needed.
+   */
+  protected abstract T parseAndAddGap(T value, String gap) throws java.text.ParseException;
+
+  public static class FacetRange {
+    public final String name;
+    public final String lower;
+    public final String upper;
+    public final boolean includeLower;
+    public final boolean includeUpper;
+    
+    public FacetRange(String name, String lower, String upper, boolean includeLower, boolean includeUpper) {
+      this.name = name;
+      this.lower = lower;
+      this.upper = upper;
+      this.includeLower = includeLower;
+      this.includeUpper = includeUpper;
+    }
+  }
+  
+  public List<FacetRange> getRanges(){
+
+    final T start = getValue(request.getStart());
+    T end = getValue(request.getEnd()); // not final, hardend may change this
+    
+    if( end.compareTo(start) < 0 ){
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "range facet 'end' comes before 'start': "+end+" < "+start);
+    }
+    
+    // explicitly return the gap.  compute this early so we are more 
+    // likely to catch parse errors before attempting math
+    final String[] gaps = request.getGaps();
+    String gap = gaps[0];
+    
+    final EnumSet<FacetRangeInclude> include = request.getInclude();
+        
+    T low = start;
+    
+    List<FacetRange> ranges = new ArrayList<>();
+    
+    int gapCounter = 0;
+    
+    while (low.compareTo(end) < 0) {
+      if (gapCounter<gaps.length) {
+        gap = gaps[gapCounter++];
+      }
+      T high = addGap(low,gap);
+      if (end.compareTo(high) < 0) {
+        if (request.isHardEnd()){
+          high = end;
+        } else {
+          end = high;
+        }
+      }
+      
+      if (high.compareTo(low) < 0) {
+        throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "range facet infinite loop (is gap negative? did the math overflow?)");
+      }
+      
+      if (high.compareTo(low) == 0) {
+        throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "range facet infinite loop: gap is either zero, or too small relative start/end and caused underflow: " + low + " + " + gap + " = " + high );
+      }
+      
+      final boolean includeLower = (include.contains(FacetRangeInclude.ALL) ||
+                                    include.contains(FacetRangeInclude.LOWER) ||
+                                   (include.contains(FacetRangeInclude.EDGE) && 
+                                   0 == low.compareTo(start)));
+      final boolean includeUpper = (include.contains(FacetRangeInclude.ALL) ||
+                                    include.contains(FacetRangeInclude.UPPER) ||
+                                   (include.contains(FacetRangeInclude.EDGE) && 
+                                   0 == high.compareTo(end)));
+      
+      final String lowS = formatValue(low);
+      final String highS = formatValue(high);
+
+      ranges.add( new FacetRange(lowS,lowS,highS,includeLower,includeUpper) );
+      low = high;
+    }
+    
+    final Set<FacetRangeOther> others = request.getOthers();
+    if (null != others && 0 < others.size() ) {
+      
+      // no matter what other values are listed, we don't do
+      // anything if "none" is specified.
+      if( !others.contains(FacetRangeOther.NONE) ) {
+        
+        boolean all = others.contains(FacetRangeOther.ALL);
+
+        if (all || others.contains(FacetRangeOther.BEFORE)) {
+          // include upper bound if "outer" or if first gap doesn't already include it
+          ranges.add( new FacetRange(FacetRangeOther.BEFORE.toString(), 
+                                        null, formatValue(start), false, include.contains(FacetRangeInclude.OUTER) || include.contains(FacetRangeInclude.ALL) ||
+                                                            !(include.contains(FacetRangeInclude.LOWER) || include.contains(FacetRangeInclude.EDGE)) ) );
+          
+        }
+        if (all || others.contains(FacetRangeOther.AFTER)) {
+          // include lower bound if "outer" or if last gap doesn't already include it
+          ranges.add( new FacetRange(FacetRangeOther.AFTER.toString(), 
+                                        formatValue(end), null, include.contains(FacetRangeInclude.OUTER) || include.contains(FacetRangeInclude.ALL) ||
+                                                   !(include.contains(FacetRangeInclude.UPPER) || include.contains(FacetRangeInclude.EDGE)), false) );
+        }
+        if (all || others.contains(FacetRangeOther.BETWEEN)) {
+          ranges.add( new FacetRange(FacetRangeOther.BETWEEN.toString(), formatValue(start), formatValue(end),
+                                        include.contains(FacetRangeInclude.LOWER) || include.contains(FacetRangeInclude.EDGE) || include.contains(FacetRangeInclude.ALL),
+                                        include.contains(FacetRangeInclude.UPPER) || include.contains(FacetRangeInclude.EDGE) || include.contains(FacetRangeInclude.ALL)) );
+        }
+      }
+      
+    }
+  
+    return ranges;
+  }
+  
+  public static RangeEndpointCalculator<? extends Comparable<?>> create(RangeFacetRequest request){
+    final SchemaField sf = request.getField();
+    final FieldType ft = sf.getType();
+    final RangeEndpointCalculator<?> calc;
+    if (ft instanceof TrieField) {
+      final TrieField trie = (TrieField)ft;
+      switch (trie.getType()) {
+        case FLOAT:
+          calc = new FloatRangeEndpointCalculator(request);
+          break;
+        case DOUBLE:
+          calc = new DoubleRangeEndpointCalculator(request);
+          break;
+        case INTEGER:
+          calc = new IntegerRangeEndpointCalculator(request);
+          break;
+        case LONG:
+          calc = new LongRangeEndpointCalculator(request);
+          break;
+        case DATE:
+          calc = new DateRangeEndpointCalculator(request, null);
+          break;
+        default:
+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Unable to range facet on tried field of unexpected type:" + sf.getName());
+      }
+    } else {
+      throw new SolrException (SolrException.ErrorCode.BAD_REQUEST, "Unable to range facet on field:" + sf);
+    } 
+    return calc;
+  }
+  
+  public static class FloatRangeEndpointCalculator extends RangeEndpointCalculator<Float> {
+  
+    public FloatRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
+    
+    @Override
+    protected Float parseVal(String rawval) {
+      return Float.valueOf(rawval);
+    }
+    
+    @Override
+    public Float parseAndAddGap(Float value, String gap) {
+      return new Float(value.floatValue() + Float.valueOf(gap).floatValue());
+    }
+    
+  }
+  
+  public static class DoubleRangeEndpointCalculator extends RangeEndpointCalculator<Double> {
+  
+    public DoubleRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
+    
+    @Override
+    protected Double parseVal(String rawval) {
+      return Double.valueOf(rawval);
+    }
+    
+    @Override
+    public Double parseAndAddGap(Double value, String gap) {
+      return new Double(value.doubleValue() + Double.valueOf(gap).doubleValue());
+    }
+    
+  }
+  
+  public static class IntegerRangeEndpointCalculator extends RangeEndpointCalculator<Integer> {
+  
+    public IntegerRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
+    
+    @Override
+    protected Integer parseVal(String rawval) {
+      return Integer.valueOf(rawval);
+    }
+    
+    @Override
+    public Integer parseAndAddGap(Integer value, String gap) {
+      return new Integer(value.intValue() + Integer.valueOf(gap).intValue());
+    }
+    
+  }
+  
+  public static class LongRangeEndpointCalculator extends RangeEndpointCalculator<Long> {
+  
+    public LongRangeEndpointCalculator(final RangeFacetRequest request) { super(request); }
+    
+    @Override
+    protected Long parseVal(String rawval) {
+      return Long.valueOf(rawval);
+    }
+    
+    @Override
+    public Long parseAndAddGap(Long value, String gap) {
+      return new Long(value.longValue() + Long.valueOf(gap).longValue());
+    }
+    
+  }
+  
+  public static class DateRangeEndpointCalculator extends RangeEndpointCalculator<Date> {
+    private final Date now;
+    public DateRangeEndpointCalculator(final RangeFacetRequest request, final Date now) { 
+      super(request); 
+      this.now = now;
+      if (! (field.getType() instanceof TrieDateField) ) {
+        throw new IllegalArgumentException("SchemaField must use field type extending TrieDateField");
+      }
+    }
+    
+    @Override
+    public String formatValue(Date val) {
+      return ((TrieDateField)field.getType()).toExternal(val);
+    }
+    
+    @Override
+    protected Date parseVal(String rawval) {
+      return ((TrieDateField)field.getType()).parseMath(now, rawval);
+    }
+    
+    @Override
+    protected Object parseGap(final String rawval) {
+      return rawval;
+    }
+    
+    @Override
+    public Date parseAndAddGap(Date value, String gap) throws java.text.ParseException {
+      final DateMathParser dmp = new DateMathParser();
+      dmp.setNow(value);
+      return dmp.parseMath(gap);
+    }
+    
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/package.html solr/core/src/java/org/apache/solr/analytics/util/package.html
new file mode 100644
index 0000000..3cc6e4a
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+Utilities used by analytics component
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java
new file mode 100644
index 0000000..f429248
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/AbsoluteValueDoubleFunction.java
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>AbsoluteValueDoubleFunction</code> takes the absolute value of the double value of the source it contains.
+ */
+public class AbsoluteValueDoubleFunction extends SingleDoubleFunction {
+  public final static String NAME = AnalyticsParams.ABSOLUTE_VALUE;
+  
+  public AbsoluteValueDoubleFunction(ValueSource source) {
+    super(source);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  public String description() {
+    return name()+"("+source.description()+")";
+  }
+
+  protected double func(int doc, FunctionValues vals) {
+    double d = vals.doubleVal(doc);
+    if (d<0) {
+      return d*-1;
+    } else {
+      return d;
+    }
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    AbsoluteValueDoubleFunction other = (AbsoluteValueDoubleFunction)o;
+    return this.source.equals(other.source);
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java
new file mode 100644
index 0000000..7784feb
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/AddDoubleFunction.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>AddDoubleFunction</code> returns the sum of it's components.
+ */
+public class AddDoubleFunction extends MultiDoubleFunction {
+  public final static String NAME = AnalyticsParams.ADD;
+
+  public AddDoubleFunction(ValueSource[] sources) {
+    super(sources);
+  }
+
+  @Override
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected double func(int doc, FunctionValues[] valsArr) {
+    double sum = 0d;
+    for (FunctionValues val : valsArr) {
+      sum += val.doubleVal(doc);
+    }
+    return sum;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java
new file mode 100644
index 0000000..97537a7
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConcatStringFunction.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>ConcatStringFunction</code> concatenates the string values of its 
+ * components in the order given.
+ */
+public class ConcatStringFunction extends MultiStringFunction {
+  public final static String NAME = AnalyticsParams.CONCATENATE;
+
+  public ConcatStringFunction(ValueSource[] sources) {
+    super(sources);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected String func(int doc, FunctionValues[] valsArr) {
+    StringBuilder sb = new StringBuilder();
+    for (FunctionValues val : valsArr) {
+      String v = val.strVal(doc);
+      if(v == null){
+        return null;
+      } else {
+        sb.append(v);
+      }
+    }
+    return sb.toString();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java
new file mode 100644
index 0000000..1ed8ca7
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDateSource.java
@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.text.ParseException;
+import java.util.Date;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.docvalues.FloatDocValues;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueDate;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.schema.TrieDateField;
+
+/**
+ * <code>ConstDateSource</code> returns a constant date for all documents
+ */
+public class ConstDateSource extends ConstDoubleSource {
+  public final static String NAME = AnalyticsParams.CONSTANT_DATE;
+
+  public ConstDateSource(Date constant) throws ParseException {
+    super(constant.getTime());
+  }
+
+  public ConstDateSource(Long constant) {
+    super(constant);
+  }
+
+  @SuppressWarnings("deprecation")
+  @Override
+  public String description() {
+    return name()+"(" + TrieDateField.formatExternal(new Date(getLong())) + ")";
+  }
+
+  protected String name() {
+    return NAME;
+  }
+  
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    return new FloatDocValues(this) {
+      @Override
+      public float floatVal(int doc) {
+        return getFloat();
+      }
+      @Override
+      public int intVal(int doc) {
+        return getInt();
+      }
+      @Override
+      public long longVal(int doc) {
+        return getLong();
+      }
+      @Override
+      public double doubleVal(int doc) {
+        return getDouble();
+      }
+      @Override
+      public String toString(int doc) {
+        return description();
+      }
+      @Override
+      public Object objectVal(int doc) {
+        return new Date(longVal(doc));
+      }
+      @SuppressWarnings("deprecation")
+      @Override
+      public String strVal(int doc) {
+        return TrieDateField.formatExternal(new Date(longVal(doc)));
+      }
+      @Override
+      public boolean boolVal(int doc) {
+        return getFloat() != 0.0f;
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final MutableValueDate mval = new MutableValueDate();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            mval.value = longVal(doc);
+            mval.exists = true;
+          }
+        };
+      }
+    };
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java
new file mode 100644
index 0000000..6311086
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstDoubleSource.java
@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
+import org.apache.lucene.queries.function.valuesource.ConstNumberSource;
+import org.apache.lucene.queries.function.valuesource.ConstValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>ConstDoubleSource</code> returns a constant double for all documents
+ */
+public class ConstDoubleSource extends ConstNumberSource {
+  public final static String NAME = AnalyticsParams.CONSTANT_NUMBER;
+  final double constant;
+
+  public ConstDoubleSource(double constant) {
+    this.constant = constant;
+  }
+
+  @Override
+  public String description() {
+    return name()+"(" + getFloat() + ")";
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    return new DoubleDocValues(this) {
+      @Override
+      public double doubleVal(int doc) {
+        return constant;
+      }
+      @Override
+      public boolean exists(int doc) {
+        return true;
+      }
+    };
+  }
+
+  @Override
+  public int hashCode() {
+    return (int)Double.doubleToLongBits(constant) * 31;
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (!(o instanceof ConstValueSource)) return false;
+    ConstDoubleSource other = (ConstDoubleSource)o;
+    return  this.constant == other.constant;
+  }
+
+  @Override
+  public int getInt() {
+    return (int)constant;
+  }
+
+  @Override
+  public long getLong() {
+    return (long)constant;
+  }
+
+  @Override
+  public float getFloat() {
+    return (float)constant;
+  }
+
+  @Override
+  public double getDouble() {
+    return constant;
+  }
+
+  @Override
+  public Number getNumber() {
+    return new Double(constant);
+  }
+
+  @Override
+  public boolean getBool() {
+    return constant != 0.0f;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java
new file mode 100644
index 0000000..c2c9af7
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/ConstStringSource.java
@@ -0,0 +1,51 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.valuesource.LiteralValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>ConstStringSource</code> returns a constant string for all documents
+ */
+public class ConstStringSource extends LiteralValueSource {
+  public final static String NAME = AnalyticsParams.CONSTANT_STRING;
+
+  public ConstStringSource(String string) {
+    super(string);
+  }
+
+  @Override
+  public String description() {
+    return name()+"(" + string + ")";
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o) return true;
+    if (!(o instanceof ConstStringSource)) return false;
+    ConstStringSource that = (ConstStringSource) o;
+
+    return getValue().equals(that.getValue());
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
new file mode 100644
index 0000000..c002e35
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateFieldSource.java
@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Date;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.docvalues.LongDocValues;
+import org.apache.lucene.queries.function.valuesource.LongFieldSource;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueDate;
+import org.apache.solr.schema.TrieDateField;
+
+/**
+ * Extends {@link LongFieldSource} to have a field source that takes in 
+ * and returns {@link Date} values while working with long values internally.
+ */
+public class DateFieldSource extends LongFieldSource {
+
+  public DateFieldSource(String field) {
+    super(field);
+  }
+
+  public long externalToLong(String extVal) {
+    return NumericUtils.prefixCodedToLong(new BytesRef(extVal));
+  }
+
+  public Object longToObject(long val) {
+    return new Date(val);
+  }
+
+  @SuppressWarnings("deprecation")
+  public String longToString(long val) {
+    return TrieDateField.formatExternal((Date)longToObject(val));
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final NumericDocValues arr = DocValues.getNumeric(readerContext.reader(), field);
+    final Bits valid = DocValues.getDocsWithField(readerContext.reader(), field);
+    return new LongDocValues(this) {
+      @Override
+      public long longVal(int doc) {
+        return arr.get(doc);
+      }
+
+      @Override
+      public boolean exists(int doc) {
+        return valid.get(doc);
+      }
+
+      @Override
+      public Object objectVal(int doc) {
+        return exists(doc) ? longToObject(arr.get(doc)) : null;
+      }
+
+      @Override
+      public String strVal(int doc) {
+        return exists(doc) ? longToString(arr.get(doc)) : null;
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final MutableValueDate mval = new MutableValueDate();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            mval.value = arr.get(doc);
+            mval.exists = exists(doc);
+          }
+        };
+      }
+
+    };
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (o.getClass() != this.getClass()) return false;
+    DateFieldSource other = (DateFieldSource) o;
+    return field.equals(other.field);
+  }
+
+  @Override
+  public int hashCode() {
+    int h = this.getClass().hashCode();
+    h += super.hashCode();
+    return h;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java
new file mode 100644
index 0000000..f2d4c4a
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/DateMathFunction.java
@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.text.ParseException;
+import java.util.Date;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.util.DateMathParser;
+
+/**
+ * <code>DateMathFunction</code> returns a start date modified by a list of DateMath operations.
+ */
+public class DateMathFunction extends MultiDateFunction {
+  public final static String NAME = AnalyticsParams.DATE_MATH;
+  final private DateMathParser parser;
+  
+  /**
+   * @param sources A list of ValueSource objects. The first element in the list
+   * should be a {@link DateFieldSource} or {@link ConstDateSource} object which
+   * represents the starting date. The rest of the field should be {@link BytesRefFieldSource}
+   * or {@link ConstStringSource} objects which contain the DateMath operations to perform on 
+   * the start date.
+   */
+  public DateMathFunction(ValueSource[] sources) {
+    super(sources);
+    parser = new DateMathParser();
+  }
+
+  @Override
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected long func(int doc, FunctionValues[] valsArr) {
+    long time = 0;
+    Date date = (Date)valsArr[0].objectVal(doc);
+    try {
+      parser.setNow(date);
+      for (int count = 1; count < valsArr.length; count++) {
+          date = parser.parseMath(valsArr[count].strVal(doc));
+        parser.setNow(date);
+      }
+      time = parser.getNow().getTime();
+    } catch (ParseException e) {
+      e.printStackTrace();
+      time = date.getTime();
+    }
+    return time;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java
new file mode 100644
index 0000000..f029d79
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/DivDoubleFunction.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>DivDoubleFunction</code> returns the quotient of 'a' and 'b'.
+ */
+public class DivDoubleFunction extends DualDoubleFunction {
+  public final static String NAME = AnalyticsParams.DIVIDE;
+
+  /**
+    * @param   a  the numerator.
+    * @param   b  the denominator.
+    */
+  public DivDoubleFunction(ValueSource a, ValueSource b) {
+    super(a, b);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
+    return aVals.doubleVal(doc)/bVals.doubleVal(doc);
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java
new file mode 100644
index 0000000..21f5eda
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/DualDoubleFunction.java
@@ -0,0 +1,95 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
+import org.apache.lucene.search.IndexSearcher;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps two ValueSources
+ * and applies an extendible double function to their values.
+ **/
+public abstract class DualDoubleFunction extends ValueSource {
+  protected final ValueSource a;
+  protected final ValueSource b;
+
+  public DualDoubleFunction(ValueSource a, ValueSource b) {
+    this.a = a;
+    this.b = b;
+  }
+
+  protected abstract String name();
+  protected abstract double func(int doc, FunctionValues aVals, FunctionValues bVals);
+
+  @Override
+  public String description() {
+    return name() + "(" + a.description() + "," + b.description() + ")";
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues aVals =  a.getValues(context, readerContext);
+    final FunctionValues bVals =  b.getValues(context, readerContext);
+    return new DoubleDocValues(this) {
+      @Override
+      public double doubleVal(int doc) {
+        return func(doc, aVals, bVals);
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        return aVals.exists(doc) & bVals.exists(doc);
+      }
+
+      @Override
+      public String toString(int doc) {
+        return name() + '(' + aVals.toString(doc) + ',' + bVals.toString(doc) + ')';
+      }
+    };
+  }
+
+  @Override
+  public void createWeight(Map context, IndexSearcher searcher) throws IOException {
+    a.createWeight(context,searcher);
+    b.createWeight(context,searcher);
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    DualDoubleFunction other = (DualDoubleFunction)o;
+    return this.a.equals(other.a)
+        && this.b.equals(other.b);
+  }
+
+  @Override
+  public int hashCode() {
+    int h = a.hashCode();
+    h ^= (h << 13) | (h >>> 20);
+    h += b.hashCode();
+    h ^= (h << 23) | (h >>> 10);
+    h += name().hashCode();
+    return h;
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java
new file mode 100644
index 0000000..33a9995
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/FilterFieldSource.java
@@ -0,0 +1,156 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Date;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.schema.TrieDateField;
+
+/**
+ * <code>DefaultIsMissingFieldSource</code> wraps a field source to return missing values 
+ * if the value is equal to the default value.
+ */
+public class FilterFieldSource extends ValueSource {
+  public final static String NAME = AnalyticsParams.FILTER;
+  public final Object missValue;
+  protected final ValueSource source;
+  
+  public FilterFieldSource(ValueSource source, Object missValue) {
+    this.source = source;
+    this.missValue = missValue;
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @SuppressWarnings("deprecation")
+  @Override
+  public String description() {
+    if (missValue.getClass().equals(Date.class)) {
+      return name()+"("+source.description()+","+TrieDateField.formatExternal((Date)missValue)+")";
+    } else {
+      return name()+"("+source.description()+","+missValue.toString()+")";
+    }
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues vals =  source.getValues(context, readerContext);
+    return new FunctionValues() {
+
+      @Override
+      public byte byteVal(int doc) {
+        return vals.byteVal(doc);
+      }
+
+      @Override
+      public short shortVal(int doc) {
+        return vals.shortVal(doc);
+      }
+
+      @Override
+      public float floatVal(int doc) {
+        return vals.floatVal(doc);
+      }
+
+      @Override
+      public int intVal(int doc) {
+        return vals.intVal(doc);
+      }
+
+      @Override
+      public long longVal(int doc) {
+        return vals.longVal(doc);
+      }
+
+      @Override
+      public double doubleVal(int doc) {
+        return vals.doubleVal(doc);
+      }
+
+      @Override
+      public String strVal(int doc) {
+        return vals.strVal(doc);
+      }
+
+      @Override
+      public Object objectVal(int doc) {
+        return exists(doc)? vals.objectVal(doc) : null;
+      }
+
+      @Override
+      public boolean exists(int doc) {
+        Object other = vals.objectVal(doc);
+        return other!=null&&!missValue.equals(other);
+      }
+
+      @Override
+      public String toString(int doc) {
+        return NAME + '(' + vals.toString(doc) + ')';
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final ValueFiller delegateFiller = vals.getValueFiller();
+          private final MutableValue mval = delegateFiller.getValue();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            delegateFiller.fillValue(doc);
+            mval.exists = exists(doc);
+          }
+        };
+      }
+    };
+  }
+  
+  public ValueSource getRootSource() {
+    if (source instanceof FilterFieldSource) {
+      return ((FilterFieldSource)source).getRootSource();
+    } else {
+      return source;
+    }
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    FilterFieldSource other = (FilterFieldSource)o;
+    return this.source.equals(other.source) && this.missValue.equals(other.missValue);
+  }
+
+  @Override
+  public int hashCode() {
+    return source.hashCode()+name().hashCode();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java
new file mode 100644
index 0000000..c4729a3
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/LogDoubleFunction.java
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>LogDoubleFunction</code> returns the log of a double value with a given base.
+ */
+public class LogDoubleFunction extends DualDoubleFunction {
+  public final static String NAME = AnalyticsParams.LOG;
+  
+  public LogDoubleFunction(ValueSource a, ValueSource b) {
+    super(a,b);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
+    return Math.log(aVals.doubleVal(doc))/Math.log(bVals.doubleVal(doc));
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java
new file mode 100644
index 0000000..1b51f6d
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDateFunction.java
@@ -0,0 +1,134 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.LongDocValues;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueDate;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
+ * and applies an extendible date function to their values.
+ **/
+public abstract class MultiDateFunction extends ValueSource {
+  protected final ValueSource[] sources;
+  
+  public MultiDateFunction(ValueSource[] sources) {
+    this.sources = sources;
+  }
+
+  abstract protected String name();
+  abstract protected long func(int doc, FunctionValues[] valsArr);
+
+  @Override
+  public String description() {
+    StringBuilder sb = new StringBuilder();
+    sb.append(name()).append('(');
+    boolean firstTime=true;
+    for (ValueSource source : sources) {
+      if (firstTime) {
+        firstTime=false;
+      } else {
+        sb.append(',');
+      }
+      sb.append(source);
+    }
+    sb.append(')');
+    return sb.toString();
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues[] valsArr = new FunctionValues[sources.length];
+    for (int i=0; i<sources.length; i++) {
+      valsArr[i] = sources[i].getValues(context, readerContext);
+    }
+
+    return new LongDocValues(this) {
+      @Override
+      public long longVal(int doc) {
+        return func(doc, valsArr);
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        boolean exists = true;
+        for (FunctionValues val : valsArr) {
+          exists = exists & val.exists(doc);
+        }
+        return exists;
+      }
+      
+      @Override
+      public String toString(int doc) {
+        StringBuilder sb = new StringBuilder();
+        sb.append(name()).append('(');
+        boolean firstTime=true;
+        for (FunctionValues vals : valsArr) {
+          if (firstTime) {
+            firstTime=false;
+          } else {
+            sb.append(',');
+          }
+          sb.append(vals.toString(doc));
+        }
+        sb.append(')');
+        return sb.toString();
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final MutableValueDate mval = new MutableValueDate();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            mval.value = longVal(doc);
+            mval.exists = exists(doc);
+          }
+        };
+      }
+    };
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    MultiDateFunction other = (MultiDateFunction)o;
+    return this.name().equals(other.name())
+            && Arrays.equals(this.sources, other.sources);
+  }
+
+  @Override
+  public int hashCode() {
+    return Arrays.hashCode(sources) + name().hashCode();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java
new file mode 100644
index 0000000..db6f0d0
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiDoubleFunction.java
@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
+import org.apache.lucene.search.IndexSearcher;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
+ * and applies an extendible double function to their values.
+ **/
+public abstract class MultiDoubleFunction extends ValueSource {
+  protected final ValueSource[] sources;
+
+  public MultiDoubleFunction(ValueSource[] sources) {
+    this.sources = sources;
+  }
+
+  abstract protected String name();
+  abstract protected double func(int doc, FunctionValues[] valsArr);
+
+  @Override
+  public String description() {
+    StringBuilder sb = new StringBuilder();
+    sb.append(name()).append('(');
+    boolean firstTime=true;
+    for (ValueSource source : sources) {
+      if (firstTime) {
+        firstTime=false;
+      } else {
+        sb.append(',');
+      }
+      sb.append(source);
+    }
+    sb.append(')');
+    return sb.toString();
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues[] valsArr = new FunctionValues[sources.length];
+    for (int i=0; i<sources.length; i++) {
+      valsArr[i] = sources[i].getValues(context, readerContext);
+    }
+
+    return new DoubleDocValues(this) {
+      @Override
+      public double doubleVal(int doc) {
+        return func(doc, valsArr);
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        boolean exists = true;
+        for (FunctionValues val : valsArr) {
+          exists = exists & val.exists(doc);
+        }
+        return exists;
+      }
+       
+      @Override
+      public String toString(int doc) {
+        StringBuilder sb = new StringBuilder();
+        sb.append(name()).append('(');
+        boolean firstTime=true;
+        for (FunctionValues vals : valsArr) {
+          if (firstTime) {
+            firstTime=false;
+          } else {
+            sb.append(',');
+          }
+          sb.append(vals.toString(doc));
+        }
+        sb.append(')');
+        return sb.toString();
+      }
+    };
+  }
+
+  @Override
+  public void createWeight(Map context, IndexSearcher searcher) throws IOException {
+    for (ValueSource source : sources)
+      source.createWeight(context, searcher);
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    MultiDoubleFunction other = (MultiDoubleFunction)o;
+    return this.name().equals(other.name())
+            && Arrays.equals(this.sources, other.sources);
+  }
+
+  @Override
+  public int hashCode() {
+    return Arrays.hashCode(sources) + name().hashCode();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java
new file mode 100644
index 0000000..5ef3fdd
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiStringFunction.java
@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.StrDocValues;
+import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueStr;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps multiple ValueSources
+ * and applies an extendible string function to their values.
+ **/
+public abstract class MultiStringFunction extends ValueSource {
+  protected final ValueSource[] sources;
+  
+  public MultiStringFunction(ValueSource[] sources) {
+    this.sources = sources;
+  }
+
+  abstract protected String name();
+  abstract protected CharSequence func(int doc, FunctionValues[] valsArr);
+
+  @Override
+  public String description() {
+    StringBuilder sb = new StringBuilder();
+    sb.append(name()).append('(');
+    boolean firstTime=true;
+    for (ValueSource source : sources) {
+      if (firstTime) {
+        firstTime=false;
+      } else {
+        sb.append(',');
+      }
+      sb.append(source);
+    }
+    sb.append(')');
+    return sb.toString();
+  }
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues[] valsArr = new FunctionValues[sources.length];
+    for (int i=0; i<sources.length; i++) {
+      valsArr[i] = sources[i].getValues(context, readerContext);
+    }
+
+    return new StrDocValues(this) {
+      @Override
+      public String strVal(int doc) {
+        CharSequence cs = func(doc, valsArr);
+        return  cs != null ? cs.toString() : null;
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        boolean exists = true;
+        for (FunctionValues val : valsArr) {
+          exists = exists & val.exists(doc);
+        }
+        return exists;
+      }
+      
+      @Override
+      public boolean bytesVal(int doc, BytesRefBuilder bytes) {
+        bytes.clear();
+        CharSequence cs = func(doc, valsArr);
+        if( cs != null ){
+          bytes.copyChars(func(doc,valsArr));
+          return true;
+        } else {
+          return false;
+        }
+      }
+      
+      @Override
+      public String toString(int doc) {
+        StringBuilder sb = new StringBuilder();
+        sb.append(name()).append('(');
+        boolean firstTime=true;
+        for (FunctionValues vals : valsArr) {
+          if (firstTime) {
+            firstTime=false;
+          } else {
+            sb.append(',');
+          }
+          sb.append(vals.toString(doc));
+        }
+        sb.append(')');
+        return sb.toString();
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final MutableValueStr mval = new MutableValueStr();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            mval.exists = bytesVal(doc, mval.value);
+          }
+        };
+      }
+    };
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    MultiStringFunction other = (MultiStringFunction)o;
+    return this.name().equals(other.name())
+            && Arrays.equals(this.sources, other.sources);
+  }
+
+  @Override
+  public int hashCode() {
+    return Arrays.hashCode(sources) + name().hashCode();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java
new file mode 100644
index 0000000..5f9de24
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/MultiplyDoubleFunction.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>MultiplyDoubleFunction</code> returns the product of it's components.
+ */
+public class MultiplyDoubleFunction extends MultiDoubleFunction {
+  public final static String NAME = AnalyticsParams.MULTIPLY;
+
+  public MultiplyDoubleFunction(ValueSource[] sources) {
+    super(sources);
+  }
+
+  @Override
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected double func(int doc, FunctionValues[] valsArr) {
+    double product = 1d;
+    for (FunctionValues val : valsArr) {
+      product *= val.doubleVal(doc);
+    }
+    return product;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java
new file mode 100644
index 0000000..4bff8d0
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/NegateDoubleFunction.java
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>NegateDoubleFunction</code> negates the double value of the source it contains.
+ */
+public class NegateDoubleFunction extends SingleDoubleFunction {
+  public final static String NAME = AnalyticsParams.NEGATE;
+  
+  public NegateDoubleFunction(ValueSource source) {
+    super(source);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  public String description() {
+    return name()+"("+source.description()+")";
+  }
+
+  protected double func(int doc, FunctionValues vals) {
+    return vals.doubleVal(doc)*-1;
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    NegateDoubleFunction other = (NegateDoubleFunction)o;
+    return this.source.equals(other.source);
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java
new file mode 100644
index 0000000..1b4348b
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/PowDoubleFunction.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>PowDoubleFunction</code> returns 'a' raised to the power of 'b'.
+ */
+public class PowDoubleFunction extends DualDoubleFunction {
+  public final static String NAME = AnalyticsParams.POWER;
+
+  /**
+    * @param   a  the base.
+    * @param   b  the exponent.
+    */
+  public PowDoubleFunction(ValueSource a, ValueSource b) {
+    super(a, b);
+  }
+
+  @Override
+  protected String name() {
+    return NAME;
+  }
+
+  @Override
+  protected double func(int doc, FunctionValues aVals, FunctionValues bVals) {
+    return Math.pow(aVals.doubleVal(doc), bVals.doubleVal(doc));
+  }
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java
new file mode 100644
index 0000000..568f94e
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/ReverseStringFunction.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.solr.analytics.util.AnalyticsParams;
+
+/**
+ * <code>ReverseStringFunction</code> reverses the string value of the source it contains.
+ */
+public class ReverseStringFunction extends SingleStringFunction {
+  public final static String NAME = AnalyticsParams.REVERSE;
+  
+  public ReverseStringFunction(ValueSource source) {
+    super(source);
+  }
+
+  protected String name() {
+    return NAME;
+  }
+
+  protected CharSequence func(int doc, FunctionValues vals) {
+    String val = vals.strVal(doc);
+    return val != null ? StringUtils.reverse(val) : null;
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java
new file mode 100644
index 0000000..45fc4ca
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleDoubleFunction.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.DoubleDocValues;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps one ValueSource
+ * and applies an extendible double function to its values.
+ */
+public abstract class SingleDoubleFunction extends ValueSource {
+  protected final ValueSource source;
+  
+  public SingleDoubleFunction(ValueSource source) {
+    this.source = source;
+  }
+
+  @Override
+  public String description() {
+    return name()+"("+source.description()+")";
+  }
+
+  abstract String name();
+  abstract double func(int doc, FunctionValues vals);
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues vals =  source.getValues(context, readerContext);
+    return new DoubleDocValues(this) {
+      @Override
+      public double doubleVal(int doc) {
+        return func(doc, vals);
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        return vals.exists(doc);
+      }
+
+      @Override
+      public String toString(int doc) {
+        return name() + '(' + vals.toString(doc) + ')';
+      }
+    };
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    SingleDoubleFunction other = (SingleDoubleFunction)o;
+    return this.source.equals(other.source);
+  }
+
+  @Override
+  public int hashCode() {
+    return source.hashCode()+name().hashCode();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java
new file mode 100644
index 0000000..7540649
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/SingleStringFunction.java
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.queries.function.FunctionValues;
+import org.apache.lucene.queries.function.ValueSource;
+import org.apache.lucene.queries.function.docvalues.StrDocValues;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.mutable.MutableValue;
+import org.apache.lucene.util.mutable.MutableValueStr;
+
+/**
+ * Abstract {@link ValueSource} implementation which wraps one ValueSource
+ * and applies an extendible string function to its values.
+ */
+public abstract class SingleStringFunction extends ValueSource {
+  protected final ValueSource source;
+  
+  public SingleStringFunction(ValueSource source) {
+    this.source = source;
+  }
+
+  @Override
+  public String description() {
+    return name()+"("+source.description()+")";
+  }
+
+  abstract String name();
+  abstract CharSequence func(int doc, FunctionValues vals);
+
+  @Override
+  public FunctionValues getValues(Map context, AtomicReaderContext readerContext) throws IOException {
+    final FunctionValues vals =  source.getValues(context, readerContext);
+    return new StrDocValues(this) {
+      @Override
+      public String strVal(int doc) {
+        CharSequence cs = func(doc, vals);
+        return cs != null ? cs.toString() : null;
+      }
+      
+      @Override
+      public boolean bytesVal(int doc, BytesRefBuilder bytes) {
+        CharSequence cs = func(doc, vals);
+        if( cs != null ){
+          bytes.copyChars(func(doc,vals));
+          return true;
+        } else {
+          bytes.clear();
+          return false;
+        }
+      }
+
+      @Override
+      public Object objectVal(int doc) {
+        return strVal(doc);
+      }
+      
+      @Override
+      public boolean exists(int doc) {
+        return vals.exists(doc);
+      }
+
+      @Override
+      public String toString(int doc) {
+        return name() + '(' + strVal(doc) + ')';
+      }
+
+      @Override
+      public ValueFiller getValueFiller() {
+        return new ValueFiller() {
+          private final MutableValueStr mval = new MutableValueStr();
+
+          @Override
+          public MutableValue getValue() {
+            return mval;
+          }
+
+          @Override
+          public void fillValue(int doc) {
+            mval.exists = bytesVal(doc, mval.value);
+          }
+        };
+      }
+    };
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (getClass() != o.getClass()) return false;
+    SingleStringFunction other = (SingleStringFunction)o;
+    return this.source.equals(other.source);
+  }
+
+  @Override
+  public int hashCode() {
+    return source.hashCode()+name().hashCode();
+  }
+
+}
diff --git solr/core/src/java/org/apache/solr/analytics/util/valuesource/package.html solr/core/src/java/org/apache/solr/analytics/util/valuesource/package.html
new file mode 100644
index 0000000..c5059c1
--- /dev/null
+++ solr/core/src/java/org/apache/solr/analytics/util/valuesource/package.html
@@ -0,0 +1,27 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+<p>
+ValueSource function/sources used by analytics component
+</p>
+</body>
+</html>
diff --git solr/core/src/java/org/apache/solr/core/SolrCore.java solr/core/src/java/org/apache/solr/core/SolrCore.java
index 7445b02..77b1fd9 100644
--- solr/core/src/java/org/apache/solr/core/SolrCore.java
+++ solr/core/src/java/org/apache/solr/core/SolrCore.java
@@ -41,6 +41,7 @@ import org.apache.solr.core.DirectoryFactory.DirContext;
 import org.apache.solr.handler.SnapPuller;
 import org.apache.solr.handler.UpdateRequestHandler;
 import org.apache.solr.handler.admin.ShowFileRequestHandler;
+import org.apache.solr.handler.component.AnalyticsComponent;
 import org.apache.solr.handler.component.DebugComponent;
 import org.apache.solr.handler.component.ExpandComponent;
 import org.apache.solr.handler.component.FacetComponent;
@@ -1281,6 +1282,7 @@ public final class SolrCore implements SolrInfoMBean, Closeable {
     addIfNotPresent(components,StatsComponent.COMPONENT_NAME,StatsComponent.class);
     addIfNotPresent(components,DebugComponent.COMPONENT_NAME,DebugComponent.class);
     addIfNotPresent(components,RealTimeGetComponent.COMPONENT_NAME,RealTimeGetComponent.class);
+    addIfNotPresent(components,AnalyticsComponent.COMPONENT_NAME,AnalyticsComponent.class);
     addIfNotPresent(components,ExpandComponent.COMPONENT_NAME,ExpandComponent.class);
 
     return components;
diff --git solr/core/src/java/org/apache/solr/handler/component/AnalyticsComponent.java solr/core/src/java/org/apache/solr/handler/component/AnalyticsComponent.java
new file mode 100644
index 0000000..38e73e2
--- /dev/null
+++ solr/core/src/java/org/apache/solr/handler/component/AnalyticsComponent.java
@@ -0,0 +1,92 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.handler.component;
+
+import java.io.IOException;
+
+import org.apache.solr.analytics.plugin.AnalyticsStatisticsCollector;
+import org.apache.solr.analytics.request.AnalyticsStats;
+import org.apache.solr.analytics.util.AnalyticsParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+
+public class AnalyticsComponent extends SearchComponent {
+  public static final String COMPONENT_NAME = "analytics";
+  private final AnalyticsStatisticsCollector analyticsCollector = new AnalyticsStatisticsCollector();;
+
+  @Override
+  public void prepare(ResponseBuilder rb) throws IOException {
+    if (rb.req.getParams().getBool(AnalyticsParams.ANALYTICS,false)) {
+      rb.setNeedDocSet( true );
+    }
+  }
+
+  @Override
+  public void process(ResponseBuilder rb) throws IOException {
+    if (rb.req.getParams().getBool(AnalyticsParams.ANALYTICS,false)) {
+      SolrParams params = rb.req.getParams();
+      AnalyticsStats s = new AnalyticsStats(rb.req, rb.getResults().docSet, params, analyticsCollector);
+      rb.rsp.add( "stats", s.execute() );
+    }
+  }
+  
+  /*
+  @Override
+  public int distributedProcess(ResponseBuilder rb) throws IOException {
+    return ResponseBuilder.STAGE_DONE;
+  }
+  
+  @Override
+  public void modifyRequest(ResponseBuilder rb, SearchComponent who, ShardRequest sreq) {
+    // TODO Auto-generated method stub
+    super.modifyRequest(rb, who, sreq);
+  }
+  
+  @Override
+  public void handleResponses(ResponseBuilder rb, ShardRequest sreq) {
+    // TODO Auto-generated method stub
+    super.handleResponses(rb, sreq);
+  }
+ 
+  @Override
+  public void finishStage(ResponseBuilder rb) {
+    // TODO Auto-generated method stub
+    super.finishStage(rb);
+  }
+  */
+  
+  @Override
+  public String getName() {
+    return COMPONENT_NAME;
+  }
+  
+  @Override
+  public String getDescription() {
+    return "Perform analytics";
+  }
+
+  @Override
+  public String getVersion() {
+    return getClass().getPackage().getSpecificationVersion();
+  }
+
+  @Override
+  public NamedList getStatistics() {
+    return analyticsCollector.getStatistics();
+  }
+}
diff --git solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java
index d819b8b..ec8a103 100644
--- solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java
+++ solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java
@@ -76,6 +76,7 @@ public class SearchHandler extends RequestHandlerBase implements SolrCoreAware ,
     names.add( HighlightComponent.COMPONENT_NAME );
     names.add( StatsComponent.COMPONENT_NAME );
     names.add( DebugComponent.COMPONENT_NAME );
+    names.add( AnalyticsComponent.COMPONENT_NAME );
     names.add( ExpandComponent.COMPONENT_NAME);
     return names;
   }
diff --git solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
index 0860589..1877c5b 100644
--- solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
+++ solr/core/src/java/org/apache/solr/handler/component/StatsComponent.java
@@ -19,9 +19,8 @@ package org.apache.solr.handler.component;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.Collection;
-import java.util.LinkedHashMap;
+import java.util.HashMap;
 import java.util.IdentityHashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -34,7 +33,6 @@ import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.ShardParams;
 import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.StatsParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.SimpleOrderedMap;
@@ -64,31 +62,21 @@ public class StatsComponent extends SearchComponent {
     if (rb.req.getParams().getBool(StatsParams.STATS,false)) {
       rb.setNeedDocSet( true );
       rb.doStats = true;
-      rb._statsInfo = new StatsInfo(rb);
     }
   }
 
   @Override
   public void process(ResponseBuilder rb) throws IOException {
-    if (!rb.doStats) return;
-
-    boolean isShard = rb.req.getParams().getBool(ShardParams.IS_SHARD, false);
-    NamedList<Object> out = new SimpleOrderedMap<>();
-    NamedList<Object> stats_fields = new SimpleOrderedMap<>();
-
-    for (StatsField statsField : rb._statsInfo.getStatsFields()) {
-      DocSet docs = statsField.computeBaseDocSet();
-      NamedList<?> stv = statsField.computeLocalStatsValues(docs).getStatsValues();
-      
-      if (isShard == true || (Long) stv.get("count") > 0) {
-        stats_fields.add(statsField.getOutputKey(), stv);
-      } else {
-        stats_fields.add(statsField.getOutputKey(), null);
-      }
+    if (rb.doStats) {
+      SolrParams params = rb.req.getParams();
+      SimpleStats s = new SimpleStats(rb.req,
+              rb.getResults().docSet,
+              params,
+              rb );
+
+      // TODO ???? add this directly to the response, or to the builder?
+      rb.rsp.add( "stats", s.getStatsCounts() );
     }
-    
-    out.add("stats_fields", stats_fields);
-    rb.rsp.add( "stats", out );
   }
 
   @Override
@@ -101,7 +89,15 @@ public class StatsComponent extends SearchComponent {
     if (!rb.doStats) return;
 
     if ((sreq.purpose & ShardRequest.PURPOSE_GET_TOP_IDS) != 0) {
-      sreq.purpose |= ShardRequest.PURPOSE_GET_STATS;
+        sreq.purpose |= ShardRequest.PURPOSE_GET_STATS;
+
+        StatsInfo si = rb._statsInfo;
+        if (si == null) {
+          rb._statsInfo = si = new StatsInfo();
+          si.parse(rb.req.getParams(), rb);
+          // should already be true...
+          // sreq.params.set(StatsParams.STATS, "true");
+        }
     } else {
       // turn off stats on other requests
       sreq.params.set(StatsParams.STATS, "false");
@@ -113,7 +109,7 @@ public class StatsComponent extends SearchComponent {
   public void handleResponses(ResponseBuilder rb, ShardRequest sreq) {
     if (!rb.doStats || (sreq.purpose & ShardRequest.PURPOSE_GET_STATS) == 0) return;
 
-    Map<String, StatsValues> allStatsValues = rb._statsInfo.getAggregateStatsValues();
+    StatsInfo si = rb._statsInfo;
 
     for (ShardResponse srsp : sreq.responses) {
       NamedList stats = null;
@@ -130,9 +126,9 @@ public class StatsComponent extends SearchComponent {
       NamedList stats_fields = (NamedList) stats.get("stats_fields");
       if (stats_fields != null) {
         for (int i = 0; i < stats_fields.size(); i++) {
-          String key = stats_fields.getName(i);
-          StatsValues stv = allStatsValues.get(key);
-          NamedList shardStv = (NamedList) stats_fields.get(key);
+          String field = stats_fields.getName(i);
+          StatsValues stv = si.statsFields.get(field);
+          NamedList shardStv = (NamedList) stats_fields.get(field);
           stv.accumulate(shardStv);
         }
       }
@@ -145,24 +141,23 @@ public class StatsComponent extends SearchComponent {
     // wait until STAGE_GET_FIELDS
     // so that "result" is already stored in the response (for aesthetics)
 
-    Map<String, StatsValues> allStatsValues = rb._statsInfo.getAggregateStatsValues();
+    StatsInfo si = rb._statsInfo;
 
     NamedList<NamedList<Object>> stats = new SimpleOrderedMap<>();
     NamedList<Object> stats_fields = new SimpleOrderedMap<>();
     stats.add("stats_fields", stats_fields);
-    
-    for (Map.Entry<String,StatsValues> entry : allStatsValues.entrySet()) {
-      String key = entry.getKey();
-      NamedList stv = entry.getValue().getStatsValues();
+    for (String field : si.statsFields.keySet()) {
+      NamedList stv = si.statsFields.get(field).getStatsValues();
       if ((Long) stv.get("count") != 0) {
-        stats_fields.add(key, stv);
+        stats_fields.add(field, stv);
       } else {
-        stats_fields.add(key, null);
+        stats_fields.add(field, null);
       }
     }
 
     rb.rsp.add("stats", stats);
-    rb._statsInfo = null; // free some objects 
+
+    rb._statsInfo = null;
   }
 
 
@@ -176,209 +171,167 @@ public class StatsComponent extends SearchComponent {
   }
 }
 
-/**
- * Models all of the information about stats needed for a single request
- * @see StatsField
- */
 class StatsInfo {
+  Map<String, StatsValues> statsFields;
 
-  private final ResponseBuilder rb;
-  private final List<StatsField> statsFields = new ArrayList<>(7);
-  private final Map<String, StatsValues> distribStatsValues = new LinkedHashMap<>();
+  void parse(SolrParams params, ResponseBuilder rb) {
+    statsFields = new HashMap<>();
 
-  public StatsInfo(ResponseBuilder rb) { 
-    this.rb = rb;
-    SolrParams params = rb.req.getParams();
-    String[] statsParams = params.getParams(StatsParams.STATS_FIELD);
-    if (null == statsParams) {
-      // no stats.field params, nothing to parse.
-      return;
-    }
-
-    for (String paramValue : statsParams) {
-      StatsField current = new StatsField(rb, paramValue);
-      statsFields.add(current);
-      distribStatsValues.put(current.getOutputKey(), current.buildNewStatsValues());
+    String[] statsFs = params.getParams(StatsParams.STATS_FIELD);
+    if (statsFs != null) {
+      for (String field : statsFs) {
+        boolean calcDistinct = params.getFieldBool(field, StatsParams.STATS_CALC_DISTINCT, false);
+        SchemaField sf = rb.req.getSchema().getField(field);
+        statsFields.put(field, StatsValuesFactory.createStatsValues(sf, calcDistinct));
+      }
     }
   }
+}
 
-  /**
-   * Returns an immutable list of {@link StatsField} instances
-   * modeling each of the {@link StatsParams#STATS_FIELD} params specified
-   * as part of this request
-   */
-  public List<StatsField> getStatsFields() {
-    return Collections.<StatsField>unmodifiableList(statsFields);
-  }
 
-  /**
-   * Returns an immutable map of response key =&gt; {@link StatsValues}
-   * instances for the current distributed request.  
-   * Depending on where we are in the process of handling this request, 
-   * these {@link StatsValues} instances may not be complete -- but they 
-   * will never be null.
-   */
-  public Map<String, StatsValues> getAggregateStatsValues() {
-    return Collections.<String, StatsValues>unmodifiableMap(distribStatsValues);
+class SimpleStats {
+
+  /** The main set of documents */
+  protected DocSet docs;
+  /** Configuration params behavior should be driven by */
+  protected SolrParams params;
+  /** Searcher to use for all calculations */
+  protected SolrIndexSearcher searcher;
+  protected SolrQueryRequest req;
+  protected ResponseBuilder rb;
+
+  // per-stats values
+  SolrParams localParams;
+  String statsField;
+  DocSet base;
+  String key;
+
+  public SimpleStats(SolrQueryRequest req,
+                      DocSet docs,
+                      SolrParams params,
+                      ResponseBuilder rb) {
+    this.req = req;
+    this.searcher = req.getSearcher();
+    this.docs = docs;
+    this.params = params;
+    this.rb = rb;
   }
 
-}
-
-/**
- * Models all of the information associated with a single {@link StatsParams#STATS_FIELD}
- * instance.
- */
-class StatsField {
-
-  private final SolrIndexSearcher searcher;
-  private final ResponseBuilder rb;
-  private final String originalParam; // for error messages
-  private final SolrParams localParams;
-  private final SchemaField sf;
-  private final String fieldName;
-  private final String key;
-  private final boolean calcDistinct;
-  private final String[] facets;
-  private final List<String> excludeTagList;
-
-  /**
-   * @param rb the current request/response
-   * @param statsParam the raw {@link StatsParams#STATS_FIELD} string
-   */
-  public StatsField(ResponseBuilder rb, String statsParam) { 
-    this.rb = rb;
-    this.searcher = rb.req.getSearcher();
-    this.originalParam = statsParam;
+  protected void parseParams(String param) throws SyntaxError, IOException {
+    localParams = QueryParsing.getLocalParams(param, req.getParams());
+    base = docs;
+    statsField = param;
+    key = param;
 
-    SolrParams params = rb.req.getParams();
+    if (localParams == null) return;
 
-    try {
-      SolrParams localParams = QueryParsing.getLocalParams(statsParam, params);
-      if (null == localParams) {
-        localParams = new ModifiableSolrParams();
-      }
-      this.localParams = localParams;
-    } catch (SyntaxError e) {
-      throw new SolrException(ErrorCode.BAD_REQUEST, "Unable to parse " + 
-                              StatsParams.STATS_FIELD + ": " + originalParam + " due to: "
-                              + e.getMessage(), e);
-    }
+    statsField = localParams.get(CommonParams.VALUE);
 
-    // pull fieldName out of localParams, or default to original param value
-    this.fieldName = localParams.get(CommonParams.VALUE, statsParam);
-    // allow explicit set of the key via localparams, default to fieldName
-    this.key = localParams.get(CommonParams.OUTPUT_KEY, fieldName);
+    // reset set the default key now that localParams have been removed
+    key = statsField;
 
-    calcDistinct = params.getFieldBool(fieldName, StatsParams.STATS_CALC_DISTINCT, false);
+    // allow explicit set of the key
+    key = localParams.get(CommonParams.OUTPUT_KEY, key);
 
-    String[] facets = params.getFieldParams(key, StatsParams.STATS_FACET);
-    this.facets = (null == facets) ? new String[0] : facets;
 
     // figure out if we need a new base DocSet
     String excludeStr = localParams.get(CommonParams.EXCLUDE);
-    this.excludeTagList = (null == excludeStr) 
-      ? Collections.<String>emptyList()
-      : StrUtils.splitSmart(excludeStr,',');
-
-    this.sf = searcher.getSchema().getField(fieldName);
-  }
-
-  /** 
-   * The key to be used when refering to this {@link StatsField} instance in the 
-   * response tp clients.
-   */
-  public String getOutputKey() {
-    return key;
-  }
+    if (excludeStr == null) return;
+
+    Map<?,?> tagMap = (Map<?,?>)req.getContext().get("tags");
+    if (tagMap != null && rb != null) {
+      List<String> excludeTagList = StrUtils.splitSmart(excludeStr,',');
+
+      IdentityHashMap<Query,Boolean> excludeSet = new IdentityHashMap<Query,Boolean>();
+      for (String excludeTag : excludeTagList) {
+        Object olst = tagMap.get(excludeTag);
+        // tagMap has entries of List<String,List<QParser>>, but subject to change in the future
+        if (!(olst instanceof Collection)) continue;
+        for (Object o : (Collection<?>)olst) {
+          if (!(o instanceof QParser)) continue;
+          QParser qp = (QParser)o;
+          excludeSet.put(qp.getQuery(), Boolean.TRUE);
+        }
+      }
+      if (excludeSet.size() == 0) return;
 
-  /**
-   * Returns a new, empty, {@link StatsValues} instance that can be used for
-   * accumulating the appropriate stats from this {@link StatsField}
-   */
-  public StatsValues buildNewStatsValues() {
-    return StatsValuesFactory.createStatsValues(sf, calcDistinct);
-  }
+      List<Query> qlist = new ArrayList<Query>();
 
-  /**
-   * Computes a base {@link DocSet} for the current request to be used
-   * when computing global stats for the local index.
-   *
-   * This is typically the same as the main DocSet for the {@link ResponseBuilder}
-   * unless {@link CommonParams#TAG tag}ged filter queries have been excluded using 
-   * the {@link CommonParams#EXCLUDE ex} local param
-   */
-  public DocSet computeBaseDocSet() throws IOException {
-
-    DocSet docs = rb.getResults().docSet;
-    Map<?,?> tagMap = (Map<?,?>) rb.req.getContext().get("tags");
-
-    if (excludeTagList.isEmpty() || null == tagMap) {
-      // either the exclude list is empty, or there
-      // aren't any tagged filters to exclude anyway.
-      return docs;
-    }
+      // add the base query
+      if (!excludeSet.containsKey(rb.getQuery())) {
+        qlist.add(rb.getQuery());
+      }
 
-    IdentityHashMap<Query,Boolean> excludeSet = new IdentityHashMap<Query,Boolean>();
-    for (String excludeTag : excludeTagList) {
-      Object olst = tagMap.get(excludeTag);
-      // tagMap has entries of List<String,List<QParser>>, but subject to change in the future
-      if (!(olst instanceof Collection)) continue;
-      for (Object o : (Collection<?>)olst) {
-        if (!(o instanceof QParser)) continue;
-        QParser qp = (QParser)o;
-        try {
-          excludeSet.put(qp.getQuery(), Boolean.TRUE);
-        } catch (SyntaxError e) {
-          // this shouldn't be possible since the request should have already
-          // failed when attempting to execute the query, but just in case...
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Excluded query can't be parsed: " + 
-                                  originalParam + " due to: " + e.getMessage(), e);
+      // add the filters
+      if (rb.getFilters() != null) {
+        for (Query q : rb.getFilters()) {
+          if (!excludeSet.containsKey(q)) {
+            qlist.add(q);
+          }
         }
       }
+
+      // get the new base docset for this facet
+      this.base = searcher.getDocSet(qlist);
     }
-    if (excludeSet.size() == 0) return docs;
-    
-    List<Query> qlist = new ArrayList<Query>();
-    
-    // add the base query
-    if (!excludeSet.containsKey(rb.getQuery())) {
-      qlist.add(rb.getQuery());
-    }
-    
-    // add the filters
-    if (rb.getFilters() != null) {
-      for (Query q : rb.getFilters()) {
-        if (!excludeSet.containsKey(q)) {
-          qlist.add(q);
-        }
-      }
+
+  }
+
+  public NamedList<Object> getStatsCounts() throws IOException {
+    NamedList<Object> res = new SimpleOrderedMap<>();
+
+    try {
+      res.add("stats_fields", getStatsFields());
+    } catch (SyntaxError e) {
+      throw new SolrException(ErrorCode.BAD_REQUEST, e);
     }
-    
-    // get the new base docset for this facet
-    return searcher.getDocSet(qlist);
+
+    return res;
   }
 
-  /**
-   * Computes the {@link StatsValues} for this {@link StatsField} relative to the 
-   * specified {@link DocSet} 
-   * @see #computeBaseDocSet
-   */
-  public StatsValues computeLocalStatsValues(DocSet base) throws IOException {
+  public NamedList<Object> getStatsFields() throws IOException, SyntaxError {
+    NamedList<Object> res = new SimpleOrderedMap<>();
+    String[] statsFs = params.getParams(StatsParams.STATS_FIELD);
+    boolean isShard = params.getBool(ShardParams.IS_SHARD, false);
+    if (null != statsFs) {
+      final IndexSchema schema = searcher.getSchema();
+      for (String f : statsFs) {
+        boolean calcDistinct = params.getFieldBool(f, StatsParams.STATS_CALC_DISTINCT, false);
 
-    if (sf.multiValued() || sf.getType().multiValuedFieldCache()) {
-      // TODO: should this also be used for single-valued string fields? (should work fine)
-      return DocValuesStats.getCounts(searcher, fieldName, base, calcDistinct, facets);
-    } else {
-      return getFieldCacheStats(base);
+        parseParams(f);
+
+        String[] facets = params.getFieldParams(key, StatsParams.STATS_FACET);
+        if (facets == null) {
+          facets = new String[0]; // make sure it is something...
+        }
+        SchemaField sf = schema.getField(statsField);
+        FieldType ft = sf.getType();
+        NamedList<?> stv;
+
+        if (sf.multiValued() || ft.multiValuedFieldCache()) {
+          // TODO: should this also be used for single-valued string fields? (should work fine)
+          stv = DocValuesStats.getCounts(searcher, sf.getName(), base, calcDistinct, facets).getStatsValues();
+        } else {
+          stv = getFieldCacheStats(statsField, calcDistinct, facets);
+        }
+        if (isShard == true || (Long) stv.get("count") > 0) {
+          res.add(key, stv);
+        } else {
+          res.add(key, null);
+        }
+      }
     }
+    return res;
   }
 
-  private StatsValues getFieldCacheStats(DocSet base) throws IOException {
+  public NamedList<?> getFieldCacheStats(String fieldName, boolean calcDistinct, String[] facet) throws IOException {
     IndexSchema schema = searcher.getSchema();
+    final SchemaField sf = schema.getField(fieldName);
+
     final StatsValues allstats = StatsValuesFactory.createStatsValues(sf, calcDistinct);
 
     List<FieldFacetStats> facetStats = new ArrayList<>();
-    for( String facetField : facets ) {
+    for( String facetField : facet ) {
       SchemaField fsf = schema.getField(facetField);
 
       if ( fsf.multiValued()) {
@@ -417,7 +370,7 @@ class StatsField {
     for (FieldFacetStats f : facetStats) {
       allstats.addFacet(f.name, f.facetStatsValues);
     }
-    return allstats;
+    return allstats.getStatsValues();
   }
 
 }
diff --git solr/core/src/java/org/apache/solr/handler/component/SuggestComponent.java solr/core/src/java/org/apache/solr/handler/component/SuggestComponent.java
index 33881cf..d17059e 100644
--- solr/core/src/java/org/apache/solr/handler/component/SuggestComponent.java
+++ solr/core/src/java/org/apache/solr/handler/component/SuggestComponent.java
@@ -33,7 +33,6 @@ import java.util.concurrent.ConcurrentHashMap;
 import org.apache.lucene.search.suggest.Lookup;
 import org.apache.lucene.search.suggest.Lookup.LookupResult;
 import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRef;
 import org.apache.solr.common.SolrException;
@@ -341,11 +340,6 @@ public class SuggestComponent extends SearchComponent implements SolrCoreAware,
     return sizeInBytes;
   }
   
-  @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return Accountables.namedAccountables("field", suggesters);
-  }
-  
   private Set<SolrSuggester> getSuggesters(SolrParams params) {
     Set<SolrSuggester> solrSuggesters = new HashSet<>();
     for(String suggesterName : getSuggesterNames(params)) {
diff --git solr/core/src/java/org/apache/solr/spelling/suggest/SolrSuggester.java solr/core/src/java/org/apache/solr/spelling/suggest/SolrSuggester.java
index 13cf979..92ef4e7 100644
--- solr/core/src/java/org/apache/solr/spelling/suggest/SolrSuggester.java
+++ solr/core/src/java/org/apache/solr/spelling/suggest/SolrSuggester.java
@@ -22,7 +22,6 @@ import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.io.IOException;
-import java.util.Collections;
 import java.util.List;
 
 import org.apache.lucene.search.spell.Dictionary;
@@ -213,11 +212,6 @@ public class SolrSuggester implements Accountable {
   }
   
   @Override
-  public Iterable<? extends Accountable> getChildResources() {
-    return lookup.getChildResources();
-  }
-  
-  @Override
   public String toString() {
     return "SolrSuggester [ name=" + name + ", "
         + "sourceLocation=" + sourceLocation + ", "
diff --git solr/core/src/java/org/apache/solr/update/processor/MaxFieldValueUpdateProcessorFactory.java solr/core/src/java/org/apache/solr/update/processor/MaxFieldValueUpdateProcessorFactory.java
index 1ce15fa..6366973 100644
--- solr/core/src/java/org/apache/solr/update/processor/MaxFieldValueUpdateProcessorFactory.java
+++ solr/core/src/java/org/apache/solr/update/processor/MaxFieldValueUpdateProcessorFactory.java
@@ -59,8 +59,9 @@ public final class MaxFieldValueUpdateProcessorFactory extends FieldValueSubsetU
   public Collection pickSubset(Collection values) {
     Collection result = values;
     try {
-      result = Collections.singletonList
-        (Collections.max(values));
+      // NOTE: max must be put into a temp local in order to avoid ecj errors for javadoc lint
+      Object max = Collections.max(values);
+      result = Collections.singletonList(max);
     } catch (ClassCastException e) {
       throw new SolrException
         (BAD_REQUEST, 
diff --git solr/core/src/java/org/apache/solr/update/processor/MinFieldValueUpdateProcessorFactory.java solr/core/src/java/org/apache/solr/update/processor/MinFieldValueUpdateProcessorFactory.java
index fe4e23b..da18d73 100644
--- solr/core/src/java/org/apache/solr/update/processor/MinFieldValueUpdateProcessorFactory.java
+++ solr/core/src/java/org/apache/solr/update/processor/MinFieldValueUpdateProcessorFactory.java
@@ -59,8 +59,9 @@ public final class MinFieldValueUpdateProcessorFactory extends FieldValueSubsetU
   public Collection pickSubset(Collection values) {
     Collection result = values;
     try {
-      result = Collections.singletonList
-        (Collections.min(values));
+      // NOTE: min must be put into a temp local in order to avoid ecj errors for javadoc lint
+      Object min = Collections.min(values);
+      result = Collections.singletonList(min);
     } catch (ClassCastException e) {
       throw new SolrException
         (BAD_REQUEST, 
diff --git solr/core/src/test-files/analytics/requestFiles/expressions.txt solr/core/src/test-files/analytics/requestFiles/expressions.txt
new file mode 100644
index 0000000..329d32d
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/expressions.txt
@@ -0,0 +1,70 @@
+o.ar.s.sum=sum(int_id)
+o.ar.s.unique=unique(long_ld)
+o.ar.s.su=add(sum(int_id),unique(long_ld))
+o.ar.s.mean=mean(int_id)
+o.ar.s.count=count(long_ld)
+o.ar.s.median=median(int_id)
+o.ar.s.mcm=add(mean(int_id),count(long_ld),median(int_id))
+
+o.mr.s.sum=sum(int_id)
+o.mr.s.unique=unique(long_ld)
+o.mr.s.su=mult(sum(int_id),unique(long_ld))
+o.mr.s.mean=mean(int_id)
+o.mr.s.count=count(long_ld)
+o.mr.s.median=median(int_id)
+o.mr.s.mcm=mult(mean(int_id),count(long_ld),median(int_id))
+
+o.dr.s.sum=sum(int_id)
+o.dr.s.unique=unique(long_ld)
+o.dr.s.su=div(sum(int_id),unique(long_ld))
+o.dr.s.mean=mean(int_id)
+o.dr.s.count=count(long_ld)
+o.dr.s.mc=div(mean(int_id),count(long_ld))
+
+o.pr.s.sum=sum(int_id)
+o.pr.s.unique=unique(long_ld)
+o.pr.s.su=pow(sum(int_id),unique(long_ld))
+o.pr.s.mean=mean(int_id)
+o.pr.s.count=count(long_ld)
+o.pr.s.mc=pow(mean(int_id),count(long_ld))
+
+o.nr.s.sum=sum(int_id)
+o.nr.s.s=neg(sum(int_id))
+o.nr.s.count=count(long_ld)
+o.nr.s.c=neg(count(long_ld))
+
+o.avr.s.sum=sum(int_id)
+o.avr.s.s=abs(neg(sum(int_id)))
+o.avr.s.count=count(long_ld)
+o.avr.s.c=abs(neg(count(long_ld)))
+
+o.cnr.s.c8=const_num(8)
+o.cnr.s.c10=const_num(10)
+
+o.dmr.s.median=median(date_dtd)
+o.dmr.s.cme=const_str(+2YEARS)
+o.dmr.s.dmme=date_math(median(date_dtd),const_str(+2YEARS))
+o.dmr.s.max=max(date_dtd)
+o.dmr.s.cma=const_str(+2MONTHS)
+o.dmr.s.dmma=date_math(max(date_dtd),const_str(+2MONTHS))
+
+o.cdr.s.cd1=const_date(1800-12-31T23:59:59Z)
+o.cdr.s.cs1=const_str(1800-12-31T23:59:59Z)
+o.cdr.s.cd2=const_date(1804-06-30T23:59:59Z)
+o.cdr.s.cs2=const_str(1804-06-30T23:59:59Z)
+
+o.csr.s.cs1=const_str(this is the first)
+o.csr.s.cs2=const_str(this is the second)
+o.csr.s.cs3=const_str(this is the third)
+
+o.cr.s.csmin=const_str(this is the first)
+o.cr.s.min=min(string_sd)
+o.cr.s.ccmin=concat(const_str(this is the first),min(string_sd))
+o.cr.s.csmax=const_str(this is the second)
+o.cr.s.max=max(string_sd)
+o.cr.s.ccmax=concat(const_str(this is the second),max(string_sd))
+
+o.rr.s.min=min(string_sd)
+o.rr.s.rmin=rev(min(string_sd))
+o.rr.s.max=max(string_sd)
+o.rr.s.rmax=rev(max(string_sd))
diff --git solr/core/src/test-files/analytics/requestFiles/fieldFacetExtras.txt solr/core/src/test-files/analytics/requestFiles/fieldFacetExtras.txt
new file mode 100644
index 0000000..3979f57
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/fieldFacetExtras.txt
@@ -0,0 +1,66 @@
+o.sr.s.mean=mean(int_id)
+o.sr.s.median=median(int_id)
+o.sr.s.count=count(int_id)
+o.sr.s.percentile_20=percentile(20,int_id)
+o.sr.ff=long_ld
+o.sr.ff.long_ld.ss=mean
+o.sr.ff.long_ld.sd=asc
+o.sr.ff=float_fd
+o.sr.ff.float_fd.ss=median
+o.sr.ff.float_fd.sd=desc
+o.sr.ff=double_dd
+o.sr.ff.double_dd.ss=count
+o.sr.ff.double_dd.sd=asc
+o.sr.ff=string_sd
+o.sr.ff.string_sd.ss=percentile_20
+o.sr.ff.string_sd.sd=desc
+
+o.lr.s.mean=mean(int_id)
+o.lr.s.median=median(int_id)
+o.lr.s.count=count(int_id)
+o.lr.s.percentile_20=percentile(20,int_id)
+o.lr.ff=long_ld
+o.lr.ff.long_ld.ss=mean
+o.lr.ff.long_ld.sd=asc
+o.lr.ff.long_ld.limit=5
+o.lr.ff=float_fd
+o.lr.ff.float_fd.ss=median
+o.lr.ff.float_fd.sd=desc
+o.lr.ff.float_fd.limit=3
+o.lr.ff=double_dd
+o.lr.ff.double_dd.ss=count
+o.lr.ff.double_dd.sd=asc
+o.lr.ff.double_dd.limit=7
+o.lr.ff=string_sd
+o.lr.ff.string_sd.ss=percentile_20
+o.lr.ff.string_sd.sd=desc
+o.lr.ff.string_sd.limit=1
+
+
+
+o.offAll.s.mean=mean(int_id)
+o.offAll.ff=long_ld
+o.offAll.ff.long_ld.ss=mean
+o.offAll.ff.long_ld.sd=asc
+o.offAll.ff.long_ld.limit=7
+
+o.off0.s.mean=mean(int_id)
+o.off0.ff=long_ld
+o.off0.ff.long_ld.ss=mean
+o.off0.ff.long_ld.sd=asc
+o.off0.ff.long_ld.limit=2
+o.off0.ff.long_ld.offset=0
+
+o.off1.s.mean=mean(int_id)
+o.off1.ff=long_ld
+o.off1.ff.long_ld.ss=mean
+o.off1.ff.long_ld.sd=asc
+o.off1.ff.long_ld.limit=2
+o.off1.ff.long_ld.offset=2
+
+o.off2.s.mean=mean(int_id)
+o.off2.ff=long_ld
+o.off2.ff.long_ld.ss=mean
+o.off2.ff.long_ld.sd=asc
+o.off2.ff.long_ld.limit=3
+o.off2.ff.long_ld.offset=4
diff --git solr/core/src/test-files/analytics/requestFiles/fieldFacets.txt solr/core/src/test-files/analytics/requestFiles/fieldFacets.txt
new file mode 100644
index 0000000..5ba5953
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/fieldFacets.txt
@@ -0,0 +1,132 @@
+o.sum.s.int=sum(int_id)
+o.sum.s.long=sum(long_ld)
+o.sum.s.float=sum(float_fd)
+o.sum.s.double=sum(double_dd)
+o.sum.ff=string_sd
+o.sum.ff=date_dtd
+
+o.mean.s.int=mean(int_id)
+o.mean.s.long=mean(long_ld)
+o.mean.s.float=mean(float_fd)
+o.mean.s.double=mean(double_dd)
+o.mean.ff=string_sd
+o.mean.ff=date_dtd
+
+o.sumOfSquares.s.int=sumofsquares(int_id)
+o.sumOfSquares.s.long=sumofsquares(long_ld)
+o.sumOfSquares.s.float=sumofsquares(float_fd)
+o.sumOfSquares.s.double=sumofsquares(double_dd)
+o.sumOfSquares.ff=string_sd
+o.sumOfSquares.ff=date_dtd
+
+o.stddev.s.int=stddev(int_id)
+o.stddev.s.long=stddev(long_ld)
+o.stddev.s.float=stddev(float_fd)
+o.stddev.s.double=stddev(double_dd)
+o.stddev.ff=string_sd
+o.stddev.ff=date_dtd
+
+o.median.s.int=median(int_id)
+o.median.s.long=median(long_ld)
+o.median.s.float=median(float_fd)
+o.median.s.double=median(double_dd)
+o.median.ff=string_sd
+o.median.ff=date_dtd
+
+o.percentile_20n.s.int=percentile(20,int_id)
+o.percentile_20n.s.long=percentile(20,long_ld)
+o.percentile_20n.s.float=percentile(20,float_fd)
+o.percentile_20n.s.double=percentile(20,double_dd)
+o.percentile_20n.ff=string_sd
+o.percentile_20n.ff=date_dtd
+
+o.percentile_20.s.str=percentile(20,string_sd)
+o.percentile_20.s.date=percentile(20,date_dtd)
+o.percentile_20.ff=int_id
+o.percentile_20.ff=long_ld
+
+o.percentile_60n.s.int=percentile(60,int_id)
+o.percentile_60n.s.long=percentile(60,long_ld)
+o.percentile_60n.s.float=percentile(60,float_fd)
+o.percentile_60n.s.double=percentile(60,double_dd)
+o.percentile_60n.ff=string_sd
+o.percentile_60n.ff=date_dtd
+
+o.percentile_60.s.str=percentile(60,string_sd)
+o.percentile_60.s.date=percentile(60,date_dtd)
+o.percentile_60.ff=int_id
+o.percentile_60.ff=long_ld
+
+o.minn.s.int=min(int_id)
+o.minn.s.long=min(long_ld)
+o.minn.s.float=min(float_fd)
+o.minn.s.double=min(double_dd)
+o.minn.ff=string_sd
+o.minn.ff=date_dtd
+
+o.min.s.str=min(string_sd)
+o.min.s.date=min(date_dtd)
+o.min.ff=int_id
+o.min.ff=long_ld
+
+o.maxn.s.int=max(int_id)
+o.maxn.s.long=max(long_ld)
+o.maxn.s.float=max(float_fd)
+o.maxn.s.double=max(double_dd)
+o.maxn.ff=string_sd
+o.maxn.ff=date_dtd
+
+o.max.s.str=max(string_sd)
+o.max.s.date=max(date_dtd)
+o.max.ff=int_id
+o.max.ff=long_ld
+
+o.countn.s.int=count(int_id)
+o.countn.s.long=count(long_ld)
+o.countn.s.float=count(float_fd)
+o.countn.s.double=count(double_dd)
+o.countn.ff=string_sd
+o.countn.ff=date_dtd
+
+o.count.s.str=count(string_sd)
+o.count.s.date=count(date_dtd)
+o.count.ff=int_id
+o.count.ff=long_ld
+
+o.uniquen.s.int=unique(int_id)
+o.uniquen.s.long=unique(long_ld)
+o.uniquen.s.float=unique(float_fd)
+o.uniquen.s.double=unique(double_dd)
+o.uniquen.ff=string_sd
+o.uniquen.ff=date_dtd
+
+o.unique.s.str=unique(string_sd)
+o.unique.s.date=unique(date_dtd)
+o.unique.ff=int_id
+o.unique.ff=long_ld
+
+o.missingn.s.int=missing(int_id)
+o.missingn.s.long=missing(long_ld)
+o.missingn.s.float=missing(float_fd)
+o.missingn.s.double=missing(double_dd)
+o.missingn.ff=string_sd
+o.missingn.ff=date_dtd
+
+o.missing.s.str=missing(string_sd)
+o.missing.s.date=missing(date_dtd)
+o.missing.ff=int_id
+o.missing.ff=long_ld
+
+o.multivalued.s.mean=mean(int_id)
+o.multivalued.ff=long_ldm
+o.multivalued.ff=string_sdm
+o.multivalued.ff=date_dtdm
+
+o.missingf.s.mean=mean(int_id)
+o.missingf.ff=date_dtd
+o.missingf.ff.date_dtd.dim=true
+o.missingf.ff=string_sd
+o.missingf.ff.string_sd.dim=true
+o.missingf.ff.string_sd.sm=true
+o.missingf.ff=date_dtdm
+o.missingf.ff.date_dtdm.sm=true
diff --git solr/core/src/test-files/analytics/requestFiles/functions.txt solr/core/src/test-files/analytics/requestFiles/functions.txt
new file mode 100644
index 0000000..e4930b6
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/functions.txt
@@ -0,0 +1,62 @@
+o.ar.s.sum=sum(add(int_id,float_fd))
+o.ar.s.sumc=sum(add_if_dd)
+o.ar.s.mean=mean(add(long_ld,double_dd,float_fd))
+o.ar.s.meanc=mean(add_ldf_dd)
+
+o.mr.s.sum=sum(mult(int_id,float_fd))
+o.mr.s.sumc=sum(mult_if_dd)
+o.mr.s.mean=mean(mult(long_ld,double_dd,float_fd))
+o.mr.s.meanc=mean(mult_ldf_dd)
+
+o.dr.s.sum=sum(div(int_id,float_fd))
+o.dr.s.sumc=sum(div_if_dd)
+o.dr.s.mean=mean(div(long_ld,double_dd))
+o.dr.s.meanc=mean(div_ld_dd)
+
+o.pr.s.sum=sum(pow(int_id,float_fd))
+o.pr.s.sumc=sum(pow_if_dd)
+o.pr.s.mean=mean(pow(long_ld,double_dd))
+o.pr.s.meanc=mean(pow_ld_dd)
+
+o.nr.s.sum=sum(neg(int_id))
+o.nr.s.sumc=sum(neg_i_dd)
+o.nr.s.mean=mean(neg(long_ld))
+o.nr.s.meanc=mean(neg_l_dd)
+
+o.avr.s.sum=sum(abs(neg(int_id)))
+o.avr.s.sumc=sum(int_id)
+o.avr.s.mean=mean(abs(neg(int_id)))
+o.avr.s.meanc=mean(int_id)
+
+o.cnr.s.sum=sum(const_num(8))
+o.cnr.s.sumc=sum(const_8_dd)
+o.cnr.s.mean=mean(const_num(10))
+o.cnr.s.meanc=mean(const_10_dd)
+
+o.dmr.s.median=median(date_math(date_dtd,const_str(+2YEARS)))
+o.dmr.s.medianc=median(dm_2y_dtd)
+o.dmr.s.max=max(date_math(date_dtd,const_str(+2MONTHS)))
+o.dmr.s.maxc=max(dm_2m_dtd)
+
+o.cdr.s.median=median(const_date(1800-06-30T23:59:59Z))
+o.cdr.s.medianc=median(const_00_dtd)
+o.cdr.s.max=max(const_date(1804-06-30T23:59:59Z))
+o.cdr.s.maxc=max(const_04_dtd)
+
+o.csr.s.min=min(const_str(this is the first))
+o.csr.s.minc=min(const_first_sd)
+o.csr.s.max=max(const_str(this is the second))
+o.csr.s.maxc=max(const_second_sd)
+
+o.cr.s.min=min(concat(const_str(this is the first),string_sd))
+o.cr.s.minc=min(concat_first_sd)
+o.cr.s.max=max(concat(const_str(this is the second),string_sd))
+o.cr.s.maxc=max(concat_second_sd)
+
+o.rr.s.min=min(rev(string_sd))
+o.rr.s.minc=min(rev_sd)
+o.rr.s.max=max(rev(string_sd))
+o.rr.s.maxc=max(rev_sd)
+
+o.ms.s.min=min(miss_dd)
+o.ms.s.max=max(miss_dd)
diff --git solr/core/src/test-files/analytics/requestFiles/noFacets.txt solr/core/src/test-files/analytics/requestFiles/noFacets.txt
new file mode 100644
index 0000000..b3d9163
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/noFacets.txt
@@ -0,0 +1,74 @@
+o.sr.s.int_id=sum(int_i)
+o.sr.s.long_ld=sum(long_l)
+o.sr.s.float_fd=sum(float_f)
+o.sr.s.double_dd=sum(double_d)
+
+o.sosr.s.int_id=sumofsquares(int_id)
+o.sosr.s.long_ld=sumofsquares(long_ld)
+o.sosr.s.float_fd=sumofsquares(float_fd)
+o.sosr.s.double_dd=sumofsquares(double_dd)
+
+o.mr.s.int_id=mean(int_id)
+o.mr.s.long_ld=mean(long_ld)
+o.mr.s.float_fd=mean(float_fd)
+o.mr.s.double_dd=mean(double_dd)
+
+o.str.s.int_id=stddev(int_id)
+o.str.s.long_ld=stddev(long_ld)
+o.str.s.float_fd=stddev(float_fd)
+o.str.s.double_dd=stddev(double_dd)
+
+o.medr.s.int_id=median(int_id)
+o.medr.s.long_ld=median(long_ld)
+o.medr.s.float_fd=median(float_fd)
+o.medr.s.double_dd=median(double_dd)
+o.medr.s.date_dtd=median(date_dtd)
+
+o.p2r.s.int_id=percentile(20,int_id)
+o.p2r.s.long_ld=percentile(20,long_ld)
+o.p2r.s.float_fd=percentile(20,float_fd)
+o.p2r.s.double_dd=percentile(20,double_dd)
+o.p2r.s.date_dtd=percentile(20,date_dtd)
+o.p2r.s.string_sd=percentile(20,string_sd)
+
+o.p6r.s.int_id=percentile(60,int_id)
+o.p6r.s.long_ld=percentile(60,long_ld)
+o.p6r.s.float_fd=percentile(60,float_fd)
+o.p6r.s.double_dd=percentile(60,double_dd)
+o.p6r.s.date_dtd=percentile(60,date_dtd)
+o.p6r.s.string_sd=percentile(60,string_sd)
+
+o.mir.s.int_id=min(int_id)
+o.mir.s.long_ld=min(long_ld)
+o.mir.s.float_fd=min(float_fd)
+o.mir.s.double_dd=min(double_dd)
+o.mir.s.date_dtd=min(date_dtd)
+o.mir.s.string_sd=min(string_sd)
+
+o.mar.s.int_id=max(int_id)
+o.mar.s.long_ld=max(long_ld)
+o.mar.s.float_fd=max(float_fd)
+o.mar.s.double_dd=max(double_dd)
+o.mar.s.date_dtd=max(date_dtd)
+o.mar.s.string_sd=max(string_sd)
+
+o.cr.s.int_id=count(int_id)
+o.cr.s.long_ld=count(long_ld)
+o.cr.s.float_fd=count(float_fd)
+o.cr.s.double_dd=count(double_dd)
+o.cr.s.date_dtd=count(date_dtd)
+o.cr.s.string_sd=count(string_sd)
+
+o.ur.s.int_id=unique(int_id)
+o.ur.s.long_ld=unique(long_ld)
+o.ur.s.float_fd=unique(float_fd)
+o.ur.s.double_dd=unique(double_dd)
+o.ur.s.date_dtd=unique(date_dtd)
+o.ur.s.string_sd=unique(string_sd)
+
+o.misr.s.int_id=missing(int_id)
+o.misr.s.long_ld=missing(long_ld)
+o.misr.s.float_fd=missing(float_fd)
+o.misr.s.double_dd=missing(double_dd)
+o.misr.s.date_dtd=missing(date_dtd)
+o.misr.s.string_sd=missing(string_sd)
diff --git solr/core/src/test-files/analytics/requestFiles/queryFacets.txt solr/core/src/test-files/analytics/requestFiles/queryFacets.txt
new file mode 100644
index 0000000..6be4a4e
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/queryFacets.txt
@@ -0,0 +1,45 @@
+o.ir.s.sum=sum(int_id)
+o.ir.s.mean=mean(int_id)
+o.ir.s.median=median(int_id)
+o.ir.s.percentile_8=percentile(8,int_id)
+o.ir.ff=string_sd
+o.ir.ff.string_sd.h=true
+o.ir.qf=float1
+o.ir.qf.float1.q=float_fd:[* TO 50]
+o.ir.qf=float2
+o.ir.qf.float2.q=float_fd:[* TO 30]
+
+o.pr.s.sum=sum(int_id)
+o.pr.s.mean=mean(int_id)
+o.pr.s.median=median(int_id)
+o.pr.s.q1=concat(const_str(float_fd:[), percentile(10,int_id), const_str( TO ), median(int_id), const_str(]))
+o.pr.hs.q2=concat(const_str(float_fd:[), percentile(30,int_id), const_str( TO ), median(int_id), const_str(]))
+o.pr.hs.q3=concat(const_str(float_fd:[), percentile(40,int_id), const_str( TO ), median(int_id), const_str(]))
+o.pr.s.percentile_8=percentile(8,int_id)
+o.pr.ff=string_sd
+o.pr.ff.string_sd.h=true
+o.pr.qf=float3
+o.pr.qf.float3.q=result(q1)
+o.pr.qf.float3.q=result(q2)
+o.pr.qf.float3.q=result(q3)
+o.pr.qf.float3.q=result(q1,string_sd,abc2)
+o.pr.qf=float4
+o.pr.qf.float4.d=float3
+o.pr.qf.float4.q=qresult(q1,float3,result(q1))
+
+o.lr.s.sum=sum(long_ld)
+o.lr.s.mean=mean(long_ld)
+o.lr.s.median=median(long_ld)
+o.lr.s.percentile_8=percentile(8,long_ld)
+o.lr.qf=string
+o.lr.qf.string.q=string_sd:abc1
+o.lr.qf.string.q=string_sd:abc2
+
+o.fr.s.sum=sum(float_fd)
+o.fr.s.mean=mean(float_fd)
+o.fr.s.median=median(float_fd)
+o.fr.s.percentile_8=percentile(8,float_fd)
+o.fr.qf=lad
+o.fr.qf.lad.q=long_ld:[20 TO *]
+o.fr.qf.lad.q=long_ld:[30 TO *]
+o.fr.qf.lad.q=double_dd:[* TO 50]
diff --git solr/core/src/test-files/analytics/requestFiles/rangeFacets.txt solr/core/src/test-files/analytics/requestFiles/rangeFacets.txt
new file mode 100644
index 0000000..cbfe052
--- /dev/null
+++ solr/core/src/test-files/analytics/requestFiles/rangeFacets.txt
@@ -0,0 +1,170 @@
+o.ri.s.sum=sum(int_id)
+o.ri.s.mean=mean(int_id)
+o.ri.s.median=median(int_id)
+o.ri.s.count=count(int_id)
+o.ri.s.sumOfSquares=sumofsquares(int_id)
+o.ri.rf=long_ld
+o.ri.rf.long_ld.st=5
+o.ri.rf.long_ld.e=30
+o.ri.rf.long_ld.g=5
+o.ri.rf.long_ld.ib=lower
+o.ri.rf.long_ld.or=all
+o.ri.rf=double_dd
+o.ri.rf.double_dd.st=3
+o.ri.rf.double_dd.e=39
+o.ri.rf.double_dd.g=7
+o.ri.rf.double_dd.ib=upper
+o.ri.rf.double_dd.ib=outer
+o.ri.rf.double_dd.or=all
+o.ri.rf=date_dtd
+o.ri.rf.date_dtd.st=1007-01-01T23:59:59Z
+o.ri.rf.date_dtd.e=1044-01-01T23:59:59Z
+o.ri.rf.date_dtd.g=+7YEARS
+o.ri.rf.date_dtd.ib=lower
+o.ri.rf.date_dtd.ib=edge
+o.ri.rf.date_dtd.ib=outer
+o.ri.rf.date_dtd.or=all
+
+o.rf.s.sum=sum(float_fd)
+o.rf.s.mean=mean(float_fd)
+o.rf.s.median=median(float_fd)
+o.rf.s.count=count(float_fd)
+o.rf.s.sumOfSquares=sumofsquares(float_fd)
+o.rf.rf=long_ld
+o.rf.rf.long_ld.st=0
+o.rf.rf.long_ld.e=29
+o.rf.rf.long_ld.g=4
+o.rf.rf.long_ld.ib=all
+o.rf.rf.long_ld.or=all
+o.rf.rf=double_dd
+o.rf.rf.double_dd.st=4
+o.rf.rf.double_dd.e=47
+o.rf.rf.double_dd.g=11
+o.rf.rf.double_dd.ib=edge
+o.rf.rf.double_dd.or=all
+o.rf.rf=date_dtd
+o.rf.rf.date_dtd.st=1004-01-01T23:59:59Z
+o.rf.rf.date_dtd.e=1046-01-01T23:59:59Z
+o.rf.rf.date_dtd.g=+5YEARS
+o.rf.rf.date_dtd.ib=upper
+o.rf.rf.date_dtd.ib=edge
+o.rf.rf.date_dtd.or=all
+
+o.hi.s.sum=sum(int_id)
+o.hi.s.mean=mean(int_id)
+o.hi.s.median=median(int_id)
+o.hi.s.count=count(int_id)
+o.hi.s.sumOfSquares=sumofsquares(int_id)
+o.hi.rf=long_ld
+o.hi.rf.long_ld.st=5
+o.hi.rf.long_ld.e=30
+o.hi.rf.long_ld.g=5
+o.hi.rf.long_ld.he=true
+o.hi.rf.long_ld.ib=lower
+o.hi.rf.long_ld.or=all
+o.hi.rf=double_dd
+o.hi.rf.double_dd.st=3
+o.hi.rf.double_dd.e=39
+o.hi.rf.double_dd.g=7
+o.hi.rf.double_dd.he=true
+o.hi.rf.double_dd.ib=upper
+o.hi.rf.double_dd.ib=outer
+o.hi.rf.double_dd.or=all
+o.hi.rf=date_dtd
+o.hi.rf.date_dtd.st=1007-01-01T23:59:59Z
+o.hi.rf.date_dtd.e=1044-01-01T23:59:59Z
+o.hi.rf.date_dtd.g=+7YEARS
+o.hi.rf.date_dtd.he=true
+o.hi.rf.date_dtd.ib=lower
+o.hi.rf.date_dtd.ib=edge
+o.hi.rf.date_dtd.ib=outer
+o.hi.rf.date_dtd.or=all
+
+o.hf.s.sum=sum(float_fd)
+o.hf.s.mean=mean(float_fd)
+o.hf.s.median=median(float_fd)
+o.hf.s.count=count(float_fd)
+o.hf.s.sumOfSquares=sumofsquares(float_fd)
+o.hf.rf=long_ld
+o.hf.rf.long_ld.st=0
+o.hf.rf.long_ld.e=29
+o.hf.rf.long_ld.g=4
+o.hf.rf.long_ld.he=true
+o.hf.rf.long_ld.ib=all
+o.hf.rf.long_ld.or=all
+o.hf.rf=double_dd
+o.hf.rf.double_dd.st=4
+o.hf.rf.double_dd.e=47
+o.hf.rf.double_dd.g=11
+o.hf.rf.double_dd.he=true
+o.hf.rf.double_dd.ib=edge
+o.hf.rf.double_dd.or=all
+o.hf.rf=date_dtd
+o.hf.rf.date_dtd.st=1004-01-01T23:59:59Z
+o.hf.rf.date_dtd.e=1046-01-01T23:59:59Z
+o.hf.rf.date_dtd.g=+5YEARS
+o.hf.rf.date_dtd.he=true
+o.hf.rf.date_dtd.ib=upper
+o.hf.rf.date_dtd.ib=edge
+o.hf.rf.date_dtd.or=all
+
+o.mi.s.sum=sum(int_id)
+o.mi.s.mean=mean(int_id)
+o.mi.s.median=median(int_id)
+o.mi.s.count=count(int_id)
+o.mi.s.sumOfSquares=sumofsquares(int_id)
+o.mi.rf=long_ld
+o.mi.rf.long_ld.st=5
+o.mi.rf.long_ld.e=30
+o.mi.rf.long_ld.g=4,2,6,3
+o.mi.rf.long_ld.ib=lower
+o.mi.rf.long_ld.or=all
+o.mi.rf=double_dd
+o.mi.rf.double_dd.st=3
+o.mi.rf.double_dd.e=39
+o.mi.rf.double_dd.g=3,1,7
+o.mi.rf.double_dd.ib=upper
+o.mi.rf.double_dd.ib=outer
+o.mi.rf.double_dd.or=all
+o.mi.rf=date_dtd
+o.mi.rf.date_dtd.st=1007-01-01T23:59:59Z
+o.mi.rf.date_dtd.e=1044-01-01T23:59:59Z
+o.mi.rf.date_dtd.g=+2YEARS,+7YEARS
+o.mi.rf.date_dtd.ib=lower
+o.mi.rf.date_dtd.ib=edge
+o.mi.rf.date_dtd.ib=outer
+o.mi.rf.date_dtd.or=all
+
+o.mf.s.sum=sum(float_fd)
+o.mf.s.mean=mean(float_fd)
+o.mf.s.median=median(float_fd)
+o.mf.s.count=count(float_fd)
+o.mf.s.sumOfSquares=sumofsquares(float_fd)
+o.mf.rf=long_ld
+o.mf.rf.long_ld.st=0
+o.mf.rf.long_ld.e=29
+o.mf.rf.long_ld.g=1,4
+o.mf.rf.long_ld.ib=all
+o.mf.rf.long_ld.or=all
+o.mf.rf=double_dd
+o.mf.rf.double_dd.st=4
+o.mf.rf.double_dd.e=47
+o.mf.rf.double_dd.g=2,3,11
+o.mf.rf.double_dd.ib=edge
+o.mf.rf.double_dd.or=all
+o.mf.rf=date_dtd
+o.mf.rf.date_dtd.st=1004-01-01T23:59:59Z
+o.mf.rf.date_dtd.e=1046-01-01T23:59:59Z
+o.mf.rf.date_dtd.g=+4YEARS,+5YEARS
+o.mf.rf.date_dtd.ib=upper
+o.mf.rf.date_dtd.ib=edge
+o.mf.rf.date_dtd.or=all
+
+o.pf.s.mean=mean(float_fd)
+o.pf.hs.min=min(date_dtd)
+o.pf.hs.max=max(date_dtd)
+o.pf.hs.gap=const_str(+5YEARS)
+o.pf.rf=date_dtd
+o.pf.rf.date_dtd.st=result(min)
+o.pf.rf.date_dtd.e=result(max)
+o.pf.rf.date_dtd.g=result(gap)
diff --git solr/core/src/test-files/analytics/requestXMLFiles/expressions.xml solr/core/src/test-files/analytics/requestXMLFiles/expressions.xml
new file mode 100644
index 0000000..511805d
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/expressions.xml
@@ -0,0 +1,285 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>Add Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>unique</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>add(sum(int(int_id)),unique(long(long_ld)))</expression>
+ 			<name>add sum and unique</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>add(mean(int(int_id)),count(long(long_ld)),median(int(int_id)))</expression>
+ 			<name>add mean and count and median</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Multiply Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>unique</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mult(sum(int(int_id)),unique(long(long_ld)))</expression>
+ 			<name>multiply sum and unique</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mult(mean(int(int_id)),count(long(long_ld)),median(int(int_id)))</expression>
+ 			<name>multiply mean and count and median</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Divide Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>unique</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>div(sum(int(int_id)),unique(long(long_ld)))</expression>
+ 			<name>divide sum by unique</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>div(mean(int(int_id)),count(long(long_ld)))</expression>
+ 			<name>divide mean by count</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Power Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>unique</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>pow(sum(int(int_id)),unique(long(long_ld)))</expression>
+ 			<name>power sum by unique</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>pow(mean(int(int_id)),count(long(long_ld)))</expression>
+ 			<name>power mean by count</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Negate Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>neg(sum(int(int_id)))</expression>
+ 			<name>negate of sum</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>neg(count(long(long_ld)))</expression>
+ 			<name>negate of count</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Const Num Request</name>
+ 		
+ 		<statistic>
+ 			<expression>const_num(8)</expression>
+ 			<name>constant 8</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_num(10)</expression>
+ 			<name>constant 10</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Date Math Request</name>
+ 		
+ 		<statistic>
+ 			<expression>median(date(date_dtd))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_str(+2YEARS)</expression>
+ 			<name>constant str median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>date_math(median(date(date_dtd)),const_str(+2YEARS))</expression>
+ 			<name>date math median</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(date(date_dtd))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_str(+2MONTHS)</expression>
+ 			<name>constant str max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>date_math(max(date(date_dtd)),const_str(+2MONTHS))</expression>
+ 			<name>date math max</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Constant Date Request</name>
+ 		
+ 		<statistic>
+ 			<expression>const_str(1800-12-31T23:59:59Z)</expression>
+ 			<name>const str 1</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_date(1800-12-31T23:59:59Z)</expression>
+ 			<name>const date 1</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_str(1804-06-30T23:59:59Z)</expression>
+ 			<name>const str 2</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_date(1804-06-30T23:59:59Z)</expression>
+ 			<name>const date 2</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Constant String Request</name>
+ 		
+ 		<statistic>
+ 			<expression>const_str(this is the first)</expression>
+ 			<name>const str 1</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_str(this is the second)</expression>
+ 			<name>const str 2</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>const_str(this is the third)</expression>
+ 			<name>const str 3</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Concatenate Request</name>
+ 		
+ 		<statistic>
+ 			<expression>const_str(this is the first)</expression>
+ 			<name>const str min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(str(string_sd))</expression>
+ 			<name>min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>concat(const_str(this is the first),min(str(string_sd)))</expression>
+ 			<name>concat const and min</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>const_str(this is the second)</expression>
+ 			<name>const str max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(str(string_sd))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>concat(const_str(this is the second),max(str(string_sd)))</expression>
+ 			<name>concat const and max</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Reverse Request</name>
+ 		
+ 		<statistic>
+ 			<expression>min(str(string_sd))</expression>
+ 			<name>min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>rev(min(str(string_sd)))</expression>
+ 			<name>reverse min</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(str(string_sd))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>rev(max(str(string_sd)))</expression>
+ 			<name>reverse max</name>
+ 		</statistic>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope> 
diff --git solr/core/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml solr/core/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml
new file mode 100644
index 0000000..5d7bf07
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/fieldFacetExtras.xml
@@ -0,0 +1,101 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>sort request</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,int(int_id))</expression>
+ 			<name>perc_20</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 			<sortSpecification>
+ 				<statName>mean</statName>
+ 				<direction>asc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>float_fd</field>
+ 			<sortSpecification>
+ 				<statName>median</statName>
+ 				<direction>desc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>double_dd</field>
+ 			<sortSpecification>
+ 				<statName>count</statName>
+ 				<direction>asc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 			<sortSpecification>
+ 				<statName>perc_20</statName>
+ 				<direction>desc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>limit request</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,int(int_id))</expression>
+ 			<name>perc_20</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet limit="5">
+ 			<field>long_ld</field>
+ 			<sortSpecification>
+ 				<statName>mean</statName>
+ 				<direction>asc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet limit="3">
+ 			<field>float_fd</field>
+ 			<sortSpecification>
+ 				<statName>median</statName>
+ 				<direction>desc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet limit="7">
+ 			<field>double_dd</field>
+ 			<sortSpecification>
+ 				<statName>count</statName>
+ 				<direction>asc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 		<fieldFacet limit="1">
+ 			<field>string_sd</field>
+ 			<sortSpecification>
+ 				<statName>perc_20</statName>
+ 				<direction>desc</direction>
+ 			</sortSpecification>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope>
diff --git solr/core/src/test-files/analytics/requestXMLFiles/fieldFacets.xml solr/core/src/test-files/analytics/requestXMLFiles/fieldFacets.xml
new file mode 100644
index 0000000..53dd2d3
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/fieldFacets.xml
@@ -0,0 +1,496 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>sum</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>mean</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>sumOfSquares</name>
+ 		
+ 		<statistic>
+ 			<expression>sumofsquares(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>stddev</name>
+ 		
+ 		<statistic>
+ 			<expression>stddev(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>median</name>
+ 		
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>perc_20 numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(20,int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>perc_20</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(20,str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>perc_60 numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(60,int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>perc_60</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(60,str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>min numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>min(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>min</name>
+ 		
+ 		<statistic>
+ 			<expression>min(str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>max numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>max(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>max</name>
+ 		
+ 		<statistic>
+ 			<expression>max(str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>count numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>count</name>
+ 		
+ 		<statistic>
+ 			<expression>count(str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>unique numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>unique(int(int_id))</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(float(float_fd))</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(double(double_dd))</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>unique</name>
+ 		
+ 		<statistic>
+ 			<expression>unique(str(string_sd))</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(date(date_dtd))</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>missing numeric</name>
+ 		
+ 		<statistic>
+ 			<expression>missing(int{int_id})</expression>
+ 			<name>int</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(long{long_ld})</expression>
+ 			<name>long</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(float{float_fd})</expression>
+ 			<name>float</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(double{double_dd})</expression>
+ 			<name>double</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>missing</name>
+ 		
+ 		<statistic>
+ 			<expression>missing(str{string_sd})</expression>
+ 			<name>str</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(date{date_dtd})</expression>
+ 			<name>date</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>int_id</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>long_ld</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>multivalued</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>long_ldm</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>string_sdm</field>
+ 		</fieldFacet>
+ 		<fieldFacet>
+ 			<field>date_dtdm</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>missing facet</name>
+
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<fieldFacet>
+ 			<field>date_dtd</field>
+ 		</fieldFacet>
+ 		<fieldFacet showMissing="true">
+ 			<field>string_sd</field>
+ 		</fieldFacet>
+ 		<fieldFacet showMissing="true">
+ 			<field>date_dtdm</field>
+ 		</fieldFacet>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope>
diff --git solr/core/src/test-files/analytics/requestXMLFiles/functions.xml solr/core/src/test-files/analytics/requestXMLFiles/functions.xml
new file mode 100644
index 0000000..40f5ada
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/functions.xml
@@ -0,0 +1,246 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>Add Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(add(int(int_id),float(float_fd)))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(add_if_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(add(long(long_ld),double(double_dd),float(float_fd)))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(add_ldf_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Multiply Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(mult(int(int_id),float(float_fd)))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(mult_if_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(mult(long(long_ld),double(double_dd),float(float_fd)))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(mult_ldf_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Divide Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(div(int(int_id),float(float_fd)))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(div_if_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(div(long(long_ld),double(double_dd)))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(double(div_ld_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Power Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(pow(int(int_id),float(float_fd))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(pow_if_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(pow(long(long_ld),double(double_dd)))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(double(pow_ld_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Negate Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(neg(int(int_id)))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(neg_i_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(neg(long(long_ld)))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(neg_l_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Const Num Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(const_num(8))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(const_8_dd))</expression>
+ 			<name>sum calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(const_num(10))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(const_10_dd))</expression>
+ 			<name>mean calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Date Math Request</name>
+ 		
+ 		<statistic>
+ 			<expression>median(date_math(date(date_dtd),const_str(+2YEARS)))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(date(dm_2y_dtd))</expression>
+ 			<name>median calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(date_math(date(date_dtd),const_str(+2MONTHS)))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(date(dm_2m_dtd))</expression>
+ 			<name>max calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Constant Date Request</name>
+ 		
+ 		<statistic>
+ 			<expression>median(const_date(1800-06-30T23:59:59Z))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(date(const_00_dtd))</expression>
+ 			<name>median calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(const_date(1804-06-30T23:59:59Z))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(date(const_04_dtd))</expression>
+ 			<name>max calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Constant String Request</name>
+ 		
+ 		<statistic>
+ 			<expression>min(const_str(this is the first))</expression>
+ 			<name>min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(str(const_first_sd))</expression>
+ 			<name>min calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(const_str(this is the second))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(str(const_second_sd))</expression>
+ 			<name>max calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Concatenate Request</name>
+ 		
+ 		<statistic>
+ 			<expression>min(concat(const_str(this is the first),str(string_sd)))</expression>
+ 			<name>min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(str(concat_first_sd))</expression>
+ 			<name>min calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(concat(const_str(this is the second),str(string_sd)))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(str(concat_second_sd))</expression>
+ 			<name>max calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Reverse Request</name>
+ 		
+ 		<statistic>
+ 			<expression>min(rev(str(string_sd)))</expression>
+ 			<name>min</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(str(rev_sd))</expression>
+ 			<name>min calced</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>max(rev(str(string_sd)))</expression>
+ 			<name>max</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(str(rev_sd))</expression>
+ 			<name>max calced</name>
+ 		</statistic>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope> 
diff --git solr/core/src/test-files/analytics/requestXMLFiles/noFacets.xml solr/core/src/test-files/analytics/requestXMLFiles/noFacets.xml
new file mode 100644
index 0000000..ce00d38
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/noFacets.xml
@@ -0,0 +1,310 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>Sum Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>SumOfSquares Request</name>
+ 		
+ 		<statistic>
+ 			<expression>sumofsquares(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Mean Request</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>mean(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Stddev Request</name>
+ 		
+ 		<statistic>
+ 			<expression>stddev(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>stddev(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Median Request</name>
+ 		
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Perc 20 Request</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(20,int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(20,str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Perc 60 Request</name>
+ 		
+ 		<statistic>
+ 			<expression>perc(60,int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>perc(60,str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Min Request</name>
+ 		
+ 		<statistic>
+ 			<expression>min(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>min(str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Max Request</name>
+ 		
+ 		<statistic>
+ 			<expression>max(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>max(str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Unique Request</name>
+ 		
+ 		<statistic>
+ 			<expression>unique(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>unique(str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Count Request</name>
+ 		
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(long(long_ld))</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(float(float_fd))</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(double(double_dd))</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(date(date_dtd))</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(str(string_sd))</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+ 	
+ 	<analyticsRequest>
+ 		<name>Missing Request</name>
+ 		 		
+ 		<statistic>
+ 			<expression>missing(int{int_id})</expression>
+ 			<name>int_id</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(long{long_ld})</expression>
+ 			<name>long_ld</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(float{float_fd})</expression>
+ 			<name>float_fd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(double{double_dd})</expression>
+ 			<name>double_dd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(date{date_dtd})</expression>
+ 			<name>date_dtd</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>missing(str{string_sd})</expression>
+ 			<name>string_sd</name>
+ 		</statistic>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope> 
diff --git solr/core/src/test-files/analytics/requestXMLFiles/queryFacets.xml solr/core/src/test-files/analytics/requestXMLFiles/queryFacets.xml
new file mode 100644
index 0000000..73f615b
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/queryFacets.xml
@@ -0,0 +1,94 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>int request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>perc(8,int(int_id))</expression>
+ 			<name>perc_8</name>
+ 		</statistic>
+ 		
+ 		<queryFacet>
+ 			<name>float1</name>
+ 			<query>float_fd:[* TO 50]</query>
+ 		</queryFacet>
+ 		<queryFacet>
+ 			<name>float2</name>
+ 			<query>float_fd:[* TO 30]</query>
+ 		</queryFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>long request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(long(long_ld))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(long(long_ld))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>median(long(long_ld))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>perc(8,long(long_ld))</expression>
+ 			<name>perc_8</name>
+ 		</statistic>
+ 		
+ 		<queryFacet>
+ 			<name>string</name>
+ 			<query>string_sd:abc1</query>
+ 			<query>string_sd:abc2</query>
+ 		</queryFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>float request</name>
+ 		
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		
+ 		<statistic>
+ 			<expression>perc(8,float(float_fd))</expression>
+ 			<name>perc_8</name>
+ 		</statistic>
+ 		
+ 		<queryFacet>
+ 			<name>long and double</name>
+ 			<query>long_ld:[20 TO *]</query>
+ 			<query>long_ld:[30 TO *]</query>
+ 			<query>double_dd:[* TO 50]</query>
+ 		</queryFacet>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope>
diff --git solr/core/src/test-files/analytics/requestXMLFiles/rangeFacets.xml solr/core/src/test-files/analytics/requestXMLFiles/rangeFacets.xml
new file mode 100644
index 0000000..3434d2e
--- /dev/null
+++ solr/core/src/test-files/analytics/requestXMLFiles/rangeFacets.xml
@@ -0,0 +1,319 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<analyticsRequestEnvelope stats="true" olap="true">
+ 	<analyticsRequest>
+ 		<name>regular int</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(int(int_id))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="false">
+ 			<field>long_ld</field>
+ 			<start>5</start>
+ 			<end>30</end>
+ 			<gap>5</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>double_dd</field>
+ 			<start>3</start>
+ 			<end>39</end>
+ 			<gap>7</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>date_dtd</field>
+ 			<start>1007-01-01T23:59:59Z</start>
+ 			<end>1044-01-01T23:59:59Z</end>
+ 			<gap>+7YEARS</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>regular float</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(float(float_fd))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(float(float_fd))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="false">
+ 			<field>long_ld</field>
+ 			<start>0</start>
+ 			<end>29</end>
+ 			<gap>4</gap>
+ 			<includeBoundary>all</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>double_dd</field>
+ 			<start>4</start>
+ 			<end>47</end>
+ 			<gap>11</gap>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>date_dtd</field>
+ 			<start>1004-01-01T23:59:59Z</start>
+ 			<end>1046-01-01T23:59:59Z</end>
+ 			<gap>+5YEARS</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>hardend int</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(int(int_id))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="true">
+ 			<field>long_ld</field>
+ 			<start>5</start>
+ 			<end>30</end>
+ 			<gap>5</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="true">
+ 			<field>double_dd</field>
+ 			<start>3</start>
+ 			<end>39</end>
+ 			<gap>7</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="true">
+ 			<field>date_dtd</field>
+ 			<start>1007-01-01T23:59:59Z</start>
+ 			<end>1044-01-01T23:59:59Z</end>
+ 			<gap>+7YEARS</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>hardend float</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(float(float_fd))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(float(float_fd))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="true">
+ 			<field>long_ld</field>
+ 			<start>0</start>
+ 			<end>29</end>
+ 			<gap>4</gap>
+ 			<includeBoundary>all</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="true">
+ 			<field>double_dd</field>
+ 			<start>4</start>
+ 			<end>47</end>
+ 			<gap>11</gap>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="true">
+ 			<field>date_dtd</field>
+ 			<start>1004-01-01T23:59:59Z</start>
+ 			<end>1046-01-01T23:59:59Z</end>
+ 			<gap>+5YEARS</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>multigap int</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(int(int_id))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(int(int_id))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(int(int_id))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(int(int_id))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(int(int_id))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="false">
+ 			<field>long_ld</field>
+ 			<start>5</start>
+ 			<end>30</end>
+ 			<gap>4</gap>
+ 			<gap>2</gap>
+ 			<gap>6</gap>
+ 			<gap>3</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>double_dd</field>
+ 			<start>3</start>
+ 			<end>39</end>
+ 			<gap>3</gap>
+ 			<gap>1</gap>
+ 			<gap>7</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>date_dtd</field>
+ 			<start>1007-01-01T23:59:59Z</start>
+ 			<end>1044-01-01T23:59:59Z</end>
+ 			<gap>+2YEARS</gap>
+ 			<gap>+7YEARS</gap>
+ 			<includeBoundary>lower</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<includeBoundary>outer</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+ 	<analyticsRequest>
+ 		<name>multigap float</name>
+ 		
+ 		<statistic>
+ 			<expression>mean(float(float_fd))</expression>
+ 			<name>mean</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sum(float(float_fd))</expression>
+ 			<name>sum</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>median(float(float_fd))</expression>
+ 			<name>median</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>count(float(float_fd))</expression>
+ 			<name>count</name>
+ 		</statistic>
+ 		<statistic>
+ 			<expression>sumofsquares(float(float_fd))</expression>
+ 			<name>sumOfSquares</name>
+ 		</statistic>
+ 		
+ 		<rangeFacet hardend="false">
+ 			<field>long_ld</field>
+ 			<start>0</start>
+ 			<end>29</end>
+ 			<gap>1</gap>
+ 			<gap>4</gap>
+ 			<includeBoundary>all</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>double_dd</field>
+ 			<start>4</start>
+ 			<end>47</end>
+ 			<gap>2</gap>
+ 			<gap>3</gap>
+ 			<gap>11</gap>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 		<rangeFacet hardend="false">
+ 			<field>date_dtd</field>
+ 			<start>1004-01-01T23:59:59Z</start>
+ 			<end>1046-01-01T23:59:59Z</end>
+ 			<gap>+4YEARS</gap>
+ 			<gap>+5YEARS</gap>
+ 			<includeBoundary>upper</includeBoundary>
+ 			<includeBoundary>edge</includeBoundary>
+ 			<otherRange>all</otherRange>
+ 		</rangeFacet>
+ 	</analyticsRequest>
+</analyticsRequestEnvelope>
diff --git solr/core/src/test-files/solr/collection1/conf/schema-analytics.xml solr/core/src/test-files/solr/collection1/conf/schema-analytics.xml
new file mode 100644
index 0000000..3c5713d
--- /dev/null
+++ solr/core/src/test-files/solr/collection1/conf/schema-analytics.xml
@@ -0,0 +1,94 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- The Solr schema file. This file should be named "schema.xml" and
+     should be located where the classloader for the Solr webapp can find it.
+
+     This schema is used for testing, and as such has everything and the
+     kitchen sink thrown in. See example/solr/conf/schema.xml for a
+     more concise example.
+
+  -->
+
+<schema name="schema-docValues" version="1.5">
+  <types>
+
+    <!-- field type definitions... note that the "name" attribute is
+         just a label to be used by field definitions.  The "class"
+         attribute and any other attributes determine the real type and
+         behavior of the fieldtype.
+      -->
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't sort correctly or support range queries.)
+         These are provided more for backward compatability, allowing one
+         to create a schema that matches an existing lucene index.
+    -->
+    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="float" class="solr.TrieFloatField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="long" class="solr.TrieLongField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="double" class="solr.TrieDoubleField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
+         seconds part (.999) is optional.
+      -->
+    <fieldtype name="date" class="solr.TrieDateField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+
+    <fieldtype name="boolean" class="solr.BoolField" />
+    <fieldtype name="string" class="solr.StrField" />
+
+    <fieldType name="uuid" class="solr.UUIDField" />
+
+  </types>
+
+
+  <fields>
+
+    <field name="id" type="string" required="true" />
+
+    <field name="floatdv" type="float" indexed="false" stored="false" docValues="true" default="1" />
+    <field name="intdv" type="int" indexed="false" stored="false" docValues="true" default="2" />
+    <field name="doubledv" type="double" indexed="false" stored="false" docValues="true" default="3" />
+    <field name="longdv" type="long" indexed="false" stored="false" docValues="true" default="4" />
+    <field name="datedv" type="date" indexed="false" stored="false" docValues="true" default="1995-12-31T23:59:59.999Z" />
+
+    <field name="stringdv" type="string" indexed="false" stored="false" docValues="true" default="solr" />
+    <field name="stringdvm" type="string" indexed="false" stored="false" docValues="true" default="solr" multiValued="true" />
+    
+    <dynamicField name="*_i" type="int" indexed="true" stored="true" docValues="false" multiValued="false" />
+    <dynamicField name="*_id" type="int" indexed="true" stored="true" docValues="true" multiValued="false" />
+    <dynamicField name="*_idm" type="int" indexed="true" stored="true" docValues="true" multiValued="true" />
+    <dynamicField name="*_l" type="long" indexed="true" stored="true" docValues="false" multiValued="false" />
+    <dynamicField name="*_ld" type="long" indexed="true" stored="true" docValues="true" multiValued="false" />
+    <dynamicField name="*_ldm" type="long" indexed="true" stored="true" docValues="true" multiValued="true" />
+    <dynamicField name="*_f" type="float" indexed="true" stored="true" docValues="false" multiValued="false" />
+    <dynamicField name="*_fd" type="float" indexed="true" stored="true" docValues="true" multiValued="false" />
+    <dynamicField name="*_fdm" type="float" indexed="true" stored="true" docValues="true" multiValued="true" />
+    <dynamicField name="*_d" type="double" indexed="true" stored="true" docValues="false" multiValued="false" />
+    <dynamicField name="*_dd" type="double" indexed="true" stored="true" docValues="true" multiValued="false" />
+    <dynamicField name="*_ddm" type="double" indexed="true" stored="true" docValues="true" multiValued="true" />
+    <dynamicField name="*_dt" type="date" indexed="true" stored="true" docValues="false" multiValued="false" />
+    <dynamicField name="*_dtd" type="date" indexed="true" stored="true" docValues="true" multiValued="false" />
+    <dynamicField name="*_dtdm" type="date" indexed="true" stored="true" docValues="true" multiValued="true" />
+    <dynamicField name="*_s" type="string" indexed="true" stored="true" docValues="false" multiValued="false"/>
+    <dynamicField name="*_sd" type="string" indexed="true" stored="true" docValues="true" multiValued="false"/>
+    <dynamicField name="*_sdm" type="string" indexed="true" stored="true" docValues="true" multiValued="true" />
+  </fields>
+
+  <uniqueKey>id</uniqueKey>
+
+</schema>
diff --git solr/core/src/test-files/solr/collection1/conf/schema-trie.xml solr/core/src/test-files/solr/collection1/conf/schema-trie.xml
index 0f879b0..bb2b354 100644
--- solr/core/src/test-files/solr/collection1/conf/schema-trie.xml
+++ solr/core/src/test-files/solr/collection1/conf/schema-trie.xml
@@ -219,7 +219,7 @@
              See the Java Regular Expression documentation for more
              infomation on pattern and replacement string syntax.
 
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/core/src/test-files/solr/collection1/conf/schema11.xml solr/core/src/test-files/solr/collection1/conf/schema11.xml
index 6bf7d62..92b352e 100755
--- solr/core/src/test-files/solr/collection1/conf/schema11.xml
+++ solr/core/src/test-files/solr/collection1/conf/schema11.xml
@@ -214,7 +214,7 @@
              See the Java Regular Expression documentation for more
              infomation on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/core/src/test/org/apache/solr/TestDistributedSearch.java solr/core/src/test/org/apache/solr/TestDistributedSearch.java
index d0e80dd..42a6542 100644
--- solr/core/src/test/org/apache/solr/TestDistributedSearch.java
+++ solr/core/src/test/org/apache/solr/TestDistributedSearch.java
@@ -362,18 +362,7 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
     query("q","*:*", "sort",i1+" desc", "stats", "true", "stats.field", tdate_a);
     query("q","*:*", "sort",i1+" desc", "stats", "true", "stats.field", tdate_b);
 
-    query("q","*:*", "sort",i1+" desc", "stats", "true", 
-          "fq", "{!tag=nothing}-*:*",
-          "stats.field", "{!key=special_key ex=nothing}stats_dt");
-    query("q","*:*", "sort",i1+" desc", "stats", "true", 
-          "f.stats_dt.stats.calcdistinct", "true",
-          "stats.field", "{!key=special_key}stats_dt");
-    query("q","*:*", "sort",i1+" desc", "stats", "true", 
-          "f.stats_dt.stats.calcdistinct", "true",
-          "fq", "{!tag=xxx}id:[3 TO 9]",
-          "stats.field", "{!key=special_key}stats_dt",
-          "stats.field", "{!ex=xxx}stats_dt");
-
+    handle.put("stats_fields", UNORDERED);
     query("q","*:*", "sort",i1+" desc", "stats", "true",
           "stats.field", "stats_dt",
           "stats.field", i1,
diff --git solr/core/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java solr/core/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java
new file mode 100644
index 0000000..2089a79
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/AbstractAnalyticsStatsTest.java
@@ -0,0 +1,217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics;
+
+import java.io.ByteArrayInputStream;
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Scanner;
+
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
+import javax.xml.parsers.ParserConfigurationException;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.lucene.util.IOUtils;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.analytics.util.MedianCalculator;
+import org.apache.solr.analytics.util.PercentileCalculator;
+import org.apache.solr.request.SolrQueryRequest;
+import org.w3c.dom.Document;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.ObjectArrays;
+
+public class AbstractAnalyticsStatsTest extends SolrTestCaseJ4 {
+  
+  protected static final String[] BASEPARMS = new String[]{ "q", "*:*", "indent", "true", "olap", "true", "rows", "0" };
+  protected static final HashMap<String,Object> defaults = new HashMap<>();
+
+  public static enum VAL_TYPE {
+    INTEGER("int"),
+    LONG("long"),
+    FLOAT("float"),
+    DOUBLE("double"),
+    STRING("str"),
+    DATE("date");
+
+    private VAL_TYPE (final String text) {
+      this.text = text;
+    }
+
+    private final String text;
+
+    @Override
+    public String toString() {
+      return text;
+    }
+  }
+
+  static private Document doc;
+  static private XPathFactory xPathFact =  XPathFactory.newInstance();
+
+  static private String rawResponse;
+
+  public static void setResponse(String response) throws ParserConfigurationException, IOException, SAXException {
+    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
+    factory.setNamespaceAware(true); // never forget this!
+    DocumentBuilder builder = factory.newDocumentBuilder();
+    doc = builder.parse(new InputSource(new ByteArrayInputStream(response.getBytes(StandardCharsets.UTF_8))));
+    xPathFact = XPathFactory.newInstance();
+    rawResponse = response;
+  }
+
+  protected String getRawResponse() {
+    return rawResponse;
+  }
+
+  public Object getStatResult(String section, String name, VAL_TYPE type) throws XPathExpressionException {
+
+    // Construct the XPath expression. The form better not change or all these will fail.
+    StringBuilder sb = new StringBuilder("/response/lst[@name='stats']/lst[@name='").append(section).append("']");
+
+    // This is a little fragile in that it demands the elements have the same name as type, i.e. when looking for a
+    // VAL_TYPE.DOUBLE, the element in question is <double name="blah">47.0</double>.
+    sb.append("/").append(type.toString()).append("[@name='").append(name).append("']");
+    String val = xPathFact.newXPath().compile(sb.toString()).evaluate(doc, XPathConstants.STRING).toString();
+    try {
+      switch (type) {
+        case INTEGER: return Integer.parseInt(val);
+        case DOUBLE:  return Double.parseDouble(val);
+        case FLOAT:   return Float.parseFloat(val);
+        case LONG:    return Long.parseLong(val);
+        case STRING:  assertTrue(rawResponse, val != null && val.length() > 0 ); return val;
+        case DATE:    assertTrue(rawResponse, val != null && val.length() > 0 ); return val;
+      }
+    } catch (Exception e) {
+      e.printStackTrace();
+      fail("Caught exception in getStatResult, xPath = " + sb.toString() + " \nraw data: " + rawResponse);
+    }
+    fail("Unknown type used in getStatResult");
+    return null; // Really can't get here, but the compiler thinks we can!
+  }
+
+
+  public <T extends Number & Comparable<T>> Double calculateNumberStat(ArrayList<T> list, String stat) {
+    Double result;
+    if (stat.equals("median")) {
+      result = MedianCalculator.getMedian(list);
+    } else if (stat.equals("mean")) {
+      double d = 0;
+      for (T element : list) {
+        d += element.doubleValue();
+      }
+      result = Double.valueOf(d/list.size());
+    } else if (stat.equals("sum")) {
+      double d = 0;
+      for (T element : list) {
+        d += element.doubleValue();
+      }
+      result = Double.valueOf(d);
+    } else if (stat.equals("sumOfSquares")) {
+      double d = 0;
+      for (T element : list) {
+        d += element.doubleValue()*element.doubleValue();
+      }
+      result = Double.valueOf(d);
+    } else if (stat.equals("stddev")) {
+      double sum = 0;
+      double sumSquares = 0;
+      for (T element : list) {
+        sum += element.doubleValue();
+        sumSquares += element.doubleValue()*element.doubleValue();
+      }
+      result = Math.sqrt(sumSquares/list.size()-sum*sum/(list.size()*list.size()));
+    } else {
+      throw new IllegalArgumentException();
+    }
+    return result;
+  }
+
+  public <T extends Comparable<T>> Object calculateStat(ArrayList<T> list, String stat) {
+    Object result;
+    if (stat.contains("perc_")) {
+      double[] perc = new double[]{Double.parseDouble(stat.substring(5))/100};
+      result = PercentileCalculator.getPercentiles(list, perc).get(0);
+    } else if (stat.equals("count")) {
+      result = Long.valueOf(list.size());
+    } else if (stat.equals("unique")) {
+      HashSet<T> set = new HashSet<>();
+      set.addAll(list);
+      result = Long.valueOf((long)set.size());
+    } else if (stat.equals("max")) {
+      Collections.sort(list);
+      result = list.get(list.size()-1);
+    } else if (stat.equals("min")) {
+      Collections.sort(list);
+      result = list.get(0);
+    } else {
+      result = null;
+    }
+    return result;
+  }
+
+  @SuppressWarnings("unchecked")
+  public <T extends Comparable<T>> Long calculateMissing(ArrayList<T> list, String type) {
+    T def = (T)defaults.get(type);
+    long miss = 0;
+    for (T element : list) {
+      if (element.compareTo(def)==0) {
+        miss++;
+      }
+    }
+    return Long.valueOf(miss);
+  }
+  
+  public static SolrQueryRequest request(String...args){
+    return SolrTestCaseJ4.req( ObjectArrays.concat(BASEPARMS, args,String.class) );
+  }
+
+  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
+    InputStream in = clazz.getResourceAsStream(fileName);
+    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
+    Scanner file = new Scanner(in, "UTF-8");
+    try { 
+      ArrayList<String> strList = new ArrayList<>();
+      while (file.hasNextLine()) {
+        String line = file.nextLine();
+        line = line.trim();
+        if( StringUtils.isBlank(line) || line.startsWith("#")){
+          continue;
+        }
+        String[] param = line.split("=");
+        strList.add(param[0]);
+        strList.add(param[1]);
+      }
+      return strList.toArray(new String[0]);
+    } finally {
+      IOUtils.closeWhileHandlingException(file, in);
+    }
+  }
+  
+}
diff --git solr/core/src/test/org/apache/solr/analytics/NoFacetTest.java solr/core/src/test/org/apache/solr/analytics/NoFacetTest.java
new file mode 100644
index 0000000..f217150
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/NoFacetTest.java
@@ -0,0 +1,480 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics;
+
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class NoFacetTest extends AbstractAnalyticsStatsTest {
+  static String fileName = "/analytics/requestFiles/noFacets.txt";
+
+  static public final int INT = 71;
+  static public final int LONG = 36;
+  static public final int FLOAT = 93;
+  static public final int DOUBLE = 49;
+  static public final int DATE = 12;
+  static public final int STRING = 28;
+  static public final int NUM_LOOPS = 100;
+  
+  //INT
+  static ArrayList<Integer> intTestStart; 
+  static long intMissing = 0;
+  
+  //LONG
+  static ArrayList<Long> longTestStart; 
+  static long longMissing = 0;
+  
+  //FLOAT
+  static ArrayList<Float> floatTestStart; 
+  static long floatMissing = 0;
+  
+  //DOUBLE
+  static ArrayList<Double> doubleTestStart; 
+  static long doubleMissing = 0;
+  
+  //DATE
+  static ArrayList<String> dateTestStart; 
+  static long dateMissing = 0;
+  
+  //STR
+  static ArrayList<String> stringTestStart; 
+  static long stringMissing = 0;
+  
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+    defaults.put("int_id", new Integer(0));
+    defaults.put("long_ld", new Long(0));
+    defaults.put("float_fd", new Float(0));
+    defaults.put("double_dd", new Double(0));
+    defaults.put("date_dtd", "1800-12-31T23:59:59Z");
+    defaults.put("string_sd", "str0");
+    
+    intTestStart = new ArrayList<>();
+    longTestStart = new ArrayList<>();
+    floatTestStart = new ArrayList<>();
+    doubleTestStart = new ArrayList<>();
+    dateTestStart = new ArrayList<>();
+    stringTestStart = new ArrayList<>();
+    
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT;
+      long l = j%LONG;
+      float f = j%FLOAT;
+      double d = j%DOUBLE;
+      String dt = (1800+j%DATE) + "-12-31T23:59:59Z";
+      String s = "str" + (j%STRING);
+      List<String> fields = new ArrayList<>();
+      fields.add("id"); fields.add("1000"+j);
+      
+      if( i != 0 ){
+        fields.add("int_id"); fields.add("" + i);
+        intTestStart.add(i);
+      } else intMissing++;
+      
+      if( l != 0l ){
+        fields.add("long_ld"); fields.add("" + l);
+        longTestStart.add(l);
+      } else longMissing++;
+      
+      if( f != 0.0f ){
+        fields.add("float_fd"); fields.add("" + f);
+        floatTestStart.add(f);
+      } else floatMissing++;
+      
+      if( d != 0.0d ){
+        fields.add("double_dd"); fields.add("" + d);
+        doubleTestStart.add(d);
+      } else doubleMissing++;
+      
+      if( (j%DATE) != 0 ){
+        fields.add("date_dtd"); fields.add(dt);
+        dateTestStart.add(dt);
+      } else dateMissing++;
+      
+      if( (j%STRING) != 0 ){
+        fields.add("string_sd"); fields.add(s);
+        stringTestStart.add(s);
+      } else stringMissing++;
+      
+      fields.add("int_i"); fields.add("" + i);
+      fields.add("long_l"); fields.add("" + l);
+      fields.add("float_f"); fields.add("" + f);
+      fields.add("double_d"); fields.add("" + d);
+      
+      assertU(adoc(fields.toArray(new String[0])));
+      
+      
+      if (usually()) {
+        assertU(commit());  // to have several segments
+      }
+    }
+    
+    assertU(commit()); 
+    
+    //Sort ascending tests
+    setResponse(h.query(request(fileToStringArr(NoFacetTest.class, fileName))));
+  }
+      
+  @Test
+  public void sumTest() throws Exception {
+    //Int
+    Double intResult = (Double)getStatResult("sr", "int_id", VAL_TYPE.DOUBLE);
+    Double intTest = (Double)calculateNumberStat(intTestStart, "sum");
+    assertEquals(getRawResponse(), intResult,intTest);
+    
+    //Long
+    Double longResult = (Double)getStatResult("sr", "long_ld", VAL_TYPE.DOUBLE);
+    Double longTest = (Double)calculateNumberStat(longTestStart, "sum");
+    assertEquals(getRawResponse(), longResult,longTest);
+    
+    //Float
+    Double floatResult = (Double)getStatResult("sr", "float_fd", VAL_TYPE.DOUBLE);
+    Double floatTest = (Double)calculateNumberStat(floatTestStart, "sum");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+    
+    //Double
+    Double doubleResult = (Double)getStatResult("sr", "double_dd", VAL_TYPE.DOUBLE);
+        Double doubleTest = (Double) calculateNumberStat(doubleTestStart, "sum");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+  }
+  
+  @Test
+  public void sumOfSquaresTest() throws Exception { 
+    //Int
+    Double intResult = (Double)getStatResult("sosr", "int_id", VAL_TYPE.DOUBLE);
+    Double intTest = (Double)calculateNumberStat(intTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(), intResult,intTest);
+    
+    //Long
+    Double longResult = (Double)getStatResult("sosr", "long_ld", VAL_TYPE.DOUBLE);
+    Double longTest = (Double)calculateNumberStat(longTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(), longResult,longTest);
+    
+    //Float
+    Double floatResult = (Double)getStatResult("sosr", "float_fd", VAL_TYPE.DOUBLE);
+    Double floatTest = (Double)calculateNumberStat(floatTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+    
+    //Double
+    Double doubleResult = (Double)getStatResult("sosr", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+  }
+  
+  @Test
+  public void meanTest() throws Exception { 
+    //Int
+    Double intResult = (Double)getStatResult("mr", "int_id", VAL_TYPE.DOUBLE);
+    Double intTest = (Double)calculateNumberStat(intTestStart, "mean");
+    assertEquals(getRawResponse(), intResult,intTest);
+    
+    //Long
+    Double longResult = (Double)getStatResult("mr", "long_ld", VAL_TYPE.DOUBLE);
+    Double longTest = (Double)calculateNumberStat(longTestStart, "mean");
+    assertEquals(getRawResponse(), longResult,longTest);
+    
+    //Float
+    Double floatResult = (Double)getStatResult("mr", "float_fd", VAL_TYPE.DOUBLE);
+    Double floatTest = (Double)calculateNumberStat(floatTestStart, "mean");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+    
+    //Double
+    Double doubleResult = (Double)getStatResult("mr", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "mean");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+  }
+  
+  @Test
+  public void stddevTest() throws Exception { 
+    //Int
+    Double intResult = (Double)getStatResult("str", "int_id", VAL_TYPE.DOUBLE);
+    Double intTest = (Double)calculateNumberStat(intTestStart, "stddev");
+    assertEquals(getRawResponse(), intResult, intTest, 0.00000000001);
+    
+    //Long
+    Double longResult = (Double)getStatResult("str", "long_ld", VAL_TYPE.DOUBLE);
+    Double longTest = (Double)calculateNumberStat(longTestStart, "stddev");
+    assertEquals(getRawResponse(), longResult, longTest, 0.00000000001);
+    
+    //Float
+    Double floatResult = (Double)getStatResult("str", "float_fd", VAL_TYPE.DOUBLE);
+    Double floatTest = (Double)calculateNumberStat(floatTestStart, "stddev");
+    assertEquals(getRawResponse(), floatResult, floatTest, 0.00000000001);
+
+
+    //Double
+    Double doubleResult = (Double)getStatResult("str", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "stddev");
+    assertEquals(getRawResponse(), doubleResult, doubleTest, 0.00000000001);
+  }
+  
+  @Test
+  public void medianTest() throws Exception { 
+    //Int
+    Double intResult = (Double)getStatResult("medr", "int_id", VAL_TYPE.DOUBLE);
+    Double intTest = (Double)calculateNumberStat(intTestStart, "median");
+    assertEquals(getRawResponse(), intResult,intTest);
+    
+    //Long
+    Double longResult = (Double)getStatResult("medr", "long_ld", VAL_TYPE.DOUBLE);
+    Double longTest = (Double)calculateNumberStat(longTestStart, "median");
+    assertEquals(getRawResponse(), longResult,longTest);
+    
+    //Float
+    Double floatResult = (Double)getStatResult("medr", "float_fd", VAL_TYPE.DOUBLE);
+    Double floatTest = (Double)calculateNumberStat(floatTestStart, "median");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+    
+    //Double
+    Double doubleResult = (Double)getStatResult("medr", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateNumberStat(doubleTestStart, "median");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+  }
+  
+  @Test
+  public void perc20Test() throws Exception {
+    //Int 20
+    Integer intResult = (Integer)getStatResult("p2r", "int_id", VAL_TYPE.INTEGER);
+    Integer intTest = (Integer)calculateStat(intTestStart, "perc_20");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long 20
+    Long longResult = (Long)getStatResult("p2r", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "perc_20");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float 20
+    Float floatResult = (Float)getStatResult("p2r", "float_fd", VAL_TYPE.FLOAT);
+    Float floatTest = (Float)calculateStat(floatTestStart, "perc_20");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double 20
+    Double doubleResult = (Double)getStatResult("p2r", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateStat(doubleTestStart, "perc_20");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date 20
+    String dateResult = (String)getStatResult("p2r", "date_dtd", VAL_TYPE.DATE);
+    String dateTest = (String)calculateStat(dateTestStart, "perc_20");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String 20
+    String stringResult = (String)getStatResult("p2r", "string_sd", VAL_TYPE.STRING);
+    String stringTest = (String)calculateStat(stringTestStart, "perc_20");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }
+  
+  @Test
+  public void perc60Test() throws Exception { 
+    //Int 60
+    Integer intResult = (Integer)getStatResult("p6r", "int_id", VAL_TYPE.INTEGER);
+    Integer intTest = (Integer)calculateStat(intTestStart, "perc_60");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long 60
+    Long longResult = (Long)getStatResult("p6r", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "perc_60");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float 60
+    Float floatResult = (Float)getStatResult("p6r", "float_fd", VAL_TYPE.FLOAT);
+    Float floatTest = (Float)calculateStat(floatTestStart, "perc_60");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double 60
+    Double doubleResult = (Double)getStatResult("p6r", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateStat(doubleTestStart, "perc_60");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date 60
+    String dateResult = (String)getStatResult("p6r", "date_dtd", VAL_TYPE.DATE);
+    String dateTest = (String)calculateStat(dateTestStart, "perc_60");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String 60
+    String stringResult = (String)getStatResult("p6r", "string_sd", VAL_TYPE.STRING);
+    String stringTest = (String)calculateStat(stringTestStart, "perc_60");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }
+  
+  @Test
+  public void minTest() throws Exception { 
+    //Int
+    Integer intResult = (Integer)getStatResult("mir", "int_id", VAL_TYPE.INTEGER);
+    Integer intTest = (Integer)calculateStat(intTestStart, "min");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long
+    Long longResult = (Long)getStatResult("mir", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "min");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float
+    Float floatResult = (Float)getStatResult("mir", "float_fd", VAL_TYPE.FLOAT);
+    Float floatTest = (Float)calculateStat(floatTestStart, "min");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double
+    Double doubleResult = (Double)getStatResult("mir", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateStat(doubleTestStart, "min");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date
+    String dateResult = (String)getStatResult("mir", "date_dtd", VAL_TYPE.DATE);
+    String dateTest = (String)calculateStat(dateTestStart, "min");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String
+    String stringResult = (String)getStatResult("mir", "string_sd", VAL_TYPE.STRING);
+    String stringTest = (String)calculateStat(stringTestStart, "min");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }
+  
+  @Test
+  public void maxTest() throws Exception { 
+    //Int
+    Integer intResult = (Integer)getStatResult("mar", "int_id", VAL_TYPE.INTEGER);
+    Integer intTest = (Integer)calculateStat(intTestStart, "max");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long
+    Long longResult = (Long)getStatResult("mar", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "max");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float
+    Float floatResult = (Float)getStatResult("mar", "float_fd", VAL_TYPE.FLOAT);
+    Float floatTest = (Float)calculateStat(floatTestStart, "max");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double
+    Double doubleResult = (Double)getStatResult("mar", "double_dd", VAL_TYPE.DOUBLE);
+    Double doubleTest = (Double)calculateStat(doubleTestStart, "max");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date
+    String dateResult = (String)getStatResult("mar", "date_dtd", VAL_TYPE.DATE);
+    String dateTest = (String)calculateStat(dateTestStart, "max");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String
+    String stringResult = (String)getStatResult("mar", "string_sd", VAL_TYPE.STRING);
+    String stringTest = (String)calculateStat(stringTestStart, "max");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }
+  
+  @Test
+  public void uniqueTest() throws Exception { 
+    //Int
+    Long intResult = (Long)getStatResult("ur", "int_id", VAL_TYPE.LONG);
+    Long intTest = (Long)calculateStat(intTestStart, "unique");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long
+    Long longResult = (Long)getStatResult("ur", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "unique");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float
+    Long floatResult = (Long)getStatResult("ur", "float_fd", VAL_TYPE.LONG);
+    Long floatTest = (Long)calculateStat(floatTestStart, "unique");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double
+    Long doubleResult = (Long)getStatResult("ur", "double_dd", VAL_TYPE.LONG);
+    Long doubleTest = (Long)calculateStat(doubleTestStart, "unique");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date
+    Long dateResult = (Long)getStatResult("ur", "date_dtd", VAL_TYPE.LONG);
+    Long dateTest = (Long)calculateStat(dateTestStart, "unique");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String
+    Long stringResult = (Long)getStatResult("ur", "string_sd", VAL_TYPE.LONG);
+    Long stringTest = (Long)calculateStat(stringTestStart, "unique");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }
+  
+  @Test
+  public void countTest() throws Exception { 
+    //Int
+    Long intResult = (Long)getStatResult("cr", "int_id", VAL_TYPE.LONG);
+    Long intTest = (Long)calculateStat(intTestStart, "count");
+    assertEquals(getRawResponse(), intResult,intTest);
+
+    //Long
+    Long longResult = (Long)getStatResult("cr", "long_ld", VAL_TYPE.LONG);
+    Long longTest = (Long)calculateStat(longTestStart, "count");
+    assertEquals(getRawResponse(), longResult,longTest);
+
+    //Float
+    Long floatResult = (Long)getStatResult("cr", "float_fd", VAL_TYPE.LONG);
+    Long floatTest = (Long)calculateStat(floatTestStart, "count");
+    assertEquals(getRawResponse(), floatResult,floatTest);
+
+    //Double
+    Long doubleResult = (Long)getStatResult("cr", "double_dd", VAL_TYPE.LONG);
+    Long doubleTest = (Long)calculateStat(doubleTestStart, "count");
+    assertEquals(getRawResponse(), doubleResult,doubleTest);
+
+    //Date
+    Long dateResult = (Long)getStatResult("cr", "date_dtd", VAL_TYPE.LONG);
+    Long dateTest = (Long)calculateStat(dateTestStart, "count");
+    assertEquals(getRawResponse(), dateResult,dateTest);
+
+    //String
+    Long stringResult = (Long)getStatResult("cr", "string_sd", VAL_TYPE.LONG);
+    Long stringTest = (Long)calculateStat(stringTestStart, "count");
+    assertEquals(getRawResponse(), stringResult,stringTest);
+  }  
+    
+  @Test
+  public void missingDefaultTest() throws Exception { 
+    //Int
+    long intResult = (Long)getStatResult("misr", "int_id", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), intMissing,intResult);
+
+    //Long
+    long longResult = (Long)getStatResult("misr", "long_ld", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), longMissing,longResult);
+
+    //Float
+    long floatResult = (Long)getStatResult("misr", "float_fd", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), floatMissing,floatResult);
+
+    //Double
+    long doubleResult = (Long)getStatResult("misr", "double_dd", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), doubleMissing,doubleResult);
+
+    //Date
+    long dateResult = (Long)getStatResult("misr", "date_dtd", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), dateMissing,dateResult);
+
+    //String
+    long stringResult = (Long)getStatResult("misr", "string_sd", VAL_TYPE.LONG);
+    assertEquals(getRawResponse(), stringMissing, stringResult);
+  }
+
+}
diff --git solr/core/src/test/org/apache/solr/analytics/expression/ExpressionTest.java solr/core/src/test/org/apache/solr/analytics/expression/ExpressionTest.java
new file mode 100644
index 0000000..5cf8be1
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/expression/ExpressionTest.java
@@ -0,0 +1,251 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.expression;
+
+import com.google.common.collect.ObjectArrays;
+
+import org.apache.lucene.util.IOUtils;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.analytics.AbstractAnalyticsStatsTest;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.schema.TrieDateField;
+import org.apache.solr.util.DateMathParser;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.io.FileNotFoundException;
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.Scanner;
+
+public class ExpressionTest extends AbstractAnalyticsStatsTest {
+  private static final String fileName = "/analytics/requestFiles/expressions.txt";
+
+  private static final String[] BASEPARMS = new String[]{"q", "*:*", "indent", "true", "stats", "true", "olap", "true", "rows", "0"};
+
+  private static final int INT = 71;
+  private static final int LONG = 36;
+  private static final int FLOAT = 93;
+  private static final int DOUBLE = 49;
+  private static final int DATE = 12;
+  private static final int STRING = 28;
+  private static final int NUM_LOOPS = 100;
+
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml", "schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j % INT;
+      long l = j % LONG;
+      float f = j % FLOAT;
+      double d = j % DOUBLE;
+      String dt = (1800 + j % DATE) + "-12-31T23:59:59Z";
+      String s = "str" + (j % STRING);
+      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f,
+          "double_dd", "" + d, "date_dtd", dt, "string_sd", s));
+
+      if (usually()) {
+        assertU(commit()); // to have several segments
+      }
+    }
+
+    assertU(commit());
+
+    setResponse(h.query(request(fileToStringArr(ExpressionTest.class, fileName))));
+  }
+
+  @Test
+  public void addTest() throws Exception {
+    double sumResult = (Double) getStatResult("ar", "sum", VAL_TYPE.DOUBLE);
+    double uniqueResult = ((Long) getStatResult("ar", "unique", VAL_TYPE.LONG)).doubleValue();
+    double result = (Double) getStatResult("ar", "su", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), sumResult + uniqueResult, result, 0.0);
+
+    double meanResult = (Double) getStatResult("ar", "mean", VAL_TYPE.DOUBLE);
+    double medianResult = (Double) getStatResult("ar", "median", VAL_TYPE.DOUBLE);
+    double countResult = ((Long) getStatResult("ar", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("ar", "mcm", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), meanResult + countResult + medianResult, result, 0.0);
+  }
+
+  @Test
+  public void multiplyTest() throws Exception {
+    double sumResult = (Double) getStatResult("mr", "sum", VAL_TYPE.DOUBLE);
+    double uniqueResult = ((Long) getStatResult("mr", "unique", VAL_TYPE.LONG)).doubleValue();
+    double result = (Double) getStatResult("mr", "su", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), sumResult * uniqueResult, result, 0.0);
+
+    double meanResult = (Double) getStatResult("mr", "mean", VAL_TYPE.DOUBLE);
+    double medianResult = (Double) getStatResult("mr", "median", VAL_TYPE.DOUBLE);
+    double countResult = ((Long) getStatResult("mr", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("mr", "mcm", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), meanResult * countResult * medianResult, result, 0.0);
+  }
+
+  @Test
+  public void divideTest() throws Exception {
+    double sumResult = (Double) getStatResult("dr", "sum", VAL_TYPE.DOUBLE);
+    double uniqueResult = ((Long) getStatResult("dr", "unique", VAL_TYPE.LONG)).doubleValue();
+    double result = (Double) getStatResult("dr", "su", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), sumResult / uniqueResult, result, 0.0);
+
+    double meanResult = (Double) getStatResult("dr", "mean", VAL_TYPE.DOUBLE);
+    double countResult = ((Long) getStatResult("dr", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("dr", "mc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), meanResult / countResult, result, 0.0);
+  }
+
+  @Test
+  public void powerTest() throws Exception {
+    double sumResult = (Double) getStatResult("pr", "sum", VAL_TYPE.DOUBLE);
+    double uniqueResult = ((Long) getStatResult("pr", "unique", VAL_TYPE.LONG)).doubleValue();
+    double result = (Double) getStatResult("pr", "su", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), Math.pow(sumResult, uniqueResult), result, 0.0);
+
+    double meanResult = (Double) getStatResult("pr", "mean", VAL_TYPE.DOUBLE);
+    double countResult = ((Long) getStatResult("pr", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("pr", "mc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), Math.pow(meanResult, countResult), result, 0.0);
+  }
+
+  @Test
+  public void negateTest() throws Exception {
+    double sumResult = (Double) getStatResult("nr", "sum", VAL_TYPE.DOUBLE);
+    double result = (Double) getStatResult("nr", "s", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), -1 * sumResult, result, 0.0);
+
+    double countResult = ((Long) getStatResult("nr", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("nr", "c", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), -1 * countResult, result, 0.0);
+  }
+
+  @Test
+  public void absoluteValueTest() throws Exception {
+    double sumResult = (Double) getStatResult("avr", "sum", VAL_TYPE.DOUBLE);
+    double result = (Double) getStatResult("avr", "s", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), sumResult, result, 0.0);
+
+    double countResult = ((Long) getStatResult("avr", "count", VAL_TYPE.LONG)).doubleValue();
+    result = (Double) getStatResult("avr", "c", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), countResult, result, 0.0);
+  }
+
+  @Test
+  public void constantNumberTest() throws Exception {
+    double result = (Double) getStatResult("cnr", "c8", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), 8, result, 0.0);
+
+    result = (Double) getStatResult("cnr", "c10", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), 10, result, 0.0);
+  }
+
+  @SuppressWarnings("deprecation")
+  @Test
+  public void dateMathTest() throws Exception {
+    String math = (String) getStatResult("dmr", "cme", VAL_TYPE.STRING);
+    DateMathParser date = new DateMathParser();
+    date.setNow(TrieDateField.parseDate((String) getStatResult("dmr", "median", VAL_TYPE.DATE)));
+    String dateMath = (String) getStatResult("dmr", "dmme", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), TrieDateField.parseDate(dateMath), date.parseMath(math));
+
+    math = (String) getStatResult("dmr", "cma", VAL_TYPE.STRING);
+    date = new DateMathParser();
+    date.setNow(TrieDateField.parseDate((String) getStatResult("dmr", "max", VAL_TYPE.DATE)));
+    dateMath = (String) getStatResult("dmr", "dmma", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), TrieDateField.parseDate(dateMath), date.parseMath(math));
+  }
+
+  @Test
+  public void constantDateTest() throws Exception {
+    String date = (String) getStatResult("cdr", "cd1", VAL_TYPE.DATE);
+    String str = (String) getStatResult("cdr", "cs1", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), date, str);
+
+    date = (String) getStatResult("cdr", "cd2", VAL_TYPE.DATE);
+    str = (String) getStatResult("cdr", "cs2", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), date, str);
+  }
+
+  @Test
+  public void constantStringTest() throws Exception {
+    String str = (String) getStatResult("csr", "cs1", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), str, "this is the first");
+
+    str = (String) getStatResult("csr", "cs2", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), str, "this is the second");
+
+    str = (String) getStatResult("csr", "cs3", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), str, "this is the third");
+  }
+
+  @Test
+  public void concatenateTest() throws Exception {
+    StringBuilder builder = new StringBuilder();
+    builder.append((String) getStatResult("cr", "csmin", VAL_TYPE.STRING));
+    builder.append((String) getStatResult("cr", "min", VAL_TYPE.STRING));
+    String concat = (String) getStatResult("cr", "ccmin", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), concat, builder.toString());
+
+    builder.setLength(0);
+    builder.append((String) getStatResult("cr", "csmax", VAL_TYPE.STRING));
+    builder.append((String) getStatResult("cr", "max", VAL_TYPE.STRING));
+    concat = (String) getStatResult("cr", "ccmax", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), concat, builder.toString());
+  }
+
+  @Test
+  public void reverseTest() throws Exception {
+    StringBuilder builder = new StringBuilder();
+    builder.append((String) getStatResult("rr", "min", VAL_TYPE.STRING));
+    String rev = (String) getStatResult("rr", "rmin", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), rev, builder.reverse().toString());
+
+    builder.setLength(0);
+    builder.append((String) getStatResult("rr", "max", VAL_TYPE.STRING));
+    rev = (String) getStatResult("rr", "rmax", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), rev, builder.reverse().toString());
+  }
+
+  public static SolrQueryRequest request(String... args) {
+    return SolrTestCaseJ4.req(ObjectArrays.concat(BASEPARMS, args, String.class));
+  }
+
+  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
+    InputStream in = clazz.getResourceAsStream(fileName);
+    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
+    Scanner file = new Scanner(in, "UTF-8");
+    try { 
+      ArrayList<String> strList = new ArrayList<>();
+      while (file.hasNextLine()) {
+        String line = file.nextLine();
+        if (line.length()<2) {
+          continue;
+        }
+        String[] param = line.split("=");
+        strList.add(param[0]);
+        strList.add(param[1]);
+      }
+      return strList.toArray(new String[0]);
+    } finally {
+      IOUtils.closeWhileHandlingException(file, in);
+    }
+  }
+}
diff --git solr/core/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java solr/core/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java
new file mode 100644
index 0000000..3d3ca3f
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/facet/AbstractAnalyticsFacetTest.java
@@ -0,0 +1,302 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.facet;
+
+import java.io.ByteArrayInputStream;
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Scanner;
+
+import org.apache.lucene.util.IOUtils;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.analytics.util.MedianCalculator;
+import org.apache.solr.analytics.util.PercentileCalculator;
+import org.apache.solr.request.SolrQueryRequest;
+
+import com.google.common.collect.ObjectArrays;
+
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
+import javax.xml.parsers.ParserConfigurationException;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+public class AbstractAnalyticsFacetTest extends SolrTestCaseJ4 {
+  protected static final HashMap<String,Object> defaults = new HashMap<>();
+  
+  protected String latestType = "";
+
+  private static Document doc;
+  private static XPathFactory xPathFact =  XPathFactory.newInstance();
+  private static String rawResponse;
+
+  protected static void setResponse(String response) throws ParserConfigurationException, IOException, SAXException {
+    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
+    factory.setNamespaceAware(true); // never forget this!
+    DocumentBuilder builder = factory.newDocumentBuilder();
+    doc = builder.parse(new InputSource(new ByteArrayInputStream(response.getBytes(StandardCharsets.UTF_8))));
+    xPathFact = XPathFactory.newInstance();
+    rawResponse = response;
+  }
+
+  protected String getRawResponse() {
+    return rawResponse;
+  }
+
+  protected Node getNode(String xPath) throws XPathExpressionException {
+    return (Node)xPathFact.newXPath().compile(xPath).evaluate(doc, XPathConstants.NODE);
+  }
+  private NodeList getNodes(String n1, String n2, String n3, String element, String n4) throws XPathExpressionException {
+    // Construct the XPath expression. The form better not change or all these will fail.
+    StringBuilder sb = new StringBuilder("/response/lst[@name='stats']/lst[@name='").append(n1).append("']");
+    sb.append("/lst[@name='").append(n2).append("']");
+    sb.append("/lst[@name='").append(n3).append("']");
+    sb.append("//").append(element).append("[@name='").append(n4).append("']");
+    return (NodeList)xPathFact.newXPath().compile(sb.toString()).evaluate(doc, XPathConstants.NODESET);
+
+  }
+  protected ArrayList<String> getStringList(String n1, String n2, String n3, String element, String n4)
+      throws XPathExpressionException {
+    ArrayList<String> ret = new ArrayList<>();
+    NodeList nodes = getNodes(n1, n2, n3, element, n4);
+    for (int idx = 0; idx < nodes.getLength(); ++idx) {
+      ret.add(nodes.item(idx).getTextContent());
+    }
+    return ret;
+  }
+
+  protected ArrayList<Integer> getIntegerList(String n1, String n2, String n3, String element, String n4)
+      throws XPathExpressionException {
+    ArrayList<Integer> ret = new ArrayList<>();
+    NodeList nodes = getNodes(n1, n2, n3, element, n4);
+    for (int idx = 0; idx < nodes.getLength(); ++idx) {
+      ret.add(Integer.parseInt(nodes.item(idx).getTextContent()));
+    }
+    return ret;
+  }
+  protected ArrayList<Long> getLongList(String n1, String n2, String n3, String element, String n4)
+      throws XPathExpressionException {
+    ArrayList<Long> ret = new ArrayList<>();
+    NodeList nodes = getNodes(n1, n2, n3, element, n4);
+    for (int idx = 0; idx < nodes.getLength(); ++idx) {
+      ret.add(Long.parseLong(nodes.item(idx).getTextContent()));
+    }
+    return ret;
+  }
+  protected ArrayList<Float> getFloatList(String n1, String n2, String n3, String element, String n4)
+      throws XPathExpressionException {
+    ArrayList<Float> ret = new ArrayList<>();
+    NodeList nodes = getNodes(n1, n2, n3, element, n4);
+    for (int idx = 0; idx < nodes.getLength(); ++idx) {
+      ret.add(Float.parseFloat(nodes.item(idx).getTextContent()));
+    }
+    return ret;
+  }
+
+  protected ArrayList<Double> getDoubleList(String n1, String n2, String n3, String element, String n4)
+      throws XPathExpressionException {
+    ArrayList<Double> ret = new ArrayList<>();
+    NodeList nodes = getNodes(n1, n2, n3, element, n4);
+    for (int idx = 0; idx < nodes.getLength(); ++idx) {
+      ret.add(Double.parseDouble(nodes.item(idx).getTextContent()));
+    }
+    return ret;
+  }
+
+
+  public static void increment(List<Long> list, int idx){
+    Long i = list.remove(idx);
+    list.add(idx, i+1);
+  }
+  
+  public static String[] filter(String...args){
+    List<String> l = new ArrayList<>();
+    for( int i=0; i <args.length; i+=2){
+      if( args[i+1].equals("0") || args[i+1].equals("0.0") || 
+          args[i+1].equals("1800-12-31T23:59:59Z") || args[i+1].equals("str0") ||
+          args[i+1].equals("this is the firststr0") || 
+          args[i+1].equals("this is the secondstr0") ){
+        continue;
+      }
+      l.add(args[i]);
+      l.add(args[i+1]);
+    }
+    return l.toArray(new String[0]);
+  }
+  
+  protected void setLatestType(String latestType) {
+    this.latestType = latestType;
+  }
+
+  @SuppressWarnings({ "unchecked", "rawtypes" })
+  public <T extends Number & Comparable<T>> ArrayList calculateNumberStat(ArrayList<ArrayList<T>> lists, String stat) {
+    ArrayList result;
+    if (stat.equals("median")) {
+      result = new ArrayList<Double>();
+      for (List<T> list : lists) {
+        result.add(MedianCalculator.getMedian(list));
+      }
+    } else if (stat.equals("mean")) {
+      result = new ArrayList<Double>();
+      for (List<T> list : lists) {
+        double d = 0;
+        for (T element : list) {
+          d += element.doubleValue();
+        }
+        result.add(d/list.size());
+      }
+    } else if (stat.equals("sum")) {
+      result = new ArrayList<Double>();
+      for (Collection<T> list : lists) {
+        double d = 0;
+        for (T element : list) {
+          d += element.doubleValue();
+        }
+        result.add(d);
+      }
+    } else if (stat.equals("sumOfSquares")) {
+      result = new ArrayList<Double>();
+      for (List<T> list : lists) {
+        double d = 0;
+        for (T element : list) {
+          d += element.doubleValue()*element.doubleValue();
+        }
+        result.add(d);
+      }
+    } else if (stat.equals("stddev")) {
+      result = new ArrayList<Double>();
+      for (List<T> list : lists) {
+        double sum = 0;
+        double sumSquares = 0;
+        for (T element : list) {
+          sum += element.doubleValue();
+          sumSquares += element.doubleValue()*element.doubleValue();
+        }
+        String res = Double.toString(Math.sqrt(sumSquares/list.size()-sum*sum/(list.size()*list.size())));
+        result.add(Double.parseDouble(res));
+      }
+    } else {
+      throw new IllegalArgumentException();
+    }
+    return result;
+  }
+
+  @SuppressWarnings({ "unchecked", "rawtypes" })
+  public <T extends Comparable<T>> ArrayList calculateStat(ArrayList<ArrayList<T>> lists, String stat) {
+    ArrayList result;
+    if (stat.contains("perc_")) {
+      double[] perc = new double[]{Double.parseDouble(stat.substring(5))/100};
+      result = new ArrayList<T>();
+      for (List<T> list : lists) {
+        if( list.size() == 0) continue;
+        result.add(PercentileCalculator.getPercentiles(list, perc).get(0));
+      }
+    } else if (stat.equals("count")) {
+      result = new ArrayList<Long>();
+      for (List<T> list : lists) {
+        //if( list.size() == 0) continue;
+        result.add((long)list.size());
+      }
+    } else if (stat.equals("missing")) {
+      result = new ArrayList<Long>();
+      for (ArrayList<T> list : lists) {
+        if( list.size() == 0) continue;
+        result.add(calculateMissing(list,latestType));
+      }
+    } else if (stat.equals("unique")) {
+      result = new ArrayList<Long>();
+      for (List<T> list : lists) {
+        HashSet<T> set = new HashSet<>();
+        set.addAll(list);
+        result.add((long)set.size());
+      }
+    } else if (stat.equals("max")) {
+      result = new ArrayList<T>();
+      for (List<T> list : lists) {
+        if( list.size() == 0) continue;
+        Collections.sort(list);
+        result.add(list.get(list.size()-1));
+      }
+    } else if (stat.equals("min")) {
+      result = new ArrayList<T>();
+      for (List<T> list : lists) {
+        if( list.size() == 0) continue;
+        Collections.sort((List<T>)list);
+        result.add(list.get(0));
+      }
+    } else {
+      result = null;
+    }
+    return result;
+  }
+
+  @SuppressWarnings("unchecked")
+  public <T extends Comparable<T>> Long calculateMissing(ArrayList<T> list, String type) {
+    T def = (T)defaults.get(type);
+    long miss = 0;
+    for (T element : list) {
+      if (element.compareTo(def)==0) {
+        miss++;
+      }
+    }
+    return Long.valueOf(miss);
+  }
+  
+  public static SolrQueryRequest request(String...args){
+    return SolrTestCaseJ4.req( ObjectArrays.concat(BASEPARMS, args,String.class) );
+  }
+  
+  public static final String[] BASEPARMS = new String[]{ "q", "*:*", "indent", "true", "olap", "true", "rows", "0" };
+
+  
+  public static String[] fileToStringArr(Class<?> clazz, String fileName) throws FileNotFoundException {
+    InputStream in = clazz.getResourceAsStream(fileName);
+    if (in == null) throw new FileNotFoundException("Resource not found: " + fileName);
+    Scanner file = new Scanner(in, "UTF-8");
+    try { 
+      ArrayList<String> strList = new ArrayList<>();
+      while (file.hasNextLine()) {
+        String line = file.nextLine();
+        if (line.length()<2) {
+          continue;
+        }
+        String[] param = line.split("=");
+        strList.add(param[0]);
+        strList.add(param[1]);
+      }
+      return strList.toArray(new String[0]);
+    } finally {
+      IOUtils.closeWhileHandlingException(file, in);
+    }
+  }
+}
diff --git solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java
new file mode 100644
index 0000000..09e63fb
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetExtrasTest.java
@@ -0,0 +1,174 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.facet;
+
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class FieldFacetExtrasTest extends AbstractAnalyticsFacetTest {
+  static String fileName = "/analytics/requestFiles/fieldFacetExtras.txt";
+
+  public static final int INT = 21;
+  public static final int LONG = 22;
+  public static final int FLOAT = 23;
+  public static final int DOUBLE = 24;
+  public static final int DATE = 25;
+  public static final int STRING = 26;
+  public static final int NUM_LOOPS = 100;
+  
+  //INT
+  static ArrayList<ArrayList<Integer>> intLongTestStart; 
+  static ArrayList<ArrayList<Integer>> intFloatTestStart; 
+  static ArrayList<ArrayList<Integer>> intDoubleTestStart; 
+  static ArrayList<ArrayList<Integer>> intStringTestStart; 
+  
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+
+    //INT
+    intLongTestStart = new ArrayList<>();
+    intFloatTestStart = new ArrayList<>();
+    intDoubleTestStart = new ArrayList<>();
+    intStringTestStart = new ArrayList<>();
+
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT;
+      long l = j%LONG;
+      float f = j%FLOAT;
+      double d = j%DOUBLE;
+      int dt = j%DATE;
+      int s = j%STRING;
+      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59.999Z", "string_sd", "abc" + s));
+      //Long
+      if (j-LONG<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intLongTestStart.add(list1);
+      } else {
+        intLongTestStart.get((int)l).add(i);
+      }
+      //String
+      if (j-FLOAT<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intFloatTestStart.add(list1);
+      } else {
+        intFloatTestStart.get((int)f).add(i);
+      }
+      //String
+      if (j-DOUBLE<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intDoubleTestStart.add(list1);
+      } else {
+        intDoubleTestStart.get((int)d).add(i);
+      }
+      //String
+      if (j-STRING<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intStringTestStart.add(list1);
+      } else {
+        intStringTestStart.get(s).add(i);
+      }
+      
+      if (usually()) {
+        assertU(commit()); // to have several segments
+      }
+    }
+    
+    assertU(commit()); 
+    setResponse(h.query(request(fileToStringArr(FieldFacetExtrasTest.class, fileName))));
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void limitTest() throws Exception { 
+
+    Collection<Double> lon = getDoubleList("lr", "fieldFacets", "long_ld", "double", "mean");
+    assertEquals(getRawResponse(), lon.size(),5);
+    Collection<Double> flo = getDoubleList("lr", "fieldFacets", "float_fd", "double", "median");
+    assertEquals(getRawResponse(), flo.size(),3);
+    Collection<Long> doub = getLongList("lr", "fieldFacets", "double_dd", "long", "count");
+    assertEquals(getRawResponse(), doub.size(),7);
+    Collection<Integer> string = getIntegerList("lr", "fieldFacets", "string_sd", "int", "percentile_20");
+    assertEquals(getRawResponse(), string.size(),1);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void offsetTest() throws Exception { 
+
+    Collection<Double> lon;
+   
+    List<Double> all = new ArrayList<>();
+    lon = getDoubleList("off0", "fieldFacets", "long_ld", "double", "mean");
+    assertEquals(getRawResponse(), lon.size(),2);
+    assertArrayEquals(new Double[]{ 1.5,  2.0 }, lon.toArray(new Double[0]));
+    all.addAll(lon);
+    
+    lon = getDoubleList("off1", "fieldFacets", "long_ld", "double", "mean");
+    assertEquals(getRawResponse(), lon.size(),2);
+    assertArrayEquals(new Double[]{ 3.0,  4.0 }, lon.toArray(new Double[0]));
+    all.addAll(lon);
+    
+    lon = getDoubleList("off2", "fieldFacets", "long_ld", "double", "mean");
+    assertEquals(getRawResponse(), lon.size(),3);
+    assertArrayEquals(new Double[]{ 5.0,  5.75, 6.0 }, lon.toArray(new Double[0]));
+    all.addAll(lon);
+    
+    lon = getDoubleList("offAll", "fieldFacets", "long_ld", "double", "mean");
+    assertEquals(getRawResponse(), lon.size(),7);
+    assertArrayEquals(all.toArray(new Double[0]), lon.toArray(new Double[0]));
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void sortTest() throws Exception { 
+    Collection<Double> lon = getDoubleList("sr", "fieldFacets", "long_ld", "double", "mean");
+    ArrayList<Double> longTest = calculateNumberStat(intLongTestStart, "mean");
+    Collections.sort(longTest);
+    assertEquals(getRawResponse(), longTest,lon);
+    
+    Collection<Double> flo = getDoubleList("sr", "fieldFacets", "float_fd", "double", "median");
+    ArrayList<Double> floatTest = calculateNumberStat(intFloatTestStart, "median");
+    Collections.sort(floatTest,Collections.reverseOrder());
+    assertEquals(getRawResponse(), floatTest,flo);
+    
+    Collection<Long> doub = getLongList("sr", "fieldFacets", "double_dd", "long", "count");
+    ArrayList<Long> doubleTest = (ArrayList<Long>)calculateStat(intDoubleTestStart, "count");
+    Collections.sort(doubleTest);
+    assertEquals(getRawResponse(), doubleTest,doub);
+    
+    Collection<Integer> string = getIntegerList("sr", "fieldFacets", "string_sd", "int", "percentile_20");
+    ArrayList<Integer> stringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_20");
+    Collections.sort(stringTest,Collections.reverseOrder());
+    assertEquals(getRawResponse(), stringTest,string);
+  }
+
+}
diff --git solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java
new file mode 100644
index 0000000..2eab53a
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/facet/FieldFacetTest.java
@@ -0,0 +1,1084 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.facet;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+
+public class FieldFacetTest extends AbstractAnalyticsFacetTest{
+  static String fileName = "/analytics/requestFiles/fieldFacets.txt";
+
+  public static final int INT = 71;
+  public static final int LONG = 36;
+  public static final int LONGM = 50;
+  public static final int FLOAT = 73;
+  public static final int FLOATM = 84;
+  public static final int DOUBLE = 49;
+  public static final int DATE = 12;
+  public static final int DATEM = 30;
+  public static final int STRING = 28;
+  public static final int STRINGM = 40;
+  public static final int NUM_LOOPS = 100;
+  
+  //INT
+  private static ArrayList<ArrayList<Integer>> intDateTestStart; 
+  private static ArrayList<Long> intDateTestMissing; 
+  private static ArrayList<ArrayList<Integer>> intStringTestStart; 
+  private static ArrayList<Long> intStringTestMissing; 
+  
+  //LONG
+  private static ArrayList<ArrayList<Long>> longDateTestStart; 
+  private static ArrayList<Long> longDateTestMissing; 
+  private static ArrayList<ArrayList<Long>> longStringTestStart; 
+  private static ArrayList<Long> longStringTestMissing; 
+  
+  //FLOAT
+  private static ArrayList<ArrayList<Float>> floatDateTestStart; 
+  private static ArrayList<Long> floatDateTestMissing; 
+  private static ArrayList<ArrayList<Float>> floatStringTestStart; 
+  private static ArrayList<Long> floatStringTestMissing; 
+  
+  //DOUBLE
+  private static ArrayList<ArrayList<Double>> doubleDateTestStart; 
+  private static ArrayList<Long> doubleDateTestMissing; 
+  private static ArrayList<ArrayList<Double>> doubleStringTestStart; 
+  private static ArrayList<Long> doubleStringTestMissing; 
+  
+  //DATE
+  private static ArrayList<ArrayList<String>> dateIntTestStart; 
+  private static ArrayList<Long> dateIntTestMissing; 
+  private static ArrayList<ArrayList<String>> dateLongTestStart; 
+  private static ArrayList<Long> dateLongTestMissing; 
+  
+  //String
+  private static ArrayList<ArrayList<String>> stringIntTestStart; 
+  private static ArrayList<Long> stringIntTestMissing; 
+  private static ArrayList<ArrayList<String>> stringLongTestStart; 
+  private static ArrayList<Long> stringLongTestMissing; 
+  
+  //Multi-Valued
+  private static ArrayList<ArrayList<Integer>> multiLongTestStart; 
+  private static ArrayList<Long> multiLongTestMissing; 
+  private static ArrayList<ArrayList<Integer>> multiStringTestStart; 
+  private static ArrayList<Long> multiStringTestMissing; 
+  private static ArrayList<ArrayList<Integer>> multiDateTestStart; 
+  private static ArrayList<Long> multiDateTestMissing; 
+  
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+    
+    defaults.put("int", new Integer(0));
+    defaults.put("long", new Long(0));
+    defaults.put("float", new Float(0));
+    defaults.put("double", new Double(0));
+    defaults.put("date", "1800-12-31T23:59:59Z");
+    defaults.put("string", "str0");
+
+    //INT
+    intDateTestStart = new ArrayList<>();
+    intDateTestMissing = new ArrayList<>();
+    intStringTestStart = new ArrayList<>();
+    intStringTestMissing = new ArrayList<>();
+    
+    //LONG
+    longDateTestStart = new ArrayList<>();
+    longDateTestMissing = new ArrayList<>();
+    longStringTestStart = new ArrayList<>();
+    longStringTestMissing = new ArrayList<>();
+    
+    //FLOAT
+    floatDateTestStart = new ArrayList<>();
+    floatDateTestMissing = new ArrayList<>();
+    floatStringTestStart = new ArrayList<>();
+    floatStringTestMissing = new ArrayList<>();
+    
+    //DOUBLE
+    doubleDateTestStart = new ArrayList<>();
+    doubleDateTestMissing = new ArrayList<>();
+    doubleStringTestStart = new ArrayList<>();
+    doubleStringTestMissing = new ArrayList<>();
+    
+    //DATE
+    dateIntTestStart = new ArrayList<>();
+    dateIntTestMissing = new ArrayList<>();
+    dateLongTestStart = new ArrayList<>();
+    dateLongTestMissing = new ArrayList<>();
+    
+    //String
+    stringIntTestStart = new ArrayList<>();
+    stringIntTestMissing = new ArrayList<>();
+    stringLongTestStart = new ArrayList<>();
+    stringLongTestMissing = new ArrayList<>();
+    
+    //Multi-Valued
+    multiLongTestStart = new ArrayList<>();
+    multiLongTestMissing = new ArrayList<>();
+    multiStringTestStart = new ArrayList<>();
+    multiStringTestMissing = new ArrayList<>();
+    multiDateTestStart = new ArrayList<>();
+    multiDateTestMissing = new ArrayList<>();
+
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT;
+      long l = j%LONG;
+      long lm = j%LONGM;
+      float f = j%FLOAT;
+      double d = j%DOUBLE;
+      int dt = j%DATE;
+      int dtm = j%DATEM;
+      int s = j%STRING;
+      int sm = j%STRINGM;
+      if (dt==0 && dtm == 0) {
+        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
+          "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm)));
+      } else if (dt == 0) {
+        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
+            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
+            "date_dtdm", (1800+dtm) + "-12-31T23:59:59Z")));
+      } else if (dtm == 0) {
+        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
+            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
+            "date_dtdm", (1800+dt) + "-12-31T23:59:59Z")));
+      } else {
+        assertU(adoc(filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+            "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59Z", "string_sd", "str" + s,
+            "long_ldm", "" + l, "long_ldm", ""+lm, "string_sdm", "str" + s, "string_sdm", "str"+sm,
+            "date_dtdm", (1800+dt) + "-12-31T23:59:59Z", "date_dtdm", (1800+dtm) + "-12-31T23:59:59Z")));
+      }
+      
+      if( dt != 0 ){
+        //Dates
+        if (j-DATE<0) {
+          ArrayList<Integer> list1 = new ArrayList<>();
+          if( i != 0 ){
+            list1.add(i);
+            intDateTestMissing.add(0l);
+          } else {
+            intDateTestMissing.add(1l);
+          }
+          intDateTestStart.add(list1);
+          ArrayList<Long> list2 = new ArrayList<>();
+          if( l != 0l ){
+            list2.add(l);
+            longDateTestMissing.add(0l);
+          } else {
+            longDateTestMissing.add(1l);
+          }
+          longDateTestStart.add(list2);
+          ArrayList<Float> list3 = new ArrayList<>();
+          if ( f != 0.0f ){
+            list3.add(f);
+            floatDateTestMissing.add(0l);
+          } else {
+            floatDateTestMissing.add(1l);
+            
+          }
+          floatDateTestStart.add(list3);
+          ArrayList<Double> list4 = new ArrayList<>();
+          if( d != 0.0d ){
+            list4.add(d);
+            doubleDateTestMissing.add(0l);
+          } else {
+            doubleDateTestMissing.add(1l);
+          }
+          doubleDateTestStart.add(list4);
+          ArrayList<Integer> list5 = new ArrayList<>();
+          if( i != 0 ){
+            list5.add(i);
+            multiDateTestMissing.add(0l);
+          } else {
+            multiDateTestMissing.add(1l);
+            
+          }
+          multiDateTestStart.add(list5);
+        } else {
+          if( i != 0 ) intDateTestStart.get(dt-1).add(i); else increment(intDateTestMissing,dt-1);
+          if( l != 0l ) longDateTestStart.get(dt-1).add(l); else increment(longDateTestMissing,dt-1);
+          if( f != 0.0f ) floatDateTestStart.get(dt-1).add(f); else increment(floatDateTestMissing,dt-1);
+          if( d != 0.0d ) doubleDateTestStart.get(dt-1).add(d); else increment(doubleDateTestMissing,dt-1);
+          if( i != 0 ) multiDateTestStart.get(dt-1).add(i); else increment(multiDateTestMissing,dt-1);
+        }
+      }
+      
+      if (j-DATEM<0 && dtm!=dt && dtm!=0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        if( i != 0 ){
+          list1.add(i);
+          multiDateTestMissing.add(0l);
+        } else {
+          multiDateTestMissing.add(1l);
+        }
+        multiDateTestStart.add(list1);
+      } else if (dtm!=dt && dtm!=0) {
+        if( i != 0 ) multiDateTestStart.get(dtm-1).add(i);
+      }
+      
+      if( s != 0 ){
+        //Strings
+        if (j-STRING<0) {
+          ArrayList<Integer> list1 = new ArrayList<>();
+          if( i != 0 ){
+            list1.add(i);
+            intStringTestMissing.add(0l);
+          } else {
+            intStringTestMissing.add(1l);
+          }
+          intStringTestStart.add(list1);
+          ArrayList<Long> list2 = new ArrayList<>();
+          if( l != 0l ){
+            list2.add(l);
+            longStringTestMissing.add(0l);
+          } else {
+            longStringTestMissing.add(1l);
+          }
+          longStringTestStart.add(list2);
+          ArrayList<Float> list3 = new ArrayList<>();
+          if( f != 0.0f ){
+            list3.add(f);
+            floatStringTestMissing.add(0l);
+          } else {
+            floatStringTestMissing.add(1l);
+          }
+          floatStringTestStart.add(list3);
+          ArrayList<Double> list4 = new ArrayList<>();
+          if( d != 0.0d ){
+            list4.add(d);
+            doubleStringTestMissing.add(0l);
+          } else {
+            doubleStringTestMissing.add(1l);
+          }
+          doubleStringTestStart.add(list4);
+          ArrayList<Integer> list5 = new ArrayList<>();
+          if( i != 0 ){
+            list5.add(i);
+            multiStringTestMissing.add(0l);
+          } else {
+            multiStringTestMissing.add(1l);
+          }
+          multiStringTestStart.add(list5);
+        } else {
+          if( i != 0 ) intStringTestStart.get(s-1).add(i); else increment(intStringTestMissing,s-1);
+          if( l != 0l ) longStringTestStart.get(s-1).add(l); else increment(longStringTestMissing,s-1);
+          if( f != 0.0f ) floatStringTestStart.get(s-1).add(f); else increment(floatStringTestMissing,s-1);
+          if( d != 0.0d ) doubleStringTestStart.get(s-1).add(d); else increment(doubleStringTestMissing,s-1);
+          if( i != 0 ) multiStringTestStart.get(s-1).add(i); else increment(multiStringTestMissing,s-1);
+        }
+      }
+      
+      //Strings
+      if( sm != 0 ){
+        if (j-STRINGM<0&&sm!=s) {
+          ArrayList<Integer> list1 = new ArrayList<>();
+          if( i != 0 ){
+            list1.add(i);
+            multiStringTestMissing.add(0l);
+          } else {
+            multiStringTestMissing.add(1l);
+          }
+          multiStringTestStart.add(list1);
+        } else if (sm!=s) {
+          if( i != 0 ) multiStringTestStart.get(sm-1).add(i); else increment(multiStringTestMissing,sm-1);
+        }
+      }
+      
+      //Int
+      if( i != 0 ){
+        if (j-INT<0) {
+          ArrayList<String> list1 = new ArrayList<>();
+          if( dt != 0 ){
+            list1.add((1800+dt) + "-12-31T23:59:59Z");
+            dateIntTestMissing.add(0l);
+          } else {
+            dateIntTestMissing.add(1l);
+          }
+          dateIntTestStart.add(list1);
+          ArrayList<String> list2 = new ArrayList<>();
+          if( s != 0 ){
+            list2.add("str"+s);
+            stringIntTestMissing.add(0l);
+          } else {
+            stringIntTestMissing.add(1l);
+          }
+          stringIntTestStart.add(list2);
+        } else {
+          if( dt != 0 ) dateIntTestStart.get(i-1).add((1800+dt) + "-12-31T23:59:59Z"); else increment(dateIntTestMissing,i-1);
+          if( s != 0 ) stringIntTestStart.get(i-1).add("str"+s); else increment(stringIntTestMissing,i-1);
+        }
+      }
+      
+      //Long
+      if( l != 0 ){
+        if (j-LONG<0) {
+          ArrayList<String> list1 = new ArrayList<>();
+          if( dt != 0 ){
+            list1.add((1800+dt) + "-12-31T23:59:59Z");
+            dateLongTestMissing.add(0l);
+          } else {
+            dateLongTestMissing.add(1l);
+          }
+          dateLongTestStart.add(list1);
+          ArrayList<String> list2 = new ArrayList<>();
+          if( s != 0 ){
+            list2.add("str"+s);
+            stringLongTestMissing.add(0l);
+          } else {
+            stringLongTestMissing.add(1l);
+          }
+          stringLongTestStart.add(list2);
+          ArrayList<Integer> list3 = new ArrayList<>();
+          if( i != 0 ){
+            list3.add(i);
+            multiLongTestMissing.add(0l);
+          } else {
+            multiLongTestMissing.add(1l);
+          }
+          multiLongTestStart.add(list3);
+        } else {
+          if( dt != 0 ) dateLongTestStart.get((int)l-1).add((1800+dt) + "-12-31T23:59:59Z"); else increment(dateLongTestMissing,(int)l-1);
+          if( s != 0 ) stringLongTestStart.get((int)l-1).add("str"+s); else increment(stringLongTestMissing,(int)l-1);
+          if( i != 0 ) multiLongTestStart.get((int)l-1).add(i); else increment(multiLongTestMissing,(int)l-1);
+        }
+      }
+      
+      //Long
+      if( lm != 0 ){
+        if (j-LONGM<0&&lm!=l) {
+          ArrayList<Integer> list1 = new ArrayList<>();
+          if( i != 0 ){
+            list1.add(i);
+            multiLongTestMissing.add(0l);
+          } else {
+            multiLongTestMissing.add(1l);
+          }
+          multiLongTestStart.add(list1);
+        } else if (lm!=l) {
+          if( i != 0 ) multiLongTestStart.get((int)lm-1).add(i); else increment( multiLongTestMissing,(int)lm-1);
+        }
+      }
+      
+      if (usually()) {
+        assertU(commit()); // to have several segments
+      }
+    }
+    
+    assertU(commit());
+    String[] reqFacetParamas = fileToStringArr(FieldFacetTest.class, fileName);
+    String[] reqParamas = new String[reqFacetParamas.length + 2];
+    System.arraycopy(reqFacetParamas, 0, reqParamas, 0, reqFacetParamas.length);
+    reqParamas[reqFacetParamas.length] = "solr";
+    reqParamas[reqFacetParamas.length+1] = "asc";
+    setResponse(h.query(request(reqFacetParamas)));
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void sumTest() throws Exception { 
+    //Int Date
+    Collection<Double> intDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "int");
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "sum");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Double> intString = getDoubleList("sum","fieldFacets", "string_sd", "double", "int");
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "sum");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Double> longDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "long");
+    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "sum");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Double> longString = getDoubleList("sum","fieldFacets", "string_sd", "double", "long");
+    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "sum");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Double> floatDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "float");
+    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "sum");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Double> floatString = getDoubleList("sum","fieldFacets", "string_sd", "double", "float");
+    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "sum");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("sum","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "sum");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("sum","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "sum");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void meanTest() throws Exception { 
+    //Int Date
+    Collection<Double> intDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "int");
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "mean");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Double> intString = getDoubleList("mean","fieldFacets", "string_sd", "double", "int");
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "mean");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Double> longDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "long");
+    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "mean");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Double> longString = getDoubleList("mean","fieldFacets", "string_sd", "double", "long");
+    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "mean");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Double> floatDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "float");
+    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "mean");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Double> floatString = getDoubleList("mean","fieldFacets", "string_sd", "double", "float");
+    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "mean");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("mean","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "mean");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("mean","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "mean");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void sumOfSquaresFacetAscTest() throws Exception {
+    //Int Date
+    Collection<Double> intDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "int");
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Double> intString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "int");
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Double> longDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "long");
+    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Double> longString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "long");
+    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Double> floatDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "float");
+    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Double> floatString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "float");
+    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("sumOfSquares","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("sumOfSquares","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "sumOfSquares");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void stddevFacetAscTest() throws Exception { 
+    //Int Date
+    ArrayList<Double> intDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "int");
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "stddev");
+    checkStddevs(intDate,intDateTest);
+    //Int String
+    ArrayList<Double> intString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "int");
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "stddev");
+    checkStddevs(intString,intStringTest);
+
+    //Long Date
+    ArrayList<Double> longDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "long");
+    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "stddev");
+    checkStddevs(longDate,longDateTest);
+    //Long String
+    ArrayList<Double> longString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "long");
+    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "stddev");
+    checkStddevs(longString,longStringTest);
+
+    //Float Date
+    ArrayList<Double> floatDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "float");
+    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "stddev");
+    checkStddevs(floatDate,floatDateTest);
+    //Float String
+    ArrayList<Double> floatString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "float");
+    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "stddev");
+    checkStddevs(floatString,floatStringTest);
+
+    //Double Date
+    ArrayList<Double> doubleDate = getDoubleList("stddev","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "stddev");
+    checkStddevs(doubleDate,doubleDateTest);
+    //Double String
+    ArrayList<Double> doubleString = getDoubleList("stddev","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "stddev");
+    checkStddevs(doubleString,doubleStringTest);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void medianFacetAscTest() throws Exception { 
+    //Int Date
+    Collection<Double> intDate = getDoubleList( "median","fieldFacets", "date_dtd", "double", "int");
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateTestStart, "median");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Double> intString = getDoubleList("median","fieldFacets", "string_sd", "double", "int");
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "median");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Double> longDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "long");
+    ArrayList<Double> longDateTest = calculateNumberStat(longDateTestStart, "median");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Double> longString = getDoubleList("median","fieldFacets", "string_sd", "double", "long");
+    ArrayList<Double> longStringTest = calculateNumberStat(longStringTestStart, "median");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Double> floatDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "float");
+    ArrayList<Double> floatDateTest = calculateNumberStat(floatDateTestStart, "median");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Double> floatString = getDoubleList("median","fieldFacets", "string_sd", "double", "float");
+    ArrayList<Double> floatStringTest = calculateNumberStat(floatStringTestStart, "median");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("median","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = calculateNumberStat(doubleDateTestStart, "median");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("median","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = calculateNumberStat(doubleStringTestStart, "median");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void perc20Test() throws Exception { 
+    //Int Date
+    Collection<Integer> intDate = getIntegerList("percentile_20n","fieldFacets", "date_dtd", "int", "int");
+    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "perc_20");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Integer> intString = getIntegerList("percentile_20n","fieldFacets", "string_sd", "int", "int");
+    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_20");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("percentile_20n","fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "perc_20");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Long> longString = getLongList("percentile_20n","fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "perc_20");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Float> floatDate = getFloatList("percentile_20n","fieldFacets", "date_dtd", "float", "float");
+    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "perc_20");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Float> floatString = getFloatList("percentile_20n","fieldFacets", "string_sd", "float", "float");
+    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "perc_20");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("percentile_20n","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "perc_20");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("percentile_20n","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "perc_20");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+
+    //Date Int
+    Collection<String> dateInt = getStringList("percentile_20","fieldFacets", "int_id", "date", "date");
+    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "perc_20");
+    assertEquals(getRawResponse(),dateInt,dateIntTest);
+    //Date Long
+    Collection<String> dateString = getStringList("percentile_20","fieldFacets", "long_ld", "date", "date");
+    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "perc_20");
+    assertEquals(getRawResponse(),dateString,dateLongTest);
+
+    //String Int
+    Collection<String> stringInt = getStringList("percentile_20","fieldFacets", "int_id", "str", "str");
+    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "perc_20");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    //String Long
+    Collection<String> stringLong = getStringList("percentile_20","fieldFacets", "long_ld", "str", "str");
+    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "perc_20");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void perc60Test() throws Exception { 
+    //Int Date
+    Collection<Integer> intDate = getIntegerList("percentile_60n","fieldFacets", "date_dtd", "int", "int");
+    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "perc_60");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Integer> intString = getIntegerList("percentile_60n","fieldFacets", "string_sd", "int", "int");
+    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "perc_60");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("percentile_60n","fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "perc_60");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Long> longString = getLongList("percentile_60n","fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "perc_60");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Float> floatDate = getFloatList("percentile_60n","fieldFacets", "date_dtd", "float", "float");
+    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "perc_60");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Float> floatString = getFloatList("percentile_60n","fieldFacets", "string_sd", "float", "float");
+    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "perc_60");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("percentile_60n","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "perc_60");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("percentile_60n","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "perc_60");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+
+    //Date Int
+    Collection<String> dateInt = getStringList("percentile_60","fieldFacets", "int_id", "date", "date");
+    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "perc_60");
+    assertEquals(getRawResponse(),dateInt,dateIntTest);
+    //Date Long
+    Collection<String> dateString = getStringList("percentile_60","fieldFacets", "long_ld", "date", "date");
+    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "perc_60");
+    assertEquals(getRawResponse(),dateString,dateLongTest);
+
+    //String Int
+    Collection<String> stringInt = getStringList("percentile_60","fieldFacets", "int_id", "str", "str");
+    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "perc_60");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    //String Long
+    Collection<String> stringLong = getStringList("percentile_60","fieldFacets", "long_ld", "str", "str");
+    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "perc_60");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void minTest() throws Exception { 
+    //Int Date
+    Collection<Integer> intDate = getIntegerList("minn","fieldFacets", "date_dtd", "int", "int");
+    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "min");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Integer> intString = getIntegerList("minn","fieldFacets", "string_sd", "int", "int");
+    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "min");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("minn","fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "min");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Long> longString = getLongList("minn","fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "min");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Float> floatDate = getFloatList("minn","fieldFacets", "date_dtd", "float", "float");
+    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "min");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Float> floatString = getFloatList("minn","fieldFacets", "string_sd", "float", "float");
+    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "min");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("minn","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "min");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Double> doubleString = getDoubleList("minn","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "min");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+
+    //Date Int
+    Collection<String> dateInt = getStringList("min","fieldFacets", "int_id", "date", "date");
+    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "min");
+    assertEquals(getRawResponse(),dateInt,dateIntTest);
+    //Date Long
+    Collection<String> dateString = getStringList("min","fieldFacets", "long_ld", "date", "date");
+    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "min");
+    assertEquals(getRawResponse(),dateString,dateLongTest);
+
+    //String Int
+    Collection<String> stringInt = getStringList("min","fieldFacets", "int_id", "str", "str");
+    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "min");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    //String Long
+    Collection<String> stringLong = getStringList("min","fieldFacets", "long_ld", "str", "str");
+    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "min");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void maxTest() throws Exception { 
+    //Int Date
+    Collection<Integer> intDate = getIntegerList("maxn","fieldFacets", "date_dtd", "int", "int");
+    ArrayList<Integer> intDateTest = (ArrayList<Integer>)calculateStat(intDateTestStart, "max");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    
+    //Int String
+    Collection<Integer> intString = getIntegerList("maxn","fieldFacets", "string_sd", "int", "int");
+    ArrayList<Integer> intStringTest = (ArrayList<Integer>)calculateStat(intStringTestStart, "max");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("maxn","fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "max");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    
+    //Long String
+    Collection<Long> longString = getLongList("maxn","fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "max");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Float> floatDate = getFloatList("maxn","fieldFacets", "date_dtd", "float", "float");
+    ArrayList<Float> floatDateTest = (ArrayList<Float>)calculateStat(floatDateTestStart, "max");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    
+    //Float String
+    Collection<Float> floatString = getFloatList("maxn","fieldFacets", "string_sd", "float", "float");
+    ArrayList<Float> floatStringTest = (ArrayList<Float>)calculateStat(floatStringTestStart, "max");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Double> doubleDate = getDoubleList("maxn","fieldFacets", "date_dtd", "double", "double");
+    ArrayList<Double> doubleDateTest = (ArrayList<Double>)calculateStat(doubleDateTestStart, "max");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    
+    //Double String
+    Collection<Double> doubleString = getDoubleList("maxn","fieldFacets", "string_sd", "double", "double");
+    ArrayList<Double> doubleStringTest = (ArrayList<Double>)calculateStat(doubleStringTestStart, "max");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+    
+    //String Int
+    Collection<String> stringInt = getStringList("max","fieldFacets", "int_id", "str", "str");
+    ArrayList<String> stringIntTest = (ArrayList<String>)calculateStat(stringIntTestStart, "max");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    
+    //String Long
+    Collection<String> stringLong = getStringList("max","fieldFacets", "long_ld", "str", "str");
+    ArrayList<String> stringLongTest = (ArrayList<String>)calculateStat(stringLongTestStart, "max");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+
+    //Date Int
+    Collection<String> dateInt = getStringList("max","fieldFacets", "int_id", "date", "date");
+    ArrayList<String> dateIntTest = (ArrayList<String>)calculateStat(dateIntTestStart, "max");
+    assertEquals(getRawResponse(),dateInt,dateIntTest);
+    
+    //Date Long
+    Collection<String> dateString = getStringList("max","fieldFacets", "long_ld", "date", "date");
+    ArrayList<String> dateLongTest = (ArrayList<String>)calculateStat(dateLongTestStart, "max");
+    assertEquals(getRawResponse(),dateString,dateLongTest);
+
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void uniqueTest() throws Exception { 
+    //Int Date
+    Collection<Long> intDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "int");
+    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(intDateTestStart, "unique");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    //Int String
+    Collection<Long> intString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "int");
+    ArrayList<Long> intStringTest = (ArrayList<Long>)calculateStat(intStringTestStart, "unique");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "unique");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    //Long String
+    Collection<Long> longString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "unique");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Long> floatDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "float");
+    ArrayList<Long> floatDateTest = (ArrayList<Long>)calculateStat(floatDateTestStart, "unique");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    //Float String
+    Collection<Long> floatString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "float");
+    ArrayList<Long> floatStringTest = (ArrayList<Long>)calculateStat(floatStringTestStart, "unique");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Long> doubleDate = getLongList("uniquen", "fieldFacets", "date_dtd", "long", "double");
+    ArrayList<Long> doubleDateTest = (ArrayList<Long>)calculateStat(doubleDateTestStart, "unique");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    //Double String
+    Collection<Long> doubleString = getLongList("uniquen", "fieldFacets", "string_sd", "long", "double");
+    ArrayList<Long> doubleStringTest = (ArrayList<Long>)calculateStat(doubleStringTestStart, "unique");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+
+    //Date Int
+    Collection<Long> dateInt = getLongList("unique", "fieldFacets", "int_id", "long", "date");
+    ArrayList<Long> dateIntTest = (ArrayList<Long>)calculateStat(dateIntTestStart, "unique");
+    assertEquals(getRawResponse(),dateInt,dateIntTest);
+    //Date Long
+    Collection<Long> dateString = getLongList("unique", "fieldFacets", "long_ld", "long", "date");
+    ArrayList<Long> dateLongTest = (ArrayList<Long>)calculateStat(dateLongTestStart, "unique");
+    assertEquals(getRawResponse(),dateString,dateLongTest);
+
+    //String Int
+    Collection<Long> stringInt = getLongList("unique", "fieldFacets", "int_id", "long", "str");
+    ArrayList<Long> stringIntTest = (ArrayList<Long>)calculateStat(stringIntTestStart, "unique");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    //String Long
+    Collection<Long> stringLong = getLongList("unique", "fieldFacets", "long_ld", "long", "str");
+    ArrayList<Long> stringLongTest = (ArrayList<Long>)calculateStat(stringLongTestStart, "unique");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void countTest() throws Exception { 
+    //Int Date
+    Collection<Long> intDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "int");
+    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(intDateTestStart, "count");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    
+    //Int String
+    Collection<Long> intString = getLongList("countn", "fieldFacets", "string_sd", "long", "int");
+    ArrayList<Long> intStringTest = (ArrayList<Long>)calculateStat(intStringTestStart, "count");
+    assertEquals(getRawResponse(),intString,intStringTest);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "long");
+    ArrayList<Long> longDateTest = (ArrayList<Long>)calculateStat(longDateTestStart, "count");
+    assertEquals(getRawResponse(),longDate,longDateTest);
+    
+    //Long String
+    Collection<Long> longString = getLongList("countn", "fieldFacets", "string_sd", "long", "long");
+    ArrayList<Long> longStringTest = (ArrayList<Long>)calculateStat(longStringTestStart, "count");
+    assertEquals(getRawResponse(),longString,longStringTest);
+
+    //Float Date
+    Collection<Long> floatDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "float");
+    ArrayList<Long> floatDateTest = (ArrayList<Long>)calculateStat(floatDateTestStart, "count");
+    assertEquals(getRawResponse(),floatDate,floatDateTest);
+    
+    //Float String
+    Collection<Long> floatString = getLongList("countn", "fieldFacets", "string_sd", "long", "float");
+    ArrayList<Long> floatStringTest = (ArrayList<Long>)calculateStat(floatStringTestStart, "count");
+    assertEquals(getRawResponse(),floatString,floatStringTest);
+
+    //Double Date
+    Collection<Long> doubleDate = getLongList("countn", "fieldFacets", "date_dtd", "long", "double");
+    ArrayList<Long> doubleDateTest = (ArrayList<Long>)calculateStat(doubleDateTestStart, "count");
+    assertEquals(getRawResponse(),doubleDate,doubleDateTest);
+    
+    //Double String
+    Collection<Long> doubleString = getLongList("countn", "fieldFacets", "string_sd", "long", "double");
+    ArrayList<Long> doubleStringTest = (ArrayList<Long>)calculateStat(doubleStringTestStart, "count");
+    assertEquals(getRawResponse(),doubleString,doubleStringTest);
+
+    //Date Int
+    Collection<Long> dateInt = getLongList("count", "fieldFacets", "int_id", "long", "date");
+    ArrayList<Long> dateIntTest = (ArrayList<Long>)calculateStat(dateIntTestStart, "count");
+    assertEquals(getRawResponse(),dateIntTest,dateInt);
+    
+    //Date Long
+    Collection<Long> dateLong = getLongList("count", "fieldFacets", "long_ld", "long", "date");
+    ArrayList<Long> dateLongTest = (ArrayList<Long>)calculateStat(dateLongTestStart, "count");
+    assertEquals(getRawResponse(),dateLong,dateLongTest);
+
+    //String Int
+    Collection<Long> stringInt = getLongList("count", "fieldFacets", "int_id", "long", "str");
+    ArrayList<Long> stringIntTest = (ArrayList<Long>)calculateStat(stringIntTestStart, "count");
+    assertEquals(getRawResponse(),stringInt,stringIntTest);
+    
+    //String Long
+    Collection<Long> stringLong = getLongList("count", "fieldFacets", "long_ld", "long", "str");
+    ArrayList<Long> stringLongTest = (ArrayList<Long>)calculateStat(stringLongTestStart, "count");
+    assertEquals(getRawResponse(),stringLong,stringLongTest);
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void missingTest() throws Exception { 
+    //Int Date
+    Collection<Long> intDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "int");
+    setLatestType("int");
+    assertEquals(getRawResponse(),intDateTestMissing,intDate);
+    
+    //Int String
+    Collection<Long> intString = getLongList("missingn", "fieldFacets", "string_sd", "long", "int");
+    assertEquals(getRawResponse(),intStringTestMissing,intString);
+
+    //Long Date
+    Collection<Long> longDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "long");
+    setLatestType("long");
+    assertEquals(getRawResponse(),longDateTestMissing,longDate);
+    
+    //Long String
+    Collection<Long> longString = getLongList("missingn", "fieldFacets", "string_sd", "long", "long");
+    assertEquals(getRawResponse(),longStringTestMissing,longString);
+
+    //Float Date
+    Collection<Long> floatDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "float");
+    setLatestType("float");
+    assertEquals(getRawResponse(),floatDateTestMissing,floatDate);
+    
+    //Float String
+    Collection<Long> floatString = getLongList("missingn", "fieldFacets", "string_sd", "long", "float");
+    assertEquals(getRawResponse(),floatStringTestMissing,floatString);
+
+    //Double Date
+    Collection<Long> doubleDate = getLongList("missingn", "fieldFacets", "date_dtd", "long", "double");
+    setLatestType("double");
+    assertEquals(getRawResponse(),doubleDateTestMissing,doubleDate);
+    
+    //Double String
+    Collection<Long> doubleString = getLongList("missingn", "fieldFacets", "string_sd", "long", "double");
+    assertEquals(getRawResponse(),doubleStringTestMissing,doubleString);
+
+    //Date Int
+    Collection<Long> dateInt = getLongList("missing", "fieldFacets", "int_id", "long", "date");
+    setLatestType("date");
+    assertEquals(getRawResponse(),dateIntTestMissing,dateInt);
+    
+    //Date Long
+    Collection<Long> dateLong = getLongList("missing", "fieldFacets", "long_ld", "long", "date");
+    assertEquals(getRawResponse(),dateLongTestMissing,dateLong);
+
+    //String Int
+    Collection<Long> stringInt = getLongList("missing", "fieldFacets", "int_id", "long", "str");
+    setLatestType("string");
+    assertEquals(getRawResponse(),stringIntTestMissing,stringInt);
+    
+    //String Long
+    Collection<Long> stringLong = getLongList("missing", "fieldFacets", "long_ld", "long", "str");
+    assertEquals(getRawResponse(),stringLongTestMissing,stringLong);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void multiValueTest() throws Exception { 
+    //Long
+    Collection<Double> lon = getDoubleList("multivalued", "fieldFacets", "long_ldm", "double", "mean");
+    ArrayList<Double> longTest = calculateNumberStat(multiLongTestStart, "mean");
+    assertEquals(getRawResponse(),lon,longTest);
+    //Date
+    Collection<Double> date = getDoubleList("multivalued", "fieldFacets", "date_dtdm", "double", "mean");
+    ArrayList<Double> dateTest = calculateNumberStat(multiDateTestStart, "mean");
+    assertEquals(getRawResponse(),date,dateTest);
+    //String
+    Collection<Double> string = getDoubleList("multivalued", "fieldFacets", "string_sdm", "double", "mean");
+    ArrayList<Double> stringTest = calculateNumberStat(multiStringTestStart, "mean");
+    assertEquals(getRawResponse(),string,stringTest);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void missingFacetTest() throws Exception { 
+    //int MultiDate
+    String xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='date_dtdm']/lst[@name='(MISSING)']";
+    assertNotNull(getRawResponse(), getNode(xPath));
+
+    ArrayList<Double> string = getDoubleList("missingf", "fieldFacets", "date_dtdm", "double", "mean");
+    string.remove(0);
+    ArrayList<Double> stringTest = calculateNumberStat(multiDateTestStart, "mean");
+    assertEquals(getRawResponse(), string,stringTest);
+    
+    //Int String
+    xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='string_sd']/lst[@name='(MISSING)']";
+    assertNotNull(getRawResponse(), getNode(xPath));
+
+    xPath = "/response/lst[@name='stats']/lst[@name='missingf']/lst[@name='fieldFacets']/lst[@name='string_sd']/lst[@name='str0']";
+    assertNull(getRawResponse(), getNode(xPath));
+    List<Double> intString = getDoubleList("missingf", "fieldFacets", "string_sd", "double", "mean");
+    intString.remove(0);
+    ArrayList<Double> intStringTest = calculateNumberStat(intStringTestStart, "mean");
+    assertEquals(getRawResponse(), intString,intStringTest);
+    
+    //Int Date
+    Collection<Double> intDate = getDoubleList("missingf", "fieldFacets", "date_dtd", "double", "mean");
+    ArrayList<ArrayList<Double>> intDateMissingTestStart = (ArrayList<ArrayList<Double>>) intDateTestStart.clone();
+    ArrayList<Double> intDateTest = calculateNumberStat(intDateMissingTestStart, "mean");
+    assertEquals(getRawResponse(),intDate,intDateTest);
+    
+    
+  }
+
+  private void checkStddevs(ArrayList<Double> list1, ArrayList<Double> list2) {
+    Collections.sort(list1);
+    Collections.sort(list2);
+    for (int i = 0; i<list1.size(); i++) {
+      if ((Math.abs(list1.get(i)-list2.get(i))<.00000000001) == false) {
+        Assert.assertEquals(getRawResponse(), list1.get(i), list2.get(i), 0.00000000001);
+      }
+    }
+  }
+
+  public static void assertEquals(String mes, Object actual, Object expected) {
+    Collections.sort((List<Comparable>) actual);
+    Collections.sort((List<Comparable>)  expected);
+    Assert.assertEquals(mes, actual, expected);
+  }
+}
diff --git solr/core/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java solr/core/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java
new file mode 100644
index 0000000..8c5787d
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/facet/QueryFacetTest.java
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.facet;
+
+
+import java.util.ArrayList;
+
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class QueryFacetTest extends AbstractAnalyticsFacetTest {
+  static String fileName = "/analytics/requestFiles/queryFacets.txt";
+
+  public final int INT = 71;
+  public final int LONG = 36;
+  public final int FLOAT = 93;
+  public final int DOUBLE = 49;
+  public final int DATE = 12;
+  public final int STRING = 28;
+  public final int NUM_LOOPS = 100;
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void queryTest() throws Exception { 
+    h.update("<delete><query>*:*</query></delete>");
+    //INT
+    ArrayList<ArrayList<Integer>> int1TestStart = new ArrayList<>();
+    int1TestStart.add(new ArrayList<Integer>());
+    ArrayList<ArrayList<Integer>> int2TestStart = new ArrayList<>();
+    int2TestStart.add(new ArrayList<Integer>());
+    
+    //LONG
+    ArrayList<ArrayList<Long>> longTestStart = new ArrayList<>();
+    longTestStart.add(new ArrayList<Long>());
+    longTestStart.add(new ArrayList<Long>());
+    
+    //FLOAT
+    ArrayList<ArrayList<Float>> floatTestStart = new ArrayList<>();
+    floatTestStart.add(new ArrayList<Float>());
+    floatTestStart.add(new ArrayList<Float>());
+    floatTestStart.add(new ArrayList<Float>());
+    
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT;
+      long l = j%LONG;
+      float f = j%FLOAT;
+      double d = j%DOUBLE;
+      int dt = j%DATE;
+      int s = j%STRING;
+      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+          "double_dd", "" + d,  "date_dtd", (1800+dt) + "-12-31T23:59:59.999Z", "string_sd", "abc" + new Integer(s).toString().charAt(0)));
+
+      if (f<=50) {
+        int1TestStart.get(0).add(i);
+      }
+      if (f<=30) {
+        int2TestStart.get(0).add(i);
+      }
+      if (new Integer(s).toString().charAt(0)=='1') {
+        longTestStart.get(0).add(l);
+      }
+      if (new Integer(s).toString().charAt(0)=='2') {
+        longTestStart.get(1).add(l);
+      }
+      if (l>=20) {
+        floatTestStart.get(0).add(f);
+      }
+      if (l>=30) {
+        floatTestStart.get(1).add(f);
+      }
+      if (d<=50) {
+        floatTestStart.get(2).add(f);
+      }
+      
+      if (usually()) {
+        assertU(commit()); // to have several segments
+      }
+    }
+    
+    assertU(commit()); 
+    
+    //Query ascending tests
+    setResponse(h.query(request(fileToStringArr(QueryFacetTest.class, fileName))));
+    
+    //Int One
+    ArrayList<Double> int1 = getDoubleList("ir", "queryFacets", "float1", "double", "sum");
+    ArrayList<Double> int1Test = calculateNumberStat(int1TestStart, "sum");
+    assertEquals(getRawResponse(), int1, int1Test);
+    //Int Two
+    ArrayList<Integer> int2 = getIntegerList("ir", "queryFacets", "float2", "int", "percentile_8");
+    ArrayList<Integer> int2Test = (ArrayList<Integer>)calculateStat(int2TestStart, "perc_8");
+    assertEquals(getRawResponse(), int2, int2Test);
+
+    //Long
+    ArrayList<Double> long1 = getDoubleList("lr", "queryFacets", "string", "double", "median");
+    ArrayList<Double> long1Test = calculateNumberStat(longTestStart, "median");
+    assertEquals(getRawResponse(),long1,long1Test);
+
+    //Float
+    ArrayList<Double> float1 = getDoubleList("fr", "queryFacets", "lad", "double", "mean");
+    ArrayList<Double> float1Test = calculateNumberStat(floatTestStart, "mean");
+    assertEquals(getRawResponse(), float1, float1Test);
+  }
+
+}
diff --git solr/core/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java solr/core/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java
new file mode 100644
index 0000000..c6e7494
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/facet/RangeFacetTest.java
@@ -0,0 +1,445 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.facet;
+
+
+import java.util.ArrayList;
+
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+
+public class RangeFacetTest extends AbstractAnalyticsFacetTest {
+  static String fileName = "/analytics/requestFiles/rangeFacets.txt";
+
+  public static final int INT = 71;
+  public static final int LONG = 36;
+  public static final int FLOAT = 93;
+  public static final int DOUBLE = 48;
+  public static final int DATE = 52;
+  public static final int STRING = 28;
+  public static final int NUM_LOOPS = 100;
+  
+  //INT
+  static ArrayList<ArrayList<Integer>> intLongTestStart; 
+  static ArrayList<ArrayList<Integer>> intDoubleTestStart; 
+  static ArrayList<ArrayList<Integer>> intDateTestStart; 
+  
+  //FLOAT
+  static ArrayList<ArrayList<Float>> floatLongTestStart; 
+  static ArrayList<ArrayList<Float>> floatDoubleTestStart; 
+  static ArrayList<ArrayList<Float>> floatDateTestStart; 
+  
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+    
+    //INT
+    intLongTestStart = new ArrayList<>();
+    intDoubleTestStart = new ArrayList<>();
+    intDateTestStart = new ArrayList<>();
+    
+    //FLOAT
+    floatLongTestStart = new ArrayList<>();
+    floatDoubleTestStart = new ArrayList<>();
+    floatDateTestStart = new ArrayList<>();
+    
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT;
+      long l = j%LONG;
+      float f = j%FLOAT;
+      double d = j%DOUBLE;
+      int dt = j%DATE;
+      int s = j%STRING;
+      assertU(adoc("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+          "double_dd", "" + d,  "date_dtd", (1000+dt) + "-01-01T23:59:59Z", "string_sd", "abc" + s));
+      //Longs
+      if (j-LONG<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intLongTestStart.add(list1);
+        ArrayList<Float> list2 = new ArrayList<>();
+        list2.add(f);
+        floatLongTestStart.add(list2);
+      } else {
+        intLongTestStart.get((int)l).add(i);
+        floatLongTestStart.get((int)l).add(f);
+      }
+      //Doubles
+      if (j-DOUBLE<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intDoubleTestStart.add(list1);
+        ArrayList<Float> list2 = new ArrayList<>();
+        list2.add(f);
+        floatDoubleTestStart.add(list2);
+      } else {
+        intDoubleTestStart.get((int)d).add(i);
+        floatDoubleTestStart.get((int)d).add(f);
+      }
+      //Dates
+      if (j-DATE<0) {
+        ArrayList<Integer> list1 = new ArrayList<>();
+        list1.add(i);
+        intDateTestStart.add(list1);
+        ArrayList<Float> list2 = new ArrayList<>();
+        list2.add(f);
+        floatDateTestStart.add(list2);
+      } else {
+        intDateTestStart.get(dt).add(i);
+        floatDateTestStart.get(dt).add(f);
+      }
+      
+      if (usually()) {
+        assertU(commit());  // to have several segments
+      }
+    }
+    
+    assertU(commit()); 
+    
+    setResponse(h.query(request(fileToStringArr(RangeFacetTest.class, fileName))));
+  }
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void rangeTest() throws Exception {
+    
+    //Int Long
+    ArrayList<Long> intLong = getLongList("ri", "rangeFacets", "long_ld", "long", "count");
+    ArrayList<Long> intLongTest = calculateStat(transformLists(intLongTestStart, 5, 30, 5
+                                                        , false, true, false, false, false), "count");
+    assertEquals(getRawResponse(), intLong,intLongTest);
+    //Int Double
+    ArrayList<Double> intDouble = getDoubleList("ri", "rangeFacets", "double_dd", "double", "mean");
+    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, 7
+                                                          , false, false, true, false, true), "mean");
+    assertEquals(getRawResponse(), intDouble,intDoubleTest);
+    //Int Date
+    ArrayList<Long> intDate = getLongList("ri", "rangeFacets", "date_dtd", "long", "count");
+    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, 7
+                                                      , false, true, false, true, true), "count");
+    assertEquals(getRawResponse(), intDate,intDateTest);
+    
+    //Float Long
+    ArrayList<Double> floatLong = getDoubleList("rf", "rangeFacets", "long_ld", "double", "median");
+    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, 4
+                                                          , false, true, true, true, true), "median");
+    assertEquals(getRawResponse(), floatLong,floatLongTest);
+    //Float Double
+    ArrayList<Long> floatDouble = getLongList("rf", "rangeFacets", "double_dd", "long", "count");
+    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, 11
+                                                                     , false, false, false, true, false), "count");
+    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
+    //Float Date                      
+    ArrayList<Double> floatDate = getDoubleList("rf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
+    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, 5
+                                                          , false, false, true, true, false), "sumOfSquares");
+    assertEquals(getRawResponse(), floatDate,floatDateTest);
+  }
+  
+
+  @SuppressWarnings("unchecked")
+  @Test
+  public void hardendRangeTest() throws Exception {
+    //Int Long
+    ArrayList<Double> intLong = getDoubleList("hi", "rangeFacets", "long_ld", "double", "sum");
+    ArrayList<Double> intLongTest = calculateNumberStat(transformLists(intLongTestStart, 5, 30, 5
+                                                        , true, true, false, false, false), "sum");
+    assertEquals(getRawResponse(), intLong,intLongTest);
+    //Int Double
+    ArrayList<Double> intDouble = getDoubleList("hi", "rangeFacets", "double_dd", "double", "mean");
+    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, 7
+                                                          , true, false, true, false, true), "mean");
+    assertEquals(getRawResponse(), intDouble,intDoubleTest);
+    //Int Date
+    ArrayList<Long> intDate = getLongList("hi", "rangeFacets", "date_dtd", "long", "count");
+    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, 7
+                                                      , true, true, false, true, true), "count");
+    assertEquals(getRawResponse(), intDate,intDateTest);
+    
+    //Float Long
+    ArrayList<Double> floatLong = getDoubleList("hf", "rangeFacets", "long_ld", "double", "median");
+    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, 4
+                                                          , true, true, true, true, true), "median");
+    assertEquals(getRawResponse(), floatLong,floatLongTest);
+    //Float Double
+    ArrayList<Long> floatDouble = getLongList("hf", "rangeFacets", "double_dd", "long", "count");
+    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, 11
+                                                                     , true, false, false, true, false), "count");
+    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
+    //Float Date                      
+    ArrayList<Double> floatDate = getDoubleList("hf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
+    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, 5
+                                                          , true, false, true, true, false), "sumOfSquares");
+    assertEquals(getRawResponse(), floatDate,floatDateTest);
+  }
+  
+  @SuppressWarnings("unchecked")
+  @Test
+  public void multiGapTest() throws Exception {
+    //Int Long
+    ArrayList<Double> intLong = getDoubleList("mi", "rangeFacets", "long_ld", "double", "sum");
+    ArrayList<Double> intLongTest = calculateNumberStat(transformLists(intLongTestStart, 5, 30, "4,2,6,3"
+                                                        , false, true, false, false, false), "sum");
+    assertEquals(getRawResponse(), intLong,intLongTest);
+    //Int Double
+    ArrayList<Double> intDouble = getDoubleList("mi", "rangeFacets", "double_dd", "double", "mean");
+    ArrayList<Double> intDoubleTest = calculateNumberStat(transformLists(intDoubleTestStart, 3, 39, "3,1,7"
+                                                          , false, false, true, false, true), "mean");
+    assertEquals(getRawResponse(), intDouble,intDoubleTest);
+    //Int Date
+    ArrayList<Long> intDate = getLongList("mi", "rangeFacets", "date_dtd", "long", "count");
+    ArrayList<Long> intDateTest = (ArrayList<Long>)calculateStat(transformLists(intDateTestStart, 7, 44, "2,7"
+                                                      , false, true, false, true, true), "count");
+    assertEquals(getRawResponse(), intDate,intDateTest);
+    
+    //Float Long
+    ArrayList<Double> floatLong = getDoubleList("mf", "rangeFacets", "long_ld", "double", "median");
+    ArrayList<Double> floatLongTest = calculateNumberStat(transformLists(floatLongTestStart, 0, 29, "1,4"
+                                                          , false, true, true, true, true), "median");;
+    assertEquals(getRawResponse(), floatLong,floatLongTest);
+    //Float Double
+    ArrayList<Long> floatDouble = getLongList("mf", "rangeFacets", "double_dd", "long", "count");
+    ArrayList<Long> floatDoubleTest = (ArrayList<Long>)calculateStat(transformLists(floatDoubleTestStart, 4, 47, "2,3,11"
+                                                          , false, false, false, true, false), "count");
+    assertEquals(getRawResponse(), floatDouble,floatDoubleTest);
+    //Float Date                      
+    ArrayList<Double> floatDate = getDoubleList("mf", "rangeFacets", "date_dtd", "double", "sumOfSquares");
+    ArrayList<Double> floatDateTest = calculateNumberStat(transformLists(floatDateTestStart, 4, 46, "4,5"
+                                                          , false, false, true, true, false), "sumOfSquares");
+    assertEquals(getRawResponse(), floatDate,floatDateTest);
+  }
+  
+  private <T> ArrayList<ArrayList<T>> transformLists(ArrayList<ArrayList<T>> listsStart, int start, int end, int gap
+      , boolean hardend, boolean incLow, boolean incUp, boolean incEdge, boolean incOut) {
+    int off = (end-start)%gap;
+    if (!hardend && off>0) {
+      end+=gap-off;
+    }
+
+    ArrayList<ArrayList<T>> lists = new ArrayList<>();
+    ArrayList<T> between = new ArrayList<>();
+    if (incLow && incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i; j<=i+gap && j<=end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start; i<listsStart.size() && i<=end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else if (incLow && !incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i; j<i+gap && j<end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start; i<listsStart.size() && i<end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else if (!incLow && incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i+1; j<=i+gap && j<=end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start+1; i<listsStart.size() && i<=end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i+1; j<i+gap && j<end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start+1; i<listsStart.size() && i<end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    }
+    
+    if (incEdge && !incLow && start>=0) {
+      lists.get(0).addAll(listsStart.get(start));
+      between.addAll(listsStart.get(start));
+    }
+    if (incEdge && !incUp && end<listsStart.size()) {
+      lists.get(lists.size()-1).addAll(listsStart.get(end));
+      between.addAll(listsStart.get(end));
+    }
+    ArrayList<T> before = new ArrayList<>();
+    ArrayList<T> after = new ArrayList<>();
+    if (incOut || !(incLow||incEdge)) {
+      for (int i = 0; i<=start; i++) {
+        before.addAll(listsStart.get(i));
+      }
+    } else {
+      for (int i = 0; i<start; i++) {
+        before.addAll(listsStart.get(i));
+      }
+    }
+    if (incOut || !(incUp||incEdge)) {
+      for (int i = end; i<listsStart.size(); i++) {
+        after.addAll(listsStart.get(i));
+      }
+    } 
+    else {
+      for (int i = end+1; i<listsStart.size(); i++) {
+        after.addAll(listsStart.get(i));
+      }
+    }
+    if (before.size()>0) {
+      lists.add(before);
+    }
+    if (after.size()>0) {
+      lists.add(after);
+    }
+    if (between.size()>0) {
+      lists.add(between);
+    }
+    return lists;
+  }
+  
+  private <T> ArrayList<ArrayList<T>> transformLists(ArrayList<ArrayList<T>> listsStart, int start, int end, String gapString
+      , boolean hardend, boolean incLow, boolean incUp, boolean incEdge, boolean incOut) {
+    String[] stringGaps = gapString.split(",");
+    int[] gaps = new int[stringGaps.length];
+    for (int i = 0; i<gaps.length; i++) {
+      gaps[i] = Integer.parseInt(stringGaps[i]);
+    }
+    int bigGap = 0;
+    int last = gaps[gaps.length-1];
+    for (int i = 0; i<gaps.length-1; i++) {
+      bigGap += gaps[i];
+    }
+    int off = (end-start-bigGap)%last;
+    if (!hardend && off>0) {
+      end+=last-off;
+    }
+    
+    ArrayList<ArrayList<T>> lists = new ArrayList<>();
+    ArrayList<T> between = new ArrayList<>();
+    int gap = 0;
+    int gapCounter = 0;
+    if (incLow && incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        if (gapCounter<gaps.length) {
+          gap = gaps[gapCounter++];
+        }
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i; j<=i+gap && j<=end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start; i<listsStart.size() && i<=end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else if (incLow && !incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        if (gapCounter<gaps.length) {
+          gap = gaps[gapCounter++];
+        }
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i; j<i+gap && j<end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start; i<listsStart.size() && i<end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else if (!incLow && incUp) {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        if (gapCounter<gaps.length) {
+          gap = gaps[gapCounter++];
+        }
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i+1; j<=i+gap && j<=end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start+1; i<listsStart.size() && i<=end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    } else {
+      for (int i = start; i<end && i<listsStart.size(); i+=gap) {
+        if (gapCounter<gaps.length) {
+          gap = gaps[gapCounter++];
+        }
+        ArrayList<T> list = new ArrayList<>();
+        for (int j = i+1; j<i+gap && j<end && j<listsStart.size(); j++) {
+          list.addAll(listsStart.get(j));
+        }
+        lists.add(list);
+      }
+      for (int i = start+1; i<listsStart.size() && i<end; i++) {
+        between.addAll(listsStart.get(i));
+      }
+    }
+    
+    if (incEdge && !incLow && start>=0) {
+      lists.get(0).addAll(listsStart.get(start));
+      between.addAll(listsStart.get(start));
+    }
+    if (incEdge && !incUp && end<listsStart.size()) {
+      lists.get(lists.size()-1).addAll(listsStart.get(end));
+      between.addAll(listsStart.get(end));
+    }
+    ArrayList<T> before = new ArrayList<>();
+    ArrayList<T> after = new ArrayList<>();
+    if (incOut || !(incLow||incEdge)) {
+      for (int i = 0; i<=start; i++) {
+        before.addAll(listsStart.get(i));
+      }
+    } else {
+      for (int i = 0; i<start; i++) {
+        before.addAll(listsStart.get(i));
+      }
+    }
+    if (incOut || !(incUp||incEdge)) {
+      for (int i = end; i<listsStart.size(); i++) {
+        after.addAll(listsStart.get(i));
+      }
+    } 
+    else {
+      for (int i = end+1; i<listsStart.size(); i++) {
+        after.addAll(listsStart.get(i));
+      }
+    }
+    if (before.size()>0) {
+      lists.add(before);
+    }
+    if (after.size()>0) {
+      lists.add(after);
+    }
+    if (between.size()>0) {
+      lists.add(between);
+    }
+    return lists;
+  }
+  
+}
diff --git solr/core/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java solr/core/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java
new file mode 100644
index 0000000..6a91401
--- /dev/null
+++ solr/core/src/test/org/apache/solr/analytics/util/valuesource/FunctionTest.java
@@ -0,0 +1,234 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analytics.util.valuesource;
+
+
+import org.apache.solr.analytics.AbstractAnalyticsStatsTest;
+import org.apache.solr.analytics.facet.AbstractAnalyticsFacetTest;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class FunctionTest extends AbstractAnalyticsStatsTest {
+  static String fileName = "/analytics/requestFiles/functions.txt";
+
+  static public final int INT = 71;
+  static public final int LONG = 36;
+  static public final int FLOAT = 93;
+  static public final int DOUBLE = 49;
+  static public final int DATE = 12;
+  static public final int STRING = 28;
+  static public final int NUM_LOOPS = 100;
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig-basic.xml","schema-analytics.xml");
+    h.update("<delete><query>*:*</query></delete>");
+    
+    for (int j = 0; j < NUM_LOOPS; ++j) {
+      int i = j%INT+1;
+      long l = j%LONG+1;
+      float f = j%FLOAT+1;
+      double d = j%DOUBLE+1;
+      double d0 = j%DOUBLE;
+      String dt = (1800+j%DATE) + "-06-30T23:59:59Z";
+      String s = "str" + (j%STRING);
+
+      double add_if = (double)i+f;
+      double add_ldf = (double)l+d+f;
+      double mult_if = (double)i*f;
+      double mult_ldf = (double)l*d*f;
+      double div_if = (double)i/f;
+      double div_ld = (double)l/d;
+      double pow_if = Math.pow(i,f);
+      double pow_ld = Math.pow(l,d);
+      double neg_i = (double)i*-1;
+      double neg_l = (double)l*-1;
+      String dm_2y = (1802+j%DATE) + "-06-30T23:59:59Z";
+      String dm_2m = (1800+j%DATE) + "-08-30T23:59:59Z";
+      String concat_first = "this is the first"+s;
+      String concat_second = "this is the second"+s;
+      String rev = new StringBuilder(s).reverse().toString();
+      
+      assertU(adoc(AbstractAnalyticsFacetTest.filter("id", "1000" + j, "int_id", "" + i, "long_ld", "" + l, "float_fd", "" + f, 
+            "double_dd", "" + d,  "date_dtd", dt, "string_sd", s,
+            "add_if_dd", ""+add_if, "add_ldf_dd", ""+add_ldf, "mult_if_dd", ""+mult_if, "mult_ldf_dd", ""+mult_ldf,
+            "div_if_dd", ""+div_if, "div_ld_dd", ""+div_ld, "pow_if_dd", ""+pow_if, "pow_ld_dd", ""+pow_ld,
+            "neg_i_dd", ""+neg_i, "neg_l_dd", ""+neg_l, "const_8_dd", "8", "const_10_dd", "10", "dm_2y_dtd", dm_2y, "dm_2m_dtd", dm_2m,
+            "const_00_dtd", "1800-06-30T23:59:59Z", "const_04_dtd", "1804-06-30T23:59:59Z", "const_first_sd", "this is the first", "const_second_sd", "this is the second",
+            "concat_first_sd", concat_first, "concat_second_sd", concat_second, "rev_sd", rev, "miss_dd", ""+d0 )));
+      
+      
+      if (usually()) {
+        assertU(commit()); // to have several segments
+      }
+    }
+    
+    assertU(commit()); 
+    
+    setResponse(h.query(request(fileToStringArr(FunctionTest.class, fileName))));
+  }
+      
+  @Test
+  public void addTest() throws Exception { 
+    double result = (Double)getStatResult("ar", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("ar", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    // TODO checfk why asserted 2times
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+
+    result = (Double)getStatResult("ar", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("ar", "meanc", VAL_TYPE.DOUBLE);
+    assertTrue(result==calculated);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+  }
+  
+  @Test
+  public void multiplyTest() throws Exception { 
+    double result = (Double)getStatResult("mr", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("mr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+    
+    result = (Double)getStatResult("mr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("mr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+  }
+  
+  @Test
+  public void divideTest() throws Exception { 
+    Double result = (Double)getStatResult("dr", "sum", VAL_TYPE.DOUBLE);
+    Double calculated = (Double)getStatResult("dr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+    
+    result = (Double)getStatResult("dr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("dr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+  }
+  
+  @Test
+  public void powerTest() throws Exception { 
+    double result = (Double)getStatResult("pr", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("pr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+    
+    result = (Double)getStatResult("pr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("pr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+  }
+  
+  @Test
+  public void negateTest() throws Exception { 
+    double result = (Double)getStatResult("nr", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("nr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+    
+    result = (Double)getStatResult("nr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("nr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+  }
+
+  @Test 
+  public void absoluteValueTest() throws Exception {
+    double result = (Double)getStatResult("avr", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("avr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+    
+    result = (Double)getStatResult("avr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("avr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+  }
+  
+  @Test
+  public void constantNumberTest() throws Exception { 
+    double result = (Double)getStatResult("cnr", "sum", VAL_TYPE.DOUBLE);
+    double calculated = (Double)getStatResult("cnr", "sumc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    
+    result = (Double)getStatResult("cnr", "mean", VAL_TYPE.DOUBLE);
+    calculated = (Double)getStatResult("cnr", "meanc", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), result, calculated, 0.0);
+    assertEquals(getRawResponse(),  result, calculated, 0.0);
+  }
+  
+  @Test
+  public void dateMathTest() throws Exception {
+    String result = (String)getStatResult("dmr", "median", VAL_TYPE.DATE);
+    String calculated = (String)getStatResult("dmr", "medianc", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), result, calculated);
+    
+    result = (String)getStatResult("dmr", "max", VAL_TYPE.DATE);
+    calculated = (String)getStatResult("dmr", "maxc", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), result, calculated);
+  }
+  
+  @Test
+  public void constantDateTest() throws Exception { 
+    String result = (String)getStatResult("cdr", "median", VAL_TYPE.DATE);
+    String calculated = (String)getStatResult("cdr", "medianc", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), result, calculated);
+    assertEquals(getRawResponse(), result, calculated);
+    
+    result = (String)getStatResult("cdr", "max", VAL_TYPE.DATE);
+    calculated = (String)getStatResult("cdr", "maxc", VAL_TYPE.DATE);
+    assertEquals(getRawResponse(), result, calculated);
+  }
+  
+  @Test
+  public void constantStringTest() throws Exception { 
+    String result = (String)getStatResult("csr", "min", VAL_TYPE.STRING);
+    String calculated = (String)getStatResult("csr", "minc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+    
+    result = (String)getStatResult("csr", "max", VAL_TYPE.STRING);
+    calculated = (String)getStatResult("csr", "maxc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+  }
+  
+  @Test
+  public void concatenateTest() throws Exception { 
+    String result = (String)getStatResult("cr", "min", VAL_TYPE.STRING);
+    String calculated = (String)getStatResult("cr", "minc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+    
+    result = (String)getStatResult("cr", "max", VAL_TYPE.STRING);
+    calculated = (String)getStatResult("cr", "maxc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+  }
+  
+  @Test
+  public void reverseTest() throws Exception { 
+    String result = (String)getStatResult("rr", "min", VAL_TYPE.STRING);
+    String calculated = (String)getStatResult("rr", "minc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+    
+    result = (String)getStatResult("rr", "max", VAL_TYPE.STRING);
+    calculated = (String)getStatResult("rr", "maxc", VAL_TYPE.STRING);
+    assertEquals(getRawResponse(), result, calculated);
+  }
+  
+  @Test
+  public void missingTest() throws Exception { 
+    double min = (Double)getStatResult("ms", "min", VAL_TYPE.DOUBLE);
+    double max = (Double)getStatResult("ms", "max", VAL_TYPE.DOUBLE);
+    assertEquals(getRawResponse(), 48.0d, max, 0.0);
+    assertEquals(getRawResponse(), 1.0d, min, 0.0);
+  }
+
+}
diff --git solr/core/src/test/org/apache/solr/handler/component/StatsComponentTest.java solr/core/src/test/org/apache/solr/handler/component/StatsComponentTest.java
index 01f33fb..fd1382e 100644
--- solr/core/src/test/org/apache/solr/handler/component/StatsComponentTest.java
+++ solr/core/src/test/org/apache/solr/handler/component/StatsComponentTest.java
@@ -46,8 +46,6 @@ import org.junit.BeforeClass;
 @LuceneTestCase.SuppressCodecs({"Lucene40", "Lucene41", "Lucene42"})
 public class StatsComponentTest extends AbstractSolrTestCase {
 
-  final static String XPRE = "/response/lst[@name='stats']/";
-
   @BeforeClass
   public static void beforeClass() throws Exception {
     initCore("solrconfig.xml", "schema11.xml");
@@ -72,7 +70,6 @@ public class StatsComponentTest extends AbstractSolrTestCase {
       // all of our checks should work with all of these params
       // ie: with or w/o these excluded filters, results should be the same.
       SolrParams[] baseParamsSet = new SolrParams[] {
-        // NOTE: doTestFieldStatisticsResult needs the full list of possible tags to exclude
         params("stats.field", f, "stats", "true"),
         params("stats.field", "{!ex=fq1,fq2}"+f, "stats", "true",
                "fq", "{!tag=fq1}-id:[0 TO 2]", 
@@ -103,12 +100,6 @@ public class StatsComponentTest extends AbstractSolrTestCase {
   }
 
   public void doTestFieldStatisticsResult(String f, SolrParams[] baseParamsSet) throws Exception {
-    // used when doing key overrides in conjunction with the baseParamsSet
-    //
-    // even when these aren't included in the request, using them helps us
-    // test the code path of an exclusion that refers to an fq that doesn't exist
-    final String all_possible_ex = "fq1,fq2";
-
     assertU(adoc("id", "1", f, "-10"));
     assertU(adoc("id", "2", f, "-20"));
     assertU(commit());
@@ -116,80 +107,39 @@ public class StatsComponentTest extends AbstractSolrTestCase {
     assertU(adoc("id", "4", f, "-40"));
     assertU(commit());
 
-    final String fpre = XPRE + "lst[@name='stats_fields']/lst[@name='"+f+"']/";
-
-    final String key = "key_key";
-    final String kpre = XPRE + "lst[@name='stats_fields']/lst[@name='"+key+"']/";
-
     // status should be the same regardless of baseParams
     for (SolrParams baseParams : baseParamsSet) {
-      for (String ct : new String[] {"stats.calcdistinct", "f."+f+".stats.calcdistinct"}) {
-        assertQ("test statistics values using: " + ct, 
-                req(baseParams, "q", "*:*", ct, "true")
-                , fpre + "double[@name='min'][.='-40.0']"
-                , fpre + "double[@name='max'][.='-10.0']"
-                , fpre + "double[@name='sum'][.='-100.0']"
-                , fpre + "long[@name='count'][.='4']"
-                , fpre + "long[@name='missing'][.='0']"
-                , fpre + "long[@name='countDistinct'][.='4']"
-                , "count(" + fpre + "arr[@name='distinctValues']/*)=4"
-                , fpre + "double[@name='sumOfSquares'][.='3000.0']"
-                , fpre + "double[@name='mean'][.='-25.0']"
-                , fpre + "double[@name='stddev'][.='12.909944487358056']"
-                );  
-        
-        assertQ("test statistics w/fq using: " + ct, 
-                req(baseParams, "q", "*:*", "fq", "-id:4", ct, "true")
-                , fpre + "double[@name='min'][.='-30.0']"
-                , fpre + "double[@name='max'][.='-10.0']"
-                , fpre + "double[@name='sum'][.='-60.0']"
-                , fpre + "long[@name='count'][.='3']"
-                , fpre + "long[@name='missing'][.='0']"
-                , fpre + "long[@name='countDistinct'][.='3']"
-                , "count(" + fpre + "arr[@name='distinctValues']/*)=3"
-                , fpre + "double[@name='sumOfSquares'][.='1400.0']"
-                , fpre + "double[@name='mean'][.='-20.0']"
-                , fpre + "double[@name='stddev'][.='10.0']"
-                );  
-        
-        // now do both in a single query
-
-        assertQ("test statistics w & w/fq via key override using: " + ct, 
-                req(baseParams, "q", "*:*", ct, "true",
-                    "fq", "{!tag=key_ex_tag}-id:4", 
-                    "stats.field", "{!key="+key+" ex=key_ex_tag,"+all_possible_ex+"}"+f)
-
-                // field name key, fq is applied
-                , fpre + "double[@name='min'][.='-30.0']"
-                , fpre + "double[@name='max'][.='-10.0']"
-                , fpre + "double[@name='sum'][.='-60.0']"
-                , fpre + "long[@name='count'][.='3']"
-                , fpre + "long[@name='missing'][.='0']"
-                , fpre + "long[@name='countDistinct'][.='3']"
-                , "count(" + fpre + "arr[@name='distinctValues']/*)=3"
-                , fpre + "double[@name='sumOfSquares'][.='1400.0']"
-                , fpre + "double[@name='mean'][.='-20.0']"
-                , fpre + "double[@name='stddev'][.='10.0']"
-
-                // overridden key, fq is excluded
-                , kpre + "double[@name='min'][.='-40.0']"
-                , kpre + "double[@name='max'][.='-10.0']"
-                , kpre + "double[@name='sum'][.='-100.0']"
-                , kpre + "long[@name='count'][.='4']"
-                , kpre + "long[@name='missing'][.='0']"
-                , kpre + "long[@name='countDistinct'][.='4']"
-                , "count(" + kpre + "arr[@name='distinctValues']/*)=4"
-                , kpre + "double[@name='sumOfSquares'][.='3000.0']"
-                , kpre + "double[@name='mean'][.='-25.0']"
-                , kpre + "double[@name='stddev'][.='12.909944487358056']"
-
-                );  
-
-        
-
-      }
-    }
 
+      assertQ("test statistics values", 
+              req(baseParams, "q", "*:*", "stats.calcdistinct", "true")
+              , "//double[@name='min'][.='-40.0']"
+              , "//double[@name='max'][.='-10.0']"
+              , "//double[@name='sum'][.='-100.0']"
+              , "//long[@name='count'][.='4']"
+              , "//long[@name='missing'][.='0']"
+              , "//long[@name='countDistinct'][.='4']"
+              , "count(//arr[@name='distinctValues']/*)=4"
+              , "//double[@name='sumOfSquares'][.='3000.0']"
+              , "//double[@name='mean'][.='-25.0']"
+              , "//double[@name='stddev'][.='12.909944487358056']"
+              );  
+
+      assertQ("test statistics w/fq", 
+              req(baseParams, 
+                  "q", "*:*", "fq", "-id:4",
+                  "stats.calcdistinct", "true")
+              , "//double[@name='min'][.='-30.0']"
+              , "//double[@name='max'][.='-10.0']"
+              , "//double[@name='sum'][.='-60.0']"
+              , "//long[@name='count'][.='3']"
+              , "//long[@name='missing'][.='0']"
+              , "//long[@name='countDistinct'][.='3']"
+              , "count(//arr[@name='distinctValues']/*)=3"
+              , "//double[@name='sumOfSquares'][.='1400.0']"
+              , "//double[@name='mean'][.='-20.0']"
+              , "//double[@name='stddev'][.='10.0']"
+              );  
+    }
   }
 
 
diff --git solr/example/example-DIH/solr/db/conf/schema.xml solr/example/example-DIH/solr/db/conf/schema.xml
index 0e2badc..dfcaf36 100755
--- solr/example/example-DIH/solr/db/conf/schema.xml
+++ solr/example/example-DIH/solr/db/conf/schema.xml
@@ -615,7 +615,7 @@
              See the Java Regular Expression documentation for more
              information on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/example/example-DIH/solr/mail/conf/schema.xml solr/example/example-DIH/solr/mail/conf/schema.xml
index 9f83427..5486762 100755
--- solr/example/example-DIH/solr/mail/conf/schema.xml
+++ solr/example/example-DIH/solr/mail/conf/schema.xml
@@ -534,7 +534,7 @@
              See the Java Regular Expression documentation for more
              information on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/example/example-DIH/solr/rss/conf/schema.xml solr/example/example-DIH/solr/rss/conf/schema.xml
index c95c6b2..1fff650 100755
--- solr/example/example-DIH/solr/rss/conf/schema.xml
+++ solr/example/example-DIH/solr/rss/conf/schema.xml
@@ -565,7 +565,7 @@
              See the Java Regular Expression documentation for more
              information on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/example/example-DIH/solr/solr/conf/schema.xml solr/example/example-DIH/solr/solr/conf/schema.xml
index f5b0ed5..ab8823a 100755
--- solr/example/example-DIH/solr/solr/conf/schema.xml
+++ solr/example/example-DIH/solr/solr/conf/schema.xml
@@ -615,7 +615,7 @@
              See the Java Regular Expression documentation for more
              information on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/example/solr/collection1/conf/schema.xml solr/example/solr/collection1/conf/schema.xml
index 99022e7..9acf20f 100755
--- solr/example/solr/collection1/conf/schema.xml
+++ solr/example/solr/collection1/conf/schema.xml
@@ -615,7 +615,7 @@
              See the Java Regular Expression documentation for more
              information on pattern and replacement string syntax.
              
-             http://docs.oracle.com/javase/7/docs/api/java/util/regex/package-summary.html
+             http://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html
           -->
         <filter class="solr.PatternReplaceFilterFactory"
                 pattern="([^a-z])" replacement="" replace="all"
diff --git solr/site/html/tutorial.html solr/site/html/tutorial.html
index db5dfb1..725c1aa 100755
--- solr/site/html/tutorial.html
+++ solr/site/html/tutorial.html
@@ -54,13 +54,13 @@ To follow along with this tutorial, you will need...
 </p>
 <ol>
   
-<li>Java 1.7 or greater.  Some places you can get it are from
+<li>Java 1.8 or greater.  Some places you can get it are from
   <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Oracle</a>,
   <a href="http://openjdk.java.net/">Open JDK</a>, or
   <a href="http://www.ibm.com/developerworks/java/jdk/">IBM</a>.
   <ul>
     <li>Running <span class="codefrag">java -version</span> at the command 
-      line should indicate a version number starting with 1.7.
+      line should indicate a version number starting with 1.8.
     </li>
     <li>Gnu's GCJ is not supported and does not work with Solr.</li>
   </ul>
