Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java	(revision 1711436)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopAnalyzer;
@@ -25,9 +28,6 @@
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 
-import java.io.IOException;
-import java.io.Reader;
-
 /**
  * Filters {@link ClassicTokenizer} with {@link ClassicFilter}, {@link
  * LowerCaseFilter} and {@link StopFilter}, using a list of
@@ -94,7 +94,7 @@
     tok = new StopFilter(tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void setReader(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) {
         src.setMaxTokenLength(ClassicAnalyzer.this.maxTokenLength);
         super.setReader(reader);
       }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java	(revision 1711436)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopAnalyzer;
@@ -25,9 +28,6 @@
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 
-import java.io.IOException;
-import java.io.Reader;
-
 /**
  * Filters {@link StandardTokenizer} with {@link StandardFilter}, {@link
  * LowerCaseFilter} and {@link StopFilter}, using a list of
@@ -89,7 +89,7 @@
     tok = new StopFilter(tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void setReader(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) {
         src.setMaxTokenLength(StandardAnalyzer.this.maxTokenLength);
         super.setReader(reader);
       }
Index: lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java
===================================================================
--- lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java	(revision 1711436)
+++ lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java	(working copy)
@@ -17,6 +17,9 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopAnalyzer;
@@ -24,9 +27,6 @@
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 
-import java.io.IOException;
-import java.io.Reader;
-
 /**
  * Filters {@link org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer}
  * with {@link org.apache.lucene.analysis.standard.StandardFilter},
@@ -91,7 +91,7 @@
     tok = new StopFilter(tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void setReader(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) {
         src.setMaxTokenLength(UAX29URLEmailAnalyzer.this.maxTokenLength);
         super.setReader(reader);
       }
Index: lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java
===================================================================
--- lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java	(revision 1711436)
+++ lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java	(working copy)
@@ -1,6 +1,5 @@
 package org.apache.lucene.analysis.miscellaneous;
 
-import java.io.IOException;
 import java.io.Reader;
 import java.util.Collections;
 import java.util.Map;
@@ -16,7 +15,6 @@
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.Rethrow;
 
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
@@ -105,11 +103,7 @@
 
       @Override
       protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {
-        try {
-          assertNotSame(specialAnalyzer.tokenStream("special", text), components.getTokenStream());
-        } catch (IOException e) {
-          Rethrow.rethrow(e);
-        }
+        assertNotSame(specialAnalyzer.tokenStream("special", text), components.getTokenStream());
         TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());
         return new TokenStreamComponents(components.getTokenizer(), filter);
       }
Index: lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java	(revision 1711436)
+++ lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java	(working copy)
@@ -17,10 +17,6 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.store.AlreadyClosedException;
-import org.apache.lucene.util.CloseableThreadLocal;
-import org.apache.lucene.util.Version;
-
 import java.io.Closeable;
 import java.io.IOException;
 import java.io.Reader;
@@ -27,6 +23,10 @@
 import java.util.HashMap;
 import java.util.Map;
 
+import org.apache.lucene.store.AlreadyClosedException;
+import org.apache.lucene.util.CloseableThreadLocal;
+import org.apache.lucene.util.Version;
+
 /**
  * An Analyzer builds TokenStreams, which analyze text.  It thus represents a
  * policy for extracting index terms from text.
@@ -131,11 +131,10 @@
    * @param reader the reader the streams source reads from
    * @return TokenStream for iterating the analyzed content of <code>reader</code>
    * @throws AlreadyClosedException if the Analyzer is closed.
-   * @throws IOException if an i/o error occurs.
    * @see #tokenStream(String, String)
    */
   public final TokenStream tokenStream(final String fieldName,
-                                       final Reader reader) throws IOException {
+                                       final Reader reader) {
     TokenStreamComponents components = reuseStrategy.getReusableComponents(this, fieldName);
     final Reader r = initReader(fieldName, reader);
     if (components == null) {
@@ -168,7 +167,7 @@
    * @throws IOException if an i/o error occurs (may rarely happen for strings).
    * @see #tokenStream(String, Reader)
    */
-  public final TokenStream tokenStream(final String fieldName, final String text) throws IOException {
+  public final TokenStream tokenStream(final String fieldName, final String text) {
     TokenStreamComponents components = reuseStrategy.getReusableComponents(this, fieldName);
     @SuppressWarnings("resource") final ReusableStringReader strReader = 
         (components == null || components.reusableStringReader == null) ?
@@ -313,10 +312,8 @@
      * 
      * @param reader
      *          a reader to reset the source component
-     * @throws IOException
-     *           if the component's reset method throws an {@link IOException}
      */
-    protected void setReader(final Reader reader) throws IOException {
+    protected void setReader(final Reader reader) {
       source.setReader(reader);
     }
 
Index: lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java	(revision 1711436)
+++ lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java	(working copy)
@@ -17,12 +17,12 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+
 import org.apache.lucene.util.AttributeFactory;
 import org.apache.lucene.util.AttributeSource;
 
-import java.io.Reader;
-import java.io.IOException;
-
 /** A Tokenizer is a TokenStream whose input is a Reader.
   <p>
   This is an abstract class; subclasses must override {@link #incrementToken()}
@@ -83,7 +83,7 @@
   /** Expert: Set a new reader on the Tokenizer.  Typically, an
    *  analyzer (in its tokenStream method) will use
    *  this to re-use a previously created tokenizer. */
-  public final void setReader(Reader input) throws IOException {
+  public final void setReader(Reader input) {
     if (input == null) {
       throw new NullPointerException("input must not be null");
     } else if (this.input != ILLEGAL_STATE_READER) {
Index: lucene/core/src/test/org/apache/lucene/document/TestDocument.java
===================================================================
--- lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(revision 1711436)
+++ lucene/core/src/test/org/apache/lucene/document/TestDocument.java	(working copy)
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.io.IOException;
 import java.io.StringReader;
 import java.nio.charset.StandardCharsets;
 import java.util.List;
@@ -356,8 +355,6 @@
       fail("did not hit expected exc");
     } catch (IllegalArgumentException iae) {
       // expected
-    } catch (IOException ioe) {
-      throw new RuntimeException(ioe);
     }
   }
   
Index: lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
===================================================================
--- lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(revision 1711436)
+++ lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java	(working copy)
@@ -246,11 +246,7 @@
   @Deprecated // maintenance reasons LUCENE-6445
   public static TokenStream getTokenStream(String field, String contents,
       Analyzer analyzer) {
-    try {
-      return analyzer.tokenStream(field, contents);
-    } catch (IOException ex) {
-      throw new RuntimeException(ex);
-    }
+    return analyzer.tokenStream(field, contents);
   }
 
 }
Index: lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
===================================================================
--- lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(revision 1711436)
+++ lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java	(working copy)
@@ -284,13 +284,7 @@
     if (analyzer == null)
       throw new IllegalArgumentException("analyzer must not be null");
     
-    TokenStream stream;
-    try {
-      stream = analyzer.tokenStream(fieldName, text);
-    } catch (IOException ex) {
-      throw new RuntimeException(ex);
-    }
-
+    TokenStream stream = analyzer.tokenStream(fieldName, text);
     addField(fieldName, stream, 1.0f, analyzer.getPositionIncrementGap(fieldName), analyzer.getOffsetGap(fieldName));
   }
 
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java	(revision 1711436)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java	(working copy)
@@ -329,7 +329,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -397,7 +397,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -472,7 +472,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader)  {
           }
         };
       }
@@ -998,7 +998,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -1068,7 +1068,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -1142,7 +1142,7 @@
             }
          
             @Override
-            protected void setReader(final Reader reader) throws IOException {
+            protected void setReader(final Reader reader) {
             }
           };
         }
@@ -1205,7 +1205,7 @@
             }
          
             @Override
-            protected void setReader(final Reader reader) throws IOException {
+            protected void setReader(final Reader reader) {
             }
           };
         }
Index: lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java
===================================================================
--- lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java	(revision 1711436)
+++ lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java	(working copy)
@@ -281,7 +281,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -360,7 +360,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
@@ -431,7 +431,7 @@
           }
          
           @Override
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
           }
         };
       }
Index: solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/TokenizeTextBuilder.java
===================================================================
--- solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/TokenizeTextBuilder.java	(revision 1711436)
+++ solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/TokenizeTextBuilder.java	(working copy)
@@ -81,11 +81,8 @@
       }
       this.analyzer = fieldType.getIndexAnalyzer();
       Preconditions.checkNotNull(analyzer);
-      try { // register CharTermAttribute for later (implicit) reuse
-        this.token = analyzer.tokenStream("content", reader).addAttribute(CharTermAttribute.class);
-      } catch (IOException e) {
-        throw new MorphlineCompilationException("Cannot create token stream", config, e);
-      }
+      // register CharTermAttribute for later (implicit) reuse
+      this.token = analyzer.tokenStream("content", reader).addAttribute(CharTermAttribute.class);
       Preconditions.checkNotNull(token);
       validateArguments();
     }
Index: solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
===================================================================
--- solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java	(revision 1711436)
+++ solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java	(working copy)
@@ -17,37 +17,47 @@
 
 package org.apache.solr.handler;
 
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.commons.lang.ArrayUtils;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.tokenattributes.*;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.Attribute;
 import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.AttributeReflector;
-import org.apache.lucene.util.CharsRef;
-import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.IOUtils;
 import org.apache.solr.analysis.TokenizerChain;
+import org.apache.solr.common.SolrException;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.SimpleOrderedMap;
-import org.apache.solr.common.SolrException;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.response.SolrQueryResponse;
 import org.apache.solr.schema.FieldType;
 
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.*;
-
-import org.apache.commons.lang.ArrayUtils;
-
 /**
  * A base class for all analysis request handlers.
  *
@@ -114,11 +124,7 @@
     }
 
     TokenStream tokenStream = tfac.create();
-    try {
-      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));
-    } catch (IOException e) {
-      throw new RuntimeException(e);
-    }
+    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));
     List<AttributeSource> tokens = analyzeTokenStream(tokenStream);
 
     namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));
Index: solr/core/src/java/org/apache/solr/schema/AbstractSpatialPrefixTreeFieldType.java
===================================================================
--- solr/core/src/java/org/apache/solr/schema/AbstractSpatialPrefixTreeFieldType.java	(revision 1711436)
+++ solr/core/src/java/org/apache/solr/schema/AbstractSpatialPrefixTreeFieldType.java	(working copy)
@@ -85,9 +85,13 @@
         return new TokenStreamComponents(new KeywordTokenizer()) {
           private Shape shape = null;
           
-          protected void setReader(final Reader reader) throws IOException {
+          protected void setReader(final Reader reader) {
             source.setReader(reader);
-            shape = parseShape(IOUtils.toString(reader));
+            try {
+              shape = parseShape(IOUtils.toString(reader));
+            } catch (IOException e) {
+              throw new RuntimeException(e);
+            }
           }
           
           public TokenStream getTokenStream() {
