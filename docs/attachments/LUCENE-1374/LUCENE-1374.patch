Index: src/test/org/apache/lucene/index/TestIndexWriter.java
===================================================================
--- src/test/org/apache/lucene/index/TestIndexWriter.java	(revision 689791)
+++ src/test/org/apache/lucene/index/TestIndexWriter.java	(working copy)
@@ -3797,4 +3797,37 @@
     dir.close();
   }
   
+  public void testMergeCompressedFields() throws IOException {
+    File indexDir = new File(System.getProperty("tempDir"), "mergecompressedfields");
+    Directory dir = FSDirectory.getDirectory(indexDir);
+    try {
+      for(int i=0;i<5;i++) {
+        // Must make a new writer & doc each time, w/
+        // different fields, so bulk merge of stored fields
+        // cannot run:
+        IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), i==0, IndexWriter.MaxFieldLength.UNLIMITED);
+        w.setMergeFactor(5);
+        w.setMergeScheduler(new SerialMergeScheduler());
+        Document doc = new Document();
+        doc.add(new Field("test1", "this is some data that will be compressed this this this", Field.Store.COMPRESS, Field.Index.NO));
+        doc.add(new Field("test2", new byte[20], Field.Store.COMPRESS));
+        doc.add(new Field("field" + i, "random field", Field.Store.NO, Field.Index.TOKENIZED));
+        w.addDocument(doc);
+        w.close();
+      }
+
+      byte[] cmp = new byte[20];
+
+      IndexReader r = IndexReader.open(dir);
+      for(int i=0;i<5;i++) {
+        Document doc = r.document(i);
+        assertEquals("this is some data that will be compressed this this this", doc.getField("test1").stringValue());
+        byte[] b = doc.getField("test2").binaryValue();
+        assertTrue(Arrays.equals(b, cmp));
+      }
+    } finally {
+      dir.close();
+      _TestUtil.rmDir(indexDir);
+    }
+  }
 }
Index: src/java/org/apache/lucene/index/FieldsWriter.java
===================================================================
--- src/java/org/apache/lucene/index/FieldsWriter.java	(revision 689791)
+++ src/java/org/apache/lucene/index/FieldsWriter.java	(working copy)
@@ -197,6 +197,7 @@
           // optimized case for merging, the data
           // is already compressed
           data = field.getBinaryValue();
+          assert data != null;
           len = field.getBinaryLength();
           offset = field.getBinaryOffset();  
         } else {
Index: src/java/org/apache/lucene/document/AbstractField.java
===================================================================
--- src/java/org/apache/lucene/document/AbstractField.java	(revision 689791)
+++ src/java/org/apache/lucene/document/AbstractField.java	(working copy)
@@ -218,7 +218,10 @@
   }
   
   public byte[] getBinaryValue(byte[] result){
-    return isBinary ? (byte[]) fieldsData : null;
+    if (isBinary || fieldsData instanceof byte[])
+      return (byte[]) fieldsData;
+    else
+      return null;
   }
 
   /**
@@ -227,8 +230,16 @@
    * @return length of byte[] segment that represents this Field value
    */
   public int getBinaryLength() {
-     return binaryLength;
-    }
+    if (isBinary) {
+      if (!isCompressed)
+        return binaryLength;
+      else
+        return ((byte[]) fieldsData).length;
+    } else if (fieldsData instanceof byte[])
+      return ((byte[]) fieldsData).length;
+    else
+      return 0;
+  }
 
   /**
    * Returns offset into byte[] segment that is used as value, if Field is not binary
