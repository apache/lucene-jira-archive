Index: lucene/core/src/java/org/apache/lucene/search/BulkScorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BulkScorer.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/BulkScorer.java	(working copy)
@@ -43,4 +43,8 @@
    * @return true if more matching documents may remain.
    */
   public abstract boolean score(LeafCollector collector, int max) throws IOException;
+  
+  public float getBackGroundScore(int doc) throws IOException{
+    return 0;
+  }
 }
Index: lucene/core/src/java/org/apache/lucene/search/TermScorerDirichletLM.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TermScorerDirichletLM.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/TermScorerDirichletLM.java	(revision 0)
@@ -0,0 +1,102 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.search.similarities.Similarity;
+
+/** Expert: A <code>Scorer</code> for documents matching a <code>Term</code>.
+ */
+final class TermScorerDirichletLM extends Scorer {
+  private final DocsEnum docsEnum;
+  private final Similarity.SimScorer docScorer;
+  
+  /**
+   * Construct a <code>TermScorer</code>.
+   * 
+   * @param weight
+   *          The weight of the <code>Term</code> in the query.
+   * @param td
+   *          An iterator over the documents matching the <code>Term</code>.
+   * @param docScorer
+   *          The </code>Similarity.SimScorer</code> implementation 
+   *          to be used for score computations.
+   */
+  TermScorerDirichletLM(Weight weight, DocsEnum td, Similarity.SimScorer docScorer) {
+    super(weight);
+    this.docScorer = docScorer;
+    this.docsEnum = td;
+  }
+
+  @Override
+  public int docID() {
+    return docsEnum.docID();
+  }
+
+  @Override
+  public int freq() throws IOException {
+    return docsEnum.freq();
+  }
+
+  /**
+   * Advances to the next document matching the query. <br>
+   * 
+   * @return the document matching the query or NO_MORE_DOCS if there are no more documents.
+   */
+  @Override
+  public int nextDoc() throws IOException {
+    return docsEnum.nextDoc();
+  }
+  
+  @Override
+  public float score() throws IOException {
+    assert docID() != NO_MORE_DOCS;
+    return docScorer.score(docsEnum.docID(), docsEnum.freq());  
+  }
+  
+  @Override
+  public float background(int doc) throws IOException{
+    assert docID() != NO_MORE_DOCS;
+    return docScorer.background(doc);  
+  }
+
+  /**
+   * Advances to the first match beyond the current whose document number is
+   * greater than or equal to a given target. <br>
+   * The implementation uses {@link DocsEnum#advance(int)}.
+   * 
+   * @param target
+   *          The target document number.
+   * @return the matching document or NO_MORE_DOCS if none exist.
+   */
+  @Override
+  public int advance(int target) throws IOException {
+    return docsEnum.advance(target);
+  }
+  
+  @Override
+  public long cost() {
+    return docsEnum.cost();
+  }
+
+  /** Returns a string representation of this <code>TermScorer</code>. */
+  @Override
+  public String toString() { return "scorer(" + weight + ")"; }
+}
Index: lucene/core/src/java/org/apache/lucene/search/BooleanScorerDirichletLM.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BooleanScorerDirichletLM.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/BooleanScorerDirichletLM.java	(revision 0)
@@ -0,0 +1,287 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.search.BooleanQuery.BooleanWeight;
+import org.apache.lucene.search.BooleanQueryDirichletLM.BooleanWeightDirichletLM;
+
+/* Description from Doug Cutting (excerpted from
+ * LUCENE-1483):
+ *
+ * BooleanScorer uses an array to score windows of
+ * 2K docs. So it scores docs 0-2K first, then docs 2K-4K,
+ * etc. For each window it iterates through all query terms
+ * and accumulates a score in table[doc%2K]. It also stores
+ * in the table a bitmask representing which terms
+ * contributed to the score. Non-zero scores are chained in
+ * a linked list. At the end of scoring each window it then
+ * iterates through the linked list and, if the bitmask
+ * matches the boolean constraints, collects a hit. For
+ * boolean queries with lots of frequent terms this can be
+ * much faster, since it does not need to update a priority
+ * queue for each posting, instead performing constant-time
+ * operations per posting. The only downside is that it
+ * results in hits being delivered out-of-order within the
+ * window, which means it cannot be nested within other
+ * scorers. But it works well as a top-level scorer.
+ *
+ * The new BooleanScorer2 implementation instead works by
+ * merging priority queues of postings, albeit with some
+ * clever tricks. For example, a pure conjunction (all terms
+ * required) does not require a priority queue. Instead it
+ * sorts the posting streams at the start, then repeatedly
+ * skips the first to to the last. If the first ever equals
+ * the last, then there's a hit. When some terms are
+ * required and some terms are optional, the conjunction can
+ * be evaluated first, then the optional terms can all skip
+ * to the match and be added to the score. Thus the
+ * conjunction can reduce the number of priority queue
+ * updates for the optional terms. */
+
+final class BooleanScorerDirichletLM extends BulkScorer {
+  
+  private static final class BooleanScorerCollector extends SimpleCollector {
+    private BucketTable bucketTable;
+    private int mask;
+    private Scorer scorer;
+    
+    public BooleanScorerCollector(int mask, BucketTable bucketTable) {
+      this.mask = mask;
+      this.bucketTable = bucketTable;
+    }
+    
+    @Override
+    public void collect(final int doc) throws IOException {
+      final BucketTable table = bucketTable;
+      final int i = doc & BucketTable.MASK;
+      final Bucket bucket = table.buckets[i];
+      
+      if (bucket.doc != doc) {                    // invalid bucket
+        bucket.doc = doc;                         // set doc
+        bucket.score = scorer.score();            // initialize score
+        bucket.bits = mask;                       // initialize mask
+        bucket.coord = 1;                         // initialize coord
+
+        bucket.next = table.first;                // push onto valid list
+        table.first = bucket;
+      } else {                                    // valid bucket
+        bucket.score += scorer.score();           // increment score
+        bucket.bits |= mask;                      // add bits in mask
+        bucket.coord++;                           // increment coord
+      }
+    }
+    
+    @Override
+    public void setScorer(Scorer scorer) {
+      this.scorer = scorer;
+    }
+    
+    @Override
+    public boolean acceptsDocsOutOfOrder() {
+      return true;
+    }
+
+  }
+  
+  static final class Bucket {
+    int doc = -1;            // tells if bucket is valid
+    double score;             // incremental score
+    // TODO: break out bool anyProhibited, int
+    // numRequiredMatched; then we can remove 32 limit on
+    // required clauses
+    int bits;                // used for bool constraints
+    int coord;               // count of terms in score
+    Bucket next;             // next valid bucket
+  }
+  
+  /** A simple hash table of document scores within a range. */
+  static final class BucketTable {
+    public static final int SIZE = 1 << 11;
+    public static final int MASK = SIZE - 1;
+
+    final Bucket[] buckets = new Bucket[SIZE];
+    Bucket first = null;                          // head of valid list
+  
+    public BucketTable() {
+      // Pre-fill to save the lazy init when collecting
+      // each sub:
+      for(int idx=0;idx<SIZE;idx++) {
+        buckets[idx] = new Bucket();
+      }
+    }
+
+    public LeafCollector newCollector(int mask) {
+      return new BooleanScorerCollector(mask, this);
+    }
+
+    public int size() { return SIZE; }
+  }
+
+  static final class SubScorer {
+    public BulkScorer scorer;
+    // TODO: re-enable this if BQ ever sends us required clauses
+    //public boolean required = false;
+    public boolean prohibited;
+    public LeafCollector collector;
+    public SubScorer next;
+    public boolean more;
+
+    public SubScorer(BulkScorer scorer, boolean required, boolean prohibited,
+        LeafCollector collector, SubScorer next) {
+      if (required) {
+        throw new IllegalArgumentException("this scorer cannot handle required=true");
+      }
+      this.scorer = scorer;
+      this.more = true;
+      // TODO: re-enable this if BQ ever sends us required clauses
+      //this.required = required;
+      this.prohibited = prohibited;
+      this.collector = collector;
+      this.next = next;
+    }
+  }
+  
+  private SubScorer scorers = null;
+  private BucketTable bucketTable = new BucketTable();
+  private final float[] coordFactors;
+  // TODO: re-enable this if BQ ever sends us required clauses
+  //private int requiredMask = 0;
+  private final int minNrShouldMatch;
+  private int end;
+  private Bucket current;
+  // Any time a prohibited clause matches we set bit 0:
+  private static final int PROHIBITED_MASK = 1;
+
+  private final Weight weight;
+
+  BooleanScorerDirichletLM(BooleanWeightDirichletLM weight, boolean disableCoord, int minNrShouldMatch,
+      List<BulkScorer> optionalScorers, List<BulkScorer> prohibitedScorers, int maxCoord) throws IOException {
+    this.minNrShouldMatch = minNrShouldMatch;
+    this.weight = weight;
+
+    for (BulkScorer scorer : optionalScorers) {
+      scorers = new SubScorer(scorer, false, false, bucketTable.newCollector(0), scorers);
+    }
+    
+    for (BulkScorer scorer : prohibitedScorers) {
+      scorers = new SubScorer(scorer, false, true, bucketTable.newCollector(PROHIBITED_MASK), scorers);
+    }
+
+    coordFactors = new float[optionalScorers.size() + 1];
+    for (int i = 0; i < coordFactors.length; i++) {
+      coordFactors[i] = disableCoord ? 1.0f : weight.coord(i, maxCoord); 
+    }
+  }
+  
+  @Override
+  public float getBackGroundScore(int doc) throws IOException {
+    float bck = 0;
+    for (SubScorer sub = scorers; sub != null; sub = sub.next) {
+      bck+=sub.scorer.getBackGroundScore(doc);
+    }
+    return bck;
+  }
+
+  @Override
+  public boolean score(LeafCollector collector, int max) throws IOException {
+
+    boolean more;
+    Bucket tmp;
+    FakeScorer fs = new FakeScorer();
+
+    // The internal loop will set the score and doc before calling collect.
+    collector.setScorer(fs);
+    do {
+      bucketTable.first = null;
+      
+      while (current != null) {         // more queued 
+
+        // check prohibited & required
+        if ((current.bits & PROHIBITED_MASK) == 0) {
+
+          // TODO: re-enable this if BQ ever sends us required
+          // clauses
+          //&& (current.bits & requiredMask) == requiredMask) {
+          
+          // NOTE: Lucene always passes max =
+          // Integer.MAX_VALUE today, because we never embed
+          // a BooleanScorer inside another (even though
+          // that should work)... but in theory an outside
+          // app could pass a different max so we must check
+          // it:
+          if (current.doc >= max) {
+            tmp = current;
+            current = current.next;
+            tmp.next = bucketTable.first;
+            bucketTable.first = tmp;
+            continue;
+          }
+          
+          if (current.coord >= minNrShouldMatch) {
+            fs.background = this.getBackGroundScore(current.doc);
+            fs.score = (float) (current.score * coordFactors[current.coord]);
+            fs.doc = current.doc;
+            fs.freq = current.coord;
+            collector.collect(current.doc);
+          }
+        }
+        
+        current = current.next;         // pop the queue
+      }
+      
+      if (bucketTable.first != null){
+        current = bucketTable.first;
+        bucketTable.first = current.next;
+        return true;
+      }
+
+      // refill the queue
+      more = false;
+      end += BucketTable.SIZE;
+      for (SubScorer sub = scorers; sub != null; sub = sub.next) {
+        if (sub.more) {
+          sub.more = sub.scorer.score(sub.collector, end);
+          more |= sub.more;
+        }
+      }
+      current = bucketTable.first;
+      
+    } while (current != null || more);
+
+    return false;
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder buffer = new StringBuilder();
+    buffer.append("boolean(");
+    for (SubScorer sub = scorers; sub != null; sub = sub.next) {
+      buffer.append(sub.scorer.toString());
+      buffer.append(" ");
+    }
+    buffer.append(")");
+    return buffer.toString();
+  }
+}
Index: lucene/core/src/java/org/apache/lucene/search/TermQueryDirichletLM.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TermQueryDirichletLM.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/TermQueryDirichletLM.java	(revision 0)
@@ -0,0 +1,212 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.DocsEnum;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.IndexReaderContext;
+import org.apache.lucene.index.ReaderUtil;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
+import org.apache.lucene.index.TermState;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.similarities.Similarity.SimScorer;
+import org.apache.lucene.search.similarities.Similarity;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+
+/** A Query that matches documents containing a term.
+  This may be combined with other terms with a {@link BooleanQuery}.
+  */
+public class TermQueryDirichletLM extends Query {
+  private final Term term;
+  private final int docFreq;
+  private final TermContext perReaderTermState;
+
+  final class TermWeightDirichletLM extends Weight {
+    private final Similarity similarity;
+    private final Similarity.SimWeight stats;
+    private final TermContext termStates;
+
+    public TermWeightDirichletLM(IndexSearcher searcher, TermContext termStates)
+      throws IOException {
+      assert termStates != null : "TermContext must not be null";
+      this.termStates = termStates;
+      this.similarity = searcher.getSimilarity();
+      this.stats = similarity.computeWeight(
+          getBoost(), 
+          searcher.collectionStatistics(term.field()), 
+          searcher.termStatistics(term, termStates));
+    }
+
+    @Override
+    public String toString() { return "weight(" + TermQueryDirichletLM.this + ")"; }
+
+    @Override
+    public Query getQuery() { return TermQueryDirichletLM.this; }
+
+    @Override
+    public float getValueForNormalization() {
+      return stats.getValueForNormalization();
+    }
+
+    @Override
+    public void normalize(float queryNorm, float topLevelBoost) {
+      stats.normalize(queryNorm, topLevelBoost);
+    }
+
+    @Override
+    public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {
+      assert termStates.topReaderContext == ReaderUtil.getTopLevelContext(context) : "The top-reader used to create Weight (" + termStates.topReaderContext + ") is not the same as the current reader's top-reader (" + ReaderUtil.getTopLevelContext(context);
+      final TermsEnum termsEnum = getTermsEnum(context);
+      if (termsEnum == null) {
+        return null;
+      }
+      DocsEnum docs = termsEnum.docs(acceptDocs, null);
+      assert docs != null;
+      return new TermScorerDirichletLM(this, docs, similarity.simScorer(stats, context));
+    }
+    
+    /**
+     * Returns a {@link TermsEnum} positioned at this weights Term or null if
+     * the term does not exist in the given context
+     */
+    private TermsEnum getTermsEnum(AtomicReaderContext context) throws IOException {
+      final TermState state = termStates.get(context.ord);
+      if (state == null) { // term is not present in that reader
+        assert termNotInReader(context.reader(), term) : "no termstate found but term exists in reader term=" + term;
+        return null;
+      }
+      //System.out.println("LD=" + reader.getLiveDocs() + " set?=" + (reader.getLiveDocs() != null ? reader.getLiveDocs().get(0) : "null"));
+      final TermsEnum termsEnum = context.reader().terms(term.field()).iterator(null);
+      termsEnum.seekExact(term.bytes(), state);
+      return termsEnum;
+    }
+    
+    private boolean termNotInReader(AtomicReader reader, Term term) throws IOException {
+      // only called from assert
+      //System.out.println("TQ.termNotInReader reader=" + reader + " term=" + field + ":" + bytes.utf8ToString());
+      return reader.docFreq(term) == 0;
+    }
+    
+    @Override
+    public Explanation explain(AtomicReaderContext context, int doc) throws IOException {
+      Scorer scorer = scorer(context, context.reader().getLiveDocs());
+      if (scorer != null) {
+        int newDoc = scorer.advance(doc);
+        if (newDoc == doc) {
+          float freq = scorer.freq();
+          SimScorer docScorer = similarity.simScorer(stats, context);
+          ComplexExplanation result = new ComplexExplanation();
+          result.setDescription("weight("+getQuery()+" in "+doc+") [" + similarity.getClass().getSimpleName() + "], result of:");
+          Explanation scoreExplanation = docScorer.explain(doc, new Explanation(freq, "termFreq=" + freq));
+          result.addDetail(scoreExplanation);
+          result.setValue(scoreExplanation.getValue());
+          result.setMatch(true);
+          return result;
+        }
+      }
+      return new ComplexExplanation(false, 0.0f, "no matching term");      
+    }
+  }
+
+  /** Constructs a query for the term <code>t</code>. */
+  public TermQueryDirichletLM(Term t) {
+    this(t, -1);
+  }
+
+  /** Expert: constructs a TermQuery that will use the
+   *  provided docFreq instead of looking up the docFreq
+   *  against the searcher. */
+  public TermQueryDirichletLM(Term t, int docFreq) {
+    term = t;
+    this.docFreq = docFreq;
+    perReaderTermState = null;
+  }
+  
+  /** Expert: constructs a TermQuery that will use the
+   *  provided docFreq instead of looking up the docFreq
+   *  against the searcher. */
+  public TermQueryDirichletLM(Term t, TermContext states) {
+    assert states != null;
+    term = t;
+    docFreq = states.docFreq();
+    perReaderTermState = states;
+  }
+
+  /** Returns the term of this query. */
+  public Term getTerm() { return term; }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher) throws IOException {
+    final IndexReaderContext context = searcher.getTopReaderContext();
+    final TermContext termState;
+    if (perReaderTermState == null || perReaderTermState.topReaderContext != context) {
+      // make TermQuery single-pass if we don't have a PRTS or if the context differs!
+      termState = TermContext.build(context, term);
+    } else {
+     // PRTS was pre-build for this IS
+     termState = this.perReaderTermState;
+    }
+
+    // we must not ignore the given docFreq - if set use the given value (lie)
+    if (docFreq != -1)
+      termState.setDocFreq(docFreq);
+    
+    return new TermWeightDirichletLM(searcher, termState);
+  }
+
+  @Override
+  public void extractTerms(Set<Term> terms) {
+    terms.add(getTerm());
+  }
+
+  /** Prints a user-readable version of this query. */
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    if (!term.field().equals(field)) {
+      buffer.append(term.field());
+      buffer.append(":");
+    }
+    buffer.append(term.text());
+    buffer.append(ToStringUtils.boost(getBoost()));
+    return buffer.toString();
+  }
+
+  /** Returns true iff <code>o</code> is equal to this. */
+  @Override
+  public boolean equals(Object o) {
+    if (!(o instanceof TermQueryDirichletLM))
+      return false;
+    TermQueryDirichletLM other = (TermQueryDirichletLM)o;
+    return (this.getBoost() == other.getBoost())
+      && this.term.equals(other.term);
+  }
+
+  /** Returns a hash code value for this object.*/
+  @Override
+  public int hashCode() {
+    return Float.floatToIntBits(getBoost()) ^ term.hashCode();
+  }
+
+}
Index: lucene/core/src/java/org/apache/lucene/search/similarities/LMSimilarityAccurateDocLength.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/similarities/LMSimilarityAccurateDocLength.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/similarities/LMSimilarityAccurateDocLength.java	(revision 0)
@@ -0,0 +1,151 @@
+package org.apache.lucene.search.similarities;
+
+import java.util.Locale;
+
+import org.apache.lucene.search.CollectionStatistics;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.TermStatistics;
+import org.apache.lucene.search.similarities.LMSimilarity.CollectionModel;
+import org.apache.lucene.search.similarities.LMSimilarity.DefaultCollectionModel;
+import org.apache.lucene.search.similarities.LMSimilarity.LMStats;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public abstract class LMSimilarityAccurateDocLength extends SimilarityBaseAccurateDocLength {
+  /** The collection model. */
+  protected final CollectionModel collectionModel;
+  
+  /** Creates a new instance with the specified collection language model. */
+  public LMSimilarityAccurateDocLength(CollectionModel collectionModel) {
+    this.collectionModel = collectionModel;
+  }
+  
+  /** Creates a new instance with the default collection language model. */
+  public LMSimilarityAccurateDocLength() {
+    this(new DefaultCollectionModel());
+  }
+  
+  @Override
+  protected BasicStats newStats(String field, float queryBoost) {
+    return new LMStats(field, queryBoost);
+  }
+
+  /**
+   * Computes the collection probability of the current term in addition to the
+   * usual statistics.
+   */
+  @Override
+  protected void fillBasicStats(BasicStats stats, CollectionStatistics collectionStats, TermStatistics termStats) {
+    super.fillBasicStats(stats, collectionStats, termStats);
+    LMStats lmStats = (LMStats) stats;
+    lmStats.setCollectionProbability(collectionModel.computeProbability(stats));
+  }
+
+  @Override
+  protected void explain(Explanation expl, BasicStats stats, int doc,
+      float freq, float docLen) {
+    expl.addDetail(new Explanation(collectionModel.computeProbability(stats),
+                                   "collection probability"));
+  }
+  
+  /**
+   * Returns the name of the LM method. The values of the parameters should be
+   * included as well.
+   * <p>Used in {@link #toString()}</p>.
+   */
+  public abstract String getName();
+  
+  /**
+   * Returns the name of the LM method. If a custom collection model strategy is
+   * used, its name is included as well.
+   * @see #getName()
+   * @see CollectionModel#getName()
+   * @see DefaultCollectionModel 
+   */
+  @Override
+  public String toString() {
+    String coll = collectionModel.getName();
+    if (coll != null) {
+      return String.format(Locale.ROOT, "LM %s - %s", getName(), coll);
+    } else {
+      return String.format(Locale.ROOT, "LM %s", getName());
+    }
+  }
+
+  /** Stores the collection distribution of the current term. */
+  public static class LMStats extends BasicStats {
+    /** The probability that the current term is generated by the collection. */
+    private float collectionProbability;
+    
+    /**
+     * Creates LMStats for the provided field and query-time boost
+     */
+    public LMStats(String field, float queryBoost) {
+      super(field, queryBoost);
+    }
+    
+    /**
+     * Returns the probability that the current term is generated by the
+     * collection.
+     */
+    public final float getCollectionProbability() {
+      return collectionProbability;
+    }
+    
+    /**
+     * Sets the probability that the current term is generated by the
+     * collection.
+     */
+    public final void setCollectionProbability(float collectionProbability) {
+      this.collectionProbability = collectionProbability;
+    } 
+  }
+  
+  /** A strategy for computing the collection language model. */
+  public static interface CollectionModel {
+    /**
+     * Computes the probability {@code p(w|C)} according to the language model
+     * strategy for the current term.
+     */
+    public float computeProbability(BasicStats stats);
+    
+    /** The name of the collection model strategy. */
+    public String getName();
+  }
+  
+  /**
+   * Models {@code p(w|C)} as the number of occurrences of the term in the
+   * collection, divided by the total number of tokens {@code + 1}.
+   */
+  public static class DefaultCollectionModel implements CollectionModel {
+
+    /** Sole constructor: parameter-free */
+    public DefaultCollectionModel() {}
+
+    @Override
+    public float computeProbability(BasicStats stats) {
+        return ((float)stats.getTotalTermFreq()) / ((float)stats.getNumberOfFieldTokens());
+    }
+    
+    @Override
+    public String getName() {
+      return null;
+    }
+  }
+  
+}
Index: lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBaseAccurateDocLength.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBaseAccurateDocLength.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBaseAccurateDocLength.java	(revision 0)
@@ -0,0 +1,107 @@
+package org.apache.lucene.search.similarities;
+
+import java.io.IOException;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.FieldInvertState;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.util.BytesRef;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public abstract class SimilarityBaseAccurateDocLength extends SimilarityBase {
+  
+  @Override
+  public long computeNorm(FieldInvertState state) {
+    final int numTerms;
+    if (discountOverlaps)
+      numTerms = state.getLength() - state.getNumOverlap();
+    else
+      numTerms = state.getLength();
+    return numTerms;
+  }
+  
+  @Override
+  public SimScorer simScorer(SimWeight stats, AtomicReaderContext context) throws IOException {
+    if (stats instanceof MultiSimilarity.MultiStats) {
+      // a multi term query (e.g. phrase). return the summation, 
+      // scoring almost as if it were boolean query
+      SimWeight subStats[] = ((MultiSimilarity.MultiStats) stats).subStats;
+      SimScorer subScorers[] = new SimScorer[subStats.length];
+      for (int i = 0; i < subScorers.length; i++) {
+        BasicStats basicstats = (BasicStats) subStats[i];
+        subScorers[i] = new BasicSimScorer(basicstats, context.reader().getNormValues(basicstats.field));
+      }
+      return new MultiSimilarity.MultiSimScorer(subScorers);
+    } else {
+      BasicStats basicstats = (BasicStats) stats;
+      return new BasicSimScorer(basicstats, context.reader().getNormValues(basicstats.field));
+    }
+  }
+  
+  /** Delegates the {@link #score(int, float)} and
+   * {@link #explain(int, Explanation)} methods to
+   * {@link SimilarityBase#score(BasicStats, float, float)} and
+   * {@link SimilarityBase#explain(BasicStats, int, Explanation, float)},
+   * respectively.
+   */
+  private class BasicSimScorer extends SimScorer {
+    private final BasicStats stats;
+    private final NumericDocValues norms;
+    
+    BasicSimScorer(BasicStats stats, NumericDocValues norms) throws IOException {
+      this.stats = stats;
+      this.norms = norms;
+    }
+    
+    @Override
+    public float score(int doc, float freq) {
+      // We have to supply something in case norms are omitted
+      return SimilarityBaseAccurateDocLength.this.score(stats, freq,
+          norms == null ? 1F : norms.get(doc));
+    }
+
+    @Override
+    public float background(int docID) {
+      return SimilarityBaseAccurateDocLength.this.background(norms.get(docID),stats);
+    }
+    
+    @Override
+    public Explanation explain(int doc, Explanation freq) {
+      return SimilarityBaseAccurateDocLength.this.explain(stats, doc, freq,
+          norms == null ? 1F : norms.get(doc));
+    }
+
+    @Override
+    public float computeSlopFactor(int distance) {
+      return 1.0f / (distance + 1);
+    }
+
+    @Override
+    public float computePayloadFactor(int doc, int start, int end, BytesRef payload) {
+      return 1f;
+    }
+  }
+
+  public float background(long l, BasicStats stats) {
+    return 0;
+  }
+
+  
+}
Index: lucene/core/src/java/org/apache/lucene/search/similarities/Similarity.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/similarities/Similarity.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/similarities/Similarity.java	(working copy)
@@ -216,6 +216,10 @@
       result.addDetail(freq);
       return result;
     }
+    
+    public float background(int docID) {
+      return 0;
+    }
   }
   
   /** Stores the weight for a query across the indexed collection. This abstract
Index: lucene/core/src/java/org/apache/lucene/search/similarities/LMDirichletSimilarityAccurateDocLength.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/similarities/LMDirichletSimilarityAccurateDocLength.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/similarities/LMDirichletSimilarityAccurateDocLength.java	(revision 0)
@@ -0,0 +1,94 @@
+package org.apache.lucene.search.similarities;
+
+import java.util.Locale;
+
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.similarities.LMSimilarity.CollectionModel;
+import org.apache.lucene.search.similarities.LMSimilarity.LMStats;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class LMDirichletSimilarityAccurateDocLength extends LMSimilarityAccurateDocLength {
+  /** The &mu; parameter. */
+  private final float mu;
+  
+  /** Instantiates the similarity with the provided &mu; parameter. */
+  public LMDirichletSimilarityAccurateDocLength(CollectionModel collectionModel, float mu) {
+    super(collectionModel);
+    this.mu = mu;
+  }
+  
+  /** Instantiates the similarity with the provided &mu; parameter. */
+  public LMDirichletSimilarityAccurateDocLength(float mu) {
+    this.mu = mu;
+  }
+
+  /** Instantiates the similarity with the default &mu; value of 2000. */
+  public LMDirichletSimilarityAccurateDocLength(CollectionModel collectionModel) {
+    this(collectionModel, 2000);
+  }
+  
+  /** Instantiates the similarity with the default &mu; value of 2000. */
+  public LMDirichletSimilarityAccurateDocLength() {
+    this(2000);
+  }
+  
+  @Override
+  protected float score(BasicStats stats, float freq, float docLen) {
+    float score = stats.getTotalBoost() * (float)(Math.log(1 + freq /
+        (mu * ((LMStats)stats).getCollectionProbability())));
+    return score;
+  }
+  
+  @Override
+  protected void explain(Explanation expl, BasicStats stats, int doc,
+      float freq, float docLen) {
+    if (stats.getTotalBoost() != 1.0f) {
+      expl.addDetail(new Explanation(stats.getTotalBoost(), "boost"));
+    }
+
+    expl.addDetail(new Explanation(mu, "mu"));
+    Explanation weightExpl = new Explanation();
+    weightExpl.setValue((float)Math.log(1 + freq /
+        (mu * ((LMStats)stats).getCollectionProbability())));
+    weightExpl.setDescription("term weight");
+    expl.addDetail(weightExpl);
+    expl.addDetail(new Explanation(
+        (float)Math.log(mu / (docLen + mu)), "document norm"));
+    super.explain(expl, stats, doc, freq, docLen);
+  }
+
+  /** Returns the &mu; parameter. */
+  public float getMu() {
+    return mu;
+  }
+  
+  @Override
+  public String getName() {
+    return String.format(Locale.ROOT, "Dirichlet(%f)", getMu());
+  }
+  
+  
+  @Override
+  public float background(long l, BasicStats stats) {
+    if (((LMStats)stats).getCollectionProbability()==0){
+      return 0;
+    }
+    return stats.getTotalBoost()*((float)Math.log(((LMStats)stats).getCollectionProbability())+ (float)Math.log(this.mu/(this.mu+l)));
+  }
+}
Index: lucene/core/src/java/org/apache/lucene/search/similarities/LMJelinekMercerSimilarityAccurateDocLength.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/similarities/LMJelinekMercerSimilarityAccurateDocLength.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/similarities/LMJelinekMercerSimilarityAccurateDocLength.java	(revision 0)
@@ -0,0 +1,78 @@
+package org.apache.lucene.search.similarities;
+
+import java.util.Locale;
+
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.similarities.LMSimilarity.CollectionModel;
+import org.apache.lucene.search.similarities.LMSimilarity.LMStats;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class LMJelinekMercerSimilarityAccurateDocLength extends LMSimilarityAccurateDocLength {
+  /** The &lambda; parameter. */
+  private final float lambda;
+  
+  /** Instantiates with the specified collectionModel and &lambda; parameter. */
+  public LMJelinekMercerSimilarityAccurateDocLength(
+      CollectionModel collectionModel, float lambda) {
+    super(collectionModel);
+    this.lambda = lambda;
+  }
+
+  /** Instantiates with the specified &lambda; parameter. */
+  public LMJelinekMercerSimilarityAccurateDocLength(float lambda) {
+    this.lambda = lambda;
+  }
+  
+  @Override
+  protected float score(BasicStats stats, float freq, float docLen) {
+    return stats.getTotalBoost() *
+        (float)Math.log(1 +
+            ((1 - lambda) * freq / docLen) /
+            (lambda * ((LMStats)stats).getCollectionProbability()));
+  }
+  
+  @Override
+  protected void explain(Explanation expl, BasicStats stats, int doc,
+      float freq, float docLen) {
+    if (stats.getTotalBoost() != 1.0f) {
+      expl.addDetail(new Explanation(stats.getTotalBoost(), "boost"));
+    }
+    expl.addDetail(new Explanation(lambda, "lambda"));
+    super.explain(expl, stats, doc, freq, docLen);
+  }
+
+  /** Returns the &lambda; parameter. */
+  public float getLambda() {
+    return lambda;
+  }
+
+  @Override
+  public String getName() {
+    return String.format(Locale.ROOT, "Jelinek-Mercer(%f)", getLambda());
+  }
+  
+  @Override
+  public float background(long l, BasicStats stats) {
+    if (((LMStats)stats).getCollectionProbability()==0){
+      return 0;
+    }
+    return stats.getTotalBoost()*(float)Math.log(lambda * ((LMStats)stats).getCollectionProbability());
+  }
+  
+}
Index: lucene/core/src/java/org/apache/lucene/search/FakeScorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/FakeScorer.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/FakeScorer.java	(working copy)
@@ -25,6 +25,7 @@
   float score;
   int doc = -1;
   int freq = 1;
+  float background = 0;
 
   public FakeScorer() {
     super(null);
@@ -56,6 +57,11 @@
   }
 
   @Override
+  public float background(int doc){
+    return background;
+  }
+  
+  @Override
   public long cost() {
     return 1;
   }
Index: lucene/core/src/java/org/apache/lucene/search/BooleanQueryDirichletLM.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/BooleanQueryDirichletLM.java	(revision 0)
+++ lucene/core/src/java/org/apache/lucene/search/BooleanQueryDirichletLM.java	(revision 0)
@@ -0,0 +1,663 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.similarities.LMSimilarityAccurateDocLength;
+import org.apache.lucene.search.similarities.Similarity;
+import org.apache.lucene.search.similarities.SimilarityBaseAccurateDocLength;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.ToStringUtils;
+
+/** A Query that matches documents matching boolean combinations of other
+  * queries, e.g. {@link TermQuery}s, {@link PhraseQuery}s or other
+  * BooleanQuerys.
+  */
+public class BooleanQueryDirichletLM extends Query implements Iterable<BooleanClause> {
+
+  private static int maxClauseCount = 1024;
+
+  /** Thrown when an attempt is made to add more than {@link
+   * #getMaxClauseCount()} clauses. This typically happens if
+   * a PrefixQuery, FuzzyQuery, WildcardQuery, or TermRangeQuery 
+   * is expanded to many terms during search. 
+   */
+  public static class TooManyClauses extends RuntimeException {
+    public TooManyClauses() {
+      super("maxClauseCount is set to " + maxClauseCount);
+    }
+  }
+
+  /** Return the maximum number of clauses permitted, 1024 by default.
+   * Attempts to add more than the permitted number of clauses cause {@link
+   * TooManyClauses} to be thrown.
+   * @see #setMaxClauseCount(int)
+   */
+  public static int getMaxClauseCount() { return maxClauseCount; }
+
+  /** 
+   * Set the maximum number of clauses permitted per BooleanQuery.
+   * Default value is 1024.
+   */
+  public static void setMaxClauseCount(int maxClauseCount) {
+    if (maxClauseCount < 1) {
+      throw new IllegalArgumentException("maxClauseCount must be >= 1");
+    }
+    BooleanQueryDirichletLM.maxClauseCount = maxClauseCount;
+  }
+
+  private ArrayList<BooleanClause> clauses = new ArrayList<>();
+  private final boolean disableCoord;
+
+  /** Constructs an empty boolean query. */
+  public BooleanQueryDirichletLM() {
+    disableCoord = false;
+  }
+
+  /** Constructs an empty boolean query.
+   *
+   * {@link Similarity#coord(int,int)} may be disabled in scoring, as
+   * appropriate. For example, this score factor does not make sense for most
+   * automatically generated queries, like {@link WildcardQuery} and {@link
+   * FuzzyQuery}.
+   *
+   * @param disableCoord disables {@link Similarity#coord(int,int)} in scoring.
+   */
+  public BooleanQueryDirichletLM(boolean disableCoord) {
+    this.disableCoord = disableCoord;
+  }
+
+  /** Returns true iff {@link Similarity#coord(int,int)} is disabled in
+   * scoring for this query instance.
+   * @see #BooleanQueryDirichletLM(boolean)
+   */
+  public boolean isCoordDisabled() { return disableCoord; }
+
+  /**
+   * Specifies a minimum number of the optional BooleanClauses
+   * which must be satisfied.
+   *
+   * <p>
+   * By default no optional clauses are necessary for a match
+   * (unless there are no required clauses).  If this method is used,
+   * then the specified number of clauses is required.
+   * </p>
+   * <p>
+   * Use of this method is totally independent of specifying that
+   * any specific clauses are required (or prohibited).  This number will
+   * only be compared against the number of matching optional clauses.
+   * </p>
+   *
+   * @param min the number of optional clauses that must match
+   */
+  public void setMinimumNumberShouldMatch(int min) {
+    this.minNrShouldMatch = min;
+  }
+  protected int minNrShouldMatch = 0;
+
+  /**
+   * Gets the minimum number of the optional BooleanClauses
+   * which must be satisfied.
+   */
+  public int getMinimumNumberShouldMatch() {
+    return minNrShouldMatch;
+  }
+
+  /** Adds a clause to a boolean query.
+   *
+   * @throws TooManyClauses if the new number of clauses exceeds the maximum clause number
+   * @see #getMaxClauseCount()
+   */
+  public void add(Query query, BooleanClause.Occur occur) {
+    add(new BooleanClause(query, occur));
+  }
+
+  /** Adds a clause to a boolean query.
+   * @throws TooManyClauses if the new number of clauses exceeds the maximum clause number
+   * @see #getMaxClauseCount()
+   */
+  public void add(BooleanClause clause) {
+    if (clauses.size() >= maxClauseCount) {
+      throw new TooManyClauses();
+    }
+
+    clauses.add(clause);
+  }
+
+  /** Returns the set of clauses in this query. */
+  public BooleanClause[] getClauses() {
+    return clauses.toArray(new BooleanClause[clauses.size()]);
+  }
+
+  /** Returns the list of clauses in this query. */
+  public List<BooleanClause> clauses() { return clauses; }
+
+  /** Returns an iterator on the clauses in this query. It implements the {@link Iterable} interface to
+   * make it possible to do:
+   * <pre class="prettyprint">for (BooleanClause clause : booleanQuery) {}</pre>
+   */
+  @Override
+  public final Iterator<BooleanClause> iterator() { return clauses().iterator(); }
+
+  /**
+   * Expert: the Weight for BooleanQuery, used to
+   * normalize, score and explain these queries.
+   *
+   * @lucene.experimental
+   */
+  protected class BooleanWeightDirichletLM extends Weight {
+    /** The Similarity implementation. */
+    protected Similarity similarity;
+    protected ArrayList<Weight> weights;
+    protected int maxCoord;  // num optional + num required
+    private final boolean disableCoord;
+
+    public BooleanWeightDirichletLM(IndexSearcher searcher, boolean disableCoord)
+      throws IOException {
+      this.similarity = searcher.getSimilarity();
+      this.disableCoord = disableCoord;
+      weights = new ArrayList<>(clauses.size());
+      for (int i = 0 ; i < clauses.size(); i++) {
+        BooleanClause c = clauses.get(i);
+        Weight w = c.getQuery().createWeight(searcher);
+        weights.add(w);
+        if (!c.isProhibited()) {
+          maxCoord++;
+        }
+      }
+    }
+
+    @Override
+    public Query getQuery() { return BooleanQueryDirichletLM.this; }
+
+    @Override
+    public float getValueForNormalization() throws IOException {
+      float sum = 0.0f;
+      for (int i = 0 ; i < weights.size(); i++) {
+        // call sumOfSquaredWeights for all clauses in case of side effects
+        float s = weights.get(i).getValueForNormalization();         // sum sub weights
+        if (!clauses.get(i).isProhibited()) {
+          // only add to sum for non-prohibited clauses
+          sum += s;
+        }
+      }
+
+      sum *= getBoost() * getBoost();             // boost each sub-weight
+
+      return sum ;
+    }
+
+    public float coord(int overlap, int maxOverlap) {
+      // LUCENE-4300: in most cases of maxOverlap=1, BQ rewrites itself away,
+      // so coord() is not applied. But when BQ cannot optimize itself away
+      // for a single clause (minNrShouldMatch, prohibited clauses, etc), its
+      // important not to apply coord(1,1) for consistency, it might not be 1.0F
+      return maxOverlap == 1 ? 1F : similarity.coord(overlap, maxOverlap);
+    }
+
+    @Override
+    public void normalize(float norm, float topLevelBoost) {
+      topLevelBoost *= getBoost();                         // incorporate boost
+      for (Weight w : weights) {
+        // normalize all clauses, (even if prohibited in case of side affects)
+        w.normalize(norm, topLevelBoost);
+      }
+    }
+
+    @Override
+    public Explanation explain(AtomicReaderContext context, int doc)
+      throws IOException {
+      final int minShouldMatch =
+        BooleanQueryDirichletLM.this.getMinimumNumberShouldMatch();
+      ComplexExplanation sumExpl = new ComplexExplanation();
+      sumExpl.setDescription("sum of:");
+      int coord = 0;
+      float sum = 0.0f;
+      boolean fail = false;
+      int shouldMatchCount = 0;
+      Iterator<BooleanClause> cIter = clauses.iterator();
+      for (Iterator<Weight> wIter = weights.iterator(); wIter.hasNext();) {
+        Weight w = wIter.next();
+        BooleanClause c = cIter.next();
+        if (w.scorer(context, context.reader().getLiveDocs()) == null) {
+          if (c.isRequired()) {
+            fail = true;
+            Explanation r = new Explanation(0.0f, "no match on required clause (" + c.getQuery().toString() + ")");
+            sumExpl.addDetail(r);
+          }
+          continue;
+        }
+        Explanation e = w.explain(context, doc);
+        if (e.isMatch()) {
+          if (!c.isProhibited()) {
+            sumExpl.addDetail(e);
+            sum += e.getValue();
+            coord++;
+          } else {
+            Explanation r =
+              new Explanation(0.0f, "match on prohibited clause (" + c.getQuery().toString() + ")");
+            r.addDetail(e);
+            sumExpl.addDetail(r);
+            fail = true;
+          }
+          if (c.getOccur() == Occur.SHOULD) {
+            shouldMatchCount++;
+          }
+        } else if (c.isRequired()) {
+          Explanation r = new Explanation(0.0f, "no match on required clause (" + c.getQuery().toString() + ")");
+          r.addDetail(e);
+          sumExpl.addDetail(r);
+          fail = true;
+        }
+      }
+      if (fail) {
+        sumExpl.setMatch(Boolean.FALSE);
+        sumExpl.setValue(0.0f);
+        sumExpl.setDescription
+          ("Failure to meet condition(s) of required/prohibited clause(s)");
+        return sumExpl;
+      } else if (shouldMatchCount < minShouldMatch) {
+        sumExpl.setMatch(Boolean.FALSE);
+        sumExpl.setValue(0.0f);
+        sumExpl.setDescription("Failure to match minimum number "+
+                               "of optional clauses: " + minShouldMatch);
+        return sumExpl;
+      }
+      
+      sumExpl.setMatch(0 < coord ? Boolean.TRUE : Boolean.FALSE);
+      sumExpl.setValue(sum);
+      
+      final float coordFactor = disableCoord ? 1.0f : coord(coord, maxCoord);
+      if (coordFactor == 1.0f) {
+        return sumExpl;                             // eliminate wrapper
+      } else {
+        ComplexExplanation result = new ComplexExplanation(sumExpl.isMatch(),
+                                                           sum*coordFactor,
+                                                           "product of:");
+        result.addDetail(sumExpl);
+        result.addDetail(new Explanation(coordFactor,
+                                         "coord("+coord+"/"+maxCoord+")"));
+        return result;
+      }
+    }
+
+    @Override
+    public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder,
+                                 Bits acceptDocs) throws IOException {
+
+      if (scoreDocsInOrder || minNrShouldMatch > 1) {
+        // TODO: (LUCENE-4872) in some cases BooleanScorer may be faster for minNrShouldMatch
+        // but the same is even true of pure conjunctions...
+        return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);
+      }
+
+      List<BulkScorer> prohibited = new ArrayList<BulkScorer>();
+      List<BulkScorer> optional = new ArrayList<BulkScorer>();
+      Iterator<BooleanClause> cIter = clauses.iterator();
+      for (Weight w  : weights) {
+        BooleanClause c =  cIter.next();
+        BulkScorer subScorer = w.bulkScorer(context, false, acceptDocs);
+        if (subScorer == null) {
+          if (c.isRequired()) {
+            return null;
+          }
+        } else if (c.isRequired()) {
+          // TODO: there are some cases where BooleanScorer
+          // would handle conjunctions faster than
+          // BooleanScorer2...
+          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);
+        } else if (c.isProhibited()) {
+          prohibited.add(subScorer);
+        } else {
+          optional.add(subScorer);
+        }
+      }
+
+      // Check if we can and should return a BooleanScorer
+      return new BooleanScorerDirichletLM(this, disableCoord, minNrShouldMatch, optional, prohibited, maxCoord);
+    }
+
+    @Override
+    public Scorer scorer(AtomicReaderContext context, Bits acceptDocs)
+        throws IOException {
+      // initially the user provided value,
+      // but if minNrShouldMatch == optional.size(),
+      // we will optimize and move these to required, making this 0
+      int minShouldMatch = minNrShouldMatch;
+
+      List<Scorer> required = new ArrayList<>();
+      List<Scorer> prohibited = new ArrayList<>();
+      List<Scorer> optional = new ArrayList<>();
+      Iterator<BooleanClause> cIter = clauses.iterator();
+      for (Weight w  : weights) {
+        BooleanClause c =  cIter.next();
+        Scorer subScorer = w.scorer(context, acceptDocs);
+        if (subScorer == null) {
+          if (c.isRequired()) {
+            return null;
+          }
+        } else if (c.isRequired()) {
+          required.add(subScorer);
+        } else if (c.isProhibited()) {
+          prohibited.add(subScorer);
+        } else {
+          optional.add(subScorer);
+        }
+      }
+      
+      // scorer simplifications:
+      
+      if (optional.size() == minShouldMatch) {
+        // any optional clauses are in fact required
+        required.addAll(optional);
+        optional.clear();
+        minShouldMatch = 0;
+      }
+      
+      if (required.isEmpty() && optional.isEmpty()) {
+        // no required and optional clauses.
+        return null;
+      } else if (optional.size() < minShouldMatch) {
+        // either >1 req scorer, or there are 0 req scorers and at least 1
+        // optional scorer. Therefore if there are not enough optional scorers
+        // no documents will be matched by the query
+        return null;
+      }
+      
+      // three cases: conjunction, disjunction, or mix
+      
+      // pure conjunction
+      if (optional.isEmpty()) {
+        return excl(req(required, disableCoord), prohibited);
+      }
+      
+      // pure disjunction
+      if (required.isEmpty()) {
+        return excl(opt(optional, minShouldMatch, disableCoord), prohibited);
+      }
+      
+      // conjunction-disjunction mix:
+      // we create the required and optional pieces with coord disabled, and then
+      // combine the two: if minNrShouldMatch > 0, then its a conjunction: because the
+      // optional side must match. otherwise its required + optional, factoring the
+      // number of optional terms into the coord calculation
+      
+      Scorer req = excl(req(required, true), prohibited);
+      Scorer opt = opt(optional, minShouldMatch, true);
+
+      // TODO: clean this up: its horrible
+      if (disableCoord) {
+        if (minShouldMatch > 0) {
+          return new ConjunctionScorer(this, new Scorer[] { req, opt }, 1F);
+        } else {
+          return new ReqOptSumScorer(req, opt);          
+        }
+      } else if (optional.size() == 1) {
+        if (minShouldMatch > 0) {
+          return new ConjunctionScorer(this, new Scorer[] { req, opt }, coord(required.size()+1, maxCoord));
+        } else {
+          float coordReq = coord(required.size(), maxCoord);
+          float coordBoth = coord(required.size() + 1, maxCoord);
+          return new BooleanTopLevelScorers.ReqSingleOptScorer(req, opt, coordReq, coordBoth);
+        }
+      } else {
+        if (minShouldMatch > 0) {
+          return new BooleanTopLevelScorers.CoordinatingConjunctionScorer(this, coords(), req, required.size(), opt);
+        } else {
+          return new BooleanTopLevelScorers.ReqMultiOptScorer(req, opt, required.size(), coords()); 
+        }
+      }
+    }
+    
+    @Override
+    public boolean scoresDocsOutOfOrder() {
+      if (minNrShouldMatch > 1) {
+        // BS2 (in-order) will be used by scorer()
+        return false;
+      }
+      int optionalCount = 0;
+      for (BooleanClause c : clauses) {
+        if (c.isRequired()) {
+          // BS2 (in-order) will be used by scorer()
+          return false;
+        } else if (!c.isProhibited()) {
+          optionalCount++;
+        }
+      }
+      
+      if (optionalCount == minNrShouldMatch) {
+        return false; // BS2 (in-order) will be used, as this means conjunction
+      }
+      
+      // scorer() will return an out-of-order scorer if requested.
+      return true;
+    }
+    
+    private Scorer req(List<Scorer> required, boolean disableCoord) {
+      if (required.size() == 1) {
+        Scorer req = required.get(0);
+        if (!disableCoord && maxCoord > 1) {
+          return new BooleanTopLevelScorers.BoostedScorer(req, coord(1, maxCoord));
+        } else {
+          return req;
+        }
+      } else {
+        return new ConjunctionScorer(this, 
+                                     required.toArray(new Scorer[required.size()]),
+                                     disableCoord ? 1.0F : coord(required.size(), maxCoord));
+      }
+    }
+    
+    private Scorer excl(Scorer main, List<Scorer> prohibited) throws IOException {
+      if (prohibited.isEmpty()) {
+        return main;
+      } else if (prohibited.size() == 1) {
+        return new ReqExclScorer(main, prohibited.get(0));
+      } else {
+        float coords[] = new float[prohibited.size()+1];
+        Arrays.fill(coords, 1F);
+        return new ReqExclScorer(main, 
+                                 new DisjunctionSumScorer(this, 
+                                                          prohibited.toArray(new Scorer[prohibited.size()]), 
+                                                          coords));
+      }
+    }
+    
+    private Scorer opt(List<Scorer> optional, int minShouldMatch, boolean disableCoord) throws IOException {
+      if (optional.size() == 1) {
+        Scorer opt = optional.get(0);
+        if (!disableCoord && maxCoord > 1) {
+          return new BooleanTopLevelScorers.BoostedScorer(opt, coord(1, maxCoord));
+        } else {
+          return opt;
+        }
+      } else {
+        float coords[];
+        if (disableCoord) {
+          coords = new float[optional.size()+1];
+          Arrays.fill(coords, 1F);
+        } else {
+          coords = coords();
+        }
+        if (minShouldMatch > 1) {
+          return new MinShouldMatchSumScorer(this, optional, minShouldMatch, coords);
+        } else {
+          return new DisjunctionSumScorer(this, 
+                                          optional.toArray(new Scorer[optional.size()]), 
+                                          coords);
+        }
+      }
+    }  
+    
+    private float[] coords() {
+      float[] coords = new float[maxCoord+1];
+      coords[0] = 0F;
+      for (int i = 1; i < coords.length; i++) {
+        coords[i] = coord(i, maxCoord);
+      }
+      return coords;
+    }
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher) throws IOException {
+    return new BooleanWeightDirichletLM(searcher, disableCoord);
+  }
+
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    if (minNrShouldMatch == 0 && clauses.size() == 1) {                    // optimize 1-clause queries
+      BooleanClause c = clauses.get(0);
+      if (!c.isProhibited()) {  // just return clause
+
+        Query query = c.getQuery().rewrite(reader);    // rewrite first
+
+        if (getBoost() != 1.0f) {                 // incorporate boost
+          if (query == c.getQuery()) {                   // if rewrite was no-op
+            query = query.clone();         // then clone before boost
+          }
+          // Since the BooleanQuery only has 1 clause, the BooleanQuery will be
+          // written out. Therefore the rewritten Query's boost must incorporate both
+          // the clause's boost, and the boost of the BooleanQuery itself
+          query.setBoost(getBoost() * query.getBoost());
+        }
+
+        return query;
+      }
+    }
+
+    BooleanQueryDirichletLM clone = null;                    // recursively rewrite
+    for (int i = 0 ; i < clauses.size(); i++) {
+      BooleanClause c = clauses.get(i);
+      Query query = c.getQuery().rewrite(reader);
+      if (query != c.getQuery()) {                     // clause rewrote: must clone
+        if (clone == null) {
+          // The BooleanQuery clone is lazily initialized so only initialize
+          // it if a rewritten clause differs from the original clause (and hasn't been
+          // initialized already).  If nothing differs, the clone isn't needlessly created
+          clone = this.clone();
+        }
+        clone.clauses.set(i, new BooleanClause(query, c.getOccur()));
+      }
+    }
+    if (clone != null) {
+      return clone;                               // some clauses rewrote
+    } else {
+      return this;                                // no clauses rewrote
+    }
+  }
+
+  // inherit javadoc
+  @Override
+  public void extractTerms(Set<Term> terms) {
+    for (BooleanClause clause : clauses) {
+      if (clause.getOccur() != Occur.MUST_NOT) {
+        clause.getQuery().extractTerms(terms);
+      }
+    }
+  }
+
+  @Override @SuppressWarnings("unchecked")
+  public BooleanQueryDirichletLM clone() {
+    BooleanQueryDirichletLM clone = (BooleanQueryDirichletLM)super.clone();
+    clone.clauses = (ArrayList<BooleanClause>) this.clauses.clone();
+    return clone;
+  }
+
+  /** Prints a user-readable version of this query. */
+  @Override
+  public String toString(String field) {
+    StringBuilder buffer = new StringBuilder();
+    boolean needParens= getBoost() != 1.0 || getMinimumNumberShouldMatch() > 0;
+    if (needParens) {
+      buffer.append("(");
+    }
+
+    for (int i = 0 ; i < clauses.size(); i++) {
+      BooleanClause c = clauses.get(i);
+      if (c.isProhibited()) {
+        buffer.append("-");
+      } else if (c.isRequired()) {
+        buffer.append("+");
+      }
+
+      Query subQuery = c.getQuery();
+      if (subQuery != null) {
+        if (subQuery instanceof BooleanQueryDirichletLM) {  // wrap sub-bools in parens
+          buffer.append("(");
+          buffer.append(subQuery.toString(field));
+          buffer.append(")");
+        } else {
+          buffer.append(subQuery.toString(field));
+        }
+      } else {
+        buffer.append("null");
+      }
+
+      if (i != clauses.size()-1) {
+        buffer.append(" ");
+      }
+    }
+
+    if (needParens) {
+      buffer.append(")");
+    }
+
+    if (getMinimumNumberShouldMatch()>0) {
+      buffer.append('~');
+      buffer.append(getMinimumNumberShouldMatch());
+    }
+
+    if (getBoost() != 1.0f) {
+      buffer.append(ToStringUtils.boost(getBoost()));
+    }
+
+    return buffer.toString();
+  }
+
+  /** Returns true iff <code>o</code> is equal to this. */
+  @Override
+  public boolean equals(Object o) {
+    if (!(o instanceof BooleanQueryDirichletLM)) {
+      return false;
+    }
+    BooleanQueryDirichletLM other = (BooleanQueryDirichletLM)o;
+    return this.getBoost() == other.getBoost()
+        && this.clauses.equals(other.clauses)
+        && this.getMinimumNumberShouldMatch() == other.getMinimumNumberShouldMatch()
+        && this.disableCoord == other.disableCoord;
+  }
+
+  /** Returns a hash code value for this object.*/
+  @Override
+  public int hashCode() {
+    return Float.floatToIntBits(getBoost()) ^ clauses.hashCode()
+      + getMinimumNumberShouldMatch() + (disableCoord ? 17:0);
+  }
+  
+}
Index: lucene/core/src/java/org/apache/lucene/search/TopScoreDocCollector.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/TopScoreDocCollector.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/TopScoreDocCollector.java	(working copy)
@@ -44,7 +44,7 @@
     
     @Override
     public void collect(int doc) throws IOException {
-      float score = scorer.score();
+      float score = scorer.score()+scorer.background(doc);
 
       // This collector cannot handle these scores:
       assert score != Float.NEGATIVE_INFINITY;
@@ -82,7 +82,7 @@
     
     @Override
     public void collect(int doc) throws IOException {
-      float score = scorer.score();
+      float score = scorer.score()+scorer.background(doc);;
 
       // This collector cannot handle these scores:
       assert score != Float.NEGATIVE_INFINITY;
@@ -137,7 +137,7 @@
     
     @Override
     public void collect(int doc) throws IOException {
-      float score = scorer.score();
+      float score = scorer.score()+scorer.background(doc);
 
       // This collector cannot handle NaN
       assert !Float.isNaN(score);
@@ -177,7 +177,7 @@
     
     @Override
     public void collect(int doc) throws IOException {
-      float score = scorer.score();
+      float score = scorer.score()+scorer.background(doc);
 
       // This collector cannot handle NaN
       assert !Float.isNaN(score);
Index: lucene/core/src/java/org/apache/lucene/search/Scorer.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/Scorer.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/Scorer.java	(working copy)
@@ -61,6 +61,13 @@
    */
   public abstract float score() throws IOException;
   
+  /**
+   * returns the background score of the current document matching the query.default is 0. 
+   */
+  public float background(int doc) throws IOException{
+    return 0;
+  }
+  
   /** returns parent Weight
    * @lucene.experimental
    */
Index: lucene/core/src/java/org/apache/lucene/search/Weight.java
===================================================================
--- lucene/core/src/java/org/apache/lucene/search/Weight.java	(revision 1611434)
+++ lucene/core/src/java/org/apache/lucene/search/Weight.java	(working copy)
@@ -149,6 +149,11 @@
       }
       this.scorer = scorer;
     }
+    
+    @Override
+    public float getBackGroundScore(int doc) throws IOException{
+      return this.scorer.background(doc);
+    }
 
     @Override
     public boolean score(LeafCollector collector, int max) throws IOException {
